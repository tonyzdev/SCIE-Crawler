[
  {
    "title": "Structured Pruning of Deep Convolutional Neural Networks",
    "doi": "https://doi.org/10.1145/3005348",
    "publication_date": "2017-02-09",
    "publication_year": 2017,
    "authors": "Sajid Anwar; Kyuyeon Hwang; Wonyong Sung",
    "corresponding_authors": "",
    "abstract": "Real-time application of deep learning algorithms is often hindered by high computational complexity and frequent memory accesses. Network pruning is a promising technique to solve this problem. However, pruning usually results in irregular network connections that not only demand extra representation efforts but also do not fit well on parallel computation. We introduce structured sparsity at various scales for convolutional neural networks: feature map-wise, kernel-wise, and intra-kernel strided sparsity. This structured sparsity is very advantageous for direct computational resource savings on embedded computers, in parallel computing environments, and in hardware-based systems. To decide the importance of network connections and paths, the proposed method uses a particle filtering approach. The importance weight of each particle is assigned by assessing the misclassification rate with a corresponding connectivity pattern. The pruned network is retrained to compensate for the losses due to pruning. While implementing convolutions as matrix products, we particularly show that intra-kernel strided sparsity with a simple constraint can significantly reduce the size of the kernel and feature map tensors. The proposed work shows that when pruning granularities are applied in combination, we can prune the CIFAR-10 network by more than 70% with less than a 1% loss in accuracy.",
    "cited_by_count": 669,
    "openalex_id": "https://openalex.org/W2276892413",
    "type": "article"
  },
  {
    "title": "Spin-transfer torque magnetic random access memory (STT-MRAM)",
    "doi": "https://doi.org/10.1145/2463585.2463589",
    "publication_date": "2013-05-01",
    "publication_year": 2013,
    "authors": "Dmytro Apalkov; A. V. Khvalkovskiy; Steven Watts; V. Nikitin; Xueti Tang; D. K. Lottis; Ki-Seok Moon; Xiao Luo; Eugene Chen; Adrian Ong; A. Driskill-Smith; M. Krounbi",
    "corresponding_authors": "",
    "abstract": "Spin-transfer torque magnetic random access memory (STT-MRAM) is a novel, magnetic memory technology that leverages the base platform established by an existing 100+nm node memory product called MRAM to enable a scalable nonvolatile memory solution for advanced process nodes. STT-MRAM features fast read and write times, small cell sizes of 6F 2 and potentially even smaller, and compatibility with existing DRAM and SRAM architecture with relatively small associated cost added. STT-MRAM is essentially a magnetic multilayer resistive element cell that is fabricated as an additional metal layer on top of conventional CMOS access transistors. In this review we give an overview of the existing STT-MRAM technologies currently in research and development across the world, as well as some specific discussion of results obtained at Grandis and with our foundry partners. We will show that in-plane STT-MRAM technology, particularly the DMTJ design, is a mature technology that meets all conventional requirements for an STT-MRAM cell to be a nonvolatile solution matching DRAM and/or SRAM drive circuitry. Exciting recent developments in perpendicular STT-MRAM also indicate that this type of STT-MRAM technology may reach maturity faster than expected, allowing even smaller cell size and product introduction at smaller nodes.",
    "cited_by_count": 454,
    "openalex_id": "https://openalex.org/W2010216838",
    "type": "article"
  },
  {
    "title": "A Survey on Chip to System Reverse Engineering",
    "doi": "https://doi.org/10.1145/2755563",
    "publication_date": "2016-04-13",
    "publication_year": 2016,
    "authors": "Md Shahed Enamul Quadir; Junlin Chen; Domenic Forte; Navid Asadizanjani; Sina Shahbazmohamadi; Lei Wang; John A. Chandy; Mark Tehranipoor",
    "corresponding_authors": "",
    "abstract": "The reverse engineering (RE) of electronic chips and systems can be used with honest and dishonest intentions. To inhibit RE for those with dishonest intentions (e.g., piracy and counterfeiting), it is important that the community is aware of the state-of-the-art capabilities available to attackers today. In this article, we will be presenting a survey of RE and anti-RE techniques on the chip, board, and system levels. We also highlight the current challenges and limitations of anti-RE and the research needed to overcome them. This survey should be of interest to both governmental and industrial bodies whose critical systems and intellectual property (IP) require protection from foreign enemies and counterfeiters who possess advanced RE capabilities.",
    "cited_by_count": 238,
    "openalex_id": "https://openalex.org/W2336864643",
    "type": "article"
  },
  {
    "title": "A Review, Classification, and Comparative Evaluation of Approximate Arithmetic Circuits",
    "doi": "https://doi.org/10.1145/3094124",
    "publication_date": "2017-08-11",
    "publication_year": 2017,
    "authors": "Honglan Jiang; Cong Liu; Leibo Liu; Fabrizio Lombardi; Jie Han",
    "corresponding_authors": "",
    "abstract": "Often as the most important arithmetic modules in a processor, adders, multipliers, and dividers determine the performance and energy efficiency of many computing tasks. The demand of higher speed and power efficiency, as well as the feature of error resilience in many applications (e.g., multimedia, recognition, and data analytics), have driven the development of approximate arithmetic design. In this article, a review and classification are presented for the current designs of approximate arithmetic circuits including adders, multipliers, and dividers. A comprehensive and comparative evaluation of their error and circuit characteristics is performed for understanding the features of various designs. By using approximate multipliers and adders, the circuit for an image processing application consumes as little as 47% of the power and 36% of the power-delay product of an accurate design while achieving similar image processing quality. Improvements in delay, power, and area are obtained for the detection of differences in images by using approximate dividers.",
    "cited_by_count": 234,
    "openalex_id": "https://openalex.org/W2742536119",
    "type": "article"
  },
  {
    "title": "Spiking Neural Networks Hardware Implementations and Challenges",
    "doi": "https://doi.org/10.1145/3304103",
    "publication_date": "2019-04-05",
    "publication_year": 2019,
    "authors": "Maxence Bouvier; Alexandre Valentian; Thomas Mesquida; François Rummens; Marina Reyboz; Elisa Vianello; Édith Beigné",
    "corresponding_authors": "",
    "abstract": "Neuromorphic computing is henceforth a major research field for both academic and industrial actors. As opposed to Von Neumann machines, brain-inspired processors aim at bringing closer the memory and the computational elements to efficiently evaluate machine learning algorithms. Recently, spiking neural networks, a generation of cognitive algorithms employing computational primitives mimicking neuron and synapse operational principles, have become an important part of deep learning. They are expected to improve the computational performance and efficiency of neural networks, but they are best suited for hardware able to support their temporal dynamics. In this survey, we present the state of the art of hardware implementations of spiking neural networks and the current trends in algorithm elaboration from model selection to training mechanisms. The scope of existing solutions is extensive; we thus present the general framework and study on a case-by-case basis the relevant particularities. We describe the strategies employed to leverage the characteristics of these event-driven algorithms at the hardware level and discuss their related advantages and challenges.",
    "cited_by_count": 200,
    "openalex_id": "https://openalex.org/W3124237980",
    "type": "article"
  },
  {
    "title": "Design space exploration for 3D architectures",
    "doi": "https://doi.org/10.1145/1148015.1148016",
    "publication_date": "2006-04-01",
    "publication_year": 2006,
    "authors": "Yuan Xie; Gabriel H. Loh; Bryan Black; Kerry Bernstein",
    "corresponding_authors": "",
    "abstract": "As technology scales, interconnects have become a major performance bottleneck and a major source of power consumption for microprocessors. Increasing interconnect costs make it necessary to consider alternate ways of building modern microprocessors. One promising option is 3D architectures where a stack of multiple device layers with direct vertical tunneling through them are put together on the same chip. As fabrication of 3D integrated circuits has become viable, developing CAD tools and architectural techniques is imperative to explore the design space to 3D microarchitectures. In this article, we give a brief introduction to 3D integration technology, discuss the EDA design tools that can enable the adoption of 3D ICs, and present the implementation of various microprocessor components using 3D technology. An industrial case study is presented as an initial attempt to design 3D microarchitectures.",
    "cited_by_count": 306,
    "openalex_id": "https://openalex.org/W1987131925",
    "type": "article"
  },
  {
    "title": "Nanowire-based programmable architectures",
    "doi": "https://doi.org/10.1145/1084748.1084750",
    "publication_date": "2005-07-01",
    "publication_year": 2005,
    "authors": "André DeHon",
    "corresponding_authors": "André DeHon",
    "abstract": "Chemists can now construct wires which are just a few atoms in diameter; these wires can be selectively field-effect gated, and wire crossings can act as diodes with programmable resistance. These new capabilities present both opportunities and challenges for constructing nanoscale computing systems. The tiny feature sizes offer a path to economically scale down to atomic dimensions. However, the associated bottom-up synthesis techniques only produce highly regular structures and come with high defect rates and minimal control during assembly. To exploit these technologies, we develop nanowire-based architectures which can bridge between lithographic and atomic-scale feature sizes and tolerate defective and stochastic assembly of regular arrays to deliver high density universal computing devices. Using 10nm pitch nanowires, these nanowire-based programmable architectures offer one to two orders of magnitude greater mapped-logic density than defect-free lithographic FPGAs at 22nm.",
    "cited_by_count": 265,
    "openalex_id": "https://openalex.org/W2147004330",
    "type": "article"
  },
  {
    "title": "Predictive technology model for nano-CMOS design exploration",
    "doi": "https://doi.org/10.1145/1229175.1229176",
    "publication_date": "2007-04-01",
    "publication_year": 2007,
    "authors": "Wei Zhao; Yu Cao",
    "corresponding_authors": "",
    "abstract": "A predictive MOSFET model is critical for early circuit design research. In this work, a new generation of Predictive Technology Model (PTM) is developed, covering emerging physical effects and alternative structures, such as the double-gate device (i.e., FinFET). Based on physical models and early stage silicon data, PTM of bulk and double-gate devices are successfully generated from 130nm to 32nm technology nodes, with effective channel length down to 13nm. By tuning only ten primary parameters, PTM can be easily customized to cover a wide range of process uncertainties. The accuracy of PTM predictions is comprehensively verified with published silicon data: the error of the current is below 10% for both NMOS and PMOS. Furthermore, the new PTM correctly captures process sensitivities in the nanometer regime. PTM is available online at http://www.eas.asu.edu/~ptm.",
    "cited_by_count": 250,
    "openalex_id": "https://openalex.org/W2105407012",
    "type": "article"
  },
  {
    "title": "Design of reversible sequential circuits optimizing quantum cost, delay, and garbage outputs",
    "doi": "https://doi.org/10.1145/1877745.1877748",
    "publication_date": "2010-12-01",
    "publication_year": 2010,
    "authors": "Himanshu Thapliyal; N. Ranganathan",
    "corresponding_authors": "",
    "abstract": "Reversible logic has shown potential to have extensive applications in emerging technologies such as quantum computing, optical computing, quantum dot cellular automata as well as ultra low power VLSI circuits. Recently, several researchers have focused their efforts on the design and synthesis of efficient reversible logic circuits. In these works, the primary design focus has been on optimizing the number of reversible gates and the garbage outputs. The number of reversible gates is not a good metric of optimization as each reversible gate is of different type and computational complexity, and thus will have a different quantum cost and delay. The computational complexity of a reversible gate can be represented by its quantum cost. Further, delay constitutes an important metric, which has not been addressed in prior works on reversible sequential circuits as a design metric to be optimized. In this work, we present novel designs of reversible sequential circuits that are optimized in terms of quantum cost, delay and the garbage outputs. The optimized designs of several reversible sequential circuits are presented including the D Latch, the JK latch, the T latch and the SR latch, and their corresponding reversible master-slave flip-flop designs. The proposed master-slave flip-flop designs have the special property that they don't require the inversion of the clock for use in the slave latch. Further, we introduce a novel strategy of cascading a Fredkin gate at the outputs of a reversible latch to realize the designs of the Fredkin gate based asynchronous set/reset D latch and the master-slave D flip-flop. Finally, as an example of complex reversible sequential circuits, the reversible logic design of the universal shift register is introduced. The proposed reversible sequential designs were verified through simulations using Verilog HDL and simulation results are presented.",
    "cited_by_count": 217,
    "openalex_id": "https://openalex.org/W2054495961",
    "type": "article"
  },
  {
    "title": "High-level synthesis of digital microfluidic biochips",
    "doi": "https://doi.org/10.1145/1324177.1324178",
    "publication_date": "2008-01-01",
    "publication_year": 2008,
    "authors": "Fei Su; Krishnendu Chakrabarty",
    "corresponding_authors": "",
    "abstract": "Microfluidic biochips offer a promising platform for massively parallel DNA analysis, automated drug discovery, and real-time biomolecular recognition. Current techniques for full-custom design of droplet-based “digital” biochips do not scale well for concurrent assays and for next-generation system-on-chip (SOC) designs that are expected to include microfluidic components. We propose a system design methodology that attempts to apply classical high-level synthesis techniques to the design of digital microfluidic biochips. We focus here on the problem of scheduling bioassay functions under resource constraints. We first develop an optimal scheduling strategy based on integer linear programming. However, because the scheduling problem is NP-complete, we also develop two heuristic techniques that scale well for large problem instances. A clinical diagnostic procedure, namely multiplexed in-vitro diagnostics on human physiological fluids, is first used to illustrate and evaluate the proposed method. Next, the synthesis approach is applied to a protein assay, which serves as a more complex bioassay application. The proposed synthesis approach is expected to reduce human effort and design cycle time, and it will facilitate the integration of microfluidic components with microelectronic components in next-generation SOCs.",
    "cited_by_count": 195,
    "openalex_id": "https://openalex.org/W2147820467",
    "type": "article"
  },
  {
    "title": "A survey of software aging and rejuvenation studies",
    "doi": "https://doi.org/10.1145/2539117",
    "publication_date": "2014-01-01",
    "publication_year": 2014,
    "authors": "Domenico Cotroneo; Roberto Natella; Roberto Pietrantuono; Stefano Russo",
    "corresponding_authors": "",
    "abstract": "Software aging is a phenomenon plaguing many long-running complex software systems, which exhibit performance degradation or an increasing failure rate. Several strategies based on the proactive rejuvenation of the software state have been proposed to counteract software aging and prevent failures. This survey article provides an overview of studies on Software Aging and Rejuvenation (SAR) that have appeared in major journals and conference proceedings, with respect to the statistical approaches that have been used to forecast software aging phenomena and to plan rejuvenation, the kind of systems and aging effects that have been studied, and the techniques that have been proposed to rejuvenate complex software systems. The analysis is useful to identify key results from SAR research, and it is leveraged in this article to highlight trends and open issues.",
    "cited_by_count": 177,
    "openalex_id": "https://openalex.org/W2065325623",
    "type": "article"
  },
  {
    "title": "Nanoscale electronic synapses using phase change devices",
    "doi": "https://doi.org/10.1145/2463585.2463588",
    "publication_date": "2013-05-01",
    "publication_year": 2013,
    "authors": "Bryan L. Jackson; Bipin Rajendran; Gregory S. Corrado; M. Breitwisch; Geoffrey W. Burr; R. Cheek; Kailash Gopalakrishnan; Simone Raoux; Charles Rettner; Alvaro Padilla; Alex G. Schrott; Rohit S. Shenoy; B. N. Kurdi; Chung Lam; Dharmendra S. Modha",
    "corresponding_authors": "",
    "abstract": "The memory capacity, computational power, communication bandwidth, energy consumption, and physical size of the brain all tend to scale with the number of synapses, which outnumber neurons by a factor of 10,000. Although progress in cortical simulations using modern digital computers has been rapid, the essential disparity between the classical von Neumann computer architecture and the computational fabric of the nervous system makes large-scale simulations expensive, power hungry, and time consuming. Over the last three decades, CMOS-based neuromorphic implementations of “electronic cortex” have emerged as an energy efficient alternative for modeling neuronal behavior. However, the key ingredient for electronic implementation of any self-learning system—programmable, plastic Hebbian synapses scalable to biological densities—has remained elusive. We demonstrate the viability of implementing such electronic synapses using nanoscale phase change devices. We introduce novel programming schemes for modulation of device conductance to closely mimic the phenomenon of Spike Timing Dependent Plasticity (STDP) observed biologically, and verify through simulations that such plastic phase change devices should support simple correlative learning in networks of spiking neurons. Our devices, when arranged in a crossbar array architecture, could enable the development of synaptronic systems that approach the density (∼10 11 synapses per sq cm) and energy efficiency (consuming ∼1pJ per synaptic programming event) of the human brain.",
    "cited_by_count": 165,
    "openalex_id": "https://openalex.org/W2077586448",
    "type": "article"
  },
  {
    "title": "Performance evaluation and design trade-offs for wireless network-on-chip architectures",
    "doi": "https://doi.org/10.1145/2287696.2287706",
    "publication_date": "2012-08-01",
    "publication_year": 2012,
    "authors": "Kevin K. Chang; Sujay Deb; Amlan Ganguly; Xinmin Yu; Suman P. Sah; Partha Pratim Pande; Benjamin J. Belzer; Deukhyoun Heo",
    "corresponding_authors": "",
    "abstract": "Massive levels of integration are making modern multicore chips all pervasive in several domains. High performance, robustness, and energy-efficiency are crucial for the widespread adoption of such platforms. Networks-on-Chip (NoCs) have emerged as communication backbones to enable a high degree of integration in multicore Systems-on-Chip (SoCs). Despite their advantages, an important performance limitation in traditional NoCs arises from planar metal interconnect-based multihop links with high latency and power consumption. This limitation can be addressed by drawing inspiration from the evolution of natural complex networks, which offer great performance-cost trade-offs. Analogous with many natural complex systems, future multicore chips are expected to be hierarchical and heterogeneous in nature as well. In this article we undertake a detailed performance evaluation for hierarchical small-world NoC architectures where the long-range communications links are established through the millimeter-wave wireless communication channels. Through architecture-space exploration in conjunction with novel power-efficient on-chip wireless link design, we demonstrate that it is possible to improve performance of conventional NoC architectures significantly without incurring high area overhead.",
    "cited_by_count": 119,
    "openalex_id": "https://openalex.org/W2097250113",
    "type": "article"
  },
  {
    "title": "Photonic network-on-chip architectures using multilayer deposited silicon materials for high-performance chip multiprocessors",
    "doi": "https://doi.org/10.1145/1970406.1970409",
    "publication_date": "2011-06-01",
    "publication_year": 2011,
    "authors": "Aleksandr Biberman; Kyle Preston; Gilbert Hendry; Nicolás Sherwood-Droz; Johnnie Chan; Jacob S. Levy; Michal Lipson; Keren Bergman",
    "corresponding_authors": "",
    "abstract": "Integrated photonics has been slated as a revolutionary technology with the potential to mitigate the many challenges associated with on- and off-chip electrical interconnection networks. To date, all proposed chip-scale photonic interconnects have been based on the crystalline silicon platform for CMOS-compatible fabrication. However, maintaining CMOS compatibility does not preclude the use of other CMOS-compatible silicon materials such as silicon nitride and polycrystalline silicon. In this work, we investigate utilizing devices based on these deposited materials to design photonic networks with multiple layers of photonic devices. We apply rigorous device optimization and insertion loss analysis on various network architectures, demonstrating that multilayer photonic networks can exhibit dramatically lower total insertion loss, enabling unprecedented bandwidth scalability. We show that significant improvements in waveguide propagation and waveguide crossing insertion losses resulting from using these materials enables the realization of topologies that were previously not feasible using only the single-layer crystalline silicon approaches.",
    "cited_by_count": 118,
    "openalex_id": "https://openalex.org/W2056545160",
    "type": "article"
  },
  {
    "title": "Extracting Success from IBM’s 20-Qubit Machines Using Error-Aware Compilation",
    "doi": "https://doi.org/10.1145/3386162",
    "publication_date": "2020-05-28",
    "publication_year": 2020,
    "authors": "S. Nishio; Yulu Pan; Takahiko Satoh; Hideharu Amano; Rodney Van Meter",
    "corresponding_authors": "",
    "abstract": "NISQ (Noisy, Intermediate-Scale Quantum) computing requires error mitigation to achieve meaningful computation. Our compilation tool development focuses on the fact that the error rates of individual qubits are not equal, with a goal of maximizing the success probability of real-world subroutines such as an adder circuit. We begin by establishing a metric for choosing among possible paths and circuit alternatives for executing gates between variables placed far apart within the processor, and test our approach on two IBM 20-qubit systems named Tokyo and Poughkeepsie. We find that a single-number metric describing the fidelity of individual gates is a useful but imperfect guide. Our compiler uses this subsystem and maps complete circuits onto the machine using a beam search-based heuristic that will scale as processor and program sizes grow. To evaluate the whole compilation process, we compiled and executed adder circuits, then calculated the KL-divergence (a measure of the distance between two probability distributions). For a circuit within the capabilities of the hardware, our compilation increases estimated success probability and reduces KL-divergence relative to an error-oblivious placement.",
    "cited_by_count": 108,
    "openalex_id": "https://openalex.org/W3098780233",
    "type": "article"
  },
  {
    "title": "Spintronics",
    "doi": "https://doi.org/10.1145/2663351",
    "publication_date": "2015-09-02",
    "publication_year": 2015,
    "authors": "Wang Kang; Yue Zhang; Zhaohao Wang; Jacques‐Olivier Klein; Claude Chappert; D. Ravelosona; Gefei Wang; Youguang Zhang; Weisheng Zhao",
    "corresponding_authors": "",
    "abstract": "Conventional MOS integrated circuits and systems suffer serve power and scalability challenges as technology nodes scale into ultra-deep-micron technology nodes (e.g., below 40nm). Both static and dynamic power dissipations are increasing, caused mainly by the intrinsic leakage currents and large data traffic. Alternative approaches beyond charge-only-based electronics, and in particular, spin-based devices, show promising potential to overcome these issues by adding the spin freedom of electrons to electronic circuits. Spintronics provides data non-volatility, fast data access, and low-power operation, and has now become a hot topic in both academia and industry for achieving ultra-low-power circuits and systems. The ITRS report on emerging research devices identified the magnetic tunnel junction (MTJ) nanopillar (one of the Spintronics nanodevices) as one of the most promising technologies to be part of future micro-electronic circuits. In this review we will give an overview of the status and prospects of spin-based devices and circuits that are currently under intense investigation and development across the world, and address particularly their merits and challenges for practical applications. We will also show that, with a rapid development of Spintronics, some novel computing architectures and paradigms beyond classic Von-Neumann architecture have recently been emerging for next-generation ultra-low-power circuits and systems.",
    "cited_by_count": 100,
    "openalex_id": "https://openalex.org/W2219963777",
    "type": "article"
  },
  {
    "title": "A Survey on Silicon Photonics for Deep Learning",
    "doi": "https://doi.org/10.1145/3459009",
    "publication_date": "2021-06-30",
    "publication_year": 2021,
    "authors": "Febin Sunny; Ebadollah Taheri; Mahdi Nikdast; Sudeep Pasricha",
    "corresponding_authors": "",
    "abstract": "Deep learning has led to unprecedented successes in solving some very difficult problems in domains such as computer vision, natural language processing, and general pattern recognition. These achievements are the culmination of decades-long research into better training techniques and deeper neural network models, as well as improvements in hardware platforms that are used to train and execute the deep neural network models. Many application-specific integrated circuit (ASIC) hardware accelerators for deep learning have garnered interest in recent years due to their improved performance and energy-efficiency over conventional CPU and GPU architectures. However, these accelerators are constrained by fundamental bottlenecks due to (1) the slowdown in CMOS scaling, which has limited computational and performance-per-watt capabilities of emerging electronic processors; and (2) the use of metallic interconnects for data movement, which do not scale well and are a major cause of bandwidth, latency, and energy inefficiencies in almost every contemporary processor. Silicon photonics has emerged as a promising CMOS-compatible alternative to realize a new generation of deep learning accelerators that can use light for both communication and computation. This article surveys the landscape of silicon photonics to accelerate deep learning, with a coverage of developments across design abstractions in a bottom-up manner, to convey both the capabilities and limitations of the silicon photonics paradigm in the context of deep learning acceleration.",
    "cited_by_count": 69,
    "openalex_id": "https://openalex.org/W3174630792",
    "type": "article"
  },
  {
    "title": "A Side-Channel-Resistant Implementation of SABER",
    "doi": "https://doi.org/10.1145/3429983",
    "publication_date": "2021-04-23",
    "publication_year": 2021,
    "authors": "Michiel Van Beirendonck; Jan-Pieter D’Anvers; Angshuman Karmakar; Josep Balasch; Ingrid Verbauwhede",
    "corresponding_authors": "",
    "abstract": "The candidates for the NIST Post-Quantum Cryptography standardization have undergone extensive studies on efficiency and theoretical security, but research on their side-channel security is largely lacking. This remains a considerable obstacle for their real-world deployment, where side-channel security can be a critical requirement. This work describes a side-channel-resistant instance of Saber, one of the lattice-based candidates, using masking as a countermeasure. Saber proves to be very efficient to masking due to two specific design choices: power-of-two moduli and limited noise sampling of learning with rounding. A major challenge in masking lattice-based cryptosystems is the integration of bit-wise operations with arithmetic masking, requiring algorithms to securely convert between masked representations. The described design includes a novel primitive for masked logical shifting on arithmetic shares and adapts an existing masked binomial sampler for Saber. An implementation is provided for an ARM Cortex-M4 microcontroller, and its side-channel resistance is experimentally demonstrated. The masked implementation features a 2.5x overhead factor, significantly lower than the 5.7x previously reported for a masked variant of NewHope. Masked key decapsulation requires less than 3,000,000 cycles on the Cortex-M4 and consumes less than 12kB of dynamic memory, making it suitable for deployment in embedded platforms.",
    "cited_by_count": 68,
    "openalex_id": "https://openalex.org/W3159559383",
    "type": "article"
  },
  {
    "title": "Hardware Trust and Assurance through Reverse Engineering: A Tutorial and Outlook from Image Analysis and Machine Learning Perspectives",
    "doi": "https://doi.org/10.1145/3464959",
    "publication_date": "2021-06-30",
    "publication_year": 2021,
    "authors": "Ulbert J. Botero; Ronald S. Wilson; Hangwei Lu; Mir Tanjidur Rahman; Mukhil A. Mallaiyan; Fatemeh Ganji; Navid Asadizanjani; Mark Tehranipoor; Damon L. Woodard; Domenic Forte",
    "corresponding_authors": "",
    "abstract": "In the context of hardware trust and assurance, reverse engineering has been often considered as an illegal action. Generally speaking, reverse engineering aims to retrieve information from a product, i.e., integrated circuits (ICs) and printed circuit boards (PCBs) in hardware security-related scenarios, in the hope of understanding the functionality of the device and determining its constituent components. Hence, it can raise serious issues concerning Intellectual Property (IP) infringement, the (in)effectiveness of security-related measures, and even new opportunities for injecting hardware Trojans. Ironically, reverse engineering can enable IP owners to verify and validate the design. Nevertheless, this cannot be achieved without overcoming numerous obstacles that limit successful outcomes of the reverse engineering process. This article surveys these challenges from two complementary perspectives: image processing and machine learning. These two fields of study form a firm basis for the enhancement of efficiency and accuracy of reverse engineering processes for both PCBs and ICs. In summary, therefore, this article presents a roadmap indicating clearly the actions to be taken to fulfill hardware trust and assurance objectives.",
    "cited_by_count": 68,
    "openalex_id": "https://openalex.org/W3176686472",
    "type": "article"
  },
  {
    "title": "NxTF: An API and Compiler for Deep Spiking Neural Networks on Intel Loihi",
    "doi": "https://doi.org/10.1145/3501770",
    "publication_date": "2022-01-29",
    "publication_year": 2022,
    "authors": "Bodo Rueckauer; Connor Bybee; Ralf Goettsche; Yashwardhan Singh; Joyesh Mishra; Andreas Wild",
    "corresponding_authors": "",
    "abstract": "Spiking Neural Networks (SNNs) is a promising paradigm for efficient event-driven processing of spatio-temporally sparse data streams. Spiking Neural Networks (SNNs) have inspired the design of and can take advantage of the emerging class of neuromorphic processors like Intel Loihi. These novel hardware architectures expose a variety of constraints that affect firmware, compiler, and algorithm development alike. To enable rapid and flexible development of SNN algorithms on Loihi, we developed NxTF: a programming interface derived from Keras and compiler optimized for mapping deep convolutional SNNs to the multi-core Intel Loihi architecture. We evaluate NxTF on Deep Neural Networks (DNNs) trained directly on spikes as well as models converted from traditional DNNs, processing both sparse event-based and dense frame-based datasets. Further, we assess the effectiveness of the compiler to distribute models across a large number of cores and to compress models by exploiting Loihi’s weight-sharing features. Finally, we evaluate model accuracy, energy, and time-to-solution compared to other architectures. The compiler achieves near-optimal resource utilization of 80% across 16 Loihi chips for a 28-layer, 4M parameter MobileNet model with input size 128×128. In addition, we report the lowest error rate of 8.52% for the CIFAR-10 dataset on neuromorphic hardware, using an off-the-shelf MobileNet.",
    "cited_by_count": 50,
    "openalex_id": "https://openalex.org/W4225708293",
    "type": "article"
  },
  {
    "title": "An Electro-Photonic System for Accelerating Deep Neural Networks",
    "doi": "https://doi.org/10.1145/3606949",
    "publication_date": "2023-07-12",
    "publication_year": 2023,
    "authors": "Cansu Demirkiran; Furkan Eris; Gongyu Wang; Jonathan Elmhurst; Nick Moore; Nicholas C. Harris; Ayon Basumallik; Vijay Janapa Reddi; Ajay Joshi; Darius Bunandar",
    "corresponding_authors": "",
    "abstract": "The number of parameters in deep neural networks (DNNs) is scaling at about 5× the rate of Moore’s Law. To sustain this growth, photonic computing is a promising avenue, as it enables higher throughput in dominant general matrix-matrix multiplication (GEMM) operations in DNNs than their electrical counterpart. However, purely photonic systems face several challenges including lack of photonic memory and accumulation of noise. In this article, we present an electro-photonic accelerator, ADEPT, which leverages a photonic computing unit for performing GEMM operations, a vectorized digital electronic application-specific integrated circuits for performing non-GEMM operations, and SRAM arrays for storing DNN parameters and activations. In contrast to prior works in photonic DNN accelerators, we adopt a system-level perspective and show that the gains while large are tempered relative to prior expectations. Our goal is to encourage architects to explore photonic technology in a more pragmatic way considering the system as a whole to understand its general applicability in accelerating today’s DNNs. Our evaluation shows that ADEPT can provide, on average, 5.73× higher throughput per watt compared to the traditional systolic arrays in a full-system, and at least 6.8× and 2.5× better throughput per watt, compared to state-of-the-art electronic and photonic accelerators, respectively.",
    "cited_by_count": 39,
    "openalex_id": "https://openalex.org/W3196795730",
    "type": "article"
  },
  {
    "title": "Reversible circuit synthesis using a cycle-based approach",
    "doi": "https://doi.org/10.1145/1877745.1877747",
    "publication_date": "2010-12-01",
    "publication_year": 2010,
    "authors": "Mehdi Saeedi; Morteza Saheb Zamani; Mehdi Sedighi; Zahra Sasanian",
    "corresponding_authors": "",
    "abstract": "Reversible logic has applications in various research areas, including signal processing, cryptography and quantum computation. In this article, direct NCT-based synthesis of a given k -cycle in a cycle-based synthesis scenario is examined. To this end, a set of seven building blocks is proposed that reveals the potential of direct synthesis of a given permutation to reduce both quantum cost and average runtime. To synthesize a given large cycle, we propose a decomposition algorithm to extract the suggested building blocks from the input specification. Then, a synthesis method is introduced that uses the building blocks and the decomposition algorithm. Finally, a hybrid synthesis framework is suggested that uses the proposed cycle-based synthesis method in conjunction with one of the recent NCT-based synthesis approaches which is based on Reed-Muller (RM) spectra. The time complexity and the effectiveness of the proposed synthesis approach are analyzed in detail. Our analyses show that the proposed hybrid framework leads to a better quantum cost in the worst-case scenario compared to the previously presented methods. The proposed framework always converges and typically synthesizes a given specification very fast compared to the available synthesis algorithms. Besides, the quantum costs of benchmark functions are improved about 20% on average (55% in the best case).",
    "cited_by_count": 126,
    "openalex_id": "https://openalex.org/W1976996072",
    "type": "article"
  },
  {
    "title": "Modeling and design challenges and solutions for carbon nanotube-based interconnect in future high performance integrated circuits",
    "doi": "https://doi.org/10.1145/1167943.1167944",
    "publication_date": "2006-07-01",
    "publication_year": 2006,
    "authors": "Yehia Massoud; Arthur Nieuwoudt",
    "corresponding_authors": "",
    "abstract": "Single-walled carbon nanotube (SWCNT) bundles have the potential to provide an attractive solution for the resistivity and electromigration problems faced by traditional copper interconnect as technology scales into the nanoscale regime. In this article, we evaluate the performance and reliability of nanotube bundles for both local and global interconnect in future VLSI applications. To provide a holistic evaluation of SWCNT bundles for on-chip interconnect, we have developed an efficient equivalent circuit model that captures the statistical distribution of individual metallic and semiconducting nanotubes while accurately incorporating recent experimental and theoretical results on inductance, contact resistance, and ohmic resistance. Leveraging the circuit model, we examine the performance and reliability of nanotube bundles for both individual signal lines and system-level designs. SWCNT interconnect bundles can provide significant improvement in delay and maximum current density over traditional copper interconnect, depending on bundle geometry and process technology. However, for system-level designs, the statistical variation in the delay of SWCNT bundles may lead to reliability issues in future process technology. Consequently, if the SWCNT chirality can be effectively controlled and other manufacturing challenges are met, SWCNT bundles potentially are a viable alternative to standard copper interconnect as process technology scales.",
    "cited_by_count": 122,
    "openalex_id": "https://openalex.org/W2002085065",
    "type": "article"
  },
  {
    "title": "Placement of defect-tolerant digital microfluidic biochips using the T-tree formulation",
    "doi": "https://doi.org/10.1145/1295231.1295234",
    "publication_date": "2007-11-01",
    "publication_year": 2007,
    "authors": "Ping-Hung Yuh; Chia-Lin Yang; Yao‐Wen Chang",
    "corresponding_authors": "",
    "abstract": "Droplet-based microfluidic biochips have recently gained much attention and are expected to revolutionize the biological laboratory procedures. As biochips are adopted for the complex procedures in molecular biology, its complexity is expected to increase due to the need of multiple and concurrent assays on a chip. In this article, we formulate the placement problem of digital microfluidic biochips with a tree-based topological representation, called T-tree . To the best knowledge of the authors, this is the first work that adopts a topological representation to solve the placement problem of digital microfluidic biochips. We also consider the defect tolerant issue to avoid to use defective cells due to fabrication. Experimental results demonstrate that our approach is more efficient and effective than the previous unified synthesis and placement framework.",
    "cited_by_count": 107,
    "openalex_id": "https://openalex.org/W2013470780",
    "type": "article"
  },
  {
    "title": "Large-scale integrated photonics for high-performance interconnects",
    "doi": "https://doi.org/10.1145/1970406.1970408",
    "publication_date": "2011-06-01",
    "publication_year": 2011,
    "authors": "Raymond G. Beausoleil",
    "corresponding_authors": "Raymond G. Beausoleil",
    "abstract": "Moore's Law has set great expectations that the performance of information technology will improve exponentially until at least the end of this decade. Although the physics of silicon transistors alone might allow these expectations to be met, the physics of the long metal wires that cross and connect packages almost certainly will not. Global-level interconnects incorporating large-scale integrated photonics fabricated on the same platform as silicon microelectronics hold the promise of revolutionizing computing by enabling parallel many-core and network switch architectures that combine unprecedented performance and ease of use with affordable power consumption. Over the last decade, remarkable progress has been made in research on low-power silicon photonic devices for interconnect applications, and CMOS-compatible fabrication technologies promise a “Moore's Law for photonics” that could completely change the economics of integrated optics. In this survey, photonic technologies amenable to large-scale CMOS integration are reviewed from the perspective of high-performance interconnects operating over distance scales of 1mm to 100m. An overview of the requirements placed on integrated optical devices by a variety of modern computer applications leads to discussions of active and passive photonic components designed to generate, guide, filter, modulate, and detect light in the telecommunication bands. Critical challenges and prospects for large-scale integration are evaluated with an emphasis on silicon-on-insulator as a platform for photonics.",
    "cited_by_count": 90,
    "openalex_id": "https://openalex.org/W2087015358",
    "type": "article"
  },
  {
    "title": "Emerging Technology-Based Design of Primitives for Hardware Security",
    "doi": "https://doi.org/10.1145/2816818",
    "publication_date": "2016-04-13",
    "publication_year": 2016,
    "authors": "Yu Bi; Kaveh Shamsi; J.S. Yuan; Pierre‐Emmanuel Gaillardon; Giovanni De Micheli; Xunzhao Yin; Xiaobo Sharon Hu; Michael Niemier; Yier Jin",
    "corresponding_authors": "",
    "abstract": "Hardware security concerns such as intellectual property (IP) piracy and hardware Trojans have triggered research into circuit protection and malicious logic detection from various design perspectives. In this article, emerging technologies are investigated by leveraging their unique properties for applications in the hardware security domain. Security, for the first time, will be treated as one design metric for emerging nano-architecture. Five example circuit structures including camouflaging gates, polymorphic gates, current/voltage-based circuit protectors, and current-based XOR logic are designed to show the high efficiency of silicon nanowire FETs and graphene SymFET in applications such as circuit protection and IP piracy prevention. Simulation results indicate that highly efficient and secure circuit structures can be achieved via the use of non-CMOS devices.",
    "cited_by_count": 85,
    "openalex_id": "https://openalex.org/W1692694227",
    "type": "article"
  },
  {
    "title": "High-Performance Computing with Quantum Processing Units",
    "doi": "https://doi.org/10.1145/3007651",
    "publication_date": "2017-03-17",
    "publication_year": 2017,
    "authors": "Keith A. Britt; Travis S. Humble",
    "corresponding_authors": "",
    "abstract": "The prospects of quantum computing have driven efforts to realize fully functional quantum processing units (QPUs). Recent success in developing proof-of-principle QPUs has prompted the question of how to integrate these emerging processors into modern high-performance computing (HPC) systems. We examine how QPUs can be integrated into current and future HPC system architectures by accounting for functional and physical design requirements. We identify two integration pathways that are differentiated by infrastructure constraints on the QPU and the use cases expected for the HPC system. This includes a tight integration that assumes infrastructure bottlenecks can be overcome as well as a loose integration that assumes they cannot. We find that the performance of both approaches is likely to depend on the quantum interconnect that serves to entangle multiple QPUs. We also identify several challenges in assessing QPU performance for HPC, and we consider new metrics that capture the interplay between system architecture and the quantum parallelism underlying computational performance.",
    "cited_by_count": 80,
    "openalex_id": "https://openalex.org/W2963083109",
    "type": "article"
  },
  {
    "title": "Hardware Optimizations of Dense Binary Hyperdimensional Computing: Rematerialization of Hypervectors, Binarized Bundling, and Combinational Associative Memory",
    "doi": "https://doi.org/10.1145/3314326",
    "publication_date": "2019-10-10",
    "publication_year": 2019,
    "authors": "Manuel Schmuck; Luca Benini; Abbas Rahimi",
    "corresponding_authors": "",
    "abstract": "Brain-inspired hyperdimensional (HD) computing models neural activity patterns of the very size of the brain’s circuits with points of a hyperdimensional space, that is, with hypervectors . Hypervectors are D -dimensional (pseudo)random vectors with independent and identically distributed (i.i.d.) components constituting ultra-wide holographic words: D =10,000 bits, for instance. At its very core, HD computing manipulates a set of seed hypervectors to build composite hypervectors representing objects of interest. It demands memory optimizations with simple operations for an efficient hardware realization. In this article, we propose hardware techniques for optimizations of HD computing, in a synthesizable open-source VHDL library, to enable co-located implementation of both learning and classification tasks on only a small portion of Xilinx UltraScale FPGAs: (1) We propose simple logical operations to rematerialize the hypervectors on the fly rather than loading them from memory. These operations massively reduce the memory footprint by directly computing the composite hypervectors whose individual seed hypervectors do not need to be stored in memory. (2) Bundling a series of hypervectors over time requires a multibit counter per every hypervector component. We instead propose a binarized back-to-back bundling without requiring any counters. This truly enables on-chip learning with minimal resources as every hypervector component remains binary over the course of training to avoid otherwise multibit components. (3) For every classification event, an associative memory is in charge of finding the closest match between a set of learned hypervectors and a query hypervector by using a distance metric. This operator is proportional to hypervector dimension ( D ), and hence may take O( D ) cycles per classification event. Accordingly, we significantly improve the throughput of classification by proposing associative memories that steadily reduce the latency of classification to the extreme of a single cycle. (4) We perform a design space exploration incorporating the proposed techniques on FPGAs for a wearable biosignal processing application as a case study. Our techniques achieve up to 2.39× area saving, or 2,337× throughput improvement. The Pareto optimal HD architecture is mapped on only 18,340 configurable logic blocks (CLBs) to learn and classify five hand gestures using four electromyography sensors.",
    "cited_by_count": 80,
    "openalex_id": "https://openalex.org/W2963492949",
    "type": "article"
  },
  {
    "title": "Energy- and performance-aware scheduling of tasks on parallel and distributed systems",
    "doi": "https://doi.org/10.1145/2367736.2367743",
    "publication_date": "2012-10-01",
    "publication_year": 2012,
    "authors": "Hafiz Fahad Sheikh; Hengxing Tan; Ishfaq Ahmad; Sanjay Ranka; Phanisekhar Bv",
    "corresponding_authors": "",
    "abstract": "Enabled by high-speed networking in commercial, scientific, and government settings, the realm of high performance is burgeoning with greater amounts of computational and storage resources. Large-scale systems such as computational grids consume a significant amount of energy due to their massive sizes. The energy and cooling costs of such systems are often comparable to the procurement costs over a year period. In this survey, we will discuss allocation and scheduling algorithms, systems, and software for reducing power and energy dissipation of workflows on the target platforms of single processors, multicore processors, and distributed systems. Furthermore, recent research achievements will be investigated that deal with power and energy efficiency via different power management techniques and application scheduling algorithms. The article provides a comprehensive presentation of the architectural, software, and algorithmic issues for energy-aware scheduling of workflows on single, multicore, and parallel architectures. It also includes a systematic taxonomy of the algorithms developed in the literature based on the overall optimization goals and characteristics of applications.",
    "cited_by_count": 77,
    "openalex_id": "https://openalex.org/W2013103723",
    "type": "article"
  },
  {
    "title": "A Reconfigurable Digital Neuromorphic Processor with Memristive Synaptic Crossbar for Cognitive Computing",
    "doi": "https://doi.org/10.1145/2700234",
    "publication_date": "2015-04-27",
    "publication_year": 2015,
    "authors": "Yongtae Kim; Yong Zhang; Peng Li",
    "corresponding_authors": "",
    "abstract": "This article presents a brain-inspired reconfigurable digital neuromorphic processor (DNP) architecture for large-scale spiking neural networks. The proposed architecture integrates an arbitrary number of N digital leaky integrate-and-fire (LIF) silicon neurons to mimic their biological counterparts and on-chip learning circuits to realize spike-timing-dependent plasticity (STDP) learning rules. We leverage memristor nanodevices to build an N × N crossbar array to store not only multibit synaptic weight values but also network configuration data with significantly reduced area overhead. Additionally, the crossbar array is designed to be accessible both column- and row-wise to expedite the synaptic weight update process for learning. The proposed digital pulse width modulator (PWM) produces binary pulses with various durations for reading and writing the multilevel memristive crossbar. The proposed column based analog-to-digital conversion (ADC) scheme efficiently accumulates the presynaptic weights of each neuron and reduces silicon area overhead by using a shared arithmetic unit to process the LIF operations of all N neurons. With 256 silicon neurons, learning circuits and 64K synapses, the power dissipation and area of our DNP are 6.45 mW and 1.86 mm 2 , respectively, when implemented in a 90-nm CMOS technology. The functionality of the proposed DNP architecture is demonstrated by realizing an unsupervised-learning based character recognition system.",
    "cited_by_count": 70,
    "openalex_id": "https://openalex.org/W2062258233",
    "type": "article"
  },
  {
    "title": "A Study of Complex Deep Learning Networks on High-Performance, Neuromorphic, and Quantum Computers",
    "doi": "https://doi.org/10.1145/3178454",
    "publication_date": "2018-04-30",
    "publication_year": 2018,
    "authors": "Thomas E. Potok; Catherine D. Schuman; Steven R. Young; Robert M. Patton; Federico M. Spedalieri; Jeremy Liu; Ke-Thia Yao; Garrett S. Rose; Gangotree Chakma",
    "corresponding_authors": "",
    "abstract": "Current deep learning approaches have been very successful using convolutional neural networks trained on large graphical-processing-unit-based computers. Three limitations of this approach are that (1) they are based on a simple layered network topology, i.e., highly connected layers, without intra-layer connections; (2) the networks are manually configured to achieve optimal results, and (3) the implementation of the network model is expensive in both cost and power. In this article, we evaluate deep learning models using three different computing architectures to address these problems: quantum computing to train complex topologies, high performance computing to automatically determine network topology, and neuromorphic computing for a low-power hardware implementation. We use the MNIST dataset for our experiment, due to input size limitations of current quantum computers. Our results show the feasibility of using the three architectures in tandem to address the above deep learning limitations. We show that a quantum computer can find high quality values of intra-layer connection weights in a tractable time as the complexity of the network increases, a high performance computer can find optimal layer-based topologies, and a neuromorphic computer can represent the complex topology and weights derived from the other architectures in low power memristive hardware.",
    "cited_by_count": 69,
    "openalex_id": "https://openalex.org/W2821976686",
    "type": "article"
  },
  {
    "title": "Energy-Efficient Neural Computing with Approximate Multipliers",
    "doi": "https://doi.org/10.1145/3097264",
    "publication_date": "2018-04-30",
    "publication_year": 2018,
    "authors": "Syed Shakib Sarwar; Swagath Venkataramani; Aayush Ankit; Anand Raghunathan; Kaushik Roy",
    "corresponding_authors": "",
    "abstract": "Neural networks, with their remarkable ability to derive meaning from a large volume of complicated or imprecise data, can be used to extract patterns and detect trends that are too complex for the von Neumann computing paradigm. Their considerable computational requirements stretch the capabilities of even modern computing platforms. We propose an approximate multiplier that exploits the inherent application resilience to error and utilizes the notion of computation sharing to achieve improved energy consumption for neural networks. We also propose a Multiplier-less Artificial Neuron (MAN), which is even more compact and energy efficient. We also propose a network retraining methodology to recover some of the accuracy loss due to the use of these approximate multipliers. We evaluated the proposed algorithm/design on several recognition applications. The results show that we achieve ∼33%, ∼32%, and ∼25% reduction in power consumption and ∼33%, ∼34%, and ∼27% reduction in area, respectively, for 12-, 8-, and 4-bit MAN, with a maximum ∼2.4% loss in accuracy compared to a conventional neuron implementation of equivalent bit precision. These comparisons were performed under iso-speed conditions.",
    "cited_by_count": 67,
    "openalex_id": "https://openalex.org/W2871705258",
    "type": "article"
  },
  {
    "title": "A GPU-Outperforming FPGA Accelerator Architecture for Binary Convolutional Neural Networks",
    "doi": "https://doi.org/10.1145/3154839",
    "publication_date": "2018-04-30",
    "publication_year": 2018,
    "authors": "Yixing Li; Zichuan Liu; Kai Xu; Hao Yu; Fengbo Ren",
    "corresponding_authors": "",
    "abstract": "FPGA-based hardware accelerators for convolutional neural networks (CNNs) have received attention due to their higher energy efficiency than GPUs. However, it is challenging for FPGA-based solutions to achieve a higher throughput than GPU counterparts. In this article, we demonstrate that FPGA acceleration can be a superior solution in terms of both throughput and energy efficiency when a CNN is trained with binary constraints on weights and activations. Specifically, we propose an optimized fully mapped FPGA accelerator architecture tailored for bitwise convolution and normalization that features massive spatial parallelism with deep pipelines stages. A key advantage of the FPGA accelerator is that its performance is insensitive to data batch size, while the performance of GPU acceleration varies largely depending on the batch size of the data. Experiment results show that the proposed accelerator architecture for binary CNNs running on a Virtex-7 FPGA is 8.3× faster and 75× more energy-efficient than a Titan X GPU for processing online individual requests in small batch sizes. For processing static data in large batch sizes, the proposed solution is on a par with a Titan X GPU in terms of throughput while delivering 9.5× higher energy efficiency.",
    "cited_by_count": 65,
    "openalex_id": "https://openalex.org/W2699539367",
    "type": "article"
  },
  {
    "title": "The Big Hack Explained",
    "doi": "https://doi.org/10.1145/3401980",
    "publication_date": "2020-08-26",
    "publication_year": 2020,
    "authors": "Dhwani Mehta; Hangwei Lu; Olivia P. Paradis; Mukhil Azhagan M. S.; Mir Tanjidur Rahman; Yousef Iskander; P. Chawla; Damon L. Woodard; Mark Tehranipoor; Navid Asadizanjani",
    "corresponding_authors": "",
    "abstract": "Over the past two decades, globalized outsourcing in the semiconductor supply chain has lowered manufacturing costs and shortened the time-to-market for original equipment manufacturers (OEMs). However, such outsourcing has rendered the printed circuit boards (PCBs) vulnerable to malicious activities and alterations on a global scale. In this article, we take an in-depth look into one such attack, called the “Big Hack,” that was recently reported by Bloomberg Buisnessweek. The article provides background on the Big Hack from three perspectives: an attacker, a security investigator, and the societal impacts. This study provides details on vulnerabilities in the modern PCB supply chain, the possible attacks, and the existing and emerging countermeasures. The necessity for novel visual inspection techniques for PCB assurance is emphasized throughout the article. Further, a review of various imaging modalities, image analysis algorithms, and open research challenges are provided for automated visual inspection.",
    "cited_by_count": 63,
    "openalex_id": "https://openalex.org/W3081524416",
    "type": "article"
  },
  {
    "title": "A Classification of Memory-Centric Computing",
    "doi": "https://doi.org/10.1145/3365837",
    "publication_date": "2020-01-30",
    "publication_year": 2020,
    "authors": "Hoang Anh Du Nguyen; Jintao Yu; Muath Abu Lebdeh; Mottaqiallah Taouil; Said Hamdioui; Francky Catthoor",
    "corresponding_authors": "",
    "abstract": "Technological and architectural improvements have been constantly required to sustain the demand of faster and cheaper computers. However, CMOS down-scaling is suffering from three technology walls: leakage wall, reliability wall, and cost wall. On top of that, a performance increase due to architectural improvements is also gradually saturating due to three well-known architecture walls: memory wall, power wall, and instruction-level parallelism (ILP) wall. Hence, a lot of research is focusing on proposing and developing new technologies and architectures. In this article, we present a comprehensive classification of memory-centric computing architectures; it is based on three metrics: computation location, level of parallelism, and used memory technology. The classification not only provides an overview of existing architectures with their pros and cons but also unifies the terminology that uniquely identifies these architectures and highlights the potential future architectures that can be further explored. Hence, it sets up a direction for future research in the field.",
    "cited_by_count": 55,
    "openalex_id": "https://openalex.org/W3009643182",
    "type": "article"
  },
  {
    "title": "Architectural implications of quantum computing technologies",
    "doi": "https://doi.org/10.1145/1126257.1126259",
    "publication_date": "2006-01-01",
    "publication_year": 2006,
    "authors": "Rodney Van Meter; Mark Oskin",
    "corresponding_authors": "",
    "abstract": "In this article we present a classification scheme for quantum computing technologies that is based on the characteristics most relevant to computer systems architecture. The engineering trade-offs of execution speed, decoherence of the quantum states, and size of systems are described. Concurrency, storage capacity, and interconnection network topology influence algorithmic efficiency, while quantum error correction and necessary quantum state measurement are the ultimate drivers of logical clock speed. We discuss several proposed technologies. Finally, we use our taxonomy to explore architectural implications for common arithmetic circuits, examine the implementation of quantum error correction, and discuss cluster-state quantum computation.",
    "cited_by_count": 96,
    "openalex_id": "https://openalex.org/W2136744126",
    "type": "article"
  },
  {
    "title": "Design considerations of sub-mW indoor light energy harvesting for wireless sensor systems",
    "doi": "https://doi.org/10.1145/1773814.1773817",
    "publication_date": "2008-06-18",
    "publication_year": 2008,
    "authors": "W. S. Wang; Terence O’Donnell; N. Wang; Mike Hayes; Brendan O’Flynn; Cian O’Mathúna",
    "corresponding_authors": "",
    "abstract": "For most wireless sensor networks, one common and major bottleneck is the limited battery lifetime. The frequent maintenance efforts associated with battery replacement significantly increase the system operational and logistics cost. Unnoticed power failures on nodes will degrade the system reliability and may lead to system failure. In building management applications, to solve this problem, small energy sources such as indoor light energy are promising to provide long-term power to these distributed wireless sensor nodes. This article provides comprehensive design considerations for an indoor light energy harvesting system for building management applications. Photovoltaic cells characteristics, energy storage units, power management circuit design, and power consumption pattern of the target mote are presented. Maximum power point tracking circuits are proposed which significantly increase the power obtained from the solar cells. The novel fast charge circuit reduces the charging time. A prototype was then successfully built and tested in various indoor light conditions to discover the practical issues of the design. The evaluation results show that the proposed prototype increases the power harvested from the PV cells by 30% and also accelerates the charging rate by 34% in a typical indoor lighting condition. By entirely eliminating the rechargeable battery as energy storage, the proposed system would expect an operational lifetime 10--20 years instead of the current less than 6 months battery lifetime.",
    "cited_by_count": 94,
    "openalex_id": "https://openalex.org/W2075865182",
    "type": "article"
  },
  {
    "title": "Data structures and algorithms for simplifying reversible circuits",
    "doi": "https://doi.org/10.1145/1216396.1216399",
    "publication_date": "2006-10-01",
    "publication_year": 2006,
    "authors": "Aditya K. Prasad; Vivek Shende; Igor L. Markov; John P. Hayes; Ketan N. Patel",
    "corresponding_authors": "",
    "abstract": "Reversible logic is motivated by low-power design, quantum circuits, and nanotechnology. We develop a compact representation of small reversible circuits to generate and store optimal circuits for all 40,320 three-input reversible functions, and millions of four-input circuits. This allows implementing a function optimally in constant time for use in the peephole optimization of larger circuits produced by existing techniques, and guarantees that every three-bit subcircuit is optimal. To generate subcircuits, we use a graph-based data structure and algorithms for circuit restructuring. Finally, we demonstrate a suboptimal circuit for which peephole optimization fails.",
    "cited_by_count": 92,
    "openalex_id": "https://openalex.org/W2063803513",
    "type": "article"
  },
  {
    "title": "Integrated control-path design and error recovery in the synthesis of digital microfluidic lab-on-chip",
    "doi": "https://doi.org/10.1145/1777401.1777404",
    "publication_date": "2010-08-01",
    "publication_year": 2010,
    "authors": "Yang Zhao; Tao Xu; Krishnendu Chakrabarty",
    "corresponding_authors": "",
    "abstract": "Recent advances in digital microfluidics have led to tremendous interest in miniaturized lab-on-chip devices for biochemical analysis. Synthesis tools have also emerged for the automated design of lab-on-chip from the specifications of laboratory protocols. However, none of these tools consider control flow or address the problem of recovering from fluidic errors that can occur during on-chip bioassay execution. We present a synthesis method that incorporates control paths and an error-recovery mechanism in the design of a digital microfluidic lab-on-chip. Based on error-propagation estimates, we determine the best locations for fluidic checkpoints during biochip synthesis. A microcontroller coordinates the implementation of the control-flow-based bioassay by intercepting the synthesis results that are mapped to the software programs. Real-life bioassay applications are used as case studies to evaluate the proposed design method. For a representative protein assay, compared to a baseline chip design, the biochip with a control path can reduce the completion time by 30% when errors occur during the implementation of the bioassay.",
    "cited_by_count": 87,
    "openalex_id": "https://openalex.org/W2018208873",
    "type": "article"
  },
  {
    "title": "Synthesis of reversible sequential elements",
    "doi": "https://doi.org/10.1145/1324177.1324181",
    "publication_date": "2008-01-01",
    "publication_year": 2008,
    "authors": "Min-Lun Chuang; Chun-Yao Wang",
    "corresponding_authors": "",
    "abstract": "To construct a reversible sequential circuit, reversible sequential elements are required. This work presents novel designs of reversible sequential elements such as the D latch, JK latch, and T latch. Based on these reversible latches, we construct the designs of the corresponding flip-flops. Then we further discuss the physical implementations of our designs based on electron waveguide Y-branch switch technology. Test costs, including test generation and test application, of reversible sequential circuits with these reversible flip-flops are also discussed. Compared with previous work, the implementation cost of our new designs, including the number of gates and the number of garbage outputs, is significantly reduced. The number of gates in our designs is 47.4% of the designs in previous work on average. The number of garbage outputs in our designs is 25% of the designs in previous work on average.",
    "cited_by_count": 82,
    "openalex_id": "https://openalex.org/W1982907376",
    "type": "article"
  },
  {
    "title": "Reversible logic synthesis with Fredkin and Peres gates",
    "doi": "https://doi.org/10.1145/1330521.1330523",
    "publication_date": "2008-03-01",
    "publication_year": 2008,
    "authors": "James Donald; Niraj K. Jha",
    "corresponding_authors": "",
    "abstract": "Reversible logic has applications in low-power computing and quantum computing. Most reversible logic synthesis methods are tied to particular gate types, and cannot synthesize large functions. This article extends RMRLS, a reversible logic synthesis tool, to include additional gate types. While classic RMRLS can synthesize functions using NOT, CNOT, and n -bit Toffoli gates, our work details the inclusion of n -bit Fredkin and Peres gates. We find that these additional gates reduce the average gate count for three-variable functions from 6.10 to 4.56, and improve the synthesis results of many larger functions, both in terms of gate count and quantum cost.",
    "cited_by_count": 81,
    "openalex_id": "https://openalex.org/W2010636784",
    "type": "article"
  },
  {
    "title": "Memristive devices in computing system",
    "doi": "https://doi.org/10.1145/2463585.2463587",
    "publication_date": "2013-05-01",
    "publication_year": 2013,
    "authors": "J. Joshua Yang; R. Stanley Williams",
    "corresponding_authors": "",
    "abstract": "Memristive devices with a simple structure are not only very small but also very versatile, which makes them an ideal candidate used for the next generation computing system in the post-Si era. The working mechanism of the devices and a family of nanodevices built based on this working mechanism are introduced first followed by some proposed applications of these novel devices. The promises and challenges of these devices are then discussed, together with the significant progresses made recently in dealing with these challenges.",
    "cited_by_count": 69,
    "openalex_id": "https://openalex.org/W2056475144",
    "type": "article"
  },
  {
    "title": "Effect of Wordline/Bitline Scaling on the Performance, Energy Consumption, and Reliability of Cross-Point Memory Array",
    "doi": "https://doi.org/10.1145/2422094.2422103",
    "publication_date": "2013-02-01",
    "publication_year": 2013,
    "authors": "Jiale Liang; Stanley Yeh; S.S. Wong; H.‐S. Philip Wong",
    "corresponding_authors": "",
    "abstract": "The impact of wordline/bitline metal wire scaling on the write/read performance, energy consumption, speed, and reliability of the cross-point memory array is quantitatively studied for technology nodes down to single-digit nm. The impending resistivity increase in the Cu wires is found to cause significant decrease of both write and read window margins at the regime when electron surface scattering and grain boundary scattering are substantial. At deeply-scaled device dimensions, the wire energy dissipation and wire latency become comparable to or even exceed the intrinsic values of memory cells. The large current density flowing through the wordlines/bitlines raises additional reliability concerns for the cross-point memory array. All these issues are exacerbated at smaller memory resistance values and larger memory array sizes. They thereby impose strict constraints on the memory device design and preclude the realization of large-scale cross-point memory array with minimum feature sizes beyond the 10 nm node. A rethink in the design methodology of cross-point memory to incorporate and mitigate the scaling effects of wordline/bitline is necessary. Possible solutions include the use of memory wires with better conductivity and scalability, memory arrays with smaller partition sizes, and memory elements with larger resistance values and resistance ratios.",
    "cited_by_count": 67,
    "openalex_id": "https://openalex.org/W2060598156",
    "type": "article"
  },
  {
    "title": "Design of efficient reversible logic-based binary and BCD adder circuits",
    "doi": "https://doi.org/10.1145/2491682",
    "publication_date": "2013-09-01",
    "publication_year": 2013,
    "authors": "Himanshu Thapliyal; N. Ranganathan",
    "corresponding_authors": "",
    "abstract": "Reversible logic is gaining significance in the context of emerging technologies such as quantum computing since reversible circuits do not lose information during computation and there is one-to-one mapping between the inputs and outputs. In this work, we present a class of new designs for reversible binary and BCD adder circuits. The proposed designs are primarily optimized for the number of ancilla inputs and the number of garbage outputs and are designed for possible best values for the quantum cost and delay. In reversible circuits, in addition to the primary inputs, some constant input bits are used to realize different logic functions which are referred to as ancilla inputs and are overheads that need to be reduced. Further, the garbage outputs which do not contribute to any useful computations but are needed to maintain reversibility are also overheads that need to be reduced in reversible designs. First, we propose two new designs for the reversible ripple carry adder: (i) one with no input carry c 0 and no ancilla input bits, and (ii) one with input carry c 0 and no ancilla input bits. The proposed reversible ripple carry adder designs with no ancilla input bits have less quantum cost and logic depth (delay) compared to their existing counterparts in the literature. In these designs, the quantum cost and delay are reduced by deriving designs based on the reversible Peres gate and the TR gate. Next, four new designs for the reversible BCD adder are presented based on the following two approaches: (i) the addition is performed in binary mode and correction is applied to convert to BCD when required through detection and correction, and (ii) the addition is performed in binary mode and the result is always converted using a binary to BCD converter. The proposed reversible binary and BCD adders can be applied in a wide variety of digital signal processing applications and constitute important design components of reversible computing.",
    "cited_by_count": 67,
    "openalex_id": "https://openalex.org/W3123104598",
    "type": "article"
  },
  {
    "title": "Q <scp>uick</scp> R <scp>ecall</scp>",
    "doi": "https://doi.org/10.1145/2700249",
    "publication_date": "2015-08-03",
    "publication_year": 2015,
    "authors": "Hrishikesh Jayakumar; Arnab Raha; Woo-Suk Lee; Vijay Raghunathan",
    "corresponding_authors": "",
    "abstract": "Transiently Powered Computers (TPCs) are a new class of batteryless embedded systems that depend solely on energy harvested from external sources for performing computations. Enabling long-running computations on TPCs is a major challenge due to the highly intermittent nature of the power supply (often bursts of &lt; 100ms), resulting in frequent system reboots. Prior work seeks to address this issue by frequently checkpointing system state in flash memory, preserving it across power cycles. However, this involves a substantial overhead due to the high erase/write times of flash memory. This article proposes the use of Ferroelectric RAM (FRAM), an emerging nonvolatile memory technology that combines the benefits of SRAM and flash, to seamlessly enable long-running computations in TPCs. We propose a lightweight, in-situ checkpointing technique for TPCs using FRAM that consumes only 30 nJ while decreasing the time taken for saving and restoring a checkpoint to only 21.06μ s , which is over two orders of magnitude lower than the corresponding overhead using flash. We have implemented and evaluated our technique, Q uick R ecall , using the TI MSP430FR5739 FRAM-enabled microcontroller. Experimental results show that our highly-efficient checkpointing translate to significant speedup (1.25x - 8.4x) in program execution time and reduction (∼3x) in application-level energy consumption.",
    "cited_by_count": 66,
    "openalex_id": "https://openalex.org/W1131252562",
    "type": "article"
  },
  {
    "title": "A Torus-Based Hierarchical Optical-Electronic Network-on-Chip for Multiprocessor System-on-Chip",
    "doi": "https://doi.org/10.1145/2093145.2093150",
    "publication_date": "2012-02-01",
    "publication_year": 2012,
    "authors": "Yaoyao Ye; Jiang Xu; Xiaowen Wu; Wei Zhang; Weichen Liu; Mahdi Nikdast",
    "corresponding_authors": "",
    "abstract": "Networks-on-chip (NoCs) are emerging as a key on-chip communication architecture for multiprocessor systems-on-chip (MPSoCs). Optical communication technologies are introduced to NoCs in order to empower ultra-high bandwidth with low power consumption. However, in existing optical NoCs, communication locality is poorly supported, and the importance of floorplanning is overlooked. These significantly limit the power efficiency and performance of optical NoCs. In this work, we address these issues and propose a torus-based hierarchical hybrid optical-electronic NoC, called THOE. THOE takes advantage of both electrical and optical routers and interconnects in a hierarchical manner. It employs several new techniques including floorplan optimization, an adaptive power control mechanism, low-latency control protocols, and hybrid optical-electrical routers with a low-power optical switching fabric. Both of the unfolded and folded torus topologies are explored for THOE. Based on a set of real MPSoC applications, we compared THOE with a typical torus-based optical NoC as well as a torus-based electronic NoC in 45nm on a 256-core MPSoC, using a SystemC-based cycle-accurate NoC simulator. Compared with the matched electronic torus-based NoC, THOE achieves 2.46X performance and 1.51X network switching capacity utilization, with 84% less energy consumption. Compared with the optical torus-based NoC, THOE achieves 4.71X performance and 3.05X network switching capacity utilization, while reducing 99% of energy consumption. Besides real MPSoC applications, a uniform traffic pattern is also used to show the average packet delay and network throughput of THOE. Regarding hardware cost, THOE reduces 75% of laser sources and half of optical receivers compared with the optical torus-based NoC.",
    "cited_by_count": 64,
    "openalex_id": "https://openalex.org/W2024526199",
    "type": "article"
  },
  {
    "title": "Wireless, Ultra-Low-Power Implantable Sensor for Chronic Bladder Pressure Monitoring",
    "doi": "https://doi.org/10.1145/2180878.2180883",
    "publication_date": "2012-06-01",
    "publication_year": 2012,
    "authors": "Steve Majerus; S.L. Garverick; Michael A. Suster; Paul C. Fletter; Margot S. Damaser",
    "corresponding_authors": "",
    "abstract": "The wireless implantable/intracavity micromanometer (WIMM) system was designed to fulfill the unmet need for a chronic bladder pressure sensing device in urological fields such as urodynamics for diagnosis and neuromodulation for bladder control. Neuromodulation in particular would benefit from a wireless bladder pressure sensor which could provide real-time pressure feedback to an implanted stimulator, resulting in greater bladder capacity while using less power. The WIMM uses custom integrated circuitry, a MEMS transducer, and a wireless antenna to transmit pressure telemetry at a rate of 10 Hz. Aggressive power management techniques yield an average current draw of 9 μ A from a 3.6-Volt micro-battery, which minimizes the implant size. Automatic pressure offset cancellation circuits maximize the sensing dynamic range to account for drifting pressure offset due to environmental factors, and a custom telemetry protocol allows transmission with minimum overhead. Wireless operation of the WIMM has demonstrated that the external receiver can receive the telemetry packets, and the low power consumption allows for at least 24 hours of operation with a 4-hour wireless recharge session.",
    "cited_by_count": 63,
    "openalex_id": "https://openalex.org/W2029043529",
    "type": "article"
  },
  {
    "title": "Realizing Reversible Computing in QCA Framework Resulting in Efficient Design of Testable ALU",
    "doi": "https://doi.org/10.1145/2629538",
    "publication_date": "2014-12-30",
    "publication_year": 2014,
    "authors": "Bibhash Sen; Manojit Dutta; Samik Some; Biplab K. Sikdar",
    "corresponding_authors": "",
    "abstract": "Reversible logic is emerging as a prospective logic design style for implementing ultra-low-power VLSI circuits. It promises low-power consuming circuits by nullifying the energy dissipation in irreversible logic. On the other hand, as a potential alternative to CMOS technology, Quantum-dot Cellular Automata (QCA) promises energy efficient digital design with high device density and high computing speed. The integration of reversible logic in QCA circuit is expected to be effective in addressing the issue of energy dissipation at nano scale regime. This work targets the design of reversible ALU (arithmetic logic unit) in QCA framework and proposes a new “Reversible QCA” (RQCA). The primary design focus is on optimizing the number of reversible gates, quantum cost and the garbage outputs that are the most important hindrances in realizing reversible logic. Besides optimization, the fault coverage capability of RQCA under missing/additional cell deposition defects is analysed. The scope of reversible logic is further outstretched by introducing a novel DFT (design for testability) architecture around the reversible ALU that reduces testing overhead. The performance of proposed ALU is evaluated, subjected to different faults, and is established to be more effective than the existing ALU.",
    "cited_by_count": 63,
    "openalex_id": "https://openalex.org/W2113740239",
    "type": "article"
  },
  {
    "title": "Design Considerations for Multilevel CMOS/Nano Memristive Memory",
    "doi": "https://doi.org/10.1145/2093145.2093151",
    "publication_date": "2012-02-01",
    "publication_year": 2012,
    "authors": "Harika Manem; Jeyavijayan Rajendran; Garrett S. Rose",
    "corresponding_authors": "",
    "abstract": "With technology migration into nano and molecular scales several hybrid CMOS/nano logic and memory architectures have been proposed that aim to achieve high device density with low power consumption. The discovery of the memristor has further enabled the realization of denser nanoscale logic and memory systems by facilitating the implementation of multilevel logic. This work describes the design of such a multilevel nonvolatile memristor memory system, and the design constraints imposed in the realization of such a memory. In particular, the limitations on load, bank size, number of bits achievable per device, placed by the required noise margin for accurately reading and writing the data stored in a device are analyzed. Also analyzed are the nondisruptive read and write methodologies for the hybrid multilevel memristor memory to program and read the memristive information without corrupting it. This work showcases two write methodologies that leverage the best traits of memristors when used in either linear (low power) or nonlinear drift (fast speeds) modes. The system can therefore be tailored depending on the required performance parameters of a given application for a fast memory or a slower but very energy-efficient system. We propose for the first time, a hybrid memory that aims to incorporate the area advantage provided by the utilization of multilevel logic and nanoscale memristive devices in conjunction with CMOS for the realization of a high density nonvolatile multilevel memory.",
    "cited_by_count": 60,
    "openalex_id": "https://openalex.org/W2035027123",
    "type": "article"
  },
  {
    "title": "Real-Time Anomaly Detection Framework for Many-Core Router through Machine-Learning Techniques",
    "doi": "https://doi.org/10.1145/2827699",
    "publication_date": "2016-06-16",
    "publication_year": 2016,
    "authors": "Amey Kulkarni; Youngok Pino; Matthew French; Tinoosh Mohsenin",
    "corresponding_authors": "",
    "abstract": "In this article, we propose a real-time anomaly detection framework for an NoC-based many-core architecture. We assume that processing cores and memories are safe and anomaly is included through a communication medium (i.e., router). The article targets three different attacks, namely, traffic diversion, route looping, and core address spoofing attacks. The attacks are detected by using machine-learning techniques. Comprehensive analysis on machine-learning algorithms suggests that Support Vector Machine (SVM) and K-Nearest Neighbor (K-NN) have better attack detection efficiency. It has been observed that both algorithms have accuracy in the range of 94% to 97%. Additional hardware complexity analysis advocates SVM to be implemented on hardware. To test the framework, we implement a condition-based attack insertion module; attacks are performed intra- and intercluster. The proposed real-time anomaly detection framework is fully placed and routed on Xilinx Virtex-7 FPGA. Postplace and -route implementation results show that SVM has 12% to 2% area overhead and 3% to 1% power overhead for the quad-core and 16-core implementation, respectively. It is also observed that it takes 25% to 18% of the total execution time to detect an anomaly in transferred packets for quad-core and 16-core, respectively. The proposed framework achieves 65% reduction in area overhead and is 3 times faster compared to previous published work.",
    "cited_by_count": 59,
    "openalex_id": "https://openalex.org/W2442112158",
    "type": "article"
  },
  {
    "title": "Design of Approximate Compressors for Multiplication",
    "doi": "https://doi.org/10.1145/3007649",
    "publication_date": "2017-04-20",
    "publication_year": 2017,
    "authors": "Anusha Gorantla; P. Deepa",
    "corresponding_authors": "",
    "abstract": "Approximate computing is a promising technique for energy-efficient Very Large Scale Integration (VLSI) system design. It is best suited for error-resilient applications such as signal processing and multimedia. Approximate computing reduces accuracy but still provides significant and faster results with lower power consumption. This is attractive to arithmetic circuits. In this article, various novel design approaches of approximate 4-2 and 5-2 compressors have been proposed for reduction of the partial product stages in multiplication. Three approximate 8 × 8 Dadda multiplier designs using three novel approximate 4-2 compressors and two approximate 8 × 8 Dadda multiplier designs using two novel approximate 5-2 compressors have proposed. The synthesis results show that the proposed designs achieved significant accuracy improvement together with power and delay reductions compared to the existing approximate designs.",
    "cited_by_count": 59,
    "openalex_id": "https://openalex.org/W2606856030",
    "type": "article"
  },
  {
    "title": "On-chip caches built on multilevel spin-transfer torque RAM cells and its optimizations",
    "doi": "https://doi.org/10.1145/2463585.2463592",
    "publication_date": "2013-05-01",
    "publication_year": 2013,
    "authors": "Yiran Chen; Weng‐Fai Wong; Hai Li; Cheng‐Kok Koh; Yaojun Zhang; Wujie Wen",
    "corresponding_authors": "",
    "abstract": "It has been predicted that a processor's caches could occupy as much as 90% of chip area a few technology nodes from the current ones. In this article, we investigate the use of multilevel spin-transfer torque RAM (STT-RAM) cells in the design of processor caches. We start with examining the access (read and write) scheme for multilevel cell (MLC) STT-RAM from a circuit design perspective, detailing the read and write circuits. Compared to traditional SRAM caches, a multilevel cell (MLC) STT-RAM cache design is denser, fast, and requires less energy. However, a number of critical architecture-level issues remain to be solved before MLC STT-RAM technology can be deployed in processor caches. We shall offer solutions to the issue of bit encoding as well as tackle the write endurance problem. In particular, the latter has been neglected in previous works on STT-RAM caches. We propose a set remapping scheme that can potentially prolong the lifetime of a MLC STT-RAM cache by 80× on average. Furthermore, a method for recovering the performance that may be lost in some applications due to set remapping is proposed. The impacts of process variations of the MLC STT-RAM cell on the robustness of the memory hierarchy is also discussed, together with various enhancement techniques, namely, ECC and design redundancy.",
    "cited_by_count": 58,
    "openalex_id": "https://openalex.org/W2120246901",
    "type": "article"
  },
  {
    "title": "Embedding of Large Boolean Functions for Reversible Logic",
    "doi": "https://doi.org/10.1145/2786982",
    "publication_date": "2015-12-09",
    "publication_year": 2015,
    "authors": "Mathias Soeken; Robert Wille; Oliver Keszöcze; D. Michael Miller; Rolf Drechsler",
    "corresponding_authors": "",
    "abstract": "Reversible logic represents the basis for many emerging technologies and has recently been intensively studied. However, most of the Boolean functions of practical interest are irreversible and must be embedded into a reversible function before they can be synthesized. Thus far, an optimal embedding is guaranteed only for small functions, whereas a significant overhead results when large functions are considered. We study this issue in this article. We prove that determining an optimal embedding is coNP-hard already for restricted cases. Then, we propose heuristic and exact methods for determining both the number of additional lines and a corresponding embedding. For the approaches, we considered sum of products and binary decision diagrams as function representations. Experimental evaluations show the applicability of the approaches for large functions. Consequently, the reversible embedding of large functions is enabled as a precursor to subsequent synthesis.",
    "cited_by_count": 56,
    "openalex_id": "https://openalex.org/W1501182936",
    "type": "article"
  },
  {
    "title": "CDMA Enabled Wireless Network-on-Chip",
    "doi": "https://doi.org/10.1145/2536778",
    "publication_date": "2014-05-01",
    "publication_year": 2014,
    "authors": "Vineeth Vijayakumaran; Manoj Prashanth Yuvaraj; Naseef Mansoor; Nishad Nerurkar; Amlan Ganguly; Andres Kwasinski",
    "corresponding_authors": "",
    "abstract": "Multihop communication links in conventional Networks-on-Chips (NoCs) results in lower rates of data transfer and higher energy dissipation. Long-range millimeter-wave wireless interconnects were envisioned to alleviate this problem. However, the available bandwidth of the wireless channels is limited and hence an efficient media access control (MAC) scheme is required to enhance the utilization of the available bandwidth. In this article we show that with multiple simultaneous access of the shared wireless medium using a Code Division Multiple Access (CDMA) scheme the peak performance can be improved significantly while lowering energy dissipation in data transfer compared to the conventional wireline counterparts as well as state-of-the-art Wireless NoCs using similar technologies. We present a thorough analysis of the reliability in data transfer using the CDMA based wireless links and show that a reliability-aware architecture design with CDMA based wireless links can lower the energy dissipation in NoC fabrics without compromising the achievable robustness.",
    "cited_by_count": 56,
    "openalex_id": "https://openalex.org/W2019940951",
    "type": "article"
  },
  {
    "title": "Composable Probabilistic Inference Networks Using MRAM-based Stochastic Neurons",
    "doi": "https://doi.org/10.1145/3304105",
    "publication_date": "2019-03-26",
    "publication_year": 2019,
    "authors": "Ramtin Zand; Kerem Y. Çamsarı; Supriyo Datta; Ronald F. DeMara",
    "corresponding_authors": "",
    "abstract": "Magnetoresistive random access memory (MRAM) technologies with thermally unstable nanomagnets are leveraged to develop an intrinsic stochastic neuron as a building block for restricted Boltzmann machines (RBMs) to form deep belief networks (DBNs). The embedded MRAM-based neuron is modeled using precise physics equations. The simulation results exhibit the desired sigmoidal relation between the input voltages and probability of the output state. A probabilistic inference network simulator (PIN-Sim) is developed to realize a circuit-level model of an RBM utilizing resistive crossbar arrays along with differential amplifiers to implement the positive and negative weight values. The PIN-Sim is composed of five main blocks to train a DBN, evaluate its accuracy, and measure its power consumption. The MNIST dataset is leveraged to investigate the energy and accuracy tradeoffs of seven distinct network topologies in SPICE using the 14nm HP-FinFET technology library with the nominal voltage of 0.8V, in which an MRAM-based neuron is used as the activation function. The software and hardware level simulations indicate that a $784\\times200\\times10$ topology can achieve less than 5% error rates with $\\sim400 pJ$ energy consumption. The error rates can be reduced to 2.5% by using a $784\\times500\\times500\\times500\\times10$ DBN at the cost of $\\sim10\\times$ higher energy consumption and significant area overhead. Finally, the effects of specific hardware-level parameters on power dissipation and accuracy tradeoffs are identified via the developed PIN-Sim framework.",
    "cited_by_count": 50,
    "openalex_id": "https://openalex.org/W3125659218",
    "type": "article"
  },
  {
    "title": "OpenQL: A Portable Quantum Programming Framework for Quantum Accelerators",
    "doi": "https://doi.org/10.1145/3474222",
    "publication_date": "2021-12-20",
    "publication_year": 2021,
    "authors": "N. Khammassi; Imran Ashraf; J. van Someren; Răzvan Nane; Anna M. Krol; M. A. Rol; Lingling Lao; K. Bertels; Carmen G. Almudéver",
    "corresponding_authors": "",
    "abstract": "With the potential of quantum algorithms to solve intractable classical problems, quantum computing is rapidly evolving, and more algorithms are being developed and optimized. Expressing these quantum algorithms using a high-level language and making them executable on a quantum processor while abstracting away hardware details is a challenging task. First, a quantum programming language should provide an intuitive programming interface to describe those algorithms. Then a compiler has to transform the program into a quantum circuit, optimize it, and map it to the target quantum processor respecting the hardware constraints such as the supported quantum operations, the qubit connectivity, and the control electronics limitations. In this article, we propose a quantum programming framework named OpenQL, which includes a high-level quantum programming language and its associated quantum compiler. We present the programming interface of OpenQL, we describe the different layers of the compiler and how we can provide portability over different qubit technologies. Our experiments show that OpenQL allows the execution of the same high-level algorithm on two different qubit technologies, namely superconducting qubits and Si-Spin qubits. Besides the executable code, OpenQL also produces an intermediate quantum assembly code, which is technology independent and can be simulated using the QX simulator.",
    "cited_by_count": 43,
    "openalex_id": "https://openalex.org/W3032429584",
    "type": "article"
  },
  {
    "title": "Defects, Fault Modeling, and Test Development Framework for RRAMs",
    "doi": "https://doi.org/10.1145/3510851",
    "publication_date": "2022-03-25",
    "publication_year": 2022,
    "authors": "Moritz Fieback; Guilherme Cardoso Medeiros; Lizhou Wu; Hassen Aziza; Rajendra Bishnoi; Mottaqiallah Taouil; Said Hamdioui",
    "corresponding_authors": "",
    "abstract": "Resistive RAM (RRAM) is a promising technology to replace traditional technologies such as Flash, because of its low energy consumption, CMOS compatibility, and high density. Many companies are prototyping this technology to validate its potential. Bringing this technology to the market requires high-quality tests to ensure customer satisfaction. Hence, it is of great importance to deeply understand manufacturing defects and accurately model them to develop optimal tests. This paper presents a holistic framework for defect and fault modeling that enables the development of optimal tests for RRAMs. An overview and classification of RRAM manufacturing defects are provided. Defects in contacts and interconnects are modeled as resistors. Unique RRAM defects, e.g., forming defects, require Device-Aware defect modeling which incorporates the defect’s impact on the device’s electric properties by adjusting the affected technology and electrical parameters. Additionally, a systematic approach to define the fault space is presented, followed by a methodology to validate this space. With this methodology, accurate fault modeling for contact, interconnect, and forming defects is performed and tests are developed. The tests are able to detect all faults in a time-efficient manner, thereby proving the effectiveness of the framework. Finally, an outlook on future RRAM testing is presented.",
    "cited_by_count": 29,
    "openalex_id": "https://openalex.org/W4220791354",
    "type": "article"
  },
  {
    "title": "Tile-based QCA design using majority-like logic primitives",
    "doi": "https://doi.org/10.1145/1116696.1116697",
    "publication_date": "2005-10-01",
    "publication_year": 2005,
    "authors": "Jr‐Chuan Huang; M. Momenzadeh; L. Schiano; Marco Ottavi; Fabrizio Lombardi",
    "corresponding_authors": "",
    "abstract": "The design of circuits and systems in Quantum-dot Cellular Automata (QCA) is still in infancy. The basic logic primitive in QCA is the majority voter (MV), that is not a universal function; so, inverters (INV) are also required. Blocks (referred to as tiles) are utilized in this article. A tile with a combined logic function of MV and INV (MV-like function) is proposed. It is shown that the MV-like tile can be effectively used in logic design as basic primitive. Tiles based on both the fully populated (FP) and non-fully populated (NFP) grids are investigated in detail. Various arrangements in inputs and outputs are also possible among the 4 sides of a grid, thus defining different tiles. Using a coherence vector simulation engine, it is shown that the 3 × 3 grid offers versatile logic operation. Different combinational functions such as majority-like and wire crossing are obtained using these tiles. Tile-based design of different circuits is compared to gate-based and SQUARES designs.",
    "cited_by_count": 75,
    "openalex_id": "https://openalex.org/W1976036211",
    "type": "article"
  },
  {
    "title": "Simulation of random cell displacements in QCA",
    "doi": "https://doi.org/10.1145/1229175.1229177",
    "publication_date": "2007-04-01",
    "publication_year": 2007,
    "authors": "G. Schulhof; Konrad Walus; G.A. Jullien",
    "corresponding_authors": "",
    "abstract": "We analyze the behavior of quantum-dot cellular automata (QCA) building blocks in the presence of random cell displacements. The QCA cells are modeled using the coherence vector description and simulated using QCADesigner. We evaluate various fundamental circuits: the wire, the inverter, the majority gate, and the two-wire crossing approaches: the coplanar crossover and the multilayer crossover. Our results show that different building blocks have different displacement tolerances. The coplanar crossover and inverter perform the weakest. The wire is the most robust. We have found displacement tolerances to be a function of circuit layout and geometry rather than cell size.",
    "cited_by_count": 63,
    "openalex_id": "https://openalex.org/W1982064050",
    "type": "article"
  },
  {
    "title": "Automated design of pin-constrained digital microfluidic biochips under droplet-interference constraints",
    "doi": "https://doi.org/10.1145/1295231.1295235",
    "publication_date": "2007-11-01",
    "publication_year": 2007,
    "authors": "Tao Xu; William L. Hwang; Fei Su; Krishnendu Chakrabarty",
    "corresponding_authors": "",
    "abstract": "Microfluidics-based biochips, also referred to as lab-on-a-chip, are devices that integrate fluid-handling functions such as sample preparation, analysis, separation, and detection. This emerging technology combines electronics with biology to open new application areas such as point-of-care diagnosis, on-chip DNA analysis, and automated drug discovery. We propose a design automation method for pin-constrained biochips that manipulate nanoliter volumes of discrete droplets on a microfluidic array. In contrast to the direct-addressing scheme that has been studied thus far in the literature, we assign a small number of independent control pins to a large number of electrodes in the biochip, thereby reducing design complexity and product cost. The design procedure relies on a droplet-trace-based array partitioning scheme and an efficient pin assignment technique, referred to as the “Connect-5 algorithm.” The proposed method is evaluated using a set of multiplexed bioassays.",
    "cited_by_count": 63,
    "openalex_id": "https://openalex.org/W2146429746",
    "type": "article"
  },
  {
    "title": "Non-Volatile Processor Based on MRAM for Ultra-Low-Power IoT Devices",
    "doi": "https://doi.org/10.1145/3001936",
    "publication_date": "2016-12-01",
    "publication_year": 2016,
    "authors": "Sophiane Senni; Lionel Torres; Gilles Sassatelli; Abdoulaye Gamatié",
    "corresponding_authors": "",
    "abstract": "Over the past few years, a new era of smart connected devices has emerged in the market to enable the future world of the Internet of Things (IoT). A key requirement for IoT applications is the power consumption to allow very high autonomy in the case of battery-powered systems. Depending on the application, such devices will be most of the time in a low-power mode (sleep mode) and will wake up only when there is a task to accomplish (active mode). Emerging non-volatile memory technologies are seen as a very attractive solution to design ultra-low-power systems. Among these technologies, magnetic random access memory is a promising candidate, as it combines non-volatility, high density, reasonable latency, and low leakage. Integration of non-volatility as a new feature of memories has the great potential to allow full data retention after a complete shutdown with a fast wake-up time. This article explores the benefits of having a non-volatile processor to enable ultra-low-power IoT devices.",
    "cited_by_count": 48,
    "openalex_id": "https://openalex.org/W2557257858",
    "type": "article"
  },
  {
    "title": "Distributed In-Memory Computing on Binary RRAM Crossbar",
    "doi": "https://doi.org/10.1145/2996192",
    "publication_date": "2017-03-17",
    "publication_year": 2017,
    "authors": "Leibin Ni; Hantao Huang; Zichuan Liu; Rajiv Joshi; Hao Yu",
    "corresponding_authors": "",
    "abstract": "The recently emerging resistive random-access memory (RRAM) can provide nonvolatile memory storage but also intrinsic computing for matrix-vector multiplication, which is ideal for the low-power and high-throughput data analytics accelerator performed in memory. However, the existing RRAM crossbar--based computing is mainly assumed as a multilevel analog computing, whose result is sensitive to process nonuniformity as well as additional overhead from AD-conversion and I/O. In this article, we explore the matrix-vector multiplication accelerator on a binary RRAM crossbar with adaptive 1-bit-comparator--based parallel conversion. Moreover, a distributed in-memory computing architecture is also developed with the according control protocol. Both memory array and logic accelerator are implemented on the binary RRAM crossbar, where the logic-memory pair can be distributed with the control bus protocol. Experimental results have shown that compared to the analog RRAM crossbar, the proposed binary RRAM crossbar can achieve significant area savings with better calculation accuracy. Moreover, significant speedup can be achieved for matrix-vector multiplication in neural network--based machine learning such that the overall training and testing time can be both reduced. In addition, large energy savings can be also achieved when compared to the traditional CMOS-based out-of-memory computing architecture.",
    "cited_by_count": 48,
    "openalex_id": "https://openalex.org/W2603636614",
    "type": "article"
  },
  {
    "title": "Energy-Efficient and Improved Image Recognition with Conditional Deep Learning",
    "doi": "https://doi.org/10.1145/3007192",
    "publication_date": "2017-02-09",
    "publication_year": 2017,
    "authors": "Priyadarshini Panda; Abhronil Sengupta; Kaushik Roy",
    "corresponding_authors": "",
    "abstract": "Deep-learning neural networks have proven to be very successful for a wide range of recognition tasks across modern computing platforms. However, the computational requirements associated with such deep nets can be quite high, and hence their energy-efficient implementation is of great interest. Although, traditionally, the entire network is utilized for the recognition of all inputs, we observe that the classification difficulty varies widely across inputs in real-world datasets; only a small fraction of inputs requires the full computational effort of a network, while a large majority can be classified correctly with very low effort. In this article, we propose Conditional Deep Learning (CDL), where the convolutional layer features are used to identify the variability in the difficulty of input instances and conditionally activate the deeper layers of the network. We achieve this by cascading a linear network of output neurons for each convolutional layer and monitoring the output of the linear network to decide whether classification can be terminated at the current stage or not. The proposed methodology thus enables the network to dynamically adjust the computational effort depending on the difficulty of the input data while maintaining competitive classification accuracy. The overall energy benefits for MNIST/CIFAR10/Tiny ImageNet datasets with state-of-the-art deep-learning architectures are 1.84 × /2.83 × /4.02 × , respectively. We further employ the conditional approach to train deep-learning networks from scratch with integrated supervision from the additional output neurons appended at the intermediate convolutional layers. Our proposed integrated CDL training leads to an improvement in the gradient convergence behavior giving substantial error rate reduction on MNIST/CIFAR-10, resulting in improved classification over state-of-the-art baseline networks.",
    "cited_by_count": 47,
    "openalex_id": "https://openalex.org/W2586565528",
    "type": "article"
  },
  {
    "title": "SUOR",
    "doi": "https://doi.org/10.1145/2600072",
    "publication_date": "2014-05-01",
    "publication_year": 2014,
    "authors": "Xiaowen Wu; Jiang Xu; Yaoyao Ye; Zhehui Wang; Mahdi Nikdast; Xuan Wang",
    "corresponding_authors": "",
    "abstract": "Chip multiprocessor (CMP) is becoming an attractive platform for applications seeking both high performance and high energy efficiency. In large-scale CMPs, the communication efficiency among cores is crucial for the overall system performance and energy consumption. In this article, we propose a ring-based optical network-on-chip, called SUOR, to fulfill the communication requirement of CMPs. SUOR effectively explores the distinctive properties of optical signals and photonic devices, and dynamically partitions each data channel into multiple sections. Each section can be utilized independently to boost performance as well as reduce energy consumption. We develop a set of distributed control protocols and algorithms for SUOR, but physically allocate the corresponding cluster agents close to each other to benefit from the strengths of optical interconnects at long distances as well as electrical interconnects at short distances. Simulation results show that SUOR outperforms the alternative optical networks under a wide range of traffic patterns. For example, compared with MWSR design, SUOR achieves 2.58× throughput as well as saves 64% energy consumption on average in a 256-core CMP. Compared with MWMR design, SUOR achieves 1.52× throughput and reduces 73% energy consumption on average.",
    "cited_by_count": 46,
    "openalex_id": "https://openalex.org/W2058674318",
    "type": "article"
  },
  {
    "title": "Design Options for Optical Ring Interconnect in Future Client Devices",
    "doi": "https://doi.org/10.1145/2602155",
    "publication_date": "2014-05-01",
    "publication_year": 2014,
    "authors": "Paolo Grani; Sandro Bartolini",
    "corresponding_authors": "",
    "abstract": "Nanophotonic is a promising solution for on-chip interconnection due to its intrinsic low-latency and low-power features. Future tiled chip multiprocessors (CMPs) for rich client devices can receive energy benefits from this technology but we show that great care has to be put in the integration of the various involved facets to avoid queuing and serialization issues and obtain the rated potential advantages. We evaluate different management strategies for accessing a simple, shared photonic path (ring), working in conjunctions with a standard electronic mesh or alone, in a tiled CMP. Our results highlight that a careful selection of the most latency-critical messages to be routed in photonics and the use of a conflict-free access scheme is crucial for obtaining performance/power advantages when the available bandwidth is limited. We identify the design point where all the traffic can be routed on the photonic path and thus the electronic network can be suppressed. At this point, the ring achieves 20--25% speedup and 84% energy consumption improvement over the electronic baseline. Then we investigate the same trade-offs when the number of rings is increased up to eight, allowing to raise performance benefits up to 40% or reaching up to 80% energy reduction. We finally explore the effects of deploying a given optical parallelism split between a higher number of waveguides for further improving energy savings.",
    "cited_by_count": 45,
    "openalex_id": "https://openalex.org/W2013626493",
    "type": "article"
  },
  {
    "title": "Software aging in the eucalyptus cloud computing infrastructure",
    "doi": "https://doi.org/10.1145/2539122",
    "publication_date": "2014-01-01",
    "publication_year": 2014,
    "authors": "Jean Araújo; Rubens Matos; Vandi Alves; Paulo Maciel; Francisco Souza; Rivalino Matias; Kishor S. Trivedi",
    "corresponding_authors": "",
    "abstract": "The need for high reliability, availability and performance has significantly increased in modern applications, that handle rapidly growing demands while providing uninterruptible services. Cloud computing systems fundamentally provide access to large pools of data and computational resources. Eucalyptus is a software framework largely used to implement private clouds and hybrid-style Infrastructure as a Service. It implements the Amazon Web Service (AWS) API, allowing interoperability with other AWS-based services. This article investigates the software aging effects in the Eucalyptus framework, considering workloads composed of intensive requests for remote storage attachment and virtual machine instantiations. We found problems that may be harmful to system dependability and performance, specifically regarding to RAM memory and swap space exhaustion, besides highly excessive CPU utilization by the virtual machines. We also present an approach that applies time series analysis to schedule rejuvenation, so as to reduce the downtime by predicting the proper moment to perform the rejuvenation. We experimentally evaluate our approach using an Eucalyptus test bed. The results show that our approach achieves higher availability, when compared to a threshold-triggered rejuvenation method based on continuous monitoring of resources utilization.",
    "cited_by_count": 45,
    "openalex_id": "https://openalex.org/W2130854642",
    "type": "article"
  },
  {
    "title": "STT-MRAM-Based PUF Architecture Exploiting Magnetic Tunnel Junction Fabrication-Induced Variability",
    "doi": "https://doi.org/10.1145/2790302",
    "publication_date": "2016-05-06",
    "publication_year": 2016,
    "authors": "Elena Ioana Vatajelu; Giorgio Di Natale; Mario Barbareschi; Lionel Torres; Marco Indaco; P. Prinetto",
    "corresponding_authors": "",
    "abstract": "Physically Unclonable Functions (PUFs) are emerging cryptographic primitives used to implement low-cost device authentication and secure secret key generation. Weak PUF s (i.e., devices able to generate a single signature or to deal with a limited number of challenges) are widely discussed in literature. One of the most investigated solutions today is based on SRAMs. However, the rapid development of low-power, high-density, high-performance SoCs has pushed the embedded memories to their limits and opened the field to the development of emerging memory technologies. The Spin-Transfer-Torque Magnetic Random Access Memory (STT-MRAM) has emerged as a promising choice for embedded memories due to its reduced read/write latency and high CMOS integration capability. In this article, we propose an innovative PUF design based on STT-MRAM memory. We exploit the high variability affecting the electrical resistance of the Magnetic Tunnel Junction (MTJ) device in anti-parallel magnetization. We will demonstrate that the proposed solution is robust, unclonable, and unpredictable.",
    "cited_by_count": 44,
    "openalex_id": "https://openalex.org/W2345348465",
    "type": "article"
  },
  {
    "title": "Spike-Time-Dependent Encoding for Neuromorphic Processors",
    "doi": "https://doi.org/10.1145/2738040",
    "publication_date": "2015-09-21",
    "publication_year": 2015,
    "authors": "Chenyuan Zhao; Bryant Wysocki; Yifang Liu; Clare Thiem; Nathan McDonald; Yang Yi",
    "corresponding_authors": "",
    "abstract": "This article presents our research towards developing novel and fundamental methodologies for data representation using spike-timing-dependent encoding. Time encoding efficiently maps a signal's amplitude information into a spike time sequence that represents the input data and offers perfect recovery for band-limited stimuli. In this article, we pattern the neural activities across multiple timescales and encode the sensory information using time-dependent temporal scales. The spike encoding methodologies for autonomous classification of time-series signatures are explored using near-chaotic reservoir computing. The proposed spiking neuron is compact, low power, and robust. A hardware implementation of these results is expected to produce an agile hardware implementation of time encoding as a signal conditioner for dynamical neural processor designs.",
    "cited_by_count": 43,
    "openalex_id": "https://openalex.org/W2061056596",
    "type": "article"
  },
  {
    "title": "Long Short-Term Memory Network Design for Analog Computing",
    "doi": "https://doi.org/10.1145/3289393",
    "publication_date": "2019-01-09",
    "publication_year": 2019,
    "authors": "Zhou Zhao; Ashok Srivastava; Lu Peng; Qing Chen",
    "corresponding_authors": "",
    "abstract": "We present an analog-integrated circuit implementation of long short-term memory network, which is compatible with digital CMOS technology. We have used multiple-input floating gate MOSFETs as both the front-end to obtain converted analog signals and the differential pairs in proposed analog multipliers. Analog crossbar is built by the analog multiplier processing matrix and bitwise multiplications. We have shown that using current signals as internal transmission signals can largely reduce computation delay, compared to the digital implementation. We also have introduced analog blocks to work as activation functions for the algorithm. In the back-end of our design, we have used current comparators to achieve the output to be readable to external digital systems. We have designed the LSTM network with the matrix size of 16 × 16 in TSMC 180nm CMOS technology. The post-layout simulations show that the latency of one computing cycle is 1.19ns without memory, and power dissipation of the single analog LSTM computing core with 2 kilobytes SRAM at 200MHz is 460.3mW. The overhead of power dissipation due to SRAM access is 8.3%, in which the computing of each LSTM layer requires one computing cycle. The energy efficiency is 0.95TOP/s/W.",
    "cited_by_count": 43,
    "openalex_id": "https://openalex.org/W2910166072",
    "type": "article"
  },
  {
    "title": "DFR",
    "doi": "https://doi.org/10.1145/3264659",
    "publication_date": "2018-10-31",
    "publication_year": 2018,
    "authors": "Kangjun Bai; Yang Yi",
    "corresponding_authors": "",
    "abstract": "Neuromorphic computing, which is built on a brain-inspired silicon chip, is uniquely applied to keep pace with the explosive escalation of algorithms and data density on machine learning. Reservoir computing, an emerging computing paradigm based on the recurrent neural network with proven benefits across multifaceted applications, offers an alternative training mechanism only at the readout stage. In this work, we successfully design and fabricate an energy-efficient analog delayed feedback reservoir (DFR) computing system, which is built upon a temporal encoding scheme, a nonlinear transfer function, and a dynamic delayed feedback loop. Measurement results demonstrate its high energy efficiency with rich dynamic behaviors, making the designed system a candidate for low power embedded applications. The system performance, as well as the robustness, are studied and analyzed through the Monte Carlo simulation. The chaotic time series prediction benchmark, NARMA10, is examined through the proposed DFR computing system, and exhibits a 36%−85% reduction on the error rate compared to state-of-the-art DFR computing system designs. To the best of our knowledge, our work represents the first analog integrated circuit (IC) implementation of the DFR computing system.",
    "cited_by_count": 40,
    "openalex_id": "https://openalex.org/W2905059955",
    "type": "article"
  },
  {
    "title": "QCOR",
    "doi": "https://doi.org/10.1145/3380964",
    "publication_date": "2020-03-18",
    "publication_year": 2020,
    "authors": "Tiffany M. Mintz; Alexander McCaskey; Eugene Dumitrescu; Shirley Moore; Sarah Powers; Pavel Lougovski",
    "corresponding_authors": "",
    "abstract": "Quantum computing (QC) is an emerging computational paradigm that leverages the laws of quantum mechanics to perform elementary logic operations. Existing programming models for QC were designed with fault-tolerant hardware in mind, envisioning stand-alone applications. However, the susceptibility of near-term quantum computers to noise limits their stand-alone utility. To better leverage limited computational strengths of noisy quantum devices, hybrid algorithms have been suggested whereby quantum computers are used in tandem with their classical counterparts in a heterogeneous fashion. This modus operandi calls out for a programming model and a high-level programming language that natively and seamlessly supports heterogeneous quantum-classical hardware architectures in a single-source-code paradigm. Motivated by the lack of such a model, we introduce a language extension specification, called QCOR , which enables single-source quantum-classical programming. Programs written using the QCOR library–based language extensions can be compiled to produce functional hybrid binary executables. After defining QCOR’s programming model, memory model, and execution model, we discuss how QCOR enables variational, iterative, and feed-forward QC. QCOR approaches quantum-classical computation in a hardware-agnostic heterogeneous fashion and strives to build on best practices of high-performance computing. The high level of abstraction in the language extension is intended to accelerate the adoption of QC by researchers familiar with classical high-performance computing.",
    "cited_by_count": 38,
    "openalex_id": "https://openalex.org/W3011176868",
    "type": "article"
  },
  {
    "title": "Guarding Machine Learning Hardware Against Physical Side-channel Attacks",
    "doi": "https://doi.org/10.1145/3465377",
    "publication_date": "2022-02-02",
    "publication_year": 2022,
    "authors": "Anuj Dubey; Rosario Cammarota; Vikram Suresh; Aydın Aysu",
    "corresponding_authors": "",
    "abstract": "Machine learning (ML) models can be trade secrets due to their development cost. Hence, they need protection against malicious forms of reverse engineering (e.g., in IP piracy). With a growing shift of ML to the edge devices, in part for performance and in part for privacy benefits, the models have become susceptible to the so-called physical side-channel attacks. ML being a relatively new target compared to cryptography poses the problem of side-channel analysis in a context that lacks published literature. The gap between the burgeoning edge-based ML devices and the research on adequate defenses to provide side-channel security for them thus motivates our study. Our work develops and combines different flavors of side-channel defenses for ML models in the hardware blocks. We propose and optimize the first defense based on Boolean masking . We first implement all the masked hardware blocks. We then present an adder optimization to reduce the area and latency overheads. Finally, we couple it with a shuffle-based defense. We quantify that the area-delay overhead of masking ranges from 5.4× to 4.7× depending on the adder topology used and demonstrate a first-order side-channel security of millions of power traces. Additionally, the shuffle countermeasure impedes a straightforward second-order attack on our first-order masked implementation.",
    "cited_by_count": 25,
    "openalex_id": "https://openalex.org/W3197298723",
    "type": "article"
  },
  {
    "title": "Design and Analysis of FPGA-based PUFs with Enhanced Performance for Hardware-oriented Security",
    "doi": "https://doi.org/10.1145/3517813",
    "publication_date": "2022-03-25",
    "publication_year": 2022,
    "authors": "N. Nalla Anandakumar; Mohammad Hashmi; Somitra Kumar Sanadhya",
    "corresponding_authors": "",
    "abstract": "This article presents a thorough analysis of two distinct Physically Unclonable Functions (PUF), namely RO-PUF (Ring oscillator-based PUF) and RS-LPUF (RS Latch-based PUF), prototyped on FPGA. It is shown that the implemented PUFs possess significantly enhanced performance when compared to the state of the art. It is also identified that the enhancements are achieved through the incorporation of Programmable Delay Lines of FPGA Lookup Tables, the Temporal Majority Voting (TMV) scheme, and placed macro techniques for routing and placements of PUF units. The prototypes developed on Xilinx Artix-7 FPGAs are used for validation over the rated temperature range of 0-85° C with ±5% variation in the supply voltage. The proposed schemes when evaluated experimentally also achieve good uniformity, bit-aliasing, uniqueness, and reliability. Finally, it is shown that the proposed designs outperform the existing conventional PUFs in the area and speed tradeoff.",
    "cited_by_count": 24,
    "openalex_id": "https://openalex.org/W4220658028",
    "type": "article"
  },
  {
    "title": "Hardware Trojan Detection Using Unsupervised Deep Learning on Quantum Diamond Microscope Magnetic Field Images",
    "doi": "https://doi.org/10.1145/3531010",
    "publication_date": "2022-04-29",
    "publication_year": 2022,
    "authors": "Maitreyi Ashok; Matthew Turner; Ronald L. Walsworth; Edlyn V. Levine; Anantha P. Chandrakasan",
    "corresponding_authors": "",
    "abstract": "This paper presents a method for hardware trojan detection in integrated circuits. Unsupervised deep learning is used to classify wide field-of-view (4x4 mm$^2$), high spatial resolution magnetic field images taken using a Quantum Diamond Microscope (QDM). QDM magnetic imaging is enhanced using quantum control techniques and improved diamond material to increase magnetic field sensitivity by a factor of 4 and measurement speed by a factor of 16 over previous demonstrations. These upgrades facilitate the first demonstration of QDM magnetic field measurement for hardware trojan detection. Unsupervised convolutional neural networks and clustering are used to infer trojan presence from unlabeled data sets of 600x600 pixel magnetic field images without human bias. This analysis is shown to be more accurate than principal component analysis for distinguishing between field programmable gate arrays configured with trojan free and trojan inserted logic. This framework is tested on a set of scalable trojans that we developed and measured with the QDM. Scalable and TrustHub trojans are detectable down to a minimum trojan trigger size of 0.5% of the total logic. The trojan detection framework can be used for golden-chip free detection, since knowledge of the chips' identities is only used to evaluate detection accuracy",
    "cited_by_count": 24,
    "openalex_id": "https://openalex.org/W4225162971",
    "type": "article"
  },
  {
    "title": "Reliable Constructions for the Key Generator of Code-based Post-quantum Cryptosystems on FPGA",
    "doi": "https://doi.org/10.1145/3544921",
    "publication_date": "2022-06-23",
    "publication_year": 2022,
    "authors": "Alvaro Cintas Canto; Mehran Mozaffari Kermani; Reza Azarderakhsh",
    "corresponding_authors": "",
    "abstract": "Advances in quantum computing have urged the need for cryptographic algorithms that are low-power, low-energy, and secure against attacks that can be potentially enabled. For this post-quantum age, different solutions have been studied. Code-based cryptography is one feasible solution whose hardware architectures have become the focus of research in the NIST standardization process and has been advanced to the final round (to be concluded by 2022–2024). Nevertheless, although these constructions, e.g., McEliece and Niederreiter public key cryptography, have strong error correction properties, previous studies have proved the vulnerability of their hardware implementations against faults product of the environment and intentional faults, i.e., differential fault analysis. It is previously shown that depending on the codes used, i.e., classical or reduced (using either quasi-dyadic Goppa codes or quasi-cyclic alternant codes), flaws in error detection could be observed. In this work, efficient fault detection constructions are proposed for the first time to account for such shortcomings. Such schemes are based on regular parity, interleaved parity, and two different cyclic redundancy checks (CRC), i.e., CRC-2 and CRC-8. Without losing the generality, we experiment on the McEliece variant, noting that the presented schemes can be used for other code-based cryptosystems. We perform error detection capability assessments and implementations on field-programmable gate array Kintex-7 device xc7k70tfbv676-1 to verify the practicality of the presented approaches. To demonstrate the appropriateness for constrained embedded systems, the performance degradation and overheads of the presented schemes are assessed.",
    "cited_by_count": 24,
    "openalex_id": "https://openalex.org/W4283321430",
    "type": "article"
  },
  {
    "title": "The Bitlet Model: A Parameterized Analytical Model to Compare PIM and CPU Systems",
    "doi": "https://doi.org/10.1145/3465371",
    "publication_date": "2022-03-25",
    "publication_year": 2022,
    "authors": "Ronny Ronen; Adi Eliahu; Orian Leitersdorf; Natan Peled; Kunal Korgaonkar; Anupam Chattopadhyay; Ben Perach; Shahar Kvatinsky",
    "corresponding_authors": "",
    "abstract": "Currently, data-intensive applications are gaining popularity. Together with this trend, processing-in-memory (PIM)–based systems are being given more attention and have become more relevant. This article describes an analytical modeling tool called Bitlet that can be used in a parameterized fashion to estimate the performance and power/energy of a PIM-based system and, thereby, assess the affinity of workloads for PIM as opposed to traditional computing. The tool uncovers interesting trade-offs between, mainly, the PIM computation complexity (cycles required to perform a computation through PIM), the amount of memory used for PIM, the system memory bandwidth, and the data transfer size. Despite its simplicity, the model reveals new insights when applied to real-life examples. The model is demonstrated for several synthetic examples and then applied to explore the influence of different parameters on two systems — IMAGING and FloatPIM. Based on the demonstrations, insights about PIM and its combination with a CPU are provided.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W3184976412",
    "type": "article"
  },
  {
    "title": "A Survey on Memory-centric Computer Architectures",
    "doi": "https://doi.org/10.1145/3544974",
    "publication_date": "2022-06-29",
    "publication_year": 2022,
    "authors": "Anteneh Gebregiorgis; Hoang Anh Du Nguyen; Jintao Yu; Rajendra Bishnoi; Mottaqiallah Taouil; Francky Catthoor; Said Hamdioui",
    "corresponding_authors": "",
    "abstract": "Faster and cheaper computers have been constantly demanding technological and architectural improvements. However, current technology is suffering from three technology walls: leakage wall, reliability wall, and cost wall. Meanwhile, existing architecture performance is also saturating due to three well-known architecture walls: memory wall, power wall, and instruction-level parallelism (ILP) wall. Hence, a lot of novel technologies and architectures have been introduced and developed intensively. Our previous work has presented a comprehensive classification and broad overview of memory-centric computer architectures. In this article, we aim to discuss the most important classes of memory-centric architectures thoroughly and evaluate their advantages and disadvantages. Moreover, for each class, the article provides a comprehensive survey on memory-centric architectures available in the literature.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W4293251144",
    "type": "article"
  },
  {
    "title": "FPIC: A Novel Semantic Dataset for Optical PCB Assurance",
    "doi": "https://doi.org/10.1145/3588032",
    "publication_date": "2023-03-22",
    "publication_year": 2023,
    "authors": "Nathan Jessurun; Olivia P. Dizon-Paradis; Jacob Harrison; Shajib Ghosh; Mark Tehranipoor; Damon L. Woodard; Navid Asadizanjani",
    "corresponding_authors": "",
    "abstract": "Outsourced printed circuit board (PCB) fabrication necessitates increased hardware assurance capabilities. Several assurance techniques based on automated optical inspection (AOI) have been proposed that leverage PCB images acquired using digital cameras. We review state-of-the-art AOI techniques and observe a strong, rapid trend toward machine learning (ML) solutions. These require significant amounts of labeled ground truth data, which is lacking in the publicly available PCB data space. We contribute the FICS PCB Image Collection (FPIC) dataset to address this need. Additionally, we outline new hardware security methodologies enabled by our data set.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W4353069825",
    "type": "article"
  },
  {
    "title": "Application-independent defect tolerance of reconfigurable nanoarchitectures",
    "doi": "https://doi.org/10.1145/1167943.1167945",
    "publication_date": "2006-07-01",
    "publication_year": 2006,
    "authors": "Mehdi B. Tahoori",
    "corresponding_authors": "Mehdi B. Tahoori",
    "abstract": "Self-assembled nanofabrication processes yield regular and reconfigurable devices. However, defect densities in this emerging nanotechnology are higher than those in conventional lithography-based VLSI. In this article, we present an application-independent defect tolerant design flow to minimize customized postfabrication design efforts to be performed per chip. In this flow, higher level design steps are not needed to be aware of the existence and the location of defects in the chip. Only a final mapping step is required to be defect aware. Application independence of this flow minimizes the number of per-chip design steps, making it appropriate for high volume production. We also present two mapping algorithms, recursive and greedy, which make the connection between defect-unaware design steps and the final defect-aware mapping step. Experiments show that the results obtained by the greedy algorithm are very close to the exact solutions. Using these algorithms, we analyze the manufacturing yield of molecular crossbars under different defect distribution models. We report on the size of the minimum crossbar to be fabricated such that a defect-free crossbar of the desirable size can be found with a guaranteed manufacturing yield.",
    "cited_by_count": 65,
    "openalex_id": "https://openalex.org/W2054265145",
    "type": "article"
  },
  {
    "title": "HDLQ",
    "doi": "https://doi.org/10.1145/1216396.1216397",
    "publication_date": "2006-10-01",
    "publication_year": 2006,
    "authors": "Marco Ottavi; L. Schiano; Fabrizio Lombardi; Douglas Tougaw",
    "corresponding_authors": "",
    "abstract": "Emerging technologies have attracted a substantial interest in overcoming the physical limitations of CMOS as projected at the end of the Technology Roadmap; among these technologies, quantum-dot cellular automata (QCA) relies on different and novel paradigms to implement dense, low power circuits and systems for high-performance computing. As applicable to existing technologies, a hierarchical process can be utilized to facilitate the design of QCA circuits. Tools and methodologies both at system and physical levels are required to support all design phases. This article presents an HDL model to describe QCA “devices” (also referred elsewhere in the technical literature as building blocks, i.e., majority voter, inverter, wire, crossover) and facilitate the evaluation of their design. This tool, referred to as HDLQ, allows a designer to verify the logic characteristics of a QCA system, while supporting within a design environment different operational mechanisms (such as fault injection) and the unique features of QCA (such as bidirectionality and timing/clocking partitioning). The applicability of this design environment to various memory circuits for logic and timing verification is presented in detail. Various defective conditions for kinks due to thermodynamic effects and permanent faults due to manufacturing defects are considered for injection.",
    "cited_by_count": 63,
    "openalex_id": "https://openalex.org/W2025768701",
    "type": "article"
  },
  {
    "title": "Integrated droplet routing and defect tolerance in the synthesis of digital microfluidic biochips",
    "doi": "https://doi.org/10.1145/1389089.1389091",
    "publication_date": "2008-08-01",
    "publication_year": 2008,
    "authors": "Tao Xu; Krishnendu Chakrabarty",
    "corresponding_authors": "",
    "abstract": "Microfluidic biochips are revolutionizing high-throughput DNA sequencing, immunoassays, and clinical diagnostics. As high-throughput bioassays are mapped to digital microfluidic platforms, the need for design automation techniques is being increasingly felt. Moreover, as most applications of biochips are safety-critical in nature, defect tolerance is an essential system attribute. Several synthesis tools have recently been proposed for the automated design of biochips from the specifications of laboratory protocols. However, only a few of these tools address the problem of defect tolerance. In addition, most of these methods do not consider the problem of droplet routing in microfluidic arrays. These methods typically rely on postsynthesis droplet routing to implement biochemical protocols. Such an approach is not only time consuming, but also imposes an undue burden on the chip user. Postsynthesis droplet routing does not guarantee that feasible droplet pathways can be found for area-constrained biochip layouts; nonroutable fabricated biochips must be discarded. We present a synthesis tool that integrates defect tolerance and droplet routing in the design flow. Droplet routability, defined as the ease with which droplet pathways can be determined, is estimated and integrated in the synthesis procedure. Presynthesis and postsynthesis defect-tolerance methods are also presented. We use a large-scale protein assay as a case study to evaluate the proposed synthesis method.",
    "cited_by_count": 59,
    "openalex_id": "https://openalex.org/W2121993001",
    "type": "article"
  },
  {
    "title": "Arithmetic on a distributed-memory quantum multicomputer",
    "doi": "https://doi.org/10.1145/1324177.1324179",
    "publication_date": "2008-01-01",
    "publication_year": 2008,
    "authors": "Rodney Van Meter; William J. Munro; Kae Nemoto; Kohei M. Itoh",
    "corresponding_authors": "",
    "abstract": "We evaluate the performance of quantum arithmetic algorithms run on a distributed quantum computer (a quantum multicomputer). We vary the node capacity and I/O capabilities, and the network topology. The tradeoff of choosing between gates executed remotely, through “teleported gates” on entangled pairs of qubits (telegate), versus exchanging the relevant qubits via quantum teleportation, then executing the algorithm using local gates (teledata), is examined. We show that the teledata approach performs better, and that carry-ripple adders perform well when the teleportation block is decomposed so that the key quantum operations can be parallelized. A node size of only a few logical qubits performs adequately provided that the nodes have two transceiver qubits. A linear network topology performs acceptably for a broad range of system sizes and performance parameters. We therefore recommend pursuing small, high-I/O bandwidth nodes and a simple network. Such a machine will run Shor's algorithm for factoring large numbers efficiently.",
    "cited_by_count": 59,
    "openalex_id": "https://openalex.org/W3102886813",
    "type": "article"
  },
  {
    "title": "SpiNNaker",
    "doi": "https://doi.org/10.1145/2043643.2043647",
    "publication_date": "2011-12-01",
    "publication_year": 2011,
    "authors": "Luis A. Plana; David Clark; Simon Davidson; Steve Furber; Jim Garside; Eustace Painkras; Jeffrey Pepper; Steve Temple; John Bainbridge",
    "corresponding_authors": "",
    "abstract": "The design and implementation of globally asynchronous locally synchronous systems-on-chip is a challenging activity. The large size and complexity of the systems require the use of computer-aided design (CAD) tools but, unfortunately, most tools do not work adequately with asynchronous circuits. This article describes the successful design and implementation of SpiNNaker, a GALS multicore system-on-chip. The process was completed using commercial CAD tools from synthesis to layout. A hierarchical methodology was devised to deal with the asynchronous sections of the system, encapsulating and validating timing assumptions at each level. The crossbar topology combined with a pipelined asynchronous fabric implementation allows the on-chip network to meet the stringent requirements of the system. The implementation methodology constrains the design in a way that allows the tools to complete their tasks successfully. A first test chip, with reduced resources and complexity was taped-out using the proposed methodology. Test chips were received in December 2009 and were fully functional. The methodology had to be modified to cope with the increased complexity of the SpiNNaker SoC. SpiNNaker chips were delivered in May 2011 and were also fully operational, and the interconnect requirements were met.",
    "cited_by_count": 43,
    "openalex_id": "https://openalex.org/W2171471042",
    "type": "article"
  },
  {
    "title": "Novel Through-Silicon-Via Inductor-Based On-Chip DC-DC Converter Designs in 3D ICs",
    "doi": "https://doi.org/10.1145/2637481",
    "publication_date": "2014-11-18",
    "publication_year": 2014,
    "authors": "Umamaheswara Rao Tida; Cheng Zhuo; Yiyu Shi",
    "corresponding_authors": "",
    "abstract": "There has been a tremendous research effort in recent years to move DC-DC converters on chip for enhanced performance. However, a major limiting factor to implementing on-chip inductive DC-DC converters is the large area overhead induced by spiral inductors. Thus, we propose using through-silicon-vias (TSVs), a critical enabling technique in three-dimensional (3D) integrated systems, to implement on-chip inductors for DC-DC converters. While existing literature show that TSV inductors are inferior compared with conventional spiral inductors due to substrate loss for RF applications, in this article, we demonstrate that it is not the case for DC-DC converters, which operate at relatively low frequencies. Experimental results show that by replacing conventional spiral inductors with TSV inductors, with almost the same efficiency and output voltage, up to 4.3× and 3.2× inductor area reduction can be achieved for the single-phase buck converter and the interleaved buck converter with magnetic coupling, respectively.",
    "cited_by_count": 42,
    "openalex_id": "https://openalex.org/W1969483737",
    "type": "article"
  },
  {
    "title": "Early History and Challenges of Implantable Electronics",
    "doi": "https://doi.org/10.1145/2180878.2180880",
    "publication_date": "2012-06-01",
    "publication_year": 2012,
    "authors": "Wen H. Ko",
    "corresponding_authors": "Wen H. Ko",
    "abstract": "Implantable systems for biomedical research and clinical care are now a flourishing field of activities in academia as well as industrial institutions. The broad field includes experimental explorations in electronics, mechanical, chemical, and biological components and systems, and the combination of all these. Today virtually all implants involve both electronic circuits and micro-electro-mechanical-systems (MEMS). This article offers a very brief glance back at the early history of implant electronics in the period from the 1950s to the 1970s, by employing selected examples from the author's research. This short review also discusses the challenges of implantable electronics at present, and suggests some potentially important trends in the future research and development of implantable microsystems. It is aimed as an introduction of implantable/attached electronic systems to research engineers that are interested in implantable systems as a section of Biomedical Instrumentations.",
    "cited_by_count": 42,
    "openalex_id": "https://openalex.org/W2129748191",
    "type": "article"
  },
  {
    "title": "Iris",
    "doi": "https://doi.org/10.1145/1970406.1970410",
    "publication_date": "2011-06-01",
    "publication_year": 2011,
    "authors": "Zheng Li; Moustafa Mohamed; Xi Chen; Hong-Yu Zhou; Alan R. Mickelson; Li Shang; Manish Vachharajani",
    "corresponding_authors": "",
    "abstract": "On-chip communication, including short, often-multicast, latency-critical coherence and synchronization messages, and long, unicast, throughput-sensitive data transfers, limits the power efficiency and performance scalability of many-core chip-multiprocessor systems. This article analyzes on-chip communication challenges and studies the characteristics of existing electrical and emerging nanophotonic interconnect. Iris, a CMOS-compatible high-performance low-power nanophotonic on-chip network, is thus introduced. Iris's circuit-switched subnetwork supports throughput-sensitive data transfer. Iris's optical-antenna-array-based broadcast--multicast subnetwork optimizes latency-critical traffic and supports the path setup of circuit-switched communication. Overall, the proposed nanophotonic network design offers an on-chip communication backplane that is power efficient while demonstrating low latency and high throughput.",
    "cited_by_count": 41,
    "openalex_id": "https://openalex.org/W2025666719",
    "type": "article"
  },
  {
    "title": "SPARCNet",
    "doi": "https://doi.org/10.1145/3005448",
    "publication_date": "2017-05-12",
    "publication_year": 2017,
    "authors": "Adam Page; Ali Jafari; Colin Shea; Tinoosh Mohsenin",
    "corresponding_authors": "",
    "abstract": "Deep neural networks have been shown to outperform prior state-of-the-art solutions that often relied heavily on hand-engineered feature extraction techniques coupled with simple classification algorithms. In particular, deep convolutional neural networks have been shown to dominate on several popular public benchmarks such as the ImageNet database. Unfortunately, the benefits of deep networks have yet to be fully exploited in embedded, resource-bound settings that have strict power and area budgets. Graphical processing unit (GPU) have been shown to improve throughput and energy-efficiency over central processing unit (CPU) due to their highly parallel architecture yet still impose a significant power burden. In a similar fashion, field programmable gate array (FPGA) can be used to improve performance while further allowing more fine-grained control over implementation to improve efficiency. In order to reduce power and area while still achieving required throughput, classification-efficient network architectures are required in addition to optimal deployment on efficient hardware. In this work, we target both of these enterprises. For the first objective, we analyze simple, biologically inspired reduction strategies that are applied both before and after training. The central theme of the techniques is the introduction of sparsification to help dissolve away the dense connectivity that is often found at different levels in convolutional neural networks. The sparsification techniques include feature compression partition , structured filter pruning , and dynamic feature pruning . Additionally, we explore filter factorization and filter quantization approximation techniques to further reduce the complexity of convolutional layers. In the second contribution, we propose SPARCNet, a hardware accelerator for efficient deployment of SPAR se C onvolutional NET works. The accelerator looks to enable deploying networks in such resource-bound settings by both exploiting efficient forms of parallelism inherent in convolutional layers and by exploiting the sparsification and approximation techniques proposed. To demonstrate both contributions, modern deep convolutional network architectures containing millions of parameters are explored within the context of the computer vision dataset CIFAR. Utilizing the reduction techniques, we demonstrate the ability to reduce computation and memory by 60% and 93% with less than 0.03% impact on accuracy when compared to the best baseline network with 93.47% accuracy. The SPARCNet accelerator with different numbers of processing engines is implemented on a low-power Artix-7 FPGA platform. Additionally, the same networks are optimally implemented on a number of embedded commercial-off-the-shelf platforms including NVIDIAs CPU+GPU SoCs TK1 and TX1 and Intel Edison. Compared to NVIDIAs TK1 and TX1, the FPGA-based accelerator obtains 11.8 × and 7.5 × improvement in energy efficiency while maintaining a classification throughput of 72 images/s. When further compared to a number of recent FPGA-based accelerators, SPARCNet is able to achieve up to 15 × improvement in energy efficiency while consuming less than 2W of total board power at 100MHz. In addition to improving efficiency, the accelerator has built-in support for sparsification techniques and ability to perform in-place rectified linear unit (ReLU) activation function, max-pooling, and batch normalization.",
    "cited_by_count": 39,
    "openalex_id": "https://openalex.org/W2614143469",
    "type": "article"
  },
  {
    "title": "Survey of STT-MRAM Cell Design Strategies",
    "doi": "https://doi.org/10.1145/2997650",
    "publication_date": "2017-04-20",
    "publication_year": 2017,
    "authors": "Soheil Salehi; Deliang Fan; Ronald F. DeMara",
    "corresponding_authors": "",
    "abstract": "Spin-Transfer Torque Random Access Memory (STT-MRAM) has been explored as a post-CMOS technology for embedded and data storage applications seeking non-volatility, near-zero standby energy, and high density. Towards attaining these objectives for practical implementations, various techniques to mitigate the specific reliability challenges associated with STT-MRAM elements are surveyed, classified, and assessed in this article. Cost and suitability metrics assessed include the area of nanomagmetic and CMOS components per bit, access time and complexity, sense margin, and energy or power consumption costs versus resiliency benefits. Solutions to the reliability issues identified are addressed within a taxonomy created to categorize the current and future approaches to reliable STT-MRAM designs. A variety of destructive and non-destructive sensing schemes are assessed for process variation tolerance, read disturbance reduction, sense margin, and write polarization asymmetry compensation. The highest resiliency strategies deliver a sensing margin above 300mV while incurring low power and energy consumption on the order of picojoules and microwatts, respectively, and attaining read sense latency of a few nanoseconds down to hundreds of picoseconds for non-destructive and destructive sensing schemes, respectively.",
    "cited_by_count": 38,
    "openalex_id": "https://openalex.org/W2607489744",
    "type": "article"
  },
  {
    "title": "STDP-based Unsupervised Feature Learning using Convolution-over-time in Spiking Neural Networks for Energy-Efficient Neuromorphic Computing",
    "doi": "https://doi.org/10.1145/3266229",
    "publication_date": "2018-10-31",
    "publication_year": 2018,
    "authors": "Gopalakrishnan Srinivasan; Priyadarshini Panda; Kaushik Roy",
    "corresponding_authors": "",
    "abstract": "Brain-inspired learning models attempt to mimic the computations performed in the neurons and synapses constituting the human brain to achieve its efficiency in cognitive tasks. In this work, we propose Spike Timing Dependent Plasticity-based unsupervised feature learning using convolution-over-time in Spiking Neural Network (SNN). We use shared weight kernels that are convolved with the input patterns over time to encode representative input features, thereby improving the sparsity as well as the robustness of the learning model. We show that the Convolutional SNN self-learns several visual categories for object recognition with limited number of training patterns while yielding comparable classification accuracy relative to the fully connected SNN. Further, we quantify the energy benefits of the Convolutional SNN over fully connected SNN on neuromorphic hardware implementation.",
    "cited_by_count": 38,
    "openalex_id": "https://openalex.org/W2903271863",
    "type": "article"
  },
  {
    "title": "Job completion time on a virtualized server with software rejuvenation",
    "doi": "https://doi.org/10.1145/2539121",
    "publication_date": "2014-01-01",
    "publication_year": 2014,
    "authors": "Fumio Machida; Victor F. Nicola; Kishor S. Trivedi",
    "corresponding_authors": "",
    "abstract": "This article analyzes the completion time of a job running on a virtualized server subject to software aging and rejuvenation in a virtual machine monitor (VMM). A job running on the server may be interrupted by virtual machine (VM) failure, VMM failure or VMM rejuvenation. The job interruption is categorized as either preemptive-repeat ( prt ), in which case the interrupted job needs to restart from the beginning, or preemptive-resume ( prs ), in which case the job resumes execution from the point of interruption. Using a semi-Markov process (SMP) to model the server behavior, the steady-state server availability is computed and the theory developed in Kulkarni et al. [1987] is used to obtain the Laplace-Stieltjes transform (LST) of the job completion time. In the numerical experiments, we introduce four types of aging behavior of VMM. The effectiveness of VMM rejuvenation on job completion time is discussed in association with the type of interruption it causes and the VMM aging type. With our parameter settings, VMM rejuvenation with prs job interruption improves the performance of job execution regardless of the aging type, with performance degradation is taken into account.",
    "cited_by_count": 37,
    "openalex_id": "https://openalex.org/W2021377858",
    "type": "article"
  },
  {
    "title": "SWIFTNoC",
    "doi": "https://doi.org/10.1145/3060517",
    "publication_date": "2017-06-29",
    "publication_year": 2017,
    "authors": "Sai Vineel Reddy Chittamuru; Srinivas Desai; Sudeep Pasricha",
    "corresponding_authors": "",
    "abstract": "On-chip communication is widely considered to be one of the major performance bottlenecks in contemporary chip multiprocessors (CMPs). With recent advances in silicon nanophotonics, photonics-based network-on-chip (NoC) architectures are being considered as a viable solution to support communication in future CMPs as they can enable higher bandwidth and lower power dissipation compared to traditional electrical NoCs. In this article, we present SwiftNoC , a novel reconfigurable silicon-photonic NoC architecture that features improved multicast-enabled channel sharing, as well as dynamic re-prioritization and exchange of bandwidth between clusters of cores running multiple applications, to increase channel utilization and system performance. Experimental results show that SwiftNoC improves throughput by up to 25.4× while reducing latency by up to 72.4% and energy-per-bit by up to 95% over state-of-the-art solutions.",
    "cited_by_count": 37,
    "openalex_id": "https://openalex.org/W2725254221",
    "type": "article"
  },
  {
    "title": "Impact of Electrostatic Coupling and Wafer-Bonding Defects on Delay Testing of Monolithic 3D Integrated Circuits",
    "doi": "https://doi.org/10.1145/3041026",
    "publication_date": "2017-07-11",
    "publication_year": 2017,
    "authors": "Abhishek Koneru; Sukeshwar Kannan; Krishnendu Chakrabarty",
    "corresponding_authors": "",
    "abstract": "Monolithic three-dimensional (M3D) integration is gaining momentum, as it has the potential to achieve significantly higher device density compared to 3D integration based on through-silicon vias. M3D integration uses several techniques that are not used in the fabrication of conventional integrated circuits (ICs). Therefore, a detailed analysis of the M3D fabrication process is required to understand the impact of defects that are likely to occur during chip fabrication. In this article, we first analyze electrostatic coupling in M3D ICs, which arises due to the aggressive scaling of the interlayer dielectric (ILD) thickness. We then analyze defects that arise due to voids created during wafer bonding, a key step in most M3D fabrication processes. We quantify the impact of these defects on the threshold voltage of a top-layer transistor in an M3D IC. We also show that wafer-bonding defects can lead to a change in the resistance of interlayer vias (ILVs), and in some cases lead to an open in an ILV or a short between two ILVs. We then analyze the impact of these defects on path delays using HSpice simulations. We study their impact on the effectiveness of delay-test patterns for multiple instances of IWLS 2005 benchmarks in which these defects were randomly injected. Our results show that the timing characteristics of an M3D IC can be significantly altered due to coupling and wafer-bonding defects if the thickness of its ILD is less than 100nm. Therefore, for such M3D ICs, test-generation methods must be enhanced to take M3D fabrication defects into account.",
    "cited_by_count": 37,
    "openalex_id": "https://openalex.org/W2735555835",
    "type": "article"
  },
  {
    "title": "A Survey of Techniques for Architecting Processor Components Using Domain-Wall Memory",
    "doi": "https://doi.org/10.1145/2994550",
    "publication_date": "2016-11-03",
    "publication_year": 2016,
    "authors": "Sparsh Mittal",
    "corresponding_authors": "Sparsh Mittal",
    "abstract": "Recent trends of increasing core-count and bandwidth/memory wall have motivated researchers to explore novel memory technologies for designing processor components such as cache, register file, shared memory, and so on. Domain-wall memory (DWM), also known as racetrack memory, is a promising emerging technology due to its non-volatility and very high density. However, use of DWM presents challenges due to characteristics of both DWM itself (e.g., requirement of shift operations, variable latency) and processor components. Recently, several techniques have been proposed to address these challenges. This article presents a survey of architectural techniques for using DWM for designing components in both CPU and GPU. We discuss techniques related to performance, energy, and reliability and also discuss works that compare DWM with other memory technologies. We also highlight the opportunities and obstacles in using DWM for designing processor components. This survey is expected to spark further research in this area and be useful for researchers, chip designers, and computer architects.",
    "cited_by_count": 36,
    "openalex_id": "https://openalex.org/W2517842268",
    "type": "article"
  },
  {
    "title": "Comprehensive Analytic Performance Assessment and K-means based Multicast Routing Algorithm and Architecture for 3D-NoC of Spiking Neurons",
    "doi": "https://doi.org/10.1145/3340963",
    "publication_date": "2019-10-03",
    "publication_year": 2019,
    "authors": "Huy-The Vu; Yuichi Okuyama; Abderazek Ben Abdallah",
    "corresponding_authors": "",
    "abstract": "Spiking neural networks (SNNs) are artificial neural network models that more closely mimic biological neural networks. In addition to neuronal and synaptic state, SNNs incorporate the variant time scale into their computational model. Since each neuron in these networks is connected to thousands of others, high bandwidth is required. Moreover, since the spike times are used to encode information in SNN, very low communication latency is also needed. The 2D-NoC was used as a solution to provide a scalable interconnection fabric in large-scale parallel SNN systems. The 3D-ICs have also attracted a lot of attention as a potential solution to resolve the interconnect bottleneck. The combination of these two emerging technologies provides a new horizon for IC designs to satisfy the high requirements of low power and small footprint in emerging AI applications. In this work, we first present a comprehensive analytical model to analyze the performance of 3D mesh NoC over variants of different SNN topologies and communications protocols. Second, we present an architecture and a low-latency spike routing algorithm, named shortest path K-means based multicast (SP-KMCR), for three-dimensional NoC of spiking neurons (3DNoC-SNN). The proposed system was validated based on an RTL-level implementation, while area/power analysis was performed using 45nm CMOS technology.",
    "cited_by_count": 34,
    "openalex_id": "https://openalex.org/W2977621362",
    "type": "article"
  },
  {
    "title": "Toward Multi-FPGA Acceleration of the Neural Networks",
    "doi": "https://doi.org/10.1145/3432816",
    "publication_date": "2021-04-29",
    "publication_year": 2021,
    "authors": "Saman Biookaghazadeh; Pravin Kumar Ravi; Ming Zhao",
    "corresponding_authors": "",
    "abstract": "High-throughput and low-latency Convolutional Neural Network (CNN) inference is increasingly important for many cloud- and edge-computing applications. FPGA-based acceleration of CNN inference has demonstrated various benefits compared to other high-performance devices such as GPGPUs. Current FPGA CNN-acceleration solutions are based on a single FPGA design, which are limited by the available resources on an FPGA. In addition, they can only accelerate conventional 2D neural networks. To address these limitations, we present a generic multi-FPGA solution, written in OpenCL, which can accelerate more complex CNNs (e.g., C3D CNN) and achieve a near linear speedup with respect to the available single-FPGA solutions. The design is built upon the Intel Deep Learning Accelerator architecture, with three extensions. First, it includes updates for better area efficiency (up to 25%) and higher performance (up to 24%). Second, it supports 3D convolutions for more challenging applications such as video learning. Third, it supports multi-FPGA communication for higher inference throughput. The results show that utilizing multiple FPGAs can linearly increase the overall bandwidth while maintaining the same end-to-end latency. In addition, the design can outperform other FPGA 2D accelerators by up to 8.4 times and 3D accelerators by up to 1.7 times.",
    "cited_by_count": 27,
    "openalex_id": "https://openalex.org/W3159273459",
    "type": "article"
  },
  {
    "title": "A Review and Comparison of AI-enhanced Side Channel Analysis",
    "doi": "https://doi.org/10.1145/3517810",
    "publication_date": "2022-03-23",
    "publication_year": 2022,
    "authors": "Max Panoff; Honggang Yu; Haoqi Shan; Yier Jin",
    "corresponding_authors": "",
    "abstract": "Side Channel Analysis (SCA) presents a clear threat to privacy and security in modern computing systems. The vast majority of communications are secured through cryptographic algorithms. These algorithms are often provably-secure from a cryptographical perspective, but their implementation on real hardware introduces vulnerabilities. Adversaries can exploit these vulnerabilities to conduct SCA and recover confidential information, such as secret keys or internal states. The threat of SCA has greatly increased as machine learning, and in particular deep learning, enhanced attacks become more common. In this work, we will examine the latest state-of-the-art deep learning techniques for side channel analysis, the theory behind them, and how they are conducted. Our focus will be on profiling attacks using deep learning techniques, but we will also examine some new and emerging methodologies enhanced by deep learning techniques, such as non-profiled attacks, artificial trace generation, and others. Finally, different deep learning enhanced SCA schemes attempted against the ANSSI SCA Database (ASCAD) and their relative performance will be evaluated and compared. This will lead to new research directions to secure cryptographic implementations against the latest SCA attacks.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W4220818465",
    "type": "review"
  },
  {
    "title": "Hardware Trojan Detection Potential and Limits with the Quantum Diamond Microscope",
    "doi": "https://doi.org/10.1145/3711712",
    "publication_date": "2025-01-08",
    "publication_year": 2025,
    "authors": "Jacob N. Lenz; Scott K. Perryman; Dmitro Martynowych; David A. Hopper; Sean M. Oliver",
    "corresponding_authors": "",
    "abstract": "The Quantum Diamond Microscope (QDM) is an instrument with a demonstrated capability to image electrical current in integrated circuits (ICs), which shows promise for detection of hardware Trojans. The anomalous current activity caused by hardware Trojans manifests through a magnetic field side channel that can be imaged with the QDM, potentially allowing for detection and localization of the effects of tampering. This paper seeks to identify the capabilities of the QDM for hardware Trojan detection through the analysis of previous QDM work as well as QDM physical limits and potential Trojan behaviors. QDM metrics of interest are identified, such as spatial resolution, sensitivity, time-to-result, and field-of-view. Rare event detection on an FPGA is demonstrated with the QDM. The concept of operations is identified for QDM utilization at different steps of IC development, noting necessary considerations and limiting factors for use at different development stages. Finally, the effects of hardware Trojans on IC current activity are estimated and compared to QDM sensitivities to project QDM detection potential for ICs of varying process sizes.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4406175873",
    "type": "article"
  },
  {
    "title": "SHIFT: Selective Hardware Information Flow Tracking Driven by Deterministic Constraints",
    "doi": "https://doi.org/10.1145/3765906",
    "publication_date": "2025-09-05",
    "publication_year": 2025,
    "authors": "Haodong Sun; Zhi Yang; Shuyuan Jin; Z. Zhang",
    "corresponding_authors": "",
    "abstract": "Information flow tracking technology is commonly used in the security analysis of hardware design. This technology protects the confidentiality and integrity of essential assets by instrumenting trace logic on each operation unit to detect whether critical information has been leaked or tampered with. However, as hardware design becomes increasingly large-scale and complex, the significant performance overhead introduced by instrumentation has become a major challenge. This paper proposes SHIFT (Selective Hardware Information Flow Tracking), a constraint-driven optimization technique. The core idea of SHIFT includes selective monitoring of operations and selective optimization of propagation logic. In the intermediate representation of the hardware design, SHIFT scans taint sources in the code statically using a conservative analysis algorithm to determine whether logic structures require monitoring and assigns optimization tags based on known conditions. During the synthesis process, these optimization tags are passed to the netlist, thereby enabling selective instrumentation of the trace logic on the cell. In the Trust-Hub AES test bench, SHIFT reduces the deployment time of the tracking model by 12.1%, decreases the number of cells by 19.9%, and reduces the synthesized area by 35.7%, Additionally, the security verification time of the flow model was reduced by 10.5%. In general, SHIFT reduces the overhead of deploying trace logic without introducing false positives.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4414149293",
    "type": "article"
  },
  {
    "title": "Design automation for microfluidics-based biochips",
    "doi": "https://doi.org/10.1145/1116696.1116698",
    "publication_date": "2005-10-01",
    "publication_year": 2005,
    "authors": "Krishnendu Chakrabarty; Jun Zeng",
    "corresponding_authors": "",
    "abstract": "Advances in microfluidics technology offer exciting possibilities in the realm of enzymatic analysis, DNA analysis, proteomic analysis involving proteins and peptides, immunoassays, implantable drug delivery devices, and environmental toxicity monitoring. Microfluidics-based biochips are therefore gaining popularity for clinical diagnostics and other laboratory procedures involving molecular biology. As more bioassays are executed concurrently on a biochip, system integration and design complexity are expected to increase dramatically. This paper presents different actuation mechanisms for microfluidics-based biochips, as well as associated design automation trends and challenges. The underlying physical principles of eletrokinetics, electrohydrodynamics, and thermo-capillarity are discussed. Next, the paper presents an overview of an integrated system-level design methodology that attempts to address key issues in the modeling, simulation, synthesis, testing and reconfiguration of digital microfluidics-based biochips. The top-down design automation will facilitate the integration of fluidic components with microelectronic component in next-generation system-on-chip designs.",
    "cited_by_count": 52,
    "openalex_id": "https://openalex.org/W1998641515",
    "type": "article"
  },
  {
    "title": "Parametric yield management for 3D ICs",
    "doi": "https://doi.org/10.1145/1412587.1412592",
    "publication_date": "2008-10-01",
    "publication_year": 2008,
    "authors": "Cesare Ferri; Sherief Reda; R. Iris Bahar",
    "corresponding_authors": "",
    "abstract": "Three-Dimensional (3D) Integrated Circuits (ICs) that integrate die with Through-Silicon Vias (TSVs) promise to continue system and functionality scaling beyond the traditional geometric 2D device scaling. 3D integration also improves the performance of ICs by reducing the communication time between different chip components through the use of short TSV-based vertical wires. This reduction is particularly attractive in processors where it is desirable to reduce the access time between the main logic die and the L2 cache or the main memory die. Process variations in 2D ICs lead to a drop in parametric yield (as measured by speed, leakage and sales profits), which forces manufacturers to speed bin their chips and to sell slow chips at reduced prices. In this paper we develop a model to quantify the impact of process variations on the parametric yield of 3D ICs, and then we propose a number of integration strategies that use a graph-theoretic framework to maximize the performance, parametric yield and profits of 3D ICs. Comparing our proposed strategies to current yield-oblivious methods, it is demonstrated that it is possible to increase the number of 3D ICs in the fastest speed bins by almost 2×, while simultaneously reducing the number of slow ICs by 29.4%. This leads to an improvement in performance by up to 6.45% and an increase of about 12.48% in total sales revenue using up-to-date market price models.",
    "cited_by_count": 47,
    "openalex_id": "https://openalex.org/W2169892331",
    "type": "article"
  },
  {
    "title": "Brownian Circuits",
    "doi": "https://doi.org/10.1145/2422094.2422097",
    "publication_date": "2013-02-01",
    "publication_year": 2013,
    "authors": "Ferdinand Peper; Jia Lee; Josep Carmona; Jordi Cortadella; Kenichi Morita",
    "corresponding_authors": "",
    "abstract": "Random fluctuations will be a major factor interfering with the operation of nanometer scale electronic devices. This article presents circuit architectures that can exploit such fluctuations, if signals have a particle-like (discrete, token-based) character. We define an abstract circuit primitive that, though lacking functionality when used with fluctuation-free signals, becomes universal when fluctuations are allowed. Key to the power of a signal’s fluctuations is the ability to explore the state space of a circuit. This ability is used to resolve deadlock situations, which could otherwise only be averted by increased design complexity. The results in this article suggest that in the design of future computers, signal fluctuations, rather than being an impediment to be avoided at any cost, may be an important ingredient to achieve efficient operation.",
    "cited_by_count": 37,
    "openalex_id": "https://openalex.org/W2071685311",
    "type": "article"
  },
  {
    "title": "Redundant Residue Number System Code for Fault-Tolerant Hybrid Memories",
    "doi": "https://doi.org/10.1145/1899390.1899394",
    "publication_date": "2011-01-01",
    "publication_year": 2011,
    "authors": "Nor Zaidi Haron; Said Hamdioui",
    "corresponding_authors": "",
    "abstract": "Hybrid memories are envisioned as one of the alternatives to existing semiconductor memories. Although offering enormous data storage capacity, low power consumption, and reduced fabrication complexity (at least for the memory cell array), such memories are subject to a high degree of intermittent and transient faults leading to reliability issues. This article examines the use of Conventional Redundant Residue Number System (C-RRNS) error correction code, which has been extensively used in digital signal processing and communication, to detect and correct intermittent and transient cluster faults in hybrid memories. It introduces a modified version of C-RRNS, referred to as 6M-RRNS, to realize the aims at lower area overhead and performance penalty. The experimental results show that 6M-RRNS realizes a competitive error correction capability, provides larger data storage capacity, and offers higher decoding performance as compared to C-RRNS and Reed-Solomon (RS) codes. For instance, for 64-bit hybrid memories at 10% fault rate, 6M-RRNS has 98.95% error correction capability, which is 0.35% better than RS and 0.40% less than C-RRNS. Moreover, when considering 1Tbit memory, 6M-RRNS offers 4.35% more data storage capacity than RS and 11.41% more than C-RRNS. Additionally, it decodes up to 5.25 times faster than C-RRNS.",
    "cited_by_count": 37,
    "openalex_id": "https://openalex.org/W2076490805",
    "type": "article"
  },
  {
    "title": "Improving Energy Efficiency in Wireless Network-on-Chip Architectures",
    "doi": "https://doi.org/10.1145/3138807",
    "publication_date": "2017-11-03",
    "publication_year": 2017,
    "authors": "Vincenzo Catania; Andrea Mineo; Salvatore Monteleone; Maurizio Palesi; Davide Patti",
    "corresponding_authors": "",
    "abstract": "Wireless Network-on-Chip (WiNoC) represents a promising emerging communication technology for addressing the scalability limitations of future manycore architectures. In a WiNoC, high-latency and power-hungry long-range multi-hop communications can be realized by performance- and energy-efficient single-hop wireless communications. However, the energy contribution of such wireless communication accounts for a significant fraction of the overall communication energy budget. This article presents a novel energy managing technique for WiNoC architectures aimed at improving the energy efficiency of the main elements of the wireless infrastructure, namely, radio-hubs. The rationale behind the proposed technique is based on selectively turning off, for the appropriate number of cycles, all the radio-hubs that are not involved in the current wireless communication. The proposed energy managing technique is assessed on several network configurations under different traffic scenarios both synthetic and extracted from the execution of real applications. The obtained results show that the application of the proposed technique allows up to 25% total communication energy saving without any impact on performance and with a negligible impact on the silicon area of the radio-hub.",
    "cited_by_count": 34,
    "openalex_id": "https://openalex.org/W2766667538",
    "type": "article"
  },
  {
    "title": "A Θ( √ n)-depth quantum adder on the 2D NTC quantum computer architecture",
    "doi": "https://doi.org/10.1145/2287696.2287707",
    "publication_date": "2012-08-01",
    "publication_year": 2012,
    "authors": "Byung-Soo Choi; Rodney Van Meter",
    "corresponding_authors": "",
    "abstract": "In this work, we propose an adder for the 2D NTC architecture, designed to match the architectural constraints of many quantum computing technologies. The chosen architecture allows the layout of logical qubits in two dimensions and the concurrent execution of one- and two-qubit gates with nearest-neighbor interaction only. The proposed adder works in three phases. In the first phase, the first column generates the summation output and the other columns do the carry-lookahead operations. In the second phase, these intermediate values are propagated from column to column, preparing for computation of the final carry for each register position. In the last phase, each column, except the first one, generates the summation output using this column-level carry. The depth and the number of qubits of the proposed adder are $\\Theta(\\sqrt{n})$ and O(n), respectively. The proposed adder executes faster than the adders designed for the 1D NTC architecture when the length of the input registers $n$ is larger than 58.",
    "cited_by_count": 33,
    "openalex_id": "https://openalex.org/W2588675857",
    "type": "article"
  },
  {
    "title": "QLib",
    "doi": "https://doi.org/10.1145/2629430",
    "publication_date": "2014-10-06",
    "publication_year": 2014,
    "authors": "Chia-Chun Lin; Amlan Chakrabarti; Niraj K. Jha",
    "corresponding_authors": "",
    "abstract": "Quantum algorithms are known for their ability to solve some problems much faster than classical algorithms. They are executed on quantum circuits, which consist of a cascade of quantum gates. However, synthesis of quantum circuits is not straightforward because of the complexity of quantum algorithms. Generally, quantum algorithms contain two parts: classical and quantum. Thus, synthesizing circuits for the two parts separately reduces overall synthesis complexity. In addition, many quantum algorithms use similar subroutines that can be implemented with similar circuit modules. Because of their frequent use, it is important to use automated scripts to generate such modules efficiently. These modules can then be subjected to further synthesis optimizations. This article proposes QLib, a quantum module library, which contains scripts to generate quantum modules of different sizes and specifications for well-known quantum algorithms. Thus, QLib can also serve as a suite of benchmarks for quantum logic and physical synthesis.",
    "cited_by_count": 32,
    "openalex_id": "https://openalex.org/W2007239487",
    "type": "article"
  },
  {
    "title": "Designing a Million-Qubit Quantum Computer Using a Resource Performance Simulator",
    "doi": "https://doi.org/10.1145/2830570",
    "publication_date": "2015-12-28",
    "publication_year": 2015,
    "authors": "Muhammad Ahsan; Rodney Van Meter; Jungsang Kim",
    "corresponding_authors": "",
    "abstract": "The optimal design of a fault-tolerant quantum computer involves finding an appropriate balance between the burden of large-scale integration of noisy components and the load of improving the reliability of hardware technology. This balance can be evaluated by quantitatively modeling the execution of quantum logic operations on a realistic quantum hardware containing limited computational resources. In this work, we report a complete performance simulation software tool capable of (1) searching the hardware design space by varying resource architecture and technology parameters, (2) synthesizing and scheduling fault-tolerant quantum algorithm within the hardware constraints, (3) quantifying the performance metrics such as the execution time and the failure probability of the algorithm, and (4) analyzing the breakdown of these metrics to highlight the performance bottlenecks and visualizing resource utilization to evaluate the adequacy of the chosen design. Using this tool we investigate a vast design space for implementing key building blocks of Shor's algorithm to factor a 1,024-bit number with a baseline budget of 1.5 million qubits. We show that a trapped-ion quantum computer designed with twice as many qubits and one-tenth of the baseline infidelity of the communication channel can factor a 2,048-bit integer in less than five months.",
    "cited_by_count": 32,
    "openalex_id": "https://openalex.org/W2206173907",
    "type": "article"
  },
  {
    "title": "Robust learning approach for neuro-inspired nanoscale crossbar architecture",
    "doi": "https://doi.org/10.1145/2539123",
    "publication_date": "2014-01-01",
    "publication_year": 2014,
    "authors": "Djaafar Chabi; Damien Querlioz; Weisheng Zhao; Jacques‐Olivier Klein",
    "corresponding_authors": "",
    "abstract": "Scaling beyond CMOS require a new combination of computing paradigm and new devices. In this context, memristor are often considered as best candidate to implement efficiently synapses in hardware neural networks. In this article, we analyze the impact of memristor parameter variability. We build an analytical model of the global reliability at the crossbar level. It is based on a supervised learning method with multilayer and redundancy extensions. Comparisons with Monte Carlo simulations of small neural network validate our analytical model. It can be used to extrapolate directly the reliability of large-scale neural system. Our extrapolations show that high defect rate and important parameter variability can be handle efficiency with a moderate amount of redundancy.",
    "cited_by_count": 31,
    "openalex_id": "https://openalex.org/W2081390428",
    "type": "article"
  },
  {
    "title": "Deep Neural Network Optimized to Resistive Memory with Nonlinear Current-Voltage Characteristics",
    "doi": "https://doi.org/10.1145/3145478",
    "publication_date": "2018-04-30",
    "publication_year": 2018,
    "authors": "Hyungjun Kim; Taesu Kim; Jin-Seok Kim; Jae‐Joon Kim",
    "corresponding_authors": "",
    "abstract": "Artificial Neural Network computation relies on intensive vector-matrix multiplications. Recently, the emerging nonvolatile memory (NVM) crossbar array showed a feasibility of implementing such operations with high energy efficiency. Thus, there have been many works on efficiently utilizing emerging NVM crossbar arrays as analog vector-matrix multipliers. However, nonlinear I-V characteristics of NVM restrain critical design parameters, such as the read voltage and weight range, resulting in substantial accuracy loss. In this article, instead of optimizing hardware parameters to a given neural network, we propose a methodology of reconstructing the neural network itself to be optimized to resistive memory crossbar arrays. To verify the validity of the proposed method, we simulated various neural networks with MNIST and CIFAR-10 dataset using two different Resistive Random Access Memory models. Simulation results show that our proposed neural network produces inference accuracies significantly higher than conventional neural network when the network is mapped to synapse devices with nonlinear I-V characteristics.",
    "cited_by_count": 31,
    "openalex_id": "https://openalex.org/W2605257365",
    "type": "article"
  },
  {
    "title": "T-count and Qubit Optimized Quantum Circuit Design of the Non-Restoring Square Root Algorithm",
    "doi": "https://doi.org/10.1145/3264816",
    "publication_date": "2018-07-31",
    "publication_year": 2018,
    "authors": "Edgard Muñoz‐Coreas; Himanshu Thapliyal",
    "corresponding_authors": "",
    "abstract": "Quantum circuits for basic mathematical functions such as the square root are required to implement scientific computing algorithms on quantum computers. Quantum circuits that are based on Clifford+T gates can easily be made fault tolerant, but the T gate is very costly to implement. As a result, reducing T-count has become an important optimization goal. Further, quantum circuits with many qubits are difficult to realize, making designs that save qubits and produce no garbage outputs desirable. In this work, we present a T-count optimized quantum square root circuit with only 2 ṡ n + 1 qubits and no garbage output. To make a fair comparison against existing work, the Bennett’s garbage removal scheme is used to remove garbage output from existing works. We determined that our proposed design achieves an average T-count savings of 43.44%, 98.95%, 41.06%, and 20.28% as well as qubit savings of 85.46%, 95.16%, 90.59%, and 86.77% compared to existing works.",
    "cited_by_count": 31,
    "openalex_id": "https://openalex.org/W2964317419",
    "type": "article"
  },
  {
    "title": "Comparative Area and Parasitics Analysis in FinFET and Heterojunction Vertical TFET Standard Cells",
    "doi": "https://doi.org/10.1145/2914790",
    "publication_date": "2016-05-25",
    "publication_year": 2016,
    "authors": "Moon Seok Kim; William Cane-Wissing; Xueqing Li; Jack Sampson; Suman Datta; Sumeet Kumar Gupta; Vijaykrishnan Narayanan",
    "corresponding_authors": "",
    "abstract": "Vertical tunnel field-effect transistors (VTFETs) have been extensively explored to overcome the scaling limits and to improve on-current ( I ON ) compared to standard lateral device structures for the future technologies. The benefits in terms of reduced footprint, high I ON and feasibility of fabrication have been demonstrated in several works. Among various VTFETs, the asymmetric heterojunction vertical tunnel FETs (HVTFETs) have emerged as one of the promising alternatives to standard transistors for low-voltage applications. However, while such device-level benefits without parasitics have been widely investigated, logic-gate design with parasitics and layout implications are not clear. In this article, we investigate and compare the layouts and parasitic capacitances and resistances of HVTFETs with FinFETs. Due to the vertical device structure of HVTFETs, a smaller footprint is observed compared to FinFETs in cells with small fan-in. However, for high fan-in cells, HVTFETs exhibit area overheads due to infeasibility of contact sharing in parallel and series transistors. These area overheads also lead to approximately 48% higher parasitic capacitance and resistance compared to FinFETs when the number of parallel and series connections increases. Further, in order to analyze the impact of parasitics, we modeled the analytical parasitics in SPICE. The models for both HVTFETs and FinFETs with parasitics were used to simulate a 15-stage inverter-based ring oscillator (RO) in order to compare the delay and energy. Our simulation results clearly show that HVTFETs exhibit less delay at a V DD &lt; 0.45 V and higher energy efficiency for V DDs in the range of 0.3V--0.7V, albeit at the cost of 8% performance degradation.",
    "cited_by_count": 30,
    "openalex_id": "https://openalex.org/W2396174493",
    "type": "article"
  },
  {
    "title": "Advanced Simulation of Droplet Microfluidics",
    "doi": "https://doi.org/10.1145/3313867",
    "publication_date": "2019-04-25",
    "publication_year": 2019,
    "authors": "Andreas Grimmer; Medina Hamidović; Werner Haselmayr; Robert Wille",
    "corresponding_authors": "",
    "abstract": "The complexity of droplet microfluidics grows with the implementation of parallel processes and multiple functionalities on a single device. This poses a severe challenge to the engineer designing the corresponding microfluidic networks. In today’s design processes, the engineer relies on calculations, assumptions, simplifications, as well as his/her experiences and intuitions. To validate the obtained specification of the microfluidic network, usually a prototype is fabricated and physical experiments are conducted thus far. In case the design does not implement the desired functionality, this prototyping iteration is repeated—obviously resulting in an expensive and time-consuming design process. To avoid unnecessary debugging loops involving fabrication and testing, simulation methods could help to initially validate the specification of the microfluidic network before any prototype is fabricated. However, state-of-the-art simulation tools come with severe limitations, which prevent their utilization for practically relevant applications. More precisely, they are often not dedicated to droplet microfluidics, cannot handle the required physical phenomena, are not publicly available, and can hardly be extended. In this work, we present an advanced simulation approach for droplet microfluidics that addresses these shortcomings and, eventually, allows simulating practically relevant applications. To this end, we propose a simulation framework at the one-dimensional analysis model, which directly works on the specification of the design, supports essential physical phenomena, is publicly available, and is easy to extend. Evaluations and case studies demonstrate the benefits of the proposed simulator: While current state-of-the-art tools were not applicable for practically relevant microfluidic networks, the proposed simulator allows reducing the design time and costs, e.g., of a drug screening device from one person month and USD 1200, respectively, to just a fraction of that.",
    "cited_by_count": 30,
    "openalex_id": "https://openalex.org/W2963444032",
    "type": "article"
  },
  {
    "title": "EM-X-DL: Efficient Cross-device Deep Learning Side-channel Attack With Noisy EM Signatures",
    "doi": "https://doi.org/10.1145/3465380",
    "publication_date": "2021-09-29",
    "publication_year": 2021,
    "authors": "Josef Danial; Debayan Das; Anupam Golder; Santosh Ghosh; Arijit Raychowdhury; Shreyas Sen",
    "corresponding_authors": "",
    "abstract": "This work presents a Cross-device Deep-Learning based Electromagnetic (EM-X-DL) side-channel analysis (SCA) on AES-128, in the presence of a significantly lower signal-to-noise ratio (SNR) compared to previous works. Using a novel algorithm to intelligently select multiple training devices and proper choice of hyperparameters, the proposed 256-class deep neural network (DNN) can be trained efficiently utilizing pre-processing techniques like PCA, LDA, and FFT on measurements from the target encryption engine running on an 8-bit Atmel microcontroller. In this way, EM-X-DL achieves &gt;90% single-trace attack accuracy. Finally, an efficient end-to-end SCA leakage detection and attack framework using EM-X-DL demonstrates high confidence of an attacker with &lt;20 averaged EM traces.",
    "cited_by_count": 25,
    "openalex_id": "https://openalex.org/W3204813235",
    "type": "article"
  },
  {
    "title": "PUF based Secure and Lightweight Authentication and Key-Sharing Scheme for Wireless Sensor Network",
    "doi": "https://doi.org/10.1145/3466682",
    "publication_date": "2021-09-29",
    "publication_year": 2021,
    "authors": "Mahabub Hasan Mahalat; Dipankar Karmakar; Anindan Mondal; Bibhash Sen",
    "corresponding_authors": "",
    "abstract": "The deployment of wireless sensor networks (WSN) in an untended environment and the openness of the wireless channel bring various security threats to WSN. The resource limitations of the sensor nodes make the conventional security systems less attractive for WSN. Moreover, conventional cryptography alone cannot ensure the desired security against the physical attacks on sensor nodes. Physically unclonable function (PUF) is an emerging hardware security primitive that provides low-cost hardware security exploiting the unique inherent randomness of a device. In this article, we have proposed an authentication and key sharing scheme for the WSN integrating Pedersen’s verifiable secret sharing (Pedersen’s VSS) and Shamir’s secret sharing (Shamir’s SS) scheme with PUF which ensure the desired security with low overhead. The security analysis depicts the resilience of the proposed scheme against different active, passive and physical attacks. Also, the performance analysis shows that the proposed scheme possesses low computation, communication and storage overhead. The scheme only needs to store a polynomial number of PUF challenge-response pairs to the user node. The sink or senor nodes do not require storing any secret key. Finally, the comparison with the previous protocols establishes the dominance of the proposed scheme to use in WSN.",
    "cited_by_count": 24,
    "openalex_id": "https://openalex.org/W3202160163",
    "type": "article"
  },
  {
    "title": "Challenges and design choices in nanoscale CMOS",
    "doi": "https://doi.org/10.1145/1063803.1063805",
    "publication_date": "2005-03-01",
    "publication_year": 2005,
    "authors": "S. Narendra",
    "corresponding_authors": "S. Narendra",
    "abstract": "The driving force for the semiconductor industry growth has been the elegant scaling nature of CMOS technology. In this article, we will first review the history of technology scaling that follows Moore's law from the prespective of microprocessor designs. Challenges to continue the historical scaling trends will be highlighted and design choices to address two specific challenges, process variation and leakage power, will be discussed. In nanoscale CMOS technology generations, supply and threshold voltages will have to continually scale to sustain performance increase, limit energy consumption, control power dissipation, and maintain reliability. These continual scaling requirements on supply and threshold voltages pose several technology and circuit design challenges. One such challenge is the expected increase in process variation and the resulting increase in design margins. Concept of adaptive circuit schemes to deal with increasing design margins will be explained. Next, with threshold voltage scaling, subthreshold leakage power has become a significant portion of total power in nanoscale CMOS systems. Therefore, it has become imperative to accurately predict and minimize leakage power of such systems, especially with increasing within-die threshold voltage variation. A model that predicts system leakage based on first principles will be presented and circuit techniques to reduce system leakage will be discussed. It is essential to point out that this article does not cover all challenges that nanoscale CMOS systems face. Challenges that are not detailed in the main sections of the article and speculation on what future nanoscale silicon based CMOS systems might resemble are summarized.",
    "cited_by_count": 49,
    "openalex_id": "https://openalex.org/W1989714673",
    "type": "article"
  },
  {
    "title": "Scan-chain design and optimization for three-dimensional integrated circuits",
    "doi": "https://doi.org/10.1145/1543438.1543442",
    "publication_date": "2009-07-01",
    "publication_year": 2009,
    "authors": "Xiaoxia Wu; Paul Falkenstern; Krishnendu Chakrabarty; Yuan Xie",
    "corresponding_authors": "",
    "abstract": "Scan chains are widely used to improve the testability of integrated circuit (IC) designs and to facilitate fault diagnosis. For traditional 2D IC design, a number of design techniques have been proposed in the literature for scan-chain routing and scan-cell partitioning. However, these techniques are not effective for three-dimensional (3D) technologies, which have recently emerged as a promising means to continue technology scaling. In this article, we propose two techniques for designing scan chains in 3D ICs, with given constraints on the number of through-silicon-vias (TSVs). The first technique is based on a genetic algorithm (GA), and it addresses the ordering of cells in a single scan chain. The second optimization technique is based on integer linear programming (ILP); it addresses single-scan-chain ordering as well as the partitioning of scan flip-flops into multiple scan chains. We compare these two methods by conducting experiments on a set of ISCAS'89 benchmark circuits. The first conclusion obtained from the results is that 3D scan-chain optimization achieves significant wire-length reduction compared to 2D counterparts. The second conclusion is that the ILP-based technique provides lower bounds on the scan-chain interconnect length for 3D ICs, and it offers considerable reduction in wire-length compared to the GA-based heuristic method.",
    "cited_by_count": 33,
    "openalex_id": "https://openalex.org/W2112647513",
    "type": "article"
  },
  {
    "title": "Barely alive memory servers",
    "doi": "https://doi.org/10.1145/2367736.2367742",
    "publication_date": "2012-10-01",
    "publication_year": 2012,
    "authors": "Vlasia Anagnostopoulou; Susmit Biswas; Heba Saadeldeen; Alan Savage; Ricardo Bianchini; Tao Yang; Diana Franklin; Frederic T. Chong",
    "corresponding_authors": "",
    "abstract": "Current resource provisioning schemes in Internet services leave servers less than 50% utilized almost all the time. At this level of utilization, the servers' energy efficiency is substantially lower than at peak utilization. A solution to this problem could be dynamically consolidating workloads into fewer servers and turning others off. However, services typically resist doing so, because of high response times during reactivation in handling traffic spikes. Moreover, services often want the memory and/or storage of all servers to be readily available at all times. In this article, we propose a family of barely alive active low-power server states that facilitates both fast reactivation and access to memory while in a low-power state. We compare these states to previously proposed active and idle states. In particular, we investigate the impact of load bursts in each energy-saving scheme. We also evaluate the additional benefits of memory access under low-power states with a study of a search service using a cooperative main-memory cache. Finally, we propose a system that combines a barely-alive state with the off state. We find that the barely alive states can reduce service energy consumption by up to 38%, compared to an energy-oblivious system. We also find that these energy savings are consistent across a large parameter space.",
    "cited_by_count": 30,
    "openalex_id": "https://openalex.org/W2139883663",
    "type": "article"
  },
  {
    "title": "Detection of trojans using a combined ring oscillator network and off-chip transient power analysis",
    "doi": "https://doi.org/10.1145/2491677",
    "publication_date": "2013-09-01",
    "publication_year": 2013,
    "authors": "Xuehui Zhang; Andrew Ferraiuolo; Mohammad Tehranipoor",
    "corresponding_authors": "",
    "abstract": "Verifying the trustworthiness of Integrated Circuits (ICs) is of utmost importance, as hardware Trojans may destroy ICs bound for critical applications. A novel methodology combining on-chip structure with external current measurements is proposed to verify whether or not an IC is Trojan free. This method considers Trojans' impact on neighboring cells and on the entire IC's power consumption, and effectively localizes the measurement of dynamic power. To achieve this, we develop a new on-chip ring oscillator network structure distributed across the entire chip and place each ring oscillator's components in different rows of a standard-cell design. By developing novel statistical data analysis, the effect of process variations on the ICs' transient power will be separated from the effect of Trojans. Simulation results using 90nm technology and experimental results on Xilinx Spartan-6 FPGAs demonstrate the efficiency of our proposed method.",
    "cited_by_count": 29,
    "openalex_id": "https://openalex.org/W2010198746",
    "type": "article"
  },
  {
    "title": "A Survey of Architectural Techniques for Near-Threshold Computing",
    "doi": "https://doi.org/10.1145/2821510",
    "publication_date": "2015-12-28",
    "publication_year": 2015,
    "authors": "Sparsh Mittal",
    "corresponding_authors": "Sparsh Mittal",
    "abstract": "Energy efficiency has now become the primary obstacle in scaling the performance of all classes of computing systems. Low-voltage computing, specifically, near-threshold voltage computing (NTC), which involves operating the transistor very close to and yet above its threshold voltage, holds the promise of providing many-fold improvement in energy efficiency. However, use of NTC also presents several challenges such as increased parametric variation, failure rate, and performance loss. This article surveys several recent techniques that aim to offset these challenges for fully leveraging the potential of NTC. By classifying these techniques along several dimensions, we also highlight their similarities and differences. It is hoped that this article will provide insights into state-of-the-art NTC techniques to researchers and system designers and inspire further research in this field.",
    "cited_by_count": 27,
    "openalex_id": "https://openalex.org/W2219540336",
    "type": "article"
  },
  {
    "title": "A Mixed Signal Architecture for Convolutional Neural Networks",
    "doi": "https://doi.org/10.1145/3304110",
    "publication_date": "2019-03-26",
    "publication_year": 2019,
    "authors": "Qiuwen Lou; Chenyun Pan; John McGuinness; András Horváth; Azad Naeemi; Michael Niemier; Xiaobo Sharon Hu",
    "corresponding_authors": "",
    "abstract": "Deep neural network (DNN) accelerators with improved energy and delay are desirable for meeting the requirements of hardware targeted for IoT and edge computing systems. Convolutional neural networks (CoNNs) belong to one of the most popular types of DNN architectures. This article presents the design and evaluation of an accelerator for CoNNs. The system-level architecture is based on mixed-signal, cellular neural networks (CeNNs). Specifically, we present (i) the implementation of different layers, including convolution, ReLU, and pooling, in a CoNN using CeNN, (ii) modified CoNN structures with CeNN-friendly layers to reduce computational overheads typically associated with a CoNN, (iii) a mixed-signal CeNN architecture that performs CoNN computations in the analog and mixed signal domain, and (iv) design space exploration that identifies what CeNN-based algorithm and architectural features fare best compared to existing algorithms and architectures when evaluated over common datasets—MNIST and CIFAR-10. Notably, the proposed approach can lead to 8.7× improvements in energy-delay product (EDP) per digit classification for the MNIST dataset at iso-accuracy when compared with the state-of-the-art DNN engine, while our approach could offer 4.3× improvements in EDP when compared to other network implementations for the CIFAR-10 dataset.",
    "cited_by_count": 27,
    "openalex_id": "https://openalex.org/W2895580425",
    "type": "article"
  },
  {
    "title": "A Fast Extraction Algorithm for Defect-Free Subcrossbar in Nanoelectronic Crossbar",
    "doi": "https://doi.org/10.1145/2517137",
    "publication_date": "2014-04-01",
    "publication_year": 2014,
    "authors": "Bo Yuan; Bin Li",
    "corresponding_authors": "",
    "abstract": "Due to the super scale, high defect density, and per-chip designing paradigm of emerging nanoelectronics, the runtime of the algorithms for defect-tolerant design is of vital importance from the perspective of practicability. In this article, an efficient and effective heuristic defect-free subcrossbar extraction algorithm is proposed which improves performance by mixing the heuristics from two state-of-the-art algorithms and then is speeded up significantly by considerably reducing the number of major loops. Compared with the current most effective algorithm that improves the solution quality (i.e., size of the defect-free subcrossbar obtained) at the cost of high time complexity O ( n 3 ), the time complexity of the proposed heuristic algorithm is proved to be O ( n 2 ). Using a large set of instances of various scales and defect densities, the simulation results show that the proposed algorithm can offer similar high-quality solutions as the current most effective algorithm while consuming much shorter runtimes (reduced to about 1/3 to 1/5) than the current most effective algorithm.",
    "cited_by_count": 26,
    "openalex_id": "https://openalex.org/W1983641062",
    "type": "article"
  },
  {
    "title": "Workload assignment considering NBTI degradation in multicore systems",
    "doi": "https://doi.org/10.1145/2539124",
    "publication_date": "2014-01-01",
    "publication_year": 2014,
    "authors": "Jin Sun; Roman Lysecky; Karthik Shankar; Avinash Kodi; Ahmed Louri; Janet Roveda",
    "corresponding_authors": "",
    "abstract": "With continuously shrinking technology, reliability issues such as Negative Bias Temperature Instability (NBTI) has resulted in considerable degradation of device performance, and eventually the short mean-time-to-failure (MTTF) of the whole multicore system. This article proposes a new workload balancing scheme based on device-level fractional NBTI model to balance the workload among active cores while relaxing stressed ones. Starting with NBTI-induced threshold voltage degradation, we define a concept of Capacity Rate (CR) as an indication of one core's ability to accept workload. Capacity rate captures core's performance variability in terms of delay and power metrics under the impact of NBTI aging. The proposed workload balancing framework employs the capacity rates as workload constraints, applies a Dynamic Zoning (DZ) algorithm to group cores into zones to process task flows, and then uses Dynamic Task Scheduling (DTS) to allocate tasks in each zone with balanced workload and minimum communication cost. Experimental results on a 64-core system show that by allowing a small part of the cores to relax over a short time period, the proposed methodology improves multicore system yield (percentage of core failures) by 20%, while extending MTTF by 30% with insignificant degradation in performance (less than 3%).",
    "cited_by_count": 26,
    "openalex_id": "https://openalex.org/W1993273773",
    "type": "article"
  },
  {
    "title": "Hardware Trojan Detection Using the Order of Path Delay",
    "doi": "https://doi.org/10.1145/3229050",
    "publication_date": "2018-07-31",
    "publication_year": 2018,
    "authors": "Xiaotong Cui; Elnaz Koopahi; Kaijie Wu; Ramesh Karri",
    "corresponding_authors": "",
    "abstract": "Many fabrication-less design houses are outsourcing their designs to third-party foundries for fabrication to lower cost. This IC development process, however, raises serious security concerns on Hardware Trojans (HTs). Many design-for-trust techniques have been proposed to detect HTs through observing erroneous output or abnormal side-channel characteristics. Side-channel characteristics such as path delay have been widely used for HT detection and functionality verification, as the changes of the characteristics of the host circuit incurred by the inserted HT can be identified through proper methods. In this article, for the first time, we propose a two-phase technique, which uses the order of the path delay in path pairs to detect HTs. In the design phase, a full-cover path set that covers all the nets of the design is generated; meanwhile, in the set, the relative order of paths in path pairs is determined according to their delay. The order of the paths in path pairs serves as the fingerprint of the design. In the test phase, the actual delay of the paths in the full-cover set is extracted from the fabricated circuits, and the order of paths in path pairs is compared with the fingerprint generated in the design phase. A mismatch between them indicates the existence of HTs. Both process variations and measurement noise are taken into consideration. The efficiency and accuracy of the proposed technique are confirmed by a series of experiments, including the examination of both violated path pairs incurred by HTs and their false alarm rate.",
    "cited_by_count": 26,
    "openalex_id": "https://openalex.org/W2898173429",
    "type": "article"
  },
  {
    "title": "Placement and Routing for Tile-based Field-coupled Nanocomputing Circuits Is <i>NP</i> -complete (Research Note)",
    "doi": "https://doi.org/10.1145/3312661",
    "publication_date": "2019-04-22",
    "publication_year": 2019,
    "authors": "Marcel Walter; Robert Wille; Daniel Große; Frank Sill Torres; Rolf Drechsler",
    "corresponding_authors": "",
    "abstract": "Field-coupled Nanocomputing (FCN) technologies provide an alternative to conventional CMOS-based computation technologies and are characterized by intriguingly low-energy dissipation. Accordingly, their design received significant attention in the recent past. FCN circuit implementations like Quantum-dot Cellular Automata (QCA) or Nanomagnet Logic (NML) have already been built in labs and basic operations such as inverters, Majority, AND, OR, and so on, are already available. The design problem basically boils down to the question of how to place basic operations and route their connections so that the desired function results while, at the same time, further constraints (related to timing, clocking, path lengths, etc.) are satisfied. While several solutions for this problem have been proposed, interestingly no clear understanding about the complexity of the underlying task exists thus far. In this research note, we consider this problem and eventually prove that placement and routing for tile-based FCN circuits is NP -complete. By this, we provide a theoretical foundation for the further development of corresponding design methods.",
    "cited_by_count": 25,
    "openalex_id": "https://openalex.org/W2940645969",
    "type": "article"
  },
  {
    "title": "Application and Thermal-reliability-aware Reinforcement Learning Based Multi-core Power Management",
    "doi": "https://doi.org/10.1145/3323055",
    "publication_date": "2019-10-10",
    "publication_year": 2019,
    "authors": "Sai Manoj Pudukotai Dinakarrao; Arun Joseph; A. Haridass; Muhammad Shafique; Jörg Henkel; Houman Homayoun",
    "corresponding_authors": "",
    "abstract": "Power management through dynamic voltage and frequency scaling (DVFS) is one of the most widely adopted techniques. However, it impacts application reliability (due to soft errors, circuit aging, and deadline misses). However, increased power density impacts the thermal reliability of the chip, sometimes leading to permanent failure. To balance both application- and thermal-reliability along with achieving power savings and maintaining performance, we propose application- and thermal-reliability-aware reinforcement learning–based multi-core power management in this work. The proposed power management scheme employs a reinforcement learner to consider the power savings and variations in the application and thermal reliability caused by DVFS. To overcome the computational overhead, the power management decisions are determined at the application-level rather than per-core or system-level granularity. Experimental evaluation of proposed multi-core power management on a microprocessor with up to 32 cores, running PARSEC applications, was done to demonstrate the applicability and efficiency of the proposed technique. Compared to the existing state-of-the-art techniques, the proposed technique enables an average energy savings of up to ∼20%, up to 4.926°C temperature reduction without degradation in the application- and thermal-reliability.",
    "cited_by_count": 25,
    "openalex_id": "https://openalex.org/W2980002279",
    "type": "article"
  },
  {
    "title": "Neuromorphic Processors with Memristive Synapses",
    "doi": "https://doi.org/10.1145/2894756",
    "publication_date": "2016-05-12",
    "publication_year": 2016,
    "authors": "Qian Wang; Yongtae Kim; Peng Li",
    "corresponding_authors": "",
    "abstract": "Due to their nonvolatile nature, excellent scalability, and high density, memristive nanodevices provide a promising solution for low-cost on-chip storage. Integrating memristor-based synaptic crossbars into digital neuromorphic processors (DNPs) may facilitate efficient realization of brain-inspired computing. This article investigates architectural design exploration of DNPs with memristive synapses by proposing two synapse readout schemes. The key design tradeoffs involving different analog-to-digital conversions and memory accessing styles are thoroughly investigated. A novel storage strategy optimized for feedforward neural networks is proposed in this work, which greatly reduces the energy and area cost of the memristor array and its peripherals.",
    "cited_by_count": 24,
    "openalex_id": "https://openalex.org/W2390826204",
    "type": "article"
  },
  {
    "title": "Impact of Fin Width Scaling on RF/Analog Performance of Junctionless Accumulation-Mode Bulk FinFET",
    "doi": "https://doi.org/10.1145/2903143",
    "publication_date": "2016-05-13",
    "publication_year": 2016,
    "authors": "Kalyan Biswas; Angsuman Sarkar; Chandan Kumar Sarkar",
    "corresponding_authors": "",
    "abstract": "In this article, the RF and analog performance of junctionless accumulation-mode bulk FinFETs is analyzed by employing the variation of fin width so that it can be used as a high-efficiency RF integrated circuit design. The RF/analog performance evaluation has been carried out using the ATLAS 3D device simulator in terms of evaluation of figure-of-merits metrics such as transconductance (g m ), gate-to-source/drain capacitances (C gg ), cutoff frequency (f T ), and maximum frequency of oscillation (f max ). Apart from RF/analog performance investigation, the variation of ON-current to OFF-current ratio (I ON /I OFF ) and transconductance generation factor (g m /I ds ) have also been carried out. From this study, it is observed that smaller fin width of the device improves its performance.",
    "cited_by_count": 24,
    "openalex_id": "https://openalex.org/W2399868650",
    "type": "article"
  },
  {
    "title": "Dynamic Reliability Management in Neuromorphic Computing",
    "doi": "https://doi.org/10.1145/3462330",
    "publication_date": "2021-07-21",
    "publication_year": 2021,
    "authors": "Shihao Song; Jui Hanamshet; Adarsha Balaji; Anup Das; Jeffrey L. Krichmar; Nikil Dutt; Nagarajan Kandasamy; Francky Catthoor",
    "corresponding_authors": "",
    "abstract": "Neuromorphic computing systems execute machine learning tasks designed with spiking neural networks. These systems are embracing non-volatile memory to implement high-density and low-energy synaptic storage. Elevated voltages and currents needed to operate non-volatile memories cause aging of CMOS-based transistors in each neuron and synapse circuit in the hardware, drifting the transistor’s parameters from their nominal values. If these circuits are used continuously for too long, the parameter drifts cannot be reversed, resulting in permanent degradation of circuit performance over time, eventually leading to hardware faults. Aggressive device scaling increases power density and temperature, which further accelerates the aging, challenging the reliable operation of neuromorphic systems. Existing reliability-oriented techniques periodically de-stress all neuron and synapse circuits in the hardware at fixed intervals, assuming worst-case operating conditions, without actually tracking their aging at run-time. To de-stress these circuits, normal operation must be interrupted, which introduces latency in spike generation and propagation, impacting the inter-spike interval and hence, performance (e.g., accuracy). We observe that in contrast to long-term aging, which permanently damages the hardware, short-term aging in scaled CMOS transistors is mostly due to bias temperature instability. The latter is heavily workload-dependent and, more importantly, partially reversible. We propose a new architectural technique to mitigate the aging-related reliability problems in neuromorphic systems by designing an intelligent run-time manager (NCRTM), which dynamically de-stresses neuron and synapse circuits in response to the short-term aging in their CMOS transistors during the execution of machine learning workloads, with the objective of meeting a reliability target. NCRTM de-stresses these circuits only when it is absolutely necessary to do so, otherwise reducing the performance impact by scheduling de-stress operations off the critical path. We evaluate NCRTM with state-of-the-art machine learning workloads on a neuromorphic hardware. Our results demonstrate that NCRTM significantly improves the reliability of neuromorphic hardware, with marginal impact on performance.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W3190126522",
    "type": "article"
  },
  {
    "title": "A Genetic-algorithm-based Approach to the Design of DCT Hardware Accelerators",
    "doi": "https://doi.org/10.1145/3501772",
    "publication_date": "2022-01-29",
    "publication_year": 2022,
    "authors": "Mario Barbareschi; Salvatore Barone; Alberto Bosio; Jie Han; Marcello Traiola",
    "corresponding_authors": "",
    "abstract": "As modern applications demand an unprecedented level of computational resources, traditional computing system design paradigms are no longer adequate to guarantee significant performance enhancement at an affordable cost. Approximate Computing (AxC) has been introduced as a potential candidate to achieve better computational performances by relaxing non-critical functional system specifications. In this article, we propose a systematic and high-abstraction-level approach allowing the automatic generation of near Pareto-optimal approximate configurations for a Discrete Cosine Transform (DCT) hardware accelerator. We obtain the approximate variants by using approximate operations, having configurable approximation degree, rather than full-precise ones. We use a genetic searching algorithm to find the appropriate tuning of the approximation degree, leading to optimal tradeoffs between accuracy and gains. Finally, to evaluate the actual HW gains, we synthesize non-dominated approximate DCT variants for two different target technologies, namely, Field Programmable Gate Arrays (FPGAs) and Application Specific Integrated Circuits (ASICs). Experimental results show that the proposed approach allows performing a meaningful exploration of the design space to find the best tradeoffs in a reasonable time. Indeed, compared to the state-of-the-art work on approximate DCT, the proposed approach allows an 18% average energy improvement while providing at the same time image quality improvement.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W4210659427",
    "type": "article"
  },
  {
    "title": "Building an Open Representation for Biological Protocols",
    "doi": "https://doi.org/10.1145/3604568",
    "publication_date": "2023-06-14",
    "publication_year": 2023,
    "authors": "Bryan Bartley; Jacob Beal; Miles Rogers; Daniel Bryce; Robert P. Goldman; Benjamin J. Keller; Peter L. Lee; Vanessa Biggers; Joshua Nowak; Mark Weston",
    "corresponding_authors": "",
    "abstract": "Laboratory protocols are critical to biological research and development, yet difficult to communicate and reproduce across projects, investigators, and organizations. While many attempts have been made to address this challenge, there is currently no available protocol representation that is unambiguous enough for precise interpretation and automation, yet simultaneously “human friendly” and abstract enough to enable reuse and adaptation. The Laboratory Open Protocol language (LabOP) is a free and open protocol representation aiming to address this gap, building on a foundation of UML, Autoprotocol, Aquarium, SBOL RDF, and the Provenance Ontology. LabOP provides a linked-data representation both for protocols and for records of their execution and the resulting data, as well as a framework for exporting from LabOP for execution by either humans or laboratory automation. LabOP is currently implemented in the form of an RDF knowledge representation, specification document, and Python library, and supports execution as manual “paper protocols,” by Autoprotocol or by Opentrons. From this initial implementation, LabOP is being further developed as an open community effort.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W4380433666",
    "type": "article"
  },
  {
    "title": "Radial addressing of nanowires",
    "doi": "https://doi.org/10.1145/1148015.1148018",
    "publication_date": "2006-04-01",
    "publication_year": 2006,
    "authors": "John E. Savage; Eric Rachlin; André DeHon; Charles M. Lieber; Yue Wu",
    "corresponding_authors": "",
    "abstract": "We introduce radial encoding of nanowires (NWs), a new method of differentiating and controlling NWs by a small set of mesoscale wires for use in crossbar memories. We describe methods of controlling these NWs and give efficient manufacturing algorithms. These new encoding and decoding methods do not suffer from the misalignment characteristic of flow-aligned NWs. They achieve comparable effective pitch and resulting memory density with axially encoded NWs, while avoiding potential cases of address ambiguity and simplifying NW preparation. We also explore hybrid axial/radial encodings and show that they offer no net benefit over pure codes.",
    "cited_by_count": 38,
    "openalex_id": "https://openalex.org/W2112721090",
    "type": "article"
  },
  {
    "title": "NANA",
    "doi": "https://doi.org/10.1145/1126257.1126258",
    "publication_date": "2006-01-01",
    "publication_year": 2006,
    "authors": "Jaidev P. Patwardhan; Chris Dwyer; Alvin R. Lebeck; Daniel J. Sorin",
    "corresponding_authors": "",
    "abstract": "This article explores the architectural challenges introduced by emerging bottom-up fabrication of nanoelectronic circuits. The specific nanotechnology we explore proposes patterned DNA nanostructures as a scaffold for the placement and interconnection of carbon nanotube or silicon nanorod FETs to create a limited size circuit (node). Three characteristics of this technology that significantly impact architecture are (1) limited node size, (2) random node interconnection, and (3) high defect rates. We present and evaluate an accumulator-based active network architecture that is compatible with any technology that presents these three challenges. This architecture represents an initial, unoptimized solution for understanding the implications of DNA-guide self-assembly.",
    "cited_by_count": 37,
    "openalex_id": "https://openalex.org/W2099939334",
    "type": "article"
  },
  {
    "title": "PicoServer",
    "doi": "https://doi.org/10.1145/1412587.1412589",
    "publication_date": "2008-10-01",
    "publication_year": 2008,
    "authors": "Taeho Kgil; Али Саиди; Nathan Binkert; Steve Reinhardt; Krisztián Flautner; Trevor Mudge",
    "corresponding_authors": "",
    "abstract": "This article extends our prior work to show that a straightforward use of 3D stacking technology enables the design of compact energy-efficient servers. Our proposed architecture, called PicoServer, employs 3D technology to bond one die containing several simple, slow processing cores to multiple memory dies sufficient for a primary memory. The multiple memory dies are composed of DRAM. This use of 3D stacks readily facilitates wide low-latency buses between processors and memory. These remove the need for an L2 cache allowing its area to be re-allocated to additional simple cores. The additional cores allow the clock frequency to be lowered without impairing throughput. Lower clock frequency means that thermal constraints, a concern with 3D stacking, are easily satisfied. We extend our original analysis on PicoServer to include: (1) a wider set of server workloads, (2) the impact of multithreading, and (3) the on-chip DRAM architecture and system memory usage. PicoServer is intentionally simple, requiring only the simplest form of 3D technology where die are stacked on top of one another. Our intent is to minimize risk of introducing a new technology (3D) to implement a class of low-cost, low-power compact server architectures.",
    "cited_by_count": 33,
    "openalex_id": "https://openalex.org/W2103227834",
    "type": "article"
  },
  {
    "title": "Designing CMOS/molecular memories while considering device parameter variations",
    "doi": "https://doi.org/10.1145/1229175.1229178",
    "publication_date": "2007-04-01",
    "publication_year": 2007,
    "authors": "Garrett S. Rose; Yuxing Yao; James M. Tour; Adam C. Cabe; Nadine Gergel-Hackett; Nabanita Majumdar; J. C. Bean; L. R. Harriott; Mircea R. Stan",
    "corresponding_authors": "",
    "abstract": "In recent years, many advances have been made in the development of molecular scale devices. Experimental data shows that these devices have potential for use in both memory and logic. This article describes the challenges faced in building crossbar array-based molecular memory and develops a methodology to optimize molecular scale architectures based on experimental device data taken at room temperature. In particular, issues in reading and writing such as memory using CMOS are discussed, and a solution is introduced for easily reading device conductivity states (typically characterized by very small currents). Additionally, a metric is derived to determine the voltages for writing to the crossbar array. The proposed memory design is also simulated with consideration to device parameter variations. Thus, the results presented here shed light on important design choices to be made at multiple abstraction levels, from devices to architectures. Simulation results, incorporating experimental device data, are presented using Cadence Spectre.",
    "cited_by_count": 32,
    "openalex_id": "https://openalex.org/W1981175504",
    "type": "article"
  },
  {
    "title": "Molecular QCA design with chemically reasonable constraints",
    "doi": "https://doi.org/10.1145/1350763.1350769",
    "publication_date": "2008-04-01",
    "publication_year": 2008,
    "authors": "Michael Crocker; Michael Niemier; Xiaobo Sharon Hu; Marya Lieberman",
    "corresponding_authors": "",
    "abstract": "In this article we examine the impacts of the fundamental constraints required for circuits and systems made from molecular Quantum-dot Cellular Automata (QCA) devices. Our design constraints are “chemically reasonable” in that we consider the characteristics and dimensions of devices and scaffoldings that have actually been fabricated. This work is a necessary first step for any work in QCA CAD, and can also help shape experiments in the physical sciences for emerging, nano-scale devices. Our work shows that QCA circuits, scaffoldings, substrates, and devices should all be considered simultaneously. Otherwise, there is a very real possibility that the devices and scaffoldings that are eventually manufactured will result in devices that only work in isolation. “Chemically reasonable” also means that expected manufacturing defects must be considered. In our simulations we introduce defects associated with self-assembled systems into various designs to begin to define manufacturing tolerances. This work is especially timely as experimentalists are beginning to work on merging experimental tracks that address devices and scaffolds—and the end result should facilitate correct logical operations.",
    "cited_by_count": 32,
    "openalex_id": "https://openalex.org/W2056157682",
    "type": "article"
  },
  {
    "title": "Asynchronous Solutions for Nanomagnetic Logic Circuits",
    "doi": "https://doi.org/10.1145/2043643.2043645",
    "publication_date": "2011-12-01",
    "publication_year": 2011,
    "authors": "Marco Vacca; Mariagrazia Graziano; Maurizio Zamboni",
    "corresponding_authors": "",
    "abstract": "In the years to come new solutions will be required to overcome the limitations of scaled CMOS technology. One approach is to adopt Nano-Magnetic Logic Circuits, highly appealing for their extremely reduced power consumption. Despite the interesting nature of this approach, many problems arise when this technology is considered for real designs. The wire is the most critical of these problems from the circuit implementation point of view. It works as a pipelined interconnection, and its delay in terms of clock cycles depends on its length. Serious complications arise at the design phase, both in terms of synthesis and of physical design. One possible solution is the use of a delay insensitive asynchronous logic, Null Convention Logic (NCL TM ). Nevertheless its use has many negative consequences in terms of area occupation and speed loss with respect to a Boolean version. In this article we analyze and compare different solutions: nanomagnetic circuits based on full NCL, mixed Boolean-NCL, and fully Boolean logic. We discuss the advantages of these logics, but also the issues they raise. In particular we analyze feedback signals, which, due to their intrinsic pipelined nature, cause errors that still have not found a solution in the literature. The innovative arrangement we propose solves most of the problems and thus soundly increases the knowledge of this technology. The analysis is performed using a VHDL behavioral model we developed and a microprocessor we designed based on this model, as a sound and realistic test bench.",
    "cited_by_count": 28,
    "openalex_id": "https://openalex.org/W2092978386",
    "type": "article"
  },
  {
    "title": "On the Effect of Quantum Interaction Distance on Quantum Addition Circuits",
    "doi": "https://doi.org/10.1145/2000502.2000504",
    "publication_date": "2011-08-01",
    "publication_year": 2011,
    "authors": "Byung-Soo Choi; Rodney Van Meter",
    "corresponding_authors": "",
    "abstract": "We investigate the theoretical limits of the effect of the quantum interaction distance on the speed of exact quantum addition circuits. For this study, we exploit graph embedding for quantum circuit analysis. We study a logical mapping of qubits and gates of any $\\Omega(\\log n)$-depth quantum adder circuit for two $n$-qubit registers onto a practical architecture, which limits interaction distance to the nearest neighbors only and supports only one- and two-qubit logical gates. Unfortunately, on the chosen $k$-dimensional practical architecture, we prove that the depth lower bound of any exact quantum addition circuits is no longer $\\Omega(\\log {n})$, but $\\Omega(\\sqrt[k]{n})$. This result, the first application of graph embedding to quantum circuits and devices, provides a new tool for compiler development, emphasizes the impact of quantum computer architecture on performance, and acts as a cautionary note when evaluating the time performance of quantum algorithms.",
    "cited_by_count": 27,
    "openalex_id": "https://openalex.org/W3123004431",
    "type": "article"
  },
  {
    "title": "Performance and Energy Impact of Locally Controlled NML Circuits",
    "doi": "https://doi.org/10.1145/1899390.1899392",
    "publication_date": "2011-01-01",
    "publication_year": 2011,
    "authors": "Aaron Dingler; Michael Niemier; Xiaobo Sharon Hu; Evan Lent",
    "corresponding_authors": "",
    "abstract": "This article quantitatively considers the performance of nanomagnetic logic circuits within the context of realistic drive circuitry. We also demonstrate how one of the five fundamental tenets of digital logic---preventing unwanted feedback---can be satisfied by realistic drive circuitry. More specifically, different types of multiphase clocks are investigated and compared. Initial projections suggest that even with drive circuitry overhead, nanomagnet logic can outperform subthreshold CMOS in terms of energy delay product---and paths to lower power exist.",
    "cited_by_count": 25,
    "openalex_id": "https://openalex.org/W2045268335",
    "type": "article"
  },
  {
    "title": "Interpreting Assays with Control Flow on Digital Microfluidic Biochips",
    "doi": "https://doi.org/10.1145/2567669",
    "publication_date": "2014-04-01",
    "publication_year": 2014,
    "authors": "Daniel Grissom; Christopher W. Curtis; Philip Brisk",
    "corresponding_authors": "",
    "abstract": "BioCoder is a C++ library developed at Microsoft Research, India, for the unambiguous specification of biochemical assays. This article describes language extensions to BioCoder along with a compiler and runtime system that translate and execute assays specified using BioCoder on a software simulator. The simulator mimics the behavior of laboratories-on-a-chip (LoCs) based on a droplet actuation technology called electrowetting on dielectric (EWoD). To date, prior compilers targeting similar EWoD devices are limited to assays specified as directed acyclic graphs (DAGs) and cannot handle arbitrary control flow or feedback from the LoC. The framework presented herein addresses these challenges through dynamic interpretation, thereby enlarging the space of assays that can be compiled onto EWoD devices.",
    "cited_by_count": 24,
    "openalex_id": "https://openalex.org/W2030184574",
    "type": "article"
  },
  {
    "title": "A physical design tool for carbon nanotube field-effect transistor circuits",
    "doi": "https://doi.org/10.1145/2287696.2287708",
    "publication_date": "2012-08-01",
    "publication_year": 2012,
    "authors": "Jiale Huang; Minhao Zhu; Shengqi Yang; Pallav Gupta; Wei Zhang; Steven M. Rubin; Gilda Garretón; Jin He",
    "corresponding_authors": "",
    "abstract": "In this article, we present a graphical Computer-Aided Design (CAD) environment for the design, analysis, and layout of Carbon NanoTube (CNT) Field-Effect Transistor (CNFET) circuits. This work is motivated by the fact that such a tool currently does not exist in the public domain for researchers. Our tool has been integrated within Electric a very powerful, yet free CAD system for custom design of Integrated Circuits (ICs). The tool supports CNFET schematic and layout entry, rule checking, and HSpice/VerilogA netlist generation. We provide users with a customizable CNFET technology library with the ability to specify λ-based design rules. We showcase the capabilities of our tool by demonstrating the design of a large CNFET standard cell and components library. Meanwhile, HSPICE simulations also have been presented for cell library characterization. We hope that the availability of this tool will invigorate the CAD community to explore novel ideas in CNFET circuit design.",
    "cited_by_count": 24,
    "openalex_id": "https://openalex.org/W2116739698",
    "type": "article"
  },
  {
    "title": "RMDDS",
    "doi": "https://doi.org/10.1145/2564923",
    "publication_date": "2014-02-01",
    "publication_year": 2014,
    "authors": "Chia-Chun Lin; Niraj K. Jha",
    "corresponding_authors": "",
    "abstract": "In this article, we propose a flexible and efficient reversible logic synthesizer. It exploits the complementary advantages of two methods: Reed-Muller Reversible Logic Synthesis (RMRLS) and Decision Diagram Synthesis (DDS), and is thus called Reed-Muller Decision Diagram Synthesis (RMDDS). RMRLS does not scale to a large number of qubits (i.e., quantum bits). DDS tools, even though efficient, add a large number of ancillary qubits and typically incur much higher quantum cost than necessary. RMDDS overcomes these obstacles. It is flexible in the sense that users can either optimize the number of qubits or the quantum cost in the circuit implementation. It is also efficient because the circuits can be synthesized within user-defined CPU times. This combination of flexibility and efficiency has been missing from synthesizers presented earlier. When used to synthesize reversible functions, RMDDS reduces the number of qubits by up to 79.2% (average of 54.6%) when the synthesis objective is to minimize the number of qubits and the quantum cost by up to 71.5% (average of 35.7%) when the synthesis objective is to minimize quantum cost, relative to DDS methods. For irreversible functions (which are automatically embedded in reversible functions), the corresponding best (average) reductions in the number of qubits is 42.1% (22.5%) when minimizing the number of qubits, and in quantum cost, it is 63.0% (25.9%) when minimizing quantum cost.",
    "cited_by_count": 24,
    "openalex_id": "https://openalex.org/W2155868549",
    "type": "article"
  },
  {
    "title": "Theory and analysis of generalized mixing and dilution of biochemical fluids using digital microfluidic biochips",
    "doi": "https://doi.org/10.1145/2629578",
    "publication_date": "2014-10-06",
    "publication_year": 2014,
    "authors": "Sudip Roy; Bhargab B. Bhattacharya; Sarmishtha Ghoshal; Krishnendu Chakrabarty",
    "corresponding_authors": "",
    "abstract": "Digital microfluidic (DMF) biochips are recently being advocated for fast on-chip implementation of biochemical laboratory assays or protocols, and several algorithms for diluting and mixing of reagents have been reported. However, all methods for such automatic sample preparation suffer from a drawback that they assume the availability of input fluids in pure form, that is, each with an extreme concentration factor ( CF ) of 100%. In many real-life scenarios, the stock solutions consist of samples/reagents with multiple CF s. No algorithm is yet known for preparing a target mixture of fluids with a given ratio when its constituents are supplied with random concentrations. An intriguing question is whether or not a given target ratio is feasible to produce from such a general input condition. In this article, we first study the feasibility properties for the generalized mixing problem under the (1:1) mix-split model with an allowable error in the target CF s not exceeding 1 2d, where the integer d is user specified and denotes the desired accuracy level of CF . Next, an algorithm is proposed which produces the desired target ratio of N reagents in ONd mix-split steps, where N ( ≥ 3) denotes the number of constituent fluids in the mixture. The feasibility analysis also leads to the characterization of the total space of input stock solutions from which a given target mixture can be derived, and conversely, the space of all target ratios, which are derivable from a given set of input reagents with arbitrary CF s. Finally, we present a generalized algorithm for diluting a sample S in minimum (1:1) mix-split steps when two or more arbitrary concentrations of S (diluted with the same buffer) are supplied as inputs. These results settle several open questions in droplet-based algorithmic microfluidics and offer efficient solutions for a wider class of on-chip sample preparation problems.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W1982492379",
    "type": "article"
  },
  {
    "title": "Fault-Tolerant Operations for Universal Blind Quantum Computation",
    "doi": "https://doi.org/10.1145/2700248",
    "publication_date": "2015-08-03",
    "publication_year": 2015,
    "authors": "Chia-Hung Chien; Rodney Van Meter; Sy‐Yen Kuo",
    "corresponding_authors": "",
    "abstract": "Blind quantum computation is an appealing use of quantum information technology because it can conceal both the client's data and the algorithm itself from the server. However, problems need to be solved in the practical use of blind quantum computation and fault-tolerance is a major challenge. On an example circuit, the computational cost measured in T gates executed by the client is 97 times more than performing the original computation directly, without using the server, even before applying error correction. (The client still benefits due to drastically reduced memory requirements.) Broadbent et al. proposed running error correction over blind computation, but our first protocol applies one layer of Steane's [[7,1,3]] code underneath instead. This protocol has better fault tolerance, but still results in a substantial overhead. We propose another protocol to reduce the client's computational load by transferring the qubit preparation to the server. For each logical qubit used in the computation, the client is only required to receive eight logical qubits via teleportation then buffer two logical qubits before returning one. This protocol also protects the client's fault-tolerant preparation of logical qubits from a side-channel attack.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W1673958064",
    "type": "article"
  },
  {
    "title": "A Reconfigurable Architecture with Sequential Logic-Based Stochastic Computing",
    "doi": "https://doi.org/10.1145/3060537",
    "publication_date": "2017-06-29",
    "publication_year": 2017,
    "authors": "M. Hassan Najafi; Peng Li; David J. Lilja; Weikang Qian; Kia Bazargan; Marc D. Riedel",
    "corresponding_authors": "",
    "abstract": "Computations based on stochastic bit streams have several advantages compared to deterministic binary radix computations, including low power consumption, low hardware cost, high fault tolerance, and skew tolerance. To take advantage of this computing technique, previous work proposed a combinational logic-based reconfigurable architecture to perform complex arithmetic operations on stochastic streams of bits. The long execution time and the cost of converting between binary and stochastic representations, however, make the stochastic architectures less energy efficient than the deterministic binary implementations. This article introduces a methodology for synthesizing a given target function stochastically using finite-state machines (FSMs), and enhances and extends the reconfigurable architecture using sequential logic. Compared to the previous approach, the proposed reconfigurable architecture can save hardware area and energy consumption by up to 30% and 40%, respectively, while achieving a higher processing speed. Both stochastic reconfigurable architectures are much more tolerant of soft errors (bit flips) than the deterministic binary radix implementations, and their fault tolerance scales gracefully to very large numbers of errors.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W2732892496",
    "type": "article"
  },
  {
    "title": "A Multi-Level-Optimization Framework for FPGA-Based Cellular Neural Network Implementation",
    "doi": "https://doi.org/10.1145/3273957",
    "publication_date": "2018-10-31",
    "publication_year": 2018,
    "authors": "Zhongyang Liu; Shaoheng Luo; Xiaowei Xu; Yiyu Shi; Cheng Zhuo",
    "corresponding_authors": "",
    "abstract": "Cellular Neural Network (CeNN) is considered as a powerful paradigm for embedded devices. Its analog and mix-signal hardware implementations are proved to be applicable to high-speed image processing, video analysis, and medical signal processing with its efficiency and popularity limited by smaller implementation size and lower precision. Recently, digital implementations of CeNNs on FPGA have attracted researchers from both academia and industry due to its high flexibility and short time-to-market. However, most existing implementations are not well optimized to fully utilize the advantages of FPGA platform with unnecessary design and computational redundancy that prevents speedup. We propose a multi-level-optimization framework for energy-efficient CeNN implementations on FPGAs. In particular, the optimization framework is featured with three level optimizations: system-, module-, and design-space-level, with focus on computational redundancy and attainable performance, respectively. Experimental results show that with various configurations our framework can achieve an energy-efficiency improvement of 3.54× and up to 3.88× speedup compared with existing implementations with similar accuracy.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W2903140524",
    "type": "article"
  },
  {
    "title": "Design of Adiabatic Logic-Based Energy-Efficient and Reliable PUF for IoT Devices",
    "doi": "https://doi.org/10.1145/3390771",
    "publication_date": "2020-06-02",
    "publication_year": 2020,
    "authors": "S. Dinesh Kumar; Himanshu Thapliyal",
    "corresponding_authors": "",
    "abstract": "Internet of Things (IoT) devices have stringent constraints on power and energy consumption. Adiabatic logic has been proposed as a novel computing platform to design energy-efficient IoT devices. Physically Unclonable Functions (PUFs) is a promising paradigm to solve security concerns such as Integrated Circuit (IC) piracy, IC counterfeiting, and the like. PUFs have shown great promise for generating the secret bits that can be used in the secure systems in an inexpensive way. However, designing a reliable PUF along with energy-efficiency is a big challenge. Therefore, for energy-efficient and reliable PUFs, we are proposing a novel energy-efficient adiabatic logic-based PUF structure. The proposed adiabatic PUF uses energy recovery concept to achieve high energy efficiency and uses the time ramp voltage to exhibit the reliable start-up behavior. The channel length of the transistors play a major role in controlling manufacturing variations. So, in this article, the circuit simulations are performed with 180nm and 45nm Complementary metal-oxide-semiconductor (CMOS) technology in a Cadence Spectre simulator to analyze the impact of channel length variations. The proposed adiabatic PUF has worst-case reliability of 96.84% and 99.6% with temperature variations at 180nm and 45nm CMOS technology, respectively. Further, the proposed adiabatic PUF consumes 1.071fJ/bit-per cycle at 180nm CMOS technology and 0.08fJ/bit-per cycle at 45nm CMOS technology.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W3034077013",
    "type": "article"
  },
  {
    "title": "Fault-Tolerant Network-on-Chip Design with Flexible Spare Core Placement",
    "doi": "https://doi.org/10.1145/3269983",
    "publication_date": "2019-01-14",
    "publication_year": 2019,
    "authors": "P. Veda Bhanu; Pranav Kulkarni; J. Soumya",
    "corresponding_authors": "",
    "abstract": "Network-on-Chip (NoC) has been proposed as a promising solution to overcome the communication challenges of System-on-Chip (SoC) design in nanoscale technologies. With the advancement in the nanoscale technology, the integration density of Intellectual Property (IP) cores in a single chip have increased, leading to heat dissipation, which in turn makes the system unreliable. Therefore, efficient fault-tolerant methods are necessary at different levels to improve overall system performance and make the system to operate normally. This article presents a flexible spare core placement technique for mesh-based NoC by taking several benchmark applications into consideration. An Integer Linear Programming (ILP)-based solution has been proposed for the spare core placement problem. Also, Particle Swarm Optimisation (PSO)-based meta-heuristic has been proposed for the same. Experiments have been performed by taking several application benchmarks reported in the literature and the applications generated using the TGFF tool. Comparisons have been carried out using our approach and the approach followed in the literature (i) by varying the network size with fixed fault percentage in the network, and (ii) by fixing the network size while varying the percentage of faults in the network. We have also compared the overall communication cost and CPU runtime between ILP and PSO approaches. The results show significant reductions in the overall communication cost, average network latency, and network power consumption across all the cases using our approach over the approaches reported in the literature.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W2908838279",
    "type": "article"
  },
  {
    "title": "Leveraging Side-Channel Information for Disassembly and Security",
    "doi": "https://doi.org/10.1145/3359621",
    "publication_date": "2019-12-18",
    "publication_year": 2019,
    "authors": "Jungmin Park; Fahim Rahman; Apostol Vassilev; Domenic Forte; Mark Tehranipoor",
    "corresponding_authors": "",
    "abstract": "With the rise of Internet of Things (IoT), devices such as smartphones, embedded medical devices, smart home appliances, as well as traditional computing platforms such as personal computers and servers have been increasingly targeted with a variety of cyber attacks. Due to limited hardware resources for embedded devices and difficulty in wide-coverage and on-time software updates, software-only cyber defense techniques, such as traditional anti-virus and malware detectors, do not offer a silver-bullet solution. Hardware-based security monitoring and protection techniques, therefore, have gained significant attention. Monitoring devices using side-channel leakage information, e.g., power supply variation and electromagnetic (EM) radiation, is a promising avenue that promotes multiple directions in security and trust applications. In this article, we provide a taxonomy of hardware-based monitoring techniques against different cyber and hardware attacks, highlight the potentials and unique challenges, and display how power-based side-channel instruction-level monitoring can offer suitable solutions to prevailing embedded device security issues. Further, we delineate approaches for future research directions.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W2995883584",
    "type": "article"
  },
  {
    "title": "Approximate Memristive In-Memory Hamming Distance Circuit",
    "doi": "https://doi.org/10.1145/3371391",
    "publication_date": "2020-03-13",
    "publication_year": 2020,
    "authors": "Mohammad Taha; Christof Teuscher",
    "corresponding_authors": "",
    "abstract": "Hamming Distance (HD) is a popular similarity measure that is used widely in pattern matching applications, DNA sequencing, and binary error-correcting codes. In this article, we extend our previous work to prove that our HD circuit is scalable, tolerant to memristor model variability, and tolerant to device-to-device variation. We showed that the operation of our circuit under non-ideal fabrication conditions changes slightly, decreasing the correct classification rates for the MNIST handwritten digits dataset by &lt;1%. Our circuit’s operation is independent of the memristor model used, as long as the model allows a reverse current. Because we leverage in-memory parallel computing, our circuit is n × faster than other HD circuits, where n is the number of HDs to be computed, and it consumes ≈100× − 1,000× less power compared to other memristive and CMOS HD circuits. Used in a full HD Associative Content Addressable Memory (ACAM), the proposed HD circuit consumes only 2.2% of the total system power. Our state-of-the-art, low-power, and fast HD circuit is relevant for a wide range of applications.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W3012413943",
    "type": "article"
  },
  {
    "title": "Mitigate Parasitic Resistance in Resistive Crossbar-based Convolutional Neural Networks",
    "doi": "https://doi.org/10.1145/3371277",
    "publication_date": "2020-05-22",
    "publication_year": 2020,
    "authors": "Fan Zhang; Miao Hu",
    "corresponding_authors": "",
    "abstract": "Traditional computing hardware often encounters on-chip memory bottleneck on large-scale Convolution Neural Networks (CNN) applications. With its unique in-memory computing feature, resistive crossbar-based computing attracts researchers’ attention as a promising solution to the memory bottleneck issue in von Neumann architectures. However, the parasitic resistances in crossbar deviate its behavior from the ideal weighted summation operation. In large-scale implementations, the impact of parasitic resistances must be carefully considered and mitigated to ensure circuits’ functionality. In this work, we implemented and simulated CNNs on resistive crossbar circuits with consideration of parasitic resistances. Moreover, we carried out a new mapping scheme for high utilization of crossbar arrays on convolution, and a mitigation algorithm to mitigate parasitic resistances in CNN applications. The mitigation algorithm considers parasitic resistances as well as data/kernel patterns of each layer to minimize the computing error in crossbar-based convolutions of CNNs. We demonstrated the proposed methods with implementations of a 4-layer CNN on MNIST, and residual neural network (ResNet) (20, 32, and 56) on CIFAR-10. Simulation results show the proposed methods well mitigate the parasitic resistances in crossbars. With our methods, modern CNNs on crossbars can preserve ideal (software) level classification accuracy with 6-bit ADCs and DACs implementation.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W3030670306",
    "type": "article"
  },
  {
    "title": "Fast Linear Interpolation",
    "doi": "https://doi.org/10.1145/3423184",
    "publication_date": "2021-04-15",
    "publication_year": 2021,
    "authors": "Nathan Zhang; Kevin Robert Canini; Sean Silva; Maya R. Gupta",
    "corresponding_authors": "",
    "abstract": "We present fast implementations of linear interpolation operators for piecewise linear functions and multi-dimensional look-up tables. These operators are common for efficient transformations in image processing and are the core operations needed for lattice models like deep lattice networks, a popular machine learning function class for interpretable, shape-constrained machine learning. We present new strategies for an efficient compiler-based solution using MLIR to accelerate linear interpolation. For real-world machine-learned multi-layer lattice models that use multidimensional linear interpolation, we show these strategies run 5-10× faster on a standard CPU compared to an optimized C++ interpreter implementation.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W3153976248",
    "type": "article"
  },
  {
    "title": "A Flexible Multichannel EEG Artifact Identification Processor using Depthwise-Separable Convolutional Neural Networks",
    "doi": "https://doi.org/10.1145/3427471",
    "publication_date": "2021-04-15",
    "publication_year": 2021,
    "authors": "Mohit Khatwani; Hasib-Al Rashid; Hirenkumar Paneliya; Mark Horton; Nicholas R. Waytowich; W. David Hairston; Tinoosh Mohsenin",
    "corresponding_authors": "",
    "abstract": "This article presents an energy-efficient and flexible multichannel Electroencephalogram (EEG) artifact identification network and its hardware using depthwise and separable convolutional neural networks. EEG signals are recordings of the brain activities. EEG recordings that are not originated from cerebral activities are termed artifacts . Our proposed model does not need expert knowledge for feature extraction or pre-processing of EEG data and has a very efficient architecture implementable on mobile devices. The proposed network can be reconfigured for any number of EEG channel and artifact classes. Experiments were done with the proposed model with the goal of maximizing the identification accuracy while minimizing the weight parameters and required number of operations. Our proposed network achieves 93.14% classification accuracy using an EEG dataset collected by 64-channel BioSemi ActiveTwo headsets, averaged across 17 patients and 10 artifact classes. Our hardware architecture is fully parameterized with number of input channels, filters, depth, and data bit-width. The number of processing engines (PE) in the proposed hardware can vary between 1 to 16, providing different latency, throughput, power, and energy efficiency measurements. We implement our custom hardware architecture on Xilinx FPGA (Artix-7), which on average consumes 1.4 to 4.7 mJ dynamic energy with different PE configurations. Energy consumption is further reduced by 16.7× implementing on application-specified integrated circuit at the post layout level in 65-nm CMOS technology. Our FPGA implementation is 1.7 × to 5.15 × higher in energy efficiency than some previous works. Moreover, our Application-Specified Integrated Circuit implementation is also 8.47 × to 25.79 × higher in energy efficiency compared to previous works. We also demonstrated that the proposed network is reconfigurable to detect artifacts from another EEG dataset collected in our lab by a 14-channel Emotiv EPOC+ headset and achieved 93.5% accuracy for eye blink artifact detection.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W3156903373",
    "type": "article"
  },
  {
    "title": "Impact of On-chip Interconnect on In-memory Acceleration of Deep Neural Networks",
    "doi": "https://doi.org/10.1145/3460233",
    "publication_date": "2021-12-31",
    "publication_year": 2021,
    "authors": "Gokul Krishnan; Sumit K. Mandal; Chaitali Chakrabarti; Jae-sun Seo; Ümit Y. Ogras; Yu Cao",
    "corresponding_authors": "",
    "abstract": "With the widespread use of Deep Neural Networks (DNNs), machine learning algorithms have evolved in two diverse directions -- one with ever-increasing connection density for better accuracy and the other with more compact sizing for energy efficiency. The increase in connection density increases on-chip data movement, which makes efficient on-chip communication a critical function of the DNN accelerator. The contribution of this work is threefold. First, we illustrate that the point-to-point (P2P)-based interconnect is incapable of handling a high volume of on-chip data movement for DNNs. Second, we evaluate P2P and network-on-chip (NoC) interconnect (with a regular topology such as a mesh) for SRAM- and ReRAM-based in-memory computing (IMC) architectures for a range of DNNs. This analysis shows the necessity for the optimal interconnect choice for an IMC DNN accelerator. Finally, we perform an experimental evaluation for different DNNs to empirically obtain the performance of the IMC architecture with both NoC-tree and NoC-mesh. We conclude that, at the tile level, NoC-tree is appropriate for compact DNNs employed at the edge, and NoC-mesh is necessary to accelerate DNNs with high connection density. Furthermore, we propose a technique to determine the optimal choice of interconnect for any given DNN. In this technique, we use analytical models of NoC to evaluate end-to-end communication latency of any given DNN. We demonstrate that the interconnect optimization in the IMC architecture results in up to 6$\\times$ improvement in energy-delay-area product for VGG-19 inference compared to the state-of-the-art ReRAM-based IMC architectures.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W3178631343",
    "type": "article"
  },
  {
    "title": "A Voltage-Controlled, Oscillation-Based ADC Design for Computation-in-Memory Architectures Using Emerging ReRAMs",
    "doi": "https://doi.org/10.1145/3451212",
    "publication_date": "2022-03-25",
    "publication_year": 2022,
    "authors": "Mahta Mayahinia; Abhairaj Singh; Christopher Bengel; Stefan Wiefels; Muath Abu Lebdeh; Stephan Menzel; Dirk J. Wouters; Anteneh Gebregiorgis; Rajendra Bishnoi; Rajiv Joshi; Said Hamdioui",
    "corresponding_authors": "",
    "abstract": "Conventional von Neumann architectures cannot successfully meet the demands of emerging computation and data-intensive applications. These shortcomings can be improved by embracing new architectural paradigms using emerging technologies. In particular, Computation-In-Memory (CiM) using emerging technologies such as Resistive Random Access Memory (ReRAM) is a promising approach to meet the computational demands of data-intensive applications such as neural networks and database queries. In CiM, computation is done in an analog manner; digitization of the results is costly in several aspects, such as area, energy, and performance, which hinders the potential of CiM. In this article, we propose an efficient Voltage-Controlled-Oscillator (VCO)–based analog-to-digital converter (ADC) design to improve the performance and energy efficiency of the CiM architecture. Due to its efficiency, the proposed ADC can be assigned in a per-column manner instead of sharing one ADC among multiple columns. This will boost the parallel execution and overall efficiency of the CiM crossbar array. The proposed ADC is evaluated using a Multiplication and Accumulation (MAC) operation implemented in ReRAM-based CiM crossbar arrays. Simulations results show that our proposed ADC can distinguish up to 32 levels within 10 ns while consuming less than 5.2 pJ of energy. In addition, our proposed ADC can tolerate ≈30% variability with a negligible impact on the performance of the ADC.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W4220655405",
    "type": "article"
  },
  {
    "title": "Automated Generation of Security Assertions for RTL Models",
    "doi": "https://doi.org/10.1145/3565801",
    "publication_date": "2022-11-22",
    "publication_year": 2022,
    "authors": "Hasini Witharana; Aruna Jayasena; Andrew Whigham; Prabhat Mishra",
    "corresponding_authors": "",
    "abstract": "System-on-Chip (SoC) security is vital in designing trustworthy systems. Detecting and fixing a vulnerability in the early stages is easier and cost-effective. Assertion-based verification is widely used for functional validation of Register-Transfer Level (RTL) designs. Assertions can improve the controllability and observability that can lead to faster error detection and localization. Although assertions are widely used for functional validation of RTL models, there is limited effort in applying assertions to detect SoC security vulnerabilities. Specifically, a fundamental challenge in SoC security and trust validation is how to develop high-quality security assertions. In this article, we perform automated vulnerability analysis of RTL models to generate security assertions for six classes of vulnerabilities. Experimental results show that the generated security assertions can detect a wide variety of vulnerabilities. Our automated framework can drastically reduce the overall security validation effort compared to the manual development of security assertions. Automated generation of security assertions will enable assertion-based verification to be one of the most promising pre-silicon security sign-off solutions.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W4309698405",
    "type": "article"
  },
  {
    "title": "Sorting in Memristive Memory",
    "doi": "https://doi.org/10.1145/3517181",
    "publication_date": "2022-02-11",
    "publication_year": 2022,
    "authors": "Mohsen Riahi Alam; M. Hassan Najafi; Nima TaheriNejad",
    "corresponding_authors": "",
    "abstract": "Sorting data is needed in many application domains. Traditionally, the data is read from memory and sent to a general-purpose processor or application-specific hardware for sorting. The sorted data is then written back to the memory. Reading/writing data from/to memory and transferring data between memory and processing unit incur significant latency and energy overhead. In this work, we develop the first architectures for in-memory sorting of data to the best of our knowledge. We propose two architectures. The first architecture is applicable to the conventional format of representing data, i.e., weighted binary radix. The second architecture is proposed for developing unary processing systems, where data is encoded as uniform unary bit-streams. As we present, each of the two architectures has different advantages and disadvantages, making one or the other more suitable for a specific application. However, the common property of both is a significant reduction in the processing time compared to prior sorting designs. Our evaluations show on average 37 × and 138× energy reduction for binary and unary designs, respectively, compared to conventional CMOS off-memory sorting systems in a 45 nm technology. We designed a 3×3 and a 5×5 Median filter using the proposed sorting solutions, which we used for processing 64×64 pixel images. Our results show a reduction of 14× and 634× in energy and latency, respectively, with the proposed binary, and 5.6× and 152×10 3 in energy and latency with the proposed unary approach compared to those of the off-memory binary and unary designs for the 3 × 3 Median filtering system.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W4211211399",
    "type": "article"
  },
  {
    "title": "ScatterVerif: Verification of Electronic Boards Using Reflection Response of Power Distribution Network",
    "doi": "https://doi.org/10.1145/3513087",
    "publication_date": "2022-02-11",
    "publication_year": 2022,
    "authors": "Tahoura Mosavirik; Fatemeh Ganji; Patrick Schaumont; Shahin Tajik",
    "corresponding_authors": "",
    "abstract": "The globalization of electronic systems’ fabrication has made some of our most critical systems vulnerable to supply chain attacks. Implanting spy chips on the printed circuit boards (PCBs) or replacing genuine components with counterfeit/recycled ones are examples of such attacks. Unfortunately, conventional attack detection schemes for PCBs are ad hoc, costly, unscalable, and error prone. This work introduces a holistic physical verification framework for PCBs, called ScatterVerif , based on the characterization of the PCBs’ power distribution network. First, we demonstrate how scattering parameters, frequently used for impedance characterization of RF circuits, can characterize the entire PCB with a single measurement. Second, we present how a class of machine learning algorithms, namely the Gaussian mixture model, can be applied to the measurements to automatically classify/cluster the genuine and tampered/counterfeit PCBs. We show that these attacks affect the overall impedance of a PCB differently in various frequency ranges, hence the conventional impedance measurements using a constant-frequency electrical stimulus might leave the attack undetected. We conduct extensive experiments on counterfeit and tampered devices and demonstrate that these attacks can be detected with high confidence. Finally, we show that the acquired data from the power distribution network characterization can also be deployed for fingerprinting genuine PCBs.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W4211263472",
    "type": "article"
  },
  {
    "title": "Spiking-NeRF: Spiking Neural Network for Energy-Efficient Neural Rendering",
    "doi": "https://doi.org/10.1145/3675808",
    "publication_date": "2024-07-11",
    "publication_year": 2024,
    "authors": "Ziwen Li; Yu Ma; Jindong Zhou; Pingqiang Zhou",
    "corresponding_authors": "",
    "abstract": "Artificial Neural Networks (ANNs) have achieved remarkable performance in many artificial intelligence tasks. As the application scenarios become more sophisticated, the computation and energy consumption of ANNs are also constantly increasing, which poses a challenge for deploying ANNs on energy-constrained devices. Spiking Neural Networks (SNNs) provide a promising solution to build energy-efficiency neural networks. However, the current training methods of SNNs cannot output values as precise as ANNs. This limits the applications of SNNs to relatively simple image classification tasks. In this article, we extend the application of SNNs to neural rendering tasks and propose an energy-efficient spiking neural rendering model, called Spiking-NeRF (Spiking Neural Radiance Fields). We first analyze the ANN-to-SNN conversion theory and propose an output scheme for SNNs to obtain the precise scene property values. Then we customize the parameter normalization method for the special network architecture of neural rendering. Furthermore, we present an early termination strategy (ETS) based on the discrete nature of spikes to reduce energy consumption. We evaluate the performance of Spiking-NeRF on both realistic and synthetic scenes. Experimental results show that Spiking-NeRF can achieve comparable rendering performance to ANN-based NeRF with up to \\(2.27\\times\\) energy reduction.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4400532390",
    "type": "article"
  },
  {
    "title": "An energy management framework for energy harvesting embedded systems",
    "doi": "https://doi.org/10.1145/1773814.1773818",
    "publication_date": "2008-06-18",
    "publication_year": 2008,
    "authors": "Clemens Moser; Jian-Jia Chen; Lothar Thiele",
    "corresponding_authors": "",
    "abstract": "Energy harvesting (also known as energy scavenging) is the process of generating electrical energy from environmental energy sources. There exists a variety of different energy sources such as solar energy, kinetic energy, or thermal energy. In recent years, this term has been frequently applied in the context of small autonomous devices such as wireless sensor nodes. In this article, a framework for energy management in energy harvesting embedded systems is presented. As a possible scenario, we focus on wireless sensor nodes that are powered by solar cells. We demonstrate that classical power management solutions have to be reconceived and/or new problems arise if perpetual operation of the system is required. In particular, we provide a set of algorithms and methods for various application scenarios, including real-time scheduling, application rate control, as well as reward maximization. The goal is to optimize the performance of the application subject to given energy constraints. Our methods optimize the system performance which, for example, allows the usage of smaller solar cells and smaller batteries. Furthermore, we show how to dimension important system parameters like the minimum battery capacity or a sufficient prediction horizon. Our theoretical results are supported by simulations using long-term measurements of solar energy in an outdoor environment. In contrast to previous works, we present a formal framework which is able to capture the performance, the parameters, and the energy model of various energy harvesting systems. We combine different viewpoints, include corresponding simulation results, and provide a thorough discussion of implementation aspects.",
    "cited_by_count": 28,
    "openalex_id": "https://openalex.org/W1982774544",
    "type": "article"
  },
  {
    "title": "A model for computing and energy dissipation of molecular QCA devices and circuits",
    "doi": "https://doi.org/10.1145/1324177.1324180",
    "publication_date": "2008-01-01",
    "publication_year": 2008,
    "authors": "Xiaojun Ma; Jing Huang; Fabrizio Lombardi",
    "corresponding_authors": "",
    "abstract": "Quantum-dot Cellular Automata is an emerging technology that offers significant improvements over CMOS. Recently QCA has been advocated as a technology for implementing reversible computing. However, existing tools for QCA design and evaluation have limited capabilities. This paper presents a new mechanical-based model for computing in QCA. By avoiding a full quantum-thermodynamical calculation, it offers a classical view of the principles of QCA operation and can be used in evaluating energy dissipation for reversible computing. The proposed model is mechanically based and is applicable to six-dot (neutrally charged) QCA cells for molecular implementation. The mechanical model consists of a sleeve of changing shape; four electrically charged balls are connected by a stick that rotates around an axle in the sleeve. The sleeve acts as a clocking unit, while the angular position of the stick within the changing shape of the sleeve, identifies the phase for quasi-adiabatic switching. A thermodynamic analysis of the proposed model is presented. The behaviors of various QCA basic devices and circuits are analyzed using the proposed model. It is shown that the proposed model is capable of evaluating the energy consumption for reversible computing at device and circuit levels for molecular QCA implementation. As applicable to QCA, two clocking schemes are also analyzed for energy dissipation and performance (in terms of number of clocking zones).",
    "cited_by_count": 27,
    "openalex_id": "https://openalex.org/W2082630934",
    "type": "article"
  },
  {
    "title": "Module-Based Synthesis of Digital Microfluidic Biochips with Droplet-Aware Operation Execution",
    "doi": "https://doi.org/10.1145/2422094.2422096",
    "publication_date": "2013-02-01",
    "publication_year": 2013,
    "authors": "Elena Maftei; Paul Pop; Jan Madsen",
    "corresponding_authors": "",
    "abstract": "Microfluidic biochips represent an alternative to conventional biochemical analyzers. A digital biochip manipulates liquids not as continuous flow, but as discrete droplets on a two-dimensional array of electrodes. Several electrodes are dynamically grouped to form a virtual device, on which operations are executed by moving the droplets. So far, researchers have ignored the locations of droplets inside devices, considering that all the electrodes forming the device are occupied throughout the operation execution. In this article, we consider a droplet-aware execution of microfluidic operations, which means that we know the exact position of droplets inside the modules at each time-step. We propose a Tabu Search-based metaheuristic for the synthesis of digital biochips with droplet-aware operation execution. Experimental results show that our approach can significantly reduce the application completion time, allowing us to use smaller area biochips and thus reduce costs.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W2082198782",
    "type": "article"
  },
  {
    "title": "Modeling DVFS and Power-Gating Actuators for Cycle-Accurate NoC-Based Simulators",
    "doi": "https://doi.org/10.1145/2751561",
    "publication_date": "2015-09-21",
    "publication_year": 2015,
    "authors": "Davide Zoni; William Fornaciari",
    "corresponding_authors": "",
    "abstract": "Networks-on-chip (NoCs) are a widely recognized viable interconnection paradigm to support the multi-core revolution. One of the major design issues of multicore architectures is still the power, which can no longer be considered mainly due to the cores, since the NoC contribution to the overall energy budget is relevant. To face both static and dynamic power while balancing NoC performance, different actuators have been exploited in literature, mainly dynamic voltage frequency scaling (DVFS) and power gating. Typically, simulation-based tools are employed to explore the huge design space by adopting simplified models of the components. As a consequence, the majority of state-of-the-art on NoC power-performance optimization do not accurately consider timing and power overheads of actuators, or (even worse) do not consider them at all, with the risk of overestimating the benefits of the proposed methodologies. This article presents a simulation framework for power-performance analysis of multicore architectures with specific focus on the NoC. It integrates accurate power gating and DVFS models encompassing also their timing and power overheads. The value added of our proposal is manyfold: (i) DVFS and power gating actuators are modeled starting from SPICE-level simulations; (ii) such models have been integrated in the simulation environment; (iii) policy analysis support is plugged into the framework to enable assessment of different policies; (iv) a flexible GALS ( globally asynchronous locally synchronous ) support is provided, covering both handshake and FIFO re-synchronization schemas. To demonstrate both the flexibility and extensibility of our proposal, two simple policies exploiting the modeled actuators are discussed in the article.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W2001413418",
    "type": "article"
  },
  {
    "title": "Computing Polynomials Using Unipolar Stochastic Logic",
    "doi": "https://doi.org/10.1145/3007648",
    "publication_date": "2017-04-14",
    "publication_year": 2017,
    "authors": "Liu Yin; Keshab K. Parhi",
    "corresponding_authors": "",
    "abstract": "This article addresses subtraction and polynomial computations using unipolar stochastic logic. Stochastic computing requires simple logic gates, and stochastic logic--based circuits are inherently fault tolerant. Thus, these structures are well suited for nanoscale CMOS technologies. It is well known that an AND gate and a multiplexer can be used to implement stochastic unipolar multiplier and adder, respectively. Although it is easy to realize multiplication and scaled addition, implementation of subtraction is nontrivial using unipolar stochastic logic. Additionally, an accurate computation of subtraction is critical for the implementation of polynomials with negative coefficients in stochastic unipolar representation. This work, for the first time, demonstrates that instead of using well-known Bernstein polynomials, stochastic computation of polynomials can be implemented by using a stochastic subtractor and factorization. Three major contributions are given in this article. First, two approaches are proposed to compute subtraction in stochastic unipolar representation. In the first approach, the subtraction operation is approximated by cascading multilevels of OR and AND gates. The accuracy of the approximation is improved with the increase in the number of stages. In the second approach, the stochastic subtraction is implemented using a multiplexer and a stochastic divider. This approach requires more hardware complexity due to the use of a linear-feedback shift register and a counter for division. Second, computation of polynomials in stochastic unipolar format is presented using scaled addition and proposed stochastic subtraction. Third, we propose stochastic computation of polynomials using factorization. Stochastic implementations of first- and second-order factors are presented for different locations of polynomial roots. From experimental results, it is shown that the proposed stochastic logic circuits require less hardware complexity than the previous stochastic polynomial implementation using Bernstein polynomials.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W2607415461",
    "type": "article"
  },
  {
    "title": "Design and Analysis of STTRAM-Based Ternary Content Addressable Memory Cell",
    "doi": "https://doi.org/10.1145/3060578",
    "publication_date": "2017-05-21",
    "publication_year": 2017,
    "authors": "Rekha Govindaraj; Swaroop Ghosh",
    "corresponding_authors": "",
    "abstract": "Content Addressable Memory (CAM) is widely used in applications where searching a specific pattern of data is a major operation. Conventional CAMs suffer from area, power, and speed limitations. We propose Spin-Torque Transfer RAM--based Ternary CAM (TCAM) cells. The proposed NOR-type TCAM cell has a 62.5% (33%) reduction in number of transistor compared to conventional CMOS TCAMs (spintronic TCAMs). We analyzed the sense margin of the proposed TCAM with respect to 16-, 32-, 64-, 128-, and 256-bit word sizes in 22nm predictive technology. Simulations indicated a reliable sense margin of 50mV even at 0.7V supply voltage for 256-bits word. We also explored a selective threshold voltage modulation of transistors to improve the sense margin and tolerate process and voltage variations. The worst-case search latency and sense margin of 256-bit TCAM is found to be 263ps and 220mV, respectively, at 1V supply voltage. The average search power consumed is 13mW, and the search energy is 4.7fJ/bit search. The write time is 4ns, and the write energy is 0.69pJ/bit. We leverage the NOR-type TCAM design to realize a 9T-2 Magnetic Tunnel Junctions NAND-type TCAM cell that has 43.75% less number of transistors than the conventional CMOS TCAM cell. A NAND-type cell can support up to 64-bit words with a maximum sense margin of up to 33mV. We compare the performance metrics of NOR- and NAND-type TCAM cells with other TCAMs in the literature.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W2618376964",
    "type": "article"
  },
  {
    "title": "Programmable Spike-Timing-Dependent Plasticity Learning Circuits in Neuromorphic VLSI Architectures",
    "doi": "https://doi.org/10.1145/2658998",
    "publication_date": "2015-09-02",
    "publication_year": 2015,
    "authors": "Mostafa Rahimi Azghadi; Saber Moradi; Daniel Fasnacht; Mehmet S. Ozdas; Giacomo Indiveri",
    "corresponding_authors": "",
    "abstract": "Hardware implementations of spiking neural networks offer promising solutions for computational tasks that require compact and low-power computing technologies. As these solutions depend on both the specific network architecture and the type of learning algorithm used, it is important to develop spiking neural network devices that offer the possibility to reconfigure their network topology and to implement different types of learning mechanisms. Here we present a neuromorphic multi-neuron VLSI device with on-chip programmable event-based hybrid analog/digital circuits; the event-based nature of the input/output signals allows the use of address-event representation infrastructures for configuring arbitrary network architectures, while the programmable synaptic efficacy circuits allow the implementation of different types of spike-based learning mechanisms. The main contributions of this article are to demonstrate how the programmable neuromorphic system proposed can be configured to implement specific spike-based synaptic plasticity rules and to depict how it can be utilised in a cognitive task. Specifically, we explore the implementation of different spike-timing plasticity learning rules online in a hybrid system comprising a workstation and when the neuromorphic VLSI device is interfaced to it, and we demonstrate how, after training, the VLSI device can perform as a standalone component (i.e., without requiring a computer), binary classification of correlated patterns.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W1779347319",
    "type": "article"
  },
  {
    "title": "A Synthesis Algorithm for Reconfigurable Single-Electron Transistor Arrays",
    "doi": "https://doi.org/10.1145/2422094.2422099",
    "publication_date": "2013-02-01",
    "publication_year": 2013,
    "authors": "Yung‐Chih Chen; Soumya Eachempati; Chun-Yao Wang; Suman Datta; Yuan Xie; Vijaykrishnan Narayanan",
    "corresponding_authors": "",
    "abstract": "Reducing power consumption has become one of the primary challenges in chip design, and therefore significant efforts are being devoted to find holistic solutions on power reduction from the device level up to the system level. Among a plethora of low power devices that are being explored, single-electron transistors (SETs) at room temperature are particularly attractive. Although prior work has proposed a binary decision diagram-based reconfigurable logic architecture using SETs, it lacks an automatic synthesis algorithm for the architecture. Consequently, in this work, we develop a product-term-based approach that synthesizes a logic circuit by mapping all its product terms into the SET architecture. The experimental results show the effectiveness and efficiency of the proposed approach on a set of MCNC benchmarks.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W2009439672",
    "type": "article"
  },
  {
    "title": "An MINLP Model for Scheduling and Placement of Quantum Circuits with a Heuristic Solution Approach",
    "doi": "https://doi.org/10.1145/2766452",
    "publication_date": "2015-09-21",
    "publication_year": 2015,
    "authors": "Tayebeh Bahreini; Naser Mohammadzadeh",
    "corresponding_authors": "",
    "abstract": "Recent works on quantum physical design have pushed the scheduling and placement of quantum circuit into their prominent positions. In this article, a mixed integer nonlinear programming model is proposed for the placement and scheduling of quantum circuits in such a way that latency is minimized. The proposed model determines locations of gates and the sequence of operations. The proposed model is proved reducible to a quadratic assignment problem which is a well-known NP-complete combinatorial optimization problem. Since it is impossible to find the optimal solution of this NP-complete problem for large quantum circuits within a reasonable amount of time, a metaheuristic solution method is developed for the proposed model. Some experiments are conducted to evaluate the performance of the developed solution approach. Experimental results show that the proposed approach improves average latency by about 24.09% for the attempted benchmarks.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W2069506054",
    "type": "article"
  },
  {
    "title": "Large-Scale Spiking Neural Networks using Neuromorphic Hardware Compatible Models",
    "doi": "https://doi.org/10.1145/2629509",
    "publication_date": "2015-04-27",
    "publication_year": 2015,
    "authors": "Jeffrey L. Krichmar; Philippe Coussy; Nikil Dutt",
    "corresponding_authors": "",
    "abstract": "Neuromorphic engineering is a fast growing field with great potential in both understanding the function of the brain, and constructing practical artifacts that build upon this understanding. For these novel chips and hardware to be useful, hardware compatible applications and simulation tools are needed. We argue that the neural circuit approach, in which networks of neuronal elements model brain circuitry are constructed, allows the development of practical applications and the exploration of brain function. At this level of abstraction, networks of 10 5 neurons or larger can be efficiently simulated, but still preserve the neuronal and synaptic dynamics that appear to be important for brain function. Because the neural circuit level supports spiking neural networks and the prevalent Addressable Event Representation (AER) communication scheme, it fits well with many existing neuromorphic hardware and simulation tools. To show how this approach can be applied, we present case studies of spiking neural networks in vision and recognition tasks based on one instantiation of a simulation environment. However, there are now many hardware options, simulation environments, and applications in this emerging field. These approaches and other considerations are discussed.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W2080357645",
    "type": "article"
  },
  {
    "title": "Composable Modular Models for Synthetic Biology",
    "doi": "https://doi.org/10.1145/2631921",
    "publication_date": "2014-12-30",
    "publication_year": 2014,
    "authors": "Göksel Mısırlı; Jennifer Hallinan; Anil Wipat",
    "corresponding_authors": "",
    "abstract": "Modelling and computational simulation are crucial for the large-scale engineering of biological circuits since they allow the system under design to be simulated prior to implementation in vivo . To support automated, model-driven design it is desirable that in silico models are modular, composable and use standard formats. The synthetic biology design process typically involves the composition of genetic circuits from individual parts. At the most basic level, these parts are representations of genetic features such as promoters, ribosome binding sites (RBSs), and coding sequences (CDSs). However, it is also desirable to model the biological molecules and behaviour that arise when these parts are combined in vivo . Modular models of parts can be composed and their associated systems simulated, facilitating the process of model-centred design. The availability of databases of modular models is essential to support software tools used in the model-driven design process. In this article, we present an approach to support the development of composable, modular models for synthetic biology, termed Standard Virtual Parts. We then describe a programmatically accessible and publicly available database of these models to allow their use by computational design tools.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W2139493897",
    "type": "article"
  },
  {
    "title": "PROTON+",
    "doi": "https://doi.org/10.1145/2830716",
    "publication_date": "2015-12-18",
    "publication_year": 2015,
    "authors": "Anja von Beuningen; Luca Ramini; Davide Bertozzi; Ulf Schlichtmann",
    "corresponding_authors": "",
    "abstract": "Optical Networks-on-Chip (ONoCs) are a promising technology to overcome the bottleneck of low bandwidth of electronic Networks-on-Chip. Recent research discusses power and performance benefits of ONoCs based on their system-level design, while layout effects are typically overlooked. As a consequence, laser power requirements are inaccurately computed from the logic scheme but do not consider the layout. In this article, we propose PROTON+, a fast tool for placement and routing of 3D ONoCs minimizing the total laser power. Using our tool, the required laser power of the system can be decreased by up to 94% compared to a state-of-the-art manually designed layout. In addition, with the help of our tool, we study the physical design space of ONoC topologies. For this purpose, topology synthesis methods (e.g., global connectivity and network partitioning) as well as different objective function weights are analyzed in order to minimize the maximum insertion loss and ultimately the system’s laser power consumption. For the first time, we study optimal positions of memory controllers. A comparison of our algorithm to a state-of-the-art placer for electronic circuits shows the need for a different set of tools custom-tailored for the particular requirements of optical interconnects.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W2219537967",
    "type": "article"
  },
  {
    "title": "Design Considerations for Memristive Crossbar Physical Unclonable Functions",
    "doi": "https://doi.org/10.1145/3094414",
    "publication_date": "2017-09-21",
    "publication_year": 2017,
    "authors": "Mesbah Uddin; Md. Badruddoja Majumder; Karsten Beckmann; Harika Manem; Zahiruddin Alamgir; Nathaniel C. Cady; Garrett S. Rose",
    "corresponding_authors": "",
    "abstract": "Hardware security has emerged as a field concerned with issues such as integrated circuit (IC) counterfeiting, cloning, piracy, and reverse engineering. Physical unclonable functions (PUF) are hardware security primitives useful for mitigating such issues by providing hardware-specific fingerprints based on intrinsic process variations within individual IC implementations. As technology scaling progresses further into the nanometer region, emerging nanoelectronic technologies, such as memristors or RRAMs (resistive random-access memory), have become interesting options for emerging computing systems. In this article, using a comprehensive temperature dependent model of an HfO x (hafnium-oxide) memristor, based on experimental measurements, we explore the best region of operation for a memristive crossbar PUF (XbarPUF). The design considered also employs XORing and a column shuffling technique to improve reliability and resilience to machine learning attacks. We present a detailed analysis for the noise margin and discuss the scalability of the XbarPUF structure. Finally, we present results for estimates of area, power, and delay alongside security performance metrics to analyze the strengths and weaknesses of the XbarPUF. Our XbarPUF exhibits nearly ideal (near 50%) uniqueness, bit-aliasing and uniformity, good reliability of 90% and up (with 100% being ideal), a very small footprint, and low average power consumption ≈104μW.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W2758998126",
    "type": "article"
  },
  {
    "title": "An Integrated Nanophotonic Parallel Adder",
    "doi": "https://doi.org/10.1145/3178452",
    "publication_date": "2018-04-30",
    "publication_year": 2018,
    "authors": "Tohru Ishihara; Akihiko Shinya; Koji Inoue; Kengo Nozaki; Masaya Notomi",
    "corresponding_authors": "",
    "abstract": "Integrated optical circuits with nanophotonic devices have attracted significant attention due to their low power dissipation and light-speed operation. With light interference and resonance phenomena, the nanophotonic device works as a voltage-controlled optical pass-gate like a pass-transistor. This article first introduces the concept of optical pass-gate logic and then proposes a parallel adder circuit based on optical pass-gate logic. Experimental results obtained with an optoelectronic circuit simulator show the advantages of our optical parallel adder circuit over a traditional CMOS-based parallel adder circuit.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W2884388026",
    "type": "article"
  },
  {
    "title": "A Survey on Low-Power Techniques with Emerging Technologies",
    "doi": "https://doi.org/10.1145/2714566",
    "publication_date": "2015-09-02",
    "publication_year": 2015,
    "authors": "Pierre‐Emmanuel Gaillardon; Édith Beigné; Suzanne Lesecq; Giovanni De Micheli",
    "corresponding_authors": "",
    "abstract": "Nowadays, power consumption is one of the main limitations of electronic systems. In this context, novel and emerging devices provide new opportunities to extend the trend toward low-power design. In this survey article, we present a transversal survey on energy-efficient techniques ranging from devices to architectures. The actual trends of device research, with fully depleted planar devices, tri-gate geometries, and gate-all-around structures, allows us to reach an increasingly higher level of performance while reducing the associated power. In addition, beyond the simple device property enhancements, emerging devices also lead to innovations at the circuit and architectural levels. In particular, devices whose properties can be tuned through additional terminals enable a fine and dynamic control of device threshold. They also enable designers to realize logic gates and to implement power-related techniques in a compact way unreachable to standard technologies. These innovations reduce power consumption at the gate level and unlock new means of actuation in architectural solutions like adaptive voltage and frequency scaling.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W1568754962",
    "type": "article"
  },
  {
    "title": "A Comparative Cross-layer Study on Racetrack Memories",
    "doi": "https://doi.org/10.1145/3333336",
    "publication_date": "2019-10-03",
    "publication_year": 2019,
    "authors": "Wang Kang; Bi Wu; Xing Chen; Daoqian Zhu; Zhaohao Wang; Xichao Zhang; Yan Zhou; Youguang Zhang; Weisheng Zhao",
    "corresponding_authors": "",
    "abstract": "Racetrack memory (RM), a new storage scheme in which information flows along a nanotrack, has been considered as a potential candidate for future high-density storage device instead of hard disk drive (HDD). The first RM technology, which was proposed in 2008 by IBM, relies on a train of opposite magnetic domains separated by domain walls (DWs), named DW-RM. After 10 years of intensive research, a variety of fundamental advancements has been achieved; unfortunately, no product has been available until now. With increasing effort and resources dedicated to the development of DW-RM, it is likely that new materials and mechanisms will soon be discovered for practical applications. However, new concepts might also be on the horizon. Recently, an alternative information carrier, magnetic skyrmion, which was experimentally discovered in 2009, has been regarded as a promising replacement of DW for RM, named skyrmion-based RM (SK-RM). Intensive effort has been involved and amazing advances have been made in observing, writing, manipulating, and deleting individual skyrmions. So, what is the relationship between DW and skyrmion? What are the key differences between DW and skyrmion, or between DW-RM and SK-RM? What benefits could SK-RM bring and what challenges need to be addressed before application? In this review article, we intend to answer these questions through a comparative cross-layer study between DW-RM and SK-RM. This work will provide guidelines, especially for circuit and architecture researchers on RM.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W2978771787",
    "type": "article"
  },
  {
    "title": "QuTiBench",
    "doi": "https://doi.org/10.1145/3358700",
    "publication_date": "2019-10-31",
    "publication_year": 2019,
    "authors": "Michaela Blott; Lisa Halder; Miriam Leeser; Linda Doyle",
    "corresponding_authors": "",
    "abstract": "Neural Networks have become one of the most successful universal machine-learning algorithms. They play a key role in enabling machine vision and speech recognition and are increasingly adopted in other application domains. Their computational complexity is enormous and comes along with equally challenging memory requirements in regards to capacity and access bandwidth, which limits deployment in particular within energy constrained, embedded environments. To address these implementation challenges, a broad spectrum of new customized and heterogeneous hardware architectures have emerged, often accompanied with co-designed algorithms to extract maximum benefit out of the hardware. Furthermore, numerous optimization techniques are being explored for neural networks to reduce compute and memory requirements while maintaining accuracy. This results in an abundance of algorithmic and architectural choices, some of which fit specific use cases better than others. For system-level designers, there is currently no good way to compare the variety of hardware, algorithm, and optimization options. While there are many benchmarking efforts in this field, they cover only subsections of the embedded design space. None of the existing benchmarks support essential algorithmic optimizations such as quantization, an important technique to stay on chip, or specialized heterogeneous hardware architectures. We propose a novel benchmark suite, QuTiBench , that addresses this need. QuTiBench is a novel multi-tiered benchmarking methodology ( Ti ) that supports algorithmic optimizations such as quantization ( Qu ) and helps system developers understand the benefits and limitations of these novel compute architectures in regard to specific neural networks and will help drive future innovation. We invite the community to contribute to QuTiBench to support the full spectrum of choices in implementing machine-learning systems.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W2993431242",
    "type": "article"
  },
  {
    "title": "Neuromemrisitive Architecture of HTM with On-Device Learning and Neurogenesis",
    "doi": "https://doi.org/10.1145/3300971",
    "publication_date": "2019-05-07",
    "publication_year": 2019,
    "authors": "Abdullah M. Zyarah; Dhireesha Kudithipudi",
    "corresponding_authors": "",
    "abstract": "Hierarchical temporal memory (HTM) is a biomimetic sequence memory algorithm that holds promise for invariant representations of spatial and spatio-temporal inputs. This article presents a comprehensive neuromemristive crossbar architecture for the spatial pooler (SP) and the sparse distributed representation classifier, which are fundamental to the algorithm. There are several unique features in the proposed architecture that tightly link with the HTM algorithm. A memristor that is suitable for emulating the HTM synapses is identified and a new Z-window function is proposed. The architecture exploits the concept of synthetic synapses to enable potential synapses in the HTM. The crossbar for the SP avoids dark spots caused by unutilized crossbar regions and supports rapid on-chip training within two clock cycles. This research also leverages plasticity mechanisms such as neurogenesis and homeostatic intrinsic plasticity to strengthen the robustness and performance of the SP. The proposed design is benchmarked for image recognition tasks using Modified National Institute of Standards and Technology (MNIST) and Yale faces datasets, and is evaluated using different metrics including entropy, sparseness, and noise robustness. Detailed power analysis at different stages of the SP operations is performed to demonstrate the suitability for mobile platforms.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W3121407351",
    "type": "article"
  },
  {
    "title": "Machine Learning Vulnerability Analysis of FPGA-based Ring Oscillator PUFs and Counter Measures",
    "doi": "https://doi.org/10.1145/3445978",
    "publication_date": "2021-05-11",
    "publication_year": 2021,
    "authors": "Noor Ahmad Hazari; Ahmed Oun; Mohammed Niamat",
    "corresponding_authors": "",
    "abstract": "Physical Unclonable Functions (PUFs) exploit the manufacturing process variations inherent in silicon-based chips to generate unique secret keys. Although PUFs are supposed to be unclonable or unbreakable, researchers have found that they are vulnerable to machine learning (ML) attacks. In this article, we analyze the vulnerability of different FPGA-based Ring Oscillator PUFs (ROPUFs) to machine learning attacks. The challenge-response pairs (CRPs) data obtained from different ROPUFs is trained using different machine learning algorithms. From the study, it is found that the Artificial Neural Network (ANN) models can be used to train the ROPUFs with a training accuracy of 99.9% and a prediction accuracy of 62% when 5,000 CRPs are used for a <?TeX $(n \\times n)$?> challenge-response ROPUF. In this article, we assume a realistic situation where a small set of the CRP dataset (approximately 15% maximum) is unscrupulously obtained by the hacker. A prediction accuracy of 62% makes the PUF vulnerable to machine learning attacks. Therefore, a secondary goal of this article is the design of a ROPUF capable of thwarting machine learning modeling attacks. The modified XOR-inverter ROPUF drastically reduces the prediction accuracy from 62% to 13.1%, thus making it increasingly difficult for hackers to attack the ROPUF.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W3161306566",
    "type": "article"
  },
  {
    "title": "Quantization of Deep Neural Networks for Accurate Edge Computing",
    "doi": "https://doi.org/10.1145/3451211",
    "publication_date": "2021-06-30",
    "publication_year": 2021,
    "authors": "Wentao Chen; Hailong Qiu; Jian Zhuang; Chutong Zhang; Yu Hen Hu; Qing Lu; Tianchen Wang; Yiyu Shi; Meiping Huang; Xiaowei Xu",
    "corresponding_authors": "",
    "abstract": "Deep neural networks have demonstrated their great potential in recent years, exceeding the performance of human experts in a wide range of applications. Due to their large sizes, however, compression techniques such as weight quantization and pruning are usually applied before they can be accommodated on the edge. It is generally believed that quantization leads to performance degradation, and plenty of existing works have explored quantization strategies aiming at minimum accuracy loss. In this paper, we argue that quantization, which essentially imposes regularization on weight representations, can sometimes help to improve accuracy. We conduct comprehensive experiments on three widely used applications: fully connected network for biomedical image segmentation, convolutional neural network for image classification on ImageNet, and recurrent neural network for automatic speech recognition, and experimental results show that quantization can improve the accuracy by 1%, 1.95%, 4.23% on the three applications respectively with 3.5x-6.4x memory reduction.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W3174488167",
    "type": "article"
  },
  {
    "title": "Challenging the Security of Logic Locking Schemes in the Era of Deep Learning: A Neuroevolutionary Approach",
    "doi": "https://doi.org/10.1145/3431389",
    "publication_date": "2021-05-11",
    "publication_year": 2021,
    "authors": "Dominik Šišejković; Farhad Merchant; Lennart M. Reimann; Harshit Srivastava; Ahmed Hallawa; Rainer Leupers",
    "corresponding_authors": "",
    "abstract": "Logic locking is a prominent technique to protect the integrity of hardware designs throughout the integrated circuit design and fabrication flow. However, in recent years, the security of locking schemes has been thoroughly challenged by the introduction of various deobfuscation attacks. As in most research branches, deep learning is being introduced in the domain of logic locking as well. Therefore, in this article we present SnapShot, a novel attack on logic locking that is the first of its kind to utilize artificial neural networks to directly predict a key bit value from a locked synthesized gate-level netlist without using a golden reference. Hereby, the attack uses a simpler yet more flexible learning model compared to existing work. Two different approaches are evaluated. The first approach is based on a simple feedforward fully connected neural network. The second approach utilizes genetic algorithms to evolve more complex convolutional neural network architectures specialized for the given task. The attack flow offers a generic and customizable framework for attacking locking schemes using machine learning techniques. We perform an extensive evaluation of SnapShot for two realistic attack scenarios, comprising both reference combinational and sequential benchmark circuits as well as silicon-proven RISC-V core modules. The evaluation results show that SnapShot achieves an average key prediction accuracy of 82.60% for the selected attack scenario, with a significant performance increase of 10.49 percentage points compared to the state of the art. Moreover, SnapShot outperforms the existing technique on all evaluated benchmarks. The results indicate that the security foundation of common logic locking schemes is built on questionable assumptions. Based on the lessons learned, we discuss the vulnerabilities and potentials of logic locking uncovered by SnapShot. The conclusions offer insights into the challenges of designing future logic locking schemes that are resilient to machine learning attacks.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W3108642877",
    "type": "article"
  },
  {
    "title": "A Cost-Efficient Digital ESN Architecture on FPGA for OFDM Symbol Detection",
    "doi": "https://doi.org/10.1145/3440017",
    "publication_date": "2021-06-30",
    "publication_year": 2021,
    "authors": "Victor M. Gan; Yibin Liang; Lianjun Li; Lingjia Liu; Yang Yi",
    "corresponding_authors": "",
    "abstract": "The echo state network (ESN) is a recently developed machine-learning paradigm whose processing capabilities rely on the dynamical behavior of recurrent neural networks. Its performance outperforms traditional recurrent neural networks in nonlinear system identification and temporal information processing applications. We design and implement a cost-efficient ESN architecture on field-programmable gate array (FPGA) that explores the full capacity of digital signal processor blocks on low-cost and low-power FPGA hardware. Specifically, our scalable ESN architecture on FPGA exploits Xilinx DSP48E1 units to cut down the need of configurable logic blocks. The proposed architecture includes a linear combination processor with negligible deployment of configurable logic blocks and a high-accuracy nonlinear function approximator. Our work is verified with the prediction task on the classical NARMA dataset and a symbol detection task for orthogonal frequency division multiplexing systems using a wireless communication testbed built on a software-defined radio platform. Experiments and performance measurement show that the new ESN architecture is capable of processing real-world data efficiently for low-cost and low-power applications.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W3175607432",
    "type": "article"
  },
  {
    "title": "BPLight-CNN: A Photonics-Based Backpropagation Accelerator for Deep Learning",
    "doi": "https://doi.org/10.1145/3446212",
    "publication_date": "2021-09-01",
    "publication_year": 2021,
    "authors": "Dharanidhar Dang; Sai Vineel Reddy Chittamuru; Sudeep Pasricha; Rabi Mahapatra; Debashis Sahoo",
    "corresponding_authors": "",
    "abstract": "Training deep learning networks involves continuous weight updates across the various layers of the deep network while using a backpropagation (BP) algorithm. This results in expensive computation overheads during training. Consequently, most deep learning accelerators today employ pretrained weights and focus only on improving the design of the inference phase. The recent trend is to build a complete deep learning accelerator by incorporating the training module. Such efforts require an ultra-fast chip architecture for executing the BP algorithm. In this article, we propose a novel photonics-based backpropagation accelerator for high-performance deep learning training. We present the design for a convolutional neural network (CNN), BPLight-CNN , which incorporates the silicon photonics-based backpropagation accelerator. BPLight-CNN is a first-of-its-kind photonic and memristor-based CNN architecture for end-to-end training and prediction. We evaluate BPLight-CNN using a photonic CAD framework (IPKISS) on deep learning benchmark models, including LeNet and VGG-Net. The proposed design achieves (i) at least 34× speedup, 34× improvement in computational efficiency, and 38.5× energy savings during training; and (ii) 29× speedup, 31× improvement in computational efficiency, and 38.7× improvement in energy savings during inference compared with the state-of-the-art designs. All of these comparisons are done at a 16-bit resolution, and BPLight-CNN achieves these improvements at a cost of approximately 6% lower accuracy compared with the state-of-the-art.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W3197256510",
    "type": "article"
  },
  {
    "title": "Analyzing Security Vulnerabilities Induced by High-level Synthesis",
    "doi": "https://doi.org/10.1145/3492345",
    "publication_date": "2022-01-29",
    "publication_year": 2022,
    "authors": "Nitin Pundir; Sohrab Aftabjahani; Rosario Cammarota; Mark Tehranipoor; Farimah Farahmandi",
    "corresponding_authors": "",
    "abstract": "High-level synthesis (HLS) is essential to map the high-level language (HLL) description (e.g., in C/C++) of hardware design to the corresponding Register Transfer Level (RTL) to produce hardware-independent design specifications with reduced design complexity for ASICs and FPGAs. Adopting HLS is crucial for industrial and government applications to lower development costs, verification efforts, and time-to-market. Current research practices focus on optimizing HLS for performance, power, and area constraints. However, the literature does not include an analysis of the security implications carried through HLS-generated RTL translations (e.g., from an untimed high-level sequential specification to a fully scheduled implementation). This article demonstrates the evidence of security vulnerabilities that emerge during the HLS translation of a high-level description of system-on-chip (SoC) intellectual properties to their corresponding RTL. The evidence provided in this manuscript highlights the need for (a) guidelines for high-level programmers to prevent these security issues at the design time and (b) automated HLS verification solutions that cover security in their optimization flow.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W4210484106",
    "type": "article"
  },
  {
    "title": "Towards Energy-Efficient Spiking Neural Networks: A Robust Hybrid CMOS-Memristive Accelerator",
    "doi": "https://doi.org/10.1145/3635165",
    "publication_date": "2023-12-05",
    "publication_year": 2023,
    "authors": "Fabiha Nowshin; Hongyu An; Yang Yi",
    "corresponding_authors": "",
    "abstract": "Spiking Neural Networks (SNNs) are energy-efficient artificial neural network models that can carry out data-intensive applications. Energy consumption, latency, and memory bottleneck are some of the major issues that arise in machine learning applications due to their data-demanding nature. Memristor-enabled Computing-In-Memory (CIM) architectures have been able to tackle the memory wall issue, eliminating the energy and time-consuming movement of data. In this work we develop a scalable CIM-based SNN architecture with our fabricated two-layer memristor crossbar array. In addition to having an enhanced heat dissipation capability, our memristor exhibits substantial enhancement of 10% to 66% in design area, power and latency compared to state-of-the-art memristors. This design incorporates an inter-spike interval (ISI) encoding scheme due to its high information density to convert the incoming input signals into spikes. Furthermore, we include a time-to-first-spike (TTFS) based output processing stage for its energy-efficiency to carry out the final classification. With the combination of ISI, CIM and TTFS, this network has a competitive inference speed of 2μs/image and can successfully classify handwritten digits with 2.9mW of power and 2.51pJ energy per spike. The proposed architecture with the ISI encoding scheme can achieve ∼10% higher accuracy than those of other encoding schemes in the MNIST dataset.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W4389337989",
    "type": "article"
  },
  {
    "title": "Evolutionary functional recovery in virtual reconfigurable circuits",
    "doi": "https://doi.org/10.1145/1265949.1265954",
    "publication_date": "2007-07-01",
    "publication_year": 2007,
    "authors": "Lukáš Sekanina",
    "corresponding_authors": "Lukáš Sekanina",
    "abstract": "A virtual reconfigurable circuit (VRC) is a domain-specific reconfigurable device developed using an ordinary FPGA in order to easily implement evolvable hardware applications. While a fast partial runtime reconfiguration and application-specific programmable elements represent the main advantages of VRC, the main disadvantage of the VRC is the area consumed. This study describes experiments conducted to estimate how the use of VRC influences the dependability of FPGA-based evolvable systems. It is shown that these systems are not as sensitive to faults as their area-demanding implementations might suggest. An evolutionary algorithm is utilized to design fault tolerant circuits as well as to perform an automatic functional recovery when faults are detected in the configuration memory of the FPGA. All the experiments are performed on models of reconfigurable devices.",
    "cited_by_count": 25,
    "openalex_id": "https://openalex.org/W2021333661",
    "type": "article"
  },
  {
    "title": "Multilayer stacking technology using wafer-to-wafer stacked method",
    "doi": "https://doi.org/10.1145/1412587.1412593",
    "publication_date": "2008-10-01",
    "publication_year": 2008,
    "authors": "N. Miyakawa; Eiri Hashimoto; Takanori Maebashi; Natsuo Nakamura; Yutaka Sacho; Shigeto Nakayama; Shinjiro Toyoda",
    "corresponding_authors": "",
    "abstract": "We have developed a new three-dimensional stacking technology using the wafer-to-wafer stacked method. Electrical conductivity between each wafer is almost 100% and contact resistance is less than 0.7Ω between a through-silicon via (TSV) and a microbump. We have also created a prototype of a three-layer stacking device using our technology, where each wafer for the stacking is fabricated by using 0.18um CMOS technology based on 8-inch wafers. The device is operated by two times the frequency of the multichip module (MCM) device case using a two-dimensional device with identical functions and minimally different power consumption. The yields obtained from the results comprising all functional tests are over 60%.",
    "cited_by_count": 24,
    "openalex_id": "https://openalex.org/W2017707213",
    "type": "article"
  },
  {
    "title": "Low-power FinFET circuit synthesis using multiple supply and threshold voltages",
    "doi": "https://doi.org/10.1145/1543438.1543440",
    "publication_date": "2009-07-01",
    "publication_year": 2009,
    "authors": "Prateek Mishra; Anish Muttreja; Niraj K. Jha",
    "corresponding_authors": "",
    "abstract": "According to Moore's law, the number of transistors in a chip doubles every 18 months. The increased transistor-count leads to increased power density. Thus, in modern circuits, power efficiency is a central determinant of circuit efficiency. With scaling, leakage power accounts for an increasingly larger portion of the total power consumption in deep submicron technologies (&gt;40%). FinFET technology has been proposed as a promising alternative to deep submicron bulk CMOS technology, because of its better scalability, short-channel characteristics, and ability to suppress leakage current and mitigate device-to-device variability when compared to bulk CMOS. The subthreshold slope of a FinFET is approximately 60mV which is close to ideal. In this article, we propose a methodology for low-power FinFET based circuit synthesis. A mechanism called TCMS (Threshold Control through Multiple Supply Voltages) was previously proposed for improving the power efficiency of FinFET based global interconnects. We propose a significant generalization of TCMS to the design of any logic circuit. This scheme represents a significant divergence from the conventional multiple supply voltage schemes considered in the past. It also obviates the need for voltage level-converters. We employ accurate delay and power estimates using table look-up methods based on HSPICE simulations for supply voltage and threshold voltage optimization. Experimental results demonstrate that TCMS can provide power savings of 67.6% and device area savings of 65.2% under relaxed delay constraints. Two other variants of TCMS are also proposed that yield similar benefits. We compare our scheme to extended cluster voltage scaling (ECVS), a popular dual- V dd scheme presented in the literature. ECVS makes use of voltage level-converters. Even when it is assumed that these level-converters have zero delay, thus significantly favoring ECVS in time-constrained power optimization, TCMS still outperforms ECVS.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W2109596500",
    "type": "article"
  },
  {
    "title": "Efficient parallel testing and diagnosis of digital microfluidic biochips",
    "doi": "https://doi.org/10.1145/1543438.1543443",
    "publication_date": "2009-07-01",
    "publication_year": 2009,
    "authors": "Siddhartha Datta; Bharat Joshi; Arun Ravindran; Arindam Mukherjee",
    "corresponding_authors": "",
    "abstract": "Microfluidics-based biochips consist of microfluidic arrays on rigid substrates through which movement of fluids is tightly controlled to facilitate biological reactions. Biochips are soon expected to revolutionize biosensing, clinical diagnostics, environmental monitoring, and drug discovery. Critical to the deployment of the biochips in such diverse areas is the dependability of these systems. Thus robust testing and diagnosis techniques are required to ensure adequate level of system dependability. Due to the underlying mixed technology and mixed energy domains, such biochips exhibit unique failure mechanisms and defects. In this article efficient parallel testing and diagnosis algorithms are presented that can detect and locate single as well as multiple faults in a microfluidic array without flooding the array, a problem that has hampered realistic implementation of several existing strategies. The fault diagnosis algorithms are well suited for built-in self-test that could drastically reduce the operating cost of microfluidic biochip. Also, the proposed alogirthms can be used both for testing and fault diagnosis during field operation as well as increasing yield during the manufacturing phase of the biochip. Furthermore, these algorithms can be applied to both online and offline testing and diagnosis. Analytical results suggest that these strategies that can be used to design highly dependable biochip systems.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W2036791269",
    "type": "article"
  },
  {
    "title": "Efficient Hardware Implementation of Cellular Neural Networks with Incremental Quantization and Early Exit",
    "doi": "https://doi.org/10.1145/3264817",
    "publication_date": "2018-10-31",
    "publication_year": 2018,
    "authors": "Xiaowei Xu; Qing Lu; Tianchen Wang; Yu Hen Hu; Zhuo Chen; Jinglan Liu; Yiyu Shi",
    "corresponding_authors": "",
    "abstract": "Cellular neural networks (CeNNs) have been widely adopted in image processing tasks. Recently, various hardware implementations of CeNNs have emerged in the literature, with Field Programmable Gate Array (FPGA) being one of the most popular choices due to its high flexibility and low time-to-market. However, CeNNs typically involve extensive computations in a recursive manner. As an example, to simply process an image of 1,920 × 1,080 pixels requires 4--8 Giga floating point multiplications (for 3 × 3 templates and 50–100 iterations), which needs to be done in a timely manner for real-time applications. To address this issue, in this article, we propose a compressed CeNN framework for efficient FPGA implementations. It involves various techniques, such as incremental quantization and early exit, which significantly reduces computation demands while maintaining an acceptable performance. Particularly, incremental quantization quantizes the numbers in CeNN templates to powers of two, so that complex and expensive multiplications can be converted to simple and cheap shift operations, which only require a minimum number of registers and logical elements (LEs). While a similar concept has been explored in hardware implementations of Convolutional Neural Networks (CNNs), CeNNs have completely different computation patterns, which require different quantization and implementation strategies. Experimental results on FPGAs show that incremental quantization and early exit can achieve a speedup of up to 7.8× and 8.3×, respectively, compared with the state-of-the-art implementations, while with almost no performance loss with four widely adopted applications. We also discover that different from CNNs, the optimal quantization strategies of CeNNs depend heavily on the applications. We hope that our work can serve as a pioneer in the hardware optimization of CeNNs.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W2902267152",
    "type": "article"
  },
  {
    "title": "A Resource-Efficient Design for a Reversible Floating Point Adder in Quantum Computing",
    "doi": "https://doi.org/10.1145/2629525",
    "publication_date": "2014-11-18",
    "publication_year": 2014,
    "authors": "Trung Duc Nguyen; Rodney Van Meter",
    "corresponding_authors": "",
    "abstract": "Reversible logic has applications in low-power computing and quantum computing. However, there are few existing designs for reversible floating-point adders and none suitable for quantum computation. In this article, we propose a resource-efficient reversible floating-point adder, suitable for binary quantum computation, improving the design of Nachtigal et al. [2011]. Our work focuses on improving the reversible designs of the alignment unit and the normalization unit, which are the most expensive parts. By changing a few elements of the existing algorithm, including the circuit designs of the RLZC (reversible leading zero counter) and converter, we have reduced the cost by about 68%. We also propose quantum designs adapted to use gates from fault-tolerant libraries. The KQ for our fault-tolerant design is almost 60 times as expensive as for a 32-bit fixed-point addition. We note that the floating-point representation makes in-place, truly reversible arithmetic impossible, requiring us to retain both inputs, which limits the sustainability of its use for quantum computation.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W2072976978",
    "type": "article"
  },
  {
    "title": "A Write-Aware STTRAM-Based Register File Architecture for GPGPU",
    "doi": "https://doi.org/10.1145/2700230",
    "publication_date": "2015-08-03",
    "publication_year": 2015,
    "authors": "Jue Wang; Yuan Xie",
    "corresponding_authors": "",
    "abstract": "The massively parallel processing capacity of GPGPUs requires a large register file (RF), and its size keeps increasing to support more concurrent threads from generation to generation. Using traditional SRAM-based RFs, there are concerns in both area cost and energy consumption, and soon they will become unrealistic. In this work, we analyze the feasibility of using STTRAM-based RF designs, which have benefits in terms of smaller silicon area and zero standby leakage power. However, STTRAM long write latency and high write energy bring new challenges. Therefore, we propose a write-aware STTRAM-based RF architecture (WarRF), which contains two techniques: Split Bank Write modifies the arbitrator design to increase the parallelism of read and write accesses in the same bank; Write Pool reduces the number of repeated write accesses to RFs. Our experiment shows that the performance of STTRAM-based RF is improved by 13% and up to 23% after adopting WarRF. In addition, the energy consumption is reduced by 38% on average compared to SRAM-based RFs.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W2203111322",
    "type": "article"
  },
  {
    "title": "FinFET-Based Low-Swing Clocking",
    "doi": "https://doi.org/10.1145/2701617",
    "publication_date": "2015-09-02",
    "publication_year": 2015,
    "authors": "Can Sitik; Emre Salman; Leo Filippini; Sung Jun Yoon; Barış Taşkın",
    "corresponding_authors": "",
    "abstract": "A low-swing clocking methodology is introduced to achieve low-power operation at 20nm FinFET technology. Low-swing clock trees are used in existing methodologies in order to decrease the dynamic power consumption in a trade-off for 3 issues: (1) the effect of leakage power consumption, which is becoming more dominant when the process scales sub-32nm; (2) the increase in insertion delay, resulting in a high clock skew; and (3) the difficulty in driving the existing DFF sinks with a low-swing clock signal without a timing violation. In this article, a FinFET-based low-swing clocking methodology is introduced to preserve the dynamic power savings of low-swing clocking while minimizing these three negative effects, facilitated through an efficient use of FinFET technology. At scaled performance constraints, the proposed methodology at 20nm FinFET leads to 42% total power savings (clock network+DFF) compared to a FinFET-based full-swing counterpart at the same frequency (3 GHz), thanks to the dynamic power savings of low-swing clocking and 3% power savings compared to a CMOS-based low-swing implementation running at the half frequency (1.5 GHz), thanks to the leakage power savings of FinFET technology.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W2247480952",
    "type": "article"
  },
  {
    "title": "Energy-Neutral Design Framework for Supercapacitor-Based Autonomous Wireless Sensor Networks",
    "doi": "https://doi.org/10.1145/2787512",
    "publication_date": "2015-09-02",
    "publication_year": 2015,
    "authors": "Trong Nhan Le; Alain Pégatoquet; Olivier Berder; Olivier Sentieys; Arnaud Carer",
    "corresponding_authors": "",
    "abstract": "To design autonomous wireless sensor networks (WSNs) with a theoretical infinite lifetime, energy harvesting (EH) techniques have been recently considered as promising approaches. Ambient sources can provide everlasting additional energy for WSN nodes and exclude their dependence on battery. In this article, an efficient energy harvesting system which is compatible with various environmental sources, such as light, heat, or wind energy, is proposed. Our platform takes advantage of double-level capacitors not only to prolong system lifetime but also to enable robust booting from the exhausting energy of the system. Simulations and experiments show that our multiple-energy-sources converter (MESC) can achive booting time in order of seconds. Although capacitors have virtual recharge cycles, they suffer higher leakage compared to rechargeable batteries. Increasing their size can decrease the system performance due to leakage energy. Therefore, an energy-neutral design framework providing a methodology to determine the minimum size of those storage devices satisfying energy-neutral operation (ENO) and maximizing system quality-of-service (QoS) in EH nodes, when using a given energy source, is proposed. Experiments validating this framework are performed on a real WSN platform with both photovoltaic cells and thermal generators in an indoor environment. Moreover, simulations on OMNET++ show that the energy storage optimized from our design framework is utilized up to 93.86%.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W2219184753",
    "type": "article"
  },
  {
    "title": "Spintronic PUFs for Security, Trust, and Authentication",
    "doi": "https://doi.org/10.1145/2809781",
    "publication_date": "2016-04-25",
    "publication_year": 2016,
    "authors": "Anirudh Iyengar; Swaroop Ghosh; Kenneth Ramclam; Jae-Won Jang; Cheng-Wei Lin",
    "corresponding_authors": "",
    "abstract": "We propose spintronic physically unclonable functions (PUFs) to exploit security-specific properties of domain wall memory (DWM) for security, trust, and authentication. We note that the nonlinear dynamics of domain walls (DWs) in the physical magnetic system is an untapped source of entropy that can be leveraged for hardware security. The spatial and temporal randomness in the physical system is employed in conjunction with microscopic and macroscopic properties such as stochastic DW motion, stochastic pinning/depinning, and serial access to realize novel relay-PUF and memory-PUF designs. The proposed PUFs show promising results (∼50% interdie Hamming distance (HD) and 10% to 20% intradie HD) in terms of randomness, stability, and resistance to attacks. We have investigated noninvasive attacks, such as machine learning and magnetic field attack, and have assessed the PUFs resilience.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W2344167703",
    "type": "article"
  },
  {
    "title": "Towards Synaptic Behavior of Nanoscale ReRAM Devices for Neuromorphic Computing Applications",
    "doi": "https://doi.org/10.1145/3381859",
    "publication_date": "2020-04-29",
    "publication_year": 2020,
    "authors": "Karsten Beckmann; Wilkie Olin-Ammentorp; Gangotree Chakma; Sherif Amer; Garrett S. Rose; Chris Hobbs; Joseph Van Nostrand; Martin Rodgers; Nathaniel C. Cady",
    "corresponding_authors": "",
    "abstract": "Resistive Random Access Memory (ReRAM), a form of non-volatile memory, has been proposed as a Flash memory replacement. In addition, novel circuit architectures have been proposed that rely on newly discovered or predicted behavior of ReRAM. One such architecture is the memristive Dynamic Adaptive Neural Network Array, developed to emulate the functionality of a biological neuron system. We demonstrated ReRAM devices that show a synaptic tendency by changing their resistance in an analog fashion. The CMOS compatible nanoscale ReRAM devices shown are based on an HfO 2 switching layer that sits on a tungsten electrode and is covered by a titanium oxygen scavenger layer and a titanium nitride top electrode. In this work, we showed devices exceeding endurance values of 10B cycles with a discrete R off /R on ratio of 15. Multi-level states were achieved by using consecutive ultra-short 5/1.5 ns pulses during the reset operation. A neural network simulation was performed in which the synaptic weights were perturbed with the ReRAM variability, which was extracted from two different characterization methods: (1) via direct write, and (2) via a write/read verification approach during the reset operation. A substantial improvement of the neural network fitness was demonstrated when using the write/read verification approach.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W3033300315",
    "type": "article"
  },
  {
    "title": "Sparse BD-Net",
    "doi": "https://doi.org/10.1145/3369391",
    "publication_date": "2020-01-30",
    "publication_year": 2020,
    "authors": "Zhezhi He; Li Yang; Shaahin Angizi; Adnan Siraj Rakin; Deliang Fan",
    "corresponding_authors": "",
    "abstract": "In this work, we propose a multiplication-less binarized depthwise-separable convolution neural network, called BD-Net. BD-Net is designed to use binarized depthwise separable convolution block as the drop-in replacement of conventional spatial-convolution in deep convolution neural network (DNN). In BD-Net, the computation-expensive convolution operations (i.e., Multiplication and Accumulation) are converted into energy-efficient Addition/Subtraction operations. For further compressing the model size while maintaining the dominant computation in addition/subtraction, we propose a brand-new sparse binarization method with a hardware-oriented structured sparsity pattern. To successfully train such sparse BD-Net, we propose and leverage two techniques: (1) a modified group-lasso regularization whose group size is identical to the capacity of basic computing core in accelerator and (2) a weight penalty clipping technique to solve the disharmony issue between weight binarization and lasso regularization. The experiment results show that the proposed sparse BD-Net can achieve comparable or even better inference accuracy, in comparison to the full precision CNN baseline. Beyond that, a BD-Net customized process-in-memory accelerator is designed using SOT-MRAM, which owns characteristics of high channel expansion flexibility and computation parallelism. Through the detailed analysis from both software and hardware perspectives, we provide an intuitive design guidance for software/hardware co-design of DNN acceleration on mobile embedded systems. Note that this journal submission is the extended version of our previous published paper in ISVLSI 2018 [24].",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W3009123798",
    "type": "article"
  },
  {
    "title": "Direction-aggregated Attack for Transferable Adversarial Examples",
    "doi": "https://doi.org/10.1145/3501769",
    "publication_date": "2022-02-02",
    "publication_year": 2022,
    "authors": "Tianjin Huang; Vlado Menkovski; Yulong Pei; Yuhao Wang; Mykola Pechenizkiy",
    "corresponding_authors": "",
    "abstract": "Deep neural networks are vulnerable to adversarial examples that are crafted by imposing imperceptible changes to the inputs. However, these adversarial examples are most successful in white-box settings where the model and its parameters are available. Finding adversarial examples that are transferable to other models or developed in a black-box setting is significantly more difficult. In this article, we propose the Direction-aggregated adversarial attacks that deliver transferable adversarial examples. Our method utilizes the aggregated direction during the attack process for avoiding the generated adversarial examples overfitting to the white-box model. Extensive experiments on ImageNet show that our proposed method improves the transferability of adversarial examples significantly and outperforms state-of-the-art attacks, especially against adversarial trained models. The best averaged attack success rate of our proposed method reaches 94.6% against three adversarial trained models and 94.8% against five defense methods. It also reveals that current defense approaches do not prevent transferable adversarial attacks.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W3156525504",
    "type": "article"
  },
  {
    "title": "MNEMOSENE: Tile Architecture and Simulator for Memristor-based Computation-in-memory",
    "doi": "https://doi.org/10.1145/3485824",
    "publication_date": "2022-01-29",
    "publication_year": 2022,
    "authors": "Mahdi Zahedi; Muah Abu Lebdeh; Christopher Bengel; Dirk J. Wouters; Stephan Menzel; Manuel Le Gallo; Abu Sebastian; Stephan Wong; Said Hamdioui",
    "corresponding_authors": "",
    "abstract": "In recent years, we are witnessing a trend toward in-memory computing for future generations of computers that differs from traditional von-Neumann architecture in which there is a clear distinction between computing and memory units. Considering that data movements between the central processing unit (CPU) and memory consume several orders of magnitude more energy compared to simple arithmetic operations in the CPU, in-memory computing will lead to huge energy savings as data no longer needs to be moved around between these units. In an initial step toward this goal, new non-volatile memory technologies, e.g., resistive RAM (ReRAM) and phase-change memory (PCM), are being explored. This has led to a large body of research that mainly focuses on the design of the memory array and its peripheral circuitry. In this article, we mainly focus on the tile architecture (comprising a memory array and peripheral circuitry) in which storage and compute operations are performed in the (analog) memory array and the results are produced in the (digital) periphery. Such an architecture is termed compute-in-memory-periphery (CIM-P). More precisely, we derive an abstract CIM-tile architecture and define its main building blocks. To bridge the gap between higher-level programming languages and the underlying (analog) circuit designs, an instruction-set architecture is defined that is intended to control and, in turn, sequence the operations within this CIM tile to perform higher-level more complex operations. Moreover, we define a procedure to pipeline the CIM-tile operations to further improve the performance. To simulate the tile and perform design space exploration considering different technologies and parameters, we introduce the fully parameterized first-of-its-kind CIM tile simulator and compiler. Furthermore, the compiler is technology-aware when scheduling the CIM-tile instructions. Finally, using the simulator, we perform several preliminary design space explorations regarding the three competing technologies, ReRAM, PCM, and STT-MRAM concerning CIM-tile parameters, e.g., the number of ADCs. Additionally, we investigate the effect of pipelining in relation to the clock speeds of the digital periphery assuming the three technologies. In the end, we demonstrate that our simulator is also capable of reporting energy consumption for each building block within the CIM tile after the execution of in-memory kernels considering the data-dependency on the energy consumption of the memory array. All the source codes are publicly available.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W4210322041",
    "type": "article"
  },
  {
    "title": "EVHA: Explainable Vision System for Hardware Testing and Assurance—An Overview",
    "doi": "https://doi.org/10.1145/3590772",
    "publication_date": "2023-04-08",
    "publication_year": 2023,
    "authors": "Md Mahfuz Al Hasan; Mohammad Tahsin Mostafiz; Thomas An Le; Jake Julia; Nidish Vashistha; Shayan Taheri; Navid Asadizanjani",
    "corresponding_authors": "",
    "abstract": "Due to the ever-growing demands for electronic chips in different sectors, semiconductor companies have been mandated to offshore their manufacturing processes. This unwanted matter has made security and trustworthiness of their fabricated chips concerning and has caused the creation of hardware attacks. In this condition, different entities in the semiconductor supply chain can act maliciously and execute an attack on the design computing layers, from devices to systems. Our attack is a hardware Trojan that is inserted during mask generation/fabrication in an untrusted foundry. The Trojan leaves a footprint in the fabrication through addition, deletion, or change of design cells. To tackle this problem, we propose EVHA (Explainable Vision System for Hardware Testing and Assurance) in this work, which can detect the smallest possible change to a design in a low-cost, accurate, and fast manner. The inputs to this system are scanning electron microscopy images acquired from the integrated circuits under examination. The system output is the determination of integrated circuit status in terms of having any defect and/or hardware Trojan through addition, deletion, or change in the design cells at the cell level. This article provides an overview on the design, development, implementation, and analysis of our defense system.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W4362722341",
    "type": "article"
  },
  {
    "title": "Hardware IP Assurance against Trojan Attacks with Machine Learning and Post-processing",
    "doi": "https://doi.org/10.1145/3592795",
    "publication_date": "2023-04-18",
    "publication_year": 2023,
    "authors": "Pravin Gaikwad; Jonathan Cruz; Prabuddha Chakraborty; Swarup Bhunia; Tamzidul Hoque",
    "corresponding_authors": "",
    "abstract": "System-on-chip (SoC) developers increasingly rely on pre-verified hardware intellectual property (IP) blocks often acquired from untrusted third-party vendors. These IPs might contain hidden malicious functionalities or hardware Trojans that may compromise the security of the fabricated SoCs. Lack of golden or reference models and vast possible Trojan attack space form some of the major barriers in detecting hardware Trojans in these third-party IP (3PIP) blocks. Recently, supervised machine learning (ML) techniques have shown promising capability in identifying nets of potential Trojans in 3PIPs without the need for golden models. However, they bring several major challenges. First, they do not guide us to an optimal choice of features that reliably covers diverse classes of Trojans. Second, they require multiple Trojan-free/trusted designs to insert known Trojans and generate a trained model. Even if a set of trusted designs are available for training, the suspect IP can have an inherently very different structure from the set of trusted designs, which may negatively impact the verification outcome. Third, these techniques only identify a set of suspect Trojan nets that require manual intervention to understand the potential threat. In this article, we present VIPR, a systematic machine learning (ML)-based trust verification solution for 3PIPs that eliminates the need for trusted designs for training. We present a comprehensive framework, associated algorithms, and a tool flow for obtaining an optimal set of features, training a targeted machine learning model, detecting suspect nets, and identifying Trojan circuitry from the suspect nets. We evaluate the framework on several Trust-Hub Trojan benchmarks and provide a comparative analysis of detection performance across different trained models, selection of features, and post-processing techniques. We demonstrate promising Trojan detection accuracy for VIPR with up to 92.85% reduction in false positives by the proposed post-processing algorithm.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W4366274271",
    "type": "article"
  },
  {
    "title": "Securing Network-on-chips Against Fault-injection and Crypto-analysis Attacks via Stochastic Anonymous Routing",
    "doi": "https://doi.org/10.1145/3592798",
    "publication_date": "2023-04-18",
    "publication_year": 2023,
    "authors": "Ahmad Patooghy; Mahdi Hasanzadeh; Amin Sarihi; Mostafa Abdelrehim; Abdel‐Hameed A. Badawy",
    "corresponding_authors": "",
    "abstract": "Network-on-chip (NoC) is widely used as an efficient communication architecture in multi-core and many-core System-on-chips (SoCs). However, the shared communication resources in an NoC platform, e.g., channels, buffers, and routers, might be used to conduct attacks compromising the security of NoC-based SoCs. Most of the proposed encryption-based protection methods in the literature require leaving some parts of the packet unencrypted to allow the routers to process/forward packets accordingly. This reveals the source/destination information of the packet to malicious routers, which can be exploited in various attacks. For the first time, we propose the idea of secure, anonymous routing with minimal hardware overhead to encrypt the entire packet while exchanging secure information over the network. We have designed and implemented a new NoC architecture that works with encrypted addresses. The proposed method can manage malicious and benign failures at NoC channels and buffers by bypassing failed components with a situation-driven stochastic path diversification approach. Hardware evaluations show that the proposed security solution combats the security threats at the affordable cost of 1.5% area and 20% power overheads chip-wide.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W4366275315",
    "type": "article"
  },
  {
    "title": "Yield enhancement of reconfigurable microfluidics-based biochips using interstitial redundancy",
    "doi": "https://doi.org/10.1145/1148015.1148017",
    "publication_date": "2006-04-01",
    "publication_year": 2006,
    "authors": "Fei Su; Krishnendu Chakrabarty",
    "corresponding_authors": "",
    "abstract": "Microfluidics-based biochips for biochemical analysis are currently receiving much attention. They automate highly repetitive laboratory procedures by replacing cumbersome equipment with miniaturized and integrated systems. As these microfluidics-based microsystems become more complex, manufacturing yield will have significant influence on production volume and product cost. We propose an interstitial redundancy approach to enhance the yield of biochips that are based on droplet-based digital microfluidics. In this design method, spare cells are placed in the interstitial sites within the microfluidic array, and they replace neighboring faulty cells via local reconfiguration. The proposed design method is evaluated using a set of concurrent real-life bioassays. The defect-tolerant design approach based on space redundancy and local reconfiguration is expected to facilitate yield enhancement of microfluidics-based biochips, especially for the emerging marketplace.",
    "cited_by_count": 25,
    "openalex_id": "https://openalex.org/W2051963132",
    "type": "article"
  },
  {
    "title": "Self-replicating hardware for reliability",
    "doi": "https://doi.org/10.1145/1265949.1265955",
    "publication_date": "2007-07-01",
    "publication_year": 2007,
    "authors": "Gianluca Tempesti; Daniel Mange; Pierre-André Mudry; Joël S. Rossier; André Stauffer",
    "corresponding_authors": "",
    "abstract": "The multicellular structure of biological organisms and the interpretation in each of their cells of a chemical program (the DNA string or genome ) is the source of inspiration for the Embryonics (embryonic electronics) project, whose final objective is the design of highly robust integrated circuits, endowed with properties usually associated with the living world: self-repair and self-replication. In this article, we provide an overview of our latest research in the domain of the self-replication of processing elements within a programmable logic substrate, a key prerequisite for achieving system-level fault tolerance in our bio-inspired approach.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W2052795668",
    "type": "article"
  },
  {
    "title": "A hybrid nano/CMOS dynamically reconfigurable system—Part I",
    "doi": "https://doi.org/10.1145/1629091.1629092",
    "publication_date": "2009-11-01",
    "publication_year": 2009,
    "authors": "Wei Zhang; Niraj K. Jha; Li Shang",
    "corresponding_authors": "",
    "abstract": "Rapid progress on nanodevices points to a promising direction for future circuit design. However, since nanofabrication techniques are not yet mature, implementation of nanocircuits, at least on a large scale, in the near future is infeasible. To ease fabrication and overcome the problem of high defect levels in nanotechnology, hybrid nano/CMOS reconfigurable architectures are attractive choices. Moreover, if the current photolithography fabrication process can be used to manufacture the hybrid chips, the benefits of nanotechnologies can be realized today. Traditional reconfigurable architectures can only support partial or coarse-grain runtime reconfiguration due to their limited on-chip storage and long off-chip reconfiguration latency. Recent progress on nano Random Access Memories (RAMs), such as carbon nanotube-based RAM (NRAM), Phase-Change Memory (PCM), magnetoresistive RAM (MRAM), etc., provides us with a chance to realize on-chip fine-grain runtime reconfiguration. These nano RAMs have good compatibility with the current fabrication process. By utilizing them in the hybrid design, we can take advantage of both CMOS and nanotechnology, and greatly improve the logic density, resource utilization, and performance of our design. In this article, we propose a high-performance reconfigurable architecture, called NATURE, that utilizes CMOS logic and nano RAMs. An automatic design flow for NATURE is presented in Part II of the article. In NATURE, the highly dense nonvolatile nano RAMs are distributed throughout the chip to allow large embedded on-chip configuration storage, which enables fast reading and hence supports fine-grain runtime reconfiguration and temporal logic folding of a circuit before being mapped to the architecture. Temporal logic folding can significantly increase the logic density of NATURE (by over an order of magnitude for large circuits) while remaining competitive in performance and power consumption. For ease of exposition, we use NRAMs to illustrate various concepts in this article due to the excellent properties of NRAMs. However, other nano RAMs can also be used instead. Experimental results based on NRAMs establish the efficacy of NATURE.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W1982744085",
    "type": "article"
  },
  {
    "title": "Complex network-enabled robust wireless network-on-chip architectures",
    "doi": "https://doi.org/10.1145/2491676",
    "publication_date": "2013-09-01",
    "publication_year": 2013,
    "authors": "Paul Wettin; Anuroop Vidapalapati; Amlan Gangul; Partha Pratim Pande",
    "corresponding_authors": "",
    "abstract": "The Network-on-Chip (NoC) paradigm has emerged as a scalable interconnection infrastructure for modern multicore chips. However, with growing levels of integration, the traditional NoCs suffer from high latency and energy dissipation in on-chip data transfer due to conventional multihop metal/dielectric-based interconnects. Three-dimensional integration, on-chip photonics, RF, and wireless links have been proposed as radical low-power and low-latency alternatives to the conventional planar wire-based designs. Wireless NoCs with Carbon NanoTube (CNT) antennas are shown to outperform traditional wire-based NoCs significantly in achievable data rate and energy dissipation. However, such emerging and transformative technologies will be prone to high levels of failures due to various issues related to manufacturing challenges and integration. On the other hand, several naturally occurring complex networks such as colonies of microbes and the World Wide Web are known to be inherently robust against high rates of failures and harsh environments. This article advocates adoption of such complex network-based architectures to minimize the effect of wireless link failures on the performance of the NoC. Through cycle-accurate simulations it is shown that the wireless NoC architectures inspired by natural complex networks perform better than their conventional wired counterparts even in the presence of high degrees of link failures. We demonstrate the robustness of the proposed wireless NoC architecture by incorporating both uniform and application-specific traffic patterns.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W1991493852",
    "type": "article"
  },
  {
    "title": "Defect-Aware Nanocrossbar Logic Mapping through Matrix Canonization Using Two-Dimensional Radix Sort",
    "doi": "https://doi.org/10.1145/2000502.2000505",
    "publication_date": "2011-08-01",
    "publication_year": 2011,
    "authors": "Sezer Gören; H. Fatih Uğurdağ; Okan Palaz",
    "corresponding_authors": "",
    "abstract": "Nanocrossbars (i.e., nanowire crossbars) offer extreme logic densities but come with very high defect rates; stuck-open/closed, broken nanowires. Achieving reasonable yield and utilization requires logic mapping that is defect-aware even at the crosspoint level. Such logic mapping works with a defect map per each manufactured chip. The problem can be expressed as matching of two bipartite graphs; one for the logic to be implemented and other for the nanocrossbar. This article shows that the problem becomes a Bipartite SubGraph Isomorphism (BSGI) problem within sub-nanocrossbars free of stuck-closed faults. Our heuristic KNS-2DS is an iterative rough canonizer with approximately O(N 2 ) complexity followed by an O(N 3 ) matching algorithm. Canonization brings a partial or full order to graph nodes. It is normally used for solving the regular Graph Isomorphism (GI) problem, while we apply it to BSGI. KNS stands for K-Neighbor Sort and is used for initializing our main contribution 2-Dimensional-Sort (2DS). 2DS operates on the adjacency matrix of a bipartite graph. Radix-2 2DS solves the problem in the absence of stuck-closed faults. With the addition of Radix-3 and our novel Radix-2.5 sort, we solve problems that also have stuck-closed faults. We offer very short runtimes (due to canonization) compared to previous work and have success on all benchmarks. KNS-2DS is also novel from the perspective of BSGI problem as it is based on canonization but not on a search tree with backtracking.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W1997313523",
    "type": "article"
  },
  {
    "title": "FinFET-Based Power Management for Improved DPA Resistance with Low Overhead",
    "doi": "https://doi.org/10.1145/2000502.2000503",
    "publication_date": "2011-08-01",
    "publication_year": 2011,
    "authors": "Meng Zhang; Niraj K. Jha",
    "corresponding_authors": "",
    "abstract": "Differential power analysis (DPA) is a side-channel attack that statistically analyzes the power consumption of a cryptographic system to obtain secret information. This type of attack is well known as a major threat to information security. Effective solutions with low energy and area cost for improved DPA resistance are urgently needed, especially for energy-constrained modern devices that are often in the physical proximity of attackers. This article presents a novel countermeasure against DPA attacks on smart cards and other digital ICs based on FinFETs, an emerging substitute for bulk CMOS at the 22nm technology node and beyond. We exploit the adaptive power management characteristic of FinFETs to generate a high level of noise at critical moments in the execution of a cryptosystem to thwart DPA attacks. We demonstrate the effectiveness of the proposed countermeasure by developing a simple power model for estimating DPA spikes. We then validate the model by carrying out DPA attacks on an ASIC implementation of the advanced encryption standard system via gate-level simulation. Both modeling and simulation-based experiment indicate that with the proposed countermeasure, even 8,000,000 power acquisitions are not sufficient to reveal the secret key. As opposed to other countermeasures presented in the literature, the proposed hardware design requires less than 1% increase in area and 15% increase in total energy consumption without any extra delay in the critical path. The proposed method is generic and can be applied to other encryption algorithms as well.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W2068028694",
    "type": "article"
  },
  {
    "title": "DAHM",
    "doi": "https://doi.org/10.1145/2367736.2367745",
    "publication_date": "2012-10-01",
    "publication_year": 2012,
    "authors": "Zahra Abbasi; Tridib Mukherjee; Georgios Varsamopoulos; Sandeep K. S. Gupta",
    "corresponding_authors": "",
    "abstract": "Dynamic Application Hosting Management (DAHM) is proposed for geographically distributed data centers, which decides on the number of active servers and on the workload share of each data center. DAHM achieves cost-efficient application hosting by taking into account: (i) the spatio-temporal variation of energy cost, (ii) the data center computing and cooling energy efficiency, (iii) the live migration cost, and (iv) any SLA violations due to migration overhead or network delay. DAHM is modeled as fixed-charge min-cost flow and mixed integer programming for stateless and stateful applications, respectively, and it is shown NP-hard. We also develop heuristic algorithms and prove, when applications are stateless and servers have an identical power consumption model, that the approximation ratio on the minimum total cost is bounded by the number of data centers. Further, the heuristics are evaluated in a simulation study using realistic parameter data; compared to a performance-oriented application assignment, that is, hosting at the data center with the least delay, the potential cost savings of DAHM reaches 33%. The savings come from reducing the total number of active servers as well as leveraging the cost efficiency of data centers. Through the simulation study, the article further explores how relaxing the delay requirement for a small fraction of users can increase the cost savings of DAHM.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W2141943900",
    "type": "article"
  },
  {
    "title": "ILP formulations for variation/defect-tolerant logic mapping on crossbar nano-architectures",
    "doi": "https://doi.org/10.1145/2491680",
    "publication_date": "2013-09-01",
    "publication_year": 2013,
    "authors": "Masoud Zamani; Hanieh Mirzaei; Mehdi B. Tahoori",
    "corresponding_authors": "",
    "abstract": "Several emerging nano-technologies, including crossbar nano-architectures, have recently been studied as possible replacement or supplement to CMOS technology in the future. However, extreme process variation and high failure rates, mainly due to atomic device sizes, are major challenges for crossbar nano-architectures. This article presents variation- and defect-tolerant logic mapping on crossbar nano-architectures. Since variation/defect-aware mapping is an NP-hard problem, we introduce a set of Integer Linear Programming (ILP) formulations to effectively solve the problem in a reasonable time. The proposed ILP formulations can be used for both diode-based and FET-based crossbars. Experimental results on benchmark circuits show that our approach can reduce the critical-path delay 39% compared to the Simulated Annealing (SA) method. It can also successfully achieve 97% defect-free mapping with 40% defect density. It can tolerate process variations to meet timing constraints in 95% of the cases, compared to only 77% achieved by SA.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W1978900825",
    "type": "article"
  },
  {
    "title": "Cell transformations and physical design techniques for 3D monolithic integrated circuits",
    "doi": "https://doi.org/10.1145/2491675",
    "publication_date": "2013-09-01",
    "publication_year": 2013,
    "authors": "Shashikanth Bobba; Ashutosh Chakraborty; Olivier Thomas; P. Batude; Giovanni De Micheli",
    "corresponding_authors": "",
    "abstract": "3D Monolithic Integration (3DMI), also termed as sequential integration, is a potential technology for future gigascale circuits. In 3DMI technology the 3D contacts, connecting different active layers, are in the order of few 100nm. Given the advantage of such small contacts, 3DMI enables fine-grain (gate-level) partitioning of circuits. In this work we present three cell transformation techniques for standard cell-based ICs with 3DMI technology. As a major contribution of this work, we propose a design flow comprising of a cell transformation technique, cell-on-cell stacking , and a physical design technique (CELONCEL PD ) aimed at placing cells transformed with cell-on-cell stacking. We analyze and compare various cell transformation techniques for 3DMI technology without disrupting the regularity of the IC design flow. Our experiments demonstrate the effectiveness of CELONCEL design technique, yielding us an area reduction of 37.5%, 16.2% average reduction in wirelength, and 6.2% average improvement in overall delay, compared with a 2D case when benchmarked across various designs in 45nm technology node.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W1987597317",
    "type": "article"
  },
  {
    "title": "Exploring the vulnerability of CMPs to soft errors with 3D stacked nonvolatile memory",
    "doi": "https://doi.org/10.1145/2491679",
    "publication_date": "2013-09-01",
    "publication_year": 2013,
    "authors": "Guangyu Sun; Eren Kursun; Jude A. Rivers; Yuan Xie",
    "corresponding_authors": "",
    "abstract": "Improving the vulnerability to soft errors is one of the important design goals for future architecture design of Chip-MultiProcessors (CMPs). In this study, we explore the soft error characteristics of CMPs with 3D stacked NonVolatile Memory (NVM), in particular, the Spin-Transfer Torque Random Access Memory (STT-RAM), whose cells are immune to radiation-induced soft errors and do not have endurance problems. We use 3D stacking as an enabler for modular integration of STT-RAM memories with minimum disruption in the baseline processor design flow, while providing further interconnection and capacity advantages. We take an in-depth look at alternative replacement schemes to explore the soft error resilience benefits and design trade-offs of 3D stacked STT-RAM and capture the multivariable optimization challenges microprocessor architectures face. We propose a vulnerability metric, with respect to the instruction and data in the core pipeline and through the cache hierarchy, to present a comprehensive system evaluation with respect to reliability, performance, and power consumption for our CMP architectures. Our experimental results show that, for the average workload, replacing memories with an STT-RAM alternative significantly mitigates soft errors on-chip, improves the performance by 14.15%, and reduces power consumption by 13.44%.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W1994547903",
    "type": "article"
  },
  {
    "title": "Fluigi",
    "doi": "https://doi.org/10.1145/2660773",
    "publication_date": "2014-12-30",
    "publication_year": 2014,
    "authors": "Haiyao Huang; Douglas Densmore",
    "corresponding_authors": "",
    "abstract": "One goal of synthetic biology is to design and build genetic circuits in living cells for a range of applications. Our incomplete knowledge of the effects of metabolic load and biological “crosstalk” on the host cell make it difficult to construct multilevel genetic logic circuits in a single cell, limiting the scalability of engineered biological systems. Microfluidic technologies provide reliable and scalable construction of synthetic biological systems by allowing compartmentalization of cells encoding simple genetic circuits and the spatiotemporal control of communication among these cells. This control is achieved via valves on the microfluidics chip which restrict fluid flow when activated. We describe a Computer Aided Design (CAD) framework called “Fluigi” for optimizing the layout of genetic circuits on a microfluidic chip, generating the control sequence of the associated signaling fluid valves, and simulating the behavior of the configured biological circuits. We demonstrate the capabilities of Fluigi on a set of Boolean algebraic benchmark circuits found in both synthetic biology and electrical engineering and a set of assay-based benchmark circuits. The integration of microfluidics and synthetic biology has the capability to increase the scale of engineered biological systems for applications in DNA assembly, biosensors, and screening assays for novel orthogonal genetic parts.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W1998190982",
    "type": "article"
  },
  {
    "title": "Exploring Dynamic Redundancy to Resuscitate Faulty PCM Blocks",
    "doi": "https://doi.org/10.1145/2602156",
    "publication_date": "2014-05-01",
    "publication_year": 2014,
    "authors": "Jie Chen; Guru Venkataramani; H. Howie Huang",
    "corresponding_authors": "",
    "abstract": "DRAM technology challenges have increased the necessity to adapt to the emerging memory technologies like Phase-Change Memory (PCM or PRAM). While such emerging technologies provide benefits like storage density, nonvolatility, and low energy consumption, they are constrained by limited write endurance that becomes more pronounced with process variation. In this article, we explore a novel PRAM-based main memory system which resuscitates a group of faulty pages in a cost-effective manner to significantly extend the PCM main memory lifetime while minimizing the performance impact. In particular, we explore three different dimensions of dynamic redundancy levels and group sizes, and design low-cost hardware and software support for our proposed schemes. We aim to have minimal hardware modifications (that have less than 1% on-chip and off-chip area overheads). Also, our schemes can improve the PRAM lifetime by up to 105× (times) over a chip with no error correction capabilities, and outperform prior schemes such as DRM and ECP at a small fraction of the hardware cost. The performance overhead resulting from our scheme is less than 8% on average across 21 applications from SPEC2006, Splash-2, and PARSEC benchmark suites.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W2015772022",
    "type": "article"
  },
  {
    "title": "An efficient heuristic to identify threshold logic functions",
    "doi": "https://doi.org/10.1145/2287696.2287702",
    "publication_date": "2012-08-01",
    "publication_year": 2012,
    "authors": "Ashok Kumar Palaniswamy; Spyros Tragoudas",
    "corresponding_authors": "",
    "abstract": "A fast method to identify the given Boolean function as a threshold function with weight assignment is introduced. It characterizes the function based on the parameters that have been defined in the literature. The proposed method is capable to quickly characterize all functions that have less than eight inputs and has been shown to operate fast for functions with as many as forty inputs. Furthermore, comparisons with other existing heuristic methods show huge increase in the number of threshold functions identified, and drastic reduction in time and complexity.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W2085266216",
    "type": "article"
  },
  {
    "title": "Performance Evaluation of Congestion-Aware Routing with DVFS on a Millimeter-Wave Small-World Wireless NoC",
    "doi": "https://doi.org/10.1145/2644816",
    "publication_date": "2014-11-18",
    "publication_year": 2014,
    "authors": "Jacob Murray; Ryan Kim; Paul Wettin; Partha Pratim Pande; Behrooz Shirazi",
    "corresponding_authors": "",
    "abstract": "The mm-wave small-world wireless NoC (mSWNoC) has emerged as an enabling interconnection infrastructure for designing high-bandwidth and energy-efficient multicore chips. In this mSWNoC architecture, long-range communication predominately takes place through the wireless shortcuts operating in the range of 10--100GHz, whereas short-range data exchange occurs through conventional metal wires. This results in performance advantages (lower latency and energy dissipation), mainly stemming from using the wireless links as long-range shortcuts between far-apart cores. The performance gain introduced by the wireless channels can be enhanced further if the wireline links of the mSWNoC are optimized according to the traffic patterns arising out of the application workloads. While there is significant energy savings, and hence temperature reduction, in the network due to the mSWNoC architecture, a load-imbalanced network is still susceptible to local temperature hotspots. In this work, we demonstrate that by incorporating congestion-avoidance routing with network-level dynamic voltage and frequency scaling (DVFS) in an mSWNoC, the power and thermal profiles can be improved without a significant impact on the overall network performance. In this work, we demonstrate how novel interconnect architectures enabled by the on-chip wireless links coupled with power management strategies can improve the energy and thermal characteristics of an mSWNoC significantly without introducing any performance degradation with respect to the conventional mesh-based NoC.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W2131641154",
    "type": "article"
  },
  {
    "title": "Exploiting Idle Hardware to Provide Low Overhead Fault Tolerance for VLIW Processors",
    "doi": "https://doi.org/10.1145/3001935",
    "publication_date": "2017-01-06",
    "publication_year": 2017,
    "authors": "Anderson L. Sartor; Arthur F. Lorenzon; Luigi Carro; Fernanda Lima Kastensmidt; Stephan Wong; Antonio Carlos Schneider Beck",
    "corresponding_authors": "",
    "abstract": "Because of technology scaling, the soft error rate has been increasing in digital circuits, which affects system reliability. Therefore, modern processors, including VLIW architectures, must have means to mitigate such effects to guarantee reliable computing. In this scenario, our work proposes three low overhead fault tolerance approaches based on instruction duplication with zero latency detection, which uses a rollback mechanism to correct soft errors in the pipelanes of a configurable VLIW processor. The first uses idle issue slots within a period of time to execute extra instructions considering distinct application phases. The second works at a finer grain, adaptively exploiting idle functional units at run-time. However, some applications present high instruction-level parallelism (ILP), so the ability to provide fault tolerance is reduced: less functional units will be idle, decreasing the number of potential duplicated instructions. The third approach attacks this issue by dynamically reducing ILP according to a configurable threshold, increasing fault tolerance at the cost of performance. While the first two approaches achieve significant fault coverage with minimal area and power overhead for applications with low ILP, the latter improves fault tolerance with low performance degradation. All approaches are evaluated considering area, performance, power dissipation, and error coverage.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W2570962028",
    "type": "article"
  },
  {
    "title": "System-Level Analysis of 3D ICs with Thermal TSVs",
    "doi": "https://doi.org/10.1145/3264736",
    "publication_date": "2018-07-31",
    "publication_year": 2018,
    "authors": "Ayed Alqahtani; Zongqing Ren; Jaeho Lee; Nader Bagherzadeh",
    "corresponding_authors": "",
    "abstract": "3D stacking of integrated circuits (ICs) provides significant advantages in saving device footprints, improving power management, and continuing performance enhancement, particularly for many-core systems. However, the stacked structure makes the heat dissipation a challenging issue. While Thermal Through Silicon Via (TTSV) is a promising way of lowering the thermal resistance of dies, past research has either overestimated or underestimated the effects of TTSVs as a consequence of the lack of detailed 3D IC models or system-level simulations. Here, we propose a simulation flow to accurately simulate TTSV effects on 3D ICs. We adopt benchmarks from Splash-2 running on a full-system mode of the gem5 simulator, which generates all the system component activities. McPAT is used to generate the corresponding power consumption and the power traces are fed to HotSpot for thermal simulation. The temperature profiles of 2D and 3D Nehalem-like ×86 processors are compared. TTSVs are later placed close to hotspot regions to facilitate heat dissipation; the peak temperature of 3D Nehalem is reduced by 5--25% with a small area overhead of 6%. By using a detailed 3D thermal model, full-system simulation, and a validated thermal simulator, our results show accurate thermal analysis of 3D ICs.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W2898404448",
    "type": "article"
  },
  {
    "title": "Stochastic Model Checking of Genetic Circuits",
    "doi": "https://doi.org/10.1145/2644817",
    "publication_date": "2014-12-30",
    "publication_year": 2014,
    "authors": "Curtis Madsen; Zhen Zhang; Nicholas Roehner; Chris Winstead; Chris J. Myers",
    "corresponding_authors": "",
    "abstract": "Synthetic genetic circuits have a number of exciting potential applications such as cleaning up toxic waste, hunting and killing tumor cells, and producing drugs and bio-fuels more efficiently. When designing and analyzing genetic circuits, researchers are often interested in the probability of observing certain behaviors. Discerning these probabilities typically involves simulating the circuit to produce some time series data and computing statistics over the resulting data. However, for very rare behaviors of complex genetic circuits, it becomes computationally intractable to obtain good results as the number of required simulation runs grows exponentially. It is, therefore, necessary to apply numerical methods to determine these probabilities directly. This article describes how stochastic model checking , a method for determining the likelihood that certain events occur in a system, can by applied to models of genetic circuits by translating them into continuous-time Markov chains (CTMCs) and analyzing them using Markov chain analysis to check continuous stochastic logic (CSL) properties. The utility of this approach is demonstrated with several case studies illustrating how this method can be used to perform design space exploration of two genetic oscillators and two genetic state-holding elements. Our results show that this method results in a substantial speedup as compared with conventional simulation-based approaches.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W1996756820",
    "type": "article"
  },
  {
    "title": "On-Chip Universal Supervised Learning Methods for Neuro-Inspired Block of Memristive Nanodevices",
    "doi": "https://doi.org/10.1145/2629503",
    "publication_date": "2015-04-27",
    "publication_year": 2015,
    "authors": "Djaafar Chabi; Weisheng Zhao; Damien Querlioz; Jacques‐Olivier Klein",
    "corresponding_authors": "",
    "abstract": "Scaling down beyond CMOS transistors requires the combination of new computing paradigms and novel devices. In this context, neuromorphic architecture is developed to achieve robust and ultra-low power computing systems. Memristive nanodevices are often associated with this architecture to implement efficiently synapses for ultra-high density. In this article, we investigate the design of a neuro-inspired logic block (NLB) dedicated to on-chip function learning and propose learning strategy. It is composed of an array of memristive nanodevices as synapses associated to neuronal circuits. Supervised learning methods are proposed for different type of memristive nanodevices and simulations are performed to demonstrate the ability to learn logic functions with memristive nanodevices. Benefiting from a compact implementation of neuron circuits and the optimization of learning process, this architecture requires small number of nanodevices and moderate power consumption.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2046404756",
    "type": "article"
  },
  {
    "title": "An Algorithm for Quantum Template Matching",
    "doi": "https://doi.org/10.1145/2629537",
    "publication_date": "2014-12-30",
    "publication_year": 2014,
    "authors": "Md. Mazder Rahman; Gerhard W. Dueck; Joseph D. Horton",
    "corresponding_authors": "",
    "abstract": "Quantum circuits are often generated by decomposing gates from networks with classical reversible gates. Only in rare cases, the results are minimal. Post-optimization methods, such as template matching, are employed to reduce the quantum costs of circuits. Quantum templates are derived from identity circuits. All minimal realizations, within certain limitations, can be embedded into templates. Due to this property, templates matching has the potential to reduce quantum costs of circuits. However, one of the difficulties in finding templates matches is due to the mobility of the gates within the circuit. Thus far, template matching procedures have employed heuristics to reduce the search space. This article presents an in-depth study of exact template matching with a set of algorithms. A graph structure with the corresponding circuits facilitates the discovery of potential sequences of templates to be matched, and how exact minimization of circuits can be accomplished. The significance of the proposed method is verified in benchmarks optimization.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2133163108",
    "type": "article"
  },
  {
    "title": "A Sub-μ A Stand-By Current Synchronous Electric Charge Extractor for Piezoelectric Energy Harvesting",
    "doi": "https://doi.org/10.1145/2700244",
    "publication_date": "2015-08-03",
    "publication_year": 2015,
    "authors": "Aldo Romani; Matteo Filippi; Michele Dini; Marco Tartagni",
    "corresponding_authors": "",
    "abstract": "In the field of energy harvesting there is a growing interest in power management circuits with intrinsic sub-μ A current consumptions, in order to operate efficiently with very low levels of available power. In this context, integrated circuits proved to be a viable solution with high associated nonrecurring costs and design risks. As an alternative, this article presents a fully autonomous and battery-less circuit solution for piezoelectric energy harvesting based on discrete components in a low-cost PCB technology, which achieves a comparable performance in a 32 × 43 mm 2 footprint. The power management circuit implements synchronous electric charge extraction (SECE) with a passive bootstrap circuit from fully discharged states. Circuit characterization showed that the circuit consumes less than 1μ A with a 3V output and may achieve energy conversion efficiencies of up to 85%. In addition, the circuit is specifically designed for operating with input and output voltages up to 20V, which grants a significant flexibility in the choice of transducers and energy storage capacitors.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2273377990",
    "type": "article"
  },
  {
    "title": "Redesign the Memory Allocator for Non-Volatile Main Memory",
    "doi": "https://doi.org/10.1145/2997651",
    "publication_date": "2017-04-14",
    "publication_year": 2017,
    "authors": "Songping Yu; Nong Xiao; Mingzhu Deng; Fang Liu; Wei Chen",
    "corresponding_authors": "",
    "abstract": "The non-volatile memory (NVM) has the merits of byte-addressability, fast speed, persistency and low power consumption, which make it attractive to be used as main memory. Commonly, user process dynamically acquires memory through memory allocators. However, traditional memory allocators designed with in-place data writes are not appropriate for the non-volatile main memory (NVRAM) due to the limited endurance. In this article, first, we quantitatively analyze the wear-oblivious of DRAM-oriented designed allocator—glibc malloc and the inefficiency of wear-conscious allocator NVMalloc. Then, we propose WAlloc, an efficient wear-aware manual memory allocator designed for NVRAM: (1) decouples metadata and data management; (2) distinguishes metadata with volatility; (3) redirects the data writes around to achieve wear-leveling; (4) redesigns an efficient and effective NVM copy mechanism, bypassing the CPU cache partially and prefetching data explicitly. Finally, experimental results show that the wear-leveling of WAlloc outperforms that of NVMalloc about 30% and 60% under random workloads and well-distributed workloads, respectively. Besides, WAlloc reduces the average data memory writes in 64 bytes block by 1.5 times comparing with glibc malloc. With the fulfillment of data persistency, cache bypassing NVM copy is better than cache line flushing NVM copy with performance improvement circa 14%.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2606906177",
    "type": "article"
  },
  {
    "title": "Resource-Constrained Scheduling for Digital Microfluidic Biochips",
    "doi": "https://doi.org/10.1145/3093930",
    "publication_date": "2017-10-14",
    "publication_year": 2017,
    "authors": "Kenneth O‘Neal; Daniel Grissom; Philip Brisk",
    "corresponding_authors": "",
    "abstract": "Digital microfluidics based on electrowetting-on-dielectric technology is poised to revolutionize many aspects of chemistry and biochemistry through miniaturization, automation, and software programmability. Digital microfluidic biochips (DMFBs) offer ample spatial parallelism, which is then exposed to the compiler. The first problem that a DMFB compiler must solve is resource-constrained scheduling, which is NP-complete. If the compiler is applied off-line, then long-running algorithms that produce solutions of high quality, such as iterative improvement or branch-and-bound search, can be applied; in an online context, where a biochemical reaction is to be executed as soon as it is specified by the programmer, heuristics that sacrifice solution quality to attain a fast runtime are used. This article describes in detail the algorithms and heuristics that have been proposed for resource-constrained scheduling, focusing on several recent contributions: path scheduling and force-directed list scheduling. It also discusses shortcomings and limitations of existing optimal scheduling problem formulations based on Integer Linear Programming and presents an updated formulation that addresses these issues. The algorithms are compared and evaluated on an extensive benchmark suite of biochemical assays used for applications, such as in vitro diagnostics, protein crystallization, and automated sample preparation.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2762896201",
    "type": "article"
  },
  {
    "title": "Low-Cost Stochastic Hybrid Multiplier for Quantized Neural Networks",
    "doi": "https://doi.org/10.1145/3309882",
    "publication_date": "2019-03-26",
    "publication_year": 2019,
    "authors": "Bingzhe Li; M. Hassan Najafi; David J. Lilja",
    "corresponding_authors": "",
    "abstract": "With increased interests of neural networks, hardware implementations of neural networks have been investigated. Researchers pursue low hardware cost by using different technologies such as stochastic computing (SC) and quantization. More specifically, the quantization is able to reduce total number of trained weights and results in low hardware cost. SC aims to lower hardware costs substantially by using simple gates instead of complex arithmetic operations. However, the advantages of both quantization and SC in neural networks are not well investigated. In this article, we propose a new stochastic multiplier with simple CMOS transistors called the stochastic hybrid multiplier for quantized neural networks. The new design uses the characteristic of quantized weights and tremendously reduces the hardware cost of neural networks. Experimental results indicate that our stochastic design achieves about 7.7x energy reduction compared to its counterpart binary implementation while maintaining slightly higher recognition error rates than the binary implementation. Compared to previous stochastic neural network implementations, our work derives at least 4x, 9x, and 10x reduction in terms of area, power, and energy, respectively.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2927803337",
    "type": "article"
  },
  {
    "title": "Cryptography with Analog Scheme Using Memristors",
    "doi": "https://doi.org/10.1145/3412439",
    "publication_date": "2020-09-15",
    "publication_year": 2020,
    "authors": "Bertrand Cambou; David Hély; Sareh Assiri",
    "corresponding_authors": "",
    "abstract": "Networks of low-power Internet of Things do not have always access to enough computing power to support mainstream cryptographic schemes; such schemes also consume computing power that can be exposed to side channel attacks. This article describes a method, that we call “cryptography with analog scheme using memristors,” leveraging the physical properties of memristors, which are active elements suitable for the design of components such as artificial neurons. The proposed devices encrypt messages by segmenting them into blocks of bits, each modulating the injected currents into randomly selected memristor cells, resulting into sets of resistance values turned into cipher texts. Through hash-protected handshakes, identical addresses are independently generated by both communicating devices, to concurrently point at the same set of cells in the arrays, and their images. These block ciphers, for example, 1 KB long, can only be decrypted with the same memristor array driven by analog circuitry or its image, rather than digital key-based schemes. The proposed methods generate cipher text, and decrypt them, with approximately one femto joule per bit, which is below observable level through differential power analysis. The article explains how the use of different cells for each message to encrypt, driven under different conditions, has the potential to mitigate mainstream attacks. It provides a detailed characterization of memristors to evaluate the feasibility of the approach and discusses some hardware and architectures to implement the scheme.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W3087912059",
    "type": "article"
  },
  {
    "title": "Dual-Level DVFS-Enabled Millimeter-Wave Wireless NoC Architectures",
    "doi": "https://doi.org/10.1145/2600074",
    "publication_date": "2014-05-01",
    "publication_year": 2014,
    "authors": "Jacob Murray; Teng Lu; Paul Wettin; Partha Pratim Pande; Behrooz Shirazi",
    "corresponding_authors": "",
    "abstract": "Wireless Network-on-Chip (WiNoC) has emerged as an enabling technology to design low power and high bandwidth massive multicore chips. WiNoCs based on small-world network architecture and designed with incorporating millimeter (mm)-wave on-chip wireless links offer significantly lower power and higher bandwidth compared to traditional mesh-based counterparts. In this mm-wave small-world WiNoC (mSWNoC), long distance communication predominately takes place through the wireless shortcuts whereas the short-range data exchange still occurs through the conventional metal wires. This results in performance advantages mainly stemming from using the wireless links as long-range shortcuts between far apart cores. This performance gain can be enhanced further if the wireline links and the processing cores of the WiNoC are optimized according to the traffic patterns and application workloads. In this work, we demonstrate that by incorporating both processor- and network-level dynamic voltage and frequency scaling (DVFS) in an mSWNoC, the power and thermal profiles can be improved without a significant impact on the overall execution time. We also show that depending on the applications, temperature hotspots can be formed either in the processing cores or in the network infrastructure. The proposed dual-level DVFS is capable of addressing both types of hotspots. In this work we will demonstrate how novel interconnect architectures enabled by the on-chip wireless links coupled with power management strategies can improve the energy and thermal characteristics of a NoC significantly.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W1963634678",
    "type": "article"
  },
  {
    "title": "3D vs. 2D Device Simulation of FinFET Logic Gates under PVT Variations",
    "doi": "https://doi.org/10.1145/2567670",
    "publication_date": "2014-04-01",
    "publication_year": 2014,
    "authors": "Sourindra Chaudhuri; Niraj K. Jha",
    "corresponding_authors": "",
    "abstract": "Recently, multigate transistors have been gaining attention as an alternative to conventional MOSFETs. Superior gate control over the channel, smaller subthreshold leakage, and reduced susceptibility to process variations are some of the key features that give multigate structures a competitive edge over MOSFETs. Among various multigate structures, silicon-on-insulator (SOI) FinFETs are promising, owing to their ease of fabrication. However, characterization of SOI FinFET devices/gates needs immediate attention in order for them to gain greater popularity in this decade. Ideally, 3D device simulation should be done for accurate circuit analysis. However, this is impractical due to the huge CPU time required. As a possible alternative, simulating a 2D crosssection of the device yields 10× to 100× reduction in CPU time. However, this introduces significant error in the range of 7% to 20% when evaluating the on/off current ( I ON /I OFF ) for a single device and leakage current or propagation delay ( I LEAK /t D ) for logic gates. In this work, we first present a methodology to obtain optimized 3D device simulation models for SOI FinFETs. Based on these 3D models, we develop adjusted 2D models to capture 3D simulation accuracy with 2D simulation efficiency. We report results for the 22nm SOI FinFET technology node. We adjust gate underlap ( L UN ) in the 2D cross section of the n/pFinFET devices in order to mimic 3D device behavior. When the adjusted 2D models are employed in mixed-mode simulation of FinFET logic gates, the error in the evaluation of I LEAK /t D is very small. To the best of our knowledge, this is the first such attempt. We show that 2D device models remain valid even under process, voltage, and temperature (PVT) variations. We target process variations in gate length ( L G ), fin thickness ( T SI ), gate oxide thickness ( T OX ), and gate workfunction ( Φ G ), which are the parameters that have been shown to have the most impact on leakage and delay.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W2035130574",
    "type": "article"
  },
  {
    "title": "An Improved Reversible Circuit Synthesis Approach using Clustering of ESOP Cubes",
    "doi": "https://doi.org/10.1145/2629543",
    "publication_date": "2014-11-18",
    "publication_year": 2014,
    "authors": "Kamalika Datta; Gaurav Rathi; Indranil Sengupta; Hafizur Rahaman",
    "corresponding_authors": "",
    "abstract": "The problem of reversible logic synthesis has drawn the attention of many researchers over the last two decades with growing emphasis on low-power design. Among the various synthesis approaches that have been reported, the ones based on compact circuit representations like Binary Decision Diagrams (BDD) and Exclusive-or Sum-Of-Products (ESOP) are interesting in the sense that they can handle large circuits with more than 100 inputs. The drawback of these approaches, however, is that the generated netlists are sub-optimal, and there is lot of scope for optimizing them. One of the best methods in this regard is an approach, where the ESOP cubes are grouped into sublists based on sharing among more than one outputs. In the work reported in this article, in contrast, an approach based on clustering the ESOP cubes based on their similarity with respect to input variables is presented, along with a technique to map each of the clusters into reversible gate netlists. This approach results in a significant reduction in quantum cost of the final netlist, but requires one additional garbage line. Experimental results on a number of reversible circuit benchmarks have been presented in support of the claim and also demonstrate that the method is very fast.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W2040483684",
    "type": "article"
  },
  {
    "title": "Critical-reliability path identification and delay analysis",
    "doi": "https://doi.org/10.1145/2564926",
    "publication_date": "2014-02-01",
    "publication_year": 2014,
    "authors": "Jifeng Chen; Shuo Wang; Mohammad Tehranipoor",
    "corresponding_authors": "",
    "abstract": "Circuit reliability analysis at the presilicon stage has become vital for sub-45nm technology designs in particular, due to aging effects, such as Negative Bias Temperature Instability (NBTI) and Hot Carrier Injection (HCI). To avoid potential reliability hazards in the postsilicon stage, current large-scale designs for commercial implementation overpessimistically analyze circuit aging under assumed worst-case workload in order not to violate the corner cases even for low possibilities, thus introducing unnecessary margin in the design timing analysis. The major issue is lack of an effective aging analysis method applicable to large designs with low CPU runtime, which is mainly due to: (1) conventional reliability tools are extremely time-consuming for circuit-level timing analysis and thus are not practical for large designs; (2) mathematical models developed to expedite the process are not accurate due to the high complexity of aging effects. In this article, a comprehensive analysis is presented to highlight the importance of each aging parameter. Then, a novel methodology is developed based on current commercial reliability tools to guarantee its high accuracy on circuit-level aging analysis. Existing proven low-level mathematical models are further enhanced to extensively speed up a higher level analysis by taking advantage of the explicit intermediate conditions stored in a pregenerated lookup table. Our results indicate ≥244 X improved computational efficiency, ≤5% relative error, and ≤0.7% absolute error compared with commercial reliability analysis tools (e.g., HSPICE MOSRA).",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W2089135503",
    "type": "article"
  },
  {
    "title": "3D-ReG",
    "doi": "https://doi.org/10.1145/3375699",
    "publication_date": "2020-01-30",
    "publication_year": 2020,
    "authors": "Bing Li; Janardhan Rao Doppa; Partha Pratim Pande; Krishnendu Chakrabarty; Joe X. Qiu; Hai Li",
    "corresponding_authors": "",
    "abstract": "Deep neural network (DNN) models are being expanded to a broader range of applications. The computational capability of traditional hardware platforms cannot accommodate the growth of model complexity. Among recent technologies to accelerate DNN, resistive memory (ReRAM)-based processing-in-memory (PIM) emerged as a promising solution for DNN inference due to its high efficiency for matrix-based computation. We face two major technical challenges in extending the use of ReRAM-based accelerators for training: (1) full-precision data is essential in back-propagation; (2) the need to support both feed-forward and back-propagation aggravates the data-movement burden. We propose a heterogeneous architecture named as 3D-ReG, which leverages full-precision GPU to ensure training accuracy and low-overhead 3D integration to provide low-cost data movements. Moreover, we introduce conservative and aggressive task-mapping schemes, which partition the computation phases in different ways to balance execution efficiency and training accuracy. We evaluate 3D-ReG implemented with two 3D integration technologies, through-silicon vias (TSVs) and monolithic inter-tier vias (MIVs), and compare them with GPU-only and PIM-only counterparts. Various GPU-only platforms using two main-memory technologies (DRAM, ReRAM) and three interconnect technologies (2D, TSV, MIV) are evaluated as well. Experimental results show that 3D-ReG can achieve on average 5.64× training speedup and 3.56× higher energy efficiency compared with the GPU with DRAM as main memory, at the cost of 0.05%–3.39% accuracy drop. We define a new metric, gain-loss ratio (GLR), which quantitatively evaluates the capability of a DNN training hardware in terms of the model accuracy and hardware efficiency. The results of our comparison show that the aggressive task-mapping scheme on MIV-based 3D-ReG outperforms the other methods.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W3010281071",
    "type": "article"
  },
  {
    "title": "On-the-fly Page Migration and Address Reconciliation for Heterogeneous Memory Systems",
    "doi": "https://doi.org/10.1145/3364179",
    "publication_date": "2020-01-09",
    "publication_year": 2020,
    "authors": "Mahzabeen Islam; Shashank Adavally; Marko Scrbak; Krishna Kavi",
    "corresponding_authors": "",
    "abstract": "For efficient placement of data in flat-address heterogeneous memory systems consisting of fast (e.g., 3D-DRAM) and slow memories (e.g., NVM), we present a hardware-based page migration technique. Unlike epoch-based approaches that migrate heavily accessed (“hot”) pages from slow to fast memories at each epoch interval, we migrate a page immediately when it becomes hot (“on-the-fly”), using hardware in user-transparent manner and with minimal OS intervention. The management of physical addresses due to page relocation becomes cumbersome and requires costly OS intervention. We use a small hardware remap table to keep track of new physical addresses of the migrated pages. This limits address reconciliation to occur only at periodic evictions of old remap entries. Also, we propose a hardware-orchestrated light-weight address reconciliation process. For our studied heterogeneous memory system, on-the-fly page migration with hardware-assisted address reconciliation provides 74% and 24% IPC improvements, on average for a set of SPEC CPU2006 workloads when compared to a baseline without any page migration and a system with on-the-fly page migration using OS-based address reconciliation, respectively. Furthermore, we present an analytical model for classifying applications as page migration friendly (applications that show performance gains from page migration) or unfriendly based on memory access behavior.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W3013592869",
    "type": "article"
  },
  {
    "title": "CONCEALING-Gate: Optical Contactless Probing Resilient Design",
    "doi": "https://doi.org/10.1145/3446998",
    "publication_date": "2021-06-30",
    "publication_year": 2021,
    "authors": "Mir Tanjidur Rahman; Nusrat Farzana Dipu; Dhwani Mehta; Shahin Tajik; Mark Tehranipoor; Navid Asadizanjani",
    "corresponding_authors": "",
    "abstract": "Optical probing, though developed as silicon debugging tools from the chip backside, has shown its capability of extracting secret data, such as cryptographic keys and user identifications, from modern system-on-chip devices. Existing optical probing countermeasures are based on detecting any device modification attempt or abrupt change in operating conditions during asset extraction. These countermeasures usually require additional fabrication steps and cause area and power overheads. In this article, we propose a novel low-overhead design methodology to prevent optical probing. It leverages additional operational logic gates, termed as “CONCEALING-Gates,” inserted as neighbor gates of the logic gates connected to the nets carrying asset signals. The switching activity of the asset carrying logic is camouflaged with the switching activity of the concealing-gate. The input signal and placement in the layout of the concealing-gates must be selected in such a way that they remain equally effective in preventing different variants of optical probing, i.e., electro-optical frequency mapping and Electro-optical probing. The methodology is suitable for the existing ASIC/FPGA design flow and fabrication process, since designing new standard logic cells is not required. We have performed a comprehensive security evaluation of the concealing-gates using a security metric developed based on the parameters that are crucial for optical probing. The attack resiliency of the logic cells, protected by concealing-gates, is evaluated using an empirical study-based simulation methodology and experimental validation. Our analysis has shown that in the presence of concealing-gates, logic cells achieve high resiliency against optical contactless probing techniques.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W3177097405",
    "type": "article"
  },
  {
    "title": "Time-varying Metamaterial-enabled Directional Modulation Schemes for Physical Layer Security in Wireless Communication Links",
    "doi": "https://doi.org/10.1145/3513088",
    "publication_date": "2022-03-23",
    "publication_year": 2022,
    "authors": "Alireza Nooraiepour; Shaghayegh Vosoughitabar; Chung‐Tse Michael Wu; Waheed U. Bajwa; Narayan B. Mandayam",
    "corresponding_authors": "",
    "abstract": "Novel transmission schemes, enabled by recent advances in the fields of metamaterial (MTM), leaky-wave antenna (LWA) and directional modulation (DM), are proposed for enhancing the physical layer (PHY) security. MTM-LWAs, which offer compact, integrated, and cost-effective alternatives to the classic phased-array architectures, are particularly of interest for emerging wireless communication systems including Internet-of-Things. The proposed secure schemes are devised to accomplish the functionalities of directional modulation (DM) transmitters for orthogonal frequency-division multiplexing (OFDM) and non-contiguous OFDM transmissions, while enjoying the implementation benefits of MTM-LWAs. Specifically, transmitter architectures based on the idea of time-modulated MTM-LWA have been put forth as a promising solution for PHY security for the first time. The PHY security for the proposed schemes are investigated from the point of view of both passive and active attacks where an adversary aims to decode secret information and feed spurious data to the legitimate receiver, respectively. Numerical simulations reveal that even when the adversary employs sophisticated state-of-the-art deep learning based attacks, the proposed transmission schemes are resistant to these attacks and reliably guarantee system security.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W4220760226",
    "type": "article"
  },
  {
    "title": "Taming Molecular Field-Coupling for Nanocomputing Design",
    "doi": "https://doi.org/10.1145/3552520",
    "publication_date": "2022-08-03",
    "publication_year": 2022,
    "authors": "Yuri Ardesi; Umberto Garlando; Fabrizio Riente; Giuliana Beretta; Gianluca Piccinini; Mariagrazia Graziano",
    "corresponding_authors": "",
    "abstract": "Molecular Field-Coupling Nanocomputing (FCN) is one of the most promising technologies for overcoming Complementary Metal Oxide Semiconductor (CMOS) scaling issues. It encodes the information in the charge distribution of nanometric molecules and propagates it through local electrostatic intermolecular interaction. This technology promises very high speed at ambient temperatures with minimal power dissipation. The main research focus on molecular FCN is currently either on single-molecule low-level analysis or circuit design based on naïve assumptions. We aim to fill this gap, assessing the potential and feasibility of FCN. We present a bottom-up analysis and design framework that starts from the physical characterization of molecular and technological parameters and enables physical-aware FCN designs. The framework explicitly considers molecular physics, allowing the designer to tame the molecular interaction to ensure the computational capabilities of the final device. The framework permits studying possible physical effects that create cross-implications and correlations among physical and system-level layers considering possible behavior variability. We characterize and verify molecular propagation in increasingly structured layouts to design complex arithmetic circuits. The results highlight molecular FCN advantages, especially in area occupation, and provide valuable quantitative feedback to designers and technologists to support the assessment of molecular FCN and the realization of an eventual prototype.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W4289544432",
    "type": "article"
  },
  {
    "title": "SAT-based Exact Modulo Scheduling Mapping for Resource-Constrained CGRAs",
    "doi": "https://doi.org/10.1145/3663675",
    "publication_date": "2024-05-22",
    "publication_year": 2024,
    "authors": "Cristian Tirelli; Juan Sapriza; Rubén Rodríguez Rodríguez; Lorenzo Ferretti; Benoît Denkinger; Giovanni Ansaloni; José Miranda; David Atienza; Laura Pozzi",
    "corresponding_authors": "",
    "abstract": "Coarse-Grain Reconfigurable Arrays (CGRAs) represent emerging low-power architectures designed to accelerate Compute-Intensive Loops (CILs). The effectiveness of CGRAs in providing acceleration relies on the quality of mapping: how efficiently the CIL is compiled onto the platform. State-of-the-Art (SoA) compilation techniques utilize modulo scheduling to minimize the Iteration Interval (II) and use graph algorithms like Max-Clique Enumeration to address mapping challenges. Our work approaches the mapping problem through a satisfiability (SAT) formulation. We introduce the Kernel Mobility Schedule (KMS), an ad hoc schedule used with the Data Flow Graph and CGRA architectural information to generate Boolean statements that, when satisfied, yield a valid mapping. Experimental results demonstrate SAT-MapIt outperforming SoA alternatives in almost 50% of explored benchmarks. Additionally, we evaluated the mapping results in a synthesizable CGRA design and emphasized the runtime metrics trends, i.e., energy efficiency and latency, across different CILs and CGRA sizes. We show that a hardware-agnostic analysis performed on compiler-level metrics can optimally prune the architectural design space, while still retaining Pareto-optimal configurations. Moreover, by exploring how implementation details impact cost and performance on real hardware, we highlight the importance of holistic software-to-hardware mapping flows, as the one presented herein.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4398197706",
    "type": "article"
  },
  {
    "title": "Carbon nanotube transistor compact model for circuit design and performance optimization",
    "doi": "https://doi.org/10.1145/1350763.1350767",
    "publication_date": "2008-04-01",
    "publication_year": 2008,
    "authors": "Jie Deng; Albert Lin; Gordon Wan; H.‐S. Philip Wong",
    "corresponding_authors": "",
    "abstract": "In this paper, we describe the development of the Stanford University Carbon Nanotube FET (CNFET) Compact Model. The CNFET Model is a circuit-compatible, compact model which describes enhancement-mode, CMOS-like CNFETs. It can be used to simulate both functionality and performance of large-scale circuits with hundreds of CNFETs. To produce realistic and relevant results, the model accounts for several practical non-idealities such as scattering in the near-ballistic channel, effects of the source/drain extension region, and charge-screening for multiple-nanotube CNFETs. The model also includes a full transcapacitance network for more accurate transient and AC results. The Stanford University CNFET Model is implemented in both HSPICE macro language and VerilogA. The VerilogA implementation shows speedups of roughly 7x∼15x over HSPICE. Applications of the model suggest that n- and p-CNFETs will have 6x and 13x speed advantage over Si n- and p-MOSFETs respectively at the 32nm node, and that a CNT density of 250 CNTs/um is ideal for multiple-nanotube gates. Such a compact CNFET model will be absolutely essential in ushering in the Design Era of CNFET circuits as carbon nanotube technology outgrows its “science discovery” phase.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W2077640425",
    "type": "article"
  },
  {
    "title": "Gated-diode FinFET DRAMs",
    "doi": "https://doi.org/10.1145/1877745.1877746",
    "publication_date": "2010-12-01",
    "publication_year": 2010,
    "authors": "Ajay N. Bhoj; Niraj K. Jha",
    "corresponding_authors": "",
    "abstract": "Scaling bulk CMOS SRAM technology for on-chip caches beyond the 22nm node is questionable, on account of high leakage power consumption, performance degradation, and instability due to process variations. Recently, two-three transistor one gated-diode (2T/3T1D) DRAMs were proposed as alternatives to address the SRAM variability problem, with an emphasis on high-activity embedded cache applications. They are highly competitive to SRAM in terms of performance, while having a smaller power and area footprint at lower technology nodes. The current evolutionary trend in transistor structures is moving toward an era of multigate devices, which makes it necessary to identify design issues and advantages of gated-diode DRAMs implemented in a multigate technology. In this work, we address gated-diode DRAM design in FinFET technology using mixed-mode 2D-device simulations. We revisit the model of internal voltage gain in bulk gated diodes and extend it to provide quantitative insight into designing Fin gated diodes, that is, gated diodes in FinFET technology. To this effect, we propose FinFET variants of the bulk gated-diode configuration and identify parameters that are critical to enhancing the retention time and read current in 2T/3T1D FinFET DRAMs. Additionally, we show the superiority of 2T1D FinFET DRAM over 6T FinFET SRAM having pass-gate feedback (6T PGFB) and 2T1D bulk DRAM under the effect of physical parameter process variations using a quasi--Monte Carlo method implemented in FinE, an environment we have developed for double-gate circuit design that integrates Sentaurus TCAD from Synopsys with the Spice3-UFDG double-gate compact model from University of Florida, under a single framework. Finally, we present a new tunable threshold gated diode FinFET amplifier which uses an n-type gated diode for voltage-boosting, along with a p-type gated diode for zero-suppression.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W2059325646",
    "type": "article"
  },
  {
    "title": "A Novel Power Delivery Method for Asynchronous Loads in Energy Harvesting Systems",
    "doi": "https://doi.org/10.1145/2043643.2043646",
    "publication_date": "2011-12-01",
    "publication_year": 2011,
    "authors": "Xuefu Zhang; Delong Shang; Fei Xia; Alex Yakovlev",
    "corresponding_authors": "",
    "abstract": "For systems depending on power harvesting, a fundamental contradiction in the power delivery chain has existed between conventional synchronous computational loads requiring relatively stable Vdd and power harvesters unable to supply it. DC/DC conversion has therefore been an integral part of such systems to resolve this contradiction. On the other hand, asynchronous computational loads, in addition to their potential power-saving capabilities, can be made tolerant to a much wider range of Vdd variance. This may open up opportunities for much more energy efficient methods of power delivery. This article presents in-depth investigations into the behavior and performance of different on-chip power delivery methods driving both asynchronous and synchronous loads directly from a harvester source. A novel power delivery method, which employs a capacitor bank for adaptively storing the energy from power harvesters depending on load and source conditions, is developed. Its advantages, especially when driving asynchronous loads, are demonstrated through comprehensive comparative analysis.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W1977482389",
    "type": "article"
  },
  {
    "title": "p-QCA",
    "doi": "https://doi.org/10.1145/2000502.2000506",
    "publication_date": "2011-08-01",
    "publication_year": 2011,
    "authors": "Rajeswari Devadoss; Kolin Paul; S. Balakrishnan",
    "corresponding_authors": "",
    "abstract": "Quantum-dot cellular automata is an interesting computation fabric with many never-seen-before properties. However, no programmable fabric scheme has utilized all these properties effectively. We propose an architecture for a programmable device using molecular QCA which exploits all the specialities of the fabric. The architecture taps the flexibility provided by the clocking system of molecular QCA to build a simple tile-based programmable device with the 3-input Majority gate as the fundamental logic element. Observing how a QCA structure can behave as either an interconnect or a logic gate depending on clocking, the proposed architecture merges routing and logic elements, thus drastically changing how programmable fabrics have been designed.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W2063870309",
    "type": "article"
  },
  {
    "title": "A Hardware Viewpoint on Biosequence Analysis",
    "doi": "https://doi.org/10.1145/2504774",
    "publication_date": "2013-11-01",
    "publication_year": 2013,
    "authors": "Mariagrazia Graziano; Stefano Frache; Maurizio Zamboni",
    "corresponding_authors": "",
    "abstract": "Biosequence alignment recently received an increasing support from both commodity and dedicated hardware platforms. Processing capabilities are constantly rising, but still not satisfying the limitless requirements of this application. We give an insight on the contribution to this need that can possibly be expected from emerging technology devices and architectures, focusing as an example on nanofabrics based on silicon nanowires. By varying a few parameters we explore the solution space, and demonstrate with proper figures of merit how this family of beyond CMOS structures could be considered as the effective disruptive technology for biosequence analysis applications.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W2095472412",
    "type": "article"
  },
  {
    "title": "Effect of process variations in 3D global clock distribution networks",
    "doi": "https://doi.org/10.1145/2287696.2287703",
    "publication_date": "2012-08-01",
    "publication_year": 2012,
    "authors": "Xu Hu; Vasilis F. Pavlidis; Giovanni De Micheli",
    "corresponding_authors": "",
    "abstract": "In three-dimensional (3D) integrated circuits, the effect of process variations on clock skew differs from 2D circuits. The combined effect of inter-die and intra-die process variations on the design of 3D clock distribution networks is considered in this article. A statistical clock skew model incorporating both the systematic and random components of process variations is employed to describe this effect. Two regular 3D clock tree topologies are investigated and compared in terms of clock skew variation. The statistical skew model used to describe clock skew variations is verified through Monte-Carlo simulations. The clock skew is shown to change in different ways with the number of planes forming the 3D IC and the clock network architecture. Simulations based on a 45-nm CMOS technology show that the maximum standard deviation of clock skew can vary from 15 ps to 77 ps. Results indicate that simply increasing the number of planes of a 3D IC does not necessarily lead to lower skew variation and higher operating frequencies. A multigroup 3D clock tree topology is proposed to effectively mitigate the variability of clock skew. Tradeoffs between the investigated 3D clock distribution networks and the number of planes comprising a 3D circuit are discussed and related design guidelines are offered. The skew variation in 3D clock trees is also compared with the skew variation of clock grids.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W2131428184",
    "type": "article"
  },
  {
    "title": "BigBus",
    "doi": "https://doi.org/10.1145/3289391",
    "publication_date": "2019-01-28",
    "publication_year": 2019,
    "authors": "Janibul Bashir; Eldhose Peter; Smruti R. Sarangi",
    "corresponding_authors": "",
    "abstract": "This article presents BigBus , a novel design of an on-chip photonic network for a 1,024-node system. For such a large on-chip network, performance and power reduction are two mutually conflicting goals. This article uses a combination of strategies to reduce static power consumption while simultaneously improving performance and the energy-delay 2 ( ED 2 ) product. The crux of the article is to segment the entire system into smaller clusters of nodes and adopt a hybrid strategy for each segment that includes conventional laser modulation, as well as a novel technique for sharing power across nodes dynamically. We represent energy internally as tokens, where one token will allow a node to send a message to any other node in its cluster. We allow optical stations to arbitrate for tokens at a global level, and then we predict the number of token equivalents of power that the off-chip laser needs to generate. Using these techniques, BigBus outperforms other competing proposals. We demonstrate a speedup of 14--34% over state of the art proposals and a 20--61% reduction in ED 2 .",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W2911810816",
    "type": "article"
  },
  {
    "title": "REDELF",
    "doi": "https://doi.org/10.1145/2751560",
    "publication_date": "2015-09-21",
    "publication_year": 2015,
    "authors": "Jinho Lee; Kyungsu Kang; Ki‐Young Choi",
    "corresponding_authors": "",
    "abstract": "3D integrated circuits (3D ICs) using through-silicon vias (TSVs) allow to envision the stacking of dies with different functions and technologies, using as an interconnect backbone a 3D network-on-chip (NoC). However, partial vertical connection in 3D NoCs seems unavoidable because of the large overhead of TSV itself (e.g., large footprint, low fabrication yield, additional fabrication processes) as well as the heterogeneity in dimension. This article proposes an energy-efficient deadlock-free routing algorithm for 3D mesh topologies where vertical connections partially exist. By introducing some rules for selecting elevators (i.e., vertical links between dies), the routing algorithm can eliminate the dedicated virtual channel requirement. In this article, the rules themselves as well as the proof of deadlock freedom are given. By eliminating the virtual channels for deadlock avoidance, the proposed routing algorithm reduces the energy consumption by 38.9% compared to a conventional routing algorithm. When the virtual channel is used for reducing the head-of-line blocking, the proposed routing algorithm increases performance by up to 23.1% and 6.9% on average.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2092163139",
    "type": "article"
  },
  {
    "title": "Guest Editorial Special Issue on Secure and Trustworthy Computing",
    "doi": "https://doi.org/10.1145/2898433",
    "publication_date": "2016-06-20",
    "publication_year": 2016,
    "authors": "Ozgur Sinanoglu; Ramesh Karri",
    "corresponding_authors": "",
    "abstract": "editorial Free Access Share on Guest Editorial Special Issue on Secure and Trustworthy Computing Editors: Ozgur Sinanoglu New York University Abu Dhabi, UAE New York University Abu Dhabi, UAEView Profile , Ramesh Karri New York University, New York New York University, New YorkView Profile Authors Info & Claims ACM Journal on Emerging Technologies in Computing SystemsVolume 13Issue 1January 2017 Article No.: 1pp 1–3https://doi.org/10.1145/2898433Published:20 June 2016Publication History 0citation335DownloadsMetricsTotal Citations0Total Downloads335Last 12 Months35Last 6 weeks6 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2473560542",
    "type": "editorial"
  },
  {
    "title": "Trading Accuracy for Energy in Stochastic Circuit Design",
    "doi": "https://doi.org/10.1145/2990503",
    "publication_date": "2017-04-20",
    "publication_year": 2017,
    "authors": "Armin Alaghi; Wei-Ting Jonas Chan; John P. Hayes; Andrew B. Kahng; Jiajia Li",
    "corresponding_authors": "",
    "abstract": "As we approach the limits of traditional Moore’s-Law scaling, alternative computing techniques that consume energy more efficiently become attractive. Stochastic computing (SC), as a re-emerging computing technique, is a low-cost and error-tolerant alternative to conventional binary circuits in several important applications such as image processing and communications. SC allows a natural accuracy-energy tradeoff that has been exploited in the past. This article presents an accuracy-energy tradeoff technique for SC circuits that reduces their energy consumption with virtually no accuracy loss. To this end, we employ voltage or frequency scaling, which normally reduce energy consumption at the cost of timing errors. Then we show that due to their inherent error tolerance, SC circuits operate satisfactorily without significant accuracy loss even with aggressive scaling. This significantly improves their energy efficiency. In contrast, conventional binary circuits quickly fail as the supply voltage decreases. To find the most energy-efficient operating point of an SC circuit, we propose an error estimation method that allows us to quickly explore the circuit’s design space. The error estimation method is based on Markov chain and least-squares regression. Furthermore, we investigate opportunities to optimize SC circuits under such aggressive scaling. We find that logical and physical design techniques can be combined to significantly expand the already-powerful accuracy-energy tradeoff possibilities of SC. In particular, we demonstrate that careful adjustment of path delays can lead to significant error reduction under voltage and frequency scaling. We perform buffer insertion and route detouring to achieve more balanced path delays. These techniques differ from conventional path-balancing techniques whose goal is to minimize power consumption by resizing the non-critical paths. The goal of our path-balancing approach is to increase error cancellation chances in voltage-/frequency-scaled SC circuits. Our circuit optimization comprehends the tradeoff between power overheads due to inserted buffers and wires versus the energy reduction from supply voltage downscaling enabled by more balanced path delays. Simulation results show that our optimized SC circuits can tolerate aggressive voltage scaling with no significant signal-to-noise ratio (SNR) degradation. In one example, a 40% supply voltage reduction (1V to 0.6V) on the SC circuit leads to 66% energy saving (20.7pJ to 6.9pJ) and makes it more efficient than its conventional binary counterpart. In the same example, a 100% frequency boosting (400ps to 200ps) of the optimized circuits leads to no significant SNR degradation. We also show that process variation and temperature variation have limited impact on optimized SC circuits. The error change is less than 5% when temperature changes by 100°C or process condition changes from worst case to best case.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2607296094",
    "type": "article"
  },
  {
    "title": "RIMEP2",
    "doi": "https://doi.org/10.1145/2629534",
    "publication_date": "2014-12-30",
    "publication_year": 2014,
    "authors": "Fatima Zohra Hadjam; Claudio Moraga",
    "corresponding_authors": "",
    "abstract": "RIMEP (Reversible Improved Multi Expression Programming), is a system that has been developed for designing reversible digital circuits. This article discloses a new version of RIMEP called “RIMEP2”. The goal was to evolve reversible circuits in a “fanout free” search space. The major changes that RIMEP has undergone, are made in the structure of the chromosome and in the fitness calculation. Although the changes seem to be minor, the impact is effective. The execution time has been considerably decreased and optimal competitive solutions were found for a set of 30 selected benchmarks, where a quantum cost reduction up to 96.13% was reached with an average of 42.17%.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W1987774503",
    "type": "article"
  },
  {
    "title": "Decomposition of Diagonal Hermitian Quantum Gates Using Multiple-Controlled Pauli Z Gates",
    "doi": "https://doi.org/10.1145/2629526",
    "publication_date": "2014-12-30",
    "publication_year": 2014,
    "authors": "Mahboobeh Houshmand; Morteza Saheb Zamani; Mehdi Sedighi; Mona Arabzadeh",
    "corresponding_authors": "",
    "abstract": "Quantum logic decomposition refers to decomposing a given quantum gate to a set of physically implementable gates. An approach has been presented to decompose arbitrary diagonal quantum gates to a set of multiplexed-rotation gates around z axis. In this article, a special class of diagonal quantum gates, namely diagonal Hermitian quantum gates, is considered and a new perspective to the decomposition problem with respect to decomposing these gates is presented. It is first shown that these gates can be decomposed to a set that solely consists of multiple-controlled Z gates. Then a binary representation for the diagonal Hermitian gates is introduced. It is shown that the binary representations of multiple-controlled Z gates form a basis for the vector space that is produced by the binary representations of all diagonal Hermitian quantum gates. Moreover, the problem of decomposing a given diagonal Hermitian gate is mapped to the problem of writing its binary representation in the specific basis mentioned previously. Moreover, CZ gate is suggested to be the two-qubit gate in the decomposition library, instead of previously used CNOT gate. Experimental results show that the proposed approach can lead to circuits with lower costs in comparison with the previous ones.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2033873076",
    "type": "article"
  },
  {
    "title": "Improved Threshold Logic Synthesis Using Implicant-Implicit Algorithms",
    "doi": "https://doi.org/10.1145/2597175",
    "publication_date": "2014-04-01",
    "publication_year": 2014,
    "authors": "Ashok Kumar Palaniswamy; Spyros Tragoudas",
    "corresponding_authors": "",
    "abstract": "Existing threshold logic synthesis methods decompose larger input functions into smaller input functions and perform synthesis for them. It is shown that significantly larger input functions can be synthesized by implementing the existing methods in an implicant-implicit manner. Experimental results on the ISCAS 85 benchmarks show that this impacts the synthesis cost, which drops significantly. More specifically, as the size of the functions that can be handled by the synthesis algorithm increases, the number of threshold logic gates required to implement very large input functions decreases. In addition, the total weight decreases and the performance is improved.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2046397491",
    "type": "article"
  },
  {
    "title": "Parallel Networks",
    "doi": "https://doi.org/10.1145/2667229",
    "publication_date": "2014-12-30",
    "publication_year": 2014,
    "authors": "Tara L. Deans",
    "corresponding_authors": "Tara L. Deans",
    "abstract": "Synthetic biology has emerged as an important technology for engineering cells to behave in controllable and predictable ways. The promise of this modern technology is dependent on our understanding of cellular complexity to allow us to engineer cells with novel function. In this regard, the fields of computer science and synthetic biology are critical for accelerating both our understanding of biological systems, and our ability to quantitatively engineer cells. Thus, advances in biology and biotechnology are arising at the intersection of computer science and synthetic biology approaches. This review seeks to introduce the field of synthetic biology to the computer science community, and to ignite a curiosity and interest in fostering a unique synergy for possible collaborations between synthetic biologists and computer scientists.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2094318956",
    "type": "article"
  },
  {
    "title": "Process Variability and Electrostatic Analysis of Molecular QCA",
    "doi": "https://doi.org/10.1145/2738041",
    "publication_date": "2015-09-02",
    "publication_year": 2015,
    "authors": "Mariagrazia Graziano; Azzurra Pulimeno; Ruiyu Wang; Wei Xiang; Massimo Ruo Roch; Gianluca Piccinini",
    "corresponding_authors": "",
    "abstract": "Molecular quantum-dot cellular automata (mQCA) is an emerging paradigm for nanoscale computation. Its revolutionary features are the expected operating frequencies (THz), the high device densities, the noncryogenic working temperature, and, above all, the limited power densities. The main drawback of this technology is a consequence of one of its very main advantages, that is, the extremely small size of a single molecule. Device prototyping and the fabrication of a simple circuit are limited by lack of control in the technological process [Pulimeno et al. 2013a]. Moreover, high defectivity might strongly impact the correct behavior of mQCA devices. Another challenging point is the lack of a solid method for analyzing and simulating mQCA behavior and performance, either in ideal or defective conditions. Our contribution in this article is threefold: (i) We identify a methodology based on both ab-initio simulations and post-processing of data for analyzing an mQCA system adopting an electronic point of view (we baptized this method as “MoSQuiTo”); (ii) we assess the performance of an mQCA device (in this case, a bis- ferrocene molecule) working in nonideal conditions, using as a reference the information on fabrication-critical issues and on the possible defects that we are obtaining while conducting our own ongoing experiments on mQCA: (iii) we determine and assess the electrostatic energy stored in a bis-ferrocene molecule both in an oxidized and reduced form. Results presented here consist of quantitative information for an mQCA device working in manifold driving conditions and subjected to defects. This information is given in terms of: (a) output voltage; (b) safe operating area (SOA); (c) electrostatic energy; and (d) relation between SOA and energy, that is, possible energy reduction subject to reliability and functionality constraints. The whole analysis is a first fundamental step toward the study of a complex mQCA circuit. It gives important suggestions on possible improvements of the technological processes. Moreover, it starts an interesting assessment on the energy of an mQCA, one of the most promising features of this technology.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2179801063",
    "type": "article"
  },
  {
    "title": "A Low-Power Variation-Aware Adaptive Write Scheme for Access-Transistor-Free Memristive Memory",
    "doi": "https://doi.org/10.1145/2717313",
    "publication_date": "2015-08-03",
    "publication_year": 2015,
    "authors": "Amirali Ghofrani; Miguel-angel lastras-montaño; Siddharth Gaba; Melika Payvand; Wei Lü; Luke Theogarajan; Kwang‐Ting Cheng",
    "corresponding_authors": "",
    "abstract": "Recent advances in access-transistor-free memristive crossbars have demonstrated the potential of memristor arrays as high-density and ultra-low-power memory. However, with considerable variations in the write-time characteristics of individual memristors, conventional fixed-pulse write schemes cannot guarantee reliable completion of the write operations and waste significant amount of energy. We propose an adaptive write scheme that adaptively adjusts the write pulses to address such variations in memristive arrays, resulting in 7×--11× average energy saving in our case studies. Our scheme embeds an online monitor to detect the completion of a write operation and takes into account the parasitic effect of line-shared devices in access-transistor-free crossbars. This feature also helps shorten the test time of memory march algorithms by eliminating the need of a verifying read right after a write, which is commonly employed in the test sequences of march algorithms.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2214739846",
    "type": "article"
  },
  {
    "title": "Electro-Photonic NoC Designs for Kilocore Systems",
    "doi": "https://doi.org/10.1145/2967614",
    "publication_date": "2016-11-03",
    "publication_year": 2016,
    "authors": "José Luis Abellán; Chao Chen; Ajay Joshi",
    "corresponding_authors": "",
    "abstract": "The increasing core count in manycore systems requires a corresponding large Network-on-chip (NoC) bandwidth to support the overlying applications. However, it is not possible to provide this large bandwidth in an energy-efficient manner using electrical link technology. To overcome this issue, photonic link technology has been proposed as a replacement. This work explores the limits and opportunities for using photonic links to design the NoC architecture for a future Kilocore system. Three different NoC designs are explored: ElecNoC, an electrical concentrated two-dimensional- (2D) mesh NoC; HybNoC, an electrical concentrated 2D mesh with a photonic multi-crossbar NoC; and PhotoNoC, a photonic multi-bus NoC. We consider both private and shared cache architectures and, to leverage the large bandwidth density of photonic links, we investigate the use of prefetching and aggressive non-blocking caches. Our analysis using contemporary Big Data workloads shows that the non-blocking caches with a shared LLC can best leverage the large bandwidth of the photonic links in the Kilocore system. Moreover, compared to ElecNoC-based and HybNoC-based Kilocore systems, a PhotoNoC-based Kilocore system achieves up to 2.5× and 1.5× better performance, respectively, and can support up to 2.1× and 1.1× higher bandwidth, respectively, while dissipating comparable power in the overall system.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2547515966",
    "type": "article"
  },
  {
    "title": "Robust and Attack Resilient Logic Locking with a High Application-Level Impact",
    "doi": "https://doi.org/10.1145/3446215",
    "publication_date": "2021-05-11",
    "publication_year": 2021,
    "authors": "Yuntao Liu; Michael Zuzak; Yang Xie; Abhishek Chakraborty; Ankur Srivastava",
    "corresponding_authors": "",
    "abstract": "Logic locking is a hardware security technique aimed at protecting intellectual property against security threats in the IC supply chain, especially those posed by untrusted fabrication facilities. Such techniques incorporate additional locking circuitry within an integrated circuit (IC) that induces incorrect digital functionality when an incorrect verification key is provided by a user. The amount of error induced by an incorrect key is known as the effectiveness of the locking technique. A family of attacks known as “SAT attacks” provide a strong mathematical formulation to find the correct key of locked circuits. To achieve high SAT resilience (i.e., complexity of SAT attacks), many conventional logic locking schemes fail to inject sufficient error into the circuit when the key is incorrect. For example, in the case of SARLock and Anti-SAT, there are usually very few (or only one) input minterms that cause any error at the circuit output. The state-of-the-art s tripped functionality logic locking (SFLL) technique provides a wide spectrum of configurations that introduced a tradeoff between SAT resilience and effectiveness. In this work, we prove that such a tradeoff is universal among all logic locking techniques. To attain high effectiveness of locking without compromising SAT resilience, we propose a novel logic locking scheme, called Strong Anti-SAT (SAS). In addition to SAT attacks, removal-based attacks are another popular kind of attack formulation against logic locking where the attacker tries to identify and remove the locking structure. Based on SAS, we also propose Robust SAS (RSAS) that is resilient to removal attacks and maintains the same SAT resilience and effectiveness as SAS. SAS and RSAS have the following significant improvements over existing techniques. (1) We prove that the SAT resilience of SAS and RSAS against SAT attack is not compromised by increase in effectiveness . (2) In contrast to prior work that focused solely on the circuit-level locking impact, we integrate SAS-locked modules into an 80386 processor and show that SAS has a high application-level impact. (3) Our experiments show that SAS and RSAS exhibit better SAT resilience than SFLL and their effectiveness is similar to SFLL.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W3163519515",
    "type": "article"
  },
  {
    "title": "Improving Barnes-Hut t-SNE Algorithm in Modern GPU Architectures with Random Forest KNN and Simulated Wide-Warp",
    "doi": "https://doi.org/10.1145/3447779",
    "publication_date": "2021-06-30",
    "publication_year": 2021,
    "authors": "Bruno H. Meyer; Aurora Pozo; Wagner M. Nunan Zola",
    "corresponding_authors": "",
    "abstract": "The t-Distributed Stochastic Neighbor Embedding (t-SNE) is a widely used technique for dimensionality reduction but is limited by its scalability when applied to large datasets. Recently, BH-tSNE was proposed; this is a successful approximation that transforms a step of the original algorithm into an N-Body simulation problem that can be solved by a modified Barnes-Hut algorithm. However, this improvement still has limitations to process large data volumes (millions of records). Late studies, such as t-SNE-CUDA, have used GPUs to implement highly parallel BH-tSNE. In this research we have developed a new GPU BH-tSNE implementation that produces the embedding of multidimensional data points into three-dimensional space. We examine scalability issues in two of the most expensive steps of GPU BH-tSNE by using efficient memory access strategies , recent acceleration techniques , and a new approach to compute the KNN graph structure used in BH-tSNE with GPU. Our design allows up to 460% faster execution when compared to the t-SNE-CUDA implementation. Although our SIMD acceleration techniques were used in a modern GPU setup, we have also verified a potential for applications in the context of multi-core processors.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W3176637524",
    "type": "article"
  },
  {
    "title": "A Quality-assured Approximate Hardware Accelerators–based on Machine Learning and Dynamic Partial Reconfiguration",
    "doi": "https://doi.org/10.1145/3462329",
    "publication_date": "2021-08-20",
    "publication_year": 2021,
    "authors": "Mahmoud Masadeh; Yassmeen Elderhalli; Osman Hasan; Sofiène Tahar",
    "corresponding_authors": "",
    "abstract": "Machine learning is widely used these days to extract meaningful information out of the Zettabytes of sensors data collected daily. All applications require analyzing and understanding the data to identify trends, e.g., surveillance, exhibit some error tolerance. Approximate computing has emerged as an energy-efficient design paradigm aiming to take advantage of the intrinsic error resilience in a wide set of error-tolerant applications. Thus, inexact results could reduce power consumption, delay, area, and execution time. To increase the energy-efficiency of machine learning on FPGA, we consider approximation at the hardware level, e.g., approximate multipliers. However, errors in approximate computing heavily depend on the application, the applied inputs, and user preferences. However, dynamic partial reconfiguration has been introduced, as a key differentiating capability in recent FPGAs, to significantly reduce design area, power consumption, and reconfiguration time by adaptively changing a selective part of the FPGA design without interrupting the remaining system. Thus, integrating “Dynamic Partial Reconfiguration” (DPR) with “Approximate Computing” (AC) will significantly ameliorate the efficiency of FPGA-based design approximation. In this article, we propose hardware-efficient quality-controlled approximate accelerators, which are suitable to be implemented in FPGA-based machine learning algorithms as well as any error-resilient applications. Experimental results using three case studies of image blending, audio blending, and image filtering applications demonstrate that the proposed adaptive approximate accelerator satisfies the required quality with an accuracy of 81.82%, 80.4%, and 89.4%, respectively. On average, the partial bitstream was found to be 28.6 <?TeX $\\times$?> smaller than the full bitstream .",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W3193875697",
    "type": "article"
  },
  {
    "title": "<i>NN-Lock</i> : A Lightweight Authorization to Prevent IP Threats of Deep Learning Models",
    "doi": "https://doi.org/10.1145/3505634",
    "publication_date": "2022-02-02",
    "publication_year": 2022,
    "authors": "Manaar Alam; Sayandeep Saha; Debdeep Mukhopadhyay; Sandip Kundu",
    "corresponding_authors": "",
    "abstract": "The prevalent usage and unparalleled recent success of Deep Neural Network (DNN) applications have raised the concern of protecting their Intellectual Property (IP) rights in different business models to prevent the theft of trade secrets. In this article, we propose a lightweight, generic, key-based DNN IP protection methodology, NN-Lock , to defend against unauthorized usage of stolen DNN models. NN-Lock utilizes SBox, a cryptographic primitive, with good security properties to encrypt each parameter of a trained DNN model with the secret keys derived from a master key through a key-scheduling algorithm. The method ensures that only an authorized user with a correct master key can accurately use the locked DNN model. Evaluation results of NN-Lock on a Google Coral edge device for various DNN architectures on several datasets show that for an incorrect master key, the accuracy of a locked model is that of a random classifier. The dense network of encrypted parameters makes the method robust against the model fine-tuning attack and a novel approximation attack using the Genetic Algorithm, which achieves reasonable success against another recent IP protection scheme called HPNN Chakraborty et al. 2020 . The security evaluation of NN-Lock against other families of attacks demonstrates its soundness in practical scenarios. NN-Lock does not modify any internal structure of a DNN model, making it scalable for all of the existing DNN implementations without adversely affecting their performance.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W4210690620",
    "type": "article"
  },
  {
    "title": "NORM: An FPGA-based Non-volatile Memory Emulation Framework for Intermittent Computing",
    "doi": "https://doi.org/10.1145/3517812",
    "publication_date": "2022-03-23",
    "publication_year": 2022,
    "authors": "Simone Ruffini; Luca Caronti; Kasım Sinan Yıldırım; Davide Brunelli",
    "corresponding_authors": "",
    "abstract": "Today’s intermittent computing systems operate by relying only on harvested energy accumulated in their tiny energy reservoirs, typically capacitors. An intermittent device dies due to a power failure when there is no energy in its capacitor and boots again when the harvested energy is sufficient to power its hardware components. Power failures prevent the forward progress of computation due to the frequent loss of computational state. To remedy this problem, intermittent computing systems comprise built-in fast non-volatile memories with high write endurance to store information that persists despite frequent power failures. However, the lack of design tools makes fast-prototyping these systems difficult. Even though FPGAs are common platforms for fast prototyping and behavioral verification of continuously powered architectures, they do not target prototyping intermittent computing systems. This article introduces a new FPGA-based framework, named NORM ( N on-volatile mem OR y e M ulator), to emulate and verify the behavior of any intermittent computing system that exploits fast non-volatile memories. Our evaluation showed that NORM can be used to emulate and validate FeRAM-based transiently powered hardware architectures successfully.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W4220965907",
    "type": "article"
  },
  {
    "title": "Thermal and Performance Efficient On-Chip Surface-Wave Communication for Many-Core Systems in Dark Silicon Era",
    "doi": "https://doi.org/10.1145/3501771",
    "publication_date": "2022-03-22",
    "publication_year": 2022,
    "authors": "Ammar Karkar; Nizar Dahir; Terrence Mak; Kin‐Fai Tong",
    "corresponding_authors": "",
    "abstract": "Due to the exceedingly high integration density of VLSI circuits and the resulting high power density, thermal integrity became a major challenge. One way to tackle this problem is Dark silicon. Dark silicon is the amount of circuitry in a chip that is forced to switch off to insure thermal integrity of the system and prevent permanent thermal-related faults. In many-core systems, the presence of Dark Silicon adds new design constraints, in general, and on the communication fabric of such systems, in particular. This is due to the fact that system-level thermal-management systems tend to increase the distance between high activity cores to insure better thermal balancing and integrity. Consequently, a designing dilemma is created where a compromise has to be made between interconnect performance and power consumption. This study proposes a hybrid wire and surface-wave interconnect (SWI) based Network-on-Chip (NoC) to address the dark silicon challenge. Through efficient utilization of one-hop cross the chip communication SWI links, the proposed architecture is able to offer an efficient and scalable communication platform in terms of performance, power, and thermal impact. As a result, evaluations of the proposed architecture compared to baseline architecture under dark silicon scenarios show reduction in maximum temperature by 15∘C, average delay up to 73.1%, and energy-saving up to ∼3X. This study explores the promising potential of the proposed architecture in extending the utilization wall for current and future many-core systems in dark silicon era.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W4221095969",
    "type": "article"
  },
  {
    "title": "Extreme Partial-Sum Quantization for Analog Computing-In-Memory Neural Network Accelerators",
    "doi": "https://doi.org/10.1145/3528104",
    "publication_date": "2022-06-29",
    "publication_year": 2022,
    "authors": "Yulhwa Kim; Hyungjun Kim; Jae‐Joon Kim",
    "corresponding_authors": "",
    "abstract": "In Analog Computing-in-Memory (CIM) neural network accelerators, analog-to-digital converters (ADCs) are required to convert the analog partial sums generated from a CIM array to digital values. The overhead from ADCs substantially degrades the energy efficiency of CIM accelerators so that previous works attempted to lower the ADC resolution considering the distribution of the partial sums. Despite the efforts, the required ADC resolution still remains relatively high. In this article, we propose the data-driven partial sum quantization scheme, which exhaustively searches for the optimal quantization range with little computational burden. We also report that analyzing the characteristics of the partial sum distributions at each layer gives an additional information to further reduce the ADC resolution compared to previous works that mostly used the characteristics of the partial sum distributions of the entire network. Based on the finer-level data-driven approach combined with retraining, we present a methodology for extreme partial-sum quantization. Experimental results show that the proposed method can reduce the ADC resolution to 2 to 3 bits for CIFAR-10 dataset, which is the smaller ADC bit resolution than any previous CIM-based NN accelerators.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W4300228436",
    "type": "article"
  },
  {
    "title": "Error-Aware Training for In-RRAM Computing Design Considering Non-Ideal Effects in RRAM Crossbar Array and Peripheral Circuits",
    "doi": "https://doi.org/10.1145/3711830",
    "publication_date": "2025-01-28",
    "publication_year": 2025,
    "authors": "Shih-Han Chang; Rainfield Y. Yen; Chien‐Nan Jimmy Liu",
    "corresponding_authors": "",
    "abstract": "In recent years, computing in-memory (CIM) technology has been proposed to solve the bottleneck of data movement in AI edge designs. In-RRAM computing (IRC) is a popular architecture due to its low leakage current and high density. However, to integrate some simple computation in memory, the IRC designs often adopt analog operations, which bring new issues to the computation accuracy. In order to speed up the verification of computation results, an accurate behavioral model for the RRAM crossbar array and the peripheral circuits with non-ideal effects are proposed. By using the proposed behavioral model, we build a hierarchical simulation framework for IRC system to provide run-time errors for circuit design optimization and CNN training. As shown in the experimental results, the simulation accuracy of IRC system is greatly improved by considering the contribution from peripheral circuits, but the simulation time can be reduced from several hours to one minute. The error-aware CNN training with the proposed models efficiently improves the CNN inference accuracy in real applications, which solves the accuracy and efficiency issues in traditional approaches.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4406902211",
    "type": "article"
  },
  {
    "title": "CosMoS: Architectural Support for Cost-Effective Data Movement in a Disaggregated Memory Systems",
    "doi": "https://doi.org/10.1145/3725218",
    "publication_date": "2025-03-19",
    "publication_year": 2025,
    "authors": "Amit Puri; John Jose; Venkatesh Tamarapalli",
    "corresponding_authors": "",
    "abstract": "Memory disaggregation has emerged as a strong alternative to traditional server systems for improved memory utilization and scalability. The compute nodes with a small local memory are connected to disaggregated memory pools through memory-semantic interconnects, such as CXL, that support high-bandwidth and low-latency memory access. A primary concern with these systems is high remote memory latency due to the presence of a network interconnect between CPU and memory. A hot page migration is generally deployed in a hybrid memory system to improve the locality of memory access. In this paper, we identify the major challenges in the present OS-based or hardware-based techniques for page migration in disaggregated memory. To this end, we propose CosMoS , an architectural solution for Cos t-effective data Mo vement in a S calable disaggregated memory system that can predict, schedule, and optimize the movement of hot pages between local and remote memory. Our mechanism also eliminates long delays on the critical demand memory accesses to other remote pages that are obstructed during hot page movement. We evaluate CosMoS over many data-centric workloads. Our results show 20% performance improvement with CosMoS compared to the state-of-the-art mechanism and 86% improvement compared to the baseline for a large-scale disaggregated memory system.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4408614834",
    "type": "article"
  },
  {
    "title": "qSAT: Design of an Efficient Quantum Satisfiability Solver for Hardware Equivalence Checking",
    "doi": "https://doi.org/10.1145/3729229",
    "publication_date": "2025-04-10",
    "publication_year": 2025,
    "authors": "Abhoy Kole; Mohammed E. Djeridane; Lennart Weingarten; Kamalika Datta; Rolf Drechsler",
    "corresponding_authors": "",
    "abstract": "The use of Boolean Satisfiability (SAT) solver for hardware verification incurs exponential run-time in several instances. In this work we have proposed an efficient quantum SAT (qSAT) solver for equivalence checking of Boolean circuits employing Grover’s algorithm. The Exclusive-Sum-of-Product (ESOP)-based generation of the Conjunctive Normal Form (CNF) equivalent clauses demands less qubits and minimizes the gates and depth of quantum circuit interpretation. The consideration of reference circuits for verification affecting Grover’s iterations and quantum resources are also presented as a case study. Experimental results are presented assessing the benefits of the proposed verification approach using open-source Qiskit platform and IBM quantum computer.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4409330059",
    "type": "article"
  },
  {
    "title": "Energy-Efficient Probabilistic Bayesian Neural Networks for Resource-Constrained Environments",
    "doi": "https://doi.org/10.1145/3748651",
    "publication_date": "2025-07-14",
    "publication_year": 2025,
    "authors": "M. Ishak; Mohammed Alawad",
    "corresponding_authors": "",
    "abstract": "In the realm of cyber-physical systems, where tight integration between computational and physical elements is paramount, the demand for efficient and scalable machine learning models is ever-present. Bayesian Neural Networks (BNNs) present a promising avenue for tackling complex tasks in such systems, yet their widespread adoption is hindered by computational complexity and resource constraints. To address these challenges, we propose an energy-efficient FPGA implementation of Probabilistic Bayesian Neural Networks (ProbBNN), a novel architecture that leverages probabilistic computing principles to streamline inference in BNNs. In ProbBNN, instead of representing each parameter as a random variable with a mean and variance, a set of parameters for each neuron is represented by a probability density function (PDF) that characterizes the distribution of these random variables, with random streams following the PDFs processed through probabilistic computing principles to propagate uncertainty throughout the network. The adoption of probabilistic computing eliminates the need for expensive Multiply-Accumulate (MAC) operations, further enhancing the scalability and cost-effectiveness of our proposed implementation of ProbBNN in real-world applications. Furthermore, Gaussian Mixture Models (GMMs) are employed to efficiently capture the underlying distributions of weights, thereby reducing the number of BNN parameters. Through evaluation and comparison with traditional BNN architectures, this implementation demonstrates significant improvements in computational efficiency, memory utilization, and energy efficiency, making it well-suited for deployment in resource-constrained cyber-physical systems, where efficient and reliable decision-making is crucial.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4412400250",
    "type": "article"
  },
  {
    "title": "A Golden-Free Unsupervised ML-Assisted Security Approach for Detection of IC Hardware Trojans",
    "doi": "https://doi.org/10.1145/3748652",
    "publication_date": "2025-07-14",
    "publication_year": 2025,
    "authors": "Ashutosh Ghimire; Mohammed Alkurdi; Md Tauhidur Rahman; Saraju P. Mohanty; Fathi Amsaad",
    "corresponding_authors": "",
    "abstract": "Hardware Trojans are deliberate malicious hardware modifications inserted in semiconductor Integrated Circuits (ICs) for the purpose of stealing or leaking sensitive information, as well as disrupting critical systems upon activation. Emerging hardware security research highlights the criticality of employing AI for effective detection within the semiconductor IC supply chain. The efficient detection of these malicious Trojan circuits is of utmost significance, as it holds paramount importance in cultivating trust within the semiconductor IC supply chain. However, prevailing detection methodologies, predominantly reliant on Side-Channel Analysis (SCA), often necessitate the utilization of golden chips for validation. This article heralds a new era in hardware Trojan detection, harnessing the prowess of unsupervised machine learning in conjunction with SCA to eliminate the need for golden data. Employing unsupervised clustering, the methodology not only showcased a superior false-positive rate but also demonstrated a comparable accuracy level when compared to supervised counterparts. Notably, the proposed model exhibited an impressive accuracy rate of 93%, particularly excelling in pinpointing diminutive Trojans triggered by concise events, surpassing the capabilities of preceding techniques. In conclusion, this research advances a paradigm in hardware Trojan detection, emphasizing its potential in enhancing the integrity of semiconductor IC supply chains.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4412400271",
    "type": "article"
  },
  {
    "title": "A Persistent Hierarchical Bloom Filter-based Framework for Scalable Authentication and Tracking of ICs",
    "doi": "https://doi.org/10.1145/3748650",
    "publication_date": "2025-07-30",
    "publication_year": 2025,
    "authors": "Md Mashfiq Rizvee; Fairuz Shadmani Shishir; Tanvir Hossain; Tamzidul Hoque; Domenic Forte; Sumaiya Shomaji",
    "corresponding_authors": "",
    "abstract": "Due to the reliance on untrusted supply chain entities, tracking and authentication of Integrated Circuits (ICs) has become crucial to prevent the rapid proliferation of counterfeits. Physically Unclonable Functions (PUFs) can be used for such IC authentication since they generate unique identifiers for individual ICs. However, PUF-generated signatures are often noisy and traditional solutions like Error Correcting Codes (ECC) are expensive and vulnerable to attacks. Moreover, comprehensive PUF-based authentication at multiple locations of the supply chain at any given time suffers from large storage requirements, high query processing time, and security threats. This article proposes a Persistent Hierarchical Bloom Filter (PHBF) to enable fast, storage-efficient and noise-tolerant authentication to track ICs across the supply chain. The proposed framework is demonstrated using 4,000 PUF-generated signatures from several FPGAs and achieved the highest possible authentication accuracy under temperature-induced and synthetic noise of varied degrees without any ECC. Our comparative analysis of storage and query time requirements against four different solutions for detecting wide range counterfeit ICs shows the significant benefit of PHBF, providing up to \\(10^{5}\\) times faster query processing and 39 times lower storage requirement compared to blockchain.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4412750886",
    "type": "article"
  },
  {
    "title": "Enhancing Blockchain Scalability using Off-Chain and Machine Learning Techniques",
    "doi": "https://doi.org/10.1145/3757743",
    "publication_date": "2025-08-04",
    "publication_year": 2025,
    "authors": "Manjula K. Pawar; Prakashgoud Patil; P. S. Hiremath",
    "corresponding_authors": "",
    "abstract": "Blockchain Technology is a nascent technology that possesses attributes such as immutability, security, transparency, openness, and decentralization. It is widely used in industry and business applications. Though it has the best features, it still suffers from some main characteristics, such as scalability and privacy. Scalability is measured through throughput (transactions per second), space,cost and latency. Bitcoin and Ethereum, which are prominent Blockchain platforms, carry out 7 and 20 transactions per second, respectively. This is much less than popular platforms such as Visa, PayPal, and Amazon, which perform thousands of transactions per second. Therefore, this paper presents comprehensive study of scalability improving techniques for Blockchain and case studies for improving scalability by using some of the techniques. The scalability of Blockchain systems can be enhanced by on-chain, off-chain, and machine learning algorithms.The proposed methodology improves the scalability using off-chain technique for supply chain management and KNN classification for healthcare domain.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4412928617",
    "type": "article"
  },
  {
    "title": "ChaoticImmuneNet: A Chaos-driven Immunity inspired Neural Network paradigm for Embodied Intelligence in Resource-Constrained Devices",
    "doi": "https://doi.org/10.1145/3764930",
    "publication_date": "2025-08-29",
    "publication_year": 2025,
    "authors": "Suraj Kumar Pandey; Shivashankar B. Nair",
    "corresponding_authors": "",
    "abstract": "Edge devices (ED) play a crucial role in enabling intelligent decision-making capabilities for Smart Cyber-Physical Systems (CPS). Nevertheless, it is a challenging objective, given the resource constraint of edge devices. Pre-trained Machine Learning models fail to perform well against real-world data, provided via EDs. Conventional Embodied Artificial Intelligence (AI) strategies outsource the training load to adapt to real-world data. However, the dependence on outsourcing attracts issues related to latency, privacy, scalability, etc. that are detrimental to a CPS. As a solution, this paper proposes ChaoticImmuneNet , a lightweight Embodied AI method that allows onboard learning on resource-constrained EDs, with limited and noisy data. The paper introduces a novel strategy, merging techniques from Artificial Immune Systems and Chaos Theory with a Siamese Neural Network for realising onboard learning. ChaoticImmuneNet differs from Chaotic Neural Networks as the former does not require specialised models and hardware to leverage chaotic dynamics. Experimental studies carried out using three diverse image datasets demonstrate the efficacy of the proposed method when compared with existing onboard learning techniques, in terms of accuracy, time and storage requirements. A real-world deployment of the ChaoticImmuneNet on a real mobile robot, operating within a warehouse prototype testify to its pragmatic utility.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413816514",
    "type": "article"
  },
  {
    "title": "ROS-BDI robots: an agent-based approach for programming the behaviour of autonomous robots",
    "doi": "https://doi.org/10.1145/3765618",
    "publication_date": "2025-09-02",
    "publication_year": 2025,
    "authors": "Maiquel de Brito",
    "corresponding_authors": "Maiquel de Brito",
    "abstract": "The Robotic Operating System (ROS) provides resources that facilitate the development of robots. However, these resources do not provide robots with some features required in complex scenarios, such as goal-oriented behaviour, autonomy, deliberative capabilities, social abilities, and proactivity combined with reactivity. On the other hand, these features are inherent to Belief-Desire-Intention (BDI) agents, whose behaviour results from reasoning over explicit representations of their beliefs (information about the environment), desires (goals to be achieved), and intentions (commitments to those goals). This work addresses the integration between ROS and BDI agents. This integration is addressed both at a conceptual level, where ROS and BDI concepts are aligned, and in a more practical level, where programming tools are presented to program the behaviour of ROS-based robots as BDI agents. The proposal is evaluated through application examples. The results of this work include an integration model and tools to develop these robots.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413934822",
    "type": "article"
  },
  {
    "title": "Analog and Temporary On-chip Memory for ANN Training and Inference",
    "doi": "https://doi.org/10.1145/3765899",
    "publication_date": "2025-09-05",
    "publication_year": 2025,
    "authors": "Shreyas Deshmukh; Raghav Singhal; Shruti Landge; Vivek Saraswat; Anmol Biswas; Abhishek Kadam; Ajay Kumar Singh; Sreenivas Subramoney; Laxmeesha Somappa; Maryam Shojaei Baghini; Udayan Ganguly",
    "corresponding_authors": "",
    "abstract": "On-chip training at the edge becomes a primary requisite for real-time and security-sensitive artificial neural network (ANN) applications. In-memory computation (IMC) techniques have been proposed to facilitate data-intensive computational operations in ANNs. IMC-based multiply-accumulate (MAC) accelerates ANN training but suffers from significant communication overhead between the MAC engine and the off-chip storage for the intermediate data. This paper proposes an analog temporary on-chip memory (ATOM) to store this intermediate data during ANN training. The ANN training architecture with the proposed ATOM has two significant advantages. First, the energy required to store intermediate data is scaled down by \\(\\sim\\) 40 \\(\\times\\) due to the on-chip and analog nature of the memory. Second, the proposed architecture avoids power and area-consuming analog-to-digital converters (ADCs) between neural network stages. The ATOM cell measurements are carried out from 20 fabricated chips, and the impact of ATOM characteristics on ANN system performance accuracy is analyzed. This paper shows significant latency improvement of \\(\\sim\\) 9 \\(\\times\\) and area savings of \\(\\sim\\) 5 \\(\\times\\) for intermediate data storage compared to the on-chip SRAM during ANN training’s forward and backward pass operations. An improvement in the area and latency will be beneficial to instrument the area- and energy-efficient hardware system for on-chip ANN applications.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4414149419",
    "type": "article"
  },
  {
    "title": "Introduction to the Special Issue on Designing Cyber-Physical Systems – From Concepts to Implementation",
    "doi": "https://doi.org/10.1145/3771084",
    "publication_date": "2025-10-07",
    "publication_year": 2025,
    "authors": "Christian Pilato; Francesca Palumbo",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4414914102",
    "type": "article"
  },
  {
    "title": "Evaluation of design strategies for stochastically assembled nanoarray memories",
    "doi": "https://doi.org/10.1145/1084748.1084749",
    "publication_date": "2005-07-01",
    "publication_year": 2005,
    "authors": "Benjamin Gojman; Eric Rachlin; John E. Savage",
    "corresponding_authors": "",
    "abstract": "A key challenge facing nanotechnologies is learning to control uncertainty introduced by stochastic self-assembly. In this article, we explore architectural and manufacturing strategies to cope with this uncertainty when assembling nanoarrays, crossbars composed of two orthogonal sets of parallel nanowires (NWs) that are differentiated at their time of manufacture. NW deposition is a stochastic process and the NW encodings present in an array cannot be known in advance. We explore the reliable construction of memories from stochastically assembled arrays. This is accomplished by describing several families of NW encodings and developing strategies to map external binary addresses onto internal NW encodings using programmable circuitry. We explore a variety of different mapping strategies and develop probabilistic methods of analysis. This is the first article that makes clear the wide range of choices that are available.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W2144892423",
    "type": "article"
  },
  {
    "title": "Partitioning and placement for buildable QCA circuits",
    "doi": "https://doi.org/10.1145/1063803.1063806",
    "publication_date": "2005-03-01",
    "publication_year": 2005,
    "authors": "Sung Kyu Lim; Ramprasad Ravichandran; Mike Niemier",
    "corresponding_authors": "",
    "abstract": "Quantum-dot Cellular Automata (QCA) is a novel computing mechanism that can represent binary information based on spatial distribution of an electron charge configuration in chemical molecules. In this article, we present the first partitioning and placement algorithm for automatic QCA layout. We identify several objectives and constraints that will enhance the buildability of QCA circuits. The results are intended to: (1) define what is computationally interesting and could actually be built within a set of predefined constraints, (2) project what designs will be possible as additional constructs become realizable, and (3) provide a vehicle that we can use to compare QCA systems to silicon-based systems.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W1993251483",
    "type": "article"
  },
  {
    "title": "Reliability analysis for flexible electronics",
    "doi": "https://doi.org/10.1145/1389089.1389092",
    "publication_date": "2008-08-01",
    "publication_year": 2008,
    "authors": "Tsung‐Ching Huang; Kwang‐Ting Cheng; Huai‐Yuan Tseng; Chen‐Pang Kung",
    "corresponding_authors": "",
    "abstract": "Flexible electronics fabricated on thin-film, lightweight, and bendable substrates (e.g., plastic) have great potential for novel applications in consumer electronics such as flexible displays, e-paper, and smart labels; however, the key elements, namely thin-film transistors (TFTs), for implementing flexible circuits often suffer from electrical instability. Therefore, thorough reliability analysis is critical for flexible circuit design to ensure that the circuit will operate reliably throughout its lifetime. In this article we propose a methodology for reliability simulation of hydrogenated amorphous silicon (a-Si:H) TFT circuits. We show that: (1) the threshold voltage ( V TH ) shift of a single TFT can be estimated by analyzing its operating conditions; and (2) the circuit lifetime can be predicted accordingly by using SPICE-like simulators with proper modeling. We also propose an algorithm to reduce the simulation time by orders of magnitude, with good prediction accuracy. To validate our analytical model and simulation methodology, we compare simulation results with the actual circuit measurements of an integrated a-Si:H TFT scan driver fabricated on a glass substrate and we demonstrate very good consistency.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W2085469852",
    "type": "article"
  },
  {
    "title": "Defects and faults in QCA-based PLAs",
    "doi": "https://doi.org/10.1145/1543438.1543441",
    "publication_date": "2009-07-01",
    "publication_year": 2009,
    "authors": "Michael Crocker; Xiaobo Sharon Hu; Michael Niemier",
    "corresponding_authors": "",
    "abstract": "Defect tolerance will be critical in any system with nanoscale feature sizes. This article examines some fundamental aspects of defect tolerance for a reconfigurable system based on Quantum-dot Cellular Automata (QCA). We analyze a novel, QCA-based, Programmable Logic Array (PLA) structure, develop an implementation independent fault model, and discuss how expected defects and faults might affect yield. Within this context, we introduce techniques for mapping Boolean logic functions to a defective QCA-based PLA. Simulation results show that our new mapping techniques can achieve higher yields than existing techniques.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2032503831",
    "type": "article"
  },
  {
    "title": "A Reconfigurable PLA Architecture for Nanomagnet Logic",
    "doi": "https://doi.org/10.1145/2093145.2093146",
    "publication_date": "2012-02-01",
    "publication_year": 2012,
    "authors": "Michael Crocker; Michael Niemier; Xiaobo Sharon Hu",
    "corresponding_authors": "",
    "abstract": "In order to continue the performance and scaling trends that we have come to expect from Moore’s Law, many emergent computational models, devices, and technologies are actively being studied to either replace or augment CMOS technology. Nanomagnet Logic (NML) is one such alternative. NML operates at room temperature, it has the potential for low power consumption, and it is CMOS compatible. In this aricle, we present an NML programmable logic array (PLA) based on a previously proposed reprogrammable quantum-dot cellular automata PLA design. We also discuss the fabrication and simulation validation of the circuit structures unique to the NML PLA, present area, energy, and delay estimates for the NML PLA, compare the area of NML PLAs to other reprogrammable nanotechnologies, and analyze how architectural-level redundancy will affect performance and defect tolerance in NML PLAs. We will use results from this study to shape a concluding discussion about, which architectures appear to be most suitable for NML.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W1985450948",
    "type": "article"
  },
  {
    "title": "Energy-Efficient Pipeline Templates for High-Performance Asynchronous Circuits",
    "doi": "https://doi.org/10.1145/2043643.2043649",
    "publication_date": "2011-12-01",
    "publication_year": 2011,
    "authors": "Basit Riaz Sheikh; Rajit Manohar",
    "corresponding_authors": "",
    "abstract": "We present two novel energy-efficient pipeline templates for high throughput asynchronous circuits. The proposed templates, called N-P and N-Inverter pipelines, use a single-track handshake protocol. There are multiple stages of logic within each pipeline. The proposed techniques minimize handshake overheads associated with input tokens and intermediate logic nodes within a pipeline template. Each template can pack a significant amount of logic in a single stage, while still maintaining a fast cycle time of only 18 transitions. Noise and timing robustness constraints of our pipelined circuits are quantified across all process corners. We present completion detection scheme based on wide NOR gates, which results in significant latency and energy savings especially as the number of outputs increase. To fully quantify all design trade-offs, three separate pipeline implementations of an 8x8-bit Booth-encoded array multiplier are presented. Compared to a standard QDI pipeline implementation, the N-Inverter and N-P pipeline implementations reduced the energy-delay product by 38.5% and 44% respectively. The overall multiplier latency was reduced by 20.2% and 18.7%, while the total transistor width was reduced by 35.6% and 46% with N-Inverter and N-P pipeline templates respectively.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2155567724",
    "type": "article"
  },
  {
    "title": "Online Adaptation and Energy Minimization for Hardware Recurrent Spiking Neural Networks",
    "doi": "https://doi.org/10.1145/3145479",
    "publication_date": "2018-01-11",
    "publication_year": 2018,
    "authors": "Yu Liu; Yingyezhe Jin; Peng Li",
    "corresponding_authors": "",
    "abstract": "The Liquid State Machine (LSM) is a promising model of recurrent spiking neural networks that provides an appealing brain-inspired computing paradigm for machine-learning applications such as pattern recognition. Moreover, processing information directly on spiking events makes the LSM well suited for cost- and energy-efficient hardware implementation. In this article, we systematically present three techniques for optimizing energy efficiency while maintaining good performance of the proposed LSM neural processors from both an algorithmic and hardware implementation point of view. First, to realize adaptive LSM neural processors, thus boost learning performance, we propose a hardware-friendly Spike-Timing Dependent Plastic (STDP) mechanism for on-chip tuning. Then, the LSM processor incorporates a novel runtime correlation-based neuron gating scheme to minimize the power dissipated by reservoir neurons. Furthermore, an activity-dependent clock gating approach is presented to address the energy inefficiency due to the memory-intensive nature of the proposed neural processors. Using two different real-world tasks of speech and image recognition to benchmark, we demonstrate that the proposed architecture boosts the average learning performance by up to 2.0% while reducing energy dissipation by up to 29% compared to a baseline LSM with little extra hardware overhead on a Xilinx Virtex-6 FPGA.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2783304281",
    "type": "article"
  },
  {
    "title": "Efficient Memristor-Based Architecture for Intrusion Detection and High-Speed Packet Classification",
    "doi": "https://doi.org/10.1145/3264819",
    "publication_date": "2018-10-31",
    "publication_year": 2018,
    "authors": "Venkataramesh Bontupalli; Chris Yakopcic; Raqibul Hasan; Tarek M. Taha",
    "corresponding_authors": "",
    "abstract": "Deep packet inspection (DPI) is a critical component to prevent intrusion detection. This requires a detailed analysis of each network packet header and body. Although this is often done on dedicated high-power servers in most networked systems, mobile systems could potentially be vulnerable to attack if utilized on an unprotected network. In this case, having DPI hardware on the mobile system would be highly beneficial. Unfortunately, DPI hardware is generally area and power consuming, making its implementation difficult in mobile systems. We developed a memristor crossbar-based approach, inspired by memristor crossbar neuromorphic circuits, for a low-power, low-area, and high-throughput DPI system that examines both the header and body of a packet. Two key types of circuits are presented: static pattern matching and regular expression circuits. This system is able to reduce execution time and power consumption due to its high-density grid and massive parallelism. Independent searches are performed using low-power memristor crossbar arrays giving rise to a throughput of 160Gbps with no loss in the classification accuracy.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2902382446",
    "type": "article"
  },
  {
    "title": "Toward Human-Scale Brain Computing Using 3D Wafer Scale Integration",
    "doi": "https://doi.org/10.1145/2976742",
    "publication_date": "2017-04-20",
    "publication_year": 2017,
    "authors": "Arvind Kumar; Zhe Wan; W. W. Wilcke; Subramanian S. Iyer",
    "corresponding_authors": "",
    "abstract": "The Von Neumann architecture, defined by strict and hierarchical separation of memory and processor, has been a hallmark of conventional computer design since the 1940s. It is becoming increasingly unsuitable for cognitive applications, which require massive parallel processing of highly interdependent data. Inspired by the brain, we propose a significantly different architecture characterized by a large number of highly interconnected simple processors intertwined with very large amounts of low-latency memory. We contend that this memory-centric architecture can be realized using 3D wafer scale integration for which the technology is nearing readiness, combined with current CMOS device technologies. The natural fault tolerance and lower power requirements of neuromorphic processing make 3D wafer stacking particularly attractive. In order to assess the performance of this architecture, we propose a specific embodiment of a neuronal system using 3D wafer scale integration; formulate a simple model of brain connectivity including short- and long-range connections; and estimate the memory, bandwidth, latency, and power requirements of the system using the connectivity model. We find that 3D wafer scale integration, combined with technologies nearing readiness, offers the potential for scaleup to a primate-scale brain, while further scaleup to a human-scale brain would require significant additional innovations.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2605389065",
    "type": "article"
  },
  {
    "title": "A Chip-Level Anti-Reverse Engineering Technique",
    "doi": "https://doi.org/10.1145/3173462",
    "publication_date": "2018-04-30",
    "publication_year": 2018,
    "authors": "Shuai Chen; Junlin Chen; Lei Wang",
    "corresponding_authors": "",
    "abstract": "Protection of intellectual property (IP) is increasingly critical for IP vendors in the semiconductor industry. However, advanced reverse engineering techniques can physically disassemble the chip and derive the IPs at a much lower cost than the value of IP design that chips carry. This invasive hardware attack—obtaining information from IC chips—always violates the IP rights of vendors. The intent of this article is to present a chip-level reverse engineering resilient design technique. In the proposed technique, transformable interconnects enable an IC chip to maintain functioning in normal use and to transform its physical structure into another pattern when exposed to invasive attacks. The newly created pattern will significantly increase the difficulty of reverse engineering. Furthermore, to improve the effectiveness of the proposed technique, a systematic design method is developed targeting integrated circuits with multiple design constraints. Simulations have been conducted to demonstrate the capability of the proposed technique, which generates extremely large complexity for reverse engineering with manageable overhead.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2884022241",
    "type": "article"
  },
  {
    "title": "Heterogeneous Scheduling of Deep Neural Networks for Low-power Real-time Designs",
    "doi": "https://doi.org/10.1145/3358699",
    "publication_date": "2019-10-31",
    "publication_year": 2019,
    "authors": "Colin Shea; Tinoosh Mohsenin",
    "corresponding_authors": "",
    "abstract": "Deep neural networks have become the readiest answer to a range of application challenges including image recognition, stock analysis, natural language processing, and biomedical applications such as seizure detection. All while outperforming prior leading solutions that relied heavily on hand-engineered techniques. However, deployment of these neural networks often requires high-computational and memory-intensive solutions. These requirements make it challenging to deploy Deep Neural Networks (DNNs) in embedded, real-time low-power applications where classic architectures, GPUs and CPUs, still impose significant power burden. Systems-on-Chip (SoC) with Field-programmable Gate Arrays (FPGAs) can be used to improve performance and allow more fine-grain control of resources than CPUs or GPUs, but it is difficult to find the optimal balance between hardware and software to improve DNN efficiency. In the current research literature there have been few proposed solutions to address optimizing hardware and software deployments of DNNs in embedded low-power systems. To address the computation resource restriction and low-power needs for deploying these networks, we describe and implement a domain-specific metric model for optimizing task deployment on differing platforms, hardware and software. Next, we propose a DNN hardware accelerator called Scalable Low-power Accelerator for real-time deep neural Networks (SCALENet) that includes multithreaded software workers. Finally, we propose a heterogeneous aware scheduler that uses the DNN-specific metric models and the SCALENet accelerator to allocate a task to a resource based on solving a numerical cost for a series of domain objectives. To demonstrate the applicability of our contribution, we deploy nine modern deep network architectures, each containing a different number of parameters within the context of two different neural network applications: image processing and biomedical seizure detection. Utilizing the metric modeling techniques integrated into the heterogeneous aware scheduler and the SCALENet accelerator, we demonstrate the ability to meet computational requirements, adapt to multiple architectures, and lower power by providing an optimized task to resource allocation. Our heterogeneous aware scheduler improves power saving by decreasing power consumption by 10% of the total system power, does not affect the accuracy of the networks, and still meets the real-time deadlines. We demonstrate the ability to achieve parity with or exceed the energy efficiency of NVIDIA GPUs when evaluated against Jetson TK1 with embedded GPU SoC and with a 4× power savings in a power envelope of 2.0W. When compared to existing FPGA-based accelerators, SCALENet’s accelerator and heterogeneous aware scheduler achieves a 4× improvement in energy efficiency.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W3029362297",
    "type": "article"
  },
  {
    "title": "mNoC",
    "doi": "https://doi.org/10.1145/2700241",
    "publication_date": "2015-08-03",
    "publication_year": 2015,
    "authors": "Jun Pang; Christopher Dwyer; Alvin R. Lebeck",
    "corresponding_authors": "",
    "abstract": "Moore's law and the continuity of device scaling have led to an increasing number of cores/nodes on a chip, creating a need for new mechanisms to achieve high-performance and power-efficient Network-on-Chip (NoC). Nanophotonics based NoCs provide for higher bandwidth and more power efficient designs than electronic networks. Present approaches often use an external laser source, ring resonators, and waveguides. However, they still suffer from important limitations: large static power consumption, and limited network scalability. In this article, we explore the use of emerging molecular scale devices to construct nanophotonic networks: Molecular-scale Network-on-Chip (mNoC). We leverage on-chip emitters such as quantum dot LEDs, which provide electrical to optical signal modulation, and chromophores, which provide optical signal filtering for receivers. These devices replace the ring resonators and the external laser source used in contemporary nanophotonic NoCs. They reduce energy consumption or enable scaling to larger crossbars for a reduced energy budget. We present a Single Writer Multiple Reader (SWMR) bus based crossbar mNoC. Our evaluation shows that an mNoC can achieve more than 88% reduction in energy for a 64×64 crossbar compared to similar ring resonator based designs. Additionally, an mNoC can scale to a 256×256 crossbar with an average 10% performance improvement and 54% energy reduction.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W1576557079",
    "type": "article"
  },
  {
    "title": "Software rejuvenation scheduling using accelerated life testing",
    "doi": "https://doi.org/10.1145/2539118",
    "publication_date": "2014-01-01",
    "publication_year": 2014,
    "authors": "Jing Zhao; Yuliang Jin; Kishor S. Trivedi; Rivalino Matias; Yanbin Wang",
    "corresponding_authors": "",
    "abstract": "A number of studies have reported the phenomenon of “Software aging”, caused by resource exhaustion and characterized by progressive software performance degradation. In this article, we carry out an experimental study of software aging and rejuvenation for an on-line bookstore application, following the standard configuration of TPC-W benchmark. While real website is used for the bookstore, the clients are emulated. In order to reduce the time to application failures caused by memory leaks, we use the accelerated life testing (ALT) approach. We then select the Weibull time to failure distribution at normal level, to be used in a semi-Markov process, to compute the optimal software rejuvenation trigger interval. Since the validation of optimal rejuvenation trigger interval with emulated browsers will take an inordinate long time, we develop a simulation model to validate the ALT experimental results, and also estimate the steady-state availability to cross-validate the results of the semi-Markov availability model.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2016510053",
    "type": "article"
  },
  {
    "title": "A Rule-Based Design Specification Language for Synthetic Biology",
    "doi": "https://doi.org/10.1145/2641571",
    "publication_date": "2014-12-30",
    "publication_year": 2014,
    "authors": "Ernst Oberortner; Swapnil Bhatia; Erik Lindgren; Douglas Densmore",
    "corresponding_authors": "",
    "abstract": "Synthetic Biology is an engineering discipline where parts of DNA sequences are composed into novel, complex systems that execute a desired biological function. Functioning and well-behaving biological systems adhere to a certain set of biological “rules”. Data exchange standards and Bio-Design Automation (BDA) tools support the organization of part libraries and the exploration of rule-compliant compositions. In this work, we formally define a design specification language, enabling the integration of biological rules into the Synthetic Biology engineering process. The supported rules are divided into five categories: Counting , Pairing , Positioning , Orientation , and Interactions . We formally define the semantics of each rule, characterize the language's expressive power, and perform a case study in that we iteratively design a genetic Priority Encoder circuit following two alternative paradigms—rule-based and template-driven. Ultimately, we touch a method to approximate the complexity and time to computationally enumerate all rule-compliant designs. Our specification language may or may not be expressive enough to capture all designs that a Synthetic Biologist might want to describe, or the complexity one might find through experiments. However, computational support for the acquisition, specification, management, and application of biological rules is inevitable to understand the functioning of biology.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2016562518",
    "type": "article"
  },
  {
    "title": "Toward a Sparse Self-Organizing Map for Neuromorphic Architectures",
    "doi": "https://doi.org/10.1145/2638559",
    "publication_date": "2015-04-27",
    "publication_year": 2015,
    "authors": "Laurent Rodriguez; Benoît Miramond; Bertrand Granado",
    "corresponding_authors": "",
    "abstract": "Neurobiological systems have often been a source of inspiration for computational science and engineering, but in the past their impact has also been limited by the understanding of biological models. Today, new technologies lead to an equilibrium situation where powerful and complex computers bring new biological knowledge of the brain behavior. At this point, we possess sufficient understanding to both imagine new brain-inspired computing paradigms and to sustain a classical paradigm which reaches its end programming and intellectual limitations. In this context, we propose to reconsider the computation problem first in the specific domain of mobile robotics. Our main proposal consists in considering computation as part of a global adaptive system, composed of sensors, actuators, a source of energy and a controlling unit. During the adaptation process, the proposed brain-inspired computing structure does not only execute the tasks of the application but also reacts to the external stimulation and acts on the emergent behavior of the system. This approach is inspired by cortical plasticity in mammalian brains and suggests developing the computation architecture along the system's experience. This article proposes modeling this plasticity as a problem of estimating a probability density function. This function would correspond to the nature and the richness of the environment perceived through multiple modalities. We define and develop a novel neural model solving the problem in a distributed and sparse manner. And we integrate this neural map into a bio-inspired hardware substrate that brings the plasticity property into parallel many-core architectures. The approach is then called Hardware Plasticity. The results show that the self-organization properties of our model solve the problem of multimodal sensory data clusterization. The properties of the proposed model allow envisaging the deployment of this adaptation layer into hardware architectures embedded into the robot's body in order to build intelligent controllers.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2152029740",
    "type": "article"
  },
  {
    "title": "A Novel Approach to Optimize Fault-Tolerant Hybrid Wireless Network-on-Chip Architectures",
    "doi": "https://doi.org/10.1145/2814572",
    "publication_date": "2016-03-15",
    "publication_year": 2016,
    "authors": "Abbas Dehghani; Kamal Jamshidi",
    "corresponding_authors": "",
    "abstract": "Wireless Network-on-Chip (WNoC) architectures have emerged as a promising interconnection infrastructure to address the performance limitations of traditional wire-based multihop NOCs. Nevertheless, the WNoC systems encounter high failure rates due to problems pertaining to integration and manufacturing of wireless interconnection in nano-domain technology. As a result, the permanent failures may lead to the formation of any shape of faulty regions in the interconnection network, which can break down the whole system. This issue is not investigated in previous studies on WNoC architectures. Our solution advocates the adoption of communication structures with both node and link on disjoint paths. On the other hand, the imposed costs of WNoC design must be reasonable. Hence, a novel approach to design an optimized fault-tolerant hybrid hierarchical WNoC architecture for enhancing performance as well as minimizing system costs is proposed. The experimental results indicate that the robustness of this newly proposed design is significantly enhanced in comparison with its the fault-tolerant wire-based counterparts in the presence of various faulty regions under both synthetic and application-specific traffic patterns.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2302400779",
    "type": "article"
  },
  {
    "title": "Rethinking Computer Architectures and Software Systems for Phase-Change Memory",
    "doi": "https://doi.org/10.1145/2893186",
    "publication_date": "2016-05-12",
    "publication_year": 2016,
    "authors": "Cheng‐Wen Wu; Guangyan Zhang; Keqin Li",
    "corresponding_authors": "",
    "abstract": "With dramatic growth of data and rapid enhancement of computing powers, data accesses become the bottleneck restricting overall performance of a computer system. Emerging phase-change memory (PCM) is byte-addressable like DRAM, persistent like hard disks and Flash SSD, and about four orders of magnitude faster than hard disks or Flash SSDs for typical file system I/Os. The maturity of PCM from research to production provides a new opportunity for improving the I/O performance of a system. However, PCM also has some weaknesses, for example, long write latency, limited write endurance, and high active energy. Existing processor cache systems, main memory systems, and online storage systems are unable to leverage the advantages of PCM, and/or to mitigate PCM’s drawbacks. The reason behind this incompetence is that they are designed and optimized for SRAM, DRAM memory, and hard drives, respectively, instead of PCM memory. There have been some efforts concentrating on rethinking computer architectures and software systems for PCM. This article presents a detailed survey and review of the areas of computer architecture and software systems that are oriented to PCM devices. First, we identify key technical challenges that need to be addressed before this memory technology can be leveraged, in the form of processor cache, main memory, and online storage, to build high-performance computer systems. Second, we examine various designs of computer architectures and software systems that are PCM aware. Finally, we obtain several helpful observations and propose a few suggestions on how to leverage PCM to optimize the performance of a computer system.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2348395997",
    "type": "article"
  },
  {
    "title": "Exploiting Data Resilience in Wireless Network-on-chip Architectures",
    "doi": "https://doi.org/10.1145/3379448",
    "publication_date": "2020-04-04",
    "publication_year": 2020,
    "authors": "Giuseppe Ascia; Vincenzo Catania; Salvatore Monteleone; Maurizio Palesi; Davide Patti; John Jose; Valerio Mario Salerno",
    "corresponding_authors": "",
    "abstract": "The emerging wireless Network-on-Chip (WiNoC) architectures are a viable solution for addressing the scalability limitations of manycore architectures in which multi-hop long-range communications strongly impact both the performance and energy figures of the system. The energy consumption of wired links as well as that of radio communications account for a relevant fraction of the overall energy budget. In this article, we extend the approximate computing paradigm to the case of the on-chip communication system in manycore architectures. We present techniques, circuitries, and programming interfaces aimed at reducing the energy consumption of a WiNoC by exploiting the trade-off energy saving vs. application output degradation. The proposed platform—namely, xWiNoC—uses variable voltage swing links and tunable transmitting power wireless interfaces along with a programming interface that allows the programmer to specify those data structures that are error-resilient. Thus, communications induced by the access to such error-resilient data structures are carried out by using links and radio channels that are configured to work in a low energy mode, albeit by exposing a higher bit error rate. xWiNoC is assessed on a set of applications belonging to different domains in which the trade-off energy vs. performance vs. application result quality is discussed. We found that up to 50% of communication energy saving can be obtained with a negligible impact on the application output quality and 3% in application performance degradation.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W3014193078",
    "type": "article"
  },
  {
    "title": "Victims Can Be Saviors",
    "doi": "https://doi.org/10.1145/3439189",
    "publication_date": "2021-01-29",
    "publication_year": 2021,
    "authors": "Manaar Alam; Sarani Bhattacharya; Debdeep Mukhopadhyay",
    "corresponding_authors": "",
    "abstract": "Micro-architectural side-channel attacks are major threats to the most mathematically sophisticated encryption algorithms. In spite of the fact that there exist several defense techniques, the overhead of implementing the countermeasures remains a matter of concern. A promising strategy is to develop online detection and prevention methods for these attacks. Though some recent studies have devised online prevention mechanisms for some categories of these attacks, still other classes remain undetected. Moreover, to detect these side-channel attacks with minimal False Positives is a challenging effort because of the similarity of their behavior with computationally intensive applications. This article presents a generalized machine learning--based multi-layer detection technique that targets these micro-architectural side-channel attacks, while not restricting its attention only on a single category of attacks. The proposed mechanism gathers low-level system information by profiling performance counter events using Linux perf tool and then applies machine learning techniques to analyze the data. A novel approach using time-series analysis of the data is implemented to find out the correlation of the execution trace of the attack process with the secret key of encryption, which helps in dealing with False-Positives and unknown attacks. This article also provides a detailed theoretical analysis of the detection mechanism of the proposed model along with its security analysis. The experimental results show that the proposed method is superior to the state-of-the-art reported techniques with high detection accuracy, low False Positives, and low implementation overhead while being able to detect before the completion of the attack.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W3126382830",
    "type": "article"
  },
  {
    "title": "A Lightweight Architecture for Hardware-Based Security in the Emerging Era of Systems of Systems",
    "doi": "https://doi.org/10.1145/3458824",
    "publication_date": "2021-06-30",
    "publication_year": 2021,
    "authors": "Nico Mexis; Nikolaos Athanasios Anagnostopoulos; Shuai Chen; Jan Bambach; Tolga Arul; Stefan Katzenbeisser",
    "corresponding_authors": "",
    "abstract": "In recent years, a new generation of the Internet of Things (IoT 2.0) is emerging, based on artificial intelligence, the blockchain technology, machine learning, and the constant consolidation of pre-existing systems and subsystems into larger systems. In this work, we construct and examine a proof-of-concept prototype of such a system of systems, which consists of heterogeneous commercial off-the-shelf components, and utilises diverse communication protocols. We recognise the inherent need for lightweight security in this context, and address it by employing a low-cost state-of-the-art security solution. Our solution is based on a novel hardware and software co-engineering paradigm, utilising well-known software-based cryptographic algorithms, in order to maximise the security potential of the hardware security primitive (a Physical Unclonable Function) that is used as a security anchor. The performance of the proposed security solution is evaluated, proving its suitability even for real-time applications. Additionally, the Dolev-Yao attacker model is considered in order to assess the resilience of our solution towards attacks against the confidentiality, integrity, and availability of the examined system of systems. In this way, it is confirmed that the proposed solution is able to address the emerging security challenges of the oncoming era of systems of systems.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W3175358749",
    "type": "article"
  },
  {
    "title": "Design of a Robust Memristive Spiking Neuromorphic System with Unsupervised Learning in Hardware",
    "doi": "https://doi.org/10.1145/3451210",
    "publication_date": "2021-06-30",
    "publication_year": 2021,
    "authors": "Md Musabbir Adnan; Sagarvarma Sayyaparaju; Samuel D. Brown; Mst Shamim Ara Shawkat; Catherine D. Schuman; Garrett S. Rose",
    "corresponding_authors": "",
    "abstract": "Spiking neural networks (SNN) offer a power efficient, biologically plausible learning paradigm by encoding information into spikes. The discovery of the memristor has accelerated the progress of spiking neuromorphic systems, as the intrinsic plasticity of the device makes it an ideal candidate to mimic a biological synapse. Despite providing a nanoscale form factor, non-volatility, and low-power operation, memristors suffer from device-level non-idealities, which impact system-level performance. To address these issues, this article presents a memristive crossbar-based neuromorphic system using unsupervised learning with twin-memristor synapses, fully digital pulse width modulated spike-timing-dependent plasticity, and homeostasis neurons. The implemented single-layer SNN was applied to a pattern-recognition task of classifying handwritten-digits. The performance of the system was analyzed by varying design parameters such as number of training epochs, neurons, and capacitors. Furthermore, the impact of memristor device non-idealities, such as device-switching mismatch, aging, failure, and process variations, were investigated and the resilience of the proposed system was demonstrated.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W3176354051",
    "type": "article"
  },
  {
    "title": "DTA-PUF: Dynamic Timing-aware Physical Unclonable Function for Resource-constrained Devices",
    "doi": "https://doi.org/10.1145/3434281",
    "publication_date": "2021-07-31",
    "publication_year": 2021,
    "authors": "Ioannis Tsiokanos; Jack Miskelly; Chongyan Gu; Máire O’Neill; Georgios Karakonstantis",
    "corresponding_authors": "",
    "abstract": "In recent years, physical unclonable functions (PUFs) have gained a lot of attention as mechanisms for hardware-rooted device authentication. While the majority of the previously proposed PUFs derive entropy using dedicated circuitry, software PUFs achieve this from existing circuitry in a system. Such software-derived designs are highly desirable for low-power embedded systems as they require no hardware overhead. However, these software PUFs induce considerable processing overheads that hinder their adoption in resource-constrained devices. In this article, we propose DTA-PUF, a novel, software PUF design that exploits the instruction- and data-dependent dynamic timing behaviour of pipelined cores to provide a reliable challenge-response mechanism without requiring any extra hardware. DTA-PUF accepts sequences of instructions as an input challenge and produces an output response based on the manifested timing errors under specific over-clocked settings. To lower the required processing effort, we systematically select instruction sequences that maximise error-rate. The application to a post-layout pipelined floating-point unit, which is implemented in 45 nm process technology, demonstrates the effectiveness and practicability of our PUF design. Finally, DTA-PUF requires up to 50× fewer instructions than existing software processor PUF designs, limiting processing costs and resulting in up to 26% power savings.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W3193554820",
    "type": "article"
  },
  {
    "title": "Fortifying Vehicular Security through Low Overhead Physically Unclonable Functions",
    "doi": "https://doi.org/10.1145/3442443",
    "publication_date": "2021-09-29",
    "publication_year": 2021,
    "authors": "Carson Labrado; Himanshu Thapliyal; Saraju P. Mohanty",
    "corresponding_authors": "",
    "abstract": "Within vehicles, the Controller Area Network (CAN) allows efficient communication between the electronic control units (ECUs) responsible for controlling the various subsystems. The CAN protocol was not designed to include much support for secure communication. The fact that so many critical systems can be accessed through an insecure communication network presents a major security concern. Adding security features to CAN is difficult due to the limited resources available to the individual ECUs and the costs that would be associated with adding the necessary hardware to support any additional security operations without overly degrading the performance of standard communication. Replacing the protocol is another option, but it is subject to many of the same problems. The lack of security becomes even more concerning as vehicles continue to adopt smart features. Smart vehicles have a multitude of communication interfaces an attacker could exploit to gain access to the networks. In this work, we propose a security framework that is based on physically unclonable functions (PUFs) and lightweight cryptography (LWC). The framework does not require any modification to the standard CAN protocol while also minimizing the amount of additional message overhead required for its operation. The improvements in our proposed framework result in major reduction in the number of CAN frames that must be sent during operation. For a system with 20 ECUs, for example, our proposed framework only requires 6.5% of the number of CAN frames that is required by the existing approach to successfully authenticate every ECU.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W3203500928",
    "type": "article"
  },
  {
    "title": "A Modular End-to-End Framework for Secure Firmware Updates on Embedded Systems",
    "doi": "https://doi.org/10.1145/3460234",
    "publication_date": "2021-09-29",
    "publication_year": 2021,
    "authors": "Solon Falas; Charalambos Konstantinou; Maria K. Michael",
    "corresponding_authors": "",
    "abstract": "Firmware refers to device read-only resident code which includes microcode and macro-instruction-level routines. For Internet-of-Things (IoT) devices without an operating system, firmware includes all the necessary instructions on how such embedded systems operate and communicate. Thus, firmware updates are essential parts of device functionality. They provide the ability to patch vulnerabilities, address operational issues, and improve device reliability and performance during the lifetime of the system. This process, however, is often exploited by attackers in order to inject malicious firmware code into the embedded device. In this article, we present a framework for secure firmware updates on embedded systems. This approach is based on hardware primitives and cryptographic modules, and it can be deployed in environments where communication channels might be insecure. The implementation of the framework is flexible, as it can be adapted in regards to the IoT device’s available hardware resources and constraints. Our security analysis shows that our framework is resilient to a variety of attack vectors. The experimental setup demonstrates the feasibility of the approach. By implementing a variety of test cases on FPGA, we demonstrate the adaptability and performance of the framework. Experiments indicate that the update procedure for a 1183-kB firmware image could be achieved, in a secure manner, under 1.73 seconds.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W3204308301",
    "type": "article"
  },
  {
    "title": "Yield, Area, and Energy Optimization in STT-MRAMs Using Failure-Aware ECC",
    "doi": "https://doi.org/10.1145/2934685",
    "publication_date": "2016-11-19",
    "publication_year": 2016,
    "authors": "Zoha Pajouhi; Xuanyao Fong; Anand Raghunathan; Kaushik Roy",
    "corresponding_authors": "",
    "abstract": "Spin-Transfer Torque MRAMs are attractive due to their non-volatility, high density, and zero leakage. However, STT-MRAMs suffer from poor reliability due to shared read and write paths. Additionally, conflicting requirements for data retention and writeability (both related to the energy barrier height of the storage device) makes design more challenging. Furthermore, the energy barrier height depends on the geometry of the storage. Any variations in the geometry of the storage device lead to variations in the energy barrier height. In order to address the poor reliability of STT-MRAMs, usage of Error Correcting Codes (ECC) has been proposed. Unlike traditional CMOS memory technologies, ECC is expected to correct both soft and hard errors in STT-MRAMs. To achieve acceptable yield with low write power, stronger ECC is required, resulting in increased number of encoded bits and degraded memory capacity. In this article, we propose Failure-aware ECC (FaECC), which masks permanent faults while maintaining the same correction capability for soft errors without increased number of encoded bits. Furthermore, we investigate the impact of process variations on run-time reliability of STT-MRAMs. In order to analyze the effectiveness of our methodology, we developed a cross-layer simulation framework that consists of device, circuit and array level analysis of STT-MRAM memory arrays. Our results show that using FaECC relaxes the requirements on the energy barrier height, which reduces the write energy and results in smaller access transistor size and memory array area.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2283769046",
    "type": "article"
  },
  {
    "title": "Gates vs. Splitters",
    "doi": "https://doi.org/10.1145/2904445",
    "publication_date": "2016-06-16",
    "publication_year": 2016,
    "authors": "Arighna Deb; Robert Wille; Oliver Keszöcze; Stefan Hillmich; Rolf Drechsler",
    "corresponding_authors": "",
    "abstract": "Optical circuits are considered a promising emerging technology for applications in ultra-high-speed networks or interconnects. However, the development of (automatic) synthesis approaches for such circuits is still in its infancy. Although first generic and automatic synthesis approaches have been proposed, no clear understanding exists yet on how to keep the costs of the resulting circuits as small as possible. In the domain of optical circuits, this is particularly interesting for the number of gates and the effect of so-called splitters to the signal strength. In this work, we investigate this relation by considering a variety of (existing as well as proposed) synthesis approaches for optical circuits. Our investigations show that reducing the number of gates and reducing the number of splitters are contradictory optimization objectives. Furthermore, the performance of synthesis guided with respect to gate efficiency as well as synthesis guided with respect to splitter freeness is evaluated and an overhead factor between the contradictory metrics is experimentally determined.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2444059250",
    "type": "article"
  },
  {
    "title": "Countering Modeling Attacks in PUF-based IoT Security Solutions",
    "doi": "https://doi.org/10.1145/3491221",
    "publication_date": "2022-03-22",
    "publication_year": 2022,
    "authors": "Wassila Lalouani; Mohamed Younis; Mohammad Ebrahimabadi; Naghmeh Karimi",
    "corresponding_authors": "",
    "abstract": "Hardware fingerprinting has emerged as a viable option for safeguarding IoT devices from cyberattacks. Such a fingerprint is used to not only authenticate the interconnected devices but also to derive cryptographic keys for ensuring data integrity and confidentiality. A Physically Unclonable Function (PUF) is deemed as an effective fingerprinting mechanism for resource-constrained IoT devices since it is simple to implement and imposes little overhead. A PUF design is realized based on the unintentional variations of microelectronics manufacturing processes. When queried with input bits (challenge), a PUF outputs a response that depends on such variations and this uniquely identifies the device. However, machine learning techniques constitute a threat where intercepted challenge-response pairs (CRPs) could be used to model the PUF and predict its output. This paper proposes an adversarial machine learning based methodology to counter such a threat. An effective label flipping approach is proposed where the attacker's model is poisoned by providing wrong CRPs. We employ an adaptive poisoning strategy that factors in potentially leaked information, i.e., the intercepted CRPs, and introduces randomness in the poisoning pattern to prevent exclusion of these wrong CRPs as outliers. The server and client use a lightweight procedure to coordinate and predict poisoned CRP exchanges. Specifically, we employ the same pseudo random number generator at communicating parties to ensure synchronization and consensus between them, and to vary the poisoning pattern over time. Our approach has been validated using datasets generated via a PUF implementation on an FPGA. The results have confirmed the effectiveness of our approach in defeating prominent PUF modeling attack techniques in the literature.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W4221035614",
    "type": "article"
  },
  {
    "title": "Characterization of Timing-based Software Side-channel Attacks and Mitigations on Network-on-Chip Hardware",
    "doi": "https://doi.org/10.1145/3585519",
    "publication_date": "2023-03-02",
    "publication_year": 2023,
    "authors": "Usman Ali; Abdul Rasheed Sahni; Omer Khan",
    "corresponding_authors": "",
    "abstract": "Modern network-on-chip (NoC) hardware is an emerging target for side-channel security attacks. A recent work implemented and characterized timing-based software side-channel attacks that target NoC hardware on a real multicore machine. This article studies the impact of system noise on prior attack setups and shows that high noise is sufficient to defeat the attacker. We propose an information theory-based attack setup that uses repetition codes and differential signaling techniques to de-noise the unwanted noise from the NoC channel to successfully implement a practical covert-communication attack on a real multicore machine. The evaluation demonstrates an attack efficacy of 97%, 88%, and 78% under low, medium, and high external noise, respectively. Our attack characterization reveals that noise-based mitigation schemes are inadequate to prevent practical covert communication, and thus isolation-based mitigation schemes must be considered to ensure strong security. Isolation-based schemes are shown to mitigate timing-based side-channel attacks. However, their impact on the performance of real-world security critical workloads is not well understood in the literature. This article evaluates the performance implications of state-of-the-art spatial and temporal isolation schemes. The performance impact is shown to range from 2–3% for a set of graph and machine learning workloads, thus making isolation-based mitigations practical.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4322768644",
    "type": "article"
  },
  {
    "title": "A Survey on Machine Learning in Hardware Security",
    "doi": "https://doi.org/10.1145/3589506",
    "publication_date": "2023-03-28",
    "publication_year": 2023,
    "authors": "Troya Çağıl Köylü; Cezar Reinbrecht; Anteneh Gebregiorgis; Said Hamdioui; Mottaqiallah Taouil",
    "corresponding_authors": "",
    "abstract": "Hardware security is currently a very influential domain, where each year countless works are published concerning attacks against hardware and countermeasures. A significant number of them use machine learning, which is proven to be very effective in other domains. This survey, as one of the early attempts, presents the usage of machine learning in hardware security in a full and organized manner. Our contributions include classification and introduction to the relevant fields of machine learning, a comprehensive and critical overview of machine learning usage in hardware security, and an investigation of the hardware attacks against machine learning (neural network) implementations.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4361215755",
    "type": "article"
  },
  {
    "title": "Machine Learning Enabled Solutions for Design and Optimization Challenges in Networks-on-Chip based Multi/Many-Core Architectures",
    "doi": "https://doi.org/10.1145/3591470",
    "publication_date": "2023-04-17",
    "publication_year": 2023,
    "authors": "Md Farhadur Reza",
    "corresponding_authors": "Md Farhadur Reza",
    "abstract": "Due to the advancement of transistor technology, a single chip processor can now have hundreds of cores. Network-on-Chip (NoC) has been the superior interconnect fabric for multi/many-core on-chip systems because of its scalability and parallelism. Due to the rise of dark silicon with the end of Dennard Scaling, it becomes essential to design energy efficient and high performance heterogeneous NoC-based multi/many-core architectures. Because of the large and complex design space, the solution space becomes difficult to explore within a reasonable time for optimal trade-offs of energy-performance-reliability. Furthermore, reactive resource management is not effective in preventing problems from happening in adaptive systems. Therefore, in this work, we explore machine learning techniques to design and configure the NoC resources based on the learning of the system and applications workloads. Machine learning can automatically learn from past experiences and guide the NoC intelligently to achieve its objective on performance, power, and reliability. We present the challenges of NoC design and resource management and propose a generalized machine learning framework to uncover near-optimal solutions quickly. We propose and implement a NoC design and optimization solution enabled by neural networks, using the generalized machine learning framework. Simulation results demonstrated that the proposed neural networks-based design and optimization solution improves performance by 15% and reduces energy consumption by 6% compared to an existing non-machine learning-based solution while the proposed solution improves NoC latency and throughput compared to two existing machine learning-based NoC optimization solutions. The challenges of machine learning technique adaptation in multi/many-core NoC have been presented to guide future research.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4366087526",
    "type": "article"
  },
  {
    "title": "Secure and Lightweight Authentication Protocol Using PUF for the IoT-based Wireless Sensor Network",
    "doi": "https://doi.org/10.1145/3624477",
    "publication_date": "2023-09-18",
    "publication_year": 2023,
    "authors": "Sourav Roy; Dipnarayan Das; Bibhash Sen",
    "corresponding_authors": "",
    "abstract": "The wireless sensor network (WSN) has been gaining popularity for automation and performance improvement in different IoT-based applications. The resource-constrained nature and operating environment of IoT make the devices highly vulnerable to different attacks. However, the Physically Unclonable Function (PUF) helps to implement secure and lightweight authentication protocols for IoT. In this context, few computation-intensive authentication protocols are found in the literature that have addressed secure IoT communication in WSN. Besides, these protocols depend on the local storage of PUF-CRP, which is susceptible to security attacks. This work proposes a lightweight and secure authentication protocol for the IoT devices in WSN. A PUF and its machine learning (ML)–based soft model is integrated to ensure secure authentication and lightweight computation in WSN. PUF prevents physical attacks while carrying much less hardware fingerprints, and the ML-based PUF provides the desired resiliency against PUF identity-based attacks by eliminating the requirement of CRP-based storage. The proposed mechanism delivers two-way authentication while nullifying the attacks on IoT. The proposed protocol is implemented on Xilinx Artix-7 FPGA and Raspberry Pi for testability and performance evaluation. Experiment results and analysis signify its low-cost computations and lightweight features desired for IoT.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4386831150",
    "type": "article"
  },
  {
    "title": "SPLIT PUF: Efficient PUF Implementation Using Underutilized FPGA Resources",
    "doi": "https://doi.org/10.1145/3725533",
    "publication_date": "2025-03-20",
    "publication_year": 2025,
    "authors": "Christopher Vega",
    "corresponding_authors": "Christopher Vega",
    "abstract": "The Field Programmable Gate Array (FPGA) market has seen significant growth due to the low cost and reduced time to market when compared to ASIC circuits. However, FPGAs’ reconfigurable nature introduces security vulnerabilities that can be exploited by adversaries to obtain sensitive information. Physical Unclonable Functions (PUFs) have shown to be valuable security primitives. By leveraging manufacturing variations in a device one can generate unique signatures that can be used for authentication and generation of secret keys. However, PUF implementation can be costly, taking up FPGA resources and requiring long design times. In this paper, we propose a method which takes advantage of the FPGA Look Up Table (LUT) architecture to embed the PUF into functional logic circuits, reducing the cost and design time. We provide detailed implementation guidelines and evaluate the PUF’s signature quality and stability under different environmental variations using a set of testbench circuits. Our results demonstrate the effectiveness of our method in securing FPGA designs while reducing implementation costs and design time.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4408656242",
    "type": "article"
  },
  {
    "title": "Towards Certified Safe Personalization in Learning Enabled Human-in-the-loop Human-in-the-plant Systems",
    "doi": "https://doi.org/10.1145/3736766",
    "publication_date": "2025-05-23",
    "publication_year": 2025,
    "authors": "Ayan Banerjee; Aranyak Maity; Imane Lamrani; Sandeep K. S. Gupta",
    "corresponding_authors": "",
    "abstract": "The paper presents AIIM, an Artificial Intelligence (AI) enabled personalIzation Management software for human-in-the-loop, human-in-the-plant Learning enabled systems (LES). AIIM can be integrated with LES software to aid a human user to achieve safe and effective operation under dynamically changing contexts. AIIM consists of: A) an AI technique to derive model coefficient of a physics guided surrogate model from operational data shared following privacy norms, and b) continuous model conformance to identify key changes in LES operational behavior that may jeopardize safety. We demonstrate two capabilities of AIIM, personalization and unknown error detection, through case studies that span a significant breadth of dynamic context change scenarios including: a) involuntary change in user context such as medication induced glucose metabolism change in automated insulin delivery (AID), b) actuation failure such as cartridge blockage in AID, c) latent sensor error in aviation, and d) unknown coding error in autonomous car software patches. We compare AIIM personalization with human-in-the-loop and self-adaptive model-predictive control design on real-life and simulation settings, to show safe and improved diabetes management.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4410641579",
    "type": "article"
  },
  {
    "title": "Demonstration of a Scalable DNA Computing Platform: Writing and Selection",
    "doi": "https://doi.org/10.1145/3744562",
    "publication_date": "2025-06-12",
    "publication_year": 2025,
    "authors": "Swapnil Bhatia; Miriam Ramliden; Vibha Rao; Grace E. Vezeau; Nina Katz-Christy; Shaelyn Tolkamp; Matt O'Leary; Hannah Jayne; Tyler Rockwood; R Pradeep; Chaitanya Joshi; Cat Ferrieri; Laurel Provencher; Gerald H. Davis; Debbie Perera; Emily Greenwald; Jean Loomis; Phyllis Gitobu; David A. Kleiman; Sean Mihm; David Turek; Hyunjun Park",
    "corresponding_authors": "",
    "abstract": "High value data like historical or health records, seismic or satellite images, particle collision events or original recordings, requires a long-term storage medium that is resilient, scalable, secure, and computable. DNA has been proposed as a solution and storage has been demonstrated using basewise synthesis. Separately, DNA computing demonstrations have shown complex programs executed on small datasets. Here, we demonstrate a new unified approach to DNA-based data storage and computing. We describe a novel combinatorial assembly approach to writing data into DNA. We define a trie-like DNA data structure and use it to write data in key-value form. We demonstrate our approach by writing The Complete Works of William Shakespeare — about one million words of text — into DNA with raw error rates rivaling conventional media. Leveraging our DNA data structure, we define two new computing instructions — select and quotient — and using them, demonstrate how DNA-encoded text could be searched for exact or approximate matches to a query word. Our search demonstrations achieve perfect recall and high precision. Our approach is more scalable in cost and throughput that previous approaches and our platform is extensible to more powerful computing instructions applicable to a variety of applications.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4411236110",
    "type": "article"
  },
  {
    "title": "Technology/System Co-Optimization for FPGA Using Emerging Reconfigurable Logic Device",
    "doi": "https://doi.org/10.1145/3750730",
    "publication_date": "2025-07-25",
    "publication_year": 2025,
    "authors": "Lu Sheng; Liuting Shang; Sungyong Jung; Yichen Zhang; Qilian Liang; Chenyun Pan",
    "corresponding_authors": "",
    "abstract": "Reconfigurable devices are gaining increasing attention as a viable alternative and supplementary solution to the traditional CMOS technology. In this article, we develop a more efficient field-programmable gate array (FPGA) based on the reconfigurable field-effective transistor (RFET). We use the multi-gate characteristics of RFET to redesign the key components of FPGAs, namely SRAM-controlled multiplexer and look-up tables. The compact structure of the proposed design requires fewer transistors and leads to reduced delay of the overall FPGA system. In addition, we develop a comprehensive technology/system co-design and co-optimization framework to thoroughly investigate the design space, including various device- and system-level design parameters. A series of benchmark tests show that under the optimal design, up to 32% and 13% reduction can be achieved in delay and energy-delay product (EDP), respectively, compared to the traditional CMOS FPGAs.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4412922854",
    "type": "article"
  },
  {
    "title": "Design of False Data Injection Attacks in a Cyber-Physical System using Gaussian Distribution",
    "doi": "https://doi.org/10.1145/3764929",
    "publication_date": "2025-09-01",
    "publication_year": 2025,
    "authors": "Sushree Padhan; Ashok Kumar Turuk",
    "corresponding_authors": "",
    "abstract": "An attacker can modify the actuator inputs, sensor observations, and state of the physical system in a cyber-physical system (CPS), causing errors in the system's proper functioning. It is crucial to investigate a CPS in the presence of all possible attack types to make it resilient. For this, all possible attack sequences must be known. This paper focuses on designing false data injection (FDI) attacks on the physical system, actuator input, and sensor measurement in a CPS, individually and in their combined locations. Each attack sequence follows a Gaussian distribution. We study a discrete linear time-invariant (LTI) CPS with a single sensor and actuator. The system also includes a Kalman filter and a Chi-square ( \\(\\chi^{2}\\) ) detector. With a \\(\\chi^{2}\\) detector and possible known system parameters, we have proposed seven types of FDI attacks at vulnerable locations based on Kullback-Leibler (KL) divergence. The attacker can remain undetected by carefully planning the attack sequences. The attack increases the state estimation error (SER), and degrades the system's proper operation. The effect of attacks on the detection result and the difference between state estimation error with and without attack is simulated through two examples from the LTI system.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413893997",
    "type": "article"
  },
  {
    "title": "<i>Impedance Leakage</i> Vulnerability and Its Utilization in Reverse-Engineering Embedded Software",
    "doi": "https://doi.org/10.1145/3764931",
    "publication_date": "2025-09-01",
    "publication_year": 2025,
    "authors": "Md Sadik Awal; Md Tauhidur Rahman",
    "corresponding_authors": "",
    "abstract": "Discovering new vulnerabilities and implementing security and privacy measures are important to protect systems and data against physical attacks. One such vulnerability is impedance, an inherent property of a device that can be exploited to leak information through an unintended side-channel, thereby posing significant security and privacy risks. Unlike traditional vulnerabilities, impedance is often overlooked or narrowly explored, as it is typically treated as a fixed value at a specific frequency in research and design endeavors, leaving its potential for information leakage largely unexplored. This paper demonstrates that the impedance of an embedded device is not constant and directly relates to the programs executed on the device. We define this phenomenon as impedance leakage and use this as a side-channel to extract software instructions from protected memory. Our experiment on the ATmega328P microcontroller and the Artix 7 FPGA indicates that the impedance side-channel can detect software instructions with 96.1% and 92.6% accuracy, respectively. Furthermore, we explore the dual nature of the impedance side-channel, highlighting the potential for beneficial purposes and the associated risk of intellectual property theft.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413893999",
    "type": "article"
  },
  {
    "title": "S <sup>2</sup> FAM: Signal-slowdown-based Fault Attack Mitigation Method for Secure Multi-tenant FPGA",
    "doi": "https://doi.org/10.1145/3756013",
    "publication_date": "2025-07-31",
    "publication_year": 2025,
    "authors": "Sandeep Sunkavilli; Mashrafi Kajol; Qiaoyan Yu",
    "corresponding_authors": "",
    "abstract": "Multi-tenant Field-programmable Gate Arrays (FPGAs) in cloud service are vulnerable to remotely exploitable attacks, among which power waster circuit (PWC)-based fault attacks have been demonstrated as a highly feasible one. PWC generates high switching activities and causes a sudden voltage drop in the power distribution network (PDN), resulting in a delay of signal propagation and FPGA malfunction. Existing countermeasures deploy bitstream checking methodologies or deploy numerous on-chip sensors to mitigate voltage-drop attacks. Since new PWCs without combinatorial loops and a multi-source attack are emerging, the current countermeasures lack the ability to mitigate new security challenges in multi-tenant FPGAs. To address these issues, a Signal-slowdown (SS)-based fault attack mitigation (S 2 FAM) method is proposed to detect both combinatorial (ring-oscillator (RO)-based PWC) and non-combinatorial (ring-oscillator Flip-flop (ROFF)-based PWC) loop-based attacks and precisely pinpoint the attack locations. A new calibration technique in S 2 FAM facilitates to identify and remove unstable sensor data, thus significantly reducing false positives. Moreover, the proposed method localizes both the single- and multi-source attacks in the FPGA by utilizing a tenant-level SS ranking (TSSR)-based algorithm. Experimental results show that the proposed method reduces the false alarm by 45.8%, compared to the existing works. Our proposed algorithm for attack localization achieves a 100% success rate and reduces the attack localization area for a multi-source attack by 25.2% than an existing countermeasure. The successful localization is achieved by utilizing our proposed method within 2 \\(\\mu\\) s (200 clock cycles) of attack duration. The proposed signal slowdown metric with the calibration process reduces the number of on-chip sensors by 78% and the localization time by 90.5%, compared to the baseline.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4414117229",
    "type": "article"
  },
  {
    "title": "Analysis and Design of Memory Testing Algorithm for Computing-in-Memory Using MBIST",
    "doi": "https://doi.org/10.1145/3766540",
    "publication_date": "2025-09-09",
    "publication_year": 2025,
    "authors": "Zhongqing Lin; Siyan Li; Qinshan Zhang; Qiushi Feng; Changxin Yue; Jiaqi Chen; Yuanyang Wang; Y. Liu; Yu Liu; L. Hao; Chunyu Peng; Qiang Zhao; Yongliang Zhou; Chenghu Dai; Xiulong Wu",
    "corresponding_authors": "",
    "abstract": "Computing-in-memory (CIM), as a novel computing architecture for the future, effectively overcomes the bottlenecks in the von Neumann architecture. The CIM architecture embeds logic into the memory array to reduce the data transfer between the processor and memory. However, embedding logic into the memory array increases the test complexity. In this study, we offer a comprehensive examination of the challenges associated with CIM and introduce a novel March-like test algorithm, named March CC, tailored for CIM chips. Computational elements are added to the read/write operation sequences, combining the tests in memory mode and computing mode into one step, which significantly improves the test efficiency. In comparison to the traditional March C- test algorithm, the proposed March CC test algorithm, with a complexity of only 10 N , enhances the fault coverage from 66.7% to 79.8% for six common single-cell fault (SCF) models and nine common double-cell fault (DCF) models. Furthermore, the March CC algorithm demonstrates good compatibility and is applicable to various memory configurations, such as SRAM, RRAM, and MRAM CIM architectures.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4414210705",
    "type": "article"
  },
  {
    "title": "Emerging nanodevice paradigm",
    "doi": "https://doi.org/10.1145/1482613.1482616",
    "publication_date": "2009-01-01",
    "publication_year": 2009,
    "authors": "Zhengfei Wang; Huaixiu Zheng; Q. W. Shi; Jie Chen",
    "corresponding_authors": "",
    "abstract": "The continued miniaturization of silicon-based electronic circuits is fast approaching its physical limitations. It is unlikely that advances in miniaturization, following the so-called Moore's Law, can continue in the foreseeable future. Nanoelectronics has to go beyond silicon technology. New device paradigms based on nanoscale materials, such as molecular electronic devices, spin devices and carbon-based devices, will emerge. In this article, we introduce a nanodevice paradigm: graphene nanoelectronics. Due to its unique quantum effects and electronic properties, researchers predict that graphene-based devices may replace carbon nanotube devices and become major building blocks for future nanoscale computing. To manifest its unique electronic properties, we present some of our recent designs, namely a graphene-based switch, a negative differential resistance (NDR) device and a random access memory array (RAM). Since these basic devices are the building blocks for large-scale circuits, our findings can help researchers construct useful computing systems and study graphene-based circuit performance in the future.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2108861298",
    "type": "article"
  },
  {
    "title": "A hybrid Nano/CMOS dynamically reconfigurable system—Part II",
    "doi": "https://doi.org/10.1145/1568485.1568487",
    "publication_date": "2009-08-01",
    "publication_year": 2009,
    "authors": "Wei Zhang; Niraj K. Jha; Li Shang",
    "corresponding_authors": "",
    "abstract": "In Part I of this work, a hybrid nano/CMOS reconfigurable architecture, called NATURE, was described. It is composed of CMOS reconfigurable logic and interconnect fabric, and nonvolatile nano on-chip memory. Through its support for cycle-by-cycle runtime reconfiguration and a highly-efficient computation model, temporal logic folding, NATURE improves logic density and area-delay product by more than an order of magnitude compared to existing CMOS-based field-programmable gate arrays (FPGAs). NATURE can be fabricated using mainstream photo-lithography fabrication techniques. Thus, it offers a currently commercially feasible architecture with high performance, superior logic density, and excellent runtime design flexibility. In Part II of this work, we present an integrated design and optimization flow for NATURE, called NanoMap. Given an input design specified in register-transfer level (RTL) and/or gate-level VHDL, NanoMap optimizes and implements the design on NATURE through logic mapping, temporal clustering, temporal placement, and routing. As opposed to other design tools for traditional FPGAs, NanoMap supports and leverages temporal logic folding by integrating novel mapping techniques. It can automatically explore and identify the best temporal logic folding configuration, targeting area, delay or area-delay product optimization. A force-directed scheduling technique is used to optimize and balance resource usage across different folding cycles. By supporting logic folding, NanoMap can provide significant design flexibility in performing area-delay trade-offs under various user-specified constraints. We present details of the mapping procedure and results for different architectural instances. Experimental results demonstrate that NanoMap can judiciously trade off area and delay targeting different optimization goals, and effectively exploit the advantages of NATURE. Part I of this work will appear in JETC Vol. 5, No. 4.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2031970461",
    "type": "article"
  },
  {
    "title": "Low-power 3D nano/CMOS hybrid dynamically reconfigurable architecture",
    "doi": "https://doi.org/10.1145/1777401.1777403",
    "publication_date": "2010-08-01",
    "publication_year": 2010,
    "authors": "Wei Zhang; Niraj K. Jha; Li Shang",
    "corresponding_authors": "",
    "abstract": "In order to continue technology scaling beyond CMOS, diverse nanoarchitectures have been proposed in recent years based on emerging nanodevices, such as nanotubes, nanowires, etc. Among them, some hybrid nano/CMOS reconfigurable architectures enjoy the advantage that they can be fabricated using photolithography. NATURE is one such architecture that we have proposed recently. It comprises CMOS reconfigurable logic and CMOS fabrication-compatible nano RAMs. It uses distributed high-density and fast nano RAMs as on-chip storage for storing multiple reconfiguration copies, enabling fine-grain cycle-by-cycle reconfiguration. It supports a highly efficient computational model, called temporal logic folding, which makes possible more than an order of magnitude improvement in logic density and area-delay product, significant power reduction, and significant design flexibility in performing area-delay trade-offs. In this article, we extend NATURE in various dimensions, evaluating various FPGA approaches in the context of today's emerging technologies. First, we explore the introduction of embedded coarse-grain modules in the fine-grain NATURE architecture and present a unified dynamically reconfigurable architecture, which can significantly enhance NATURE's computation power for data-dominated applications. Second, we explore a 3D architecture for NATURE in which the nano RAM for reconfiguration storage is on one layer and the rest of the CMOS logic on another layer. This leads to further improvements in logic density and performance. Finally, we explore the possibility of using FinFETs, an emerging double-gate CMOS technology, to implement NATURE. Since power consumption is an important consideration in the deep nanometer regime, especially for FPGAs, we present a back-gate biasing methodology for flexible threshold voltage adjustment in FinFETs to significantly reduce NATURE's power consumption. Simulation results demonstrate the efficacy of the proposed methods.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2068367875",
    "type": "article"
  },
  {
    "title": "An information-theoretic analysis of quantum-dot cellular automata for defect tolerance",
    "doi": "https://doi.org/10.1145/1777401.1777402",
    "publication_date": "2010-08-01",
    "publication_year": 2010,
    "authors": "Jianwei Dai; Lei Wang; Fabrizio Lombardi",
    "corresponding_authors": "",
    "abstract": "Quantum-dot cellular automata (QCA) has been advocated as a promising emerging nanotechnology for designing future nanocomputing systems. However, at device level, the large number of expected defects represents a significant hurdle for reliable computation in QCA-based systems. In this paper, we present an information-theoretic approach to investigate the relationship between defect tolerance and redundancy in QCA devices. By modeling defect-prone QCA devices as unreliable information processing media, we determine the information transfer capacity, as bound on the reliability that QCA devices can achieve. The proposed method allows to evaluate the effectiveness of redundancy-based defect tolerance in an effective and quantitative manner.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2072580341",
    "type": "article"
  },
  {
    "title": "Towards a net-zero data center",
    "doi": "https://doi.org/10.1145/2367736.2367738",
    "publication_date": "2012-10-01",
    "publication_year": 2012,
    "authors": "Prithviraj Banerjee; Chandrakant Patel; Cullen Bash; Amip Shah; Martin Arlitt",
    "corresponding_authors": "",
    "abstract": "A world consisting of billions of service-oriented client devices and thousands of data centers can deliver a diverse range of services, from social networking to management of our natural resources. However, these services must scale in order to meet the fundamental needs of society. To enable such scaling, the total cost of ownership of the data centers that host the services and comprise the vast majority of service delivery costs will need to be reduced. As energy drives the total cost of ownership of data centers, there is a need for a new paradigm in design and management of data centers that minimizes energy used across their lifetimes, from “cradle to cradle”. This tutorial article presents a blueprint for a “net-zero data center”: one that offsets any electricity used from the grid via adequate on-site power generation that gets fed back to the grid at a later time. We discuss how such a data center addresses the total cost of ownership, illustrating that contrary to the oft-held view of sustainability as “paying more to be green”, sustainable data centers—built on a framework that focuses on integrating supply and demand management from end-to-end—can concurrently lead to lowest cost and lowest environmental impact.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2072697037",
    "type": "article"
  },
  {
    "title": "Implementing the data center energy productivity metric",
    "doi": "https://doi.org/10.1145/2367736.2367741",
    "publication_date": "2012-10-01",
    "publication_year": 2012,
    "authors": "Landon H. Sego; Andrés Márquez; Andrew Rawson; Tahir Cader; Kevin Fox; William I. Gustafson; Christopher J. Mundy",
    "corresponding_authors": "",
    "abstract": "As data centers proliferate in size and number, the endeavor to improve their energy efficiency and productivity is becoming increasingly important. We discuss the properties of a number of the proposed metrics of energy efficiency and productivity. In particular, we focus on the Data Center Energy Productivity (DCeP) metric, which is the ratio of useful work produced by the data center to the energy consumed performing that work. We describe our approach for using DCeP as the principal outcome of a designed experiment using a highly instrumented, high-performance computing data center. We found that DCeP was successful in clearly distinguishing different operational states in the data center, thereby validating its utility as a metric for identifying configurations of hardware and software that would improve (or even maximize) energy productivity. We also discuss some of the challenges and benefits associated with implementing the DCeP metric, and we examine the efficacy of the metric in making comparisons within a data center and among data centers.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2150693201",
    "type": "article"
  },
  {
    "title": "Coupled Spin-Torque Nano-Oscillator-Based Computation",
    "doi": "https://doi.org/10.1145/3064835",
    "publication_date": "2017-07-11",
    "publication_year": 2017,
    "authors": "Karthik Yogendra; Chamika Liyanagedera; Deliang Fan; Yong Shim; Kaushik Roy",
    "corresponding_authors": "",
    "abstract": "In this article, we present a comprehensive study of four frequency locking mechanisms in Spin Torque Nano Oscillators (STNOs) and explore their suitability for a class of specialized computing applications. We implemented a physical STNO model based on Landau-Lifshitz-Gilbert-Slonczewski equation and benchmarked the model to experimental data. Based on our simulations, we provide an in-depth analysis of how the “self-organizing” ability of coupled STNO array can be effectively used for computations that are unsuitable or inefficient in the von-Neumann computing domain. As a case study, we demonstrate the computing ability of coupled STNOs with two applications: edge detection of an image and associative computing for image recognition. We provide an analysis of the scaling trends of STNOs and the effectiveness of different frequency locking mechanisms with scaling in the presence of thermal noise. We also provide an in-depth analysis of the effect of variations on the four locking mechanisms to find the most robust one in the presence of variations.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2735596879",
    "type": "article"
  },
  {
    "title": "Design and Multi-Abstraction-Level Evaluation of a NoC Router for Mixed-Criticality Real-Time Systems",
    "doi": "https://doi.org/10.1145/3264818",
    "publication_date": "2019-01-31",
    "publication_year": 2019,
    "authors": "Mourad Dridi; Stéphane Rubini; Mounir Lallali; Martha Johanna Sepúlveda Flórez; Frank Singhoff; Jean-Philippe Diguet",
    "corresponding_authors": "",
    "abstract": "A Mixed Criticality System (MCS) combines real-time software tasks with different criticality levels. In a MCS, the criticality level specifies the level of assurance against system failure. For high-critical flows of messages, it is imperative to meet deadlines; otherwise, the whole system might fail, leading to catastrophic results, like loss of life or serious damage to the environment. In contrast, low-critical flows may tolerate some delays. Furthermore, in MCS, flow performances such as the Worst Case Communication Time (WCCT) may vary depending on the criticality level of the applications. Then execution platforms must provide different operating modes for applications with different levels of criticality. To conclude, in Network-On-Chip (NoC), sharing resources between communication flows can lead to unpredictable latencies and subsequently turns the implementation of MCS in many-core architectures challenging. In this article, we propose and evaluate a new NoC router to support MCS based on an accurate WCCT analysis for high-critical flows. The proposed router, called Double Arbiter and Switching router (DAS), jointly uses Wormhole and Store And Forward communication techniques for low- and high-critical flows, respectively. It ensures that high-critical flows meet their deadlines while maximizing the bandwidth remaining for the low-critical flows. We also propose a new method for high-critical communication time analysis, applied to Store And Forward switching mode with virtual channels. For low-critical flows communication time analysis, we adapt an existing wormhole communication time analysis with share policy to our context. The second contribution of this article is a multi-abstraction-level evaluation of DAS. We evaluate the communication time of flows, the system mode change, the cost, and four properties of DAS. Simulations with a cycle-accurate SystemC NoC simulator show that, with a 15% network use rate, the communication delay of high-critical flows is reduced by 80% while communication delay of low-critical flow is increased by 18% compared to solutions based on routers with multiple virtual channels. For 10% of network interferences, using system mode change, DAS reduces the high-critical communication delays about 66%. We synthesize our router with a 28nm SOI technology and show that the size overhead is limited of 2.5% compared to the solution based on virtual channel router. Finally, we applied model checking verification techniques to automatically prove several DAS properties required by critical systems designers.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2899598529",
    "type": "article"
  },
  {
    "title": "Neural Network Classifiers Using a Hardware-Based Approximate Activation Function with a Hybrid Stochastic Multiplier",
    "doi": "https://doi.org/10.1145/3284933",
    "publication_date": "2019-01-09",
    "publication_year": 2019,
    "authors": "Bingzhe Li; Yaobin Qin; Bo Yuan; David J. Lilja",
    "corresponding_authors": "",
    "abstract": "Neural networks are becoming prevalent in many areas, such as pattern recognition and medical diagnosis. Stochastic computing is one potential solution for neural networks implemented in low-power back-end devices such as solar-powered devices and Internet of Things (IoT) devices. In this article, we investigate a new architecture of stochastic neural networks with a hardware-oriented approximate activation function. The newly proposed approximate activation function can be hidden in the proposed architecture and thus reduce the whole hardware cost. Additionally, to further reduce the hardware cost of the stochastic implementation, a new hybrid stochastic multiplier is proposed. It contains OR gates and a binary parallel counter, which aims to reduce the number of inputs of the binary parallel counter. The experimental results indicate the newly proposed approximate architecture without hybrid stochastic multipliers achieves more than 25%, 60%, and 3x reduction compared to previous stochastic neural networks, and more than 30x, 30x, and 52% reduction compared to conventional binary neural networks, in terms of area, power, and energy, respectively, while maintaining the similar error rates compared to the conventional neural networks. Furthermore, the stochastic implementation with hybrid stochastic multipliers further reduces area about 18% to 80%, power from 15% to 113.1%, and energy about 15% to 131%, respectively.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2908853553",
    "type": "article"
  },
  {
    "title": "GARDENIA",
    "doi": "https://doi.org/10.1145/3283450",
    "publication_date": "2019-01-09",
    "publication_year": 2019,
    "authors": "Zhen Xu; Xuhao Chen; Jie Shen; Yang Zhang; Cheng Chen; Canqun Yang",
    "corresponding_authors": "",
    "abstract": "This article presents the Graph Algorithm Repository for Designing Next-generation Accelerators (GARDENIA), a benchmark suite for studying irregular graph algorithms on massively parallel accelerators. Applications with limited control and data irregularity are the main focus of existing generic benchmarks for accelerators, while available graph processing benchmarks do not apply state-of-the-art algorithms and/or optimization techniques. GARDENIA includes emerging graph processing workloads from graph analytics, sparse linear algebra, and machine-learning domains, which mimic massively multithreaded commercial programs running on modern large-scale datacenters. Our characterization shows that GARDENIA exhibits irregular microarchitectural behavior, which is quite different from structured workloads and straightforward-implemented graph benchmarks.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2909224093",
    "type": "article"
  },
  {
    "title": "Energy-efficient FPGA Spiking Neural Accelerators with Supervised and Unsupervised Spike-timing-dependent-Plasticity",
    "doi": "https://doi.org/10.1145/3313866",
    "publication_date": "2019-05-30",
    "publication_year": 2019,
    "authors": "Yu Liu; Sai Sourabh Yenamachintala; Peng Li",
    "corresponding_authors": "",
    "abstract": "The liquid state machine (LSM) is a model of recurrent spiking neural networks (SNNs) and provides an appealing brain-inspired computing paradigm for machine-learning applications. Moreover, operated by processing information directly on spiking events, the LSM is amenable to efficient event-driven hardware implementation. However, training SNNs is, in general, a difficult task as synaptic weights shall be updated based on neural firing activities while achieving a learning objective. In this article, we explore bio-plausible spike-timing-dependent-plasticity (STDP) mechanisms to train liquid state machine models with and without supervision. First, we employ a supervised STDP rule to train the output layer of the LSM while delivering good classification performance. Furthermore, a hardware-friendly unsupervised STDP rule is leveraged to train the recurrent reservoir to further boost the performance. We pursue efficient hardware implementation of FPGA LSM accelerators by performing algorithm-level optimization of the two proposed training rules and exploiting the self-organizing behaviors naturally induced by STDP. Several recurrent spiking neural accelerators are built on a Xilinx Zync ZC-706 platform and trained for speech recognition with the TI46 speech corpus as the benchmark. Adopting the two proposed unsupervised and supervised STDP rules outperforms the recognition accuracy of a competitive non-STDP baseline training algorithm by up to 3.47%.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2947161672",
    "type": "article"
  },
  {
    "title": "Energy-efficient Design of MTJ-based Neural Networks with Stochastic Computing",
    "doi": "https://doi.org/10.1145/3359622",
    "publication_date": "2019-10-15",
    "publication_year": 2019,
    "authors": "Ankit Mondal; Ankur Srivastava",
    "corresponding_authors": "",
    "abstract": "Hardware implementations of Artificial Neural Networks (ANNs) using conventional binary arithmetic units are computationally expensive, energy-intensive, and have large area overheads. Stochastic Computing (SC) is an emerging paradigm that replaces these conventional units with simple logic circuits and is particularly suitable for fault-tolerant applications. We propose an energy-efficient use of Magnetic Tunnel Junctions (MTJs), a spintronic device that exhibits probabilistic switching behavior, as Stochastic Number Generators (SNGs), which forms the basis of our NN implementation in the SC domain. Further, the error resilience of target applications of NNs allows approximating the synaptic weights in our MTJ-based NN implementation, in ways brought about by properties of the MTJ-SNG, to achieve energy-efficiency. An algorithm is designed that, given an error tolerance, can perform such approximations in a single-layer NN in an optimal way owing to the convexity of the problem formulation. We then use this algorithm and develop a heuristic approach for approximating multi-layer NNs. Classification problems were evaluated on the optimized NNs and results showed substantial savings in energy for little loss in accuracy.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2981012960",
    "type": "article"
  },
  {
    "title": "Predict, Share, and Recycle Your Way to Low-power Nanophotonic Networks",
    "doi": "https://doi.org/10.1145/3356585",
    "publication_date": "2019-10-15",
    "publication_year": 2019,
    "authors": "Janibul Bashir; Smruti R. Sarangi",
    "corresponding_authors": "",
    "abstract": "High static power consumption is widely regarded as one of the largest bottlenecks in creating scalable optical NoCs. The standard techniques to reduce static power are based on sharing optical channels and modulating the laser. We show in this article that state-of-the-art techniques in these areas are suboptimal, and there is a significant room for further improvement. We propose two novel techniques—a neural network--based method for laser modulation by predicting optical traffic and a distributed and altruistic algorithm for channel sharing—that are significantly closer to a theoretically ideal scheme. In spite of this, a lot of laser power still gets wasted. We propose to reuse this energy to heat micro-ring resonators (achieve thermal tuning) by efficiently recirculating it. These three methods help us significantly reduce the energy requirements. Our design consumes 4.7× lower laser power as compared to other state-of-the-art proposals. In addition, it results in a 31% improvement in performance and 39% reduction in ED 2 for a suite of Splash2 and Parsec benchmarks.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W3014703220",
    "type": "article"
  },
  {
    "title": "Near Zero-Energy Computation Using Quantum-Dot Cellular Automata",
    "doi": "https://doi.org/10.1145/3365394",
    "publication_date": "2019-11-25",
    "publication_year": 2019,
    "authors": "Frank Sill Torres; Philipp Niemann; Robert Wille; Rolf Drechsler",
    "corresponding_authors": "",
    "abstract": "Near zero-energy computing describes the concept of executing logic operations below the ( k B T ln 2) energy limit. Landauer discussed that it is impossible to break this limit as long as the computations are performed in the conventional, non-reversible way. But even if reversible computations were performed, the basic energy needed for operating circuits realized in conventional technologies is still far above the ( k B T ln 2) energy limit (i.e., the circuits do not operate in a physically reversible manner). In contrast, novel nanotechnologies like Quantum-dot Cellular Automata (QCA) allow for computations with very low energy dissipation and hence are promising candidates for breaking this limit. Accordingly, the design of reversible QCA circuits is an active field of research. But whether QCA in general and the proposed circuits in particular are indeed able to operate in a logically and physically reversible fashion is unknown thus far, because neither physical realizations nor appropriate simulation approaches are available. In this work, we address this gap by utilizing an established theoretical model that has been implemented in a physics simulator enabling a precise consideration of how energy is dissipated in QCA designs. Our results provide strong evidence that QCA is indeed a suitable technology for near zero-energy computing. Further, the first design of a logically and physically reversible adder circuit is presented, which serves as proof of concept for future circuits with the ability of near zero-energy computing.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W3124299431",
    "type": "article"
  },
  {
    "title": "Introduction to special issue on reliability and device degradation in emerging technologies",
    "doi": "https://doi.org/10.1145/2543749.2543750",
    "publication_date": "2014-01-01",
    "publication_year": 2014,
    "authors": "Rahul Rao; Fadi H. Gebara",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W1975267176",
    "type": "article"
  },
  {
    "title": "A low-latency, high-throughput on-chip optical router architecture for future chip multiprocessors",
    "doi": "https://doi.org/10.1145/1970406.1970411",
    "publication_date": "2011-06-01",
    "publication_year": 2011,
    "authors": "Mark J. Cianchetti; David H. Albonesi",
    "corresponding_authors": "",
    "abstract": "Tens and eventually hundreds of processing cores are projected to be integrated onto future microprocessors, making the global interconnect a key component to achieving scalable chip performance within a given power envelope. While CMOS-compatible nanophotonics has emerged as a leading candidate for replacing global wires beyond the 16nm timeframe, on-chip optical interconnect architectures are typically limited in scalability or are dependent on comparatively slow electrical control networks. In this article, we present a hybrid electrical/optical router for future large scale, cache coherent multicore microprocessors. The heart of the router is a low-latency optical crossbar that uses predecoded source routing and switch state preconfiguration to transmit cache-line-sized packets several hops in a single clock cycle under contentionless conditions. Overall, our optical router achieves 2X better network performance than a state-of-the-art electrical baseline in a mesh topology while consuming 30% less network power.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W1982774840",
    "type": "article"
  },
  {
    "title": "NBTI-aware circuit node criticality computation",
    "doi": "https://doi.org/10.1145/2491681",
    "publication_date": "2013-09-01",
    "publication_year": 2013,
    "authors": "Shengqi Yang; Wenping Wang; Mark Hagan; Wei Zhang; Pallav Gupta; Yu Cao",
    "corresponding_authors": "",
    "abstract": "For sub-65nm technology nodes, Negative Bias Temperature Instability (NBTI) has become a primary limiting factor of circuit lifetime. During the past few years, researchers have spent considerable effort on accurate modeling and characterization of circuit delay degradation caused by NBTI at different design levels. The search for techniques and methodologies which can aid in effectively minimizing the NBTI effect on circuit delay is still underway. In this work, we present the usage of node criticality computation to drive NBTI-aware timing analysis and optimization. Circuits that have undergone this optimization flow show strong resistance to NBTI delay degradation. For the first time, this work proposes a node criticality computation algorithm under an NBTI-aware timing analysis and optimization framework. Our work provides answers to the following yet unaddressed questions: (a) what is the definition of node criticality in a circuit under the NBTI effect? (b) how do we identify the critical nodes that, once protected, will be immune to NBTI timing degradation? and (c) what are the NBTI effect attenuation approaches? Experimental results indicate that by protecting the critical nodes found by our proposed methodology, circuit delay degradation can be reduced by up to 50%. Combined with peak temperature reduction, the delay degradation can be be further improved.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2011335056",
    "type": "article"
  },
  {
    "title": "Skew Dependence of Nanophotonic Devices Based on Optical Near-Field Interactions",
    "doi": "https://doi.org/10.1145/2093145.2093149",
    "publication_date": "2012-02-01",
    "publication_year": 2012,
    "authors": "Makoto Naruse; Ferdinand Peper; Kouichi Akahane; Naokatsu Yamamoto; Tadashi Kawazoe; Naoya Tate; Motoichi Ohtsu",
    "corresponding_authors": "",
    "abstract": "We examine the timing dependence of nanophotonic devices based on optical excitation transfer via optical near-field interactions at the nanometer scale. We theoretically analyze the dynamic behavior of a two-input nanophotonic switch composed of three quantum dots based on a density matrix formalism while assuming arrival-time differences, or skew, between the inputs. The analysis reveals that the nanophotonic switch is resistant to a skew longer than the input signal duration, and the tolerance to skew is asymmetric with respect to the two inputs. The skew dependence is also experimentally examined based on near-field spectroscopy of InGaAs quantum dots, showing good agreement with the theory. Elucidating the dynamic properties of nanophotonics, together with the associated spatial and energy dissipation attributes at the nanometer scale, will provide critical insights for novel system architectures.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2021917777",
    "type": "article"
  },
  {
    "title": "Real-Time SoC Security against Passive Threats Using Crypsis Behavior of Geckos",
    "doi": "https://doi.org/10.1145/3014166",
    "publication_date": "2017-03-17",
    "publication_year": 2017,
    "authors": "Krishnendu Guha; Debasri Saha; Amlan Chakrabarti",
    "corresponding_authors": "",
    "abstract": "The rapid evolution of the embedded era has witnessed globalization for the design of SoC architectures in the semiconductor design industry. Though issues of cost and stringent marketing deadlines have been resolved in such a methodology, yet the root of hardware trust has been evicted. Malicious circuitry, a.k.a. Hardware Trojan Horse (HTH), is inserted by adversaries in the less trusted phases of design. A HTH remains dormant during testing but gets triggered at runtime to cause sudden active and passive attacks. In this work, we focus on the runtime passive threats based on the parameter delay. Nature-inspired algorithms offer an alternative to the conventional techniques for solving complex problems in the domain of computer science. However, most are optimization techniques and none is dedicated to security. We seek refuge to the crypsis behavior exhibited by geckos in nature to generate a runtime security technique for SoC architectures, which can bypass runtime passive threats of a HTH. An adaptive security intellectual property (IP) that works on the proposed security principles is designed. Embedded timing analysis is used for experimental validation. Low area and power overhead of our proposed security IP over standard benchmarks and practical crypto SoC architectures as obtained in experimental results supports its applicability for practical implementations.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2601241841",
    "type": "article"
  },
  {
    "title": "Improving AES Core Performance via an Advanced ASBUS Protocol",
    "doi": "https://doi.org/10.1145/3110713",
    "publication_date": "2017-12-11",
    "publication_year": 2017,
    "authors": "Xiaokun Yang; Wujie Wen; Ming Fan",
    "corresponding_authors": "",
    "abstract": "Security is becoming a de-facto requirement of System-on-Chips (SoC), leading up to a significant share of circuit design cost. In this article, we propose an advanced SBUS protocol (ASBUS), to improve the data feeding efficiency of the Advanced Encryption Standard (AES) encrypted circuits. As a case study, the direct memory access (DMA) combined with AES engine and memory controller are implemented as our design-under-test (DUT) using field-programmable gate arrays (FPGA). The results show that our presented ASBUS structure outperforms the AXI-based design for cipher tests. As an example, the 32-bit ASBUS design costs less in terms of hardware resources and achieves higher throughput (1.30 ×) than the 32-bit AXI implementation, and the dynamic energy consumed by the ASBUS cipher test is reduced to 71.27% compared with the AXI test.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2775493870",
    "type": "article"
  },
  {
    "title": "The Uncertainty of Side-channel Analysis: A Way to Leverage from Heuristics",
    "doi": "https://doi.org/10.1145/3446997",
    "publication_date": "2021-05-11",
    "publication_year": 2021,
    "authors": "Unai Rioja; Servio Paguada; Lejla Batina; Igor Armendariz",
    "corresponding_authors": "",
    "abstract": "Performing a comprehensive side-channel analysis evaluation of small embedded devices is a process known for its variability and complexity. In real-world experimental setups, the results are largely influenced by a huge amount of parameters, some of which are not easily adjusted without trial and error and are heavily relying on the experience of professional security analysts. In this article, we advocate the usage of an existing statistical methodology called Six Sigma (6 <?TeX $\\sigma$?> ) for side-channel analysis optimization. This well-known methodology is commonly used in other industrial fields, such as production and quality engineering, to reduce the variability of industrial processes. We propose a customized Six Sigma methodology, which allows even a less-experienced security analysis to select optimal values for the different variables that are critical for the side-channel analysis procedure. Moreover, we show how our methodology helps in improving different phases in the side-channel analysis process.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W3037751757",
    "type": "article"
  },
  {
    "title": "DeepPeep",
    "doi": "https://doi.org/10.1145/3414552",
    "publication_date": "2020-10-28",
    "publication_year": 2020,
    "authors": "Nandan Kumar Jha; Sparsh Mittal; Bınod Kumar; Govardhan Mattela",
    "corresponding_authors": "",
    "abstract": "The remarkable predictive performance of deep neural networks (DNNs) has led to their adoption in service domains of unprecedented scale and scope. However, the widespread adoption and growing commercialization of DNNs have underscored the importance of intellectual property (IP) protection. Devising techniques to ensure IP protection has become necessary due to the increasing trend of outsourcing the DNN computations on the untrusted accelerators in cloud-based services. The design methodologies and hyper-parameters of DNNs are crucial information, and leaking them may cause massive economic loss to the organization. Furthermore, the knowledge of DNN’s architecture can increase the success probability of an adversarial attack where an adversary perturbs the inputs and alters the prediction. In this work, we devise a two-stage attack methodology “DeepPeep,” which exploits the distinctive characteristics of design methodologies to reverse-engineer the architecture of building blocks in compact DNNs. We show the efficacy of “DeepPeep” on P100 and P4000 GPUs. Additionally, we propose intelligent design maneuvering strategies for thwarting IP theft through the DeepPeep attack and proposed “Secure MobileNet-V1.” Interestingly , compared to vanilla MobileNet-V1, secure MobileNet-V1 provides a significant reduction in inference latency (≈60%) and improvement in predictive performance (≈2%) with very low memory and computation overheads.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W3095428824",
    "type": "article"
  },
  {
    "title": "Resilient and Secure Hardware Devices Using ASL",
    "doi": "https://doi.org/10.1145/3429982",
    "publication_date": "2021-01-06",
    "publication_year": 2021,
    "authors": "Qutaiba Alasad; Jie Lin; Jiann-Shuin Yuan; Deliang Fan; Amro Awad",
    "corresponding_authors": "",
    "abstract": "Due to the globalization of Integrated Circuit (IC) design in the semiconductor industry and the outsourcing of chip manufacturing, Third-Party Intellectual Properties (3PIPs) become vulnerable to IP piracy, reverse engineering, counterfeit IC, and hardware trojans. To thwart such attacks, ICs can be protected using logic encryption techniques. However, strong resilient techniques incur significant overheads. Side-channel attacks (SCAs) further complicate matters by introducing potential attacks post fabrication. One of the most severe SCAs is power analysis (PA) attacks, in which an attacker can observe the power variations of the device and analyze them to extract the secret key. PA attacks can be mitigated via adding large extra hardware; however, the overheads of such solutions can render them impractical, especially when there are power and area constraints. All Spin Logic Device (ASLD) is one of the most promising spintronic devices due to its unique properties: small area, no spin-charge signal conversion, zero leakage current, non-volatile memory, high density, low operating voltage, and its compatibility with conventional CMOS technology. In this article, we extend the work in Reference [1] on the usage of ASLD to produce secure and resilient circuits that withstand IC attacks (during the fabrication) and PA attacks (after fabrication), including reverse engineering attacks. First, we show that ASLD has another unique feature: identical power dissipation through the switching operations, where such properties can be effectively used to prevent PA and IC attacks. We then evaluate the proposed ASLD-based on performance overheads and security guarantees.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W3118947718",
    "type": "article"
  },
  {
    "title": "Computational Capacity of Complex Memcapacitive Networks",
    "doi": "https://doi.org/10.1145/3445795",
    "publication_date": "2021-02-27",
    "publication_year": 2021,
    "authors": "Dat Tran; Christof Teuscher",
    "corresponding_authors": "",
    "abstract": "Emerging memcapacitive nanoscale devices have the potential to perform computations in new ways. In this article, we systematically study, to the best of our knowledge for the first time, the computational capacity of complex memcapacitive networks, which function as reservoirs in reservoir computing, one of the brain-inspired computing architectures. Memcapacitive networks are composed of memcapacitive devices randomly connected through nanowires. Previous studies have shown that both regular and random reservoirs provide sufficient dynamics to perform simple tasks. How do complex memcapacitive networks illustrate their computational capability, and what are the topological structures of memcapacitive networks that solve complex tasks with efficiency? Studies show that small-world power-law (SWPL) networks offer an ideal trade-off between the communication properties and the wiring cost of networks. In this study, we illustrate the computing nature of SWPL memcapacitive reservoirs by exploring the two essential properties: fading memory and linear separation through measurements of kernel quality. Compared to ideal reservoirs, nanowire memcapacitive reservoirs had a better dynamic response and improved their performance by 4.67% on three tasks: MNIST, Isolated Spoken Digits, and CIFAR-10. On the same three tasks, compared to memristive reservoirs, nanowire memcapacitive reservoirs achieved comparable performance with much less power, on average, about 99× , 17×, and 277×, respectively. Simulation results of the topological transformation of memcapacitive networks reveal that that topological structures of the memcapacitive SWPL reservoirs did not affect their performance but significantly contributed to the wiring cost and the power consumption of the systems. The minimum trade-off between the wiring cost and the power consumption occurred at different network settings of α and β : 4.5 and 0.61 for Biolek reservoirs, 2.7 and 1.0 for Mohamed reservoirs, and 3.0 and 1.0 for Najem reservoirs. The results of our research illustrate the computational capacity of complex memcapacitive networks as reservoirs in reservoir computing. Such memcapacitive networks with an SWPL topology are energy-efficient systems that are suitable for low-power applications such as mobile devices and the Internet of Things.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W3135139941",
    "type": "article"
  },
  {
    "title": "Ket Quantum Programming",
    "doi": "https://doi.org/10.1145/3474224",
    "publication_date": "2021-10-22",
    "publication_year": 2021,
    "authors": "Evandro C. R. Rosa; Rafael de Santiago",
    "corresponding_authors": "",
    "abstract": "Quantum programming languages (QPL) fill the gap between quantum mechanics and classical programming constructions, simplifying the development of quantum applications. However, most QPL addresses the inherent quantum programming problem, neglecting quantum computer implementation constraints. We present a runtime architecture for classical-quantum execution that mitigates the limitation of interaction between classical and quantum computers originated from the cloud-based model of quantum computation provided by several vendors, which implies a quantum computer processing in batch. In the proposed runtime architecture, we introduce (i) runtime quantum code generation to enable generic quantum programming and dynamic quantum execution; and (ii) the concept of futures to handle dynamic interaction between classical and quantum computers. To support our proposal, we have implemented the Ket Quantum Programming framework that features a Python-embedded classical-quantum programming language named Ket, the C++ quantum programming library Libket, and Ket Bitwise (quantum computing) Simulator. The last one improves over the bitwise representation, making the simulation time not dependent on the number of qubits but the amount of superposition and entanglement of simulation.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W3208475667",
    "type": "article"
  },
  {
    "title": "Analytical Reliability Analysis of 3D NoC under TSV Failure",
    "doi": "https://doi.org/10.1145/2700236",
    "publication_date": "2015-04-27",
    "publication_year": 2015,
    "authors": "Misagh Khayambashi; Pooria M. Yaghini; Ashkan Eghbal; Nader Bagherzadeh",
    "corresponding_authors": "",
    "abstract": "The network-on-chip (NoC) technology allows for integration of a manycore design on a single chip for higher efficiency and scalability. Three-dimensional (3D) NoCs offer several advantages over two-dimensional (2D) NoCs. Through-silicon via (TSV) technology is one of the candidates for implementation of 3D NoCs. TSV reliability analysis is still challenging for 3D NoC designers because of their unique electrical, thermal, and physical characteristics. After providing an overview of common TSV issues, this article aims to define a reliability criterion for NoC and provide a framework for quantifying this reliability as it relates to TSV issues. TSV issues are modeled as a time-invariant failure probability. Also, a reliability criterion for TSV-based NoC is defined. The relationship between NoC reliability and TSV failure is quantified. For the first time, the reliability criterion is reduced to a tractable closed-form expression that requires a single Monte Carlo simulation. Importantly, the Monte Carlo simulation depends only on network geometry. To demonstrate our proposed method, the reliability criterion of a simple 8×8×8 NoC supported by an 8×8×7 network of TSVs is calculated.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2008440113",
    "type": "article"
  },
  {
    "title": "Inexact computing using probabilistic circuits",
    "doi": "https://doi.org/10.1145/2564925",
    "publication_date": "2014-02-01",
    "publication_year": 2014,
    "authors": "Jaeyoon Kim; Sandip Tiwari",
    "corresponding_authors": "",
    "abstract": "Numerous computing applications can tolerate low error rates. In such applications, inexact approaches provide the ability to achieve significantly lower power. This work demonstrates the power-error trade-offs that can be achieved. Using probabilistic modeling in sub-50-nm silicon transistor technology, the relationship between statistical uncertainties and errors are elucidated for different configurations and topologies and the trade-offs quantified. Gate-level implementation of the probabilistic CMOS logic is validated by circuit simulations of a commercial 45-nm SOI CMOS process technology. Using a practical ALU architecture where voltages can be scaled from most significant to least significant bit blocks as an example, the potential benefits of this technique are shown. A calculation error of 10 −6 , an error rate quite tolerable for many computational tasks, is shown to be possible with a total power reduction of more than 40%.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2028612976",
    "type": "article"
  },
  {
    "title": "System Level Benchmarking with Yield-Enhanced Standard Cell Library for Carbon Nanotube VLSI Circuits",
    "doi": "https://doi.org/10.1145/2600073",
    "publication_date": "2014-05-01",
    "publication_year": 2014,
    "authors": "Shashikanth Bobba; Jie Zhang; Pierre‐Emmanuel Gaillardon; H.‐S. Philip Wong; Subhasish Mitra; Giovanni De Micheli",
    "corresponding_authors": "",
    "abstract": "The quest for technologies with superior device characteristics has showcased Carbon-Nanotube Field-Effect Transistors (CNFET) into limelight. In this work we present physical design techniques to improve the yield of CNFET circuits in the presence of Carbon Nanotube (CNT) imperfections. Various layout schemes are studied for enhancing the yield of CNFET standard cell library. With the help of existing ASIC design flow, we perform system-level benchmarking of CNFET circuits and compare them to CMOS circuits at various technology nodes. With CNFET technology, we observe maximum performance gains for circuits with gate-dominated delays. Averaged across various benchmarks at 16 nm, we report 8× improvement in Energy-Delay-Product (EDP) with CNFET circuits when compared to CMOS counterpart. We also study the performance of a complete OpenRISC processor, where we see 1.5× improvement in EDP over CMOS at 16 nm technology node. Voltage scaling enabled by CNFETs can be explored in the future for further performance benefits.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2035059520",
    "type": "article"
  },
  {
    "title": "MN-MATE",
    "doi": "https://doi.org/10.1145/2701429",
    "publication_date": "2015-08-03",
    "publication_year": 2015,
    "authors": "Kyu Ho Park; Woomin Hwang; Hyunchul Seok; Chul Min Kim; Dong–jae Shin; Dong Jin Kim; Min Kyu Maeng; Seongmin Kim",
    "corresponding_authors": "",
    "abstract": "Recent advent of manycore system increases needs for larger but faster memory hierarchy. Emerging next generation memories such as on-chip DRAM and nonvolatile memory (NVRAM) are promising candidates for replacement of DRAM-only main memory. Combined with the manycore trends, it gives an opportunity to rethink conventional resource management system with a memory hierarchy for a single cloud node. In an attempt to mitigate the energy and memory problems, we propose MN-MATE, an elastic resource management architecture for a single cloud node with manycores, on-chip DRAM, and large size of off-chip DRAM and NVRAM. In MN-MATE, the hypervisor places consolidated VMs and balances memory among them. Based on the monitored information about the allocated memory, a guest OS co-schedules tasks accessing different types of memory with complementary access intensity. Polymorphic management of DRAM hierarchy accelerates average memory access speed inside each guest OS. A guest OS reduces energy consumption with small performance loss based on the NVRAM-aware data placement policy and the hybrid page cache. A new lightweight kernel is developed to reduce the overhead from the guest OS for scientific applications. Experiment results show that our techniques in MN-MATE platform improve system performance and reduce energy consumption.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2257872960",
    "type": "article"
  },
  {
    "title": "Beat Frequency Detector--Based High-Speed True Random Number Generators",
    "doi": "https://doi.org/10.1145/2866574",
    "publication_date": "2016-04-13",
    "publication_year": 2016,
    "authors": "Yingjie Lao; Qianying Tang; Chris H. Kim; Keshab K. Parhi",
    "corresponding_authors": "",
    "abstract": "True random number generators (TRNGs) are crucial components for the security of cryptographic systems. In contrast to pseudo--random number generators (PRNGs), TRNGs provide higher security by extracting randomness from physical phenomena. To evaluate a TRNG, statistical properties of the circuit model and raw bitstream should be studied. In this article, a model for the beat frequency detector--based high-speed TRNG (BFD-TRNG) is proposed. The parameters of the model are extracted from the experimental data of a test chip. A statistical analysis of the proposed model is carried out to derive mean and variance of the counter values of the TRNG. Our statistical analysis results show that mean of the counter values is inversely proportional to the frequency difference of the two ring oscillators (ROSCs), whereas the dynamic range of the counter values increases linearly with standard deviation of environmental noise and decreases with increase of the frequency difference. Without the measurements from the test data, a model cannot be created; similarly, without a model, performance of a TRNG cannot be predicted. The key contribution of the proposed approach lies in fitting the model to measured data and the ability to use the model to predict performance of BFD-TRNGs that have not been fabricated. Several novel alternate BFD-TRNG architectures are also proposed; these include parallel BFD, cascade BFD, and parallel-cascade BFD. These TRNGs are analyzed using the proposed model, and it is shown that the parallel BFD structure requires less area per bit, whereas the cascade BFD structure has a larger dynamic range while maintaining the same mean of the counter values as the original BFD-TRNG. It is shown that 3.25 M and 4 M random bits can be obtained per counter value from parallel BFD and parallel-cascade BFD, respectively, where M counter values are computed in parallel. Furthermore, the statistical analysis results illustrate that BFD-TRNGs have better randomness and less cost per bit than other existing ROSC-TRNG designs. For example, it is shown that BFD-TRNGs accumulate 150% more jitter than the original two-oscillator TRNG and that parallel BFD-TRNGs require one-third power and one-half area for same number of random bits for a specified period.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2338778612",
    "type": "article"
  },
  {
    "title": "A Fault-Based Secret Key Retrieval Method for ECDSA",
    "doi": "https://doi.org/10.1145/2767132",
    "publication_date": "2016-04-20",
    "publication_year": 2016,
    "authors": "Alessandro Barenghi; Guido Bertoni; Luca Breveglieri; Gerardo Pelosi; Stefano Sanfilippo; Ruggero Susella",
    "corresponding_authors": "",
    "abstract": "Elliptic curve cryptosystems proved to be well suited for securing systems with constrained resources like embedded and portable devices. In a fault-based attack, errors are induced during the computation of a cryptographic primitive, and the results are collected to derive information about the secret key safely stored in the device. We introduce a novel attack methodology to recover the secret key employed in implementations of the Elliptic Curve Digital Signature Algorithm. Our attack exploits the information leakage induced when altering the execution of the modular arithmetic operations used in the signature primitive and does not rely on the underlying elliptic curve mathematical structure, thus being applicable to all standardized curves. We provide both a validation of the feasibility of the attack, even employing common off-the-shelf hardware to perform the required computations, and a low-cost countermeasure to counteract it.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2341538571",
    "type": "article"
  },
  {
    "title": "Shielding STT-RAM Based Register Files on GPUs against Read Disturbance",
    "doi": "https://doi.org/10.1145/2996191",
    "publication_date": "2016-11-01",
    "publication_year": 2016,
    "authors": "Hang Zhang; Xuhao Chen; Nong Xiao; Lei Wang; Fang Liu; Wei Chen; Zhiguang Chen",
    "corresponding_authors": "",
    "abstract": "To address the high energy consumption issue of SRAM on GPUs, emerging Spin-Transfer Torque (STT-RAM) memory technology has been intensively studied to build GPU register files for better energy-efficiency, thanks to its benefits of low leakage power, high density, and good scalability. However, STT-RAM suffers from the read disturbance issue, which stems from the fact that the voltage difference between read current and write current becomes smaller as technology scales. The read disturbance leads to high error rates for read operations, which cannot be effectively protected by the SEC-DED ECC on large-capacity register files of GPUs. Prior schemes (e.g., read-restore) to mitigate the read disturbance usually incur either non-trivial performance loss or excessive energy overhead, thus not applicable for the GPU register file design that aims to achieve both high performance and energy-efficiency. To combat the read disturbance, we propose a novel software-hardware co-designed solution (i.e., Red-Shield ), which consists of three optimizations to overcome the limitations of the existing solutions. First, we identify dead reads at compiling stage and augment instructions to avoid unnecessary restores. Second, we employ a small read buffer to accommodate register reads with high-access locality to further reduce restores. Third, we propose an adaptive restore mechanism to selectively pick the suitable restore scheme, according to the busy status of corresponding register banks. Experimental results show that our proposed design can effectively mitigate the performance loss and energy overhead caused by restore operations while still maintaining the reliability of reads.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2547755356",
    "type": "article"
  },
  {
    "title": "High-level interconnect model for the quantum logic array architecture",
    "doi": "https://doi.org/10.1145/1330521.1330522",
    "publication_date": "2008-03-01",
    "publication_year": 2008,
    "authors": "Tzvetan S. Metodi; Darshan Thaker; Andrew W. Cross; Isaac L. Chuang; Frederic T. Chong",
    "corresponding_authors": "",
    "abstract": "We summarize the main characteristics of the quantum logic array (QLA) architecture with a careful look at the key issues not described in the original conference publications: primarily, the teleportation-based logical interconnect. The design goal of the the quantum logic array architecture is to illustrate a model for a large-scale quantum architecture that solves the primary challenges of system-level reliability and data distribution over large distances. The QLA's logical interconnect design, which employs the quantum repeater protocol, is in principle capable of supporting the communication requirements for applications as large as the factoring of a 2048-bit number using Shor's quantum factoring algorithm. Our physical-level assumptions and architectural component validations are based on the trapped ion technology for implementing quantum computing.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2081401382",
    "type": "article"
  },
  {
    "title": "An FPGA Implementation of a Time Delay Reservoir Using Stochastic Logic",
    "doi": "https://doi.org/10.1145/3269984",
    "publication_date": "2018-10-31",
    "publication_year": 2018,
    "authors": "Lisa Loomis; Nathan McDonald; Cory Merkel",
    "corresponding_authors": "",
    "abstract": "This article presents and demonstrates a stochastic logic time delay reservoir design in FPGA hardware. The reservoir network approach is analyzed using a number of metrics, such as kernel quality, generalization rank, and performance on simple benchmarks and is also compared to a deterministic design. A novel re-seeding method is introduced to reduce the adverse effects of stochastic noise, which may also be implemented in other stochastic logic reservoir computing designs, such as echo state networks. Benchmark results indicate that the proposed design performs well on noise-tolerant classification problems, but more work needs to be done to improve the stochastic logic time delay reservoir's robustness for regression problems. In addition, we show that the stochastic design can significantly reduce area cost if the conversion between binary and stochastic representations is implemented efficiently.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2963955913",
    "type": "article"
  },
  {
    "title": "Technology-driven limits on runtime power management algorithms for multiprocessor systems-on-chip",
    "doi": "https://doi.org/10.1145/2367736.2367739",
    "publication_date": "2012-10-01",
    "publication_year": 2012,
    "authors": "Siddharth Garg; Diana Marculescu; Radu Mărculescu",
    "corresponding_authors": "",
    "abstract": "Runtime power management is a critical technique for reducing the energy footprint of digital electronic devices and enabling sustainable computing, since it allows electronic devices to dynamically adapt their power and energy consumption to meet performance requirements. In this article, we consider the case of MultiProcessor Systems-on-Chip (MPSoC) implemented using multiple Voltage and Frequency Islands (VFIs) relying on fine-grained Dynamic Voltage and Frequency Scaling (DVFS) to reduce the system power dissipation. In particular, we present a framework to theoretically analyze the impact of three important technology-driven constraints; (i) reliability-driven upper limits on the maximum supply voltage; (ii) inductive noise-driven constraints on the maximum rate of change of voltage/frequency; and (iii) the impact of manufacturing process variations on the performance of DVFS control for multiple VFI MPSoCs. The proposed analysis is general, in the sense that it is not bound to a specific DVFS control algorithm, but instead focuses on theoretically bounding the performance that any DVFS controller can possibly achieve. Our experimental results on real and synthetic benchmarks show that in the presence of reliability- and temperature-driven constraints on the maximum frequency and maximum frequency increment, any DVFS control algorithm will lose up to 87% performance in terms of the number of steps required to reach a reference steady state. In addition, increasing process variations can lead to up to 60% of fabricated chips being unable to meet the specified DVFS control specifications, irrespective of the DVFS algorithm used. Nonetheless, we note that although conventional DVFS might become less effective with technology scaling, it will continue to play an important role in the context of emerging power management techniques, for example, for massively parallel multiprocessor systems where only a subset of cores can be turned on at any given point of time due to total power constraints.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2026332870",
    "type": "article"
  },
  {
    "title": "Kogge-Stone Adder Realization using 1S1R Resistive Switching Crossbar Arrays",
    "doi": "https://doi.org/10.1145/3183352",
    "publication_date": "2018-04-30",
    "publication_year": 2018,
    "authors": "Debjyoti Bhattacharjee; Anne Siemon; Eike Linn; Stephan Menzel; Anupam Chattopadhyay",
    "corresponding_authors": "",
    "abstract": "Low operating voltage, high storage density, non-volatile storage capabilities, and relative low access latencies have popularized memristive devices as storage devices. Memristors can be ideally used for in-memory computing in the form of hybrid CMOS nano-crossbar arrays. In-memory serial adders have been theoretically and experimentally proven for crossbar arrays. To harness the parallelism of memristive arrays, parallel-prefix adders can be effective. In this work, a novel mapping scheme for in-memory Kogge-Stone adder has been presented. The number of cycles increases logarithmically with the bit width N of the operands, i.e., O ( log 2 N ), and the device count is 5 N . We verify the correctness of the proposed scheme by means of TaO × device model-based memristive simulations. We compare the proposed scheme with other proposed schemes in terms of number of cycle and number of devices.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2848535007",
    "type": "article"
  },
  {
    "title": "Reliability Hardening Mechanisms in Cyber-Physical Digital-Microfluidic Biochips",
    "doi": "https://doi.org/10.1145/3229052",
    "publication_date": "2018-07-31",
    "publication_year": 2018,
    "authors": "Guan-Ruei Lu; Ansuman Banerjee; Bhargab B. Bhattacharya; Tsung-Yi Ho; Hung-Ming Chen",
    "corresponding_authors": "",
    "abstract": "In the area of biomedical engineering, digital-microfluidic biochips (DMFBs) have received considerable attention because of their capability of providing an efficient and reliable platform for conducting point-of-care clinical diagnostics. System reliability, in turn, mandates error-recoverability while implementing biochemical assays on-chip for medical applications. Unfortunately, the technology of DMFBs is not yet fully equipped to handle error-recovery from various microfluidic operations involving droplet motion and reaction. Recently, a number of cyber-physical systems have been proposed to provide real-time checking and error-recovery in assays based on the feedback received from a few on-chip checkpoints. However, to synthesize robust feedback systems for different types of DMFBs, certain practical issues need to be considered such as co-optimization of checkpoint placement, error-recoverability, and layout of droplet-routing pathways. For application-specific DMFBs, we propose here an algorithm that minimizes the number of checkpoints and determines their locations to cover every path in a given droplet-routing solution. Next, for general-purpose DMFBs, where the checkpoints are pre-deployed in specific locations, we present a checkpoint-aware routing algorithm such that every droplet-routing path passes through at least one checkpoint to enable error-recovery and to ensure physical routability of all droplets. Furthermore, we also propose strategies for executing the algorithms in reliable mode to enhance error-recoverability. The proposed methods thus provide reliability-hardening mechanisms for a wide class of cyber-physical DMFBs.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2898560523",
    "type": "article"
  },
  {
    "title": "Binary Precision Neural Network Manycore Accelerator",
    "doi": "https://doi.org/10.1145/3423136",
    "publication_date": "2021-04-05",
    "publication_year": 2021,
    "authors": "Morteza Hosseini; Tinoosh Mohsenin",
    "corresponding_authors": "",
    "abstract": "This article presents a low-power, programmable, domain-specific manycore accelerator, Binarized neural Network Manycore Accelerator (BiNMAC), which adopts and efficiently executes binary precision weight/activation neural network models. Such networks have compact models in which weights are constrained to only 1 bit and can be packed several in one memory entry that minimizes memory footprint to its finest. Packing weights also facilitates executing single instruction, multiple data with simple circuitry that allows maximizing performance and efficiency. The proposed BiNMAC has light-weight cores that support domain-specific instructions, and a router-based memory access architecture that helps with efficient implementation of layers in binary precision weight/activation neural networks of proper size. With only 3.73% and 1.98% area and average power overhead, respectively, novel instructions such as Combined Population-Count-XNOR , Patch-Select , and Bit-based Accumulation are added to the instruction set architecture of the BiNMAC, each of which replaces execution cycles of frequently used functions with 1 clock cycle that otherwise would have taken 54, 4, and 3 clock cycles, respectively. Additionally, customized logic is added to every core to transpose 16×16-bit blocks of memory on a bit-level basis, that expedites reshaping intermediate data to be well-aligned for bitwise operations. A 64-cluster architecture of the BiNMAC is fully placed and routed in 65-nm TSMC CMOS technology, where a single cluster occupies an area of 0.53 mm 2 with an average power of 232 mW at 1-GHz clock frequency and 1.1 V. The 64-cluster architecture takes 36.5 mm 2 area and, if fully exploited, consumes a total power of 16.4 W and can perform 1,360 Giga Operations Per Second (GOPS) while providing full programmability. To demonstrate its scalability, four binarized case studies including ResNet-20 and LeNet-5 for high-performance image classification, as well as a ConvNet and a multilayer perceptron for low-power physiological applications were implemented on BiNMAC. The implementation results indicate that the population-count instruction alone can expedite the performance by approximately 5×. When other new instructions are added to a RISC machine with existing population-count instruction, the performance is increased by 58% on average. To compare the performance of the BiNMAC with other commercial-off-the-shelf platforms, the case studies with their double-precision floating-point models are also implemented on the NVIDIA Jetson TX2 SoC (CPU+GPU). The results indicate that, within a margin of ∼2.1%--9.5% accuracy loss, BiNMAC on average outperforms the TX2 GPU by approximately 1.9× (or 7.5× with fabrication technology scaled) in energy consumption for image classification applications. On low power settings and within a margin of ∼3.7%--5.5% accuracy loss compared to ARM Cortex-A57 CPU implementation, BiNMAC is roughly ∼9.7×--17.2× (or 38.8×--68.8× with fabrication technology scaled) more energy efficient for physiological applications while meeting the application deadline.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W3147050786",
    "type": "article"
  },
  {
    "title": "A Survey Describing Beyond Si Transistors and Exploring Their Implications for Future Processors",
    "doi": "https://doi.org/10.1145/3453143",
    "publication_date": "2021-06-30",
    "publication_year": 2021,
    "authors": "Heewoo Kim; Aporva Amarnath; Javad Bagherzadeh; Nishil Talati; Ronald Dreslinski",
    "corresponding_authors": "",
    "abstract": "The advancement of Silicon CMOS technology has led information technology innovation for decades. However, scaling transistors down according to Moore’s law is almost reaching its limitations. To improve system performance, cost, and energy efficiency, vertical-optimization in multiple layers of the computing stack is required. Technological awareness in terms of devices and circuits could enable informed system-level decisions. For example, graphene is a promising material for extremely scaled high-speed transistors because of its remarkably high mobility, but it can not be used in integrated circuits as a result of the high leakage current from its zero bandgap. In this article, we discuss the fundamental physics of transistors and their ramifications on system design to assist device-level technology consideration during system design. Additionally, various emerging devices and their utilization on a vertically-optimized computing stack are introduced. This article serves as a survey of emerging device technologies that may be relevant in these areas, with an emphasis on making the descriptions approachable by system and software designers to understand the potential solutions. A basic vocabulary will be built to understand how to digest technical content, followed by a survey of devices, and finally a discussion of the implications for future processing systems.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W3177065893",
    "type": "article"
  },
  {
    "title": "Artificial Intelligence–based Computed Tomography Processing Framework for Surgical Telementoring of Congenital Heart Disease",
    "doi": "https://doi.org/10.1145/3457613",
    "publication_date": "2021-08-20",
    "publication_year": 2021,
    "authors": "Wen Xie; Zeyang Yao; Erchao Ji; Hailong Qiu; Zewen Chen; Huiming Guo; Jian Zhuang; Qianjun Jia; Meiping Huang",
    "corresponding_authors": "",
    "abstract": "Congenital heart disease (CHD) is the most common birth defect, accounting for one-third of all congenital birth defects. As with complicated intracardiac structural abnormalities, CHD is usually treated with surgical repair, and computed tomography (CT) is the main examination method for diagnosis of CHD and also provides anatomical information to surgeons. Currently, there exists a serious shortage of professional surgeons in developing countries. Compared with developed countries where large hospitals and cardiovascular disease centers have professional surgical teams with rich treatment experience, surgeons in developing countries and remote areas suffer from lack of professional surgical skills resulting with low surgical quality and high mortality. Recently, surgical telementoring has been popular to tackle the above problems, in which less-skilled surgeons can get real-time guidance from skilled surgeons remotely through audio and video transmission. However, there still exists difficulties in applying telementoring to CHD surgeries including high resource consumption on medical data transmission and storage, large image noise, and inconvenient and inefficient discussion between surgeons on CT. In this article, we proposed a framework with an image compression module, an image denoising module, and an image segmentation module based on CT images in CHD. We evaluated the above three modules and compared them with existing works, respectively, and the results show that our methods achieve much better performance. Furthermore, with 3D printing, VR technology, and 5G communications, our framework was successfully used in a real case study to treat a patient who needed surgical treatment.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W3194213365",
    "type": "article"
  },
  {
    "title": "Placement optimization of flexible TFT circuits with mechanical strain and temperature consideration",
    "doi": "https://doi.org/10.1145/2629497",
    "publication_date": "2014-10-06",
    "publication_year": 2014,
    "authors": "Jiun-Li Lin; Po-Hsun Wu; Tsung-Yi Ho",
    "corresponding_authors": "",
    "abstract": "Mobility is the primary device parameter affecting circuit performance in flexible thin-film transistor (TFT) technologies, and is particularly sensitive to the change of mechanical strain and temperature. However, existing algorithms only consider the impact of mechanical strain in cell placement of flexible TFT circuits. Without taking temperature into consideration, mobility may be dramatically decreased which leads to circuit performance degradation. This article presents the first work to minimize the mobility variation caused by the change of both mechanical strain and temperature. Experimental results show that the proposed algorithms can effectively and efficiently reduce the increasing critical path delay.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W1988619505",
    "type": "article"
  },
  {
    "title": "Fully Binary Neural Network Model and Optimized Hardware Architectures for Associative Memories",
    "doi": "https://doi.org/10.1145/2629510",
    "publication_date": "2015-04-27",
    "publication_year": 2015,
    "authors": "Philippe Coussy; Cyrille Chavet; Hugues Nono Wouafo; Laura Conde-Canencia",
    "corresponding_authors": "",
    "abstract": "Brain processes information through a complex hierarchical associative memory organization that is distributed across a complex neural network. The GBNN associative memory model has recently been proposed as a new class of recurrent clustered neural network that presents higher efficiency than the classical models. In this article, we propose computational simplifications and architectural optimizations of the original GBNN. This work leads to significant complexity and area reduction without affecting neither memorizing nor retrieving performance. The obtained results open new perspectives in the design of neuromorphic hardware to support large-scale general-purpose neural algorithms.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2002942710",
    "type": "article"
  },
  {
    "title": "Randomly Spiking Dynamic Neural Fields",
    "doi": "https://doi.org/10.1145/2629517",
    "publication_date": "2015-04-27",
    "publication_year": 2015,
    "authors": "Benoît Chappet de Vangel; César Torres-Huitzil; Bernard Girau",
    "corresponding_authors": "",
    "abstract": "Bio-inspired neural computation attracts a lot of attention as a possible solution for the future challenges in designing computational resources. Dynamic neural fields (DNF) provide cortically inspired models of neural populations to which computation can be applied for a wide variety of tasks, such as perception and sensorimotor control. DNFs are often derived from continuous neural field theory (CNFT). In spite of the parallel structure and regularity of CNFT models, few studies of hardware implementations have been carried out targeting embedded real-time processing. In this article, a hardware-friendly model adapted from the CNFT is introduced, namely the RSDNF model (randomly spiking dynamic neural fields). Thanks to their simplified 2D structure, RSDNFs achieve scalable parallel implementations on digital hardware while maintaining the behavioral properties of CNFT models. Spike-based computations within neurons in the field are introduced to reduce interneuron connection bandwidth. Additionally, local stochastic spike propagation ensures inhibition and excitation broadcast without a fully connected network. The behavioral soundness and robustness of the model in the presence of noise and distracters is fully validated through software and hardware. A field programmable gate array (FPGA) implementation shows how the RSDNF model ensures a level of density and scalability out of reach for previous hardware implementations of dynamic neural field models.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2045604712",
    "type": "article"
  },
  {
    "title": "Matrix Calculus for Classical and Quantum Circuits",
    "doi": "https://doi.org/10.1145/2669370",
    "publication_date": "2014-11-18",
    "publication_year": 2014,
    "authors": "Alexis De Vos; Stijn De Baerdemacker",
    "corresponding_authors": "",
    "abstract": "Quantum computation on w qubits is represented by the infinite unitary group U(2 w ); classical reversible computation on w bits is represented by the finite symmetric group S 2 w . In order to establish the relationship between classical reversible computing and quantum computing, we introduce two Lie subgroups XU( n ) and ZU( n ) of the unitary group U( n ). The former consists of all unitary n × n matrices with all line sums equal to 1; the latter consists of all unitary diagonal n × n matrices with first entry equal to 1. Such a group structure also reveals the relationship between matrix calculus and diagrammatic zx-calculus of quantum circuits.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2076909459",
    "type": "article"
  },
  {
    "title": "Energy-Efficient All-Spin Cache Hierarchy Using Shift-Based Writes and Multilevel Storage",
    "doi": "https://doi.org/10.1145/2723165",
    "publication_date": "2015-08-03",
    "publication_year": 2015,
    "authors": "Rangharajan Venkatesan; Mrigank Sharad; Kaushik Roy; Anand Raghunathan",
    "corresponding_authors": "",
    "abstract": "Spintronic memories are considered to be promising candidates for future on-chip memories due to their high density, nonvolatility, and near-zero leakage. However, they also face challenges such as high write energy and latency and limited read speed due to single-ended sensing. Further, the conflicting requirements of read and write operations lead to stringent design constraints that severely compromises their benefits. Recently, domain wall memory was proposed as a spintronic memory that has a potential for very high density by storing multiple bits in the domains of a ferromagnetic nanowire. While reliable operation of DWM memory with multiple domains faces many challenges, single-bit cells that utilize domain wall motion for writes have been experimentally demonstrated [Fukami et al. 2009]. This bit-cell, which we refer to as Domain Wall Memory with Shift-based Write (DWM-SW), achieves improved write efficiency and features decoupled read-write paths, enabling independent optimizations of read and write operations. However, these benefits are achieved at the cost of sacrificing the original goal of improved density. In this work, we explore multilevel storage as a new direction to enhance the density benefits of DWM-SW. At the device level, we propose a new device--multilevel DWM with shift-based write (ML-DWM-SW)--that is capable of storing 2 bits in a single device. At the circuit level, we propose a ML-DWM-SW based bit-cell design and layout. The ML-DWM-SW bit-cell incurs no additional area overhead compared to the DWM-SW bit-cell despite storing an additional bit, thereby achieving roughly twice the density. However, it requires a two-step write operation and has data-dependent read and write energies, which pose unique challenges. To address these issues, we propose suitable architectural optimizations: (i) intra-word interleaving and (ii) bit encoding. We design “all-spin” cache architectures using the proposed ML-DWM-SW bit-cell for both general purpose processors as well as general purpose graphics processing units (GPGPUs). We perform an iso-capacity replacement of SRAM with spintronic memories and study the energy and area benefits at iso-performance conditions. For general purpose processors, the ML-DWM-SW cache achieves 10X reduction in energy and 4.4X reduction in cache area compared to an SRAM cache and 2X and 1.7X reduction in energy and area, respectively, compared to an STT-MRAM cache. For GPGPUs, the ML-DWM-SW cache achieves 5.3X reduction in energy and 3.6X area reduction compared to SRAM and 3.5X energy reduction and 1.9X area reduction compared to STT-MRAM.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2239634269",
    "type": "article"
  },
  {
    "title": "Towards a Truly Integrated Vector Processing Unit for Memory-bound Applications Based on a Cost-competitive Computational SRAM Design Solution",
    "doi": "https://doi.org/10.1145/3485823",
    "publication_date": "2022-04-28",
    "publication_year": 2022,
    "authors": "Maha Kooli; Antoine Heraud; Henri‐Pierre Charles; Bastien Giraud; Roman Gauchi; M. Ezzadeen; Kévin Mambu; Valentin Egloff; Jean-Philippe Noël",
    "corresponding_authors": "",
    "abstract": "This article presents Computational SRAM (C-SRAM) solution combining In- and Near-Memory Computing approaches. It allows performing arithmetic, logic, and complex memory operations inside or next to the memory without transferring data over the system bus, leading to significant energy reduction. Operations are performed on large vectors of data occupying the entire physical row of C-SRAM array, leading to high performance gains. We introduce the C-SRAM solution in this article as an integrated vector processing unit to be used by a scalar processor as an energy-efficient and high performing co-processor. We detail the C-SRAM system design on different levels: (i) circuit design and silicon proof of concept, (ii) system interface and instruction set architecture, and (iii) high-level software programming and simulation. Experimental results on two complete memory-bound applications, AES and MobileNetV2, show that the C-SRAM implementation achieves up to 70× timing speedup and 37× energy reduction compared to scalar architecture, and up to 17× timing speedup and 5× energy reduction compared to SIMD architecture.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W4293241660",
    "type": "article"
  },
  {
    "title": "<scp>AccHashtag</scp> : Accelerated Hashing for Detecting Fault-Injection Attacks on Embedded Neural Networks",
    "doi": "https://doi.org/10.1145/3555808",
    "publication_date": "2022-08-10",
    "publication_year": 2022,
    "authors": "Mojan Javaheripi; Jung-Woo Chang; Farinaz Koushanfar",
    "corresponding_authors": "",
    "abstract": "We propose AccHashtag , the first framework for high-accuracy detection of fault-injection attacks on Deep Neural Networks (DNNs) with provable bounds on detection performance. Recent literature in fault-injection attacks shows the severe DNN accuracy degradation caused by bit flips. In this scenario, the attacker changes a few DNN weight bits during execution by injecting faults to the dynamic random-access memory (DRAM). To detect bit flips, AccHashtag extracts a unique signature from the benign DNN prior to deployment. The signature is used to validate the model’s integrity and verify the inference output on the fly. We propose a novel sensitivity analysis that identifies the most vulnerable DNN layers to the fault-injection attack. The DNN signature is constructed by encoding the weights in vulnerable layers using a low-collision hash function. During DNN inference, new hashes are extracted from the target layers and compared against the ground-truth signatures. AccHashtag incorporates a lightweight methodology that allows for real-time fault detection on embedded platforms. We devise a specialized compute core for AccHashtag on field-programmable gate arrays (FPGAs) to facilitate online hash generation in parallel to DNN execution. Extensive evaluations with the state-of-the-art bit-flip attack on various DNNs demonstrate the competitive advantage of AccHashtag in terms of both attack detection and execution overhead.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W4297830861",
    "type": "article"
  },
  {
    "title": "Survey of Approaches and Techniques for Security Verification of Computer Systems",
    "doi": "https://doi.org/10.1145/3564785",
    "publication_date": "2022-10-06",
    "publication_year": 2022,
    "authors": "Ferhat Erata; Shuwen Deng; Faisal Zaghloul; Wenjie Xiong; Onur Demir; Jakub Szefer",
    "corresponding_authors": "",
    "abstract": "This article surveys the landscape of security verification approaches and techniques for computer systems at various levels: from a software-application level all the way to the physical hardware level. Different existing projects are compared, based on the tools used and security aspects being examined. Since many systems require both hardware and software components to work together to provide the system’s promised security protections, it is not sufficient to verify just the software levels or just the hardware levels in a mutually exclusive fashion. This survey especially highlights system levels that are verified by the different existing projects and presents to the readers the state of the art in hardware and software system security verification. Few approaches come close to providing full-system verification, and there is still much room for improvement.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W4306179292",
    "type": "article"
  },
  {
    "title": "Introduction to the Special Issue on BioFoundries and Cloud Laboratories",
    "doi": "https://doi.org/10.1145/3609485",
    "publication_date": "2023-07-31",
    "publication_year": 2023,
    "authors": "Douglas Densmore; Nathan J. Hillson; Eric Klavins; Chris J. Myers; Jean Peccoud; Giovanni Stracquadanio",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4385454669",
    "type": "article"
  },
  {
    "title": "Multiple fault diagnosis in digital microfluidic biochips",
    "doi": "https://doi.org/10.1145/1216396.1216398",
    "publication_date": "2006-10-01",
    "publication_year": 2006,
    "authors": "Daniel Davids; Siddhartha Datta; Arindam Mukherjee; Bharat Joshi; Arun Ravindran",
    "corresponding_authors": "",
    "abstract": "Microfluidics-based biochips consist of microfluidic arrays on rigid substrates through which, movement of fluids is tightly controlled to facilitate biological reactions. Biochips are soon expected to revolutionize biosensing, clinical diagnostics, and drug discovery. Critical to the deployment of biochips in such diverse areas is the dependability of these systems. Thus, robust testing techniques are required to ensure an adequate level of system dependability. Due to the underlying mixed technology and energy domains, such biochips exhibit unique failure mechanisms and defects. In this article we present a highly effective fault diagnosis strategy that uses a single source and sink to detect and locate multiple faults in a microfluidic array, without flooding the array, a problem that has hampered realistic implementations of all existing strategies. The strategy renders itself well for a built-in self-test that could drastically reduce the operating cost of microfluidic biochips. It can be used during both the manufacturing phase of the biochip, as well as field operation. Furthermore, the algorithm can pinpoint the actual fault, as opposed to merely the faulty regions that are typically identified by strategies proposed in the literature. Also, analytical results suggest that it is an effective strategy that can be used to design highly dependable biochip systems.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2031948721",
    "type": "article"
  },
  {
    "title": "ULS",
    "doi": "https://doi.org/10.1145/1773814.1773819",
    "publication_date": "2008-06-18",
    "publication_year": 2008,
    "authors": "Saraju P. Mohanty; Dhiraj K. Pradhan",
    "corresponding_authors": "",
    "abstract": "Power dissipation is a major bottleneck for emerging applications, such as implantable systems, digital cameras, and multimedia processors. Each of these applications is essentially designed as an Analog/Mixed-Signal System-on-a-Chip (AMS-SoC). These AMS-SoCs are typically operated from a single power-supply source which is a battery providing a constant supply voltage. In order to reduce power dissipation of the AMS-SoCs, multiple-supply voltage and/or variable-supply voltage is used as an attractive low-power design approach. In the multiple-/variable-supply voltage AMS-SoCs the use of a DC-to-DC voltage-level shifter is critical. The voltage-level shifter is an overhead when its own power dissipation is high. In this article a new DC-to-DC voltage-level shifter is introduced that performs level-up shifting, level-down shifting, and blocking of voltages and is called Universal Level Shifter (ULS). The ULS is a unique component that reduces dynamic power and leakage of the AMS-SoCs while facilitating their reconfigurability. The system-level architectures for three AMS-SoCs, such as Drug Delivery Nano-Electro-Mechanical-System (DDNEMS), Secure Digital Camera (SDC), and Net-centric Multimedia Processor (NMP) are introduced to demonstrate the use the ULS for system-level power management. The article presents a design flow and an algorithm for optimal design of the ULS using a dual- V th high-κ technique for efficient realization of ULS. A prototype ULS is presented for 32nm nano-CMOS technology node. The robustness of the ULS design is examined by performing three types of analysis, such as parametric, load, and power. It is observed that the ULS produces a stable output for voltages as low as 0.35 V and loads varying from 50 fF to 120 fF . The average power dissipation of the ULS with a 82 fF capacitive load is 5 μ W .",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2061503929",
    "type": "article"
  },
  {
    "title": "Evolving dependability",
    "doi": "https://doi.org/10.1145/1265949.1265953",
    "publication_date": "2007-07-01",
    "publication_year": 2007,
    "authors": "Andy M. Tyrrell; Andrew Greensted",
    "corresponding_authors": "",
    "abstract": "Evolvable hardware offers much for the future of complex systems design. Evolutionary techniques not only have the potential for larger solution space coverage, but when implemented on hardware, also allow system designs to adapt to changes in the environment, including failures in system components. This article reviews a number of novel techniques, all based in the field of bio-inspired systems, that provide varying degrees of dependability over and above standard designs. In particular, three different techniques are considered: using FPGAs and ideas from developmental biology to create designs that possess emergent fault-tolerant properties, using FPGAs and continuous evolution to circumvent faults as and when they occur, and, finally, we consider a novel ASIC designed and built with bio-inspired systems in mind.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2295119129",
    "type": "article"
  },
  {
    "title": "Low-overhead defect tolerance in crossbar nanoarchitectures",
    "doi": "https://doi.org/10.1145/1543438.1543444",
    "publication_date": "2009-07-01",
    "publication_year": 2009,
    "authors": "Mehdi B. Tahoori",
    "corresponding_authors": "Mehdi B. Tahoori",
    "abstract": "It is anticipated that the number of defects in nanoscale devices fabricated using bottom-up self-assembly process is significantly higher than that for CMOS devices fabricated by conventional top-down lithography patterning. This is mainly because of inherent lack of control in self-assembly fabrication as well as atomic scale of devices. The goal of defect tolerance, as an integral part of nano computing, is to obtain error-free computation from such fabrics containing defective elements. In this article, an application-independent defect tolerant scheme for reconfigurable crossbar array nanoarchitectures is presented. The main feature of this approach is that the existence and location of defective resources within the nano-fabric are hidden from the entire design flow, resulting in minimum post-fabrication customization per chip and minimum changes to the entire design and synthesis flow. It is also shown how to drastically minimize the area overhead associated with this flow. The proposed technique requires extraction of regular yet incomplete defect-free subsets, in contrast to previously proposed complete defect-free subsets. This can greatly reduce the area overhead required for defect tolerance while not sacrificing logic mapping or signal routing capabilities. Extensive simulation results confirm considerable reduction in the area overhead without any negative impact on the usability of modified defect-free subsets.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W1980448923",
    "type": "article"
  },
  {
    "title": "A shift-register-based QCA memory architecture",
    "doi": "https://doi.org/10.1145/1482613.1482617",
    "publication_date": "2009-01-01",
    "publication_year": 2009,
    "authors": "Barış Taşkın; Andy Chiu; Jonathan Salkind; Daniel Venutolo",
    "corresponding_authors": "",
    "abstract": "A quantum-dot cellular automata (QCA) design of an nxm -bit, shift-register-based memory architecture is presented. The architecture maintains data at a stable conformation, which is contrary to traditional data in-motion concept for QCA architectures. The memory architecture is based on an existing dual-phase-synchronized, line-based, one-bit QCA memory cell building block that provides size and latency improvements over other known one-bit memory cells through its novel clocking scheme. Read/write latencies up to ∼2X lower than the existing tile-based architecture with three-phase, line-based memory cells are obtained. Simulations with QCADesigner and HDLQ are performed on a sample 4 x 8 bit memory architecture implementation.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2122230315",
    "type": "article"
  },
  {
    "title": "A Novel Algorithm for Fast Synthesis of DNA Probes on Microarrays",
    "doi": "https://doi.org/10.1145/2422094.2422095",
    "publication_date": "2013-02-01",
    "publication_year": 2013,
    "authors": "Sumana Srinivasan; V. Kamakoti; Arnab Bhattacharya",
    "corresponding_authors": "",
    "abstract": "DNA microarrays are used extensively for biochemical analysis that includes genomics and drug discovery. This increased usage demands large microarrays, thus complicating their computer aided design (CAD) and manufacturing methodologies. One such time-consuming design problem is to minimize the border length of masks used during the manufacture of microarrays. From the manufacturing point of view the border length of masks is one of the crucial parameters determining the reliability of the microarray. This article presents a novel algorithm for synthesis (placement and embedding) of microarrays, which consumes significantly less time than the best algorithm reported in the literature, while maintaining the quality (border length of masks) of the result. The proposed technique uses only a part of each probe to decide on the placement and the remaining parts for deciding on the embedding sequence. This is in contrast to the earlier methods that considered the entire probe for both placement and embedding. The second novelty of the proposed technique is the preclassification (prior to placement and embedding) of probes based on their prefixes. This decreases the complexity of the problem of deciding the next probe to be placed from that involving computation of Hamming distance between all probes (as used in earlier approaches) to the one involving searching of nonempty cells on a constant size grid array. The proposed algorithm is 43× faster than the best reported in the literature for the case of synthesizing a microarray with 250,000 probes and further exhibits linear behavior in terms of computation time for larger microarrays.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W1978617702",
    "type": "article"
  },
  {
    "title": "Design space exploration of FinFET cache",
    "doi": "https://doi.org/10.1145/2491678",
    "publication_date": "2013-09-01",
    "publication_year": 2013,
    "authors": "Aoxiang Tang; Niraj K. Jha",
    "corresponding_authors": "",
    "abstract": "Integration of cache on-chip has significantly improved the performance of modern processors. The relentless demand for ever-increasing performance has led to the need to increase the cache capacity and number of cache levels. However, the performance improvement is accompanied by an increase in chip's power dissipation, requiring the use of more expensive cooling technologies to ensure chip reliability and long product life. The emergence of FinFETs as the technology of choice for high-performance computing poses new challenges to processor designers. With the introduction of new features in FinFETs, for example, independently controllable back gates, researchers have proposed several innovative memory cells that can reduce leakage power significantly, making the integration of a larger cache more practical. In this article, we comprehensively evaluate and compare the performance, power consumption (both dynamic and leakage), area, and temperature of different FinFET SRAM caches by exploring common configurations with varying cache size, block size, associativity, and number of banks. We evaluate caches based on four well-known FinFET SRAM cells: Pass-Gate FeedBack (PGFB), Row-based Back-Gate Biasing (RBGB), 8T, and 4T. We show how the caches can be simulated at self-consistent temperatures (at which leakage and temperature are in equilibrium). Drowsy and decay caches are two well-known leakage reduction techniques. We implement them in the context of FinFET caches to investigate their impact. We show that the RBGB cell-based cache is far superior in leakage and Power-Delay Product (PDP) to those based on the other three cells, sometimes by an order of magnitude. This superiority is maintained even when drowsy or decay leakage reduction techniques are applied to caches based on the other three cells, but not to the one based on the RBGB cell. This significantly diminishes the importance of drowsy or decay cache techniques, at least when the RBGB cell is used.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2004676554",
    "type": "article"
  },
  {
    "title": "An Implantable Release-on-Demand CMOS Drug Delivery SoC Using Electrothermal Activation Technique",
    "doi": "https://doi.org/10.1145/2180878.2180884",
    "publication_date": "2012-06-01",
    "publication_year": 2012,
    "authors": "Yujie Huang; Hsin-Hung Liao; Pen-Li Huang; Tao Wang; Yao‐Joe Yang; Yao-Hong Wang; Shey‐Shi Lu",
    "corresponding_authors": "",
    "abstract": "An implantable system-on-a-chip (SoC) integrating controller/actuation circuitry and 8 individually addressable drug reservoirs is proposed for on-demand drug delivery. It is implemented by standard 0.35- μ m CMOS technology and post-IC processing. The post-IC processing includes deposition of metallic membranes (200Å Pt/3000Å Ti/200Å Pt) to cap the drug reservoirs, deep dry etching to carve drug reservoirs in silicon as drug containers, and PDMS layer bonding to enlarge the drug storage. Based on electrothermal activation technique, drug releases can be precisely controlled by wireless signals. The wireless controller/actuation circuits including on-off keying (OOK) receiver, microcontroller unit, clock generator, power-on-reset circuit, and switch array are integrated on the same chip, providing patients the ability of remote drug activation and noninvasive therapy modification. Implanted by minimally invasive surgery, this SoC can be used for the precise drug dosing of localized treatment, such as the cancer therapy, or the immediate medication to some emergent diseases, such as heart attack. In vitro experimental results show that the reservoir content can be released successfully through the rupture of the membrane which is appointed by received wireless commands.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2042181081",
    "type": "article"
  },
  {
    "title": "Microarchitectural Transformations Using Elasticity",
    "doi": "https://doi.org/10.1145/2043643.2043648",
    "publication_date": "2011-12-01",
    "publication_year": 2011,
    "authors": "Marc Galceran-Oms; Alexander Gotmanov; Jordi Cortadella; Mike Kishinevsky",
    "corresponding_authors": "",
    "abstract": "Elasticity is a paradigm that tolerates the variations in computation and communication delays. By applying elastic transformations that allow varying the original timing, circuits can be optimized beyond the conventional rigid transformations that do not modify the external timing. Pipelining is one of the classical techniques to improve the throughput of a circuit. This article reveals how elasticity can be effectively and practically used to derive pipelined circuits by using correct-by-construction transformations that can be fully automated. Two designs, one of them industrial, are used to demonstrate how the area-performance trade-off can be explored using elasticity.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2087373108",
    "type": "article"
  },
  {
    "title": "Quantum Circuit Synthesis Targeting to Improve One-Way Quantum Computation Pattern Cost Metrics",
    "doi": "https://doi.org/10.1145/3064834",
    "publication_date": "2017-05-21",
    "publication_year": 2017,
    "authors": "Mahboobeh Houshmand; Mehdi Sedighi; Morteza Saheb Zamani; Kourosh Marjoei",
    "corresponding_authors": "",
    "abstract": "One-way quantum computation (1WQC) is a model of universal quantum computations in which a specific highly entangled state called a cluster state allows for quantum computation by single-qubit measurements. The needed computations in this model are organized as measurement patterns. The traditional approach to obtain a measurement pattern is by translating a quantum circuit that solely consists of CZ and J (α) gates into the corresponding measurement patterns and then performing some optimizations by using techniques proposed for the 1WQC model. However, in these cases, the input of the problem is a quantum circuit, not an arbitrary unitary matrix. Therefore, in this article, we focus on the first phase—that is, decomposing a unitary matrix into CZ and J (α) gates. Two well-known quantum circuit synthesis methods, namely cosine-sine decomposition and quantum Shannon decomposition are considered and then adapted for a library of gates containing CZ and J (α), equipped with optimizations. By exploring the solution space of the combinations of these two methods in a bottom-up approach of dynamic programming, a multiobjective quantum circuit synthesis method is proposed that generates a set of quantum circuits. This approach attempts to simultaneously improve the measurement pattern cost metrics after the translation from this set of quantum circuits.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2619746989",
    "type": "article"
  },
  {
    "title": "Heterogeneous HMC+DDRx Memory Management for Performance-Temperature Tradeoffs",
    "doi": "https://doi.org/10.1145/3106233",
    "publication_date": "2017-09-21",
    "publication_year": 2017,
    "authors": "Mohammad Hossein Hajkazemi; Mohammad Khavari Tavana; Tinoosh Mohsenin; Houman Homayoun",
    "corresponding_authors": "",
    "abstract": "Three-dimensional DRAMs (3D-DRAMs) are emerging as a promising solution to address the memory wall problem in computer systems. However, high fabrication cost per bit and thermal issues are the main reasons that prevent architects from using 3D-DRAM alone as the main memory building block. In this article, we address this issue by proposing a heterogeneous memory system that combines a double data rate (DDRx) DRAM with an emerging 3D hybrid memory cube (HMC) technology. Bandwidth and temperature management are the challenging issues for this heterogeneous memory architecture. To address these challenges, first we introduce a memory page allocation policy for the heterogeneous memory system to maximize performance. Then, using the proposed policy, we introduce a temperature-aware algorithm that dynamically distributes the requested bandwidth between HMC and DDRx DRAM to reduce the thermal hotspot while maintaining high performance. We take into account the impact of both core count and HMC channel count on performance while using the proposed policies. The results show that the proposed memory page allocation policy can utilize the memory bandwidth close to 99% of the ideal bandwidth utilization. Moreover, our temperate-aware bandwidth adaptation reduces the average steady-state temperature of the HMC hotspot across various workloads by 4.5 K while incurring 2.5% performance overhead.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2758168304",
    "type": "article"
  },
  {
    "title": "Reducing Power Consumption of Lasers in Photonic NoCs through Application-Specific Mapping",
    "doi": "https://doi.org/10.1145/3173463",
    "publication_date": "2018-04-30",
    "publication_year": 2018,
    "authors": "Edoardo Fusella; Alessandro Cilardo",
    "corresponding_authors": "",
    "abstract": "To face the complex communication problems that arise as the number of on-chip components grows up, photonic networks-on-chip (NoCs) have been recently proposed to replace electronic interconnects. However, photonic NoCs lack efficient laser sources, possibly resulting in an inefficient or inoperable architecture. In this article, we introduce a methodology for the design space exploration of optical NoC mapping solutions, which automatically assigns IPs/cores to the network tiles such that the laser power consumption is minimized. The experimental evaluation shows average reductions of 34.7% and 27.3% in the power consumption compared to, respectively, application-oblivious and randomly mapped photonic NoCs, allowing improved energy efficiency.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2854435871",
    "type": "article"
  },
  {
    "title": "A Learning-Based Thermal-Sensitive Power Optimization Approach for Optical NoCs",
    "doi": "https://doi.org/10.1145/3173468",
    "publication_date": "2018-04-30",
    "publication_year": 2018,
    "authors": "Zhe Zhang; Yaoyao Ye",
    "corresponding_authors": "",
    "abstract": "Optical networks-on-chip (NoCs) based on silicon photonics have been proposed as emerging on-chip communication architectures for chip multiprocessors with large core counts. However, due to the thermal sensitivity of optical devices used in optical NoCs, on-chip temperature variations cause significant thermal-induced optical power loss, which would counteract the power advantages of optical NoCs. To tackle this problem, in this work, we propose a learning-based thermal-sensitive power optimization approach for mesh- or torus-based optical NoCs in the presence of temperature variations. The key techniques proposed include an initial device-setting and thermal-tuning mechanism that is a device-level optimization technique, and a learning-based thermal-sensitive adaptive routing algorithm that is a network-level optimization technique. Simulation results of an 8x8 mesh-based optical NoC show that the proposed initial device-setting and thermal-tuning mechanism confines the worst-case thermal-induced optical energy consumption to be on the order of tens of pJ/bit, by avoiding significant thermal-induced optical power loss caused by temperature-dependent wavelength shifts. Besides, it shows that the learning-based thermal-sensitive adaptive routing algorithm is able to find an optimal path with the minimum estimated thermal-induced optical power consumption for each communication pair. The proposed routing has a greater space for optimization, especially for applications with more long-distance traffic.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2857339766",
    "type": "article"
  },
  {
    "title": "Memristor-CMOS Analog Coprocessor for Acceleration of High-Performance Computing Applications",
    "doi": "https://doi.org/10.1145/3269985",
    "publication_date": "2018-07-31",
    "publication_year": 2018,
    "authors": "Nihar Athreyas; Wenhao Song; Blair Perot; Qiangfei Xia; Abbie Mathew; Jai Gupta; Dev Gupta; J. Joshua Yang",
    "corresponding_authors": "",
    "abstract": "Vector matrix multiplication computation underlies major applications in machine vision, deep learning, and scientific simulation. These applications require high computational speed and are run on platforms that are size, weight, and power constrained. With the transistor scaling coming to an end, existing digital hardware architectures will not be able to meet this increasing demand. Analog computation with its rich set of primitives and inherent parallel architecture can be faster, more efficient, and compact for some of these applications. One such primitive is a memristor-CMOS crossbar array-based vector matrix multiplication. In this article, we develop a memristor-CMOS analog coprocessor architecture that can handle floating-point computation. To demonstrate the working of the analog coprocessor at a system level, we use a new electronic design automation tool called PSpice Systems Option, which performs integrated cosimulation of MATLAB/Simulink and PSpice. It is shown that the analog coprocessor has a superior performance when compared to other processors, and a speedup of up to 12 × when compared to projected GPU performance is observed. Using the new PSpice Systems Option tool, various application simulations for image processing and solutions to partial differential equations are performed on the analog coprocessor model.&lt;?enlrg 3pt?&gt;",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2899068323",
    "type": "article"
  },
  {
    "title": "Timing-Optimized Hardware Implementation to Accelerate Polynomial Multiplication in the NTRU Algorithm",
    "doi": "https://doi.org/10.1145/3445979",
    "publication_date": "2021-05-11",
    "publication_year": 2021,
    "authors": "Eros Camacho-Ruiz; Santiago Sánchez-Solano; Piedad Brox; Macarena C. Martínez‐Rodríguez",
    "corresponding_authors": "",
    "abstract": "Post-quantum cryptographic algorithms have emerged to secure communication channels between electronic devices faced with the advent of quantum computers. The performance of post-quantum cryptographic algorithms on embedded systems has to be evaluated to achieve a good trade-off between required resources (area) and timing. This work presents two optimized implementations to speed up the NTRUEncrypt algorithm on a system-on-chip. The strategy is based on accelerating the most time-consuming operation that is the truncated polynomial multiplication. Hardware dedicated modules for multiplication are designed by exploiting the presence of consecutive zeros in the coefficients of the blinding polynomial. The results are validated on a PYNQ-Z2 platform that includes a Zynq-7000 SoC from Xilinx and supports a Python-based programming environment. The optimized version that exploits the presence of double, triple, and quadruple consecutive zeros offers the best performance in timing, in addition to considerably reducing the possibility of an information leakage against an eventual attack on the device, making it practically negligible.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W3163324210",
    "type": "article"
  },
  {
    "title": "Built-in Self-Test and Fault Localization for Inter-Layer Vias in Monolithic 3D ICs",
    "doi": "https://doi.org/10.1145/3464430",
    "publication_date": "2021-11-03",
    "publication_year": 2021,
    "authors": "Arjun Chaudhuri; Sanmitra Banerjee; Jinwoo Kim; Heechun Park; Bon Woong Ku; Sukeshwar Kannan; Krishnendu Chakrabarty; Sung Kyu Lim",
    "corresponding_authors": "",
    "abstract": "Monolithic 3D (M3D) integration provides massive vertical integration through the use of nanoscale inter-layer vias (ILVs). However, high integration density and aggressive scaling of the inter-layer dielectric make ILVs especially prone to defects. We present a low-cost built-in self-test (BIST) method that requires only two test patterns to detect opens, stuck-at faults, and bridging faults (shorts) in ILVs. We also propose an extended BIST architecture for fault detection, called Dual-BIST, to guarantee zero ILV fault masking due to single BIST faults and negligible ILV fault masking due to multiple BIST faults. We analyze the impact of coupling between adjacent ILVs arranged in a 1D array in block-level partitioned designs. Based on this analysis, we present a novel test architecture called Shared-BIST with the added functionality of localizing single and multiple faults, including coupling-induced faults. We introduce a systematic clustering-based method for designing and integrating a delay bank with the Shared-BIST architecture for testing small-delay defects in ILVs with minimal yield loss. Simulation results for four two-tier M3D benchmark designs highlight the effectiveness of the proposed BIST framework.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W3210642049",
    "type": "article"
  },
  {
    "title": "Design Automation and Test Solutions for Monolithic 3D ICs",
    "doi": "https://doi.org/10.1145/3473462",
    "publication_date": "2021-11-16",
    "publication_year": 2021,
    "authors": "Lingjun Zhu; Arjun Chaudhuri; Sanmitra Banerjee; Gauthaman Murali; Pruek Vanna-Iampikul; Krishnendu Chakrabarty; Sung Kyu Lim",
    "corresponding_authors": "",
    "abstract": "Monolithic 3D (M3D) is an emerging heterogeneous integration technology that overcomes the limitations of the conventional through-silicon-via (TSV) and provides significant performance uplift and power reduction. However, the ultra-dense 3D interconnects impose significant challenges during physical design on how to best utilize them. Besides, the unique low-temperature fabrication process of M3D requires dedicated design-for-test mechanisms to verify the reliability of the chip. In this article, we provide an in-depth analysis on these design and test challenges in M3D. We also provide a comprehensive survey of the state-of-the-art solutions presented in the literature. This article encompasses all key steps on M3D physical design, including partitioning, placement, clock routing, and thermal analysis and optimization. In addition, we provide an in-depth analysis of various fault mechanisms, including M3D manufacturing defects, delay faults, and MIV (monolithic inter-tier via) faults. Our design-for-test solutions include test pattern generation for pre/post-bond testing, built-in-self-test, and test access architectures targeting M3D.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W3214428847",
    "type": "article"
  },
  {
    "title": "A thermal-driven test application scheme for pre-bond and post-bond scan testing of three-dimensional ICs",
    "doi": "https://doi.org/10.1145/2564922",
    "publication_date": "2014-02-01",
    "publication_year": 2014,
    "authors": "Dong Xiang; Kele Shen",
    "corresponding_authors": "",
    "abstract": "The three-dimensional (3-D) technology offers a new solution to the increasing density of integrated circuits (ICs). In this work, we propose novel scan architectures for 3-D IC pre-bond and post-bond testing by considering the interconnection overhead of through-silicon-vias (TSVs). Since hotspots in 3-D ICs often cause performance and reliability issues, we also develop different test ordering schemes for prebond and postbond testing to avoid applying test vectors that could worsen the temperature distribution. Experimental results show that the peak temperature can be lowered by 20% with the 3-D scan tree architecture. When combined with the test ordering scheme, the 3-D scan tree can further reduce peak temperature by over 30%.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2007254762",
    "type": "article"
  },
  {
    "title": "Ultra-low-leakage chip multiprocessor design with hybrid FinFET logic styles",
    "doi": "https://doi.org/10.1145/2629576",
    "publication_date": "2014-10-06",
    "publication_year": 2014,
    "authors": "Xianmin Chen; Niraj K. Jha",
    "corresponding_authors": "",
    "abstract": "FinFET has begun replacing CMOS at the 22nm technology node because of its enhanced ability to mitigate short-channel effects. Although leakage power of FinFET logic gates is lower than their CMOS counterparts, it still contributes to a large part of total power consumption. In this article, we show how ultra-low-leakage FinFET chip multiprocessors (CMPs) can be designed using a hybrid logic style. This hybrid style exploits the ultra-low-leakage feature of asymmetric-workfunction shorted-gate (ASG) FinFETs and the high-performance feature of shorted-gate (SG) FinFETs. We explore the impact of the hybrid style at both the module and CMP levels. To do this, we have developed FinFET logic libraries targeted at SG and ASG logic gates, suitably characterized for various parameters of interest. We have also modified existing tools and created a framework to evaluate the hybrid designs of SRAMs, caches, and CMPs. Using the design with SG FinFETs as the baseline for comparison, our experimental results show that the hybrid style can reduce leakage power of execution units to as low as 10.6% of the baseline without hurting performance, that of SRAMs to between 21.5% and 4.8% of the baseline with 0%-8.3% delay overhead, and that of CMPs to 10.0% of the baseline with negligible performance degradation.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2035567625",
    "type": "article"
  },
  {
    "title": "A Cross-Layer Approach for Early-Stage Power Grid Design and Optimization",
    "doi": "https://doi.org/10.1145/2700246",
    "publication_date": "2015-09-21",
    "publication_year": 2015,
    "authors": "Cheng Zhuo; Houle Gan; Wei-Kai Shih; Alaeddin Aydiner",
    "corresponding_authors": "",
    "abstract": "Power integrity has become increasingly important for sub-32nm designs. Many prior works have discussed power grid design and optimization in the post-layout stage, when design change is inevitably expensive and difficult. In contrast, during the early stage of a development cycle, designers have more flexibility to improve the design quality. However, there are several fundamental challenges at early stage when the design database is not complete, including extraction, modeling, and optimization. This article tackles these fundamental issues of early-stage power grid design from architecture to layout. The proposed methods have been silicon validated on 32nm on-market chips and successfully applied to a 22nm design for its early-stage power grid design. The findings from such practices reveal that, for sub-32nm chips, an intrinsic on-die capacitance and power gate scheme may have more significant impact than expected on power integrity, and needs to be well addressed at early stage.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2083582831",
    "type": "article"
  },
  {
    "title": "MRAM PUF",
    "doi": "https://doi.org/10.1145/2854154",
    "publication_date": "2016-05-06",
    "publication_year": 2016,
    "authors": "Jayita Das; Kevin Scott; Sanjukta Bhanja",
    "corresponding_authors": "",
    "abstract": "In this work, we have studied two novel techniques to enhance the performance of existing geometry-based magnetoresistive RAM physically unclonable function (MRAM PUF). Geometry-based MRAM PUFs rely only on geometric variations in MRAM cells that generate preferred ground state in cells and form the basis of digital signature generation. Here we study two novel ways to improve the performance of the geometry-based PUF signature. First, we study how the choice between specific geometries can enhance the reliability of the digital signature. Using fabrications and simulations, we study how the rectangular shape in the PUF cells is more susceptible to lithography-based geometric variations than the elliptical shape of the same aspect ratio. The choice of rectangular over elliptical masks in the lithography process can therefore improve the reliability of the digital signature from PUF. Second, we present a MRAM PUF architecture and study how resistances in MRAM cells can be used to generate analog voltage output that are easier to detect if probed by an adversary. In the new PUF architecture, we have the choice between selection of rows and columns to generate unique and hard-to-predict analog voltage outputs. For a 64-bit response, the analog voltage output can range between 20 and 500 mV, making it tough for an adversary to guess over this wide range of voltages. This work ends with a discussion on the threat resilience ability of the new improved MRAM PUF to attacks from probing-, tampering-, reuse-, and simulation-based models.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2346684951",
    "type": "article"
  },
  {
    "title": "System-Level Design to Detect Fault Injection Attacks on Embedded Real-Time Applications",
    "doi": "https://doi.org/10.1145/2967611",
    "publication_date": "2016-11-02",
    "publication_year": 2016,
    "authors": "Wei Jiang; Liang Wen; Ke Jiang; Xia Zhang; Xiong Pan; Keran Zhou",
    "corresponding_authors": "",
    "abstract": "Fault injection attack has been a serious threat to security-critical embedded systems for a long time, yet existing research ignores addressing of the problem from a system-level perspective. This article presents an approach to the synthesis of secure real-time applications mapped on distributed embedded systems, which focuses on preventing fault injection attacks of the security protection on processing units. We utilize symmetric cryptographic service to protect confidentiality and deploy fault detection within a confidential algorithm to resist fault injection attacks. Several fault detection schemes are identified, and their fault coverage rates and time overheads are derived and measured. Our synthesis approach makes efforts to determine the best fault detection schemes for the encryption/decryption of messages such that the overall security strength of detecting a fault injection attack is maximized and the deadline constraint of the real-time applications is guaranteed. Due to the complexity of the problem, we propose an efficient algorithm based on the fruit fly optimization algorithm, and we compare it to the simulated annealing approach. Extensive experiments and a real-life application evaluation demonstrate the superiority of our approach.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2548632561",
    "type": "article"
  },
  {
    "title": "Optimized Standard Cells for All-Spin Logic",
    "doi": "https://doi.org/10.1145/2967612",
    "publication_date": "2016-11-03",
    "publication_year": 2016,
    "authors": "Meghna G. Mankalale; Sachin S. Sapatnekar",
    "corresponding_authors": "",
    "abstract": "All-Spin Logic (ASL) devices provide a promising spintronics-based alternative for Boolean logic implementations in the post-Complementary Metal-Oxide Semiconductor (CMOS) era. In principle, any logic functionality can be implemented in ASL. In practice, the performance of an ASL gate is significantly affected by layout choices, but such implications have not been adequately explored in the past. This article proposes a systematic approach for building standard cells in ASL, which are a basic building block in an overall design methodology for implementing large ASL-based circuits. We first propose a new technique to reduce the magnet count for an ASL majority gate but still ensure correct functioning through layout optimization methods. Building on physics-based analysis, we then build a standard cell library with diverse functionality and characterize the library for delay, energy, and area. We perform delay-optimized technology mapping on ISCAS85 benchmark circuits using our library. Our approach results in circuits that are 12.90% faster, consume 26.16% less energy, and are 33.56% more area efficient compared to a standard cell library that does not incorporate layout-based optimization techniques of our work.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2548937856",
    "type": "article"
  },
  {
    "title": "Source Authentication Techniques for Network-on-Chip Router Configuration Packets",
    "doi": "https://doi.org/10.1145/2996194",
    "publication_date": "2016-11-16",
    "publication_year": 2016,
    "authors": "Arnab Kumar Biswas",
    "corresponding_authors": "Arnab Kumar Biswas",
    "abstract": "It is known that maliciously configured Network-on-Chip routers can enable an attacker to launch different attacks inside a Multiprocessor System-on-Chip. A source authentication mechanism for router configuration packets can prevent such vulnerability. This ensures that a router is configured by the configuration packets sent only by a trusted configuration source. Conventional method like Secure Hash Algorithm-3 (SHA-3) can provide required source authentication in a router but with a router area overhead of 1355.25% compared to a normal router area. We propose eight source authentication mechanisms that can achieve similar level of security as SHA-3 for a router configuration perspective without causing significant area and power increase. Moreover, the processing time of our proposed techniques is 1/100th of SHA-3 implementation. Most of our proposed techniques use different timing channel watermarking methods to transfer source authentication data to the receiver router. We also propose the Individual packet-based stream authentication technique and combinations of this technique with timing channel watermarking techniques. It is shown that, among all of our proposed techniques, maximum router area increment required is 28.32% compared to a normal router.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2550105984",
    "type": "article"
  },
  {
    "title": "Hardware-accelerated Simulation-based Inference of Stochastic Epidemiology Models for COVID-19",
    "doi": "https://doi.org/10.1145/3471188",
    "publication_date": "2022-01-12",
    "publication_year": 2022,
    "authors": "Sourabh Kulkarni; Mario Michael Krell; Seth Nabarro; Csaba Andras Moritz",
    "corresponding_authors": "",
    "abstract": "Epidemiology models are central to understanding and controlling large-scale pandemics. Several epidemiology models require simulation-based inference such as Approximate Bayesian Computation (ABC) to fit their parameters to observations. ABC inference is highly amenable to efficient hardware acceleration. In this work, we develop parallel ABC inference of a stochastic epidemiology model for COVID-19. The statistical inference framework is implemented and compared on Intel’s Xeon CPU, NVIDIA’s Tesla V100 GPU, Google’s V2 Tensor Processing Unit (TPU), and the Graphcore’s Mk1 Intelligence Processing Unit (IPU), and the results are discussed in the context of their computational architectures. Results show that TPUs are 3×, GPUs are 4×, and IPUs are 30× faster than Xeon CPUs. Extensive performance analysis indicates that the difference between IPU and GPU can be attributed to higher communication bandwidth, closeness of memory to compute, and higher compute power in the IPU. The proposed framework scales across 16 IPUs, with scaling overhead not exceeding 8% for the experiments performed. We present an example of our framework in practice, performing inference on the epidemiology model across three countries and giving a brief overview of the results.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W3115213131",
    "type": "article"
  },
  {
    "title": "STIFT: A Spatio-Temporal Integrated Folding Tree for Efficient Reductions in Flexible DNN Accelerators",
    "doi": "https://doi.org/10.1145/3531011",
    "publication_date": "2022-05-02",
    "publication_year": 2022,
    "authors": "Francisco Muñoz-Martínez; José Luis Abellán; Manuel E. Acacio; Tushar Krishna",
    "corresponding_authors": "",
    "abstract": "Increasing deployment of Deep Neural Networks (DNNs) recently fueled interest in the development of specific accelerator architectures capable of meeting their stringent performance and energy consumption requirements. DNN accelerators can be organized around three separate NoCs, namely distribution, multiplier, and reduction networks (or DN, MN, and RN, respectively) between the global buffer(s) and the compute units (multipliers/adders). Among them, the RN, used to generate and reduce the partial sums produced during DNN processing, is a first-order driver of the area and energy efficiency of the accelerator. RNs can be orchestrated to exploit a Temporal, Spatial or Spatio-Temporal reduction dataflow. Among these, Spatio-Temporal reduction is the one that has shown superior performance. However, as we demonstrate in this work, a state-of-the-art implementation of the Spatio-Temporal reduction dataflow, based on the addition of Accumulators (Ac) to the RN (i.e., RN+Ac strategy), can result into significant area and energy expenses. To cope with this important issue, we propose STIFT (that stands for Spatio-Temporal Integrated Folding Tree ) that implements the Spatio-Temporal reduction dataflow entirely on the RN hardware substrate (i.e., without the need for the extra accumulators). STIFT results into significant area and power savings regarding the more complex RN+Ac strategy, at the same time its performance advantage is preserved.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4225287131",
    "type": "article"
  },
  {
    "title": "A Deep Neural Network Accelerator using Residue Arithmetic in a Hybrid Optoelectronic System",
    "doi": "https://doi.org/10.1145/3550273",
    "publication_date": "2022-07-21",
    "publication_year": 2022,
    "authors": "Jiaxin Peng; Yousra Alkabani; Krunal Puri; Xiaoxuan Ma; Volker J. Sorger; Tarek El‐Ghazawi",
    "corresponding_authors": "",
    "abstract": "The acceleration of Deep Neural Networks (DNNs) has attracted much attention in research. Many critical real-time applications benefit from DNN accelerators but are limited by their compute-intensive nature. This work introduces an accelerator for Convolutional Neural Network (CNN) , based on a hybrid optoelectronic computing architecture and residue number system (RNS) . The RNS reduces the optical critical path and lowers the power requirements. In addition, the wavelength division multiplexing (WDM) allows high-speed operation at the system level by enabling high-level parallelism. The proposed RNS compute modules use one-hot encoding, and thus enable fast switching between the electrical and optical domains. We propose a new architecture that combines residue electrical adders and optical multipliers as the matrix-vector multiplication unit. Moreover, we enhance the implementation of different CNN computational kernels using WDM-enabled RNS based integrated photonics. The area and power efficiency of the proposed accelerator are 0.39 TOPS/s/mm 2 and 3.22 TOPS/s/W, respectively. In terms of computation capability, the proposed chip is 12.7× and 4.02× better than other optical implementation and memristor implementation, respectively. Our experimental evaluation using DNN benchmarks illustrates that our architecture can perform on average more than 72 times faster than GPU under the same power budget.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4286110990",
    "type": "article"
  },
  {
    "title": "Investigating the effects of fine-grain three-dimensional integration on microarchitecture design",
    "doi": "https://doi.org/10.1145/1412587.1412590",
    "publication_date": "2008-10-01",
    "publication_year": 2008,
    "authors": "Yuchun Ma; Yongxiang Liu; Eren Kursun; Glenn Reinman; Jason Cong",
    "corresponding_authors": "",
    "abstract": "In this article we propose techniques that enable efficient exploration of the 3D design space, where each logical block can span more than one silicon layer. Fine-grain 3D integration provides reduced intrablock wire delay as well as improved power consumption. However, the corresponding power and performance advantage is usually underutilized, since various implementations of multilayer blocks require novel physical design and microarchitecture infrastructure to explore 3D microarchitecture design space. We develop a cubic packing engine which can simultaneously optimize physical and architectural design for efficient vertical integration. This technique selects the individual unit designs from a set of single-layer or multilayer implementations to get the best microarchitectural design in terms of performance, temperature, or both. Our experimental results using a design driver of a high-performance superscalar processor show a 36% performance improvement over traditional 2D for 2--4 layers and 14% over 3D with single-layer unit implementations. Since thermal characteristics of 3D integrated circuits are among the main challenges, thermal-aware floorplanning and thermal via insertion techniques are employed to keep the peak temperatures below threshold.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W1989916619",
    "type": "article"
  },
  {
    "title": "Scaling self-timed systems powered by mechanical vibration energy harvesting",
    "doi": "https://doi.org/10.1145/1773814.1773816",
    "publication_date": "2008-06-18",
    "publication_year": 2008,
    "authors": "Justin Wenck; Jamie Collier; Jeff Siebert; Rajeevan Amirtharajah",
    "corresponding_authors": "",
    "abstract": "Passive energy harvesting from mechanical vibration has wide application in wearable devices and wireless sensors to complement or replace batteries. Energy harvesting efficiency can be increased by eliminating AC/DC conversion. A test chip demonstrating self-timing, power-on reset circuitry, and dynamic memory for energy harvesting AC voltages has been designed in 180 nm CMOS and tested. An energy scalable DSP architecture implements FIR filters that consume as little as 170 pJ per output sample. The on-chip DRAM retains data for up to 28 ms while register data is retained down to a supply voltage of 153 mV. Circuit operation is confirmed for supply frequencies between 60 Hz and 1 kHz with power consumption below 130 μW. Reaching the limits of miniaturization will require approaching the limits of power dissipation. We extrapolate from this DSP architecture to find the minimum volume required for mechanical vibration energy harvesting sensors.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2013818844",
    "type": "article"
  },
  {
    "title": "Routing in self-organizing nano-scale irregular networks",
    "doi": "https://doi.org/10.1145/1721650.1721653",
    "publication_date": "2008-03-16",
    "publication_year": 2008,
    "authors": "Yang Liu; Chris Dwyer; Alvin R. Lebeck",
    "corresponding_authors": "",
    "abstract": "The integration of novel nanotechnologies onto silicon platforms is likely to increase fabrication defects compared with traditional CMOS technologies. Furthermore, the number of nodes connected with these networks makes acquiring a global defect map impractical. As a result, on-chip networks will provide defect tolerance by self-organizing into irregular topologies. In this scenario, simple static routing algorithms based on regular physical topologies, such as meshes, will be inadequate. Additionally, previous routing approaches for irregular networks assume abundant resources and do not apply to this domain of resource-constrained self-organizing nano-scale networks. Consequently, routing algorithms that work in irregular networks with limited resources are needed. In this article, we explore routing for self-organizing nano-scale irregular networks in the context of a Self-Organizing SIMD Architecture (SOSA). Our approach trades configuration time and a small amount of storage for reduced communication latency. We augment an Euler path-based routing technique for trees to generate static shortest paths between certain pairs of nodes while remaining deadlock free. Simulations of several applications executing on SOSA show our proposed routing algorithm can reduce execution time by 8% to 30%.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W1977489325",
    "type": "article"
  },
  {
    "title": "A meshless, spectrally accurate, integral equation solver for molecular surface electrostatics",
    "doi": "https://doi.org/10.1145/1350763.1350766",
    "publication_date": "2008-04-01",
    "publication_year": 2008,
    "authors": "Shih-Hsien Kuo; Bruce Tidor; Jacob White",
    "corresponding_authors": "",
    "abstract": "The need to determine electrostatic fields in domains bounded by molecular surfaces arises in a number of nanotechnology applications including: biomolecule design, carbon nanotube simulation, and molecular electron transport analysis. Molecular surfaces are typically smooth, without the corners common in electrical interconnect problems, but are often so geometrically complicated that numerical evaluation of the associated electrostatic fields is extremely time-consuming. In this paper we describe and demonstrate a meshless spectrally-accurate integral equation method that only requires a description of the molecular surface in the form of a collection of surface points. Our meshless method is a synthesis of techniques, suitably adapted, including: spherical harmonic surface interpolation, spectral-element-like integral equation discretization, integral desingularization via variable transformation, and matrix-implicit iterative matrix solution. The spectral accuracy of this combined method is verified using analytically solvable sphere and ellipsoid problems, and then its accuracy and efficiency is demonstrated numerically by solving capacitance and coupled Poisson/linearized Poisson-Boltzmann problems associated with a commonly used model of a molecule in solution. The results demonstrate that for a tolerance of 10 −3 this new approach reduces the number of unknowns by as much as two orders of magnitude over the more commonly used flat panel methods.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2011264863",
    "type": "article"
  },
  {
    "title": "A hybrid nano-CMOS architecture for defect and fault tolerance",
    "doi": "https://doi.org/10.1145/1568485.1568488",
    "publication_date": "2009-08-01",
    "publication_year": 2009,
    "authors": "Muzaffer O. Simsir; Srihari Cadambi; Franjo Ivančić; Martin Roetteler; Niraj K. Jha",
    "corresponding_authors": "",
    "abstract": "As the end of the semiconductor roadmap for CMOS approaches, architectures based on nanoscale molecular devices are attracting attention. Among several alternatives, silicon nanowires and carbon nanotubes are the two most promising nanotechnologies according to the ITRS. These technologies may enable scaling deep into the nanometer regime. However, they suffer from very defect-prone manufacturing processes. Although the reconfigurability property of the nanoscale devices can be used to tolerate high defect rates, it may not be possible to locate all defects. With very high device densities, testing each component may not be possible because of time or technology restrictions. This points to a scenario in which even though the devices are tested, the tests are not very comprehensive at locating defects, and hence the shipped chips are still defective. Moreover, the devices in the nanometer range will be susceptible to transient faults which can produce arbitrary soft errors. Despite these drawbacks, it is possible to make nanoscale architectures practical and realistic by introducing defect and fault tolerance. In this article, we propose and evaluate a hybrid nanowire-CMOS architecture that addresses all three problems—namely high defect rates, unlocated defects, and transient faults—at the same time. This goal is achieved by using multiple levels of redundancy and majority voters. A key aspect of the architecture is that it contains a judicious balance of both nanoscale and traditional CMOS components. A companion to the architecture is a compiler with heuristics to quickly determine if logic can be mapped onto partially defective nanoscale elements. The heuristics make it possible to introduce defect-awareness in placement and routing. The architecture and compiler are evaluated by applying the complete design flow to several benchmarks.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2083519410",
    "type": "article"
  },
  {
    "title": "Enhancing data center sustainability through energy-adaptive computing",
    "doi": "https://doi.org/10.1145/2367736.2367744",
    "publication_date": "2012-10-01",
    "publication_year": 2012,
    "authors": "Krishna Kant; Muthukumar Murugan; David Hung-Chang Du",
    "corresponding_authors": "",
    "abstract": "The sustainability concerns of Information Technology (IT) go well beyond energy-efficient computing and require techniques for minimizing environmental impact of IT infrastructure over its entire life-cycle. Traditionally, IT infrastructure is overdesigned at all levels from chips to entire data centers and ecosystem; the paradigm explored in this article is to replace overdesign with rightsizing coupled with smarter control, henceforth referred to as Energy-Adaptive Computing or EAC. The article lays out the challenges of EAC in various environments in terms of the adaptation of the workload and the infrastructure to cope with energy and cooling deficiencies. The article then focuses on implementing EAC in a data center environment, and addresses the problem of simultaneous energy demand and energy supply regulation at multiple levels, work, from servers to the entire data center. The proposed control scheme adapts the assignments of tasks to servers in a way that can cope with the varying energy limitations. The article also presents some experimental results to show how the scheme can continue to meet Quality of Service (QoS) requirements of tasks under energy limitations.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W1986141617",
    "type": "article"
  },
  {
    "title": "Nonvolatile Memories as the Data Storage System for Implantable ECG Recorder",
    "doi": "https://doi.org/10.1145/2180878.2180885",
    "publication_date": "2012-06-01",
    "publication_year": 2012,
    "authors": "Zhenyu Sun; Xiang Chen; Yaojun Zhang; Hai Li; Yiran Chen",
    "corresponding_authors": "",
    "abstract": "In this article, we propose a data storage system with the emerging nonvolatile memory technologies used for the implantable electrocardiography (ECG) recorder. The proposed storage system can record the digitalized real-time ECG waveforms continuously inside the implantable device and export the stored data to external reader periodically to obtain a long-term backup. Spin transfer torque random access memory (STT-RAM) and spintronic memristor are selected as the storage elements for their nonvolatility, high density, high reliability, low power consumption, good scalability, and CMOS technology compatibility. The new read and write schemes of STT-RAM and spintronic memristors are presented and optimized to fit the specific application scenario. The tradeoffs among data accuracy, chip area, and read/write energy for the different technologies are thoroughly analyzed and compared. Our simulation results show the configuration with a data sampling rate (e.g., 128 Hz) and a quantization resolution (e.g., 12 bits) can record 18-hour real-time data within ~ 3.6-mm 2 chip area when the data storage is built with single-level cell (SLC) STT-RAMs. Daily energy consumption is 5.46 mJ. Utilizing the multilevel cell (MLC) STT-RAMs or the spintronic memristors as the storage elements can further reduce the chip area and decrease energy dissipation.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2062532328",
    "type": "article"
  },
  {
    "title": "Congestion-aware layout design for high-throughput digital microfluidic biochips",
    "doi": "https://doi.org/10.1145/2287696.2287700",
    "publication_date": "2012-08-01",
    "publication_year": 2012,
    "authors": "Sudip Roy; Debasis Mitra; Bhargab B. Bhattacharya; Krishnendu Chakrabarty",
    "corresponding_authors": "",
    "abstract": "Potential applications of digital microfluidic (DMF) biochips now include several areas of real-life applications like environmental monitoring, water and air pollutant detection, and food processing to name a few. In order to achieve sufficiently high throughput for these applications, several instances of the same bioassay may be required to be executed concurrently on different samples. As a straightforward implementation, several identical biochips can be integrated on a single substrate as a multichip to execute the assay for various samples concurrently. Controlling individual electrodes of such a chip by independent pins may not be acceptable since it increases the cost of fabrication. Thus, in order to keep the overall pin-count within an acceptable bound, all the respective electrodes of these individual pieces are connected internally underneath the chip so that they can be controlled with a single external control pin. In this article, we present an orientation strategy for layout of a multichip that reduces routing congestion and consequently facilitates wire routing for the electrode array. The electrode structure of the individual pieces of the multichip may be either direct-addressable or pin-constrained. The method also supports a hierarchical approach to wire routing that ensures scalability. In this scheme, the size of the biochip in terms of the total number of electrodes may be increased by a factor of four by increasing the number of routing layers by only one. In general, for a multichip with 4 n identical blocks, ( n + 1) layers are sufficient for wire routing.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2070364061",
    "type": "article"
  },
  {
    "title": "Automated Quantum Circuit Synthesis and Cost Estimation for the Binary Welded Tree Oracle",
    "doi": "https://doi.org/10.1145/3060582",
    "publication_date": "2017-06-29",
    "publication_year": 2017,
    "authors": "Mrityunjay Ghosh; Amlan Chakrabarti; Niraj K. Jha",
    "corresponding_authors": "",
    "abstract": "Quantum computing is a new computational paradigm that promises an exponential speed-up over classical algorithms. To develop efficient quantum algorithms for problems of a non-deterministic nature, random walk is one of the most successful concepts employed. In this article, we target both continuous-time and discrete-time random walk in both the classical and quantum regimes. Binary Welded Tree (BWT), or glued tree, is one of the most well-known quantum walk algorithms in the continuous-time domain. Prior work implements quantum walk on the BWT with static welding. In this context, static welding is randomized but case-specific. We propose a solution to automatically generate the circuit for the Oracle for welding. We implement the circuit using the Quantum Assembly Language, which is a language for describing quantum circuits. We then optimize the generated circuit using the Fault-Tolerant Quantum Logic Synthesis tool for any BWT instance. Automatic welding enables us to provide a generalized solution for quantum walk on the BWT.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2724719514",
    "type": "article"
  },
  {
    "title": "Offline Optimization of Wavelength Allocation and Laser Power in Nanophotonic Interconnects",
    "doi": "https://doi.org/10.1145/3178453",
    "publication_date": "2018-04-30",
    "publication_year": 2018,
    "authors": "Jiating Luo; Cédric Killian; Sébastien Le Beux; Daniel Chillet; Olivier Sentieys; Ian O’Connor",
    "corresponding_authors": "",
    "abstract": "Optical Network-on-Chip (ONoC) is a promising communication medium for large-scale multiprocessor systems-on-chips. Indeed, ONoC can outperform classical electrical NoCs in terms of energy efficiency and bandwidth density, in particular, because this medium can support multiple transactions at the same time on different wavelengths by using Wavelength Division Multiplexing (WDM). However, multiple signals sharing simultaneously the same part of a waveguide can lead to inter-channel crosstalk noise. This problem impacts the signal-to-noise ratio of the optical signals, which leads to an increase in the Bit Error Rate (BER) at the receiver side. If a specific BER is targeted, an increase of laser power should be necessary to satisfy the SNR. In this context, an important issue is to evaluate the laser power needed to satisfy the various desired communication bandwidths based on the BER performance requirements. In this article, we propose an off-line approach that concurrently optimizes the laser power scaling and execution time of a global application. A set of different levels of power is introduced for each laser, to ensure that optical signals can be emitted with just-enough power to ensure targeted BER. As a result, most promising solutions are highlighted for mapping a defined application onto a 16-core ring-based WDM ONoC.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2850573751",
    "type": "article"
  },
  {
    "title": "A Resource-Efficient Embedded Iris Recognition System Using Fully Convolutional Networks",
    "doi": "https://doi.org/10.1145/3357796",
    "publication_date": "2019-10-15",
    "publication_year": 2019,
    "authors": "Hokchhay Tann; Heng Zhao; Sherief Reda",
    "corresponding_authors": "",
    "abstract": "Applications of fully convolutional networks (FCN) in iris segmentation have shown promising advances. For mobile and embedded systems, a significant challenge is that the proposed FCN architectures are extremely computationally demanding. In this article, we propose a resource-efficient, end-to-end iris recognition flow, which consists of FCN-based segmentation and a contour fitting module, followed by Daugman normalization and encoding. To attain accurate and efficient FCN models, we propose a three-step SW/HW co-design methodology consisting of FCN architectural exploration, precision quantization, and hardware acceleration. In our exploration, we propose multiple FCN models, and in comparison to previous works, our best-performing model requires 50× fewer floating-point operations per inference while achieving a new state-of-the-art segmentation accuracy. Next, we select the most efficient set of models and further reduce their computational complexity through weights and activations quantization using an 8-bit dynamic fixed-point format. Each model is then incorporated into an end-to-end flow for true recognition performance evaluation. A few of our end-to-end pipelines outperform the previous state of the art on two datasets evaluated. Finally, we propose a novel dynamic fixed-point accelerator and fully demonstrate the SW/HW co-design realization of our flow on an embedded FPGA platform. In comparison with the embedded CPU, our hardware acceleration achieves up to 8.3× speedup for the overall pipeline while using less than 15% of the available FPGA resources. We also provide comparisons between the FPGA system and an embedded GPU showing different benefits and drawbacks for the two platforms.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2980390765",
    "type": "article"
  },
  {
    "title": "A High-performance Homogeneous Droplet Routing Technique for MEDA-based Biochips",
    "doi": "https://doi.org/10.1145/3327965",
    "publication_date": "2019-10-25",
    "publication_year": 2019,
    "authors": "Pampa Howladar; Pranab Roy; Hafizur Rahaman",
    "corresponding_authors": "",
    "abstract": "Recent advancement of microelectrode-dot-array (MEDA)-based architecture for digital microfluidic biochips has enabled a major enhancement in microfluidic operations for traditional lab-on-chip devices. One critical issue for MEDA-based biochips is the transportation of droplets. MEDA allows dynamic routing for droplets of different size. In this article, we propose a high-performance droplet routing technique for MEDA-based digital microfluidic biochips. First, we propose the basic concept of droplet movement strategy in MEDA-based design together with a definition of strictly shielded zones within the layout in MEDA architecture. Next, we propose transportation schemes of droplets for MEDA architecture under different blockage or crossover conditions and estimate route distances for each net in offline. Finally, a priority-based routing strategy combining various transportation schemes stated earlier has been proposed. Concurrent movement of each droplet is scheduled in a time-multiplexed manner. This poses critical challenges for parallel routing of individual droplets with optimal sharing of cells formulating a routing problem with higher complexity. The final compaction solution satisfies the timing constraint and improves fault tolerance. Simulations are carried out on standard benchmark circuits, namely, Benchmark suite I and Benchmark suite III. Experimental results show satisfactory improvements and prove a high degree of robustness for our proposed algorithm.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2981531353",
    "type": "article"
  },
  {
    "title": "ASIE",
    "doi": "https://doi.org/10.1145/3404992",
    "publication_date": "2020-08-18",
    "publication_year": 2020,
    "authors": "Ziyang Kang; Lei Wang; Shasha Guo; Rui Gong; Shiming Li; Yu Deng; Weixia Xu",
    "corresponding_authors": "",
    "abstract": "Neuromorphic computing based on spiking neural network (SNN) shows good energy-efficiency. However, it is inefficient for SNN to perform the convolution based on frame. It may contain a lot of redundant information in the frame. The output of Dynamic Vision Sensors (DVS) is a stream event based on Address Event Representation (AER). The asynchronous nature of AER events makes the event-based convolution reflect the characteristics of SNN low energy consumption. This article presents an SNN hardware inference engine based on an asynchronous Processing Element (PE) array with AER events as input. The engine uses a convolution algorithm based on AER events. This design also uses distributed storage in the PE array to store the state of neurons to reduce the cost of memory access. The experimental results show that the design can achieve a recognition accuracy of 98.0% for the MNIST AER dataset. The design can perform the reference process more efficiently in the case where the accuracy of the loss is negligible. During the filling and draining processes of the systolic array, the number of active PE units in our PE array is reduced and, thus, the average power consumption per PE unit is drastically decreased.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W3080073499",
    "type": "article"
  },
  {
    "title": "Semi-Trained Memristive Crossbar Computing Engine with <i>In Situ</i> Learning Accelerator",
    "doi": "https://doi.org/10.1145/3233987",
    "publication_date": "2018-10-31",
    "publication_year": 2018,
    "authors": "Abdullah M. Zyarah; Dhireesha Kudithipudi",
    "corresponding_authors": "",
    "abstract": "On-device intelligence is gaining significant attention recently as it offers local data processing and low power consumption. In this research, an on-device training circuitry for threshold-current memristors integrated in a crossbar structure is proposed. Furthermore, alternate approaches of mapping the synaptic weights into fully trained and semi-trained crossbars are investigated. In a semi-trained crossbar, a confined subset of memristors are tuned and the remaining subset of memristors are not programmed. This translates to optimal resource utilization and power consumption, compared to a fully programmed crossbar. The semi-trained crossbar architecture is applicable to a broad class of neural networks. System level verification is performed with an extreme learning machine for binomial and multinomial classification. The total power for a single 4 × 4 layer network, when implemented in IBM 65nm node, is estimated to be ≈42.16μW and the area is estimated to be 26.48μm × 22.35μm.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W3123782736",
    "type": "article"
  },
  {
    "title": "Design and Evaluation of Technology-Agnostic Heterogeneous Networks-on-Chip",
    "doi": "https://doi.org/10.1145/2567666",
    "publication_date": "2014-04-01",
    "publication_year": 2014,
    "authors": "Haera Chung; Christof Teuscher; Partha Pratim Pande",
    "corresponding_authors": "",
    "abstract": "Traditional metal-wire-based networks-on-chip (NoC) suffer from high latency and power dissipation as the system size scales up in the number of cores. This limitation stems from the inherent multihop communication nature of larger NoCs. It has previously been shown that the performance of NoCs can be significantly improved by introducing long-range, low power, and high-bandwidth single-hop links between distant cores. While previous work has focused on specific NoC architectures and configurations, it remains an open question whether heterogeneous link types are beneficial in a broad range of NoC architectures. In this article, we show that a generic NoC architecture with heterogeneous link types allows for NoCs with higher bandwidth at a lower cost compared to homogeneous networks. We further show that such NoCs scale up significantly better in terms of performance and cost. We demonstrate these broadly-applicable results by using a technology-agnostic complex network approach that targets NoC architectures with various emerging link types.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2001068051",
    "type": "article"
  },
  {
    "title": "Delay-based processing-in-wire for design of QCA serial decimal arithmetic units",
    "doi": "https://doi.org/10.1145/2564927",
    "publication_date": "2014-02-01",
    "publication_year": 2014,
    "authors": "Michael Gladshtein",
    "corresponding_authors": "Michael Gladshtein",
    "abstract": "Quantum-dot cellular automata (QCA) technology is now considered to be one of the prospective technologies for a nanocomputer creation. The physical properties of QCA and its expanding range of computer applications make it expedient to use the novel paradigm of nanocomputer architecture: serial decimal storage-transfer-processing. The delay-based encoding of decimal digits allows the use a delay element as a main element of QCA serial arithmetic units. The simple implementation of the delay element by a short length of QCA wire results in reduction of complexity and of the area required for a QCA circuit. The theoretical basics of delay-based processing-in-wire and design examples of QCA serial decimal arithmetic units are presented.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2090208034",
    "type": "article"
  },
  {
    "title": "Multilayer Graphene Nanoribbon and Carbon Nanotube Based Floating Gate Transistor for Nonvolatile Flash Memory",
    "doi": "https://doi.org/10.1145/2701428",
    "publication_date": "2015-08-03",
    "publication_year": 2015,
    "authors": "Nahid M. Hossain; Masud H. Chowdhury",
    "corresponding_authors": "",
    "abstract": "Floating gate transistor is the fundamental building block of nonvolatile flash memory, which is one of the most widely used memory gadgets in modern micro and nano electronic applications. Recently there has been a surge of interest to introduce a new generation of memory devices using graphene nanotechnology. In this article, we present a new floating gate transistor (FGT) design based on multilayer graphene nanoribbon (MLGNR) and carbon nanotube (CNT). In the proposed FGT, a MLGNR structure would be used as the channel of the field effect transistor (FET) and a layer of CNTs would be used as the floating gate. We have performed an analysis of the programming and erasing mechanism in the floating gate and its dependence on the applied control gate voltages. Based on our analysis we have observed that proposed graphene based floating gate transistor could be operated at a low voltage compared to conventional silicon based floating gate devices. We have presented detail analysis of the operation and the programming and erasing processes of the proposed FGT; the dependency of the programming and erasing current density on different parameters; and the impact of scaling the thicknesses of the control and tunneling oxides. To perform these analyses we have developed equivalent models for device capacitances.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2216893582",
    "type": "article"
  },
  {
    "title": "Fully Exploiting PCM Write Capacity Within Near Zero Cost Through Segment-Based Page Allocation",
    "doi": "https://doi.org/10.1145/2856423",
    "publication_date": "2016-05-12",
    "publication_year": 2016,
    "authors": "Hoda Aghaei Khouzani; Yuan Xue; Chengmo Yang",
    "corresponding_authors": "",
    "abstract": "Improving the endurance of phase change memory (PCM) is a fundamental issue when PCM technology is considered as an alternative to main memory usage. Existing wear-leveling techniques overcome this challenge through constantly remapping hot virtual pages, thus engendering a fair amount of extra write operations to PCM and imposing considerable performance and energy overhead. Our observation is that it is unnecessary to fully balance the accesses to different physical page frames during the execution of each process. Instead, since endurance is a lifetime factor, the hot virtual pages of different processes can be mapped to different physical pages in the PCM. Leveraging this property, we develop a wear-resistant page allocation algorithm, which exploits the diverse write characteristics of different program segments to improve PCM write endurance within almost no extra remapping cost in terms of energy and performance. The results of experiments conducted based on SPEC benchmarks show that the proposed technique can prolong PCM lifetime by hundreds of times within nearly zero searching and remapping overhead.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2372352392",
    "type": "article"
  },
  {
    "title": "A simulator for ballistic nanostructures in a 2-D electron gas",
    "doi": "https://doi.org/10.1145/1482613.1482618",
    "publication_date": "2009-01-01",
    "publication_year": 2009,
    "authors": "Dennis Huo; Qiaoyan Yu; David H. Wolpert; Paul Ampadu",
    "corresponding_authors": "",
    "abstract": "A multipurpose simulator for ballistic nanostructures, based on classical mechanics of electrons at the Fermi level, has been successfully implemented. Despite the simplicity of the model, the simulator successfully reproduces a number of experimental results, and is shown to consistently match observed current-voltage characteristics and magnetoresistance phenomena. The simulator results provide design guidelines for devices which operate on ballistic transport principles. Using the simulator, preliminary logic structures have been designed based on the ballistic deflection transistor.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2079213780",
    "type": "article"
  },
  {
    "title": "Dynamic Behavior Predictions for Fast and Efficient Hybrid STT-MRAM Caches",
    "doi": "https://doi.org/10.1145/3423135",
    "publication_date": "2021-01-06",
    "publication_year": 2021,
    "authors": "Nour Sayed; Longfei Mao; Mehdi B. Tahoori",
    "corresponding_authors": "",
    "abstract": "Spin Transfer Torque Magnetic Random Access Memory (STT-MRAM) is a promising candidate as a universal on-chip memory technology due to its non-volatility, high density, and scalability. However, high write energy and latency are its major shortcomings, particularly for fast cache applications. High write costs can efficiently be reduced by relaxing the STT-MRAM non-volatility requirements at the expense of significant increase in retention failure and read disturb rates resulting in data corruption. Hybrid STT-MRAM architecture combining non-volatile (NVM) and semi-volatile (SVM) STT-MRAM blocks has been proposed recently, which provides energy-efficiency, high storage capacity, better performance, and high reliability. However, a key and challenging requirement is efficient data mapping and migration between NVM and SVM sub-arrays to maximize the benefits of such hybrid caches. On-the-fly data migration decisions usually depend on the last seen data behavior, as it is assumed to be identical to the next one, which has very limited accuracy for rapidly varying workload behavior. In this article, we propose a simple but effective on-the-fly data management policy, which mainly relies on the supervised learning data-pattern classification for quick and highly accurate prediction of the data behavior in the oncoming execution time. Three prediction approaches are proposed and compared for a maximum and average achieved accuracy of 86% and 75%, respectively. Our data management policies aim to optimally leverage the specific features of NVM (high reliability) and SVM blocks (fast and energy-efficient write) of hybrid STT-MRAM memory with minimal migration costs (i.e., energy and performance overheads). Our experimental evaluation reports that for a hybrid STT-MRAM cache with the proposed prediction techniques, the total energy consumption can be reduced around 10.5%, on average, in comparison to the state-of-the-art.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W3120797592",
    "type": "article"
  },
  {
    "title": "Attack Mitigation of Hardware Trojans for Thermal Sensing via Micro-ring Resonator in Optical NoCs",
    "doi": "https://doi.org/10.1145/3433676",
    "publication_date": "2021-06-30",
    "publication_year": 2021,
    "authors": "Jun Zhou; Mengquan Li; Pengxing Guo; Weichen Liu",
    "corresponding_authors": "",
    "abstract": "As an emerging role in new-generation on-chip communication, optical networks-on-chip (ONoCs) provide ultra-high bandwidth, low latency, and low power dissipation for data transfers. However, the thermo-optic effects of the photonic devices have a great impact on the operating performance and reliability of ONoCs, where the thermal-aware control with accurate measurements, e.g., thermal sensing, is typically applied to alleviate it. Besides, the temperature-sensitive ONoCs are prone to be attacked by the hardware Trojans (HTs) covertly embedded in the counterfeit integrated circuits (ICs) from the malicious third-party vendors, leading to performance degradation, denial-of-service (DoS), or even permanent damages. In this article, we focus on the tampering and snooping attacks during the thermal sensing via micro-ring resonator (MR) in ONoCs. Based on the provided workflow and attack model, a new structure of the anti-HT module is proposed to verify and protect the obtained data from the thermal sensor for attacks in its optical sampling and electronic transmission processes. In addition, we present the detection scheme based on the spiking neural networks (SNNs) to implement an accurate classification of the network security statuses for further high-level control. Evaluation results indicate that, with less than 1% extra area of a tile, our approach can significantly enhance the hardware security of thermal sensing for ONoC with trivial costs of up to 8.73%, 5.32%, and 6.14% in average latency, execution time, and energy consumption, respectively.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W3173593825",
    "type": "article"
  },
  {
    "title": "Graphene-Based Artificial Synapses with Tunable Plasticity",
    "doi": "https://doi.org/10.1145/3447778",
    "publication_date": "2021-06-30",
    "publication_year": 2021,
    "authors": "He Wang; Nicoleta Cucu Laurenciu; Yande Jiang; Sorin Cotöfană",
    "corresponding_authors": "",
    "abstract": "Design and implementation of artificial neuromorphic systems able to provide brain akin computation and/or bio-compatible interfacing ability are crucial for understanding the human brain’s complex functionality and unleashing brain-inspired computation’s full potential. To this end, the realization of energy-efficient, low-area, and bio-compatible artificial synapses, which sustain the signal transmission between neurons, is of particular interest for any large-scale neuromorphic system. Graphene is a prime candidate material with excellent electronic properties, atomic dimensions, and low-energy envelope perspectives, which was already proven effective for logic gates implementations. Furthermore, distinct from any other materials used in current artificial synapse implementations, graphene is biocompatible, which offers perspectives for neural interfaces. In view of this, we investigate the feasibility of graphene-based synapses to emulate various synaptic plasticity behaviors and look into their potential area and energy consumption for large-scale implementations. In this article, we propose a generic graphene-based synapse structure, which can emulate the fundamental synaptic functionalities, i.e., Spike-Timing-Dependent Plasticity (STDP) and Long-Term Plasticity . Additionally, the graphene synapse is programable by means of back-gate bias voltage and can exhibit both excitatory or inhibitory behavior. We investigate its capability to obtain different potentiation/depression time scale for STDP with identical synaptic weight change amplitude when the input spike duration varies. Our simulation results, for various synaptic plasticities, indicate that a maximum 30% synaptic weight change and potentiation/depression time scale range from [-1.5 ms, 1.1 ms to [-32.2 ms, 24.1 ms] are achievable. We further explore the effect of our proposal at the Spiking Neural Network (SNN) level by performing NEST-based simulations of a small SNN implemented with 5 leaky-integrate-and-fire neurons connected via graphene-based synapses. Our experiments indicate that the number of SNN firing events exhibits a strong connection with the synaptic plasticity type, and monotonously varies with respect to the input spike frequency. Moreover, for graphene-based Hebbian STDP and spike duration of 20ms we obtain an SNN behavior relatively similar with the one provided by the same SNN with biological STDP. The proposed graphene-based synapse requires a small area (max. 30 nm 2 ), operates at low voltage (200 mV), and can emulate various plasticity types, which makes it an outstanding candidate for implementing large-scale brain-inspired computation systems.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W3174711190",
    "type": "article"
  },
  {
    "title": "SILVerIn: Systematic Integrity Verification of Printed Circuit Board Using JTAG Infrastructure",
    "doi": "https://doi.org/10.1145/3460232",
    "publication_date": "2021-06-30",
    "publication_year": 2021,
    "authors": "Shubhra Deb Paul; Swarup Bhunia",
    "corresponding_authors": "",
    "abstract": "A printed circuit board (PCB) provides necessary mechanical support to an electronic system and acts as a platform for connecting electronic components. Counterfeiting and in-field tampering of PCBs have become significant security concerns in the semiconductor industry as a result of increasing untrusted entities in the supply chain. These counterfeit components may result in performance degradation, profit reduction, and reputation risk for the manufacturers. While Integrated Circuit (IC) level authentication using physical unclonable functions (PUFs) has been widely investigated, countermeasures at the PCB level are scarce. These approaches either suffer from significant overhead issues, or opportunistic counterfeiters can breach them like clockwork. Besides, they cannot be extended to system-level (both chip and PCB together), and their applications are also limited to a specific purpose (i.e., either counterfeiting or tampering). In this article, we introduce SILVerIn , a novel systematic approach to verify the authenticity of all chips used in a PCB as well as the board for combating attacks such as counterfeiting, cloning, and in-field malicious modifications. We develop this approach by utilizing the existing boundary scan architecture (BSA) of modern ICs and PCBs. As a result, its implementation comes at a negligible (∼0.5%) hardware overhead. SILVerIn is integrated into a PCB design during the manufacturing phase. We implement our technique on a custom hardware platform consisting of an FPGA and a microcontroller. We incorporate the industry-standard JTAG (Joint Test Action Group) interface to transmit test data into the BSA and perform hands-on measurement of supply current at both chip and PCB levels on 20 boards. We reconstruct these current values to digital signatures that exhibit high uniqueness, robustness, and randomness features. Our approach manifests strong reproducibility of signatures at different supply voltage levels, even with a low-resolution measurement setup. SILVerIn also demonstrates a high resilience against machine learning-based modeling attacks, with an average prediction accuracy of ∼51%. Finally, we conduct intentional alteration experiments by replacing the on-board FPGA to replicate the scenario of PCB tampering, and the results indicate successful detection of in-field modifications in a PCB.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W3177391734",
    "type": "article"
  },
  {
    "title": "Compressing RNNs to Kilobyte Budget for IoT Devices Using Kronecker Products",
    "doi": "https://doi.org/10.1145/3440016",
    "publication_date": "2021-07-14",
    "publication_year": 2021,
    "authors": "Urmish Thakker; Igor Fedorov; Chu Zhou; Dibakar Gope; Matthew Mattina; Ganesh Dasika; Jesse Beu",
    "corresponding_authors": "",
    "abstract": "Micro-controllers (MCUs) make up most of the processors in the world with widespread applicability from automobile to medical devices. The Internet of Things promises to enable these resource-constrained MCUs with machine learning algorithms to provide always-on intelligence. Many Internet of Things applications consume time-series data that are naturally suitable for recurrent neural networks (RNNs) like LSTMs and GRUs. However, RNNs can be large and difficult to deploy on these devices, as they have few kilobytes of memory. As a result, there is a need for compression techniques that can significantly compress RNNs without negatively impacting task accuracy. This article introduces a method to compress RNNs for resource-constrained environments using the Kronecker product (KP). KPs can compress RNN layers by 16× to 38× with minimal accuracy loss. By quantizing the resulting models to 8 bits, we further push the compression factor to 50×. We compare KP with other state-of-the-art compression techniques across seven benchmarks spanning five different applications and show that KP can beat the task accuracy achieved by other techniques by a large margin while simultaneously improving the inference runtime. Sometimes the KP compression mechanism can introduce an accuracy loss. We develop a hybrid KP approach to mitigate this. Our hybrid KP algorithm provides fine-grained control over the compression ratio, enabling us to regain accuracy lost during compression by adding a small number of model parameters.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W3180864037",
    "type": "article"
  },
  {
    "title": "Thermal Characterization of Test Techniques for FinFET and 3D Integrated Circuits",
    "doi": "https://doi.org/10.1145/2422094.2422100",
    "publication_date": "2013-02-01",
    "publication_year": 2013,
    "authors": "Aoxiang Tang; Niraj K. Jha",
    "corresponding_authors": "",
    "abstract": "Power consumption has become a very important consideration during integrated circuit (IC) design and test. During test, it can far exceed the values reached during normal operation and, thus, lead to temperatures above the allowed threshold. Without appropriate temperature reduction, permanent damage may be caused to the IC or invalid test results may be obtained. FinFET is a double-gate field-effect transistor (DG-FET) that was introduced commercially in 2012. Due to the vertical nature of FinFETs and, hence, weaker ability to dissipate heat, this problem is likely to get worse for FinFET circuits. Another technology rapidly gaining popularity is 3D IC integration. Unfortunately, the compact nature of a multidie 3D IC is likely to aggravate the temperature-during-test problem even further. Hence, before temperature-aware test methodologies can be developed, it is important to thermally analyze both FinFET and 3D circuits under test. In this article, we present a methodology for thermal characterization of various test techniques, such as scan and built-in self-test (BIST), for FinFET and 3D ICs. FinFET thermal characterization makes use of a FinFET standard cell library that is characterized with the help of the University of Florida double-gate (UFDG) SPICE model. Thermal profiles for circuits under test are produced by ISAC2 from University of Colorado for FinFET circuits and HotSpot from University of Virginia for 3D ICs. Experimental results indicate that high temperatures result under BIST and much less often under scan, and that both power consumption and test application time should be reduced to lower the temperature of circuits under test, just reducing the power consumption is not enough.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W1996776201",
    "type": "article"
  },
  {
    "title": "Matrix Nanodevice-Based Logic Architectures and Associated Functional Mapping Method",
    "doi": "https://doi.org/10.1145/1899390.1899393",
    "publication_date": "2011-01-01",
    "publication_year": 2011,
    "authors": "P.-E. Gaillardon; F. Clermidy; Ian O’Connor; J. Liu; Maïmouna Amadou; Gabriela Nicolescu",
    "corresponding_authors": "",
    "abstract": "This article describes a novel computing architecture organization based on nanoscale logic cells. We propose the use of a cluster of matrix arrangements of cells. In order to interconnect such fine-grained logic cells within a matrix, conventional techniques are not suitable due to a large interconnect overhead. Therefore, we propose the use of static and incomplete interconnect topologies to create matrices of cells. We also propose a method to map functions onto such architectures. We then explore the main parameters of the structure (size of matrices and interconnect topologies) and their impact on the main performance metrics (packing efficiency, speed, and fault tolerance). A cluster packing method also allows the evaluation of the number of matrices used by complex functions and the fill factor for various matrix sizes. The analyses show that this approach is particularly suited for matrices of 16 cells interconnected by modified omega networks. We can conclude that this architecture could improve the scalability of traditional FPGAs by a factor of 8.5.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2049306625",
    "type": "article"
  },
  {
    "title": "Energy-efficient markov chain-based duty cycling schemes for greener wireless sensor networks",
    "doi": "https://doi.org/10.1145/2367736.2367740",
    "publication_date": "2012-10-01",
    "publication_year": 2012,
    "authors": "Giacomo Ghidini; Sajal K. Das",
    "corresponding_authors": "",
    "abstract": "To extend the lifetime of a wireless sensor network, sensor nodes usually duty cycle between dormant and active states. Duty cycling schemes are often evaluated in terms of connection delay, connection duration, and duty cycle. In this article, we show with experiments on Sun SPOT sensors that duty cycling time (energy) efficiency, that is, the ratio of time (energy) employed in ancillary operations when switching from and into deep sleep mode, is an important performance metric too. We propose a novel randomized duty cycling scheme based on Markov chains with the goal of (i) reducing the connection delay, while maintaining a given time (energy) efficiency, or (ii) keeping a constant connection delay, while increasing the time (energy) efficiency. Analytical and experimental results demonstrate that the Markov chain-based scheme can improve the performance in terms of connection delay without affecting the time efficiency, or vice versa, as opposed to the trade-off observed in traditional schemes. We extend the proposed duty cycling scheme to a partially randomized scheme, where wireless nodes can switch into active state beyond their schedules when their neighbors are active to anticipate message forwarding. The analytical and experimental results confirm the relationship between connection delay and time efficiency also for this scheme.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2065662561",
    "type": "article"
  },
  {
    "title": "Dual pillar spin-transfer torque MRAMs for low power applications",
    "doi": "https://doi.org/10.1145/2463585.2463590",
    "publication_date": "2013-05-01",
    "publication_year": 2013,
    "authors": "Niladri Narayan Mojumder; Xuanyao Fong; Charles Augustine; Sumeet Kumar Gupta; Sri Harsha Choday; Kaushik Roy",
    "corresponding_authors": "",
    "abstract": "Electron-spin based data storage for on-chip memories has the potential for ultra-high density, low power consumption, very high endurance, and reasonably low read/write latency. In this article, we discuss the design challenges associated with spin-transfer torque (STT) MRAM in its state-of-the-art configuration. We propose an alternative bit cell configuration and three new genres of magnetic tunnel junction (MTJ) structures to improve STT-MRAM bit cell stabilities, write endurance, and reduce write energy consumption. The proposed multi-port, multi-pillar MTJ structures offer the unique possibility of electrical and spatial isolation of memory read and write. In order to realize ultralow power under process variations, we propose device, bit-cell and architecture level design techniques. Such design alternatives at multiple levels of design abstraction has been found to achieve substantially enhanced robustness, density, reliability and low power as compared to their charge-based counterparts for future embedded applications.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2072813874",
    "type": "article"
  },
  {
    "title": "Dynamic clock stretching for variation compensation in VLSI circuit design",
    "doi": "https://doi.org/10.1145/2287696.2287699",
    "publication_date": "2012-08-01",
    "publication_year": 2012,
    "authors": "V. Mahalingam; N. Ranganathan; Ransford Hyman",
    "corresponding_authors": "",
    "abstract": "In the nanometer era, process, voltage, and temperature variations are dominating circuit performance, power, and yield. Over the past few years, statistical optimization methods have been effective in improving yield in the presence of uncertainty due to process variations. However, statistical methods overconsume resources, even in the absence of variations. Hence, to facilitate a better performance-power-yield trade-off, techniques that can dynamically enable variation compensation are becoming necessary. In this article, we propose a dynamic technique that controls the instance of data capture in critical path memory flops, by delaying the clock edge trigger. The methodology employs a dynamic delay detection circuit to identify the uncertainty in delay due to variations and stretches the clock in the destination flip-flops. The delay detection circuit uses a latch and set of combinational gates to dynamically detect and create the slack needed to accommodate the delay due to variations. The Clock Stretching Logic (CSL) is added only to paths, which have a high probability of failure in the presence of variations. The proposed methodology improves the timing yield of the circuit without significant overcompensation. The methodology approach was simulated using Synopsys design tools for circuit synthesis and Cadence tools for placement and routing of the design. Extraction of parasitic of timing information was parsed using Perl scripts and simulated using a simulation program generated in C++. Experimental results based on Monte-Carlo simulations on benchmark circuits indicate considerable improvement in timing yield with negligible area overhead.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2076126326",
    "type": "article"
  },
  {
    "title": "Memory-Centric Reconfigurable Accelerator for Classification and Machine Learning Applications",
    "doi": "https://doi.org/10.1145/2997649",
    "publication_date": "2017-05-01",
    "publication_year": 2017,
    "authors": "Robert Karam; Somnath Paul; Ruchir Puri; Swarup Bhunia",
    "corresponding_authors": "",
    "abstract": "Big Data refers to the growing challenge of turning massive, often unstructured datasets into meaningful, organized, and actionable data. As datasets grow from petabytes to exabytes and beyond, it becomes increasingly difficult to run advanced analytics, especially Machine Learning (ML) applications, in a reasonable time and on a practical power budget using traditional architectures. Previous work has focused on accelerating analytics readily implemented as SQL queries on data-parallel platforms, generally using off-the-shelf CPUs and General Purpose Graphics Processing Units (GPGPUs) for computation or acceleration. However, these systems are general-purpose and still require a vast amount of data transfer between the storage devices and computing elements, thus limiting the system efficiency. As an alternative, this article presents a reconfigurable memory-centric advanced analytics accelerator that operates at the last level of memory and dramatically reduces energy required for data transfer. We functionally validate the framework using an FPGA-based hardware emulation platform and three representative applications: Naïve Bayesian Classification, Convolutional Neural Networks, and k-Means Clustering. Results are compared with implementations on a modern CPU and workstation GPGPU. Finally, the use of in-memory dataset decompression to further reduce data transfer volume is investigated. With these techniques, the system achieves an average energy efficiency improvement of 74× and 212× over GPU and single-threaded CPU, respectively, while dataset compression is shown to improve overall efficiency by an additional 1.8× on average.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2611951231",
    "type": "article"
  },
  {
    "title": "Nanoarray architectures multilevel simulation",
    "doi": "https://doi.org/10.1145/2541882",
    "publication_date": "2014-01-01",
    "publication_year": 2014,
    "authors": "Stefano Frache; Mariagrazia Graziano; Maurizio Zamboni",
    "corresponding_authors": "",
    "abstract": "Density and regularity are deemed as the major advantages of nanoarray architectures based on nanowires. Literature demonstrated that proper reliability analyzes must be performed and solutions have to be devised to improve nanoarrays yield. Their complexity and high-fault probability claim for specific design automation tools able to explore circuit solutions, performance and fault-tolerant approaches. We envision a simulator conceived to carry on characterizations in terms of logic behavior, defect-induced output error rate assessment, switching activity, power and timing performance. Though already existing for traditional technology, a simulator based on specific technological and topological tiled nanoarray descriptions, and conceived to join both device and architecture levels, has never been attempted at the degree of accuracy we present. Our contribution is twofold. First, marking a difference with respect to the state of the art, we developed an algorithm based on an event-driven engine which works at switch level and is not simply built on top of cost functions evaluations. The straightforward advantage is the possibility to follow the evolution of dynamic control sequences throughout all the inner components of the nanoarray, and, as a consequence, to obtain circuit level characterization as a projection of the real internal parameters. Second, we added to our simulator the capability to inject faults with specific statistical distributions associated to the nanoarray topology. Here we extract output error rates and yield for one of the possible nanoarray structures proposed in literature, the NASIC. Results specificity and accuracy demonstrate the simulator trustworthiness, its effectiveness for extensive nanoarrays characterization and its suitability as a foundation for both higher architectural and lower device simulation levels. The aim of this work, then, is to provide insights into the intertwined relation between actual technology and circuit design for these emerging fabrics, and, as a consequence, to clarify how defects and variability affect circuits and systems performance.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W1985630668",
    "type": "article"
  },
  {
    "title": "NBTI tolerance and leakage reduction using gate sizing",
    "doi": "https://doi.org/10.1145/2629657",
    "publication_date": "2014-10-06",
    "publication_year": 2014,
    "authors": "Ing-Chao Lin; Shun-Ming Syu; Tsung-Yi Ho",
    "corresponding_authors": "",
    "abstract": "Leakage power is a major design constraint in deep submicron technology and below. Meanwhile, transistor degradation due to Negative Bias Temperature Instability (NBTI) has emerged as one of the main reliability concerns in nanoscale technology. Gate sizing is a widely used technique to reduce circuit leakage, and this approach has recently attracted much attention with regard to improving circuits to tolerate NBTI. However, these studies only consider timing and area constraints, and many other important issues, such as slew and max-load, are missing. In this article, we present an efficient gate sizing framework that can reduce leakage and improve circuit reliability under timing constraints. Our algorithms consider slack, slew and max-load constraints. The benchmarks are those from ISPD 2012, which feature industrial design properties, including discrete cell sizes, nonconvex cell timing models, slew dependencies and constraints, as well as large design sizes. The experimental results obtained from ISPD 2012 benchmark circuits demonstrate that our approach can meet all the constraints and tolerated NBTI degradation with a power savings of 6.54% as compared with the traditional method.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2045475919",
    "type": "article"
  },
  {
    "title": "Dynamic Cache Pooling in 3D Multicore Processors",
    "doi": "https://doi.org/10.1145/2700247",
    "publication_date": "2015-09-02",
    "publication_year": 2015,
    "authors": "Tiansheng Zhang; Jie Meng; Ayse K. Coskun",
    "corresponding_authors": "",
    "abstract": "Resource pooling, where multiple architectural components are shared among cores, is a promising technique for improving system energy efficiency and reducing total chip area. 3D stacked multicore processors enable efficient pooling of cache resources owing to the short interconnect latency between vertically stacked layers. This article first introduces a 3D multicore architecture that provides poolable cache resources. We then propose a runtime management policy to improve energy efficiency in 3D systems by utilizing the flexible heterogeneity of cache resources. Our policy dynamically allocates jobs to cores on the 3D system while partitioning cache resources based on cache hungriness of the jobs. We investigate the impact of the proposed cache resource pooling architecture and management policy in 3D systems, both with and without on-chip DRAM. We evaluate the performance, energy efficiency, and thermal behavior for a wide range of workloads running on 3D systems. Experimental results demonstrate that the proposed architecture and policy reduce system energy-delay product (EDP) and energy-delay-area product (EDAP) by 18.8% and 36.1% on average, respectively, in comparison to 3D processors with static cache sizes.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2212524031",
    "type": "article"
  },
  {
    "title": "Frontside Versus Backside Laser Injection",
    "doi": "https://doi.org/10.1145/2845999",
    "publication_date": "2016-11-30",
    "publication_year": 2016,
    "authors": "Stephan De Castro; Jean-Max Dutertre; Bruno Rouzeyre; Giorgio Di Natale; Marie-Lise Flottes",
    "corresponding_authors": "",
    "abstract": "The development of cryptographic devices was followed by the development of so-called implementation attacks, which are intended to retrieve secret information exploiting the hardware itself. Among these attacks, fault attacks can be used to disturb the circuit while performing a computation to retrieve the secret. Among possible means of injecting a fault, laser beams have proven to be accurate and powerful. The laser can be used to illuminate the circuit either from its frontside (i.e., where metal interconnections are first encountered) or from the backside (i.e., through the substrate). Historically, frontside injection was preferred because it does not require the die to be thinned. Nevertheless, due to the increasing integration of metal layers in modern technologies, frontside injections do not allow targeting of any desired location. Indeed, metal lines act as mirrors, and they reflect and refract most of the energy provided by the laser beam. Conversely, backside injections, although more difficult to set up, allow an increase of the resolution of the target location and remove the drawbacks of the frontside technique. This article compares experimental results from frontside and backside fault injections. The effectiveness of the two techniques is measured in terms of exploitable errors on an AES circuit (i.e., errors that can be used to extract the value of the secret key used during the encryption process). We will show, conversely to what is generally assumed, that frontside injection can provide even better results compared to backside injection, especially for low-cost beams with a large laser spot.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2557581627",
    "type": "article"
  },
  {
    "title": "A Simplified Phase Model for Simulation of Oscillator-Based Computing Systems",
    "doi": "https://doi.org/10.1145/2976743",
    "publication_date": "2016-12-01",
    "publication_year": 2016,
    "authors": "Yan Fang; Victor V. Yashin; Brandon Jennings; Donald M. Chiarulli; Steven P. Levitan",
    "corresponding_authors": "",
    "abstract": "Building oscillator-based computing systems with emerging nano-device technologies has become a promising solution for unconventional computing tasks like computer vision and pattern recognition. However, simulation and analysis of these computing systems is both time and compute intensive due to the nonlinearity of new devices and the complex behavior of coupled oscillators. In order to speed up the simulation of coupled oscillator systems, we propose a simplified phase model to perform phase and frequency synchronization prediction based on a synthesis of earlier models. Our model can predict the frequency-locking behavior with several orders of magnitude speedup compared to direct evaluation, enabling the effective and efficient simulation of the large numbers of oscillators required for practical computing systems. We demonstrate the oscillator-based computing paradigm with three applications, pattern matching, convolution, and image segmentation. The simulation with these models are respectively sped up by factors of 780, 300, and 1120 in our tests.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2558381285",
    "type": "article"
  },
  {
    "title": "Accelerating On-Chip Training with Ferroelectric-Based Hybrid Precision Synapse",
    "doi": "https://doi.org/10.1145/3473461",
    "publication_date": "2022-01-12",
    "publication_year": 2022,
    "authors": "Yandong Luo; Panni Wang; Shimeng Yu",
    "corresponding_authors": "",
    "abstract": "In this article, we propose a hardware accelerator design using ferroelectric transistor (FeFET)-based hybrid precision synapse (HPS) for deep neural network (DNN) on-chip training. The drain erase scheme for FeFET programming is incorporated for both FeFET HPS design and FeFET buffer design. By using drain erase, high-density FeFET buffers can be integrated onchip to store the intermediate input-output activations and gradients, which reduces the energy consuming off-chip DRAM access. Architectural evaluation results show that the energy efficiency could be improved by 1.2× ∼ 2.1×, 3.9× ∼ 6.0× compared to the other HPS-based designs and emerging non-volatile memory baselines, respectively. The chip area is reduced by 19% ∼ 36% compared with designs using SRAM on-chip buffer even though the capacity of FeFET buffer is increased. Besides, by utilizing drain erase scheme for FeFET programming, the chip area is reduced by 11% ∼ 28.5% compared with the designs using body erase scheme.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4205667545",
    "type": "article"
  },
  {
    "title": "A Novel Highly-Efficient Inexact Full Adder Cell for Motion and Edge Detection Systems of Image Processing in CNFET Technology",
    "doi": "https://doi.org/10.1145/3524061",
    "publication_date": "2022-03-30",
    "publication_year": 2022,
    "authors": "Yavar Safaei Mehrabani; Samaneh Goldani Gigasari; Mohammad Mirzaei; Hamidreza Uoosefian",
    "corresponding_authors": "",
    "abstract": "In this paper, a novel and highly efficient inexact Full Adder cell by exploiting two logic styles including conventional CMOS (C-COMS) and pass transistor logic (PTL) are presented. The so-called carbon nanotube field-effect transistor (CNFET) technology is used to implement circuits at the transistor level. To justify the efficiency of our design, extensive simulations are performed at the transistor level as well as application level. Transistor-level simulations which are carried out by the HSPICE 2008 tool, demonstrate at least 12% higher performance in terms of power-delay-area product (PDAP) of the proposed circuit compared to the latest designs. At the application level, by using the MATLAB tool, inexact Full Adders are employed in the structure of the ripple carry adder (RCA) that is applied in motion and edge detection algorithms. Computer simulation results confirm the appropriate quality of the output images in terms of the peak signal-to-noise ratio (PSNR) and structural similarity (SSIM) criteria. At last, to make a compromise between hardware and application level parameters, the power-delay-area-1/PSNR product (PDAPP) and power-delay-area-1/SSIM product (PDASP) are considered as figures of merit. The proposed circuit shows remarkable improvement from the PDAPP and PDASP points of view compared to its counterparts.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4221069911",
    "type": "article"
  },
  {
    "title": "Toward the Generation of Test Vectors for the Detection of Hardware Trojan Targeting Effective Switching Activity",
    "doi": "https://doi.org/10.1145/3597497",
    "publication_date": "2023-05-19",
    "publication_year": 2023,
    "authors": "Anindan Mondal; Debasish Kalita; Archisman Ghosh; Suchismita Roy; Bibhash Sen",
    "corresponding_authors": "",
    "abstract": "Hardware Trojans (HTs) are small circuits intentionally designed by an adversary for harmful purposes. These types of circuits are extremely difficult to detect. An HT often requires some specific signals to activate, which are almost impossible to discover. For this reason, test generation for side-channel analysis has gained significant attention in recent times and does not require HT activation. Such test generation techniques aim to generate a large amount of switching activity inside the HT circuit, increasing transient current measurement. However, such methods suffer from either long runtime or reliable results. In this work, a test generation technique is proposed based on the relative switching activity of the circuit to overcome the limitations of the existing works. Initially, the proposed technique measures the impact of each input on rare nets individually using random vector simulation. Potent inputs are selected to obtain a new set of test vectors that provide high relative switching inside a circuit. The proposed method is applied on 11 different ISCAS and 3 ITC 99 benchmark circuits. Experimental results endorse the efficacy of the proposed method outperforming traditional Hamming distance-based re-ordering techniques (up to 20×) while requiring a small runtime.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4377099130",
    "type": "article"
  },
  {
    "title": "A Fast Object Detection-Based Framework for Via Modeling on PCB X-Ray CT Images",
    "doi": "https://doi.org/10.1145/3606948",
    "publication_date": "2023-07-03",
    "publication_year": 2023,
    "authors": "David S. Koblah; Ulbert J. Botero; Sean Costello; Olivia P. Dizon-Paradis; Fatemeh Ganji; Damon L. Woodard; Domenic Forte",
    "corresponding_authors": "",
    "abstract": "For successful printed circuit board (PCB) reverse engineering (RE), the resulting device must retain the physical characteristics and functionality of the original. Although the applications of RE are within the discretion of the executing party, establishing a viable, non-destructive framework for analysis is vital for any stakeholder in the PCB industry. A widely regarded approach in PCB RE uses non-destructive x-ray computed tomography (CT) to produce three-dimensional volumes with several slices of data corresponding to multi-layered PCBs. However, the noise sources specific to x-ray CT and variability from designers hampers the thorough acquisition of features necessary for successful RE. This article investigates a deep learning approach as a successor to the current state-of-the-art for detecting vias on PCB x-ray CT images; vias are a key building block of PCB designs. During RE, vias offer an understanding of the PCB’s electrical connections across multiple layers. Our method is an improvement on an earlier iteration which demonstrates significantly faster runtime with quality of results comparable to or better than the current state-of-the-art, unsupervised iterative Hough-based method. Compared with the Hough-based method, the current framework is 4.5 times faster for the discrete image scenario and 24.1 times faster for the volumetric image scenario. The upgrades to the prior deep learning version include faster feature-based detection for real-world usability and adaptive post-processing methods to improve the quality of detections.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4382987254",
    "type": "article"
  },
  {
    "title": "FinFET-based power simulator for interconnection networks",
    "doi": "https://doi.org/10.1145/1721650.1721652",
    "publication_date": "2008-03-16",
    "publication_year": 2008,
    "authors": "Chun‐Yi Lee; Niraj K. Jha",
    "corresponding_authors": "",
    "abstract": "Double-gate FETs, specifically FinFETs, are emerging as promising substitutes for bulk CMOS at the 32nm technology node and beyond because of the various obstacles to scaling faced by CMOS, such as short-channel effects, leakage power, and process variations. Another trend in chip multiprocessor design is incorporation of sophisticated on-chip interconnection networks. However, such networks are significant power-consumers. In this article, we address these two trends by presenting a power simulator for FinFET-based on-chip interconnection networks. It estimates both dynamic and leakage power. We present results for various FinFET design styles and temperatures (since leakage power changes drastically with temperature), and show that one FinFET design style may be much superior to another from the power consumption point of view.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W1982462354",
    "type": "article"
  },
  {
    "title": "Design space exploration and data memory architecture design for a hybrid nano/CMOS dynamically reconfigurable architecture",
    "doi": "https://doi.org/10.1145/1629091.1629093",
    "publication_date": "2009-11-01",
    "publication_year": 2009,
    "authors": "Wei Zhang; Niraj K. Jha; Li Shang",
    "corresponding_authors": "",
    "abstract": "In recent years, research on nanotechnology has advanced rapidly. Novel nanodevices have been developed, such as those based on carbon nanotubes, nanowires, etc. Using these emerging nanodevices, diverse nanoarchitectures have been proposed. Among them, hybrid nano/CMOS reconfigurable architectures have attracted attention because of their advantages in performance, integration density, and fault tolerance. Recently, a high-performance hybrid nano/CMOS reconfigurable architecture, called NATURE, was presented. NATURE comprises CMOS reconfigurable logic and interconnect fabric, and CMOS-fabrication-compatible nanomemory. High-density, fast nano RAMs are distributed in NATURE as on-chip storage to store multiple reconfiguration copies for each reconfigurable element. It enables cycle-by-cycle runtime reconfiguration and a highly efficient computational model, called temporal logic folding. Through logic folding, NATURE provides more than an order of magnitude improvement in logic density and area-delay product, and significant design flexibility in performing area-delay trade-offs, at the same technology node. Moreover, NATURE can be fabricated using mainstream photolithography fabrication techniques. Hence, it offers a currently commercially viable reconfigurable architecture with high performance, superior logic density, and outstanding design flexibility, which is very attractive for deployment in cost-conscious embedded systems. In order to fully explore the potential of NATURE and further improve its performance, in this article, a thorough design space exploration is conducted to optimize its architecture. Investigations in terms of different logic element architectures, interconnect designs, and various technologies for nano RAMs are presented. Nano RAMs can not only be used as storage for configuration bits, but the high density of nano RAMs also makes them excellent candidates for large-capacity on-chip data storage in NATURE. Many logic- and memory-intensive applications, such as video and image processing, require large storage of temporal results. To enhance the capability of NATURE for implementing such applications, we investigate the design of nano data memory structures in NATURE and explore the impact of memory density. Experimental results demonstrate significant throughput improvements due to area saving from logic folding and parallel data processing.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2073262215",
    "type": "article"
  },
  {
    "title": "High parallelism, portability, and broad accessibility",
    "doi": "https://doi.org/10.1145/1330521.1330524",
    "publication_date": "2008-03-01",
    "publication_year": 2008,
    "authors": "Carlotta Guiducci; Christine Nardini",
    "corresponding_authors": "",
    "abstract": "Biotechnology is an area of great innovations that promises to have deep impact on everyday life thanks to profound changes in biology, medicine, and health care. This article will span from the description of the biochemical principles of molecular biology to the definition of the physics that supports the technology and to the devices and algorithms necessary to observe molecular events in a controlled, portable, and highly parallel manner. Throughout this discussion, constant attention will be given to the ultimate goals and applications of these innovations as well as to the related issues.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2083574252",
    "type": "article"
  },
  {
    "title": "Sparse Hardware Embedding of Spiking Neuron Systems for Community Detection",
    "doi": "https://doi.org/10.1145/3223048",
    "publication_date": "2018-10-31",
    "publication_year": 2018,
    "authors": "Kathleen E. Hamilton; Neena Imam; Travis S. Humble",
    "corresponding_authors": "",
    "abstract": "We study the applicability of spiking neural networks and neuromorphic hardware for solving general opti- mization problems without the use of adaptive training or learning algorithms. We leverage the dynamics of Hopfield networks and spin-glass systems to construct a fully connected spiking neural system to generate synchronous spike responses indicative of the underlying community structure in an undirected, unweighted graph. Mapping this fully connected system to current generation neuromorphic hardware is done by embedding sparse tree graphs to generate only the leading-order spiking dynamics. We demonstrate that for a chosen set of benchmark graphs, the spike responses generated on a current generation neuromorphic processor can improve the stability of graph partitions and non-overlapping communities can be identified even with the loss of higher-order spiking behavior if the graphs are sufficiently dense. For sparse graphs, the loss of higher-order spiking behavior improves the stability of certain graph partitions but does not retrieve the known community memberships.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2903251073",
    "type": "article"
  },
  {
    "title": "Image Complexity Guided Network Compression for Biomedical Image Segmentation",
    "doi": "https://doi.org/10.1145/3471190",
    "publication_date": "2021-12-31",
    "publication_year": 2021,
    "authors": "Suraj Mishra; Danny Z. Chen; Xiaobo Sharon Hu",
    "corresponding_authors": "",
    "abstract": "Compression is a standard procedure for making convolutional neural networks (CNNs) adhere to some specific computing resource constraints. However, searching for a compressed architecture typically involves a series of time-consuming training/validation experiments to determine a good compromise between network size and performance accuracy. To address this, we propose an image complexity-guided network compression technique for biomedical image segmentation. Given any resource constraints, our framework utilizes data complexity and network architecture to quickly estimate a compressed model which does not require network training. Specifically, we map the dataset complexity to the target network accuracy degradation caused by compression. Such mapping enables us to predict the final accuracy for different network sizes, based on the computed dataset complexity. Thus, one may choose a solution that meets both the network size and segmentation accuracy requirements. Finally, the mapping is used to determine the convolutional layer-wise multiplicative factor for generating a compressed network. We conduct experiments using 5 datasets, employing 3 commonly-used CNN architectures for biomedical image segmentation as representative networks. Our proposed framework is shown to be effective for generating compressed segmentation networks, retaining up to ≈95% of the full-sized network segmentation accuracy, and at the same time, utilizing ≈32x fewer network trainable weights (average reduction) of the full-sized networks.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2907239407",
    "type": "article"
  },
  {
    "title": "Split Manufacturing-Based Register Transfer-Level Obfuscation",
    "doi": "https://doi.org/10.1145/3289156",
    "publication_date": "2019-01-30",
    "publication_year": 2019,
    "authors": "Xiaotong Cui; Jeff Zhang; Kaijie Wu; Siddharth Garg; Ramesh Karri",
    "corresponding_authors": "",
    "abstract": "Fabrication-less integrated circuit (IC) design houses outsource fabrication to third-party foundries to reduce cost of manufacturing. The outsourcing of IC fabrication, beyond our expectation, raises concerns regarding intellectual property (IP) piracy and theft by rogue elements in the third-party foundries. Obfuscation techniques have been proposed to increase resistance to reverse engineering, IP recovery, IP theft, and piracy. However, prior work on obfuscation for IP protection has primarily applied to the gate level or the layout level. As a result, it can significantly impact the performance of the original design in addition to requiring redesign of standard cells. In this article, we propose a high-level synthesis and analysis (HLSA)-based obfuscation approach for IP protection. The proposed method is based on split manufacturing. Additional dummy units and MUXes can be added to further obfuscate the design. The proposed technique aligns with the standard-cell-based design methodologies and does not significantly impact the performance of the original design. Our experimental results confirm that the proposed approach can provide high levels of IC obfuscation with moderate area cost.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2912546287",
    "type": "article"
  },
  {
    "title": "Hardware-Software Co-design to Accelerate Neural Network Applications",
    "doi": "https://doi.org/10.1145/3304086",
    "publication_date": "2019-04-30",
    "publication_year": 2019,
    "authors": "Mohsen Imani; Ricardo Garcı́a; Saransh Gupta; Tajana Rosing",
    "corresponding_authors": "",
    "abstract": "Many applications, such as machine learning and data sensing, are statistical in nature and can tolerate some level of inaccuracy in their computation. A variety of designs have been put forward exploiting the statistical nature of machine learning through approximate computing. With approximate multipliers being the main focus due to their high usage in machine-learning designs. In this article, we propose a novel approximate floating point multiplier, called CMUL, which significantly reduces energy and improves performance of multiplication while allowing for a controllable amount of error. Our design approximately models multiplication by replacing the most costly step of the operation with a lower energy alternative. To tune the level of approximation, CMUL dynamically identifies the inputs that produces the largest approximation error and processes them in precise mode. To use CMUL for deep neural network (DNN) acceleration, we propose a framework that modifies the trained DNN model to make it suitable for approximate hardware. Our framework adjusts the DNN weights to a set of “ potential weights ” that are suitable for approximate hardware. Then, it compensates the possible quality loss by iteratively retraining the network. Our evaluation with four DNN applications shows that, CMUL can achieve 60.3% energy efficiency improvement and 3.2× energy-delay product (EDP) improvement as compared to the baseline GPU, while ensuring less than 0.2% quality loss. These results are 38.7% and 2.0× higher than energy efficiency and EDP improvement of the CMUL without using the proposed framework.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2948678916",
    "type": "article"
  },
  {
    "title": "MV-Net",
    "doi": "https://doi.org/10.1145/3358696",
    "publication_date": "2019-10-03",
    "publication_year": 2019,
    "authors": "Yibin Tang; Ying Wang; Huawei Li; Xiaowei Li",
    "corresponding_authors": "",
    "abstract": "Recently the development of deep learning has been propelling the sheer growth of vision and speech applications on lightweight embedded and mobile systems. However, the limitation of computation resource and power delivery capability in embedded platforms is recognized as a significant bottleneck that prevents the systems from providing real-time deep learning ability, since the inference of deep convolutional neural networks (CNNs) and recurrent neural networks (RNNs) involves large quantities of weights and operations. Particularly, how to provide quality-of-services (QoS)-guaranteed neural network inference ability in the multitask execution environment of multicore SoCs is even more complicated due to the existence of resource contention. In this article, we present a novel deep neural network architecture, MV-Net, which provides performance elasticity and contention-aware self-scheduling ability for QoS enhancement in mobile computing systems. When the constraints of QoS, output accuracy, and resource contention status of the system change, MV-Net can dynamically reconfigure the corresponding neural network propagation paths and thus achieves an effective tradeoff between neural network computational complexity and prediction accuracy via approximate computing. The experimental results show that (1) MV-Net significantly improves the performance flexibility of current CNN models and makes it possible to provide always-guaranteed QoS in a multitask environment, and (2) it satisfies the quality-of-results (QoR) requirement, outperforming the baseline implementation significantly, and improves the system energy efficiency at the same time.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2978122539",
    "type": "article"
  },
  {
    "title": "A Global Routing Method for Graphene Nanoribbons Based Circuits and Interconnects",
    "doi": "https://doi.org/10.1145/3384214",
    "publication_date": "2020-05-22",
    "publication_year": 2020,
    "authors": "Subrata Das; Debesh K. Das; Soumya Pandit",
    "corresponding_authors": "",
    "abstract": "With extreme miniaturization of traditional CMOS devices in deep sub-micron design levels, the delay of a circuit, as well as power dissipation and area are dominated by interconnections between logic blocks. Interconnect today is causing major problems such as delay, power dissipation, and so on. In an attempt to search for alternative materials, Graphene nanoribbons have been found to be potential for both transistors and interconnects due to its outstanding electrical and thermal properties. Graphene nanoribbons provide better options as materials used for global routing trees in VLSI circuits. However, certain special characteristics of Graphene nanoribbon prohibit direct application of existing VLSI routing tree construction methods. In this article, we address this issue and propose heuristic methods for construction of Graphene nanoribbon--based minimum hybrid cost and minimum-delay Steiner trees. We compute the delays for the trees using Elmore delay approximation. Experimental results demonstrate the effectiveness of our proposed methods, which are quite encouraging.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W3028698806",
    "type": "article"
  },
  {
    "title": "Hardware Security in Spin-based Computing-in-memory",
    "doi": "https://doi.org/10.1145/3397513",
    "publication_date": "2020-07-07",
    "publication_year": 2020,
    "authors": "Xueyan Wang; Jianlei Yang; Yinglin Zhao; Xiaotao Jia; Gang Qu; Weisheng Zhao",
    "corresponding_authors": "",
    "abstract": "Computing-in-memory (CIM) is proposed to alleviate the processor-memory data transfer bottleneck in traditional von Neumann architectures, and spintronics-based magnetic memory has demonstrated many facilitation in implementing CIM paradigm. Since hardware security has become one of the major concerns in circuit designs, this article, for the first time, investigates spin-based computing-in-memory (SpinCIM) from a security perspective. We focus on two fundamental questions: (1) How can the new SpinCIM computing paradigm be exploited to enhance hardware security?; (2) What security concerns has this new SpinCIM computing paradigm incurred?",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W3041660983",
    "type": "article"
  },
  {
    "title": "Making a Case for Partially Connected 3D NoC",
    "doi": "https://doi.org/10.1145/3394919",
    "publication_date": "2020-07-07",
    "publication_year": 2020,
    "authors": "Aqeeb Iqbal Arka; Srinivasan Gopal; Janardhan Rao Doppa; Deukhyoun Heo; Partha Pratim Pande",
    "corresponding_authors": "",
    "abstract": "3D Network-on-Chip (3D NoC) enables design of high-performance and energy-efficient manycore computing platforms. Two of the commonly used vertical interconnection technologies are: through silicon via (TSV) and near-field inductive coupling (NFIC). Both TSV- and NFIC-based links introduce additional area overhead. One of the possible ways to reduce the area overhead is to design partially connected 3D NoC with minimal effect on overall performance. The achievable performance of the partially connected 3D NoCs depends on the area, energy, and bandwidth of the vertical links. Moreover, the electromigration-induced failure of TSV is more severe than the misalignment-induced error in NFIC. By considering all these pertinent factors, we demonstrate that it is indeed possible to design a partially connected NFIC-based 3D NoC that performs as good as a fully connected TSV-based counterpart when the data rate is below a certain limit. For higher data rates, the partially connected TSV-based 3D NoC is a viable solution. However, NFIC-based 3D NoC is always more robust than the TSV-based counterpart.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W3080207448",
    "type": "article"
  },
  {
    "title": "GPUOPT",
    "doi": "https://doi.org/10.1145/3416850",
    "publication_date": "2020-09-22",
    "publication_year": 2020,
    "authors": "Janibul Bashir; Smruti R. Sarangi",
    "corresponding_authors": "",
    "abstract": "On-chip photonics is a disruptive technology, and such NoCs are superior to traditional electrical NoCs in terms of latency, power, and bandwidth. Hence, researchers have proposed a wide variety of optical networks for multicore processors. The high bandwidth and low latency features of photonic NoCs have led to the overall improvement in the system performance. However, there are very few proposals that discuss the usage of optical interconnects in Graphics Processor Units (GPUs). GPUs can also substantially gain from such novel technologies, because they need to provide significant computational throughput without further stressing their power budgets. The main shortcoming of optical networks is their high static power usage, because the lasers are turned on all the time by default, even when there is no traffic inside the chip, and thus sophisticated laser modulation schemes are required. Such modulation schemes base their decisions on an accurate prediction of network traffic in the future. In this article, we propose an energy-efficient and scalable optical interconnect for modern GPUs called GPUOPT that smartly creates an overlay network by dividing the symmetric multiprocessors (SMs) into clusters. It furthermore has separate sub-networks for coherence and non-coherence traffic. To further increase the throughput, we connect the off-chip memory with optical links as well. Subsequently, we show that traditional laser modulation schemes (for reducing static power consumption) that were designed for multicore processors are not that effective for GPUs. Hence, there was a need to create a bespoke scheme for predicting the laser power usage in GPUs. Using this set of techniques, we were able to improve the performance of a modern GPU by 45% as compared to a state-of-the-art electrical NoC. Moreover, as compared to competing optical NoCs for GPUs, our scheme reduces the laser power consumption by 67%, resulting in a net 65% reduction in ED 2 for a suite of Rodinia benchmarks.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W3088926700",
    "type": "article"
  },
  {
    "title": "Power-efficient Spike Sorting Scheme Using Analog Spiking Neural Network Classifier",
    "doi": "https://doi.org/10.1145/3432814",
    "publication_date": "2021-01-20",
    "publication_year": 2021,
    "authors": "Anand Kumar Mukhopadhyay; Atul Sharma; Indrajit Chakrabarti; Arindam Basu; Mrigank Sharad",
    "corresponding_authors": "",
    "abstract": "The method to map the neural signals to the neuron from which it originates is spike sorting. A low-power spike sorting system is presented for a neural implant device. The spike sorter constitutes a two-step trainer module that is shared by the signal acquisition channel associated with multiple electrodes. A low-power Spiking Neural Network (SNN) module is responsible for assigning the spike class. The two-step shared supervised on-chip training module is presented for improved training accuracy for the SNN. Post implant, the relatively power-hungry training module can be activated conditionally based on a statistics-driven retraining algorithm that allows on the fly training and adaptation. A low-power analog implementation for the SNN classifier is proposed based on resistive crossbar memory exploiting its approximate computing nature. Owing to the direct mapping of SNN functionality using physical characteristics of devices, the analog mode implementation can achieve ∼21 × lower power than its fully digital counterpart. We also incorporate the effect of device variation in the training process to suppress the impact of inevitable inaccuracies in such resistive crossbar devices on the classification accuracy. A variation-aware, digitally calibrated analog front-end is also presented, which consumes less than ∼50 nW power and interfaces with the digital training module as well as the analog SNN spike sorting module. Hence, the proposed scheme is a low-power, variation-tolerant, adaptive, digitally trained, all-analog spike sorter device, applicable to implantable and wearable multichannel brain-machine interfaces.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W3122870001",
    "type": "article"
  },
  {
    "title": "Dynamically Adapting Page Migration Policies Based on Applications’ Memory Access Behaviors",
    "doi": "https://doi.org/10.1145/3444750",
    "publication_date": "2021-03-24",
    "publication_year": 2021,
    "authors": "Shashank Adavally; Mahzabeen Islam; Krishna Kavi",
    "corresponding_authors": "",
    "abstract": "There have been numerous studies on heterogeneous memory systems comprised of faster DRAM (e.g., 3D stacked HBM or HMC) and slower non-volatile memories (e.g., PCM, STT-RAM). However, most of these studies focused on static policies for managing data placement and migration among the different memory devices. These policies are based on the average behavior across a range of applications. Results show that these techniques do not always result in higher performance when compared to systems that do not migrate data across the devices: some applications show performance gains, but other applications show performance losses. It is possible to utilize offline analyses to identify which applications benefit from page migration (migration friendly) and use page migration only with those applications. However, we observed that several applications exhibit both migration friendly and migration unfriendly behaviors during different phases of execution supporting a need for adaptive page migration techniques. We introduce and evaluate techniques that dynamically adapt to the behavior of applications and either reduce or increase migrations, or even halt migrations. Our adaptive techniques show performance gains for both migration friendly (on average of 81% over no migrations) and unfriendly workloads (by an average of 3%): it should be remembered that previous migration techniques resulted in performance losses for unfriendly workloads.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W3140100618",
    "type": "article"
  },
  {
    "title": "Accelerating Deep Neuroevolution on Distributed FPGAs for Reinforcement Learning Problems",
    "doi": "https://doi.org/10.1145/3425500",
    "publication_date": "2021-04-05",
    "publication_year": 2021,
    "authors": "Alexis Asseman; Nicolas Antoine; Ahmet S. Özcan",
    "corresponding_authors": "",
    "abstract": "Reinforcement learning, augmented by the representational power of deep neural networks, has shown promising results on high-dimensional problems, such as game playing and robotic control. However, the sequential nature of these problems poses a fundamental challenge for computational efficiency. Recently, alternative approaches such as evolutionary strategies and deep neuroevolution demonstrated competitive results with faster training time on distributed CPU cores. Here we report record training times (running at about 1 million frames per second) for Atari 2600 games using deep neuroevolution implemented on distributed FPGAs. Combined hardware implementation of the game console, image preprocessing and the neural network in an optimized pipeline, multiplied with the system level parallelism enabled the acceleration. These results are the first application demonstration on the IBM Neural Computer, which is a custom designed system that consists of 432 Xilinx FPGAs interconnected in a 3D mesh network topology. In addition to high performance, experiments also showed improvement in accuracy for all games compared to the CPU implementation of the same algorithm.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W3143222659",
    "type": "article"
  },
  {
    "title": "A Reconfigurable Multiplier for Signed Multiplications with Asymmetric Bit-Widths",
    "doi": "https://doi.org/10.1145/3446213",
    "publication_date": "2021-06-30",
    "publication_year": 2021,
    "authors": "Chuliang Guo; Li Zhang; Xian Zhou; Grace Li Zhang; Bing Li; Weikang Qian; Xunzhao Yin; Cheng Zhuo",
    "corresponding_authors": "",
    "abstract": "Multiplications have been commonly conducted in quantized CNNs, filters, and reconfigurable cores, and so on, which are widely deployed in mobile and embedded applications. Most multipliers are designed to perform multiplications with symmetric bit-widths, i.e., n - by n -bit multiplication. Such features would cause extra area overhead and performance loss when m - by n -bit multiplications ( m &gt; n ) are deployed in the same hardware design, resulting in inefficient multiplication operations. It is highly desired and challenging to propose a reconfigurable multiplier design to accommodate operands with both symmetric and asymmetric bit-widths. In this work, we propose a reconfigurable approximate multiplier to support multiplications at various precisions, i.e., bit-widths. Unlike prior works of approximate adders assuming a uniform weight distribution with bit-wise independence, scenarios like a quantized CNN may have a centralized weight distribution and hence follow a Gaussian-like distribution with correlated adjacent bits. Thus, a new block-based approximate adder is also proposed as part of the multiplier to ensure energy-efficient operation with an awareness of the bit-wise correlation. Our experimental results show that the proposed approximate adder significantly reduces the error rate by 76% to 98% over a state-of-the-art approximate adder for Gaussian-like distribution scenarios. Evaluation results show that the proposed multiplier is 19% faster and 22% more power saving than a Xilinx multiplier IP at the same bit precision and achieves a 23.94-dB peak signal-to-noise ratio, which is comparable to the accurate one of 24.10 dB when deployed in a Gaussian filter for image processing tasks.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W3175862166",
    "type": "article"
  },
  {
    "title": "Test Points for Online Monitoring of Quantum Circuits",
    "doi": "https://doi.org/10.1145/3477928",
    "publication_date": "2021-10-22",
    "publication_year": 2021,
    "authors": "Nikita Acharya; Miroslav Urbánek; Wibe A. de Jong; Samah Mohamed Saeed",
    "corresponding_authors": "",
    "abstract": "Noisy Intermediate-Scale Quantum (NISQ) computers consisting of tens of inherently noisy quantum bits (qubits) suffer from reliability problems. Qubits and their gates are susceptible to various types of errors. Due to limited numbers of qubits and high error rates, quantum error correction cannot be applied. Physical constraints of quantum hardware including the error rates are used to guide the design and the layout of quantum circuits. The error rates determine the selection of qubits and their operations. The resulting circuit is executed on the quantum computer. This study explores the risk of unexpected changes in the error rates of NISQ computers post-calibration. We show that unexpected changes in error rates can alter the output state of a quantum circuit. To detect these changes, we propose the insertion of test points into the quantum circuit to enable online monitoring of the physical qubit behavior. We utilize classical, superposition, and uncompute test points. Furthermore, we use a gate error coverage metric to assess the quality of the tests. We verify the effectiveness of the proposed scheme on different IBM quantum computers (IBM Q), in addition to a noisy simulation that shows the scalability of the proposed approach.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W3210774241",
    "type": "article"
  },
  {
    "title": "STAP: An Architecture and Design Tool for Automata Processing on Memristor TCAMs",
    "doi": "https://doi.org/10.1145/3450769",
    "publication_date": "2021-12-31",
    "publication_year": 2021,
    "authors": "João Paulo C. de Lima; Marcelo Brandalero; Michael Hübner; Luigi Carro",
    "corresponding_authors": "",
    "abstract": "Accelerating finite-state automata benefits several emerging application domains that are built on pattern matching. In-memory architectures, such as the Automata Processor (AP), are efficient to speed them up, at least for outperforming traditional von-Neumann architectures. In spite of the AP’s massive parallelism, current APs suffer from poor memory density, inefficient routing architectures, and limited capabilities. Although these limitations can be lessened by emerging memory technologies, its architecture is still the major source of huge communication demands and lack of scalability. To address these issues, we present STAP , a Scalable TCAM-based architecture for Automata Processing . STAP adopts a reconfigurable array of processing elements, which are based on memristive Ternary CAMs (TCAMs), to efficiently implement Non-deterministic finite automata (NFAs) through proper encoding and mapping methods. The CAD tool for STAP integrates the design flow of automata applications, a specific mapping algorithm, and place and route tools for connecting processing elements by RRAM-based programmable interconnects. Results showed 1.47× higher throughput when processing 16-bit input symbols, and improvements of 3.9× and 25× on state and routing densities over the state-of-the-art AP, while preserving 10 4 programming cycles.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4205400366",
    "type": "article"
  },
  {
    "title": "One-Step Sneak-Path Free Read Scheme for Resistive Crossbar Memory",
    "doi": "https://doi.org/10.1145/3012002",
    "publication_date": "2017-02-03",
    "publication_year": 2017,
    "authors": "Yao Wang; Liang Rong; Haibo Wang; Guangjun Wen",
    "corresponding_authors": "",
    "abstract": "A one-step sneak-path free read scheme for resistive crossbar memory is proposed in this article. During read operation, it configures the crossbar array into a four-terminal resistance network, which is composed of the selected cell and three other resistors corresponding to unselected cells that contribute to the sneak-path. Two sensing voltages with equal potential are applied to three terminals of the network. One is for sensing the resistance of the selected cell; the other is for creating zero-voltage drop across one of the three resistors, which connects the sneak-path to the selected cell. This effectively suppresses the current injected by the sneak-path to the selected cell-sensing loop. This work also proposes a cost-effective data-encoding circuit that guarantees that at least half of the memory cells are in a high-resistance state, which further minimizes sneak-path current. The impact of key design parameters, such as sensing voltage, switch on-resistance, and the ratio of memory cell resistances in different states, as well as nonideal effects are investigated. Equations for estimating the maximum array size to share a single read circuit are derived. The effectiveness of the proposed design has been validated via circuit simulations. Impacts of the word-/bit-line resistance are also analyzed.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2583504751",
    "type": "article"
  },
  {
    "title": "VLSI Architectures for the Restricted Boltzmann Machine",
    "doi": "https://doi.org/10.1145/3007193",
    "publication_date": "2017-05-12",
    "publication_year": 2017,
    "authors": "Bo Yuan; Keshab K. Parhi",
    "corresponding_authors": "",
    "abstract": "Neural network (NN) systems are widely used in many important applications ranging from computer vision to speech recognition. To date, most NN systems are processed by general processing units like CPUs or GPUs. However, as the sizes of dataset and network rapidly increase, the original software implementations suffer from long training time. To overcome this problem, specialized hardware accelerators are needed to design high-speed NN systems. This article presents an efficient hardware architecture of restricted Boltzmann machine (RBM) that is an important category of NN systems. Various optimization approaches at the hardware level are performed to improve the training speed. As-soon-as-possible and overlapped-scheduling approaches are used to reduce the latency. It is shown that, compared with the flat design, the proposed RBM architecture can achieve 50% reduction in training time. In addition, an on-the-fly computation scheme is also used to reduce the storage requirement of binary and stochastic states by several hundreds of times. Then, based on the proposed approach, a 784-2252 RBM design example is developed for MNIST handwritten digit recognition dataset. Analysis shows that the VLSI design of RBM achieves significant improvement in training speed and energy efficiency as compared to CPU/GPU-based solution.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2615398246",
    "type": "article"
  },
  {
    "title": "Improving Performance under Process and Voltage Variations in Near-Threshold Computing Using 3D ICs",
    "doi": "https://doi.org/10.1145/3060579",
    "publication_date": "2017-06-29",
    "publication_year": 2017,
    "authors": "Sandeep Kumar Samal; Guoqing Chen; Sung Kyu Lim",
    "corresponding_authors": "",
    "abstract": "Near-threshold computing (NTC) circuits have been shown to offer significant energy efficiency and power benefits but with a huge performance penalty. This performance loss exacerbates if process and voltage variations are considered. In this article, we demonstrate that three-dimensional (3D) IC technology can overcome this limitation. We present a detailed case study with a 28nm commercial-grade core at 0.6V operation optimized with various 3D IC physical design methods. First, our study under the deterministic case shows that 3D IC NTC design outperforms 2D IC NTC by 29.5% in terms of performance at comparable energy. This is significantly higher than the 12.8% performance benefit of 3D IC at nominal voltage supplies due to higher delay sensitivity to input slew at lower voltages. Second, it is well demonstrated that transistor delay is more sensitive to voltage changes at NTC operation. However, our full-chip study reveals that IR drop effect on 2D/3D IC NTC performance is not severe due to the low power consumption and hence lower IR drop values. Third, die-to-die variation impact on full-chip performance is visible in 3D IC NTC designs, but it is not worse compared to 2D IC NTC designs. This is mainly due to the shorter critical path length in 3D IC NTC designs.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2725753878",
    "type": "article"
  },
  {
    "title": "Reducing System Power Consumption Using Check-Pointing on Nonvolatile Embedded Magnetic Random Access Memories",
    "doi": "https://doi.org/10.1145/2876507",
    "publication_date": "2016-05-12",
    "publication_year": 2016,
    "authors": "Christophe Layer; Laurent Becker; Kotb Jabeur; Sylvain Claireux; B. Diény; Guillaume Prenat; Grégory Di Pendina; Stephane Gros; Pierre Paoli; Virgile Javerliac; Fabrice Bernard-Granger; Loic Decloedt",
    "corresponding_authors": "",
    "abstract": "The most widely used embedded memory technology, static random access memory (SRAM), is heading toward scaling problems in advanced technology nodes due to the leakage currents caused by the quantum tunneling effect. As an alternative, spin-transfer torque magnetic RAM (STT-MRAM) technology shows comparable performance in terms of speed and power consumption and much better performance in terms of density and leakage. Moreover, MRAM brings up new paradigms in system design thanks to its inherent nonvolatility, which allows the definition of new instant-on/off policies and leakage current optimization. Based on our compact model, we have developed a fully characterized system-on-chip from the basic cell up to the system architecture in a 40nm LP hybrid CMOS/magnetic process. Through simulations, first we demonstrate that STT-MRAM is a candidate for the memory part of embedded systems, and second we implement a check-pointing methodology based on the regular interrupt routines of a processor to enable a fast power on and off functionality. Using a synthetic benchmark developed in high-level programming languages intended to be representative of integer system performance, our method shows that having MRAM instead of SRAM in an embedded design brings up important energy savings. The influence of the check-pointing routine on power consumption is finally evaluated with regard to various shutdown and restart behaviors.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2366401214",
    "type": "article"
  },
  {
    "title": "Ultra-low-leakage, Robust FinFET SRAM Design Using Multiparameter Asymmetric FinFETs",
    "doi": "https://doi.org/10.1145/2988233",
    "publication_date": "2016-11-19",
    "publication_year": 2016,
    "authors": "Abdullah Guler; Niraj K. Jha",
    "corresponding_authors": "",
    "abstract": "Memory arrays consisting of Static Random Access Memory (SRAM) cells occupy the largest area on chip and are responsible for significant leakage power consumption in modern microprocessors. With the transition from planar Complementary Metal-Oxide-Semiconductor (CMOS) technology to FinFETs, FinFET SRAM design has become important. However, increasing leakage power consumption of FinFETs due to aggressive scaling, width quantization, read-write conflict, and process variations make FinFET SRAM design challenging. In this article, we show how Multiparameter Asymmetric (MPA) FinFETs can be used to design ultra-low-leakage and robust 6T SRAM cells. We combine multiple asymmetries, namely, asymmetry in gate work function, source/drain doping concentration, and gate underlap, to address various SRAM design issues all at once. We propose five novel MPA FinFET SRAM cell designs and compare them with symmetric and Single-Parameter Asymmetric (SPA) FinFET SRAM cells using dc and transient metrics. We show that the leakage current of MPA FinFET SRAM cells can be reduced by up to 58 × while ensuring reasonable read/write stability metric values. In addition, high stability metric values can be achieved with 22 × leakage current reduction compared to the traditional symmetric FinFET SRAM cell. There is no area overhead associated with MPA FinFET SRAM cells.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2553781108",
    "type": "article"
  },
  {
    "title": "Real-Time and Low-Power Streaming Source Separation Using Markov Random Field",
    "doi": "https://doi.org/10.1145/3183351",
    "publication_date": "2018-04-30",
    "publication_year": 2018,
    "authors": "Glenn G. Ko; Rob A. Rutenbar",
    "corresponding_authors": "",
    "abstract": "Machine learning (ML) has revolutionized a wide range of recognition tasks, ranging from text analysis to speech to vision, most notably in cloud deployments. However, mobile deployment of these ideas involves a very different category of design problems. In this article, we develop a hardware architecture for a sound source separation task, intended for deployment on a mobile phone. We focus on a novel Markov random field (MRF) sound source separation algorithm that uses expectation-maximization and Gibbs sampling to learn MRF parameters on the fly and infer the best separation of sources. The intrinsically iterative algorithm suggests challenges for both speed and power. A real-time streaming FPGA implementation runs at 150MHz with 207KB RAM, achieves a speed-up of 22× over a software reference, performs with an SDR of up to 7.021dB with 1.601ms latency, and exhibits excellent perceived audio quality. A 45nm CMOS ASIC virtual prototype simulated at 20MHz shows that this architecture is small (&lt;10 million gates) and consumes only 70mW, which is less than 2% of the power of an ARM Cortex-A9 software version. To the best of our knowledge, this is the first Gibbs sampling inference accelerator designed in conventional FPGA/ASIC technology that targets a realistic mobile perceptual application.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2804899035",
    "type": "article"
  },
  {
    "title": "MFNW",
    "doi": "https://doi.org/10.1145/3154841",
    "publication_date": "2018-04-30",
    "publication_year": 2018,
    "authors": "Ali Alsuwaiyan; Kartik Mohanram",
    "corresponding_authors": "",
    "abstract": "The increased capacity of multi-level cells (MLC) and triple-level cells (TLC) in emerging non-volatile memory (NVM) technologies comes at the cost of higher cell write energies and lower cell endurance. In this article, we describe MFNW, a Flip-N-Write encoding that effectively reduces the write energy and improves the endurance of MLC NVMs. Two MFNW modes are analyzed: cell Hamming distance mode and energy Hamming distance mode. We derive an approximate model that accurately predicts the average number of cell writes that is proportional to the energy consumption, enabling word length optimization to maximize energy reduction subject to memory space overhead constraints. In comparison to state-of-the-art MLC NVM encodings, our simulation results indicate that MFNW achieves up to 7%--39% saving for 1.56%--50% NVM space overhead. Extra energy saving (up to 19%--47%) can be achieved for the same NVM space overhead using our proposed variations of MFNW, i.e., MFNW2 and MFNW3. For TLC NVMs, we propose TFNW that can achieve up to 53% energy saving in comparison to state-of-the-art TLC NVM encodings. Endurance simulations indicate that MFNW (TFNW) is capable of extending MLC (TLC) NVM life by up to 100% (87%).",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2833453026",
    "type": "article"
  },
  {
    "title": "Framework for Quantifying and Managing Accuracy in Stochastic Circuit Design",
    "doi": "https://doi.org/10.1145/3183345",
    "publication_date": "2018-04-30",
    "publication_year": 2018,
    "authors": "Florian Neugebauer; Ilia Polian; John P. Hayes",
    "corresponding_authors": "",
    "abstract": "Stochastic circuits (SCs) offer considerable area- and power-consumption benefits in various applications at the expense of computational inaccuracies. Unlike conventional logic synthesis, managing accuracy is a central problem in SC design. It is usually tackled in ad hoc fashion by multiple trial-and-error simulations that vary relevant parameters like the stochastic number length n . We present, for the first time, a systematic design approach to controlling the accuracy of SCs and balancing it against other design parameters. We express the (in)accuracy of a circuit processing n -bit stochastic numbers by the numerical deviation of the computed value from the expected result, in conjunction with a confidence level. Using the theory of Monte Carlo simulation, we derive expressions for the stochastic number length required for a desired level of accuracy or vice versa. We discuss the integration of the theory into a design framework that is applicable to both combinational and sequential SCs. We show that for combinational SCs, accuracy is independent of the circuit’s size or complexity, a surprising result. We also show how the analysis can identify subtle errors in both combinational and sequential designs. Finally, we apply the proposed methods to a case study on filtering noisy EKG signals.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2883818061",
    "type": "article"
  },
  {
    "title": "IMFlexCom",
    "doi": "https://doi.org/10.1145/3223047",
    "publication_date": "2018-07-31",
    "publication_year": 2018,
    "authors": "Farhana Parveen; Shaahin Angizi; Deliang Fan",
    "corresponding_authors": "",
    "abstract": "In this article, we propose an &lt;u&gt;I&lt;/u&gt;n-&lt;u&gt;M&lt;/u&gt;emory &lt;u&gt;Flex&lt;/u&gt;ible &lt;u&gt;Com&lt;/u&gt;puting platform (IMFlexCom) using a novel Spin Orbit Torque Magnetic Random Access Memory (SOT-MRAM) array architecture, which could work in dual mode: memory mode and computing mode. Such intrinsic in-memory logic (AND/OR/XOR) could be used to process data within memory to greatly reduce power-hungry and long distance massive data communication in conventional Von Neumann computing systems. A comprehensive reliability analysis is performed, which confirms ∼90mV and ∼10mV (worst-case) sense margin for memory and in-memory logic operation in variations on resistance-area product and tunnel magnetoresistance. We further show that sense margin for in-memory logic computation can be significantly increased by increasing the oxide thickness. Furthermore, we employ bulk bitwise vector operation and data encryption engine as case studies to investigate the performance of our proposed design. IMFlexCom shows ∼35× energy saving and ∼18× speedup for bulk bitwise in-memory vector AND/OR operation compared to DRAM-based in-memory logic. Again, IMFlexCom can achieve 77.27% and 85.4% lower energy consumption compared to CMOS-ASIC- and CMOL-based Advanced Encryption Standard (AES) implementations, respectively. It offers almost similar energy consumption as recent DW-AES implementation with 66.7% less area overhead.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2898181439",
    "type": "article"
  },
  {
    "title": "Trained Biased Number Representation for ReRAM-Based Neural Network Accelerators",
    "doi": "https://doi.org/10.1145/3304107",
    "publication_date": "2019-03-26",
    "publication_year": 2019,
    "authors": "Weijia Wang; Bill Lin",
    "corresponding_authors": "",
    "abstract": "Recent works have demonstrated the promise of using resistive random access memory (ReRAM) to perform neural network computations in memory. In particular, ReRAM-based crossbar structures can perform matrix-vector multiplication directly in the analog domain, but the resolutions of ReRAM cells and digital/analog converters limit the precisions of inputs and weights that can be directly supported. Although convolutional neural networks (CNNs) can be trained with low-precision weights and activations, previous quantization approaches are either not amenable to ReRAM-based crossbar implementations or have poor accuracies when applied to deep CNNs on complex datasets. In this article, we propose a new CNN training and implementation approach that implements weights using a trained biased number representation , which can achieve near full-precision model accuracy with as little as 2-bit weights and 2-bit activations on the CIFAR datasets. The proposed approach is compatible with a ReRAM-based crossbar implementation. We also propose an activation-side coalescing technique that combines the steps of batch normalization, non-linear activation, and quantization into a single stage that simply performs a clipped-rounding operation. Experiments demonstrate that our approach outperforms previous low-precision number representations for VGG-11, VGG-13, and VGG-19 models on both the CIFAR-10 and CIFAR-100 datasets.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2929974204",
    "type": "article"
  },
  {
    "title": "Identification of Synthesis Approaches for IP/IC Piracy of Reversible Circuits",
    "doi": "https://doi.org/10.1145/3289392",
    "publication_date": "2019-04-29",
    "publication_year": 2019,
    "authors": "Samah Mohamed Saeed; Nithin Mahendran; Alwin Zulehner; Robert Wille; Ramesh Karri",
    "corresponding_authors": "",
    "abstract": "Reversible circuits employ a computational paradigm that is beneficial for several applications, including the design of encoding and decoding devices, low-power design, and emerging applications in quantum computation . However, similarly to conventional logic, reversible circuits are expected to be subject to Intellectual Property / Integrated Circuit piracy . To counteract such attacks, an understanding of how to identify the target function from a reversible circuit is a crucial first step. In contrast to conventional logic, the target function is (implicitly or explicitly) embedded into the reversible circuit. Numerous synthesis approaches have been proposed for this embedding task. To recover the target function embedded in a reversible circuit, one needs to know what synthesis approach has been used to embed the circuit. We propose a machine-learning-based scheme to determine the used reversible synthesis approach based on the telltale signs it leaves in the synthesized reversible circuit. We study the impact of optimizing the synthesis approaches on the telltale signs that they leave. Our analysis shows that the synthesis approaches can be determined in the vast majority of cases even if optimized versions of the synthesis approaches are used.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2943497367",
    "type": "article"
  },
  {
    "title": "LiwePMS",
    "doi": "https://doi.org/10.1145/3327963",
    "publication_date": "2019-06-10",
    "publication_year": 2019,
    "authors": "Sumin Li; Kaixin Huang; Linpeng Huang; Jiashun Zhu",
    "corresponding_authors": "",
    "abstract": "Next-generation Storage Class Memory (SCM) offers low-latency, high-density, byte-addressable access and persistency. The potent combination of these attractive characteristics makes it possible for SCM to unify the main memory and storage to reduce the storage hierarchy. Aiming for this, several persistent memory systems were designed. However, the heavy metadata and transaction cost degrade the system performance. Moreover, neither of them pays attention to wear-leveling strategy. In this article, we present a lightweight persistent memory system, LiwePMS, which allows a fast access to persistent data stored in SCM with wear-aware memory management. LiwePMS makes performance improvement by simplifying the metadata management and the consistency method. LiwePMS abstracts SCM as heap space with container-based dynamic address mapping. Also, LiwePMS implements efficient wear-aware dynamic memory allocator and lightweight transaction mechanism for data consistency in user-space library. The experiments showed that LiwePMS persists key-value records 1.5× faster than Redis RDB mechanism. LiwePMS improves the performance of persistent region operation by more than 45%, 63%, and 1.1× comparing with HEAPO, Mnemosyne, and NVML, respectively. Also, the wear-leveling policy of memory allocator outperforms that of NVMalloc from 35% to 30%, and the transaction method promotes the transaction performance to 1.8× compared to NVML.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2950318373",
    "type": "article"
  },
  {
    "title": "Directed Placement for mVLSI Devices",
    "doi": "https://doi.org/10.1145/3369585",
    "publication_date": "2019-12-12",
    "publication_year": 2019,
    "authors": "Brian Crites; Karen Kong; Philip Brisk",
    "corresponding_authors": "",
    "abstract": "Continuous-flow microfluidic devices based on integrated channel networks are becoming increasingly prevalent in research in the biological sciences. At present, these devices are physically laid out by hand by domain experts who understand both the underlying technology and the biological functions that will execute on fabricated devices. The lack of a design science that is specific to microfluidic technology creates a substantial barrier to entry. To address this concern, this article introduces Directed Placement, a physical design algorithm that leverages the natural “directedness” in most modern microfluidic designs: fluid enters at designated inputs, flows through a linear or tree-based network of channels and fluidic components, and exits the device at dedicated outputs. Directed placement creates physical layouts that share many principle similarities to those created by domain experts. Directed placement allows components to be placed closer to their neighbors compared to existing layout algorithms based on planar graph embedding or simulated annealing, leading to an average reduction in laid-out fluid channel length of 91% while improving area utilization by 8% on average. Directed placement is compatible with both passive and active microfluidic devices and is compatible with a variety of mainstream manufacturing technologies.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W3009633229",
    "type": "article"
  },
  {
    "title": "Device-aware Circuit Design for Robust Memristive Neuromorphic Systems with STDP-based Learning",
    "doi": "https://doi.org/10.1145/3380969",
    "publication_date": "2020-05-22",
    "publication_year": 2020,
    "authors": "Sagarvarma Sayyaparaju; Md Musabbir Adnan; Sherif Amer; Garrett S. Rose",
    "corresponding_authors": "",
    "abstract": "In the past decade, complementary metal oxide semiconductor-memristor hybrid neuromorphic systems have gained importance owing to the advantages of memristors such as nano-scale size, non-volatility, and low-power operation. However, they are often accompanied by non-ideal properties that can impact the system’s performance. This article presents device-aware circuit design to mitigate such effects. A bi-memristor synapse with a robust spike-timing-dependent plasticity (STDP) is designed. A mixed-mode neuron is presented whose accumulation rate is tunable on-chip and can be used with a variety of memristors without needing a re-design. The proposed designs are employed together in an example pattern recognition system. A scalable winner-takes-all circuit is presented for the output stage. A pattern recognition task based on a simple STDP-based learning is demonstrated such that the recognition rate is directly dependent on the learnt weights. Device-level issues such as switching speed/threshold asymmetry, limited switching resolution, endurance, and varying resistance range (across devices) are shown to adversely affect learning at the system level and it is demonstrated that the proposed circuits can mitigate them. Last, the area and energy costs of the proposed designs are evaluated and compared against other implementations in the literature.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W3029160061",
    "type": "article"
  },
  {
    "title": "Write Back Energy Optimization for STT-MRAM-based Last-level Cache with Data Pattern Characterization",
    "doi": "https://doi.org/10.1145/3381860",
    "publication_date": "2020-05-22",
    "publication_year": 2020,
    "authors": "Jiacheng Ni; Keren Liu; Bi Wu; Weisheng Zhao; Yuanqing Cheng; Xiaolong Zhang; Ying Wang",
    "corresponding_authors": "",
    "abstract": "Traditional memory technologies face severe challenges in meeting the ever-increasing power and memory bandwidth requirements for high-performance computing and big-data analyses. Several emerging memory technologies are promising as the replacements of SRAM or DRAM. Among them, STT-MRAM can be used to replace SRAM as the last-level cache (LLC). However, it suffers from high write energy and latency. In this article, we investigate data patterns written from SRAM-based upper-level cache to STT-MRAM-based LLC to explore the write energy reduction potential. Depending on the data layout within a cache line, redundant bits can be identified and eliminated from write back operations to save STT-MRAM write energy. We also propose a dynamic profiling method to accommodate different application characteristics. The extensive simulation results show that write energy can be saved by 37.05% ∼ 38.89% for static profiling and 19.76% ∼ 34.29% for dynamic profiling.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W3031906328",
    "type": "article"
  },
  {
    "title": "LosPem",
    "doi": "https://doi.org/10.1145/3379932",
    "publication_date": "2020-05-22",
    "publication_year": 2020,
    "authors": "Sumin Li; Linpeng Huang",
    "corresponding_authors": "",
    "abstract": "New and emerging types of Persistent Memory (PM) technologies boost the opportunity to improve the performance of storage systems. PM can unify the main memory and secondary storage by incorporating it into legacy computer systems through the memory bus. In recent years, innovative results have been presented that exploit the byte-addressability, low latency, and non-volatility of PM; these have included local PM file systems and PM systems. However, the high overhead of ensuring data consistency has limited the performance of these systems. In this article, we propose LosPem, a novel log-structured framework for persistent memory to address the performance challenge. LosPem utilizes two techniques to accomplish this. Firstly, LosPem deploys efficient hash-indexed linked lists to maintain the log contents to reduce the significant overhead of log content retrieval. Secondly, LosPem improves the transaction throughput by decoupling a transaction into two asynchronous steps and creating a write buffer on Dynamic Random Access Memory (DRAM) write buffer for processing the frequent data writes. The experimental results show that LosPem outperforms Non-volatile Memory Library (NVML), Mnemosyne and Log-structured Non-volatile Main Memory (LSNVMM) by 27%, 1.2x, and 1.0x on a read-intensive workload. On a write-intensive workload, LosPem outperforms NVML, Mnemosyne, and LSNVMM by 1.8x, 1.2x, and 34%, respectively.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W3032179339",
    "type": "article"
  },
  {
    "title": "Low Overhead Online Data Flow Tracking for Intermittently Powered Non-Volatile FPGAs",
    "doi": "https://doi.org/10.1145/3371392",
    "publication_date": "2020-07-01",
    "publication_year": 2020,
    "authors": "Xinyi Zhang; Clay Patterson; Yongpan Liu; Chengmo Yang; Chun Jason Xue; Jingtong Hu",
    "corresponding_authors": "",
    "abstract": "Energy harvesting is an attractive way to power future Internet of Things (IoT) devices since it can eliminate the need for battery or power cables. However, harvested energy is intrinsically unstable. While Field-programmable Gate Array (FPGAs) have been widely adopted in various embedded systems, it is hard to survive unstable power since all the memory components in FPGA are based on volatile Static Random-access Memory (SRAMs). The emerging non-volatile memory-based FPGAs provide promising potentials to keep configuration data on the chip during power outages. Few works have considered implementing efficient runtime intermediate data checkpoint on non-volatile FPGAs. To realize accumulative computation under intermittent power on FPGA, this article proposes a low-cost design framework, Data-Flow-Tracking FPGA (DFT-FPGA), which utilizes binary counters to track intermediate data flow. Instead of keeping all on-chip intermediate data, DFT-FPGA only targets on necessary data that is labeled by off-line analysis and identified by an online tracking system. The evaluation shows that compared with state-of-the-art techniques, DFT-FPGA can realize accumulative computing with less off-line workload and significantly reduce online roll-back time and resource utilization.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W3039644518",
    "type": "article"
  },
  {
    "title": "Lotus",
    "doi": "https://doi.org/10.1145/3415749",
    "publication_date": "2020-09-17",
    "publication_year": 2020,
    "authors": "Yunfeng Lu; Huaxi Gu; Xiaoshan Yu; Krishnendu Chakrabarty",
    "corresponding_authors": "",
    "abstract": "Machine learning is at the heart of many services provided by data centers. To improve the performance of machine learning, several parameter (gradient) synchronization methods have been proposed in the literature. These synchronization algorithms have different communication characteristics and accordingly place different demands on the network architecture. However, traditional data-center networks cannot easily meet these demands. Therefore, we analyze the communication profiles associated with several common synchronization algorithms and propose a machine learning--oriented network architecture to match their characteristics. The proposed design, named Lotus, because it looks like a lotus flower, is a hybrid optical/electrical architecture based on arrayed waveguide grating routers (AWGRs). In Lotus, a complete bipartite graph is used within the group to improve bisection bandwidth and scalability. Each pair of groups is connected by an optical link, and AWGRs between adjacent groups enhance path diversity and network reliability. We also present an efficient routing algorithm to make full use of the path diversity of Lotus, which leads to a further increase in network performance. Simulation results show that the network performance of Lotus is better than Dragonfly and 3D-Torus under realistic traffic patterns for different synchronization algorithms.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W3088249176",
    "type": "article"
  },
  {
    "title": "Depth-bounded Graph Partitioning Algorithm and Dual Clocking Method for Realization of Superconducting SFQ Circuits",
    "doi": "https://doi.org/10.1145/3412389",
    "publication_date": "2020-10-22",
    "publication_year": 2020,
    "authors": "Ghasem Pasandi; Massoud Pedram",
    "corresponding_authors": "",
    "abstract": "Superconducting Single Flux Quantum (SFQ) logic with switching delay of 1ps and switching energy of 10 −19 J is a potential emerging candidate for replacing Complementary Metal Oxide Semiconductor (CMOS) to achieve very high speed and ultra energy efficiency. Conventional SFQ circuits need Full Path Balancing (FPB), which tends to require insertion of many path balancing buffers (D-Flip-Flops). FPB method increases total power consumption as well as total area of the chip. This article presents a novel scheme for realization of superconducting SFQ circuits by introducing a new depth-bounded graph partitioning algorithm in combination with a dual clocking method (slow and fast clock pulses) that minimizes the aforesaid path balancing overheads. Experimental results show that the proposed solution reduces total number of path balancing buffers and total static power consumption by an average of 2.68× and 60%, respectively, when compared to the best of other methods for realizing SFQ circuits. However, our scheme degrades the peak throughput; therefore, it is especially valuable when the actual throughput of the SFQ circuit is much lower than the peak theoretical throughput. This is typically the case due to high-level data dependencies of the application that feeds data into an SFQ circuit.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W3108739782",
    "type": "article"
  },
  {
    "title": "Spatial and temporal thermal characterization of stacked multicore architectures",
    "doi": "https://doi.org/10.1145/2287696.2287704",
    "publication_date": "2012-08-01",
    "publication_year": 2012,
    "authors": "Eren Kursun; J. Wakil; Mukta Farooq; R. Hannon",
    "corresponding_authors": "",
    "abstract": "Three-dimensional integration provides a new way of performance growth for microprocessor architectures. While a recent studies report promising performance improvement numbers, majority of the processor stacking options are thermally-limited. Elevated stack temperatures have significant effect on the overall energy efficiency and reliability of the processor; they also limit the potential peak performance improvement from the 3D implementation. Thermal characteristics of 3D stacks differ from 2D processors in various ways including: the nature of heat dissipation throughout the stack, thermal conductivity of the 3D structures such as micro-C4 layers, and hotspot interactions among layers. The intensity of the corresponding thermal problems is highly dependent on the 3D technology, processor and stack parameters. In this study we focus on spatial and temporal thermal characteristics of 3D multicore architectures using high-fidelity technology and processor models. Our experimental results highlight the need for integrating detailed thermal models in the design flow, starting with the early design stages. In addition, the reduced time constants and elevated on-chip temperatures indicate faster response time requirements for dynamic thermal management in processor stacking options.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W1963768348",
    "type": "article"
  },
  {
    "title": "Improving Performance in Sub-Block Caches with Optimized Replacement Policies",
    "doi": "https://doi.org/10.1145/2668127",
    "publication_date": "2015-04-27",
    "publication_year": 2015,
    "authors": "Oluleye Olorode; Mehrdad Nourani",
    "corresponding_authors": "",
    "abstract": "Recent advances in computer processor design have led to the introduction of sub-blocking to cache architectures. Sub-block caches reduce the tag area and power overhead in caches without reducing the effective cache size by using fewer tags to index the full data RAM array. In spite of achieving reduced area and power overhead, sub-block caches suffer performance degradation due to cache trashing. This occurs when a wider cache line (super-block), made up of multiple valid cache lines (sub-blocks), is replaced or evicted when only a sub-block is to be allocated into the wider super-block. To address this problem, we propose cache replacement policies as they relate specifically to sub-block caches. We propose new replacement policies that are tuned for sub-block caches by adding more intelligence based on the valid state of individual sub-blocks of a super-block. We also investigate the effect of using a few level-0 registers to bypass a few level-1 cache pipe stages on sub-block cache performance. To evaluate the performance improvement offered by our proposed replacement policies and the use of level-0 registers, we developed a sub-block cache simulator based on the Simplescalar toolset for single-core evaluations and the Sniper Simulator for multicore evaluations. We show that, with minimal architectural updates to existing conventional cache replacement policies, we are able to improve level-1 cache hit rates by up to 4.17% using our proposed policies alone on SPEC2006 benchmarks and up to 14% in shared level-2 caches using multicore benchmark suites: PARSEC and SPLASH2.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W1965672293",
    "type": "article"
  },
  {
    "title": "Nanowire Volatile RAM as an Alternative to SRAM",
    "doi": "https://doi.org/10.1145/2714567",
    "publication_date": "2015-09-21",
    "publication_year": 2015,
    "authors": "Mostafizur Rahman; Santosh Khasanvis; Csaba Andras Moritz",
    "corresponding_authors": "",
    "abstract": "Maintaining benefits of CMOS technology scaling is becoming challenging, primarily due to increased manufacturing complexities and unwanted passive power dissipations. This is particularly challenging in SRAM, where manufacturing precision and leakage power control are critical issues. To alleviate these challenges, we proposed a novel volatile memory alternative to SRAM called nanowire volatile RAM (NWRAM). Due to NWRAM's regular grid-based layout and innovative circuit style, manufacturing complexities are reduced and, at the same time, considerable benefits are attained in terms of performance and leakage power reduction. In this article we elaborate NWRAM's circuit aspects and manufacturability, and quantify benefits at 16nm technology node through simulation against state-of-the-art 6T-SRAM and gridded 8T-SRAM designs. Our results show that when lower bounds in design rules are considered, 10T-NWRAM's read and write time are 1.38x and 2x faster, and the leakage power is 14x better in comparison to high-performance 6T-SRAM. Similarly the 10T-NWRAM achieves 1.3x and 1.9x read and write performance, and 35x leakage power improvements compared to high-performance 8T-SRAM. 10T-NWRAM's density is comparable to 6T-SRAM and 8T-SRAM for lower bounds, but exhibits higher active power in similar comparisons. This article details all benchmarking results and provides thorough analysis of NWRAM's evaluations.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W1972800815",
    "type": "article"
  },
  {
    "title": "Cofactor Sharing for Reversible Logic Synthesis",
    "doi": "https://doi.org/10.1145/2629524",
    "publication_date": "2014-11-18",
    "publication_year": 2014,
    "authors": "Alireza Shafaei; Mehdi Saeedi; Massoud Pedram",
    "corresponding_authors": "",
    "abstract": "Improving circuit realization of known quantum algorithms by CAD techniques has benefits for quantum experimentalists. In this article, the problem of synthesizing a given function on a set of ancillea is addressed. The proposed approach benefits from extensive sharing of cofactors among cubes that appear on function outputs. Accordingly, it can be considered a multilevel logic optimization technique for reversible circuits. In particular, the suggested approach can efficiently implement any n -input, m -output lookup table (LUT) by a reversible circuit. This problem has interesting applications in the Shor's number-factoring algorithm and in quantum walk on sparse graphs. Simulation results reveal that the proposed cofactor-sharing synthesis algorithm has a significant impact on reducing the size of modular exponentiation circuits for Shor's quantum factoring algorithm, oracle circuits in quantum walk on sparse graphs, and the well-known MCNC benchmarks.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W1982763669",
    "type": "article"
  },
  {
    "title": "Variability in Nanoscale Fabrics",
    "doi": "https://doi.org/10.1145/2422094.2422102",
    "publication_date": "2013-02-01",
    "publication_year": 2013,
    "authors": "Pritish Narayanan; Michael Leuchtenburg; Jorge Kina; Prachi Joshi; Pavan Panchapakeshan; Chi On Chui; Csaba Andras Moritz",
    "corresponding_authors": "",
    "abstract": "Emerging nanodevice-based architectures will be impacted by parameter variation in conjunction with high defect rates. Variations in key physical parameters are caused by manufacturing imprecision as well as fundamental atomic scale randomness. In this article, the impact of parameter variation on nanoscale computing fabrics is extensively studied through a novel integrated methodology across device, circuit and architectural levels. This integrated approach enables to study in detail the impact of physical parameter variation across all fabric layers. A final contribution of the article includes novel techniques to address this impact. The variability framework, while generic, is explored extensively on the Nanoscale Application Specific Integrated Circuits (NASICs) nanowire fabric. For variation of σ = 10 in key physical parameters, the on current is found to vary by up to 3.5X. Circuit-level delay shows up to 118% deviation from nominal. Monte Carlo simulations using an architectural simulator found 67% nanoprocessor chips to operate below nominal frequencies due to variation. New built-in variation mitigation and fault-tolerance schemes, leveraging redundancy, asymmetric delay paths and biased voting schemes, were developed and evaluated to mitigate these effects. They are shown to improve performance by up to 7.5X on a nanoscale processor design with variation, and improve performance in designs relying on redundancy for defect tolerance, without variation assumed. Techniques show up to 3.8X improvement in effective-yield performance products even at a high 12% defect rate. The suite of techniques provides a design space across key system-level metrics such as performance, yield and area.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W1989612329",
    "type": "article"
  },
  {
    "title": "Clock-Tree Synthesis with Methodology of Reuse in 3D-IC",
    "doi": "https://doi.org/10.1145/2567668",
    "publication_date": "2014-04-01",
    "publication_year": 2014,
    "authors": "Fu-Wei Chen; TingTing Hwang",
    "corresponding_authors": "",
    "abstract": "IP reuse methodology has been used extensively in SoC (system-on-chip) design. In this reuse methodology, while design and implementation costs are saved, manufacturing cost is not. To further reduce the cost, this reuse concept has been proposed at mask and die level in three-dimensional integrated circuits (3D-IC). In order to achieve manufacturing reuse, in this article, we propose a new methodology for designing a global clock tree in 3D-IC. The objective is to extend an existing clock tree in 2D IC to 3D IC, taking into consideration the wirelength, clock skew, and the number of TSVs. Compared with NNG- and 3D-MMM-based methods, our proposed method reduces the wirelength of the new die and the skew of the global 3D clock tree on average, 5.85% and 2.3%, and 76.92% and 48.7%, respectively. In more than two die design, the average improvements of the wirelength and clock skew of our method as compared with the 3D-MMM-based method are 4.23% and 46.84%, respectively.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W1992238982",
    "type": "article"
  },
  {
    "title": "ProWATCh",
    "doi": "https://doi.org/10.1145/2753762",
    "publication_date": "2015-09-21",
    "publication_year": 2015,
    "authors": "Milan Patnaik; R Chidhambaranathan; Chirag Garg; Arnab Roy; V.R. Devanathan; Shankar Balachandran; V. Kamakoti",
    "corresponding_authors": "",
    "abstract": "With the increase in process variations and diversity in workloads, it is imperative to holistically explore optimization techniques for power and temperature from the circuit layer right up to the compiler/ operating system (OS) layer. This article proposes one such holistic technique, called proactive workload aware temperature management framework for low-power chip multi-processors (ProWATCh). At the compiler level ProWATCh includes two techniques: (1) a novel compiler design for estimating the architectural parameters of a task at compile time; and (2) a model-based technique for dynamic estimation of architectural parameters at runtime. At the OS level ProWATCh integrates two techniques: (1) a workload- and temperature-aware process manager for dynamic distribution of tasks to different cores; and (2) a model predictive control-based task scheduler for generating the efficient sequence of task execution. At the circuit level ProWATCh implements either of two techniques: (1) a workload-aware voltage manager for dynamic supply and body bias voltage assignment for a given frequency in processors that support adaptive body bias (ABB); or (2) a workload-aware frequency governor for efficient assignment of upper and lower frequency bounds for frequency scaling in processors that do not support an ABB. Employing ProWATCh (with voltage manager) on an ABB-compatible 3D OpenSPARC architecture using MiBench benchmarks resulted in an average 18% ( 19ˆC ) reduction in peak temperature. Evaluating ProWATCh on an existing quad-core Intel Corei7 processor with frequency governor alone (as the processor does not support an ABB interface) resulted in 10% ( 8ˆC ) reduction in peak temperature when compared to what was obtained using the native Linux 3.0 completely fair scheduler (CFS). To study the effectiveness of the proposed framework across benchmark suites, ProWATCh was evaluated on a quad-core Intel Corei7 processor using CPU SPEC 2006 benchmarks which resulted in 7ˆC reduction in peak temperature as compared to the native Linux 3.0 CFS.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2004019670",
    "type": "article"
  },
  {
    "title": "Low-Power Architecture for Epileptic Seizure Detection Based on Reduced Complexity DWT",
    "doi": "https://doi.org/10.1145/2180878.2180882",
    "publication_date": "2012-06-01",
    "publication_year": 2012,
    "authors": "Mrigank Sharad; Sumeet Kumar Gupta; Shriram Raghunathan; Pedro P. Irazoqui; Kaushik Roy",
    "corresponding_authors": "",
    "abstract": "In this article, we present a low-power, user-programmable architecture for discrete wavelet transform (DWT) based epileptic seizure detection algorithm. A simplified, low-pass filter (LPF)-only-DWT technique is employed in which energy contents of different frequency bands are obtained by subtracting quasi-averaged, consecutive LPF outputs. Training phase is used to identify the range of critical DWT coefficients that are in turn used to set patient-specific system level parameters for minimizing power consumption. The proposed optimizations allow the design to work at significantly lower power in the normal operation mode. The system has been tested on neural data obtained from kainate-treated rats. The design was implemented in TSMC-65nm technology and consumes less than 550-nW power at 250-mV supply.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2147891535",
    "type": "article"
  },
  {
    "title": "Architecture and Implementation of Dynamic Parallelism, Voltage and Frequency Scaling (PVFS) on CGRAs",
    "doi": "https://doi.org/10.1145/2700250",
    "publication_date": "2015-04-27",
    "publication_year": 2015,
    "authors": "Syed M. A. H. Jafri; Ozan Ozbag; Nasim Farahini; Kolin Paul; Ahmed Hemani; Juha Plosila; Hannu Tenhunen",
    "corresponding_authors": "",
    "abstract": "In the era of platforms hosting multiple applications with arbitrary performance requirements, providing a worst-case platform-wide voltage/frequency operating point is neither optimal nor desirable. As a solution to this problem, designs commonly employ dynamic voltage and frequency scaling (DVFS). DVFS promises significant energy and power reductions by providing each application with the operating point (and hence the performance) tailored to its needs. To further enhance the optimization potential, recent works interleave dynamic parallelism with conventional DVFS. The induced parallelism results in performance gains that allow an application to lower its operating point even further (thereby saving energy and power consumption). However, the existing works employ costly dedicated hardware (for synchronization) and rely solely on greedy algorithms to make parallelism decisions. To efficiently integrate parallelism with DVFS, compared to state-of-the-art, we exploit the reconfiguration (to reduce DVFS synchronization overheads) and enhance the intelligence of the greedy algorithm (to make optimal parallelism decisions). Specifically, our solution relies on dynamically reconfigurable isolation cells and an autonomous parallelism, voltage, and frequency selection algorithm. The dynamically reconfigurable isolation cells reduce the area overheads of DVFS circuitry by configuring the existing resources to provide synchronization. The autonomous parallelism, voltage, and frequency selection algorithm ensures high power efficiency by combining parallelism with DVFS. It selects that parallelism, voltage, and frequency trio which consumes minimum power to meet the deadlines on available resources. Synthesis and simulation results using various applications/algorithms (WLAN, MPEG4, FFT, FIR, matrix multiplication) show that our solution promises significant reduction in area and power consumption (23% and 51% ) compared to state-of-the-art.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2161607031",
    "type": "article"
  },
  {
    "title": "Accuracy and Resiliency of Analog Compute-in-Memory Inference Engines",
    "doi": "https://doi.org/10.1145/3502721",
    "publication_date": "2022-03-10",
    "publication_year": 2022,
    "authors": "Zhe Wan; Tianyi Wang; Yiming Zhou; Subramanian S. Iyer; Vwani Roychowdhury",
    "corresponding_authors": "",
    "abstract": "Recently, analog compute-in-memory (CIM) architectures based on emerging analog non-volatile memory (NVM) technologies have been explored for deep neural networks (DNNs) to improve scalability, speed, and energy efficiency. Such architectures, however, leverage charge conservation, an operation with infinite resolution, and thus are susceptible to errors. Thus, the inherent stochasticity in any analog NVM used to execute DNNs, will compromise performance. Several reports have demonstrated the use of analog NVM for CIM in a limited scale. It is unclear whether the uncertainties in computations will prohibit large-scale DNNs. To explore this critical issue of scalability, this article first presents a simulation framework to evaluate the feasibility of large-scale DNNs based on CIM architecture and analog NVM. Simulation results show that DNNs trained for high-precision digital computing engines are not resilient against the uncertainty of the analog NVM devices. To avoid such catastrophic failures, this article introduces the analog bi-scale representation for the DNN, and the Hessian-aware Stochastic Gradient Descent training algorithm to enhance the inference accuracy of trained DNNs. As a result of such enhancements, DNNs such as Wide ResNets for CIFAR-100 image recognition problem are demonstrated to have significant performance improvements in accuracy without adding cost to the inference hardware .",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W3047524421",
    "type": "article"
  },
  {
    "title": "Quantum-Logic Synthesis of Hermitian Gates",
    "doi": "https://doi.org/10.1145/2794263",
    "publication_date": "2015-12-28",
    "publication_year": 2015,
    "authors": "Mona Arabzadeh; Mahboobeh Houshmand; Mehdi Sedighi; Morteza Saheb Zamani",
    "corresponding_authors": "",
    "abstract": "In this article, the problem of synthesizing a general Hermitian quantum gate into a set of primary quantum gates is addressed. To this end, an extended version of the Jacobi approach for calculating the eigenvalues of Hermitian matrices in linear algebra is considered as the basis of the proposed synthesis method. The quantum circuit synthesis method derived from the Jacobi approach and its optimization challenges are described. It is shown that the proposed method results in multiple-control rotation gates around the y axis, multiple-control phase shift gates, multiple-control NOT gates, and a middle diagonal Hermitian matrix, which can be synthesized to multiple-control Pauli Z gates. Using the proposed approach, it is shown how multiple-control U gates, where U is a single-qubit Hermitian quantum gate, can be implemented using a linear number of elementary gates in terms of circuit lines with the aid of one auxiliary qubit in an arbitrary state.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W3124967330",
    "type": "article"
  },
  {
    "title": "A Quasi-digital QPSK Modulator Design for Biomedical Devices",
    "doi": "https://doi.org/10.1145/3465379",
    "publication_date": "2022-03-10",
    "publication_year": 2022,
    "authors": "Dawei Li; Yang Zhou; Shaopin Chen; Xiaowei Xu",
    "corresponding_authors": "",
    "abstract": "For the biomedical transceiver, the data transmission is often asymmetric. At the downlink, the transceiver only needs to receive a simple command to control the operation of the external device, and the receiving data rate is low, about hundreds of Kb/s. However, data collected by external devices such as temperature sensors, pressure sensors, or cameras are often very large, which results in a transmitting data rate of several Mb/s. Therefore, a high energy-efficient modulator is needed. Compared with conventional digital modulator, analog modulator circuits have demonstrated superior energy efficiency at high data rates. This article presents a quasi-digital quadrature phase-shift keying (QPSK) modulator design realized by pure analog circuits which follows a logic design flow. The simulation results show that the system can generate a stable carrier of 64 MHz that meets intra-body communications (IBCs) requirements with a data transmission rate of 10 Mb/s. When the signal-to-noise ratios (SNRs) of the Gaussian channel is 14 dB, it can still maintain a bit error rate (BER) below 10 4 .",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4220665172",
    "type": "article"
  },
  {
    "title": "All-spin PUF: An Area-efficient and Reliable PUF Design with Signature Improvement for Spin-transfer Torque Magnetic Cell-based All-spin Circuits",
    "doi": "https://doi.org/10.1145/3517811",
    "publication_date": "2022-03-25",
    "publication_year": 2022,
    "authors": "Kangwei Xu; Dongrong Zhang; Qiang Ren; Yuanqing Cheng; Patrick Girard",
    "corresponding_authors": "",
    "abstract": "Recently, spin-transfer torque magnetic cell (STT-mCell) has emerged as a promising spintronic device to be used in Computing-in-Memory (CIM) systems. However, it is challenging to guarantee the hardware security of STT-mCell-based all-spin circuits. In this work, we propose a novel Physical Unclonable Function (PUF) design for the STT-mCell-based all-spin circuit (All-Spin PUF) exploiting the unique manufacturing process variation (PV) on STT-mCell write latency. A methodology is used to select appropriate logic gates in the all-spin chip to generate a unique identification key. A linear feedback shift register (LFSR) initiates the All-Spin PUF and simultaneously generates a 64-bit signature at each clock cycle. Signature generation is stabilized using an automatic write-back technique. In addition, a masking scheme is applied for signature improvement. The uniqueness of the improved signature is 49.61%. With ± 20% supply voltage and 5°C to 105°C temperature variations, the All-Spin PUF shows a strong resiliency. In comparison with state-of-the-art PUFs, our approach can reduce hardware overhead effectively. Finally, the robustness of the All-Spin PUF against emerging modeling attacks is verified as well.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4220791916",
    "type": "article"
  },
  {
    "title": "A Cost-Effective Built-In Self-Test Mechanism for Post-Manufacturing TSV Defects in 3D ICs",
    "doi": "https://doi.org/10.1145/3517808",
    "publication_date": "2022-04-20",
    "publication_year": 2022,
    "authors": "Dilip Kumar Maity; Surajit Kumar Roy; Chandan Giri",
    "corresponding_authors": "",
    "abstract": "Three-Dimensional Integrated Circuit (3D IC) based on Through-Silicon-Via (TSV) has brought a drastic change in IC technology. Since TSVs connect different layers of 3D stacks, their proper functioning is an essential prerequisite for system operation. Therefore, testing of TSV is essential for 3D IC. In this article, we propose a cost-effective Built-In Self-Test (BIST) method to test the TSVs of a 3D IC. The test method aims at identifying single and multiple defective TSVs using low test time with small hardware overhead. Further, we introduce a BIST partitioning scheme to reduce the test time and hardware overhead for many TSVs. We also present EBIST, an extended-BIST, to enhance BIST reliability with the least hardware cost. The time cycle needed for testing is calculated and compared with previously proposed methods. The simulation result shows that the proposed BIST reduces the test time by 87% compared to prior works. Moreover, the approach yields reduced area as compared to existing test architecture.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4224241520",
    "type": "article"
  },
  {
    "title": "B-open Defect: A Novel Defect Model in FinFET Technology",
    "doi": "https://doi.org/10.1145/3564244",
    "publication_date": "2022-09-16",
    "publication_year": 2022,
    "authors": "Freddy Forero; Victor Champac; M. Renovell",
    "corresponding_authors": "",
    "abstract": "This article proposes an electrical analysis of a new defect mechanism, to be named as b-open defect, which may occur in nanometer technologies due to the use of the Self-Aligned Double Patterning (SADP) technique. In metal lines making use of the SADP technique, a single dust particle may cause the simultaneous occurrence of a bridge defect and an open defect. When the two defects impact the same gates, the electrical effects of the bridge and the open combine and exhibit a new specific electrical behavior; we call this new defect behavior a b-open. As a consequence, existing test generation methodologies may miss defect detection. The electrical behavior of the b-open defect is first analyzed graphically and then validated through extensive SPICE simulations. The test pattern conditions to detect the b-open defect are finally determined, and it is shown that the b-open defect requires specific test generation.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4296058455",
    "type": "article"
  },
  {
    "title": "Silicon-correlated Simulation Methodology of EM Side-channel Leakage Analysis",
    "doi": "https://doi.org/10.1145/3568957",
    "publication_date": "2022-10-20",
    "publication_year": 2022,
    "authors": "Kazuki Monta; Lang Lin; Jimin Wen; Harsh Shrivastav; Calvin Chow; Hua Chen; Joao Geada; Sreeja Chowdhury; Nitin Pundir; Norman Chang; Makoto Nagata",
    "corresponding_authors": "",
    "abstract": "Cryptography hardware is vulnerable to side-channel (SC) attacks on power supply current flow and electromagnetic (EM) emission. This article proposes simulation-based power and EM side-channel leakage analysis (SCLA) techniques on a cryptographic integrated circuit (IC) chip in system level assembly. SCLA measures SC leakage metrics including T-score, SC leakage score, and the number of measurement traces to disclosure, leveraged by a secure system-on-chip design flow toward SC attack resiliency and SC leakage sign off. Power SCLA features the tracking of security sensitive registers within cryptographic logic paths and the automatic assignments of probe points on associated physical power nets. Power supply current traces are efficiently simulated for the large set of input payloads, with direct vector-based and vector-less random switching controls. EM SCLA evaluates magnetic fields created by every piece of metal wiring in metal stacks where power supply current of cryptographic processing flows. The EM emission and EM SCLA from the backside Si surface of an IC chip in flip-chip packaging are experimentally examined with a 0.13 μm test chip. The proposed simulation-based SCLA exhibits the SC leakage metrics of on-chip location and direction dependency as accurately as in the measurements.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4306875474",
    "type": "article"
  },
  {
    "title": "Eternal-thing 2.0: Analog-Trojan-resilient Ripple-less Solar Harvesting System for Sustainable IoT",
    "doi": "https://doi.org/10.1145/3575800",
    "publication_date": "2022-12-12",
    "publication_year": 2022,
    "authors": "Saswat Kumar Ram; Sauvagya Ranjan Sahoo; Banee Bandana Das; Kamalakanta Mahapatra; Saraju P. Mohanty",
    "corresponding_authors": "",
    "abstract": "Recently, harvesting natural energy is gaining more attention than other conventional approaches for sustainable IoT. System on chip power requirement for the internet of things (IoT) and generating higher voltages on chip is a massive challenge for on-chip peripherals and systems. In this article, an on-chip reliable energy-harvesting system (EHS) is designed for IoT with an inductor-free methodology. The control section monitors the computational load and the recharging of the battery/super-capacitor. An efficient maximum power point tracking algorithm is also used to avoid quiescent power consumption. The reliability of the proposed EHS is improved by using an aging tolerant ring oscillator. The effect of Trojan on the performance of energy-harvesting system is analyzed, and proper detection and mitigation mechanism is proposed. Finally, the proposed ripple mitigation techniques further improves the performance of the aging sensor. The proposed EHS is designed and simulated in CMOS 90-nm technology. The output voltage is in the range of 3–3.55 V with an input 1–1.5 V with a power throughput of 0–22 μW. The EHS consumes power under the ultra-low-power requirements of IoT smart nodes.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4311159357",
    "type": "article"
  },
  {
    "title": "PUF-Based Digital Money with Propagation-of-Provenance and Offline Transfers Between Two Parties",
    "doi": "https://doi.org/10.1145/3663676",
    "publication_date": "2024-05-25",
    "publication_year": 2024,
    "authors": "Benjamin Bean; Cyrus Minwalla; Eirini Eleni Tsiropoulou; Jim Plusquellic",
    "corresponding_authors": "",
    "abstract": "Building on prior concepts of electronic money (eCash), we introduce a digital currency where a physical unclonable function (PUF) engenders devices with the twin properties of being verifiably enrolled as a member of a legitimate set of eCash devices and of possessing a hardware-based root-of-trust. A hardware-obfuscated secure enclave (HOSE) is proposed as a means of enabling a PUF-based propagation-of-provenance (POP) mechanism, which allows eCash tokens ( eCt ) to be securely signed and validated by recipients without incurring any third-party dependencies at transfer time. The POP scheme establishes a chain of custody starting with token creation, extending through multiple bilateral in-field transactions, and culminating in redemption at the token-issuing authority. A lightweight mutual-zero-trust (MZT) authentication protocol establishes a secure channel between any two fielded devices. The POP and MZT protocols, in combination with the HOSE, enable transitivity and anonymity of eCt transfers between online and offline devices.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4399021598",
    "type": "article"
  },
  {
    "title": "Genetic Cache: A Machine Learning Approach to Designing DRAM Cache Controllers in HBM Systems",
    "doi": "https://doi.org/10.1145/3676966",
    "publication_date": "2024-07-08",
    "publication_year": 2024,
    "authors": "Morteza Amouzegar; Morteza Rezaalipour; Masoud Dehyadegari",
    "corresponding_authors": "",
    "abstract": "DRAM memory controller plays a critical role in maximizing the performance of high bandwidth memory by efficiently managing data transfers between the CPU and the memory modules. Thus, they are suitable for low-power data-intensive applications. However, the complexity of DRAM command scheduling combined with tag management overheads in the cache makes the design of in-package cache controllers significantly challenging. Traditional memory controllers often face challenges with static, inflexible access scheduling designed for general applications, leading to suboptimal performance in dynamic environments. On the other hand, while some advanced controllers employing reinforcement learning offer adaptability to workload fluctuations, they tend to introduce hardware complexity and incur longer training latencies. Our approach aims to design low-power and efficient DRAM cache controllers using a machine learning model that dynamically adjusts to workload changes with optimized hardware efficiency and reduced training time. Therefore, we propose a machine learning approach to design low-power and efficient DRAM cache controllers that will leverage the trained model to produce optimal cache command schedules at runtime. The model considers several conditions for each request queue and chooses the best response among the options. The simulation results show the superiority of our proposed design over the previous algorithms in a set of twelve data-intensive applications; our model is able to improve the performance by up to 40% in some cases and an average of 15% in performance and 10% in power consumption.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4400412942",
    "type": "article"
  },
  {
    "title": "Breaking On-Chip Communication Anonymity using Flow Correlation Attacks",
    "doi": "https://doi.org/10.1145/3677034",
    "publication_date": "2024-07-10",
    "publication_year": 2024,
    "authors": "Hansika Weerasena; Prabhat Mishra",
    "corresponding_authors": "",
    "abstract": "Network-on-chip (NoC) is widely used to facilitate communication between components in sophisticated system-on-chip (SoC) designs. Security of the on-chip communication is crucial because exploiting any vulnerability in shared NoC would be a goldmine for an attacker that puts the entire computing infrastructure at risk. We investigate the security strength of existing anonymous routing protocols in NoC architectures, making two pivotal contributions. Firstly, we develop and perform a machine learning (ML)-based flow correlation attack on existing anonymous routing techniques in NoC systems, revealing that they provide only packet-level anonymity. Secondly, we propose a novel, lightweight anonymous routing protocol featuring outbound traffic tunneling and traffic obfuscation. This protocol is designed to provide robust defense against ML-based flow correlation attacks, ensuring both packet-level and flow-level anonymity. Experimental evaluation using both real and synthetic traffic demonstrates that our proposed attack successfully deanonymizes state-of-the-art anonymous routing in NoC architectures with high accuracy (up to 99%) for diverse traffic patterns. It also reveals that our lightweight anonymous routing protocol can defend against ML-based attacks with minor hardware and performance overhead.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4400492874",
    "type": "article"
  },
  {
    "title": "Applications and Challenges of AI in PCB X-ray Inspection: A Comprehensive Study",
    "doi": "https://doi.org/10.1145/3703457",
    "publication_date": "2024-11-12",
    "publication_year": 2024,
    "authors": "Antika Roy; Md Mahfuz Al Hasan; Shajib Ghosh; Nitin Varshney; Jake Julia; Reza Forghani; Navid Asadizanjani",
    "corresponding_authors": "",
    "abstract": "As printed circuit boards (PCBs) continue to evolve in complexity and miniaturization, the demand for robust and efficient inspection techniques has become paramount in ensuring the quality and reliability of electronic devices. The application of machine learning and deep learning techniques has revolutionized PCB inspection in recent years, enabling the ability to automate and improve numerous elements of the process. In this paper, a comprehensive analysis is performed on the applications and challenges of artificial intelligence (AI), encompassing techniques of deep learning and machine learning, in the domain of PCB X-ray scrutiny. The main focus of this research centers around defect detection, identification of components and layers, deep learning algorithms for image reconstruction, as well as the identification of defects and features in advanced packaging. This study examines the current cutting-edge advancements in each of these areas, closely examining the existing methodologies and technologies employed. Furthermore, it delves into the limitations and challenges inherent in PCB X-ray inspection, such as the unavailability of data, computational demands, and the interpretability of models. In addition, this article offers prospective insights and presents promising avenues like application of generative adversarial networks and deep learning reconstruction methods for future exploration.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4404276109",
    "type": "article"
  },
  {
    "title": "SRLL: Improving Security and Reliability with User-Defined Constraint-Aware Logic Locking",
    "doi": "https://doi.org/10.1145/3709139",
    "publication_date": "2024-12-23",
    "publication_year": 2024,
    "authors": "Mona Hashemi; Siamak Mohammadi; Trevor E. Carlson",
    "corresponding_authors": "",
    "abstract": "As chip fabrication costs rise, designers have shifted to a fabless and outsourced development model which opens up the possibility for IP piracy. To address these challenges, logic locking methods modify designs to limit functionality to authorized users that present a valid secret key. However, existing techniques often face limitations in resilience against advanced attacks and do not provide solutions to achieve user-defined constraints and goals. In this paper, we propose SRLL, a user-defined constraint-aware logic locking technique that aims to improve the security and reliability of hardware designs. SRLL bridges the gap between exact and approximate attacks and allows the user to balance the resiliency against satisfiability-based, machine-learning-based, and constant propagation attacks while securing design constraints provided by the user. To enable this, we limit the locking functions to the non-critical path components and insert key gates at specific nodes, introducing a new set of critical parameters specifically designed to prevent target attacks. Finally, we obfuscate the netlist to hide inserted key gates and locking functions. Results show that SRLL maintains strong resiliency by exponentially increasing the required number of distinguishing input patterns, the complexity of finding these patterns, and adding sufficient structural complexity to the design. We evaluate SRLL using ISCAS’85, MCNC’91, and ITC’99 benchmarks, demonstrating resiliency with low overhead against modern attacks, including SAT, AppSAT, OMLA, SAIL, and SCOPE.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4405724478",
    "type": "article"
  },
  {
    "title": "Design for dependability in emerging technologies",
    "doi": "https://doi.org/10.1145/1265949.1265952",
    "publication_date": "2007-07-01",
    "publication_year": 2007,
    "authors": "Lucian Prodan; Mihai Udrescu; Oana Boncalo; Mircea Vlăduţiu",
    "corresponding_authors": "",
    "abstract": "As current microelectronics will reach their physical limits within the foreseeable future, emerging technologies may offer a solution for maintaining the trends to increase computing performance. Biologically-inspired and quantum computing represent two emerging technology vectors for novel computing architectures within nanoelectronics. However, potential benefits will come at the cost of increased device sensitivity to the surrounding environment. This article provides a dependability perspective over these technologies from a designer's standpoint. Maintaining or increasing the dependability of unconventional computational processes is discussed in two different contexts, a bio-inspired computing architecture (the Embryonics project) and a quantum computational architecture (the QUERIST project).",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2070515561",
    "type": "article"
  },
  {
    "title": "A self-organizing defect tolerant SIMD architecture",
    "doi": "https://doi.org/10.1145/1265949.1265956",
    "publication_date": "2007-07-01",
    "publication_year": 2007,
    "authors": "Jaidev P. Patwardhan; Chris Dwyer; Alvin R. Lebeck",
    "corresponding_authors": "",
    "abstract": "The continual decrease in transistor size (through either scaled CMOS or emerging nanotechnologies) promises to usher in an era of tera to peta-scale integration but with increasing defects. Regardless of fabrication methodology (top-down or bottom-up), defect-tolerant architectures are necessary to exploit the full potential of future increased device densities. This article explores a defect-tolerant SIMD architecture (SOSA) that self-organizes a large number of limited capability nodes with high defect rates into SIMD processing elements. Simulation results show that SOSA matches or exceeds the performance of conventional systems for moderate to large problems, but with lower power density.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2146655555",
    "type": "article"
  },
  {
    "title": "Hardware Trojan Attack in Embedded Memory",
    "doi": "https://doi.org/10.1145/3422353",
    "publication_date": "2021-01-06",
    "publication_year": 2021,
    "authors": "Xinmu Wang; Tamzidul Hoque; Abhishek Basak; Robert Karam; Wei Hu; Maoyuan Qin; Dejun Mu; Swarup Bhunia",
    "corresponding_authors": "",
    "abstract": "Static Random Access Memory (SRAM) is a core technology for building computing hardware, including cache memory, register files and field programmable gate array devices. Hence, SRAM reliability is essential to guarantee dependable computing. While significant research has been conducted to develop automated test algorithms for detecting manufacture-induced SRAM faults, they cannot ensure detection of faults deliberately implemented in the SRAM array by untrusted parties in the integrated circuit development flow. Indeed, such hardware Trojan attacks represent an emerging security threat. While a growing body of research addresses Trojan designs in logic circuits, little research has explored hardware Trojan attacks in embedded memory arrays [20]. In this article, we propose a new class of hardware Trojans targeting embedded SRAM arrays. The Trojans are designed to evade industry standard post-manufacturing tests while enabling attacks targeting various system hardware components during deployment. Transistor-level simulation results demonstrate minimal impact on SRAM power, performance, and stability while Trojans are not activated. We also prove the feasibility of Trojan insertion in foundries by showing the proposed layouts that preserve the SRAM cell footprint and incur zero silicon area overhead. Finally, we elaborate on several system-level attacks that can leverage these Trojans to compromise security and privacy.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W3119390090",
    "type": "article"
  },
  {
    "title": "multiPULPly",
    "doi": "https://doi.org/10.1145/3432815",
    "publication_date": "2021-04-15",
    "publication_year": 2021,
    "authors": "Adi Eliahu; Ronny Ronen; Pierre‐Emmanuel Gaillardon; Shahar Kvatinsky",
    "corresponding_authors": "",
    "abstract": "Computationally intensive neural network applications often need to run on resource-limited low-power devices. Numerous hardware accelerators have been developed to speed up the performance of neural network applications and reduce power consumption; however, most focus on data centers and full-fledged systems. Acceleration in ultra-low-power systems has been only partially addressed. In this article, we present multiPULPly, an accelerator that integrates memristive technologies within standard low-power CMOS technology, to accelerate multiplication in neural network inference on ultra-low-power systems. This accelerator was designated for PULP, an open-source microcontroller system that uses low-power RISC-V processors. Memristors were integrated into the accelerator to enable power consumption only when the memory is active, to continue the task with no context-restoring overhead, and to enable highly parallel analog multiplication. To reduce the energy consumption, we propose novel dataflows that handle common multiplication scenarios and are tailored for our architecture. The accelerator was tested on FPGA and achieved a peak energy efficiency of 19.5 TOPS/W, outperforming state-of-the-art accelerators by 1.5× to 4.5×.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W3156371026",
    "type": "article"
  },
  {
    "title": "CLU",
    "doi": "https://doi.org/10.1145/3427472",
    "publication_date": "2021-04-15",
    "publication_year": 2021,
    "authors": "Palash Das; Hemangee K. Kapoor",
    "corresponding_authors": "",
    "abstract": "Convolutional/Deep Neural Networks (CNNs/DNNs) are rapidly growing workloads for the emerging AI-based systems. The gap between the processing speed and the memory-access latency in multi-core systems affects the performance and energy efficiency of the CNN/DNN tasks. This article aims to alleviate this gap by providing a simple and yet efficient near-memory accelerator-based system that expedites the CNN inference. Towards this goal, we first design an efficient parallel algorithm to accelerate CNN/DNN tasks. The data is partitioned across the multiple memory channels (vaults) to assist in the execution of the parallel algorithm. Second, we design a hardware unit, namely the convolutional logic unit (CLU), which implements the parallel algorithm. To optimize the inference, the CLU is designed, and it works in three phases for layer-wise processing of data. Last, to harness the benefits of near-memory processing (NMP), we integrate homogeneous CLUs on the logic layer of the 3D memory, specifically the Hybrid Memory Cube (HMC). The combined effect of these results in a high-performing and energy-efficient system for CNNs/DNNs. The proposed system achieves a substantial gain in the performance and energy reduction compared to multi-core CPU- and GPU-based systems with a minimal area overhead of 2.37%.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W3156590100",
    "type": "article"
  },
  {
    "title": "Hardware Trojan Horse Detection through Improved Switching of Dormant Nets",
    "doi": "https://doi.org/10.1145/3439951",
    "publication_date": "2021-05-11",
    "publication_year": 2021,
    "authors": "Tapobrata Dhar; Surajit Kumar Roy; Chandan Giri",
    "corresponding_authors": "",
    "abstract": "Covert Hardware Trojan Horses (HTH) introduced by malicious attackers during the fabless manufacturing process of integrated circuits (IC) have the potential to cause malignant functions within the circuit. This article employs a Design-for-Security technique to detect any HTHs present in the circuit by inserting tri-state buffers (TSB) in the ICs that inject the internal nets with weighted logic values during the test phase. This increases the transitions in the logic values of the nets within the IC, thereby stimulating any inserted HTH circuits. The TSBs are efficiently inserted in the IC considering various circuit parameters and testability measures to bolster the transitions in logic values of the nets throughout the IC while minimising the area overhead. Simulation results show a significant increase in transitions in logic values within HTH triggers using this method, thus aiding in their detection through side-channel analysis or direct activation of the payload.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W3161389869",
    "type": "article"
  },
  {
    "title": "Architecting for Artificial Intelligence with Emerging Nanotechnology",
    "doi": "https://doi.org/10.1145/3445977",
    "publication_date": "2021-07-31",
    "publication_year": 2021,
    "authors": "Sourabh Kulkarni; Sachin Bhat; Csaba Andras Moritz",
    "corresponding_authors": "",
    "abstract": "Artificial Intelligence is becoming ubiquitous in products and services that we use daily. Although the domain of AI has seen substantial improvements over recent years, its effectiveness is limited by the capabilities of current computing technology. Recently, there have been several architectural innovations for AI using emerging nanotechnology. These architectures implement mathematical computations of AI with circuits that utilize physical behavior of nanodevices purpose-built for such computations. This approach leads to a much greater efficiency vs. software algorithms running on von Neumann processors or CMOS architectures, which emulate the operations with transistor circuits. In this article, we provide a comprehensive survey of these architectural directions and categorize them based on their contributions. Furthermore, we discuss the potential offered by these directions with real-world examples. We also discuss major challenges and opportunities in this field.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W3193877133",
    "type": "article"
  },
  {
    "title": "Towards Compact Modeling of Noisy Quantum Computers: A Molecular-Spin-Qubit Case of Study",
    "doi": "https://doi.org/10.1145/3474223",
    "publication_date": "2021-09-29",
    "publication_year": 2021,
    "authors": "Mario Cignoni; Giovanni Amedeo Cirillo; Giovanna Turvani; Mariagrazia Graziano; Maurizio Zamboni",
    "corresponding_authors": "",
    "abstract": "Classical simulation of Noisy Intermediate Scale Quantum computers is a crucial task for testing the expected performance of real hardware. The standard approach, based on solving Schrödinger and Lindblad equations, is demanding when scaling the number of qubits in terms of both execution time and memory. In this article, attempts in defining compact models for the simulation of quantum hardware are proposed, ensuring results close to those obtained with standard formalism. Molecular Nuclear Magnetic Resonance quantum hardware is the target technology, where three non-ideality phenomena—common to other quantum technologies—are taken into account: decoherence, off-resonance qubit evolution, and undesired qubit-qubit residual interaction. A model for each non-ideality phenomenon is embedded into a MATLAB simulation infrastructure of noisy quantum computers. The accuracy of the models is tested on a benchmark of quantum circuits, in the expected operating ranges of quantum hardware. The corresponding outcomes are compared with those obtained via numeric integration of the Schrödinger equation and the Qiskit’s QASMSimulator. The achieved results give evidence that this work is a step forward towards the definition of compact models able to provide fast results close to those obtained with the traditional physical simulation strategies, thus paving the way for their integration into a classical simulator of quantum computers.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W3202796960",
    "type": "article"
  },
  {
    "title": "Stochastic CBRAM-Based Neuromorphic Time Series Prediction System",
    "doi": "https://doi.org/10.1145/2996193",
    "publication_date": "2017-02-09",
    "publication_year": 2017,
    "authors": "Cory Merkel; Dhireesha Kudithipudi; Manan Suri; Bryant Wysocki",
    "corresponding_authors": "",
    "abstract": "In this research, we present a Conductive-Bridge RAM (CBRAM)-based neuromorphic system which efficiently addresses time series prediction. We propose a new (i) voltage-mode, stochastic, multiweight synapse circuit based on experimental bi-stable CBRAM devices, (ii) a voltage-mode neuron circuit based on the concept of charge sharing, and (iii) an optimized training methodology powered by a stochastic implementation of the Least-Mean-Squares (SLMS) training rule. To validate the proposed design, we use time series prediction for short-term electrical load forecasting in smart grids. Our system is able to forecast hourly electrical loads with a mean accuracy of 96%, an estimated power dissipation of 15 μW, and area of 14.5 μm 2 at 65 nm CMOS technology.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2587559228",
    "type": "article"
  },
  {
    "title": "Optical Overlay NUCA",
    "doi": "https://doi.org/10.1145/3064833",
    "publication_date": "2017-05-21",
    "publication_year": 2017,
    "authors": "Eldhose Peter; Anuj Arora; Janibul Bashir; Akriti Bagaria; Smruti R. Sarangi",
    "corresponding_authors": "",
    "abstract": "In this article, we propose using optical networks-on-chip (NoCs) to design cache access protocols for large shared L2 caches. We observe that the problem is unique because optical networks have very low latency, and in principle all of the cache banks are very close to each other. A naive approach is to broadcast a request to a set of banks that might possibly contain the copy of a block. However, this approach is wasteful in terms of energy and bandwidth. Hence, we propose a set of novel schemes that create a set of virtual networks ( overlays ) of cache banks over a physical optical NoC. We search for a block inside each overlay using a combination of multicast and unicast messages. We first propose two simple protocols: TSI and Broadcast . The former uses unicast messages, and the latter uses multicast messages. We subsequently propose an improved scheme, OP_BCAST , that combines the best of TSI and Broadcast , and mainly uses restricted multicast messages. Then we propose a set of novel hardware structures for creating and managing overlays, for efficiently locating blocks in the overlay, and for implementing dynamically changing overlays with OP_BCAST . The performance of the TSI scheme is within 2% to 3% of a broadcast scheme, and it is faster than traditional schemes with electrical networks by 26%. Compared to the broadcast scheme, it reduces the number of accesses, and consequently the dynamic energy of the caches by 6% to 8%. OP_BCAST is 34% faster than the best solutions with copper-based NoCs; moreover, it reduces the dynamic energy for cache access by 33% compared to the TSI scheme.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2619867529",
    "type": "article"
  },
  {
    "title": "An Accuracy Tunable Non-Boolean Co-Processor Using Coupled Nano-Oscillators",
    "doi": "https://doi.org/10.1145/3094263",
    "publication_date": "2017-09-29",
    "publication_year": 2017,
    "authors": "Neel Gala; Sarada Krithivasan; Wei-Yu Tsai; Xueqing Li; Vijaykrishnan Narayanan; V. Kamakoti",
    "corresponding_authors": "",
    "abstract": "As we enter an era witnessing the closer end of Dennard scaling, where further reduction in power supply-voltage to reduce power consumption becomes more challenging in conventional systems, a goal of developing a system capable of performing large computations with minimal area and power overheads needs more optimization aspects. A rigorous exploration of alternate computing techniques, which can mitigate the limitations of Complementary Metal-Oxide Semiconductor (CMOS) technology scaling and conventional Boolean systems, is imperative. Reflecting on these lines of thought, in this article we explore the potential of non-Boolean computing employing nano-oscillators for performing varied functions. We use a two coupled nano-oscillator as our basic computational model and propose an architecture for a non-Boolean coupled oscillator based co-processor capable of executing certain functions that are commonly used across a variety of approximate application domains. The proposed architecture includes an accuracy tunable knob, which can be tuned by the programmer at runtime. The functionality of the proposed co-processor is verified using a soft coupled oscillator model based on Kuramoto oscillators. The article also demonstrates how real-world applications such as Vector Quantization, Digit Recognition, Structural Health Monitoring, and the like, can be deployed on the proposed model. The proposed co-processor architecture is generic in nature and can be implemented using any of the existing modern day nano-oscillator technologies such as Resonant Body Transistors (RBTs), Spin-Torque Nano-Oscillators (STNOs), and Metal-Insulator Transition (MITs) . In this article, we perform a validation of the proposed architecture using the HyperField Effect Transistor (FET) technology-based coupled oscillators, which provide improvements of up to 3.5× increase in clock speed and up to 10.75× and 14.12× reduction in area and power consumption, respectively, as compared to a conventional Boolean CMOS accelerator executing the same functions.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2756546217",
    "type": "article"
  },
  {
    "title": "Robust In-Field Testing of Digital Microfluidic Biochips",
    "doi": "https://doi.org/10.1145/3123586",
    "publication_date": "2017-09-21",
    "publication_year": 2017,
    "authors": "Sukanta Bhattacharjee; Debasis Mitra; Bhargab B. Bhattacharya",
    "corresponding_authors": "",
    "abstract": "Microfluidic technology offers vast promise for implementing biochemistry-on-chip with diverse applications to clinical diagnosis, genome analysis, drug design, and point-of-care testing. Among various types of fluid-chips, droplet-based digital microfluidic biochips (DMFBs), which consist of a patterned array of controllable electrodes, provide the advantage of programmability, ease of fluidic operations, and versatile droplet mobility. However, because of manufacturing or field defects, electrode degradation, or dielectric breakdown, these chips may suffer from incorrect fluidic behavior. Reliability of fluidic operations is of utmost concern in DMFBs that are used to perform safety-critical bio-protocols. Various methods are deployed to test these devices, either offline or being overlapped with bioassay operations (termed as concurrent or in-field testing). The main challenge of in-field testing lies in the fact that the test must run concurrently with the execution of the normal assay without hampering the correctness of the latter. In prior work, optimal testing for droplet mobility over all electrodes was formulated in terms of finding either a Hamiltonian path or a Eulerian path in an undirected graph that represents the electrode-adjacency structure. Although these models have been studied for offline testing, no such effort was made in the area of concurrent testing. In this work, we propose, for in-field application, an SAT-based modeling and solution approach to find an optimal test plan that can be used to check droplet movement across the boundary between every pair of adjacent electrodes, which is visited by the droplets of the ongoing assay. The proposed method is robust and determines a test solution successfully regardless of the cover assay that is being executed concurrently. Experiments on several real-life assays and other test cases demonstrate the effectiveness of the method with respect to test completion time.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2757187224",
    "type": "article"
  },
  {
    "title": "Statistical Optimization of FinFET Processor Architectures under PVT Variations Using Dual Device-Type Assignment",
    "doi": "https://doi.org/10.1145/3110714",
    "publication_date": "2017-09-21",
    "publication_year": 2017,
    "authors": "Ye Yu; Niraj K. Jha",
    "corresponding_authors": "",
    "abstract": "With semiconductor technology scaling to the 22nm node and beyond, fin field-effect transistor (FinFET) has started replacing complementary metal-oxide semiconductor (CMOS), thanks to its superior control of short-channel effects and much lower leakage current. However, process, supply voltage, and temperature (PVT) variations across the integrated circuit (IC) become worse with technology scaling. Thus, to analyze timing, leakage power, and dynamic power under PVT variations, statistical analysis/optimization techniques are more suitable than traditional static timing/power analysis and optimization counterparts. In this article, we propose a statistical optimization framework using dual device-type assignment at the architecture level under PVT variations that takes spatial correlations into account and leverages circuit-level statistical analysis techniques. To the best of our knowledge, this is the first work to study statistical optimization at the system level under PVT variations. Simulation results show that leakage power yield and dynamic power yield at the mean value of the baseline can be improved by up to 44.2% and 21.2%, respectively, with no loss in timing yield for a single-core processor and up to 43.0% and 50.0%, respectively, without any loss in timing yield for an 8-core chip multiprocessor (CMP), at little area overhead. Under the same (99.0%) power yield constraints, leakage power and dynamic power are reduced by up to 91.2% and 4.3%, respectively, for a single-core processor, and up to 44.6% and 12.5%, respectively, for an 8-core CMP, with no loss in timing yield. We also show that optimizations performed without taking module-to-module and core-to-core spatial correlations into account overestimate yield, establishing the importance of taking such correlations into account.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2757297807",
    "type": "article"
  },
  {
    "title": "Formalizing Modularization and Data Hiding in Synthetic Biology",
    "doi": "https://doi.org/10.1145/2667231",
    "publication_date": "2014-12-30",
    "publication_year": 2014,
    "authors": "Harold Fellermann; Maik Hadorn; Rudolf Marcel Füchslin; Natalio Krasnogor",
    "corresponding_authors": "",
    "abstract": "Biological systems employ compartmentalization and other co-localization strategies in order to orchestrate a multitude of biochemical processes by simultaneously enabling “data hiding” and modularization. This article presents recent research that embraces compartmentalization and co-location as an organizational programmatic principle in synthetic biological and biomimetic systems. In these systems, artificial vesicles and synthetic minimal cells are envisioned as nanoscale reactors for programmable biochemical synthesis and as chassis for molecular information processing. We present P systems, brane calculi, and the recently developed chemtainer calculus as formal frameworks providing data hiding and modularization and thus enabling the representation of highly complicated hierarchically organized compartmentalized reaction systems. We demonstrate how compartmentalization can greatly reduce the complexity required to implement computational functionality, and how addressable compartments permit the scaling-up of programmable chemical synthesis.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2029033363",
    "type": "article"
  },
  {
    "title": "iConn",
    "doi": "https://doi.org/10.1145/2700238",
    "publication_date": "2015-04-27",
    "publication_year": 2015,
    "authors": "Zhongqi Li; Nilanjan Goswami; Tao Li",
    "corresponding_authors": "",
    "abstract": "Recently, the graphics processing unit (GPU) has made significant progress as a general-purpose parallel processor. The CPU and GPU cooperate together to solve data-parallel and control-intensive real-world applications in an optimized fashion. For example, emerging heterogeneous computing architectures such as Intel Sandy Bridge and AMD Fusion integrate the functionality of the CPU and GPU in a single die. However, the single-die CPU-GPU heterogeneous computing architecture faces the challenge of tight budget of die area. The conventional homogenous interconnect fails to provide satisfactory performance by fully exploiting the given area budget in the heterogeneous processing era. In this article, we aim to implement an interconnect network within an area budget for a CPU-GPU heterogeneous computing architecture. We propose iConn, a 2D mesh-style on-chip heterogeneous communication infrastructure. In iConn, a set of GPU logical units such as the stream processors, the texture units, and the rendering output units form a computing unit (CU). Differing from conventional homogenous router design, iConn adopts nonuniform on-chip routers in order to meet the unique communication demands from each single CPU and CU. The routers can also dynamically allocate their buffers across all virtual channels (VCs) to meet the latency requirements of CPUs and CUs. Moreover, the memory controller scheduling algorithm is modified from traditional load-over-store scheduling in order to prioritize the traffic. Our simulation results show that iConn improves the performance of CPUs by 23.0% and CUs by 9.4%.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2046713096",
    "type": "article"
  },
  {
    "title": "A Synthesis Algorithm for 4-Bit Reversible Logic Circuits with Minimum Quantum Cost",
    "doi": "https://doi.org/10.1145/2629542",
    "publication_date": "2014-12-30",
    "publication_year": 2014,
    "authors": "Zhiqiang Li; Hanwu Chen; Xiaoyu Song; Marek Perkowski",
    "corresponding_authors": "",
    "abstract": "This article presents an algorithm which can quickly find the exact minimum solution to almost all of 4-bit reversible functions. We assume minimization of quantum cost (MQC). This algorithm is designed in the most memory-efficient way, or it will quickly run out of memory. Therefore, we construct the shortest coding of permutations, the topological compression and flexible data structures for the memory savings. First, hash tables are used for all 8-gate 4-bit circuits with the minimization of gate count (MGC) by using the GT library (with NOT, CNOT, Toffoli and Toffoli-4 gates). Second, we merge and split the hash tables, thus generating a single longer hash table for high-performance. Third, we synthesize these circuits with MQC by using the GTP library (with GT, Peres, and Inverted Peres gates) based on the hash table. Finally, according to the comparison of the QC of circuits, the algorithm can quickly converge for any 4-bit reversible circuit with MQC. By synthesizing all benchmark functions, in comparison with Szyprowski and Kerntopf [2011], the running time and QC are reduced up to 99.95% and 18.2%, respectively.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2072587295",
    "type": "article"
  },
  {
    "title": "Ultra-Low-Leakage and High-Performance Logic Circuit Design Using Multiparameter Asymmetric FinFETs",
    "doi": "https://doi.org/10.1145/2832913",
    "publication_date": "2016-03-15",
    "publication_year": 2016,
    "authors": "Sourindra Chaudhuri; Niraj K. Jha",
    "corresponding_authors": "",
    "abstract": "Recently, multigate field-effect transistors have started replacing traditional planar MOSFETs to keep pace with Moore’s Law in deep submicron technology. Among different multigate transistors, FinFETs have become the preferred choice of the semiconductor industry owing to low fabrication cost, superior performance, lower leakage, and design flexibility. The back and front gates of a FinFET can either be shorted or remain independent, leading to two modes of operation: Shorted-Gate (SG) and Independent-Gate (IG). For a given mode of operation, the physical parameters of the FinFET can either be symmetric or asymmetric in nature. In this article, for the first time, we analyze multiparameter asymmetric SG FinFETs and illustrate their potential for implementing logic gates and circuits that are both ultra-low-leakage and high-performance simultaneously. We restrict this work to SG devices because IG FinFETs (symmetric/asymmetric) suffer from severely degraded on-current, which makes them unattractive for high-performance designs. We first compare head-to-head all viable single- and multiparameter symmetric/asymmetric SG FinFETs. Among all such FinFETs, the traditional SG (which are symmetric in nature), Asymmetric Workfunction Shorted-Gate (AWSG), and Asymmetric Workfunction-Underlap Shorted-Gate (AWUSG) FinFETs show the most promise. We characterize these devices under process variations in gate length ( L G ), fin thickness ( T SI ), gate-oxide thickness ( T OX ), gate underlap ( L UN ), and gate-workfunction (Φ G ) as well as supply voltage ( V DD ) variations, followed by a gate-level leakage/delay analysis at different temperatures. Although AWSG FinFETs consume very low leakage power, they do suffer from performance degradation relative to SG FinFETs. Similarly, our study reveals that no other single-parameter asymmetric FinFET provides a good combination of low-power and high-performance design. We show that gates/circuits based on AWUSG FinFETs are faster, yet consume much less leakage power and less area than gates/circuits based on traditional SG FinFETs. We observe 53.4% (30.2%) maximum (average) reduction in total power at temperature T = 348 K while meeting the same delay constraint, with 14.2% (13.5%) reduction in area for AWUSG circuits relative to SG circuits. At T = 373 K , we see 68.6% (46.9%) maximum (average) reduction in total power.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2317716042",
    "type": "article"
  },
  {
    "title": "Reversible Synthesis of Symmetric Functions with a Simple Regular Structure and Easy Testability",
    "doi": "https://doi.org/10.1145/2894757",
    "publication_date": "2016-06-27",
    "publication_year": 2016,
    "authors": "Arighna Deb; Debesh K. Das; Hafizur Rahaman; Robert Wille; Rolf Drechsler; Bhargab B. Bhattacharya",
    "corresponding_authors": "",
    "abstract": "In this article, we introduce a novel method of synthesizing symmetric Boolean functions with reversible logic gates. In contrast to earlier approaches, the proposed technique deploys a simple, regular, and cascaded structure consisting of an array of Peres and CNOT gates, which results in significant reduction with respect to the quantum cost. However, the number of circuit inputs may increase slightly when such cascades are used. In order to reduce their number, we next propose a postsynthesis optimization phase that allows judicious reuse of circuit lines. In addition to offering a cost-effective synthesis methodology, the proposed reversible logic structure supports elegant testability properties. With respect to all single or partial missing gate faults (SMGFs and PMGFs), or repeated gate faults (RGFs) in such an n -input circuit module, we show that it admits a universal test set of constant cardinality (=3) for any value of n . Thus, considering both the cost and testability issues, this approach provides a superior option for synthesizing symmetric functions compared to existing designs.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2472068728",
    "type": "article"
  },
  {
    "title": "A Fault-Tolerant Ripple-Carry Adder with Controllable-Polarity Transistors",
    "doi": "https://doi.org/10.1145/2988234",
    "publication_date": "2016-12-01",
    "publication_year": 2016,
    "authors": "Hassan Ghasemzadeh Mohammadi; Pierre‐Emmanuel Gaillardon; Jian Zhang; Giovanni De Micheli; Ernesto Sánchez; M. Sonza Reorda",
    "corresponding_authors": "",
    "abstract": "This article first explores the effects of faults on circuits implemented with controllable-polarity transistors. We propose a new fault model that suits the characteristics of these devices, and we report the results of a SPICE-based analysis of the effects of faults on the behavior of some basic gates implemented with them. Hence, we show that the considered devices are able to intrinsically tolerate a rather high number of faults. We finally exploit this property to build a robust and scalable adder whose area, performance, and leakage power characteristics are improved by 15%, 18%, and 12%;, respectively, when compared to an equivalent FinFET solution at 22nm technology node.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2557793041",
    "type": "article"
  },
  {
    "title": "A Noninvasive Technique to Detect Authentic/Counterfeit SRAM Chips",
    "doi": "https://doi.org/10.1145/3597024",
    "publication_date": "2023-04-30",
    "publication_year": 2023,
    "authors": "B. M. S. Bahar Talukder; Farah Ferdaus; Md Tauhidur Rahman",
    "corresponding_authors": "",
    "abstract": "Many commercially available memory chips are fabricated worldwide in untrusted facilities. Therefore, a counterfeit memory chip can easily enter into the supply chain in different formats. Deploying these counterfeit memory chips into an electronic system can severely affect security and reliability domains because of their substandard quality, poor performance, and shorter lifespan. Therefore, a proper solution is required to identify counterfeit memory chips before deploying them in mission-, safety-, and security-critical systems. However, a single solution to prevent counterfeiting is challenging due to the diversity of counterfeit types, sources, and refinement techniques. Besides, the chips can pass initial testing and still fail while being used in the system. Furthermore, existing solutions focus on detecting a single counterfeit type (e.g., detecting recycled memory chips). This work proposes a framework that detects major counterfeit static random-access memory (SRAM) types by attesting/identifying the origin of the manufacturer. The proposed technique generates a single signature for a manufacturer and does not require any exhaustive registration/authentication process. We validate our proposed technique using 345 SRAM chips produced by major manufacturers. The silicon results show that the test scores ( F 1 score) of our proposed technique of identifying memory manufacturer and part-number are 93% and 71%, respectively.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W3185810800",
    "type": "article"
  },
  {
    "title": "Fusing In-storage and Near-storage Acceleration of Convolutional Neural Networks",
    "doi": "https://doi.org/10.1145/3597496",
    "publication_date": "2023-06-17",
    "publication_year": 2023,
    "authors": "Ikenna Okafor; Akshay Krishna Ramanathan; Nagadastagiri Challapalle; Zheyu Li; Vijaykrishnan Narayanan",
    "corresponding_authors": "",
    "abstract": "Video analytics has a wide range of applications and has attracted much interest over the years. While it can be both computationally and energy-intensive, video analytics can greatly benefit from in/near memory compute. The practice of moving compute closer to memory has continued to show improvements to performance and energy consumption and is seeing increasing adoption. Recent advancements in solid state drives (SSDs) have incorporated near memory Field Programmable Gate Arrays (FPGAs) with shared access to the drive’s storage cells. These near memory FPGAs are capable of running operations required by video analytic pipelines such as object detection and template matching. These operations are typically executed using Convolutional Neural Networks (CNNs). A CNN is composed of multiple individually processed layers that perform various image processing tasks. Due to lack of resources, a layer may be partitioned into more manageable sub-layers. These sub-layers are then processed sequentially, however, some sub-layers can be processed simultaneously. Moreover, the storage cells within FPGA equipped SSDs are capable of being augmented with in-storage compute to accelerate CNN workloads and exploit the intra-parallelism within a CNN layer. To this end, we present our work, which leverages heterogeneous architectures to create an in/near-storage acceleration solution for video analytics. We designed a NAND flash accelerator and an FPGA accelerator, then mapped and evaluated several CNN benchmarks. We show how to utilize FPGAs, local DRAMs, and in-memory SSD compute to accelerate CNN workloads. Our work also demonstrates how to remove unnecessary memory transfers to save latency and energy.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4381052998",
    "type": "article"
  },
  {
    "title": "Automated module assignment in stacked-Vdd designs for high-efficiency power delivery",
    "doi": "https://doi.org/10.1145/1412587.1412591",
    "publication_date": "2008-10-01",
    "publication_year": 2008,
    "authors": "Yong Zhan; Sachin S. Sapatnekar",
    "corresponding_authors": "",
    "abstract": "With aggressive reductions in feature sizes and the integration of multiple functionalities on the same die, bottlenecks due to I/O pin limitations have become a critical issue in today's VLSI designs, especially for 3D IC technologies. To alleviate the pin limitation problem, a stacked-Vdd circuit paradigm has recently been proposed in the literature. However, for a circuit designed using this paradigm, a significant amount of power may be wasted if modules are not carefully assigned to different Vdd domains. In this article, we present a partition-based algorithm for efficiently assigning modules at the floorplanning level, so as to reuse currents between Vdd domains and minimize the power wasted during the operation of the circuit. Experimental results on both 3D and 2D ICs show that compared with assigning modules to different Vdd domains using enumeration and simulated annealing, our algorithm can generate circuits with competitive power and IR noise performance, while being orders of magnitude faster.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2007750849",
    "type": "article"
  },
  {
    "title": "Scalable Path-Setup Scheme for All-Optical Dynamic Circuit Switched NoCs in Cache Coherent CMPs",
    "doi": "https://doi.org/10.1145/3154840",
    "publication_date": "2018-01-31",
    "publication_year": 2018,
    "authors": "Paolo Grani; Sandro Bartolini",
    "corresponding_authors": "",
    "abstract": "Nanophotonics is a promising solution for on-chip interconnection due to its intrinsic low-latency and low-power features, which can be useful for performance and energy in future Chip Multi-Processors (CMPs). This article proposes a novel arbitrated all-optical path-setup scheme for tiled CMPs adopting circuit-switched optical networks. It aims at significantly reducing path-setup latency and overall energy consumption. The proposed arbitrated scheme is able to configure multiple photonic switches simultaneously, instead of sequentially as it is done in state-of-the-art proposals. The proposed fast optical path-setup solution reduces the overhead in each transmission and, most importantly, allows optical circuit-switched networks to effectively serve cache coherence traffic, which is mainly composed of relatively small messages. Specifically, we propose a single-arbiter scheme where the whole topology is managed by a central module (single-arbiter) that takes care of the path-setup procedures. Then, to tackle scalability, we propose a logically clustered architecture (multi-arbiter) in which an arbiter is allocated in each logical core-cluster and an ad hoc distributed reservation protocol coordinates arbiters to manage inter-cluster path reservations. We show that our proposed single-arbiter architecture outperforms a state-of-the-art optical network with sequential path-setup (optical baseline) in the case of 8- and 16-core tiled CMP setups. However, due to serialization issues, the single-arbiter solution is not able to compete with a reference electronic baseline for bigger 32- and 64-core setups even if still performing much better than the optical baseline. Conversely, our multi-arbiter hierarchical solution allows us to improve performance up to almost 20% and 40% for 32- and 64-core setups, respectively, demonstrating a wide applicability of the proposed technique. Energy-wise, the analyzed solutions enable significant savings compared to both the optical baseline with sequential path setup, and to the electronic counterpart. Specifically, results show more than 25% average improvement for the single-arbiter in the 8- and 16-core cases, and more than 40% and 15% savings for the multi-arbiter in the 32- and 64-core cases, respectively.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2792885915",
    "type": "article"
  },
  {
    "title": "Power, Performance, and Area Benefit of Monolithic 3D ICs for On-Chip Deep Neural Networks Targeting Speech Recognition",
    "doi": "https://doi.org/10.1145/3273956",
    "publication_date": "2018-10-31",
    "publication_year": 2018,
    "authors": "Kyungwook Chang; Deepak Kadetotad; Yu Cao; Jae-sun Seo; Sung Kyu Lim",
    "corresponding_authors": "",
    "abstract": "In recent years, deep learning has become widespread for various real-world recognition tasks. In addition to recognition accuracy, energy efficiency and speed (i.e., performance) are other grand challenges to enable local intelligence in edge devices. In this article, we investigate the adoption of monolithic three-dimensional (3D) IC (M3D) technology for deep learning hardware design, using speech recognition as a test vehicle. M3D has recently proven to be one of the leading contenders to address the power, performance, and area (PPA) scaling challenges in advanced technology nodes. Our study encompasses the influence of key parameters in DNN hardware implementations towards their performance and energy efficiency, including DNN architectural choices, underlying workloads, and tier partitioning choices in M3D designs. Our post-layout M3D designs, together with hardware-efficient sparse algorithms, produce power savings and performance improvement beyond what can be achieved using conventional 2D ICs. Experimental results show that M3D offers 22.3% iso-performance power saving and 6.2% performance improvement, convincingly demonstrating its entitlement as a solution for DNN ASICs. We further present architectural and physical design guidelines for M3D DNNs to maximize the benefits.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2902874459",
    "type": "article"
  },
  {
    "title": "PANE",
    "doi": "https://doi.org/10.1145/3241051",
    "publication_date": "2019-01-14",
    "publication_year": 2019,
    "authors": "Sneha N. Ved; Sarabjeet Singh; Joycee Mekie",
    "corresponding_authors": "",
    "abstract": "Communication between different IP cores in MPSoCs and HMPs often results in clock domain crossing. Asynchronous network on chip (NoC) support communication in such heterogeneous set-ups. While there are a large number of tools to model NoCs for synchronous systems, there is very limited tool support to model communication for multi-clock domain NoCs and analyse them. In this article, we propose the P luggable A synchronous NE twork on Chip (PANE) simulator, which allows system-level simulation of asynchronous network on chip (NoC). PANE allows design space exploration of synchronous, asynchronous, and mixed synchronous-asynchronous(heterogeneous) NoC for various system-level NoC parameters such as packet latencies, throughput, network saturation point and power analysis. PANE supports a large range of NoC configurations—routing algorithms, topologies, network sizes, and so on—for both synthetic and real traffic patterns. We demonstrate the application of PANE by using synchronous routers, asynchronous routers, and a mix of asynchronous and synchronous routers. One of the key advantages of PANE is that it allows a seamless transition from synchronous to asynchronous NoC simulators while keeping pace with the developments in synchronous NoC tools as they can be integrated with PANE.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2909257077",
    "type": "article"
  },
  {
    "title": "Self-learnable Cluster-based Prefetching Method for DRAM-Flash Hybrid Main Memory Architecture",
    "doi": "https://doi.org/10.1145/3284932",
    "publication_date": "2019-01-09",
    "publication_year": 2019,
    "authors": "Su-Kyung Yoon; Young-Sun Youn; Bernd Burgstaller; Shin‐Dug Kim",
    "corresponding_authors": "",
    "abstract": "This article presents a novel prefetching mechanism for memory-intensive workloads used in large-scale data centers. We design a negative-AND-flash/dynamic random-access memory (DRAM) hybrid memory architecture as a cost-effective memory architecture to resolve the scalability and power consumption problems of a DRAM-based model. A smart prefetching mechanism based on a cluster-management scheme to cope with dynamically varying and complex access patterns of any given application is designed for maximizing the performance of the DRAM. In this article, we propose a new concept for page management, called a cluster, which prefetches data in our hybrid memory architecture. The cluster management is based on a self-learning scheme on dynamically changeable access patterns by considering any correlation between missed pages. Experimental results show that the overall performance is significantly improved in relation to hit rate, execution time, and energy consumption. Namely, our proposed model can enhance the hit rate by 15% and reduce the execution time by 1.75 times. In addition, we can save energy consumption by around 48% by cutting the number of flushed pages to about an eighth of that in a conventional system.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2909311658",
    "type": "article"
  },
  {
    "title": "In Situ Stochastic Training of MTJ Crossbars With Machine Learning Algorithms",
    "doi": "https://doi.org/10.1145/3309880",
    "publication_date": "2019-03-28",
    "publication_year": 2019,
    "authors": "Ankit Mondal; Ankur Srivastava",
    "corresponding_authors": "",
    "abstract": "Owing to high device density, scalability, and non-volatility, magnetic tunnel junction (MTJ)-based crossbars have garnered significant interest for implementing the weights of neural networks (NNs). The existence of only two stable states in MTJs implies a high overhead of obtaining optimal binary weights in software. This article illustrates that the inherent parallelism in the crossbar structure makes it highly appropriate for in situ training, wherein the network is taught directly on the hardware. It leads to significantly smaller training overhead as the training time is independent of the size of the network, while also circumventing the effects of alternate current paths in the crossbar and accounting for manufacturing variations in the device. We show how the stochastic switching characteristics of MTJs can be leveraged to perform probabilistic weight updates using the gradient descent algorithm. We describe how the update operations can be performed on crossbars implementing NNs and restricted Boltzmann machines, and perform simulations on them to demonstrate the effectiveness of our techniques. The results reveal that stochastically trained MTJ-crossbar feed-forward and deep belief nets achieve a classification accuracy nearly the same as that of real-valued weight networks trained in software and exhibit immunity to device variations.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2934545132",
    "type": "article"
  },
  {
    "title": "SSS",
    "doi": "https://doi.org/10.1145/3313869",
    "publication_date": "2019-04-25",
    "publication_year": 2019,
    "authors": "Gaoming Du; Guanyu Liu; Zhenmin Li; Yifan Cao; Duoli Zhang; Yiming Ouyang; Minglun Gao; Zhonghai Lu",
    "corresponding_authors": "",
    "abstract": "Network-on-Chip (NoC) has become the de facto communication standard for multi-core or many-core System-on-Chip (SoC) due to its scalability and flexibility. However, an important factor in NoC design is temperature, which affects the overall performance of SoC—decreasing circuit frequency, increasing energy consumption, and even shortening chip lifetime. In this article, we propose SSS, a self-aware SoC using a static-dynamic hybrid method that combines dynamic mapping and static mapping to reduce the hotspot temperature for NoC-based SoCs. First, we propose monitoring and thermal modeling for self-state sensoring. Then, in static mapping stage, we calculate the optimal mapping solutions under different temperature modes using the discrete firefly algorithm to help self-decision making. Finally, in dynamic mapping stage, we achieve dynamic mapping through configuring NoC and SoC sentient units for self-optimizing. Experimental results show that SSS has substantially reduced the peak temperature by up to 37.52%. The FPGA prototype proves the effectiveness and smartness of SSS in reducing hotspot temperature.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2942427482",
    "type": "article"
  },
  {
    "title": "Higher Dimension Quantum Entanglement Generators",
    "doi": "https://doi.org/10.1145/3345501",
    "publication_date": "2019-10-15",
    "publication_year": 2019,
    "authors": "Kaitlin N. Smith; Mitchell A. Thornton",
    "corresponding_authors": "",
    "abstract": "Quantum information processing and communication techniques rely heavily upon entangled quantum states, and this dependence motivates the development of methods and systems to generate entanglement. Much research has been dedicated to state preparation for radix-2 qubits, and due to the pursuit of entangled states, the Bell state generator and its generalized forms where the number of entangled qubits is greater than two have been defined. In this work, we move beyond radix-2 and propose techniques for quantum state entanglement in high-dimensional systems through the generalization of the binary bipartite entanglement states. These higher-radix quantum informatic systems are composed of n quantum digits, or qudits, that are each mathematically characterized as elements of an r -dimensioned Hilbert vector space where r &gt; 2. Consequently, the wave function is a time-dependent state vector of dimension r n . The generalization of the binary controlled-NOT to the controlled-modulo-addition gate, the concept of partial versus maximal entanglement, and architectures for generating higher-radix entangled states for the partial and maximal case are all presented.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2981088582",
    "type": "article"
  },
  {
    "title": "Projection of Dual-Rail DPA Countermeasures in Future FinFET and Emerging TFET Technologies",
    "doi": "https://doi.org/10.1145/3381857",
    "publication_date": "2020-05-18",
    "publication_year": 2020,
    "authors": "Ignacio M. Delgado-Lozano; Erica Tena‐Sánchez; Juan Núñez; Antonio J. Acosta",
    "corresponding_authors": "",
    "abstract": "The design of near future cryptocircuits will require greater performance characteristics in order to be implemented in devices with very limited resources for secure applications. Considering the security against differential power side-channel attacks (DPA), explorations of different implementations of dual-precharge logic gates with advanced and emerging technologies, using nanometric FinFET and Tunnel FET transistors, are proposed aiming to maintain or even improve the security levels obtained by current Metal-Oxide Semiconductor Field-Effect Transistor (MOSFET) technologies and reducing the resources needed for the implementations. As case study, dual-precharge logic primitives have been designed and included in the 4-bit substitution box of PRIDE algorithm, measuring the performance and evaluating the security through simulation-based Differential Power Analysis (DPA) attacks for each implementation. Extensive electrical simulations with predictive Predictive Transistor model on scaled 16nm and 22nm MOSFET, 16nm and 20nm FinFET, and 20nm Tunnel Field Effect Transistor (TFET) demonstrate a clear evolution of security and performances with respect to current 90nm MOSFET implementations, providing FinFET as fastest solutions with a delay 3.7 times better than conventional proposals, but TFET being the best candidate for future cryptocircuits in terms of average power consumption (x0.02 times compared with conventional technologies) and security in some orders of magnitude.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W3026655801",
    "type": "article"
  },
  {
    "title": "Towards on-node Machine Learning for Ultra-low-power Sensors Using Asynchronous Σ Δ Streams",
    "doi": "https://doi.org/10.1145/3404975",
    "publication_date": "2020-08-26",
    "publication_year": 2020,
    "authors": "Patricia Gonzalez-Guerrero; Tommy Tracy; Xinfei Guo; Rahul Sreekumar; Marzieh Lenjani; Kevin Skadron; Mircea R. Stan",
    "corresponding_authors": "",
    "abstract": "We propose a novel architecture to enable low-power, complex on-node data processing, for the next generation of sensors for the internet of things (IoT), smartdust, or edge intelligence. Our architecture combines near-analog-memory-computing (NAM) and asynchronous-computing-with-streams (ACS), eliminating the need for ADCs. ACS enables ultra-low power, massive computational resources required to execute on-node complex Machine Learning (ML) algorithms; while NAM addresses the memory-wall that represents a common bottleneck for ML and other complex functions. In ACS an analog value is mapped to an asynchronous stream that can take one of two logic levels ( v h , v l ). This stream-based data representation enables area/power-efficient computing units such as a multiplier implemented as an AND gate yielding savings in power of ∼90% compared to digital approaches. The generation of streams for NAM and ACS in a brute force manner, using analog-to-digital-converters (ADCs) and digital-to-streams-converters, would sky-rocket the power-latency-energy cost making the approach impractical. Our NAM-ACS architecture eliminates expensive conversions, enabling an end-to-end processing on asynchronous streams data-path. We tailor the NAM-ACS architecture for random forest (RaF), an ML algorithm, chosen for its ability to classify using a reduced number of features. Simulations show that our NAM-ACS architecture enables 75% of savings in power compared with a single ADC, obtaining a classification accuracy of 85% using an RaF-inspired algorithm.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W3081056518",
    "type": "article"
  },
  {
    "title": "Introduction to the Special Issue on New Trends in Nanoelectronic Device, Circuit, and Architecture Design, Part 1",
    "doi": "https://doi.org/10.1145/3392080",
    "publication_date": "2020-06-27",
    "publication_year": 2020,
    "authors": "Helen Li; Wei Zhang; Swarup Bhunia; Wujie Wen",
    "corresponding_authors": "",
    "abstract": "introduction Share on Introduction to the Special Issue on New Trends in Nanoelectronic Device, Circuit, and Architecture Design, Part 1 Editors: Helen Li Duke University, Durham, NC Duke University, Durham, NCView Profile , Wei Zhang Hong Kong University of Science and Technology, Clear Water Bay, NT, Hong Kong SAR Hong Kong University of Science and Technology, Clear Water Bay, NT, Hong Kong SARView Profile , Swarup Bhunia University of Florida, Gainesville, FL University of Florida, Gainesville, FLView Profile , Wujie Wen Lehigh University, Bethlehem, PA Lehigh University, Bethlehem, PAView Profile Authors Info & Claims ACM Journal on Emerging Technologies in Computing SystemsVolume 16Issue 3July 2020 Article No.: 24pp 1–3https://doi.org/10.1145/3392080Published:27 June 2020Publication History 0citation105DownloadsMetricsTotal Citations0Total Downloads105Last 12 Months9Last 6 weeks2 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteGet Access",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W3082640008",
    "type": "article"
  },
  {
    "title": "Approximate Spintronic Memories",
    "doi": "https://doi.org/10.1145/3404980",
    "publication_date": "2020-09-15",
    "publication_year": 2020,
    "authors": "Nour Sayed; Rajendra Bishnoi; Mehdi B. Tahoori",
    "corresponding_authors": "",
    "abstract": "Various applications, such as multimedia, machine learning, and signal processing, have a significant intrinsic error resilience. This makes them preferable for approximate computing as they have the ability to tolerate computations and data errors along with producing acceptable outputs. From the technology perspective, emerging technologies with inherent non-determinism and high failure rates are candidates for the realization of approximate computing. Spin Transfer Torque Magnetic Random Access Memories (STT-MRAM) is an emerging non-volatile memory technology and a potential candidate to replace SRAM due to its high density, scalability, and zero-leakage. The write operation in this technology is inherently stochastic and increases the rate of write errors. Moreover, this technology is associated with other failure mechanisms such as read-disturb and failures due to data retention. These errors are highly dependent on the STT-MRAM parameters (i.e., thermal stability, read/write current, and read/write latency), which varies with the operating temperature and the process variation effects. Fast and energy-efficient STT-MRAM designed for on-chip memories can be easily achieved by relaxing the device parameters at the cost of increased error rate, which can be addressed by approximating memory accesses. In this work, a detailed study of reliability and gains (i.e., performance and energy) tradeoff at the device and system-level of the STT-MRAM-based data cache system is presented in the scope of approximate memories.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W3088523196",
    "type": "article"
  },
  {
    "title": "Network-on-Chip Intellectual Property Protection Using Circular Path--based Fingerprinting",
    "doi": "https://doi.org/10.1145/3410024",
    "publication_date": "2020-09-17",
    "publication_year": 2020,
    "authors": "Arnab Kumar Biswas",
    "corresponding_authors": "Arnab Kumar Biswas",
    "abstract": "Intellectual property (IP) reuse is a well-known technique in chip design industry. But this technique also exposes a security vulnerability called IP stealing attack. Network-on-Chip (NoC) is an on-chip scalable communication medium and is used as an IP and sold by various vendors to be integrated in a Multiprocessor System-on-Chip (MPSoC). An attacker can launch IP stealing attack against NoC IP. In this article, we propose a NoC IP protection technique called circular path--based fingerprinting (CPF) using fingerprint embedding. We also provide a theoretical model using polyomino theory to get the number of distinct fingerprints in a NoC. We show that our proposed technique requires much less hardware overhead compared to an existing NoC IP security solution and also provides better security against removal and masking attacks. In particular, our proposed CPF technique requires 27.41% less router area compared to the existing solution. We also show that our CPF solution does not affect the normal packet latency and hence does not degrade the NoC performance.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W3088544988",
    "type": "article"
  },
  {
    "title": "Neural Network-based Inherently Fault-tolerant Hardware Cryptographic Primitives without Explicit Redundancy Checks",
    "doi": "https://doi.org/10.1145/3409594",
    "publication_date": "2020-09-22",
    "publication_year": 2020,
    "authors": "Manaar Alam; Arnab Bag; Debapriya Basu Roy; Dirmanto Jap; Jakub Breier; Shivam Bhasin; Debdeep Mukhopadhyay",
    "corresponding_authors": "",
    "abstract": "Fault injection-based cryptanalysis is one of the most powerful practical threats to modern cryptographic primitives. Popular countermeasures to such fault-based attacks generally use some form of redundant computation to detect and react/correct the injected faults. However, such countermeasures are shown to be vulnerable to selective fault injections. In this article, we aim to develop a cryptographic primitive that is fault tolerant by its construction and does not require to compute the same value multiple times. We utilize the effectiveness of Neural Networks (NNs), which show “some degree” of robustness by functioning correctly even after the occurrence of faults in any of its parameters. We also propose a novel strategy that enhances the fault tolerance of the implementation to “high degree” (close to 100%) by incorporating selective constraints in the NN parameters during the training phase. We evaluated the performance of revised NN considering both software and FPGA implementations for standard cryptographic primitives like 8×8 AES SBox and 4×4 PRESENT SBox. The results show that the fault tolerance of such implementations can be significantly increased with the proposed methodology. Such NN-based cryptographic primitives will provide inherent resistance against fault injections without requiring any redundancy countermeasures.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W3088797670",
    "type": "article"
  },
  {
    "title": "Implantable Closed-Loop Epilepsy Prosthesis",
    "doi": "https://doi.org/10.1145/2180878.2180881",
    "publication_date": "2012-06-01",
    "publication_year": 2012,
    "authors": "Muhammad Tariqus Salam; Mohamad Sawan; Dang Khoa Nguyen",
    "corresponding_authors": "",
    "abstract": "In this article, we present an implantable closed-loop epilepsy prosthesis, which is dedicated to automatically detect seizure onsets based on intracerebral electroencephalographic (icEEG) recordings from intracranial electrode contacts and provide an electrical stimulation feedback to the same contacts in order to disrupt these seizures. A novel epileptic seizure detector and a dedicated electrical stimulator were assembled together with common recording electrodes to complete the proposed prosthesis. The seizure detector was implemented in CMOS 0.18- μ m by incorporating a new seizure detection algorithm that models time-amplitude and -frequency relationship in icEEG. The detector was validated offline on ten patients with refractory epilepsy and showed excellent performance for early detection of seizures. The electrical stimulator, used for suppressing the developing seizure, is composed of two biphasic channels and was assembled with embedded FPGA in a miniature PCB. The stimulator efficiency was evaluated on cadaveric animal brain tissue in an in vitro morphologic electrical model. Spatial characteristics of the voltage distribution in cortex were assessed in an attempt to identify optimal stimulation parameters required to affect the suspected epileptic focus. The experimental results suggest that lower frequency stimulation parameters cause significant amount of shunting of current through the cerebrospinal fluid; however higher frequency stimulation parameters produce effective spatial voltage distribution with lower stimulation charge.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2013191198",
    "type": "article"
  },
  {
    "title": "Resilient and adaptive performance logic",
    "doi": "https://doi.org/10.1145/2287696.2287705",
    "publication_date": "2012-08-01",
    "publication_year": 2012,
    "authors": "Bao Liu; Xuemei Chen; Fiona Teshome",
    "corresponding_authors": "",
    "abstract": "As VLSI technology continues scaling, increasingly significant parametric variations and increasingly prevalent defects present unprecedented challenges to VLSI design at nanometer scale. Specifically, performance variability has hindered performance scaling, while soft errors become an emerging problem for logic computation at recent technology nodes. In this article, we leverage the existing Totally Self-Checking (TSC)/Strongly Fault-Secure (SFS) logic design techniques, and propose Resilient and Adaptive Performance (RAP) logic for maximum adaptive performance and soft error resilience in nanoscale computing. RAP logic clears all timing errors in the absence of external soft errors, albeit at a higher area/power cost compared with Razor logic. Our experimental results further show that dual-rail static (Domino) RAP logic outperforms alternative Delay-Insensitive (DI) code-based static (Domino) RAP logic with less area, higher performance, and lower power consumption for the large test cases, and achieves an average of 2.29(2.41)× performance boost, 2.12(1.91)× layout area, and 2.38(2.34)× power consumption compared with the traditional minimum area static logic based on the Nangate 45-nm open cell library.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2081484285",
    "type": "article"
  },
  {
    "title": "From Transistors to NEMS",
    "doi": "https://doi.org/10.1145/2093145.2093147",
    "publication_date": "2012-02-01",
    "publication_year": 2012,
    "authors": "M. Henry; Leyla Nazhandali",
    "corresponding_authors": "",
    "abstract": "A rapidly growing class of battery constrained electronic applications are those with very long sleep periods, such as structural health monitoring systems, biomedical implants, and wireless border security cameras. The traditional method for sleep-mode power reduction, transistor power gating, has drawbacks, including performance loss and residual leakage. This article presents a thorough evaluation of a new nanotechnology-enabled power gating structure, CMOS-compatible NEMS switches, in the presence of aggressive supply voltage scaling. Due to the infinite off-resistance of the NEMS switches, the average power consumption of an FFT processor performing 1 FFT per hour drops by around 30 times compared to a transistor-based power gating implementation. Additionally, the low on-resistance and nanoscale size means even with current prototypes, area overhead is as much as 5 times lower, with much room for improvement. The major drawback of NEMS switches is the high activation voltage, which can be many times higher than typical CMOS supply voltages. We demonstrate that with a charge pump, these voltages can be generated on-die, and the energy and bootup delay overhead is negligible compared to the FFT processing itself. These results show that NEMS-based power-gating warrants further investigation and the fabrication of a prototype.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2082286937",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1970406",
    "publication_date": "2011-06-01",
    "publication_year": 2011,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Moore's Law has set great expectations that the performance of information technology will improve exponentially until at least the end of this decade. Although the physics of silicon transistors alone might allow these expectations to be met, the ...",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4244506844",
    "type": "paratext"
  },
  {
    "title": "Temporal State Machines: Using Temporal Memory to Stitch Time-based Graph Computations",
    "doi": "https://doi.org/10.1145/3451214",
    "publication_date": "2021-05-11",
    "publication_year": 2021,
    "authors": "Advait Madhavan; Matthew W. Daniels; M. D. Stiles",
    "corresponding_authors": "",
    "abstract": "Race logic, an arrival-time-coded logic family, has demonstrated energy and performance improvements for applications ranging from dynamic programming to machine learning. However, the various ad hoc mappings of algorithms into hardware rely on researcher ingenuity and result in custom architectures that are difficult to systematize. We propose to associate race logic with the mathematical field of tropical algebra, enabling a more methodical approach toward building temporal circuits. This association between the mathematical primitives of tropical algebra and generalized race logic computations guides the design of temporally coded tropical circuits. It also serves as a framework for expressing high-level timing-based algorithms. This abstraction, when combined with temporal memory, allows for the systematic exploration of race logic-based temporal architectures by making it possible to partition feed-forward computations into stages and organize them into a state machine. We leverage analog memristor-based temporal memories to design such a state machine that operates purely on time-coded wavefronts. We implement a version of Dijkstra's algorithm to evaluate this temporal state machine. This demonstration shows the promise of expanding the expressibility of temporal computing to enable it to deliver significant energy and throughput advantages.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W3090014039",
    "type": "article"
  },
  {
    "title": "Power Management of Monolithic 3D Manycore Chips with Inter-tier Process Variations",
    "doi": "https://doi.org/10.1145/3430765",
    "publication_date": "2021-01-06",
    "publication_year": 2021,
    "authors": "Anwesha Chatterjee; Shouvik Musavvir; Ryan Kim; Janardhan Rao Doppa; Partha Pratim Pande",
    "corresponding_authors": "",
    "abstract": "Voltage/frequency island (VFI)-based power management is a popular methodology for designing energy-efficient manycore architectures without incurring significant performance overhead. However, monolithic 3D (M3D) integration has emerged as an enabling technology to design high-performance and energy-efficient circuits and systems. The smaller dimension of vertical monolithic inter-tier vias (MIVs) lowers effective wirelength and allows high integration density. However, sequential fabrication of M3D layers introduces inter-tier process variations that affect the performance of transistors and interconnects in different layers. Therefore, VFI-based power management in M3D manycore systems requires the consideration of inter-tier process variation effects. In this work, we present the design of an imitation learning (IL)-enabled VFI-based power-management strategy that considers the inter-tier process-variation effects in M3D manycore chips. We demonstrate that the IL-based power-management strategy can be fine-tuned based on the M3D characteristics. Our policy generates suitable V/F levels based on the computation and communication characteristics of the system for both process-oblivious and process-aware configurations. We show that the proposed process-variation-aware IL-based VFI implementation for M3D manycore chips lowers the overall energy-delay-product (EDP) by up to 16.2% on average compared to an ideal M3D system with no M3D process variations.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W3118377034",
    "type": "article"
  },
  {
    "title": "Improving the Quality of FPGA RO-PUF by Principal Component Analysis (PCA)",
    "doi": "https://doi.org/10.1145/3442444",
    "publication_date": "2021-05-11",
    "publication_year": 2021,
    "authors": "K. A. Asha; Li En Hsu; Abhishek Patyal; Hung-Ming Chen",
    "corresponding_authors": "",
    "abstract": "Ring Oscillator Physical Unclonable Functions (RO-PUFs) exploit the inherent manufacturing process variations, such as systematic and stochastic variations, to generate secret PUF responses that are unique to the device. Stochastic variations are random, while systematic variation exhibits a strong spatial correlation. Therefore, systematic process variation reduces the randomness of the PUF response. This lowers the ability of a PUF response to uniquely identify and authenticate individual devices. Further, the impact of systematic variation is paramount when the two ROs in comparison are placed far apart. Comparing the ROs that are close to each other does improve the randomness, but the responses generated are unreliable and limiting the possible Challenge-Response Pairs (CRPs). In this article, we are proposing a method to reduce the impact of systematic process variation on the RO oscillation frequencies by using Principal Component Analysis (PCA). Principal Components (PCs) model the directions of systematic and stochastic variation present on a device. By projecting the oscillation frequencies in the direction of stochastic variation, the impact of systematic variation can be reduced. Our proposed method neither restricts the placement of ROs to close groups nor limits the possible CRPs. The method is evaluated on a large population of 218 Xilinx Artix-7 FPGAs. To evaluate the efficiency of the proposed method, we purposely paired the ROs that are placed far apart on the FPGA fabric. Results obtained prove the ability of the proposed method in removing the impact of systematic variation on the oscillation frequencies and thereby producing truly random responses.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W3162223152",
    "type": "article"
  },
  {
    "title": "Bridging the Gap between RTL and Software Fault Injection",
    "doi": "https://doi.org/10.1145/3446214",
    "publication_date": "2021-05-11",
    "publication_year": 2021,
    "authors": "Johann Laurent; Christophe Deleuze; Florian Pebay-Peyroula; Vincent Beroulle",
    "corresponding_authors": "",
    "abstract": "Protecting programs against hardware fault injection requires accurate software fault models. However, typical models, such as the instruction skip, do not take into account the microarchitecture specificities of a processor. We propose in this article an approach to study the relation between faults at the Register Transfer Level (RTL) and faults at the software level. The goal is twofold: accurately model RTL faults at the software level and materialize software fault models to actual RTL injections. These goals lead to a better understanding of a system's security against hardware fault injection, which is important to design effective and cost-efficient countermeasures. Our approach is based on the comparison between results from RTL simulations and software injections (using a program mutation tool). Various analyses are included in this article to give insight on the relevance of software fault models, such as the computation of a coverage and fidelity metric, and to link software fault models to hardware RTL descriptions. These analyses are applied on various single-bit and multiple-bit injection campaigns to study the faulty behaviors of a RISC-V processor.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W3162478356",
    "type": "article"
  },
  {
    "title": "Improving Deep Learning Networks for Profiled Side-channel Analysis Using Performance Improvement Techniques",
    "doi": "https://doi.org/10.1145/3453162",
    "publication_date": "2021-06-30",
    "publication_year": 2021,
    "authors": "Damien Robissout; Lilian Bossuet; Amaury Habrard; Vincent Grosso",
    "corresponding_authors": "",
    "abstract": "The use of deep learning techniques to perform side-channel analysis attracted the attention of many researchers as they obtained good performances with them. Unfortunately, the understanding of the neural networks used to perform side-channel attacks is not very advanced yet. In this article, we propose to contribute to this direction by studying the impact of some particular deep learning techniques for tackling side-channel attack problems. More precisely, we propose to focus on three existing techniques: batch normalization, dropout, and weight decay, not yet used in side-channel context. By combining adequately these techniques for our problem, we show that it is possible to improve the attack performance, i.e., the number of traces needed to recover the secret, by more than 55%. Additionally, they allow us to have a gain of more than 34% in terms of training time. We also show that an architecture trained with such techniques is able to perform attacks efficiently even in the context of desynchronized traces.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W3176135864",
    "type": "article"
  },
  {
    "title": "Integrated Power Signature Generation Circuit for IoT Abnormality Detection",
    "doi": "https://doi.org/10.1145/3460476",
    "publication_date": "2021-09-29",
    "publication_year": 2021,
    "authors": "David E. Thompson; Haibo Wang",
    "corresponding_authors": "",
    "abstract": "This work presents a methodology to monitor the power signature of IoT devices for detecting operation abnormality. It does not require bulky measurement equipment thanks to the proposed power signature generation circuit which can be integrated into LDO voltage regulators. The proposed circuit is implemented using a 130 nm CMOS technology and simulated with power trace measured from a wireless sensor. It shows the generated power signature accurately reflects the power consumption and can be used to distinguish different operation conditions, such as wireless transmission levels, data sampling rates and microcontroller UART communications.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W3204409755",
    "type": "article"
  },
  {
    "title": "Enhancing Privacy in PUF-Cash through Multiple Trusted Third Parties and Reinforcement Learning",
    "doi": "https://doi.org/10.1145/3441139",
    "publication_date": "2021-09-29",
    "publication_year": 2021,
    "authors": "Georgios Fragkos; Cyrus Minwalla; Eirini Eleni Tsiropoulou; Jim Plusquellic",
    "corresponding_authors": "",
    "abstract": "Electronic cash ( e-Cash ) is a digital alternative to physical currency such as coins and bank notes. Suitably constructed, e-Cash has the ability to offer an anonymous offline experience much akin to cash, and in direct contrast to traditional forms of payment such as credit and debit cards. Implementing security and privacy within e-Cash, i.e., preserving user anonymity while preventing counterfeiting, fraud, and double spending, is a non-trivial challenge. In this article, we propose major improvements to an e-Cash protocol, termed PUF-Cash, based on physical unclonable functions ( PUFs ). PUF-Cash was created as an offline-first, secure e-Cash scheme that preserved user anonymity in payments. In addition, PUF-Cash supports remote payments; an improvement over traditional currency. In this work, a novel multi-trusted-third-party exchange scheme is introduced, which is responsible for “blinding” Alice’s e-Cash tokens; a feature at the heart of preserving her anonymity. The exchange operations are governed by machine learning techniques which are uniquely applied to optimize user privacy, while remaining resistant to identity-revealing attacks by adversaries and trusted authorities. Federation of the single trusted third party into multiple entities distributes the workload, thereby improving performance and resiliency within the e-Cash system architecture. Experimental results indicate that improvements to PUF-Cash enhance user privacy and scalability.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W3204492653",
    "type": "article"
  },
  {
    "title": "Polyhedral-Based Compilation Framework for In-Memory Neural Network Accelerators",
    "doi": "https://doi.org/10.1145/3469847",
    "publication_date": "2021-09-29",
    "publication_year": 2021,
    "authors": "Jianhui Han; Xiang Fei; Zhaolin Li; Youhui Zhang",
    "corresponding_authors": "",
    "abstract": "Memristor-based processing-in-memory architecture is a promising solution to the memory bottleneck in the neural network ( NN ) processing. A major challenge for the programmability of such architectures is the automatic compilation of high-level NN workloads, from various operators to the memristor-based hardware that may provide programming interfaces with different granularities. This article proposes a source-to-source compilation framework for such memristor-based NN accelerators, which can conduct automatic detection and mapping of multiple NN operators based on the flexible and rich representation capability of the polyhedral model. In contrast to previous studies, it implements support for pipeline generation to exploit the parallelism in the NN loads to leverage hardware resources for higher efficiency. The evaluation based on synthetic kernels and NN benchmarks demonstrates that the proposed framework can reliably detect and map the target operators. Case studies on typical memristor-based architectures also show its generality over various architectural designs. The evaluation further demonstrates that compared with existing polyhedral-based compilation frameworks that do not support the pipelined execution, the performance can upgrade by an order of magnitude with the pipelined execution, which emphasizes the necessity of our improvement.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W3204737618",
    "type": "article"
  },
  {
    "title": "Energy-Efficiency Comparison of Multi-Layer Deposited Nanophotonic Crossbar Interconnects",
    "doi": "https://doi.org/10.1145/3094125",
    "publication_date": "2017-08-11",
    "publication_year": 2017,
    "authors": "Hui Li; Sébastien Le Beux; Martha Johanna Sepúlveda; Ian O’Connor",
    "corresponding_authors": "",
    "abstract": "Single-layer optical crossbar interconnections based on Wavelength Division Multiplexing stand among other nanophotonic interconnects because of their low latency and low power. However, such architectures suffer from a poor scalability due to losses induced by long propagation distances on waveguides and waveguide crossings. Multi-layer deposited silicon technology allows the stacking of optical layers that are connected by means of Optical Vertical Couplers. This allows significant reduction in the optical losses, which contributes to improve the interconnect scalability but also leads to new challenges related to network designs and layouts. In this article, we investigate the design of optical crossbars using multi-layer silicon deposited technology. We propose implementations for Ring-, Matrix-, λ-router-, and Snake-based topologies. Layouts avoiding waveguide crossings are compared to those minimizing the waveguide length according to worst-case and average losses. The laser output power is estimated from the losses, which allows us to evaluate the energy efficiency improvement induced by multi-layer technology over traditional planar implementations (33% on average). Finally, networks comparison has been carried out and the results show that the ring topology leads to a 43% reduction in the laser output power.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2605720586",
    "type": "article"
  },
  {
    "title": "Power-Utility-Driven Write Management for MLC PCM",
    "doi": "https://doi.org/10.1145/2997648",
    "publication_date": "2017-04-20",
    "publication_year": 2017,
    "authors": "Bing Li; Yu Hu; Ying Wang; Jing Ye; Xiaowei Li",
    "corresponding_authors": "",
    "abstract": "Phase change memory (PCM) is a promising alternative to Dynamic Random Access Memory (DRAM) as main memory due to its merits of high density and low leakage power. Multi-level Cell (MLC) PCM is more attractive than Single-level Cell (SLC) PCM, because it can store multiple bits per cell to achieve higher density and lower per-bit cost. With the iterative program-verify write technique, MLC PCM writes demand at much higher power than DRAM writes, while the power supply system of MLC memory system is similar to that of DRAM, and the power capability is limited. The incompatibility of high write power and limited power budget results in the degradation of the write throughput and performance in MLC PCM. In this work, we investigate both write scheduling policy and power management to improve the MLC power utility and alleviate the negative impacts induced by high write power. We identify the power-utility-driven write scheduling as an online bin-packing problem and then derive a power-utility-driven scheduling (PUDS) policy from the First Fit algorithm to improve the write power usage. Based on the ramp-down characteristic of the SET pulse (the pulse changes the PCM to high resistance), we propose the SET Power Amortization (SPA) policy, which proactively reclaims the power tokens at the intra-SET level to promote the power utilization. Our experimental results demonstrate that the PUDS and SPA respectively achieve 24% and 27% performance improvement over the state-of-the-art power management technique, and the PUDS8SPA has an overall 31% improvement of the power utility and 50% increase of performance compared to the baseline system.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2607080517",
    "type": "article"
  },
  {
    "title": "COSMO: Computing with Stochastic Numbers in Memory",
    "doi": "https://doi.org/10.1145/3484731",
    "publication_date": "2022-01-12",
    "publication_year": 2022,
    "authors": "Saransh Gupta; Mohsen Imani; Joonseop Sim; Andrew Huang; Fan Wu; Jaeyoung Kang; Yeseong Kim; Tajana Rosing",
    "corresponding_authors": "",
    "abstract": "Stochastic computing (SC) reduces the complexity of computation by representing numbers with long streams of independent bits. However, increasing performance in SC comes with either an increase in area or a loss in accuracy. Processing in memory (PIM) computes data in-place while having high memory density and supporting bit-parallel operations with low energy consumption. In this article, we propose COSMO, an architecture for co mputing with s tochastic numbers in me mo ry, which enables SC in memory. The proposed architecture is general and can be used for a wide range of applications. It is a highly dense and parallel architecture that supports most SC encodings and operations in memory. It maximizes the performance and energy efficiency of SC by introducing several innovations: (i) in-memory parallel stochastic number generation, (ii) efficient implication-based logic in memory, (iii) novel memory bit line segmenting, (iv) a new memory-compatible SC addition operation, and (v) enabling flexible block allocation. To show the generality and efficiency of our stochastic architecture, we implement image processing, deep neural networks (DNNs), and hyperdimensional (HD) computing on the proposed hardware. Our evaluations show that running DNN inference on COSMO is 141× faster and 80× more energy efficient as compared to GPU.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4206512790",
    "type": "article"
  },
  {
    "title": "Generation of Black-box Audio Adversarial Examples Based on Gradient Approximation and Autoencoders",
    "doi": "https://doi.org/10.1145/3491220",
    "publication_date": "2022-03-25",
    "publication_year": 2022,
    "authors": "Po-Hao Huang; Honggang Yu; Max Panoff; Ting-Chi Wang",
    "corresponding_authors": "",
    "abstract": "Deep Neural Network (DNN) is gaining popularity thanks to its ability to attain high accuracy and performance in various security-crucial scenarios. However, recent research shows that DNN-based Automatic Speech Recognition (ASR) systems are vulnerable to adversarial attacks. Specifically, these attacks mainly focus on formulating a process of adversarial example generation as iterative, optimization-based attacks. Although these attacks make significant progress, they still take large generation time to produce adversarial examples, which makes them difficult to be launched in real-world scenarios. In this article, we propose a real-time attack framework that utilizes the neural network trained by the gradient approximation method to generate adversarial examples on Keyword Spotting (KWS) systems. The experimental results show that these generated adversarial examples can easily fool a black-box KWS system to output incorrect results with only one inference. In comparison to previous works, our attack can achieve a higher success rate with less than 0.004 s. We also extend our work by presenting a novel ensemble audio adversarial attack and testing the attack on KWS systems equipped with existing defense mechanisms. The efficacy of the proposed attack is well supported by promising experimental results.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4220724967",
    "type": "article"
  },
  {
    "title": "Optimizing 3D U-Net-based Brain Tumor Segmentation with Integer-arithmetic Deep Learning Accelerators",
    "doi": "https://doi.org/10.1145/3495210",
    "publication_date": "2022-03-10",
    "publication_year": 2022,
    "authors": "Weijia Wang; Bill Lin",
    "corresponding_authors": "",
    "abstract": "While gliomas have become the most common cancerous brain tumors, manual diagnoses from 3D MRIs are time-consuming and possibly inconsistent when conducted by different radiotherapists, which leads to the pressing demand for automatic segmentation of brain tumors. State-of-the-art approaches employ FCNs to automatically segment the MRI scans. In particular, 3D U-Net has achieved notable performance and motivated a series of subsequent works. However, their significant size and heavy computation have impeded their actual deployment. Although there exists a body of literature on the compression of CNNs using low-precision representations, they either focus on storage reduction without computational improvement or cause severe performance degradation. In this article, we propose a CNN training algorithm that approximates weights and activations using non-negative integers along with trained affine mapping functions. Moreover, our approach allows the dot-product operations to be performed in an integer-arithmetic manner and defers the floating-point decoding and encoding phases until the end of layers. Experimental results on BraTS 2018 show that our trained affine mapping approach achieves near full-precision dice accuracy with 8-bit weights and activations. In addition, we achieve a dice accuracy within 0.005 and 0.01 of the full-precision counterparts when using 4-bit and 2-bit precisions, respectively.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4220787541",
    "type": "article"
  },
  {
    "title": "SaARSP: An Architecture for Systolic-Array Acceleration of Recurrent Spiking Neural Networks",
    "doi": "https://doi.org/10.1145/3510854",
    "publication_date": "2022-06-27",
    "publication_year": 2022,
    "authors": "Jeong-Jun Lee; Wenrui Zhang; Yuan Xie; Peng Li",
    "corresponding_authors": "",
    "abstract": "Spiking neural networks (SNNs) are brain-inspired event-driven models of computation with promising ultra-low energy dissipation. Rich network dynamics emergent in recurrent spiking neural networks (R-SNNs) can form temporally based memory, offering great potential in processing complex spatiotemporal data. However, recurrence in network connectivity produces tightly coupled data dependency in both space and time, rendering hardware acceleration of R-SNNs challenging. We present the first work to exploit spatiotemporal parallelisms to accelerate the R-SNN-based inference on systolic arrays using an architecture called SaARSP. We decouple the processing of feedforward synaptic connections from that of recurrent connections to allow for the exploitation of parallelisms across multiple time points. We propose a novel time window size optimization (TWSO) technique, to further explore the temporal granularity of the proposed decoupling in terms of optimal time window size and reconfiguration of the systolic array considering layer-dependent connectivity to boost performance. Stationary dataflow and time window size are jointly optimized to trade off between weight data reuse and movements of partial sums, the two bottlenecks in latency and energy dissipation of the accelerator. The proposed systolic-array architecture offers a unifying solution to an acceleration of both feedforward and recurrent SNNs, and delivers 4,000X EDP improvement on average for different R-SNN benchmarks over a conventional baseline.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4283593055",
    "type": "article"
  },
  {
    "title": "On Securing Cryptographic ICs against Scan-based Attacks: A Hamming Weight Distribution Perspective",
    "doi": "https://doi.org/10.1145/3577215",
    "publication_date": "2022-12-22",
    "publication_year": 2022,
    "authors": "Dipojjwal Ray; Yogendra Sao; Santosh Biswas; Sk Subidh Ali",
    "corresponding_authors": "",
    "abstract": "Scan chain-based Design for Testability is the industry standard in use for testing manufacturing defects in the semiconductor industry to ensure the structural and functional correctness of chips. Fault coverage is significantly enhanced due to the higher observability and controllability of the internal latches. These ensuing benefits to testing, if misused, expose vulnerabilities that can be detrimental to the security aspects, especially in the context of crypto-chips that contain a secret key. Hence, it remains of paramount importance for a chip designer to secure crypto-chips against various scan attacks. A countermeasure is proposed in this article that preserves the secrecy of an embedded key in a cryptographic integrated circuit running an Advanced Encryption Standard (AES) implementation. A novel design involving a hardware unit is illustrated that circumvents differential scan attacks by essentially performing bit flips deterministically, using a pre-computed mask value. This helps secure the chip while retaining full testability. The controller logic directly depends on a mask determination algorithm that can defend against any scan attack with 𝒪 theoretical complexity. Security analysis of our proposed defense procedure is performed in the framework of Discrete Event Systems (DES). The sequential scan circuit of an AES cryptosystem is modeled as a DES using Finite State Automata. A security notion, Opacity , is used to quantify and formally verify the security aspects of our controlled system, which shows that the entropy of the secret key is preserved. A case study is performed that shows to mitigate state-of-the-art differential scan attacks successfully at a nominal extra overhead of 1.78%.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4312190954",
    "type": "article"
  },
  {
    "title": "Editorial to special issue on reliable computing",
    "doi": "https://doi.org/10.1145/1265949.1265950",
    "publication_date": "2007-07-01",
    "publication_year": 2007,
    "authors": "Sally A. McKee",
    "corresponding_authors": "Sally A. McKee",
    "abstract": "No abstract available.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2010119359",
    "type": "article"
  },
  {
    "title": "The spin-wave nanoscale reconfigurable mesh and the labeling problem",
    "doi": "https://doi.org/10.1145/1265949.1265951",
    "publication_date": "2007-07-01",
    "publication_year": 2007,
    "authors": "Mary Mehrnoosh Eshaghian‐Wilner; Alex Khitun; Shiva Navab; Kang L. Wang",
    "corresponding_authors": "",
    "abstract": "In this article, we present a nanoscale reconfigurable mesh which is interconnected by ferromagnetic spin-wave buses. In this architecture, unlike the traditional spin-based nano structures which transmit charge, waves are transmitted. As a result, the power consumption of the proposed modules can be low. This reconfigurable mesh, while requiring the same number of switches and buses as the standard reconfigurable mesh, is capable of simultaneously transmitting N waves on each of the spin-wave buses. Because of this highly parallel feature, very fast and fault-tolerant algorithms can be designed. To illustrate the superior performance of the proposed spin-wave reconfigurable mesh, we present three fast labeling algorithms.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2049464970",
    "type": "article"
  },
  {
    "title": "Evaluating area and performance of hybrid FPGAs with nanoscale clusters and CMOS routing",
    "doi": "https://doi.org/10.1145/1295231.1295236",
    "publication_date": "2007-11-01",
    "publication_year": 2007,
    "authors": "Reza Rad; Mohammad Tehranipoor",
    "corresponding_authors": "",
    "abstract": "Advances in fabrication technology of nanoscale devices such as nanowires, carbon nanotubes and molecular switches provide new opportunities for implementing cluster-based FPGAs. Extensive research is needed to evaluate area and performance of FPGAs made from these devices and compare with their CMOS counterparts. In this work, we propose a hybrid FPGA that uses nanoscale clusters with a functionality similar to the clusters of traditional CMOS FPGAs. The proposed cluster is constructed by a crossbar of nanowires and can be configured to implement the required LUTs and intracluster MUXes. A CMOS interface is also proposed to provide configuration and memory elements for the nanoscale cluster. In the proposed architecture, inter-cluster routing remains at CMOS scale. We have developed models for area and delay of clusters and interconnects of the proposed hybrid FPGA. FPGA tools are configured with these models and used to synthesize and configure the benchmark circuits onto the hybrid FPGAs with NiSi nanowires or nanotubes. Experiments are conducted to evaluate and compare area and performance of the hybrid FPGA and traditional CMOS FPGA (scaled to 22nm). Up to 82% area reduction was obtained from implementing MCNC benchmarks on the hybrid FPGA. Performance of the hybrid FPGA is shown to be close to that of CMOS FPGA.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2093863801",
    "type": "article"
  },
  {
    "title": "Design Space Exploration of 3D Network-on-Chip",
    "doi": "https://doi.org/10.1145/3197567",
    "publication_date": "2018-07-31",
    "publication_year": 2018,
    "authors": "Dongjin Lee; Sourav Das; Dae Hyun Kim; Janardhan Rao Doppa; Partha Pratim Pande",
    "corresponding_authors": "",
    "abstract": "High-performance and energy-efficient Network-on-Chip (NoC) architecture is one of the crucial components of the manycore processing platforms. A very promising NoC architecture recently proposed in the literature is the three-dimensional small-world NoC (3D SWNoC). Due to short vertical links in 3D integration and the robustness of small-world networks, the 3D SWNoC architecture outperforms its other 3D counterparts. However, the performance of 3D SWNoC is highly dependent on the placement of the links and associated routers. In this article, we propose a sensitivity-based link placement algorithm (SEN) to optimize the performance of 3D SWNoC. The sensitivity of a link in a NoC measures the importance of the link. The SEN algorithm optimizes the performance of 3D SWNoC by calculating the sensitivities of all the links in the NoC and removing the least important link repeatedly. We compare the performance of SEN algorithm with simulated annealing- (SA) and recently proposed machine-learning-based (ML) optimization algorithm. The optimized 3D SWNoC obtained by the proposed SEN algorithm achieves, on average, 11.5% and 13.6% lower latency and 18.4% and 21.7% lower energy-delay product than those optimized by the SA and ML algorithms respectively. In addition, the SEN algorithm is 26 to 33 times faster than the SA algorithm for the optimization of 64-, 128-, and 256-core 3D SWNoC designs. The performance gain provided by the SEN-, SA-, and ML-based methods also depend on the characteristics of the benchmarks under consideration. If the traffic pattern generated by a benchmark does not have enough variation, then the ML-based method does not have adequate opportunity to optimize the network. However, we find that ML-based methodology has faster convergence time than SEN and SA for bigger systems. The ML-based optimization algorithm is almost 4 and 97 times faster than the SEN- and SA-based algorithm for a system with 256 cores.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2898556717",
    "type": "article"
  },
  {
    "title": "Time-Randomized Wormhole NoCs for Critical Applications",
    "doi": "https://doi.org/10.1145/3281029",
    "publication_date": "2019-01-28",
    "publication_year": 2019,
    "authors": "Mladen Slijepcevic; Carles Hernàndez; Jaume Abella; Francisco J. Cazorla",
    "corresponding_authors": "",
    "abstract": "Wormhole-based NoCs (wNoCs) are widely accepted in high-performance domains as the most appropriate solution to interconnect an increasing number of cores in the chip. However, wNoCs suitability in the context of critical real-time applications has not been demonstrated yet. In this article, in the context of probabilistic timing analysis (PTA), we propose a PTA-compatible wNoC design that provides tight time-composable contention bounds. The proposed wNoC design builds on PTA ability to reason in probabilistic terms about hardware events impacting execution time (e.g., wNoC contention), discarding those sequences of events occurring with a negligible low probability. This allows our wNoC design to deliver improved guaranteed performance w.r.t. conventional time-deterministic setups. Our results show that performance guarantees of applications running on top of probabilistic wNoC designs improve by 40% and 93% on average for 4 × 4 and 6 × 6 wNoC setups, respectively.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2914173153",
    "type": "article"
  },
  {
    "title": "Thermal-aware Test Scheduling Strategy for Network-on-Chip based Systems",
    "doi": "https://doi.org/10.1145/3241050",
    "publication_date": "2019-01-31",
    "publication_year": 2019,
    "authors": "Kanchan Manna; Chatla Swami Sagar; Santanu Chattopadhyay; Indranil Sengupta",
    "corresponding_authors": "",
    "abstract": "Rapid progress in technology scaling has introduced massive parallel computing systems with multiple cores on the integrated circuit (IC), in which a flexible and scalable packet-switched architecture, Network-on-Chip (NoC), is commonly used for communication among the cores. However, technology scaling has also increased the susceptibility to internal defects in such systems. So, manufacturing tests of such multicore systems is crucial and this is a complex and time-consuming process. Due to stress on time-to-market, test engineers focus on the reduction of testtime and perform parallel tests of cores. Due to aggressive technology scaling into the nanometer regime, power consumption is also becoming a significant burden. Moreover, power consumption during manufacturing tests is more as compared to normal operation. In addition, peak power consumption is often significantly higher than the average power values. The consumed power leads to high temperature and creates hotspots, which in turn leads to failure of good parts, resulting in yield loss. Thermal safety during testing is an utmost challenging problem in NoC-based multicore systems, including three-dimensional NoC-based (3D NoC) multicore systems due to stacking of layers. This work proposes a preemptive test scheduling technique for NoC-based multicore systems to reduce the testtime by minimizing conflicts of resource usage. The preemptive test scheduling problem has been formulated using Integer Linear Programming (ILP). In this article, authors have also presented a thermal-aware test scheduling technique to test cores in 2D as well as 3D stacked NoC-based multicore systems using a Particle Swarm Optimization (PSO) based approach. To improve the solution further, several innovative augmentation techniques have been incorporated in the basic PSO. Experimental results highlight the effectiveness of the proposed method in reducing testtime and peak temperature under the power constraints and achieve a tradeoff between testtime and peak temperature.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2914379072",
    "type": "article"
  },
  {
    "title": "Hypercolumn Sparsification for Low-Power Convolutional Neural Networks",
    "doi": "https://doi.org/10.1145/3304104",
    "publication_date": "2019-03-26",
    "publication_year": 2019,
    "authors": "Praveen K. Pilly; Nigel Stepp; Yannis Liapis; David W. Payton; Narayan Srinivasa",
    "corresponding_authors": "",
    "abstract": "We provide here a novel method, called hypercolumn sparsification, to achieve high recognition performance for convolutional neural networks (CNNs) despite low-precision weights and activities during both training and test phases. This method is applicable to any CNN architecture that operates on signal patterns (e.g., audio, image, video) to extract information such as class membership. It operates on the stack of feature maps in each of the cascading feature matching and pooling layers through the processing hierarchy of the CNN by an explicit competitive process ( k -WTA, winner take all) that generates a sparse feature vector at each spatial location. This principle is inspired by local brain circuits, where neurons tuned to respond to different patterns in the incoming signals from an upstream region inhibit each other using interneurons, such that only the ones that are maximally activated survive the quenching threshold. We show this process of sparsification is critical for probabilistic learning of low-precision weights and bias terms, thereby making pattern recognition amenable for energy-efficient hardware implementations. Further, we show that hypercolumn sparsification could lead to more data-efficient learning as well as having an emergent property of significantly pruning down the number of connections in the network. A theoretical account and empirical analysis are provided to understand these effects better.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2928413811",
    "type": "article"
  },
  {
    "title": "Crossover-aware Placement and Routing for Inkjet Printed Circuits",
    "doi": "https://doi.org/10.1145/3375461",
    "publication_date": "2020-01-30",
    "publication_year": 2020,
    "authors": "Farhan Rasheed; Michael Hefenbrock; Rajendra Bishnoi; Michael Beigl; Jasmin Aghassi‐Hagmann; Mehdi B. Tahoori",
    "corresponding_authors": "",
    "abstract": "Printed Electronics technology is a key-enabler for smart sensors, soft robotics, and wearables. The inkjet printed electrolyte-gated field effect transistor (EGFET) technology is a promising candidate for such applications due to its low-power operation, high field-effect mobility, and on-demand fabrication. Unlike conventional silicon-based technologies, inkjet printed electronics technology is an additive manufacturing process where multiple layers are printed on top of each other to realize functional devices such as transistors and their interconnections. Due to the additive manufacturing process, the technology has limited routing layers. For routing of complex circuits, insulating crossovers are printed at the intersection of routing paths to isolate them. The crossover can alter the electrical properties of a circuit based on specific location on a routing path. In this work, we propose a crossover-aware placement and routing (COPnR) methodology for inkjet-printed circuits by integrating the crossover constraints in our design framework. Our proposed placement methodology is based on a state-of-the-art evolutionary algorithm while the routing optimization is done using a genetic algorithm. The proposed methodology is compared with the industrial standard placement and routing (PnR) tools. On average, the proposed methodology has 38% fewer crossovers and 94% fewer failing paths compared to the industrial PnR tools applied to printed circuit designs.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W3006960158",
    "type": "article"
  },
  {
    "title": "A Memristor-Based Compressive Sampling Encoder with Dynamic Rate Control for Low-Power Video Streaming",
    "doi": "https://doi.org/10.1145/3365836",
    "publication_date": "2020-01-30",
    "publication_year": 2020,
    "authors": "Fengyu Qian; Yanping Gong; Lei Wang",
    "corresponding_authors": "",
    "abstract": "Image sensors are widely used in various applications. With the increasing requirement for high resolutions and frame rates, power consumption has become a critical issue, which limits the use of image sensors in mobile devices and IoT applications. Compressive sensing (CS) techniques can achieve a sub-Nyquist sampling rate to reduce the power consumption in hardware circuits. Currently, most compressive measurements are implemented in digital CMOS circuits, leading to high hardware complexity and power consumption, as well as the limited sampling speed. Furthermore, CS applications with large image sizes are usually based on block-wise methods, which require real-time rate controls during practical operations. In this article, we propose a memristor-based CS encoder that can be integrated with conventional image sensors to achieve high performance with low power consumption and hardware overheads. A self-adaptive compressing rate control mechanism is also devised to maximize the performance of the proposed technique. Simulation results of wireless video streaming demonstrate the advantages of the proposed technique.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W3011081335",
    "type": "article"
  },
  {
    "title": "Reliability improvement of logic and clock paths in power-efficient designs",
    "doi": "https://doi.org/10.1145/2543749.2543751",
    "publication_date": "2014-01-01",
    "publication_year": 2014,
    "authors": "Senthil Arasu; Mehrdad Nourani; Vijay Reddy; John M. Carulli; G. Kapila; Min Chen",
    "corresponding_authors": "",
    "abstract": "Performance degradation due to transistor aging is a significant impediment to high-performance IC design due to increasing concerns of reliability mechanisms such as negative-bias-temperature-instability (NBTI). The concern only grows with technology scaling as the effects of positive bias temperature instability (PBTI) is becoming prominent in future technologies and compounding with the effects of NBTI. Although aging of transistor is inevitable and the magnitude of degradation due to aging varies depending upon the context. Specifically, in power-efficient systems designs, the logic and clock paths are susceptible to static stress resulting in peak degradation due to BTI occurrence when clock is gated. In this article, we present the reliability impact of making systems power efficient and propose a design-for-reliability methodology that can be used in conjunction with low-power design techniques to alleviate the stress conditions caused by rendering circuits in idle state. The technique— BTI-Refresh , is shown to be applicable to both logic and clock paths alike and focuses on preventing prolonged static stress using periodic refreshes to achieve alternating stress. The mechanism is shown to integrate seamlessly into the design at gate-level without requiring any architectural or RT-level changes. Using ISCAS benchmarks and Kogge-Stone-Adder circuits, it is shown to reduce the aging effect in logic path delay due to static stress by up to 50% with negligible area and power overhead. BTI-Refresh is extended to clock-paths to prevent pulse-width degradation due to static aging and with minimal clock-skew.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W1981558913",
    "type": "article"
  },
  {
    "title": "Nanopipelined threshold network synthesis",
    "doi": "https://doi.org/10.1145/2564924",
    "publication_date": "2014-02-01",
    "publication_year": 2014,
    "authors": "Luke Pierce; Spyros Tragoudas",
    "corresponding_authors": "",
    "abstract": "Threshold logic gates allow for complex multiinput functions to be implemented using a single gate thereby reducing the power and area of a circuit. Clocked threshold gates are nanopipelined to increase network throughput. It is shown that synthesis methods that do not consider the synchronization of the nanopipeline can produce an enormous amount of buffers. The proposed algorithm synthesizes a Boolean network into a nanopipelined threshold logic network by minimizing not only the number of combinational clusters but also the associated buffer insertion overhead.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W1999195917",
    "type": "article"
  },
  {
    "title": "Quantifying Irreversible Information Loss in Digital Circuits",
    "doi": "https://doi.org/10.1145/2629523",
    "publication_date": "2014-11-18",
    "publication_year": 2014,
    "authors": "Ismo Hänninen; Craig S. Lent; Gregory L. Snider",
    "corresponding_authors": "",
    "abstract": "Heat generation limits the performance of state-of-the-art integrated circuits, originating from the wasteful static CMOS operating principle. Near-term solutions like adiabatic charging for energy recovery and limiting friction-type heat sources provide considerable improvement. However, these methods do not address the ultimate thermodynamic necessity to expel energy related to information loss in the computing process. In emerging beyond-CMOS technologies, this bit erasure heat alone can overwhelm the cooling capacity and set the limits of the computing performance. Therefore, logical information loss is becoming an important factor for digital circuit design, and tools have to be developed for analysis and optimization. This article presents a framework for estimating the amount of information loss in complex logic circuits, demonstrating the method by modeling the irreversible bit erasures in a standard binary adder structure. Binary addition is one of the most often used and highly optimized digital designs, and we estimate the erasure bounds for components on various levels of design abstraction, showing that the actual logic gate implementations have orders of magnitude higher loss than the addition operation itself would require. The method and the results can be used to optimize circuits for a higher degree of logical reversibility and energy conservation.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2008955570",
    "type": "article"
  },
  {
    "title": "Extended and Robust Protein Sequence Annotation over Conservative Nonhierarchical Clusters",
    "doi": "https://doi.org/10.1145/2504729",
    "publication_date": "2013-11-01",
    "publication_year": 2013,
    "authors": "Damiano Piovesan; Giuseppe Profiti; Pier Luigi Martelli; Piero Fariselli; Rita Casadio",
    "corresponding_authors": "",
    "abstract": "Genome annotation is one of the most important issues in the genomic era. The exponential growth rate of newly sequenced genomes and proteomes urges the development of fast and reliable annotation methods, suited to exploit all the information available in curated databases of protein sequences and structures. To this aim we developed BAR+, the Bologna Annotation Resource. 1 The basic notion is that sequences with high identity value to a counterpart can inherit the same function/s and structure, if available. As a case study we describe how the ATP-binding domain of the ABC transporters can be found and modeled in over 30,000 new sequences not annotated before. We also mapped into BAR+ all the ABC transporters listed in the Transporter Classification DataBase 2 and found that within our environment annotation could be extended to another 256,866 sequences.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2013479427",
    "type": "article"
  },
  {
    "title": "Scalable Offline Searches in DNA Sequences",
    "doi": "https://doi.org/10.1145/2660774",
    "publication_date": "2014-11-18",
    "publication_year": 2014,
    "authors": "Pragyan Sheela P. Mohanty; Spyros Tragoudas",
    "corresponding_authors": "",
    "abstract": "Searching for a particular pattern in a very large DNA database is a fundamental and essential component in computational biology. In the biological world, pattern matching is required for finding repeats in a particular DNA sequence, finding motif, aligning sequences, and other similar tasks. Due to an immense amount and continuous increase of biological data, the searching process requires very fast algorithms. A function-based tool set for fast offline pattern searches in large DNA sequences is proposed. The method benefits from the use of Boolean functions, their compact storage using canonical data structure, and the existence of built-in operators for these data structures. Experiments on DNA sequences from the NCBI database show that the proposed approach is scalable. The time complexity depends on the size of the data structure used for storing the function that represents the DNA sequence. It is shown that the presented approach exhibits sublinear time complexity to the DNA sequence size.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2017283372",
    "type": "article"
  },
  {
    "title": "Design and Analysis of a Robust Carbon Nanotube-Based Asynchronous Primitive Circuit",
    "doi": "https://doi.org/10.1145/2422094.2422098",
    "publication_date": "2013-02-01",
    "publication_year": 2013,
    "authors": "Behnam Ghavami; Mohsen Raji; Hossein Pedram; Mehdi B. Tahoori",
    "corresponding_authors": "",
    "abstract": "Carbon Nanotube Field Effect Transistors (CNFETs) show great promise as extensions to silicon CMOS. However, CNFET-based circuits will face great fabrication challenges that will translate into important parameter variations and decreased reliability. Hence, asynchronous logic, which is intrinsically more robust to variability, seems an ideal and perhaps unavoidable choice for digital circuits in CNFET technology. This article presents the results on the design and analysis of a CNFET-based implementation of an asynchronous circuit primitive: the Muller C-element. Using a CNFET SPICE model, we evaluate the robustness of CNFET-based C-element in the presence of CNT fabrication-related nonidealities. We investigate a quantitative evaluation of how timing variability impacts the functionality of a C-element and then, extract the necessary delay constraints of the C-element circuit from the signal transition graph specification. Considering the large degrees of spatial correlation observed between the CNFETs fabricated on directionally grown CNTs, a layout technique is exploited to overcome the robustness challenges of a CNFET-based C-element. Extensive Monte Carlo simulations on the proposed technique have demonstrated the effectiveness of the proposed CNFET-based C-element by improving approximately 50X in its robustness in expense of 65% area, 47% delay, and 56% power consumption overheads. Experimental results indicate that implementation of some CNFET-based Quasi Delay Insensitive (QDI) benchmark circuits using the proposed C-element results in significant robustness improvement with negligible power and throughput overheads. As a promising step toward CNFET-based giga-scale integrated circuits, this article shows that the asynchronous logic is an effective approach to design robust integrated circuits in CNFET technology with inherent extreme physical variations.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2020939767",
    "type": "article"
  },
  {
    "title": "gem5-PVT",
    "doi": "https://doi.org/10.1145/2755564",
    "publication_date": "2015-09-21",
    "publication_year": 2015,
    "authors": "Xianmin Chen; Niraj K. Jha",
    "corresponding_authors": "",
    "abstract": "FinFET has begun replacing CMOS at the 22nm technology node and beyond. Compared to planar CMOS, FinFET has a higher on-current and lower leakage due to its double-gate structure. A FinFET-based system simulation framework can be very helpful to system architects for early-stage design-space exploration using this new technology. However, such a simulator does not exist. We fill this gap by presenting the details of one such simulation framework, called gem5-PVT, that we have developed. Our simulation framework combines and extends existing lower-level FinFET simulators to support timing, power, and thermal studies of FinFET-based chip multiprocessor systems under process, voltage, and temperature (PVT) variations. It uses a bottom-up modeling approach based on logic/memory cell libraries that have been very accurately characterized using TCAD device simulation. This allows accuracy to bubble up to the system level. The framework is modular and automated, hence enables system designers the flexibility to evaluate various system implementations. It is currently targeted at the 22nm FinFET technology. We report results for two case studies to demonstrate its usefulness. One study shows that more than 62.1× system-level leakage reduction, at the same performance, is possible when using a particular FinFET logic style. Another study characterizes core-to-core frequency and power variations that result from underlying PVT variations and compares the effectiveness of variation-aware scheduling schemes.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2026980799",
    "type": "article"
  },
  {
    "title": "Integration of Literature with Heterogeneous Information for Genes Correlation Scoring",
    "doi": "https://doi.org/10.1145/2504728",
    "publication_date": "2013-11-01",
    "publication_year": 2013,
    "authors": "Francesco Abate; Andrea Acquaviva; Elisa Ficarra; Enrico Macii",
    "corresponding_authors": "",
    "abstract": "Determining the correlation between biomedical terms is a powerful instrument to help scientist research activity, both to understand experimental results and to design new ones. In particular, a great potential comes from the integration of the many heterogeneous information sources currently available on the Web. In this article we focus on the correlation between genes and biological processes. In this context, we present a methodology for integrating information from biomedical literature with other heterogeneous types of structured information. In particular, the information sources integrated in this work are PubMed abstracts, pathway databases, and NCI thesaurus definitions. The integration is performed at the semantic analysis level using a customized approach we developed to modulate the impact of the different sources on the correlation score. We report the results of a study concerning the impact of the information integration on the correlation score and of the user-level parameters we introduced to modulate the impact of pathway data or NCI definitions with respect to biomedical literature information, depending on the context of the search. To evaluate the methodology, we performed correlation measures on six biological processes and nine genes by comparing the results with and without the integration of pathways and NCI definitions.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2032627418",
    "type": "article"
  },
  {
    "title": "Designing Garbage-Free Reversible Implementations of the Integer Cosine Transform",
    "doi": "https://doi.org/10.1145/2629532",
    "publication_date": "2014-11-18",
    "publication_year": 2014,
    "authors": "Alexis De Vos; Stéphane Burignat; Robert Glück; Torben Ægidius Mogensen; Holger Bock Axelsen; Michael Kirkedal Thomsen; Eva Rotenberg; Tetsuo Yokoyama",
    "corresponding_authors": "",
    "abstract": "Discrete linear transformations are important tools in information processing. Many such transforms are injective and therefore prime candidates for a physically reversible implementation into hardware. We present here reversible integer cosine transformations on n input integers. The resulting reversible circuit is able to perform both the forward transform and the inverse transform. The detailed structure of such a reversible design strongly depends on the odd prime factors of the determinant of the transform: whether those are of the form 2k ± 1 or of the form 2k ± 2l ± 1 or neither of these forms.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2069156062",
    "type": "article"
  },
  {
    "title": "Probabilistic modeling and analysis of molecular memory",
    "doi": "https://doi.org/10.1145/2629533",
    "publication_date": "2014-10-06",
    "publication_year": 2014,
    "authors": "Renu Kumawat; Vineet Sahula; Manoj Singh Gaur",
    "corresponding_authors": "",
    "abstract": "This article investigates the aspects of designing a nanocell based molecular memory. An empirical model for molecular device is developed, based on circuit behavior of nitro-substituted Oligo (Phynylene Ethynylene) molecule (OPE). This device model is subsequently used to design nanocell based 1-bit memory and verified using HSPICE. The approach is extended to train the nanocell for multibit storage capability using external voltage signals. It is observed that to successfully train a 2-bit molecular memory, the number of control signals should be approx. one-fourth of total number of nanoparticles. A computational framework is proposed to compute the probability of retrieving the stored data bits correctly, at the output terminal of the nanocell buffer. This nanocell configuration is simulated by systematically varying number of nanoparticles and molecular switches. It is observed that the probability of the existence of at least one path from input to output approaches close to unity with presence of 20 or more nanoparticles in a nanocell. During memory model validation, 1000 samples of 1-bit memory (consisting of 20 nanoparticles) were generated and verified for read and write operations. The model verification results obtained for this memory cell closely match those obtained using analytical solution of probabilistic graph model.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2072094346",
    "type": "article"
  },
  {
    "title": "Garbage-Free Reversible Multipliers for Arbitrary Constants",
    "doi": "https://doi.org/10.1145/2629515",
    "publication_date": "2014-11-18",
    "publication_year": 2014,
    "authors": "Torben Ægidius Mogensen",
    "corresponding_authors": "Torben Ægidius Mogensen",
    "abstract": "We present a method based on Mealy machines for constructing reversible circuitry for multiplying integers by arbitrary integer constants. The circuits generate no garbage and use no ancillae. The circuits are quite compact for small constants and are, in the worst case, bounded by O( n 2 ) multi-control Toffoli gates per bit-slice, where n is the number of bits in the constant. These gates will have O( n ) inputs, so the total number of pass-transistors needed to implement the circuit is O( n 3 ) transistors per bit slice, and the quantum cost (which is exponential in the number of inputs to a Toffoli gate) is O(2 n ). For some interesting cases, the cost can be reduced to O( n ) gates per bit-slice, reducing the cost to O( n 2 ) transistors per bit slice. The quantum cost is still O(2 n ), as the remaining gates have O( n ) inputs. We also look at an alternative construction that, at the cost of adding O( n ) ancillae, reduces the cost for arbitrary constants to O( n ) gates, O( n 2 ) transistors, though still with O(2 n ) quantum cost.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2093508350",
    "type": "article"
  },
  {
    "title": "On-chip sensor networks for soft-error tolerant real-time multiprocessor systems-on-chip",
    "doi": "https://doi.org/10.1145/2564928",
    "publication_date": "2014-02-01",
    "publication_year": 2014,
    "authors": "Weichen Liu; Xuan Wang; Jiang Xu; Wei Zhang; Yaoyao Ye; Xiaowen Wu; Mahdi Nikdast; Zhehui Wang",
    "corresponding_authors": "",
    "abstract": "As transistor density continues to increase with the advent of nanotechnology, reliability issues raised by the more frequent appearance of soft errors are becoming critical for future embedded multiprocessor systems design. State-of-the-art techniques for soft error protections targeting multiprocessor systems result either high chip cost and area overhead or high performance degradation and energy consumption, and do not fulfill the increasing requirements for high performance and dependability. In this article we present a systematic approach, that is, the Sensor Networks-on-Chip (SENoC), to collaboratively and efficiently manage on-chip applications and overcome reliability threats to Multiprocessor Systems-on-Chip (MPSoC). A hardware-software collaborative approach is proposed to solve soft error problems: a hardware-based on-chip sensor network is built for soft error detection, and a software-based recovery mechanism is applied for soft error correction. A two-step scheduling scheme is presented for reliable application and chip management, combining an off-line static optimization stage for application performance maximization and an online lightweight dynamic adjustment stage to handle runtime variations and exceptions. This strategy introduces only trivial overhead on hardware design and much lower overhead on software control and execution, and hence performance degradation and energy consumption is greatly reduced. We build a cycle-accurate simulator using SystemC, and verify the effectiveness of our technique by comparing performance with related techniques on several real-world applications.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2150835185",
    "type": "article"
  },
  {
    "title": "Impact of Process Variations on Speedup and Maximum Achievable Frequency of Extensible Processors",
    "doi": "https://doi.org/10.1145/2567665",
    "publication_date": "2014-04-01",
    "publication_year": 2014,
    "authors": "Mehdi Kamal; Ali Afzali‐Kusha; Saeed Safari; Massoud Pedram",
    "corresponding_authors": "",
    "abstract": "In this article, we investigate the impact of process variations on the speedup and maximum frequency of the extended ISA processor. First, without considering process variations, a custom functional unit (CFU) is designed based on nominal timing parameters, then the timing variations of critical paths of the extensible processor, including the baseline processor and the CFU, are investigated by considering both systematic and random variations. Next, the maximum frequency of the extensible processor and the speed enhancement factor of the extended ISA for different benchmarks are investigated. Results show that timing variation could reduce the speedup of the extensible processor. However, this reduction is highly dependent on the baseline processor and the CFU structures. Additionally, the impact of process variations in the worst-case design approach is studied. Results show that the speedup of the extensible processor is reduced more than in the case when custom instructions (CIs) are selected without considering process variations. To study the impact of each variation type, speedup variations due to random and systematic variations are investigated separately. The study reveals that random variation has a similar effect on the CFU and the baseline processor, while the impact of systematic variation on the baseline processor is greater than the CFU.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2162867065",
    "type": "article"
  },
  {
    "title": "Delay/Power Modeling and Optimization of FinFET Circuit Modules under PVT Variations",
    "doi": "https://doi.org/10.1145/2795231",
    "publication_date": "2016-03-08",
    "publication_year": 2016,
    "authors": "Aoxiang Tang; Xun Gao; Lung-Yen Chen; Niraj K. Jha",
    "corresponding_authors": "",
    "abstract": "The semiconductor industry has moved to FinFETs because of their superior ability to mitigate short-channel effects relative to CMOS. Thus, good FinFET delay and power models are urgently needed to facilitate FinFET IC design at the upcoming technology nodes. Another urgent problem that needs to be addressed with continued technology scaling is how to analyze circuit performance and power consumption under process, voltage, and temperature (PVT) variations. Such variations arise due to limitations of lithography that lead to variations in the physical dimensions of the device or due to environmental variations. In this article, we propose a delay/power modeling framework for analysis of FinFET logic circuits under PVT variations. We present models for FinFET logic gates and three FinFET SRAM cells. We use GenFin, which is a genetic algorithm based statistical circuit-level delay/power optimizer, to produce the models for functional units (FUs) employed in a processor. We compare the impact of PVT variations at the 22nm and 14nm FinFET technology nodes. We evaluate cache performance for various cache capacities and temperatures as well as that of FUs. Our device simulation results show that the 3σ/μ spread for 14nm circuits is, on average, 38.5% higher in dynamic power and 21.4% higher in logarithm of leakage power relative to 22nm FinFET circuits. However, the delay spread depends on the circuit.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2295246860",
    "type": "article"
  },
  {
    "title": "Area Minimization Synthesis for Reconfigurable Single-Electron Transistor Arrays with Fabrication Constraints",
    "doi": "https://doi.org/10.1145/2906360",
    "publication_date": "2016-05-13",
    "publication_year": 2016,
    "authors": "Yihang Chen; Jianyu Chen; Juinn-Dar Huang",
    "corresponding_authors": "",
    "abstract": "Power dissipation has become a pressing issue of concern in the designs of most electronic system as fabrication processes enter even deeper submicron regions. More specifically, leakage power plays a dominant role in system power dissipation. An emerging circuit design style, the reconfigurable single-electron transistor (SET) array, has been proposed for continuing Moore's Law due to its ultra-low leakage power consumption. Recently, several works have been proposed to address the issues related to automated synthesis for the reconfigurable SET array. Nevertheless, all of those existing approaches consider mandatory fabrication constraints of SET array merely in late synthesis stages. In this article, we propose a synthesis algorithm, featuring input-variable ordering and dynamic product term ordering, for area minimization. The fabrication constraints are taken into account at every synthesis stage of proposed flow to guarantee better synthesis outcomes. We also develop a simulated annealing-based postprocess to find a proper phase assignment of each input variable for further area reduction. Experimental results show that our new methodology can achieve up to 29% area reduction as compared to existing state-of-the-art techniques.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2397223961",
    "type": "article"
  },
  {
    "title": "A Fine-Grain, Uniform, Energy-Efficient Delay Element for 2-Phase Bundled-Data Circuits",
    "doi": "https://doi.org/10.1145/2948067",
    "publication_date": "2016-11-19",
    "publication_year": 2016,
    "authors": "Ajay Singhvi; Matheus T. Moreira; Ramy N. Tadros; Ney Calazans; Peter A. Beerel",
    "corresponding_authors": "",
    "abstract": "Contemporary digitally controlled delay elements (DEs) trade off power overheads and delay quantization error (DQE). This article proposes a new programmable DE that provides a balanced design that yields low power with moderate DQE even under process, voltage, and temperature variations. The element employs and leverages the advantages offered by a 28nm fully depleted silicon on insulator technology, using back body biasing to add an extra dimension to its programmability. To do so, a novel generic delay shift block is proposed, which enables incorporating both fine and coarse delays in a single DE that can be easily integrated into digital systems, which is an advantage over hybrid DEs that rely on analog design.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2550665785",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2686762",
    "publication_date": "2014-11-18",
    "publication_year": 2014,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Quantum computation on w qubits is represented by the infinite unitary group U(2w); classical reversible computation on w bits is represented by the finite symmetric group S2w. In order to establish the relationship between classical reversible ...",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4248511543",
    "type": "paratext"
  },
  {
    "title": "Introduction to the special issue on sustainable and green computing systems",
    "doi": "https://doi.org/10.1145/2367736.2367737",
    "publication_date": "2012-10-01",
    "publication_year": 2012,
    "authors": "Partha Pratim Pande; Amlan Ganguly",
    "corresponding_authors": "",
    "abstract": "introduction Share on Introduction to the special issue on sustainable and green computing systems Editors: Partha Pratim Pande Washington State University Washington State UniversityView Profile , Amlan Ganguly Rochester Institute of Technology Rochester Institute of TechnologyView Profile Authors Info & Claims ACM Journal on Emerging Technologies in Computing SystemsVolume 8Issue 4Article No.: 26pp 1–3https://doi.org/10.1145/2367736.2367737Published:30 November 2012Publication History 1citation496DownloadsMetricsTotal Citations1Total Downloads496Last 12 Months10Last 6 weeks0 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteGet Access",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2018491156",
    "type": "article"
  },
  {
    "title": "CMOS LC voltage controlled oscillator design using multiwalled and single-walled carbon nanotube wire inductors",
    "doi": "https://doi.org/10.1145/2287696.2287698",
    "publication_date": "2012-08-01",
    "publication_year": 2012,
    "authors": "Ashok Srivastava; Yao Xu; Yang Liu; Ashwani K. Sharma; Clay Mayberry",
    "corresponding_authors": "",
    "abstract": "We have utilized our Multiwalled Carbon NanoTube (MWCNT) and Single-Walled Carbon NanoTube (SWCNT) bundle interconnects model in a widely used π model to study the performances of MWCNT and SWCNT bundle wire inductors and compared these with copper (Cu) inductors. The calculation results show that the Q-factors of Carbon NanoTube (CNT) wire (SWCNT bundle and MWCNT) inductors are higher than that of the Cu wire inductor. This is mainly due to much lower resistance of CNT and negligible skin effect in carbon nanotubes at higher frequencies. The application of CNT wire inductor in LC VCO is also studied and the Cadence/Spectre simulations show that VCOs with CNT bundle wire inductors have significantly improved performance such as the higher oscillation frequency and lower phase noise due to their smaller resistances and higher Q-factors. It is also noticed that CMOS LC VCO using a SWCNT bundle wire inductor has better performance when compared with the performance of LC VCO using the MWCNT wire inductor due to its lower resistance and higher Q-factor.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2047590888",
    "type": "article"
  },
  {
    "title": "Introduction to Special Issue on Implantable Electronics",
    "doi": "https://doi.org/10.1145/2180878.2180879",
    "publication_date": "2012-06-01",
    "publication_year": 2012,
    "authors": "Swarup Bhunia; Darrin J. Young",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2050450041",
    "type": "article"
  },
  {
    "title": "Formal methods for the analysis and synthesis of nanometer-scale cellular arrays",
    "doi": "https://doi.org/10.1145/1350763.1350768",
    "publication_date": "2008-04-01",
    "publication_year": 2008,
    "authors": "Josep Carmona; Jordi Cortadella; Yousuke Takada; Ferdinand Peper",
    "corresponding_authors": "",
    "abstract": "Nanometer-scale structures suitable for computing have been investigated by several research groups in recent years. A common feature of these structures is their dynamic evolution through cascaded local interactions embedded on a discrete grid. Finding configurations capable of conducting computations is a task that often requires tedious experiments in laboratories. Formal methods—though used extensively for the specification and verification of software and hardware computing systems—are virtually unexplored with respect to computational structures at atomic scales. This paper presents a systematic approach toward the application of formal methods in this context, using techniques like abstraction, model-checking, and symbolic representations of states to explore and discover computational structures. The proposed techniques are applied to a system of CO molecules on a grid of Copper atoms, resulting in the design of a complete library of combinational logic gates based on this molecular system. The techniques are also applied on (more general) systems of cellular automata that employ an asynchronous mode of timing. The use of formal methods may narrow the gap between Physical Chemistry and Computer Science, allowing the description of interactions of nanometer scale systems on a level of abstraction suitable to devise computing devices.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W1982248531",
    "type": "article"
  },
  {
    "title": "Guest editorial",
    "doi": "https://doi.org/10.1145/1482613.1482614",
    "publication_date": "2009-01-01",
    "publication_year": 2009,
    "authors": "Sandeep K. Shukla",
    "corresponding_authors": "Sandeep K. Shukla",
    "abstract": "editorial Free Access Share on Guest editorial: IEEE/ACM symposium on nanoscale architectures (NANOARCH07) Editor: Sandeep Shukla Virginia Polytechnic and State University, Blacksburg, VA Virginia Polytechnic and State University, Blacksburg, VAView Profile Authors Info & Claims ACM Journal on Emerging Technologies in Computing SystemsVolume 5Issue 1January 2009 Article No.: 1pp 1–4https://doi.org/10.1145/1482613.1482614Online:03 February 2009Publication History 0citation640DownloadsMetricsTotal Citations0Total Downloads640Last 12 Months42Last 6 weeks1 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my Alerts New Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W1994158521",
    "type": "editorial"
  },
  {
    "title": "Towards achieving reliable and high-performance nanocomputing via dynamic redundancy allocation",
    "doi": "https://doi.org/10.1145/1482613.1482615",
    "publication_date": "2009-01-01",
    "publication_year": 2009,
    "authors": "Shuo Wang; Lei Wang; F. Jain",
    "corresponding_authors": "",
    "abstract": "Nanoelectronic devices are considered to be the computational fabrics for the emerging nanocomputing systems due to their ultra-high speed and integration density. However, the imperfect bottom-up self-assembly fabrication leads to excessive defects that have become a barrier for achieving reliable computing. In addition, transient errors continue to be a problem. The massive parallelism rendered by nanoscale integration opens up new opportunities but also poses challenges on how to manage such massive resources for reliable and high-performance computing. In this paper, we propose a nanoarchitecture solution to address these emerging challenges. By using dynamic redundancy allocation, the massive parallelism is exploited to jointly achieve fault (defect/error) tolerance and high performance. Simulation results demonstrate the effectiveness of the proposed technique under a range of fault rates and operating conditions.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2021471559",
    "type": "article"
  },
  {
    "title": "A defect/error-tolerant nanosystem architecture for DSP",
    "doi": "https://doi.org/10.1145/1629091.1629094",
    "publication_date": "2009-11-01",
    "publication_year": 2009,
    "authors": "Weiguo Tang; Lei Wang; Fabrizio Lombardi",
    "corresponding_authors": "",
    "abstract": "Emerging technologies such as silicon NanoWires (NW) and Carbon NanoTubes (CNT) have shown great potential for building the next generation of computing systems in the nano ranges. However, the excessive number of defects originating from bottom-up fabrication (such as a self-assembly process) poses a pressing challenge for achieving scalable system integration. This article proposes a new nanosystem architecture that employs nanowire crossbars for Digital Signal Processing (DSP) applications. Distributed arithmetic is utilized such that complex signal processing computation can be mapped into regular memory operations, thus making this architecture well suited for implementation by nanowire crossbars. Furthermore, the inherent features of DSP-type computation provide new insights to remedy errors (as logic/computational manifestation of defects). A new defect/error-tolerant technique that exploits algorithmic error compensation is proposed; at system level different trade-offs between correctness in output and performance are established while retaining low overhead in its implementation. As an instance of its application, the proposed approach has been utilized to a generic DSP nanosystem performing frequency-selective filtering. Simulation results show that the proposed nanoDSP introduces only a minor performance degradation under high defect rates and at a range of operational conditions. The proposed technique also features good scalability and viability for various DSP applications.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2051989591",
    "type": "article"
  },
  {
    "title": "Utilizing quantum dot transistors with programmable threshold voltages for low-power mobile computing",
    "doi": "https://doi.org/10.1145/1568485.1568489",
    "publication_date": "2009-08-01",
    "publication_year": 2009,
    "authors": "Shuo Wang; Jianwei Dai; El-Sayed Hasaneen; Lei Wang; F. Jain",
    "corresponding_authors": "",
    "abstract": "Power consumption poses one of the fundamental barriers for deploying mobile computing devices in energy-constrained situations with varying operation conditions. In particular, leakage power is projected to increase exponentially in future semiconductor process nodes. This challenging problem is pressing for renewed focus on power-performance optimization at all levels of design abstract, from novel device structures to fundamental shifts in design paradigm. In this article, we propose to exploit the programmable threshold voltage quantum dot (QD) transistors to reduce leakage thereby improving the energy efficiency for mobile computing. The unique programmability and reconfigurability enabled by QD transistors extend our capability in design optimization for new power-performance trade-offs. Simulation results demonstrate the significant leakage reduction over conventional techniques.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2094818594",
    "type": "article"
  },
  {
    "title": "A Quantum Computing Performance Simulator Based on Circuit Failure Probability and Fault Path Counting",
    "doi": "https://doi.org/10.1145/3154837",
    "publication_date": "2018-01-31",
    "publication_year": 2018,
    "authors": "Andre Van Rynbach; Muhammad Ahsan; Jungsang Kim",
    "corresponding_authors": "",
    "abstract": "Quantum computing performance simulators are needed to provide practical metrics for the effectiveness of executing theoretical quantum information processing protocols on physical hardware. In this work, we present a tool to simulate the execution of fault-tolerant quantum computation by automating the tracking of common fault paths for error propagation through an encoded circuit block and quantifying the failure probability of each encoded qubit throughout the circuit. Our simulator runs a fault path counter on encoded circuit blocks to determine the probability that two or more errors remain on the encoded qubits after each block is executed, and it combines errors from all the encoded blocks to estimate performance metrics such as the logical qubit failure probability, the overall circuit failure probability, the number of qubits used, and the time required to run the overall circuit. Our technique efficiently estimates the upper bound of the error probability and provides a useful measure of the error threshold at low error probabilities where conventional Monte Carlo methods are ineffective. We describe a way of simplifying the fault-tolerant measurement process in the Steane code to reduce the number of error correction steps necessary. We present simulation results comparing the execution of quantum adders, which constitute a major part of Shor’s algorithm.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2791433952",
    "type": "article"
  },
  {
    "title": "Prospect of ballistic CNFET in high performance applications",
    "doi": "https://doi.org/10.1145/1295231.1295233",
    "publication_date": "2007-11-01",
    "publication_year": 2007,
    "authors": "Bipul C. Paul; Shinobu Fujita; M. Okajima; Thomas C. M. Lee",
    "corresponding_authors": "",
    "abstract": "With the advent of carbon nanotube technology, evaluating circuit and system performance using these devices is becoming extremely important. In this article, we present a quasi-analytical device model for intrinsic ballistic CNFET, which can be used in any conventional circuit simulator like SPICE. This simple quasi-analytical model is effective in a wide variety of CNFET structures as well as for a wide range of operating conditions in the digital circuit application domain. We also provide insight into how the parasitic fringe capacitance in state-of-the-art CNFET geometries impacts the overall performance of CNFET circuits. We show that unless the device width can be significantly reduced, the effective gate capacitance of CNFET will be strongly dominated by the parasitic fringe capacitances, and the superior performance of intrinsic CNFET over silicon MOSFET cannot be achieved in circuit. We further show that unlike conventional MOSFET, nanotube FETs are significantly less sensitive to many process parameter variations due to their inherent device structures and cylindrical gate geometry.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2091289612",
    "type": "article"
  },
  {
    "title": "CSMO-DSE",
    "doi": "https://doi.org/10.1145/3371406",
    "publication_date": "2020-01-30",
    "publication_year": 2020,
    "authors": "Lei Wang; Yu Deng; Rui Gong; Wei Shi; Li Luo; Yongwen Wang",
    "corresponding_authors": "",
    "abstract": "Determining the optimal microarchitecture configuration of a processor at the early stages of design is undeniably a challenge. Due to many parameters at the microarchitecture level, finding the proper combination of these parameters to arrive at a balanced design is difficult. Application-specific Design Space Exploration (DSE) is even more difficult, since the property of application needs to be considered during the DSE process. Improving the speed and accuracy of the DSE process remains a particular challenge in microprocessor design. In this article, we propose a novel processor DSE methodology based on criticality and sensitivity analysis, named Criticality and Sensitivity-based Multi-Objective DSE (CSMO-DSE). In our methodology, a dependence-graph is derived from the profile generated by running a program on an instrumented cycle-accurate microprocessor simulator. Then, the criticality of the processor’s performance events is obtained through critical path analysis. The sensitivity of microarchitecture parameters to various performance events is also analyzed. Then, this information is used to optimize performance, power/area, and energy efficiency of the design. Experiments with SPEC 2006 show that CSMO-DSE methodology is 4.73× faster than the baseline DSE methodology and that the quality of result (QoR) is better than the baseline methodology for all the benchmark programs.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W3009555776",
    "type": "article"
  },
  {
    "title": "RNNFast",
    "doi": "https://doi.org/10.1145/3399670",
    "publication_date": "2020-09-18",
    "publication_year": 2020,
    "authors": "Mohammad Hossein Samavatian; Anys Bacha; Li Zhou; Radu Teodorescu",
    "corresponding_authors": "",
    "abstract": "Recurrent Neural Networks (RNNs) are an important class of neural networks designed to retain and incorporate context into current decisions. RNNs are particularly well suited for machine learning problems in which context is important, such as speech recognition and language translation. This work presents RNNFast, a hardware accelerator for RNNs that leverages an emerging class of non-volatile memory called domain-wall memory (DWM). We show that DWM is very well suited for RNN acceleration due to its very high density and low read/write energy. At the same time, the sequential nature of input/weight processing of RNNs mitigates one of the downsides of DWM, which is the linear (rather than constant) data access time. RNNFast is very efficient and highly scalable, with flexible mapping of logical neurons to RNN hardware blocks. The basic hardware primitive, the RNN processing element (PE), includes custom DWM-based multiplication, sigmoid and tanh units for high density and low energy. The accelerator is designed to minimize data movement by closely interleaving DWM storage and computation. We compare our design with a state-of-the-art GPGPU and find 21.8× higher performance with 70× lower energy.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W3105473866",
    "type": "article"
  },
  {
    "title": "Photonic Networks-on-Chip Employing Multilevel Signaling: A Cross-Layer Comparative Study",
    "doi": "https://doi.org/10.1145/3487365",
    "publication_date": "2022-03-22",
    "publication_year": 2022,
    "authors": "Venkata Sai Praneeth Karempudi; Febin Sunny; Ishan Thakkar; Sai Vineel Reddy Chittamuru; Mahdi Nikdast; Sudeep Pasricha",
    "corresponding_authors": "",
    "abstract": "Photonic network-on-chip (PNoC) architectures employ photonic links with dense wavelength-division multiplexing (DWDM) to enable high throughput on-chip transfers. Unfortunately, increasing the DWDM degree (i.e., using a larger number of wavelengths) to achieve a higher aggregated data rate in photonic links and, hence, higher throughput in PNoCs, requires sophisticated and costly laser sources along with extra photonic hardware. This extra hardware can introduce undesired noise to the photonic link and increase the bit error rate (BER), power, and area consumption of PNoCs. To mitigate these issues, the use of 4-pulse amplitude modulation (4-PAM) signaling, instead of the conventional on-off keying (OOK) signaling, can halve the wavelength signals utilized in photonic links for achieving the target aggregate data rate while reducing the overhead of crosstalk noise, BER, and photonic hardware. There are various designs of 4-PAM modulators reported in the literature. For example, the signal superposition (SS)–, electrical digital-to-analog converter (EDAC)–, and optical digital-to-analog converter (ODAC)–based designs of 4-PAM modulators have been reported. However, it is yet to be explored how these SS-, EDAC-, and ODAC-based 4-PAM modulators can be utilized to design DWDM-based photonic links and PNoC architectures. In this article, we provide a systematic analysis of the SS, EDAC, and ODAC types of 4-PAM modulators from prior work with regards to their applicability and utilization overheads. We then present a heuristic-based search method to employ these 4-PAM modulators for designing DWDM-based SS, EDAC, and ODAC types of 4-PAM photonic links with two different design goals: (i) to attain the desired BER of 10 -9 at the expense of higher optical power and lower aggregate data rate and (ii) to attain maximum aggregate data rate with the desired BER of 10 -9 at the expense of longer packet transfer latency. We then employ our designed 4-PAM SS–, 4-PAM EDAC–, 4-PAM ODAC–, and conventional OOK modulator–based photonic links to constitute corresponding variants of the well-known CLOS and SWIFT PNoC architectures. We eventually compare our designed SS-, EDAC-, and ODAC-based variants of 4-PAM links and PNoCs with the conventional OOK links and PNoCs in terms of performance and energy efficiency in the presence of inter-channel crosstalk. From our link-level and PNoC-level evaluation, we have observed that the 4-PAM EDAC–based variants of photonic links and PNoCs exhibit better performance and energy efficiency compared with the OOK-, 4-PAM SS–, and 4-PAM ODAC–based links and PNoCs.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W3206968204",
    "type": "article"
  },
  {
    "title": "RT-RCG: Neural Network and Accelerator Search Towards Effective and Real-time ECG Reconstruction from Intracardiac Electrograms",
    "doi": "https://doi.org/10.1145/3465372",
    "publication_date": "2022-03-16",
    "publication_year": 2022,
    "authors": "Yongan Zhang; Anton Banta; Yonggan Fu; Mathews John; Allison Post; Mehdi Razavi; Joseph R. Cavallaro; Behnaam Aazhang; Yingyan Lin",
    "corresponding_authors": "",
    "abstract": "There exists a gap in terms of the signals provided by pacemakers (i.e., intracardiac electrogram (EGM)) and the signals doctors use (i.e., 12-lead electrocardiogram (ECG)) to diagnose abnormal rhythms. Therefore, the former, even if remotely transmitted, are not sufficient for doctors to provide a precise diagnosis, let alone make a timely intervention. To close this gap and make a heuristic step towards real-time critical intervention in instant response to irregular and infrequent ventricular rhythms, we propose a new framework dubbed RT-RCG to automatically search for (1) efficient Deep Neural Network (DNN) structures and then (2) corresponding accelerators, to enable Real-Time and high-quality Reconstruction of ECG signals from EGM signals. Specifically, RT-RCG proposes a new DNN search space tailored for ECG reconstruction from EGM signals, and incorporates a differentiable acceleration search (DAS) engine to efficiently navigate over the large and discrete accelerator design space to generate optimized accelerators. Extensive experiments and ablation studies under various settings consistently validate the effectiveness of our RT-RCG. To the best of our knowledge, RT-RCG is the first to leverage neural architecture search (NAS) to simultaneously tackle both reconstruction efficacy and efficiency.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W3209992885",
    "type": "article"
  },
  {
    "title": "Power-based Attacks on Spatial DNN Accelerators",
    "doi": "https://doi.org/10.1145/3491219",
    "publication_date": "2022-02-02",
    "publication_year": 2022,
    "authors": "Ge Li; Mohit Tiwari; Michael Orshansky",
    "corresponding_authors": "",
    "abstract": "With proliferation of DNN-based applications, the confidentiality of DNN model is an important commercial goal. Spatial accelerators, which parallelize matrix/vector operations, are utilized for enhancing energy efficiency of DNN computation. Recently, model extraction attacks on simple accelerators, either with a single processing element or running a binarized network, were demonstrated using the methodology derived from differential power analysis (DPA) attack on cryptographic devices. This article investigates the vulnerability of realistic spatial accelerators using general, 8-bit, number representation. We investigate two systolic array architectures with weight-stationary dataflow: (1) a 3 × 1 array for a dot-product operation and (2) a 3 × 3 array for matrix-vector multiplication. Both are implemented on the SAKURA-G FPGA board. We show that both architectures are ultimately vulnerable. A conventional DPA succeeds fully on the 1D array, requiring 20K power measurements. However, the 2D array exhibits higher security even with 460K traces. We show that this is because the 2D array intrinsically entails multiple MACs simultaneously dependent on the same input. However, we find that a novel template-based DPA with multiple profiling phases is able to fully break the 2D array with only 40K traces. Corresponding countermeasures need to be investigated for spatial DNN accelerators.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4210260423",
    "type": "article"
  },
  {
    "title": "DINOS: Data INspired Oligo Synthesis for DNA Data Storage",
    "doi": "https://doi.org/10.1145/3510853",
    "publication_date": "2022-03-23",
    "publication_year": 2022,
    "authors": "Kevin Volkel; Kyle J. Tomek; Albert J. Keung; James Tuck",
    "corresponding_authors": "",
    "abstract": "As interest in DNA-based information storage grows, the costs of synthesis have been identified as a key bottleneck. A potential direction is to tune synthesis for data. Data strands tend to be composed of a small set of recurring code word sequences, and they contain longer sequences of repeated data. To exploit these properties, we propose a new framework called DINOS. DINOS consists of three key parts: (i) The first is a hierarchical strand assembly algorithm, inspired by gene assembly techniques that can assemble arbitrary data strands from a small set of primitive blocks. (ii) The assembly algorithm relies on our novel formulation for how to construct primitive blocks, spanning a variety of useful configurations from a set of code words and overhangs. Each primitive block is a code word flanked by a pair of overhangs that are created by a cyclic pairing process that keeps the number of primitive blocks small. Using these primitive blocks, any data strand of arbitrary length can be assembled, theoretically. We show a minimal system for a binary code with as few as six primitive blocks, and we generalize our processes to support an arbitrary set of overhangs and code words. (iii) We exploit our hierarchical assembly approach to identify redundant sequences and coalesce the reactions that create them to make assembly more efficient. We evaluate DINOS and describe its key characteristics. For example, the number of reactions needed to make a strand can be reduced by increasing the number of overhangs or the number of code words, but increasing the number of overhangs offers a small advantage over increasing code words while requiring substantially fewer primitive blocks. However, density is improved more by increasing the number of code words. We also find that a simple redundancy coalescing technique is able to reduce reactions by 90.6% and 41.2% on average for decompressed and compressed data, respectively, even when the smallest data fragments being assembled are 16 bits. With a simple padding heuristic that finds even more redundancy, we can further decrease reactions for the same operating point up to 91.1% and 59% for decompressed and compressed data, respectively, on average. Our approach offers greater density by up to 80% over a prior general purpose gene assembly technique. Finally, in an analysis of synthesis costs in which we make 1 GB volume using de novo synthesis versus making only the primitive blocks with de novo synthesis and otherwise assembling using DINOS, we estimate DINOS as 10 5 × cheaper than de novo synthesis.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4220979201",
    "type": "article"
  },
  {
    "title": "A Practical Shared Optical Cache With Hybrid MWSR/R-SWMR NoC for Multicore Processors",
    "doi": "https://doi.org/10.1145/3531012",
    "publication_date": "2022-04-20",
    "publication_year": 2022,
    "authors": "Haiyang Han; Theoni Alexoudi; Christos Vagionas; Nikos Pleros; Nikos Hardavellas",
    "corresponding_authors": "",
    "abstract": "Conventional electronic memory hierarchies are intrinsically limited in their ability to overcome the memory wall due to scaling constraints. Optical caches and interconnects can mitigate these constraints, and enable processors to reach performance and energy efficiency unattainable by purely electronic means. However, the promised benefits cannot be realized through a simple replacement process; to reach its full potential, the architecture needs to be holistically redesigned. This article proposes Pho$, an opto-electronic memory hierarchy architecture for multicores. Pho$ replaces conventional core-private electronic caches with a large shared optical L1 built with optical SRAMs. The shared optical cache is supported by Pho$Net, a novel hybrid MWSR/R-SWMR optical NoC that provides low-latency and high-bandwidth communication between the electronic cores and the shared optical L1 at low optical loss. Pho$Net’s unique network arbitration protocol seamlessly co-arbitrates the request and reply sub-networks and facilitates cache requests and replies that optimize for the common case of cache hits. Through Pho$ we solve the problems that render previous designs impractical. Our results show that Pho$ achieves on average 1.41× performance speedup (3.89× max) and 31% lower energy-delay product (90% max) against conventional designs. Moreover, the Pho$Net optical NoC for core-cache communication consumes 70% less power compared to directly applying previously proposed optical NoC architectures.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4224246693",
    "type": "article"
  },
  {
    "title": "Digital Fault-based Built-in Self-test and Evaluation of Low Dropout Voltage Regulators",
    "doi": "https://doi.org/10.1145/3510852",
    "publication_date": "2022-05-27",
    "publication_year": 2022,
    "authors": "Mehmet Ince; Bora Bilgic; Sule Ozev",
    "corresponding_authors": "",
    "abstract": "With increasing pressure to obtain near-zero defect rates, there is a need to explore built-in self-test and other non-traditional test techniques for embedded mixed-signal components, such as PLLs, power converters, and data converters. This article presents an extremely low-cost built-in self-test technique for LDOs, specifically designed for fault detection. The methodology relies on exciting the LDO loop at the voltage reference input via a pseudo-random signal with white noise characteristics and observing the response from the output of LDO via all-digital circuitry, thereby inducing low area and performance overhead. The BIST circuit along with an LDO as a device under test is designed in 65nm technology. Fault simulations performed at the transistor level show that all resistive open/short defects in circuit components can be detected even if they do not cause a catastrophic failure in the LDO response. The proposed technique is validated with hardware using off-the-shelf components.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4281894771",
    "type": "article"
  },
  {
    "title": "2DMAC: A Sustainable and Efficient Medium Access Control Mechanism for Future Wireless NoCs",
    "doi": "https://doi.org/10.1145/3570727",
    "publication_date": "2022-11-05",
    "publication_year": 2022,
    "authors": "Sidhartha Sankar Rout; Mitali Sinha; Sujay Deb",
    "corresponding_authors": "",
    "abstract": "Wireless Network-on-Chip (WNoC) requires a Medium Access Control (MAC) mechanism for an interference-free sharing of the wireless channel. In traditional MAC, a token is circulated among the Wireless Interfaces (WIs) in a Round Robin manner. The WI with the token holds the channel for a fixed number of cycles. However, the channel requirement of the individual WIs dynamically changes over time due to the varying traffic density across the WNoC. Moreover, the conventional WNoCs give equal importance to all the traffic taking the wireless path and transmit it in an oldest-first manner. Nevertheless, the critical data can degrade the system performance to a large extent by delaying the application runtime if not served promptly. We propose 2DMAC, which can change the token arbitration pattern and tune the channel hold time of each WI based on its runtime traffic density and criticality status. Moreover, 2DMAC prioritizes the critical traffic over the non-critical traffic during the wireless data transfer. The proposed mechanism improves the wireless channel utilization by 15.67% and the network throughput by 29.83% and reduces the critical data latency by 29.77% over the traditional MAC.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4308303341",
    "type": "article"
  },
  {
    "title": "Recovery modeling of negative bias temperature instability (NBTI) for SPICE-compatible circuit aging simulators",
    "doi": "https://doi.org/10.1145/2517648",
    "publication_date": "2014-01-01",
    "publication_year": 2014,
    "authors": "Haldun Küflüoğlu; C. Chancellor; Min Chen; C.R. Cirba; Vijay Reddy",
    "corresponding_authors": "",
    "abstract": "A feasible computational framework that enables improved predictability of NBTI degradation within commercially available tools is discussed. The NBTI model is used for real-time circuit operation where recovery is present. The complementary nature of implementation is readily incorporated into existing model extraction and verification tools. The method provides significantly enhanced accuracy in simulations when compared to circuit data, yet retains practicality and flexibility.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2000651207",
    "type": "article"
  },
  {
    "title": "Introduction to Special Issue on Neuromorphic Computing",
    "doi": "https://doi.org/10.1145/2728709",
    "publication_date": "2015-04-27",
    "publication_year": 2015,
    "authors": "Dan Hammerstrom; Vijaykrishnan Narayanan",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2009211615",
    "type": "article"
  },
  {
    "title": "Accurate Leakage/Delay Estimation for FinFET Standard Cells under PVT Variations using the Response Surface Methodology",
    "doi": "https://doi.org/10.1145/2665066",
    "publication_date": "2014-11-18",
    "publication_year": 2014,
    "authors": "Sourindra Chaudhuri; Prateek Mishra; Niraj K. Jha",
    "corresponding_authors": "",
    "abstract": "Among different multi-gate transistors, FinFETs and Trigate FETs have set themselves apart as the most promising candidates for the upcoming 22nm technology node and beyond owing to their superior device performance, lower leakage power consumption, and cost-effective fabrication process. Innovative circuit design and optimization techniques will be required to harness the power of multi-gate transistors, which in turn will depend on accurate leakage and timing characterization of these devices under spatial and environmental variations. Hence, in order to aid circuit designers, we present accurate analytical models using central composite rotatable design (CCRD) based on response surface methodology (RSM) to estimate the leakage current and delay of FinFET standard cells under the effect of variations in gate length ( L G ), fin thickness ( T SI ), gate-oxide thickness (T OX ), gate-workfunction (Φ G ), supply voltage ( V DD ), and temperature ( T ). To the best of our knowledge, this is the first such attempt to develop analytical models for leakage/delay estimation of FinFET logic gates. To derive these models, we employ TCAD device simulations of adjusted 2D device cross sections that have been shown to track TCAD device simulations of 3D device behavior within a 1--3% error range. This drastically reduces the CPU time of our modeling technique (by several orders of magnitude) without much loss in accuracy. We present analytical leakage and delay models for different sizes and logic styles (e.g., shorted-gate (SG) and independent-gate (IG) FinFETs at the 22nm technology node). Both leakage and delay estimates derived from the analytical models are in close agreement with quasi-Monte Carlo (QMC) simulation results (QMC simulations track the accuracy of Monte Carlo simulations, but are several orders of magnitude faster) obtained for different adjusted-2D logic gates with a root mean square error (RMSE) in the 0.23%--5.87% range.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2051462885",
    "type": "article"
  },
  {
    "title": "Introduction to special issue on WoSAR 2011",
    "doi": "https://doi.org/10.1145/2543749.2543752",
    "publication_date": "2014-01-01",
    "publication_year": 2014,
    "authors": "Alberto Avritzer; Tadashi Dohi",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2054787638",
    "type": "article"
  },
  {
    "title": "Guest Editorial",
    "doi": "https://doi.org/10.1145/2756554",
    "publication_date": "2015-09-02",
    "publication_year": 2015,
    "authors": "Aida Todri‐Sanial; Sanjukta Bhanja",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2150634520",
    "type": "editorial"
  },
  {
    "title": "Introduction to the Special Issue on Computational Synthetic Biology",
    "doi": "https://doi.org/10.1145/2668126",
    "publication_date": "2014-12-30",
    "publication_year": 2014,
    "authors": "Chris J. Myers; Herbert M. Sauro; Anil Wipat",
    "corresponding_authors": "",
    "abstract": "The goal of this special issue is to introduce the field of computational synthetic biology to engineers and computer scientists. The first article gives an introduction to the key biological principles and experimental techniques that support synthetic biology, and it draws analogies with the computing field. This issue also includes five original research articles in computational synthetic biology. The first research article discusses how standards can be used to modularize the design process for genetic circuits. The next two articles introduce new abstraction techniques to improve the efficiency of analysis of genetic circuit models. The last two articles introduce new design techniques that help decouple design from construction. We hope this sampling from the field will help to motivate others to join this exciting and rich area of research.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2154303652",
    "type": "article"
  },
  {
    "title": "Low-Power Heterogeneous Graphene Nanoribbon-CMOS Multistate Volatile Memory Circuit",
    "doi": "https://doi.org/10.1145/2700233",
    "publication_date": "2015-09-02",
    "publication_year": 2015,
    "authors": "Santosh Khasanvis; K. M. Masum Habib; Mostafizur Rahman; Roger K. Lake; Csaba Andras Moritz",
    "corresponding_authors": "",
    "abstract": "Graphene is an emerging nanomaterial believed to be a potential candidate for post-Si nanoelectronics due to its exotic properties. Recently, a new graphene nanoribbon crossbar (xGNR) device was proposed which exhibits negative differential resistance (NDR). In this article, a multistate memory design is presented that can store multiple bits in a single cell enabled by this xGNR device, called graphene nanoribbon tunneling random access memory (GNTRAM). An approach to increase the number of bits per cell is explored alternative to physical scaling to overcome CMOS SRAM limitations. A comprehensive design for quaternary GNTRAM is presented as a baseline, implemented with a heterogeneous integration between graphene and CMOS. Sources of leakage and approaches to mitigate them are investigated. This design is extensively benchmarked against 16nm CMOS SRAMs and 3T DRAM. The proposed quaternary cell shows up to 2.27× density benefit versus 16nm CMOS SRAMs and 1.8× versus 3T DRAM. It has comparable read performance and is power efficient up to 1.32× during active period and 818× during standby against high-performance SRAMs. Multistate GNTRAM has the potential to realize high-density low-power nanoscale embedded memories. Further improvements may be possible by using graphene more extensively, as graphene transistors become available in the future.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2233654029",
    "type": "article"
  },
  {
    "title": "Asymmetric Underlapped FinFETs for Near- and Super-Threshold Logic at Sub-10nm Technology Nodes",
    "doi": "https://doi.org/10.1145/2967615",
    "publication_date": "2016-11-02",
    "publication_year": 2016,
    "authors": "A. Arun Goud; Rangharajan Venkatesan; Anand Raghunathan; Kaushik Roy",
    "corresponding_authors": "",
    "abstract": "Extending double-gate FinFET scaling to sub-10nm technology regime requires device-engineering techniques for countering the rise of direct source to drain tunneling (DSDT), edge direct tunneling (EDT) and short channel effects (SCE) that degrade FinFET I-V characteristics. Symmetric underlap is effective for eliminating EDT, diminishing DSDT, and lowering the fringe component of gate capacitance. However, excessive symmetric underlap also lowers the on-current, which is mainly due to thermionic emission. In this work, it is demonstrated that at sub-10nm node, asymmetric underlapped FinFETs with slightly longer underlap toward drain side than source side are superior to symmetric underlapped FinFETs due to further improvement in I on /I off and reduction in gate-to-drain capacitance. Using quantum mechanical device simulations, FinFETs with various degrees of underlap have been analyzed for improvement in I-V characteristics. A FinFET model for circuit simulations has been constructed that captures the major sub-10nm leakage components, namely, thermionic emission, DSDT, EDT, direct gate oxide tunneling and its associated components. By simulating a 10-stage NAND circuit and a LEON3 processor with interconnect parasitics using these devices, it is shown that asymmetric underlap instead of symmetric underlap in sub-10nm FinFETs can offer lower energy consumption with improved performance for near-threshold logic and higher energy-efficiency for super-threshold logic operation.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2546837698",
    "type": "article"
  },
  {
    "title": "On-Chip Hybrid Power Supply System for Wireless Sensor Nodes",
    "doi": "https://doi.org/10.1145/2492683",
    "publication_date": "2014-04-01",
    "publication_year": 2014,
    "authors": "Wulong Liu; Yu Wang; Yuchun Ma; Yuan Xie; Huazhong Yang",
    "corresponding_authors": "",
    "abstract": "With the miniaturization of electronic devices, small-size but high-capacity power supply systems appear to be more and more important. A hybrid power source, which consists of a fuel cell (FC) and a rechargeable battery, has the advantages of long lifetime and good load-following capabilities. In this article, we propose the schematic of a hybrid power supply system that can be integrated on a chip compatible with present CMOS processes. For the on-chip, fuel-cell-based hybrid power system in wireless sensor node design, we propose a two steps optimization: (1) dynamic power management (DPM), and (2) adaptive fuel cell optimal power point tracking (AOPPT). Simulation results demonstrate that the on-chip FC-Bat hybrid power system can be used for wireless sensor nodes under different usage scenarios. Our proposed DPM method can achieve 12.9% more energy savings than the method without DPM. Meanwhile, implementing our AOPPT approach can save about 17% energy compared with the fixed architecture for the fuel cell system. For an on-chip power system with 1cm 2 area consumption, the wafer-level battery can power a typical sensor node for only about five months, while our on-chip hybrid power system will supply the same sensor node for two years steadily.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2618632574",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2543749",
    "publication_date": "2014-01-01",
    "publication_year": 2014,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4240602028",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2590828",
    "publication_date": "2014-02-01",
    "publication_year": 2014,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4244255509",
    "type": "paratext"
  },
  {
    "title": "<scp>AroMa</scp> : Evaluating Deep Learning Systems for Stealthy Integrity Attacks on Multi-tenant Accelerators",
    "doi": "https://doi.org/10.1145/3579033",
    "publication_date": "2023-01-06",
    "publication_year": 2023,
    "authors": "Xiangru Chen; Maneesh Merugu; Jiaqi Zhang; Sandip Ray",
    "corresponding_authors": "",
    "abstract": "Multi-tenant applications have been proliferating in recent years, supported by the emergence of computing-as-service paradigms. Unfortunately, multi-tenancy induces new security vulnerabilities due to spatial or temporal co-location of applications with possibly malicious intent. In this article, we consider a special class of stealthy integrity attacks on multi-tenant deep learning accelerators. One interesting conclusion is that it is possible to perform targeted integrity attacks on kernel weights of deep learning systems such that it remains functional but mis-labels specific categories of input data through standard RowHammer attacks by only changing 0.0009% of the total weights. We develop an automated framework, AroMa , to evaluate the impact of multi-tenancy on security of deep learning accelerators against integrity attacks on memory systems. We present extensive evaluations on AroMa to demonstrate its effectiveness.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4313645430",
    "type": "article"
  },
  {
    "title": "A Mapping Method Tolerating SAF and Variation for Memristor Crossbar Array Based Neural Network Inference on Edge Devices",
    "doi": "https://doi.org/10.1145/3585518",
    "publication_date": "2023-02-25",
    "publication_year": 2023,
    "authors": "Yu Ma; Linfeng Zheng; Pingqiang Zhou",
    "corresponding_authors": "",
    "abstract": "There is an increasing demand for running neural network inference on edge devices. Memristor crossbar array (MCA) based accelerators can be used to accelerate neural networks on edge devices. However, reliability issues in memristors, such as stuck-at faults (SAF) and variations, lead to weight deviation of neural networks and therefore have a severe influence on inference accuracy. In this work, we focus on the reliability issues in memristors for edge devices. We formulate the reliability problem as a 0–1 programming problem, based on the analysis of sum weight variation (SWV) . In order to solve the problem, we simplify the problem with an approximation - different columns have the same weights, based on our observation of the weight distribution. Then we propose an effective mapping method to solve the simplified problem. We evaluate our proposed method with two neural network applications on two datasets. The experimental results on the classification application show that our proposed method can recover 95% accuracy considering SAF defects and can increase by up to 60% accuracy with variation σ =0.4. The results of the neural rendering application show that our proposed method can prevent render quality reduction.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4322007931",
    "type": "article"
  },
  {
    "title": "Repercussions of Using DNN Compilers on Edge GPUs for Real Time and Safety Critical Systems: A Quantitative Audit",
    "doi": "https://doi.org/10.1145/3611016",
    "publication_date": "2023-08-03",
    "publication_year": 2023,
    "authors": "Omais Shafi; Mohammad Khalid Pandit; Amarjeet Saini; Gayathri Ananthanarayanan; Rijurekha Sen",
    "corresponding_authors": "",
    "abstract": "Rapid advancements in edge devices have led to a large deployment of deep neural network (DNN) based workloads. To utilize the resources at the edge effectively, many DNN compilers are proposed that efficiently map the high level DNN models developed in frameworks like PyTorch, Tensorflow, Caffe, and so on into minimum deployable lightweight execution engines. For real time applications like ADAS, these compiler optimized engines should give precise, reproducible, and predictable inferences, both in-terms of runtime and output consistency. This article is the first effort in empirically auditing state-of-the-art DNN compilers viz TensorRT, AutoTVM, and AutoScheduler. We characterize the NN compilers based on their performance predictability w.r.t inference latency, output reproducibility, hardware utilization, and so on and based on that provide various recommendations. Our methodology and findings can potentially help the application developers, in making informed decision about the choice of DNN compiler, in a real time safety critical setting.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4385548225",
    "type": "article"
  },
  {
    "title": "Design-time Reference Current Generation for Robust Spintronic-based Neuromorphic Architecture",
    "doi": "https://doi.org/10.1145/3625556",
    "publication_date": "2023-09-27",
    "publication_year": 2023,
    "authors": "Soyed Tuhin Ahmed; Mahta Mayahinia; Michael Hefenbrock; Christopher Münch; Mehdi B. Tahoori",
    "corresponding_authors": "",
    "abstract": "Neural Networks (NN) can be efficiently accelerated in a neuromorphic fabric based on emerging resistive non-volatile memories (NVM), such as Spin Transfer Torque Magnetic RAM (STT-MRAM). Compared to other NVM technologies, STT-MRAM offers many benefits, such as fast switching, high endurance, and CMOS process compatibility. However, due to its low ON/OFF-ratio, process variations and runtime temperature fluctuations can lead to miss-quantizing the sensed current and, in turn, degradation of inference accuracy. In this article, we analyze the impact of the sensed accumulated current variation on the inference accuracy in Binary NNs and propose a design-time reference current generation method to improve the robustness of the implemented NN under different temperature and process variation scenarios (up to 125 °C). Our proposed method is robust to both process and temperature variations. The proposed method improves the accuracy of NN inference by up to 20.51% on the MNIST, Fashion-MNIST, and CIFAR-10 benchmark datasets in the presence of process and temperature variations without additional runtime hardware overhead compared to existing solutions.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4387105823",
    "type": "article"
  },
  {
    "title": "An Analysis of Various Design Pathways Towards Multi-Terabit Photonic On-Interposer Interconnects",
    "doi": "https://doi.org/10.1145/3635031",
    "publication_date": "2023-12-01",
    "publication_year": 2023,
    "authors": "Venkata Sai Praneeth Karempudi; Janibul Bashir; Ishan Thakkar",
    "corresponding_authors": "",
    "abstract": "In the wake of dwindling Moore’s Law, to address the rapidly increasing complexity and cost of fabricating large-scale, monolithic systems-on-chip (SoCs), the industry has adopted dis-aggregation as a solution, wherein a large monolithic SoC is partitioned into multiple smaller chiplets that are then assembled into a large system-in-package (SiP) using advanced packaging substrates such as silicon interposer. For such interposer-based SiPs, there is a push to realize on-interposer inter-chiplet communication bandwidth of multi-Tb/s and end-to-end communication latency of no more than 10 ns. This push comes as the natural progression from some recent prior works on SiP design, and is driven by the proliferating bandwidth demand of modern data-intensive workloads. To meet this bandwidth and latency goal, prior works have focused on a potential solution of using the silicon photonic interposer (SiPhI) for integrating and interconnecting a large number of chiplets into an SiP. Despite the early promise, the existing designs of on-SiPhI interconnects still have to evolve by leaps and bounds to meet the goal of multi-Tb/s bandwidth. However, the possible design pathways, upon which such an evolution can be achieved, have not been explored in any prior works yet. In this paper, we have identified several design pathways that can help evolve on-SiPhI interconnects to achieve multi-Tb/s aggregate bandwidth. We perform an extensive link-level and system-level analysis in which we explore these design pathways in isolation and in different combinations of each other. From our link-level analysis, we have observed that the design pathways that simultaneously enhance the spectral range and optical power budget available for wavelength multiplexing can render aggregate bandwidth of up to 4 Tb/s per on-SiPhI link. We also show that such high-bandwidth on-SiPhI links can substantially improve the performance and energy-efficiency of the state-of-the-art CPU and GPU chiplets based SiPs.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4389245878",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1216396",
    "publication_date": "2006-10-01",
    "publication_year": 2006,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Emerging technologies have attracted a substantial interest in overcoming the physical limitations of CMOS as projected at the end of the Technology Roadmap; among these technologies, quantum-dot cellular automata (QCA) relies on different and novel ...",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4255771660",
    "type": "paratext"
  },
  {
    "title": "Synthetic Biology and Microdevices",
    "doi": "https://doi.org/10.1145/2504775",
    "publication_date": "2013-11-01",
    "publication_year": 2013,
    "authors": "Lyn Venken; Kathleen Marchal; Jos Vanderleyden",
    "corresponding_authors": "",
    "abstract": "Recent developments demonstrate that the combination of microbiology with micro- and nanoelectronics is a successful approach to develop new miniaturized sensing devices and other technologies. In the last decade, there has been a shift from the optimization of the abiotic components, for example, the chip, to the improvement of the processing capabilities of cells through genetic engineering. The synthetic biology approach will not only give rise to systems with new functionalities, but will also improve the robustness and speed of their response towards applied signals. To this end, the development of new genetic circuits has to be guided by computational design methods that enable to tune and optimize the circuit response. As the successful design of genetic circuits is highly dependent on the quality and reliability of its composing elements, intense characterization of standard biological parts will be crucial for an efficient rational design process in the development of new genetic circuits. Microengineered devices can thereby offer a new analytical approach for the study of complex biological parts and systems. By summarizing the recent techniques in creating new synthetic circuits and in integrating biology with microdevices, this review aims at emphasizing the power of combining synthetic biology with microfluidics and microelectronics.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2004669556",
    "type": "article"
  },
  {
    "title": "Retail beamed power using millimeter waves",
    "doi": "https://doi.org/10.1145/2287696.2287701",
    "publication_date": "2012-08-01",
    "publication_year": 2012,
    "authors": "Narayanan Komerath; Aravinda Kar",
    "corresponding_authors": "",
    "abstract": "Retail delivery of electric power through millimeter waves is relevant in developing areas where the market for communication devices outpaces the power grid infrastructure. It is also a critical component of an evolutionary path towards terrestrial and space-based renewable power generation. Narrow-band power can be delivered as focused beams to receivers near end-users, from central power plants, rural distribution points, UAVs, tethered aerostats, stratospheric airship platforms, or space satellites. The article surveys the available knowledge base on millimeter wave beamed power delivery. It then considers design requirements for a retail beamed power architecture, in the context of rural India where power delivery is lagging behind the demand growth for connectivity. A survey of technology developments relevant to millimeter wave beaming is conducted, and indicates that massive, mass-produced solid-state arrays capable of achieving good efficiency and cost effectiveness are possible in the near term to enable such retail power beaming architectures.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2035145705",
    "type": "article"
  },
  {
    "title": "Color image processing with multi-peak resonant tunneling diodes",
    "doi": "https://doi.org/10.1145/2503128",
    "publication_date": "2013-09-01",
    "publication_year": 2013,
    "authors": "Woo Hyung Lee; Pinaki Mazumder",
    "corresponding_authors": "",
    "abstract": "The article introduces a novel approach to color image processing that utilizes multi-peak resonant tunneling diodes for encoding color information in quantized states of the diodes. The Multi-Peak Resonant Tunneling Diodes (MPRTDs) are organized as a two-dimensional array of vertical pillars which are locally connected by programmable passive and active elements with a view to realizing a wide variety of color image processing functions such as quantization, color extraction, image smoothing, edge detection, and line detection. In order to process color information in the input images, two different methods for color representation schemes have been used: one using color mapping and the other using direct RGB representation. Finally, the article uses HSPICE simulation methods for the nestlist of the proposed RTD-based nanoarchitecture in order to verify a candidate of image functions by using the afore-mentioned representation methods.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2052195798",
    "type": "article"
  },
  {
    "title": "Relativistic Causality and Clockless Circuits",
    "doi": "https://doi.org/10.1145/2043643.2043650",
    "publication_date": "2011-12-01",
    "publication_year": 2011,
    "authors": "Philippe Matherat; Marc-Thierry Jaekel",
    "corresponding_authors": "",
    "abstract": "Time plays a crucial role in the performance of computing systems. The accurate modelling of logical devices, and of their physical implementations, requires an appropriate representation of time and of all properties that depend on this notion. The need for a proper model, particularly acute in the design of clockless delay-insensitive (DI) circuits, leads one to reconsider the classical descriptions of time and of the resulting order and causal relations satisfied by logical operations. This questioning meets the criticisms of classical spacetime formulated by Einstein when founding relativity theory and is answered by relativistic conceptions of time and causality. Applying this approach to clockless circuits and considering the trace formalism, we rewrite Udding’s rules, which characterize communications between DI components. We exhibit their intrinsic relation with relativistic causality. For that purpose, we introduce relativistic generalizations of traces, called R-traces, which provide a pertinent description of communications and compositions of DI components.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2073191020",
    "type": "article"
  },
  {
    "title": "Introduction to Special Issue: Highlights of NANOARCH'09",
    "doi": "https://doi.org/10.1145/1899390.1899391",
    "publication_date": "2011-01-01",
    "publication_year": 2011,
    "authors": "Shamik Das; Garrett S. Rose",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2074196085",
    "type": "article"
  },
  {
    "title": "Introduction to nanophotonic communication technology integration",
    "doi": "https://doi.org/10.1145/1970406.1970407",
    "publication_date": "2011-06-01",
    "publication_year": 2011,
    "authors": "Li Shang; Qianfan Xu",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2091910092",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2093145",
    "publication_date": "2012-02-01",
    "publication_year": 2012,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "In order to continue the performance and scaling trends that we have come to expect from Moore’s Law, many emergent computational models, devices, and technologies are actively being studied to either replace or augment CMOS technology. Nanomagnet Logic ...",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4236902295",
    "type": "paratext"
  },
  {
    "title": "A study of asynchronous design methodology for robust CMOS-nano hybrid system design",
    "doi": "https://doi.org/10.1145/1568485.1568486",
    "publication_date": "2009-08-01",
    "publication_year": 2009,
    "authors": "Rajat Subhra Chakraborty; Swarup Bhunia",
    "corresponding_authors": "",
    "abstract": "Among the emerging alternatives to CMOS, molecular electronics based diode-resistor crossbar fabric has generated considerable interest in recent times. Logic circuit design with future nano-scale molecular devices using dense and regular crossbar fabrics is promising in terms of integration density, performance and power dissipation. However, circuit design using molecular switches involve some major challenges: 1) lack of voltage gain of these switches that prevents logic cascading; 2) large output voltage level degradation; 3) vulnerability to parameter variations that affect yield and robustness of operation; and 4) high defect rate. In this article, we analyze some of the above challenges and investigate the effectiveness of asynchronous design methodology in a hybrid system design platform using molecular crossbar and CMOS interfacing elements. We explore different approaches of asynchronous circuit design and compare their suitability in terms of several circuit design parameters. We then develop the methodology and an automated synthesis flow to support two different asynchronous design approaches ( Micropipelines and Four phase Dual-rail ) for system designs using nano-crossbar logic stages and CMOS interface data-storage elements. Circuit-level simulation results for several benchmarks show considerable advantage in terms of performance and robustness at moderate area and power overhead compared to two different synchronous implementations.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2019544283",
    "type": "article"
  },
  {
    "title": "Organizing wires for reliability in magnetic QCA",
    "doi": "https://doi.org/10.1145/1629091.1629095",
    "publication_date": "2009-11-01",
    "publication_year": 2009,
    "authors": "Timothy J. Dysart; Peter M. Kogge",
    "corresponding_authors": "",
    "abstract": "This article investigates, via analytic modeling, how a magnetic QCA wire should be organized to provide the highest reliability. We compare a nonredundant wire and two redundant wire organizations. For all three organizations, a fault rate per unit length is used for comparison; additionally, since extra components are necessary to implement the redundant organizations, these components are faulty as well. We show that the difference between these two fault rates is the main driver for selecting a wire organization. Lastly, we develop a guideline for selecting the most reliable wire organization during the circuit design process.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2021904702",
    "type": "article"
  },
  {
    "title": "Monolayer Transistor SRAMs",
    "doi": "https://doi.org/10.1145/2967613",
    "publication_date": "2017-03-02",
    "publication_year": 2017,
    "authors": "Joydeep Rakshit; Kartik Mohanram; Runlai Wan; Kai Tak Lam; Jing Guo",
    "corresponding_authors": "",
    "abstract": "Monolayer heterojunction FETs based on vertical heterogeneous transition metal dichalcogenides (TMDCFETs) and planar black phosphorus FETs (BPFETs) have demonstrated excellent subthreshold swing, high I ON I OFF , and high scalability, making them attractive candidates for post-CMOS memory design. This article explores TMDCFET and BPFET SRAM design by combining atomistic self-consistent device modeling with SRAM circuit design and simulation. We perform detailed evaluations of the TMDCFET/BPFET SRAMs at a single bitcell and at SRAM array level. Our simulations show that at low operating voltages, TMDCFET/BPFET SRAMs exhibit significant advantages in static power, dynamic read/write noise margin, and read/write delay over nominal 16nm CMOS SRAMs at both bitcell and array-level implementations. We also analyze the effect of process variations on the performance of TMDCFET/BPFET SRAMs. Our simulations demonstrate that TMDCFET/BPFET SRAMs exhibit high tolerance to process variations, which is desirable for low operating voltages.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2592220727",
    "type": "article"
  },
  {
    "title": "Sketching Computation with Stochastic Processing Engines",
    "doi": "https://doi.org/10.1145/3007652",
    "publication_date": "2017-04-14",
    "publication_year": 2017,
    "authors": "Mohammed Alawad; Mingjie Lin",
    "corresponding_authors": "",
    "abstract": "This article explores how to leverage stochastic principles to gracefully exploit partial computation results, hence achieving quality-scalable embedded computing. Our work is inspired by the concept of incremental sketching frequently found in artistic rendering, where the drawing procedure consists of a series of steps, each gradually improving the quality of results. The essence of our approach is to first encode input signals as probability density functions (PDFs), then perform stochastic computing operations on all signals in the probabilistic domain, and finally decode output signals by estimating the PDF of these resulting random samples. Although numerous approximate computing schemes exist, such as inaccurate adders and multipliers that reduce bit width or weaken logic circuit design, none of them can seamlessly improve computing accuracy incrementally without making any changes to the computing hardware at runtime. Furthermore, in conventional embedded computing, a sudden shortage of computing resources, such as premature termination, often means a complete computing failure and totally unusable results. Our sketching computing scheme can readily trade off between the quality of results and computing efforts without modifying its circuit design. To validate our proposed architecture design, we have implemented a proof-of-concept computation sketching engine based on a probabilistic convolver using a Virtex-6 FPGA device. Using three widely deployed image processing applications—image correspondence, image sharpening, and edge detection—we have demonstrated that important embedded computing applications can indeed be “sketched” in a graceful manner using roughly one third the hardware and one fifth the energy compared to the traditional multiplier-based computing method.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2605435680",
    "type": "article"
  },
  {
    "title": "Mobile Unified Memory-Storage Structure Based on Hybrid Non-Volatile Memories",
    "doi": "https://doi.org/10.1145/3007650",
    "publication_date": "2017-04-21",
    "publication_year": 2017,
    "authors": "Su-Kyung Yoon; Young-Sun Youn; Kihyun Park; Shin‐Dug Kim",
    "corresponding_authors": "",
    "abstract": "In mobile computing systems, the limited amount of main memory space leads to page swap operation overhead and data duplication in both main memory and secondary storage. Furthermore, SQLite write operations in mobile devices such as smartphones and tablet PCs tend to frequently overwrite data to storage, significantly degrading performance. Thus, this article presents a unified memory-storage structure that is optimized for mobile devices and blurs the boundary between the existing main memory layer and secondary storage layer. This structure can eliminate the conventional page-swap operations that cause significant performance degradation and support fast program execution time. The unified memory-storage structure consists of a dynamic RAM (DRAM) and phase change memory (PCM) -based dual buffering module, a hybrid unified memory-storage array consisting of DRAM and NAND Flash memory, and an associated unified storage translation layer devised for the memory address and file translation mechanism as a system software module. This hybrid array of non-volatile memories is formed as a single memory-disk integrated storage space that can be logically divided into static and dynamic spaces. Experimental results show that the overall performance of the hybrid unified memory-storage system with the buffering structure increases by around 13% and power consumption is also improved by 35%, compared to current mobile system.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2606215829",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1773814",
    "publication_date": "2010-06-01",
    "publication_year": 2010,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4250272983",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1877745",
    "publication_date": "2010-12-01",
    "publication_year": 2010,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4250857802",
    "type": "paratext"
  },
  {
    "title": "Dynamic Regularization on Activation Sparsity for Neural Network Efficiency Improvement",
    "doi": "https://doi.org/10.1145/3447776",
    "publication_date": "2021-06-30",
    "publication_year": 2021,
    "authors": "Qing Yang; Jiachen Mao; Zuoguan Wang; “Helen” Li Hai",
    "corresponding_authors": "",
    "abstract": "When deploying deep neural networks in embedded systems, it is crucial to decrease the model size and computational complexity for improving the execution speed and efficiency. In addition to conventional compression techniques, e.g., weight pruning and quantization, removing unimportant activations can also dramatically reduce the amount of data communication and the computation cost. Unlike weight parameters, the pattern of activations is directly related to input data and thereby changes dynamically. To regulate the dynamic activation sparsity (DAS), in this work, we propose a generic low-cost approach based on winners-take-all (WTA) dropout technique. The network enhanced by the proposed WTA dropout, namely DASNet , features structured activation sparsity with an improved sparsity level. Compared to the static feature map pruning methods, DASNets provide better computation cost reduction. The WTA dropout technique can be easily applied in deep neural networks without incurring additional training variables. More importantly, DASNet can be seamlessly integrated with other compression techniques, such as weight pruning and quantization, without compromising accuracy. Our experiments on various networks and datasets present significant runtime speedups with negligible accuracy losses.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W3176561798",
    "type": "article"
  },
  {
    "title": "Software-driven Security Attacks: From Vulnerability Sources to Durable Hardware Defenses",
    "doi": "https://doi.org/10.1145/3456299",
    "publication_date": "2021-07-31",
    "publication_year": 2021,
    "authors": "Lauren Biernacki; Mark Gallagher; Zhixing Xu; Misiker Tadesse Aga; Austin Harris; Shijia Wei; Mohit Tiwari; Baris Kasikci; Sharad Malik; Todd Austin",
    "corresponding_authors": "",
    "abstract": "There is an increasing body of work in the area of hardware defenses for software-driven security attacks. A significant challenge in developing these defenses is that the space of security vulnerabilities and exploits is large and not fully understood. This results in specific point defenses that aim to patch particular vulnerabilities. While these defenses are valuable, they are often blindsided by fresh attacks that exploit new vulnerabilities. This article aims to address this issue by suggesting ways to make future defenses more durable based on an organization of security vulnerabilities as they arise throughout the program life cycle. We classify these vulnerability sources through programming, compilation, and hardware realization, and we show how each source introduces unintended states and transitions into the implementation. Further, we show how security exploits gain control by moving the implementation to an unintended state using knowledge of these sources and how defenses work to prevent these transitions. This framework of analyzing vulnerability sources, exploits, and defenses provides insights into developing durable defenses that could defend against broader categories of exploits. We present illustrative case studies of four important attack genealogies—showing how they fit into the presented framework and how the sophistication of the exploits and defenses have evolved over time, providing us insights for the future.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W3191405550",
    "type": "article"
  },
  {
    "title": "Low-overhead Hardware Supervision for Securing an IoT Bluetooth-enabled Device: Monitoring Radio Frequency and Supply Voltage",
    "doi": "https://doi.org/10.1145/3468064",
    "publication_date": "2021-09-29",
    "publication_year": 2021,
    "authors": "Abdelrahman Elkanishy; Paul M. Furth; Derrick T. Rivera; Abdel‐Hameed A. Badawy",
    "corresponding_authors": "",
    "abstract": "Over the past decade, the number of Internet of Things (IoT) devices increased tremendously. In particular, the Internet of Medical Things (IoMT) and the Industrial Internet of Things (IIoT) expanded dramatically. Resource restrictions on IoT devices and the insufficiency of software security solutions raise the need for smart Hardware-Assisted Security (HAS) solutions. These solutions target one or more of the three C’s of IoT devices: Communication, Control, and Computation. Communication is an essential technology in the development of IoT. Bluetooth is a widely-used wireless communication protocol in small portable devices due to its low energy consumption and high transfer rates. In this work, we propose a supervisory framework to monitor and verify the operation of a Bluetooth system-on-chip (SoC) in real-time. To verify the operation of the Bluetooth SoC, we classify its transmission state in real-time to ensure a secure connection. Our overall classification accuracy is measured as 98.7%. We study both power supply current (IVDD) and RF domains to maximize the classification performance and minimize the overhead of our proposed supervisory system.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W3203887361",
    "type": "article"
  },
  {
    "title": "High-Performance and Energy-Efficient 3D Manycore GPU Architecture for Accelerating Graph Analytics",
    "doi": "https://doi.org/10.1145/3482880",
    "publication_date": "2021-10-22",
    "publication_year": 2021,
    "authors": "Dwaipayan Choudhury; Aravind Sukumaran-Rajam; Ananth Kalyanaraman; Partha Pratim Pande",
    "corresponding_authors": "",
    "abstract": "Recent advances in GPU-based manycore accelerators provide the opportunity to efficiently process large-scale graphs on chip. However, real world graphs have a diverse range of topology and connectivity patterns (e.g., degree distributions) that make the design of input-agnostic hardware architectures a challenge. Network-on-Chip (NoC)- based architectures provide a way to overcome this challenge as the architectural topology can be used to approximately model the expected traffic patterns that emerge from graph application workloads. In this paper, we first study the mix of long- and short-range traffic patterns generated on-chip using graph workloads, and subsequently use the findings to adapt the design of an optimal NoC-based architecture. In particular, by leveraging emerging three-dimensional (3D) integration technology, we propose design of a small-world NoC (SWNoC)- enabled manycore GPU architecture, where the placement of the links connecting the streaming multiprocessors (SM) and the memory controllers (MC) follow a power-law distribution. The proposed 3D manycore GPU architecture outperforms the traditional planar (2D) counterparts in both performance and energy consumption. Moreover, by adopting a joint performance-thermal optimization strategy, we address the thermal concerns in a 3D design without noticeably compromising the achievable performance. The 3D integration technology is also leveraged to incorporate Near Data Processing (NDP) to complement the performance benefits introduced by the SWNoC architecture. As graph applications are inherently memory intensive, off-chip data movement gives rise to latency and energy overheads in the presence of external DRAM. In conventional GPU architectures, as the main memory layer is not integrated with the logic, off-chip data movement negatively impacts overall performance and energy consumption. We demonstrate that NDP significantly reduces the overheads associated with such frequent and irregular memory accesses in graph-based applications. The proposed SWNoC-enabled NDP framework that integrates 3D memory (like Micron's HMC) with a massive number of GPU cores achieves 29.5% performance improvement and 30.03% less energy consumption on average compared to a conventional planar Mesh-based design with external DRAM.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W3207980721",
    "type": "article"
  },
  {
    "title": "Introduction to the Special Issue on Design Automation for Quantum Computing",
    "doi": "https://doi.org/10.1145/3485041",
    "publication_date": "2021-12-20",
    "publication_year": 2021,
    "authors": "Robert Wille; Rolf Drechsler",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4200101013",
    "type": "article"
  },
  {
    "title": "An alternate design paradigm for low-power, low-cost, testable hybrid systems using scaled LTPS TFTs",
    "doi": "https://doi.org/10.1145/1389089.1389093",
    "publication_date": "2008-08-01",
    "publication_year": 2008,
    "authors": "Jing Li; Aditya Bansal; Swarop Ghosh; Kaushik Roy",
    "corresponding_authors": "",
    "abstract": "This article presents a holistic hybrid design methodology for low-power, low-cost, testable digital designs using low-temperature polycrystalline-silicon thin-film transistors (LTPS TFTs). An alternate scaling rule under low thermal budget (due to flexible substrate) is developed to improve the performance of TFTs in the presence of process variation. We demonstrate that LTPS TFTs can be further optimized for ultralow-power subthreshold operation with performances comparable to contemporary single-crystal silicon-on-insulator (c-Si SOI) devices after process optimization. The optimized LTPS TFTs with high current drivability and less variability can comprise a promising low-cost option to augment Si CMOS technology, opening up a plethora of new hybrid 3D applications. We illustrate one such application: IC testing. Testing of complex VLSI systems is a prime concern due to design cost of DFT circuits, area/delay overheads, and poor test confidence. To harness the benefits of TFT technology, a novel low-power, process-tolerant, generic, and reconfigurable test structure designed using LTPS TFTs is proposed to reduce the test cost, as well as to improve diagnosability and verifiability, of complex VLSI systems. Due to proper optimization of TFT devices, the proposed test structure consumes low power but operates with reasonable performance. Furthermore, the test circuits do not consume any silicon area because they can be integrated on-chip using 3D technology. Since the test architecture is reconfigurable, this eliminates the need to redesign built-in-self-test (BIST) components that may vary from one processor generation to another. We have developed test structures using 200nm TFT devices and evaluated them on designs implemented in 130nm bulk CMOS. For circuit simulations, we have developed a SPICE-compatible model for TFT devices. The BIST components designed using the test structures operate at 0.8--4.3 GHz (compared to 8.2 GHz in bulk CMOS) with low power consumption. The enhanced scan cells partially implemented in TFT (3D hybrid design) consume ∼24% less power and ∼15--20% less area of Si die compared to conventional bulk-Si design (2D planar design), with minimal delay overhead.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2043131778",
    "type": "article"
  },
  {
    "title": "Efficient LDPC Code Design for Combating Asymmetric Errors in STT-RAM",
    "doi": "https://doi.org/10.1145/3154836",
    "publication_date": "2018-01-31",
    "publication_year": 2018,
    "authors": "Bohua Li; Yukui Pei; Wujie Wen",
    "corresponding_authors": "",
    "abstract": "Spin-transfer torque random access memory (STT-RAM) is a promising emerging memory technology in the future memory hierarchy. However, its unique reliability challenges, i.e., the asymmetric bit failure mechanism at different bit flippings, have raised significant concerns in its real applications. Recent studies even show that the common memory error repair “remedies” cannot efficiently address them. In this article, we for the first time systematically study the potentials of the strong low-density parity-check (LDPC) code for combating such unique asymmetric errors in both single-level-cell (SLC) and multi-level-cell (MLC) STT-RAM designs. A generic STT-RAM channel model suitable for the SLC/MLC designs, is developed to analytically calibrate all the accumulated asymmetric factors of the write/read operations. The key initial information for LDPC decoding, namely asymmetric log-likelihood ratio (A-LLR), is redesigned and extracted from the proposed channel model, to unleash the LDPC’s asymmetric error correcting capability. LDPC codec is also carefully designed to lower the hardware cost by leveraging the systematic-structured parity check matrix. Then two customized short-length LDPC codes—(585,512) and (683,512)—augmented from the semi-random parity check matrix and the A-LLR based asymmetric decoding, are proposed for SLC and MLC STT-RAM designs, respectively. Experiments show that our proposed LDPC designs can improve the STT-RAM reliability by at least 10 2 (10 4 ) when compared to the existing error correction codes (ECCs) for the SLC (MLC) design, demonstrating the feasibility of LDPC solutions on STT-RAM.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2792538686",
    "type": "article"
  },
  {
    "title": "Integrated High-Speed Optical SerDes over 100GBd Based on Optical Time Division Multiplexing",
    "doi": "https://doi.org/10.1145/3154838",
    "publication_date": "2018-04-30",
    "publication_year": 2018,
    "authors": "Xu Shi; Zhang Luo; Mingche Lai; Zhengbin Pang; Renfa Li",
    "corresponding_authors": "",
    "abstract": "An on-chip optical transceiver for transmission system over 100GBd is proposed based on optical time division multiplexing (OTDM) technology, and the performances, such as the insertion loss, the inter-symbol interference (ISI) crosstalk, and the potential symbol rate, are analyzed in detail. Co-designed with the double rail driver, on-chip Mach-Zehnder interferometer switch repeatedly generates extremely narrow sampling pulses of only 12ps full width at half maximum. Based on such narrow optical sampling pulse train, a four-stage cascaded optical switch divides the 25GHz clock cycle into four recurrent 9.5ps time slots and one blank time slot of 2ps. Thus, a 100GBd optical transmission channel is realized based on 4-bit 25Gbps bit-streams at the electrical interface. The ISI extinction ratio at the worst channel is 1.9dB with 10dB depth modulator, and the insertion loss caused by the OTDM mechanism is about 16dB. Further, taking advantages of dark modulation, an OTDM system with 5-bit 25Gbps bit-streams at the electrical interface is proposed to generate a 125GBd transmission utilizing the same optical sampling pulse. The ISI performance is much better and the extinction ratio at the worst channel is enhanced to 3.99dB.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2803177349",
    "type": "article"
  },
  {
    "title": "SHARP",
    "doi": "https://doi.org/10.1145/3185383",
    "publication_date": "2018-04-30",
    "publication_year": 2018,
    "authors": "Scott Vanwinkle; Avinash Kodi",
    "corresponding_authors": "",
    "abstract": "As the relentless quest for higher throughput and lower energy cost continues in heterogenous multicores, there is a strong demand for energy-efficient and high-performance Network-on-Chip (NoC) architectures. Heterogeneous architectures that can simultaneously utilize both the serialized nature of the CPU as well as the thread level parallelism of the GPU are gaining traction in the industry. A critical issue with heterogeneous architectures is finding an optimal way to utilize the shared resources such as the last level cache and NoC without hindering the performance of either the CPU or the GPU core. Photonic interconnects are a disruptive technology solution that has the potential to increase the bandwidth, reduce latency, and improve energy-efficiency over traditional metallic interconnects. In this article, we propose a CPU-GPU heterogeneous architecture called Shared Heterogeneous Architecture with Reconfigurable Photonic Network-on-Chip (SHARP) that clusters CPU and GPU cores around the same router and dynamically allocates bandwidth between the CPU and GPU cores based on application demands. The SHARP architecture is designed as a Single-Writer Multiple-Reader (SWMR) crossbar with reservation-assist to connect CPU/GPU cores that dynamically reallocates bandwidth using buffer utilization information at runtime. As network traffic exhibits temporal and spatial fluctuations due to application behavior, SHARP can dynamically reallocate bandwidth and thereby adapt to application demands. SHARP demonstrates 34% performance (throughput) improvement over a baseline electrical CMESH while consuming 25% less energy per bit. Simulation results have also shown 6.9% to 14.9% performance improvement over other flavors of the proposed SHARP architecture without dynamic bandwidth allocation.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2816636183",
    "type": "article"
  },
  {
    "title": "A Process-Variation-Tolerant Method for Nanophotonic On-Chip Network",
    "doi": "https://doi.org/10.1145/3208073",
    "publication_date": "2018-04-30",
    "publication_year": 2018,
    "authors": "Yi Xu; Jun Yang; Rami Melhem",
    "corresponding_authors": "",
    "abstract": "Nanophotonic networks, a potential candidate for future networks on-chip, have been challenged for their reliability due to several device-level limitations. One of the main issues is that fabrication errors (a.k.a. process variations) can cause devices to malfunction, rendering communication unreliable. For example, the microring resonator, a preferred optical modulator device, may not resonate at the designated wavelength under process variations (PVs), leading to communication errors and bandwidth loss. This article proposes a series of solutions to the wavelength drifting problem of microrings and subsequent bandwidth loss problem of an optical network, due to PVs. The objective is to maximize network bandwidth through proper arrangement among microrings and wavelengths with minimum power requirements. Our arrangement, called “MinTrim,” solves this problem using simple integer linear programming, adding supplementary microrings, and allowing flexible assignment of wavelengths to network nodes as long as the resulting network presents maximal bandwidth. Each step is shown to improve bandwidth provisioning with lower power requirements. Evaluations on a sample network show that a baseline network could lose more than 40% bandwidth due to PVs. Such loss can be recovered by MinTrim to produce a network with 98.4% working bandwidth. In addition, the power required for arranging microrings is 39% lower than the baseline. Therefore, MinTrim provides an efficient PV-tolerant solution to improving the reliability of on-chip photonics.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2878295330",
    "type": "article"
  },
  {
    "title": "MiC",
    "doi": "https://doi.org/10.1145/3304108",
    "publication_date": "2019-04-29",
    "publication_year": 2019,
    "authors": "Qixiao Liu; Zhifeng Chen; Zhibin Yu",
    "corresponding_authors": "",
    "abstract": "Graphics processing units (GPUs) 1 have enjoyed increasing popularity in recent years, which benefits from, for example, general-purpose GPU (GPGPU) for parallel programs and new computing paradigms, such as the Internet of Things (IoT). GPUs hold great potential in providing effective solutions for big data analytics while the demands for processing large quantities of data in real time are also increasing. However, the pervasive presence of GPUs on mobile devices presents great challenges for GPGPU, mainly because GPGPU integrates a large amount of processor arrays and concurrent executing threads (up to hundreds of thousands). In particular, the root causes of performance loss in a GPGPU program can not be revealed in detail by current approaches. In this article, we propose MiC (Multi-level Characterization), a framework that comprehensively characterizes GPGPU kernels at the instruction, Basic Block (BBL), and thread levels. Specifically, we devise Instruction Vectors (IV) and Basic Blocks Vectors (BBV), a Thread Similarity Matrix (TSM), and a Divergence Flow Statistics Graph (DFSG) to profile information in each level. We use MiC to provide insights into GPGPU kernels through the characterizations of 34 kernels from popular GPGPU benchmark suites such as Compute Unified Device Architecture (CUDA) Software Development Kit (SDK), Rodinia, and Parboil. In comparison with Central Processing Unit (CPU) workloads, we conclude the key findings as follows: (1) There are comparable Instruction-Level Parallelism (ILP); (2) The BBL count is significantly smaller than CPU workloads—only 22.8 on average; (3) The dynamic instruction count per thread varies from dozens to tens of thousands and it is extremely small compared to CPU benchmarks; (4) The Pareto principle (also called 90/10 rule) does not apply to GPGPU kernels while it pervasively exists in CPU programs; (5) The loop patterns are dramatically different from those in CPU workloads; (6) The branch ratio is lower than that of CPU programs but higher than pure GPU workloads. In addition, we have also shown how TSM and DFSG are used to characterize the branch divergence in a visual way, to enable the analysis of thread behavior in GPGPU programs. In addition, we show an optimization case for a GPGPU kernel from the bottleneck identified through its characterization result, which improves 16.8% performance.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2943671750",
    "type": "article"
  },
  {
    "title": "Evaluating the Potential Applications of Quaternary Logic for Approximate Computing",
    "doi": "https://doi.org/10.1145/3359620",
    "publication_date": "2019-10-15",
    "publication_year": 2019,
    "authors": "Christos Sakalis; Alexandra Jimborean; Stefanos Kaxiras; Magnus Själander",
    "corresponding_authors": "",
    "abstract": "There exist extensive ongoing research efforts on emerging atomic-scale technologies that have the potential to become an alternative to today’s complementary metal--oxide--semiconductor technologies. A common feature among the investigated technologies is that of multi-level devices, particularly the possibility of implementing quaternary logic gates and memory cells. However, for such multi-level devices to be used reliably, an increase in energy dissipation and operation time is required. Building on the principle of approximate computing, we present a set of combinational logic circuits and memory based on multi-level logic gates in which we can trade reliability against energy efficiency. Keeping the energy and timing constraints constant, important data are encoded in a more robust binary format while error-tolerant data are encoded in a quaternary format. We analyze the behavior of the logic circuits when exposed to transient errors caused as a side effect of this encoding. We also evaluate the potential benefit of the logic circuits and memory by embedding them in a conventional computer system on which we execute jpeg, sobel, and blackscholes approximately. We demonstrate that blackscholes is not suitable for such a system and explain why. However, we also achieve dynamic energy reductions of 10% and 13% for jpeg and sobel, respectively, and improve execution time by 38% for sobel, while maintaining adequate output quality.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2980656871",
    "type": "article"
  },
  {
    "title": "Guest Editors’ Introduction to the Special Section on Hardware and Algorithms for Energy-Constrained On-chip Machine Learning",
    "doi": "https://doi.org/10.1145/3322433",
    "publication_date": "2019-04-30",
    "publication_year": 2019,
    "authors": "Jae-sun Seo; Yu Cao; Xin Li; Paul N. Whatmough",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2983898767",
    "type": "article"
  },
  {
    "title": "Thread Batching for High-performance Energy-efficient GPU Memory Design",
    "doi": "https://doi.org/10.1145/3330152",
    "publication_date": "2019-10-31",
    "publication_year": 2019,
    "authors": "Bing Li; Mengjie Mao; Xiaoxiao Liu; Tao Liu; Zihao Liu; Wujie Wen; Yiran Chen; Hai Li",
    "corresponding_authors": "",
    "abstract": "Massive multi-threading in GPU imposes tremendous pressure on memory subsystems. Due to rapid growth in thread-level parallelism of GPU and slowly improved peak memory bandwidth, memory becomes a bottleneck of GPU’s performance and energy efficiency. In this article, we propose an integrated architectural scheme to optimize the memory accesses and therefore boost the performance and energy efficiency of GPU. First, we propose a thread batch enabled memory partitioning (TEMP) to improve GPU memory access parallelism. In particular, TEMP groups multiple thread blocks that share the same set of pages into a thread batch and applies a page coloring mechanism to bound each stream multiprocessor (SM) to the dedicated memory banks. After that, TEMP dispatches the thread batch to an SM to ensure high-parallel memory-access streaming from the different thread blocks. Second, a thread batch-aware scheduling (TBAS) scheme is introduced to improve the GPU memory access locality and to reduce the contention on memory controllers and interconnection networks. Experimental results show that the integration of TEMP and TBAS can achieve up to 10.3% performance improvement and 11.3% DRAM energy reduction across diverse GPU applications. We also evaluate the performance interference of the mixed CPU+GPU workloads when they are run on a heterogeneous system that employs our proposed schemes. Our results show that a simple solution can effectively ensure the efficient execution of both GPU and CPU applications.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2996377014",
    "type": "article"
  },
  {
    "title": "Toward Practical Superconducting Accelerators for Machine Learning Using U-SFQ",
    "doi": "https://doi.org/10.1145/3653073",
    "publication_date": "2024-04-09",
    "publication_year": 2024,
    "authors": "Patricia Gonzalez-Guerrero; Kylie Huch; Nirmalendu Patra; Doru Thom Popovici; George Michelogiannakis",
    "corresponding_authors": "",
    "abstract": "Most popular superconducting circuits operate on information carried by ps-wide, μV-tall, single flux quantum (SFQ) pulses. These circuits can operate at frequencies of hundreds of GHz with orders of magnitude lower switching energy than complementary-metal-oxide-semiconductors (CMOS). However, under the stringent area constraints of modern superconductor technologies, fully-fledged, CMOS-inspired superconducting architectures cannot be fabricated at large scales. Unary SFQ (U-SFQ) is an alternative computing paradigm that can address these area constraints. In U-SFQ, information is mapped to a combination of streams of SFQ pulses and in the temporal domain. In this work, we extend U-SFQ to introduce novel building blocks such as a multiplier and an accumulator. These blocks reduce area and power consumption by 2 \\(\\times\\) and 4 \\(\\times\\) compared with previously proposed U-SFQ building blocks and yield at least 97% area savings compared with binary approaches. Using these multiplier and adder, we propose a U-SFQ Convolutional Neural Network (CNN) hardware accelerator capable of comparable peak performance with state-of-the-art superconducting binary approach (B-SFQ) in 32 \\(\\times\\) less area. CNNs can operate with 5–8 bits of resolution with no significant degradation in classification accuracy. For 5 bits of resolution, our proposed accelerator yields 5 \\(\\times\\) to 63 \\(\\times\\) better performance than CMOS and 15 \\(\\times\\) to 173 \\(\\times\\) better area efficiency than B-SFQ.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4394598493",
    "type": "article"
  },
  {
    "title": "Exploiting the Extended Neighborhood of Hexagonal Qubit Architecture for Mapping Quantum Circuits",
    "doi": "https://doi.org/10.1145/3688391",
    "publication_date": "2024-08-20",
    "publication_year": 2024,
    "authors": "Abhoy Kole; Kamalika Datta; Indranil Sengupta; Rolf Drechsler",
    "corresponding_authors": "",
    "abstract": "In this work mapping of quantum circuits to regular hexagonal grid with coupling degree of six has been investigated. Architectures involving superconducting qubits impose restrictions on 2-qubit gate operations to be carried out only between physically coupled qubits, also referred to as Nearest Neighbour (NN) Constraint. The noise introduced by the 2-qubit gates and the execution time greatly affect the computational reliability. Existing mapping techniques suffer either from the adopted approach to reduce gate overhead or from their inability to take advantage of such architectural regularity. We outlined three different qubit mapping approaches using Remote-CNOT templates, Swap gates and combination of both. We show the benefits of assigning the Cartesian coordinate system in hexagonal grid for runtime elevation and devised approaches for reduction in gate overheads. While the template-based approach gives a strict upper bound of additional gate overheads for a particular qubit mapping, the combined approach provides better result employing a larger lookahead window. Experiments on benchmark quantum circuits confirm that the proposed Swap-based method provides an average \\(25\\%\\) improvement in gate overheads over a recent work and the combined approach contributes further \\(15\\%\\) average improvement on the result at the expense of a little higher runtime.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4402100282",
    "type": "article"
  },
  {
    "title": "HDRLPIM: A Simulator for <u>H</u> yper <u>D</u> imensional <u>R</u> einforcement <u>L</u> earning based on <u>P</u> rocessing <u>I</u> n <u>M</u> emory",
    "doi": "https://doi.org/10.1145/3695875",
    "publication_date": "2024-09-12",
    "publication_year": 2024,
    "authors": "Mariam Rakka; W. Amer; Hanning Chen; Mohsen Imani; Fadi Kurdahi",
    "corresponding_authors": "",
    "abstract": "Processing In-Memory (PIM) is a data-centric computation paradigm that performs computations inside the memory, hence eliminating the memory wall problem in traditional computational paradigms used in Von-Neumann architectures. The associative processor, a type of PIM architecture, allows performing parallel and energy-efficient operations on vectors. This architecture is found useful in vector-based applications such as Hyper-Dimensional (HDC) Reinforcement Learning (RL). HDC is rising as a new powerful and lightweight alternative to costly traditional RL models such as Deep Q-Learning. The HDC implementation of Q-Learning relies on encoding the states in a high-dimensional representation where calculating Q-values and finding the maximum one can be done entirely in parallel. In this paper, we propose to implement the main operations of a hyper-dimensional reinforcement learning framework on the associative processor. This acceleration achieves up to \\(152.3\\times\\) and \\(6.4\\times\\) energy and time savings compared to an FPGA implementation. Moreover, HDRLPIM shows that an SRAM-based AP implementation promises up to \\(968.2\\times\\) energy-delay product gains compared to the FPGA implementation.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4402483632",
    "type": "article"
  },
  {
    "title": "F-Bypass: a low-power network-on-chip design utilizing bypass to improve network connectivity",
    "doi": "https://doi.org/10.1145/3695874",
    "publication_date": "2024-09-19",
    "publication_year": 2024,
    "authors": "Yiming Ouyang; Shuaijie Yuan; Jianhua Li; Huaguo Liang",
    "corresponding_authors": "",
    "abstract": "With the development of transistor feature size to nanometer level, static power consumption has gradually become the main factor affecting the overall power consumption of network on chip (NoC). Power gating is an effective technology to reduce static power consumption, but it also brings new challenges, such as BET violation, wake-up latency and network connectivity. Therefore, a power gating method is needed to improve NoC performance and reduce static power consumption. This paper proposes a low-power bypass method, namely Forwarding bypass (F-Bypass). First, F-Bypass adds bypass paths between all input and output ports and the network interface (NI), and connects the pop-up port and injection port in NI through the bypass path. When the router is powered off, F-Bypass performs wake-up-free packet transmission, which reduces the break-even time (BET) violation and cumulative wake-up latency while ensuring network connectivity. Secondly, This paper add the modified VC state table to NI, so that the power-off router can perform normal traffic control. Finally, a new wake-up criterion is proposed, which can effectively avoid the frequent wake-up of power-off routers, and the detailed hardware implementation of F-Bypass is provided.The simulation results under integrated traffic load show that compared with the traditional scheme, the delay of F-Bypass is reduced by 2.2%, the throughput is increased by 13.1%, and the total static power consumption is reduced by 75.2%. Key performance indicators are superior to other solutions, and the increased area cost is moderate.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4402640046",
    "type": "article"
  },
  {
    "title": "Construction of consistent SysML models applied to the CPS",
    "doi": "https://doi.org/10.1145/3702326",
    "publication_date": "2024-10-30",
    "publication_year": 2024,
    "authors": "Adel Khelifati; Malika Ioualalen; Ahmed Hammad",
    "corresponding_authors": "",
    "abstract": "With the increasing complexity of cyber-physical systems (CPS), it is interesting to decompose a CPS into sub-systems. This provides greater modularity and flexibility so that each system can be developed independently, making it easier to maintain. Also, it can improve its fault tolerance. However, this decomposition of the system can lead to inconsistency. This paper proposes an approach for early verification of cyber-physical systems decomposition using SysML. We address the limitations of SysML as a semi-formal language by introducing syntax and static semantics for its structural diagrams. The aim is to verify structural consistency before defining behavioral aspects. For that, the proposed approach verifies a set of structural consistency rules within a refinement relation to ensure that sub-components offer at least the same services as the abstract block and require the same services. Furthermore, the sub-blocks must satisfy all the requirements that the abstract block is supposed to verify. We used the CyCab as a case study to demonstrate the effectiveness of this approach.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4403922684",
    "type": "article"
  },
  {
    "title": "Automated design flow for diode-based nanofabrics",
    "doi": "https://doi.org/10.1145/1167943.1167946",
    "publication_date": "2006-07-01",
    "publication_year": 2006,
    "authors": "Kushal Datta; Arindam Mukherjee; Arun Ravindran",
    "corresponding_authors": "",
    "abstract": "We present an automated design flow for minimizing the use of diodes and switches (active devices) in design implementations on a nanofabric based on chemically self-assembled electronic nanotechnology as proposed in Goldstein and Budiu [2001]. Connectivity and logic in the nanofabric are realized using the switch and diode behaviors of molecular devices, unlike very large scale integrated (VLSI) circuits where complementary metal-oxide semiconductor (CMOS) gates are used. Similar to the optimization goal of reducing the number of gates in VLSI designs to minimize area, power dissipation, and delay, decreasing the number of switches and diodes used in the nanofabric can potentially minimize design implementation area and power dissipation, besides reducing the delay and signal drop between latched stages in order to improve performance. An integrated placement, topology selection, and routing approach for design implementation on the nanofabric is proposed. Note that this problem is fundamentally different from CMOS VLSI placement and routing because of the inherent routing-dependent logic realization in our target nanofabric. To the best of our knowledge this is the first reported work on automated integrated placement, topology selection, and routing for diode-based nanofabrics. A practical and scalable simulated annealing-based placement and routing algorithm has been implemented. On average, the integrated placement and routing approach achieves a reduction of 12% in the number of switches and diodes used for MCNC benchmarks, compared to separate placement and routing optimization results. The maximum reduction achieved in the number of active devices using our approach is 24%, and in general, we observed that the bigger the benchmark, the larger the improvement achieved.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2013914613",
    "type": "article"
  },
  {
    "title": "Hardware and Software Co-optimization for the Initialization Failure of the ReRAM-based Cross-bar Array",
    "doi": "https://doi.org/10.1145/3393669",
    "publication_date": "2020-07-07",
    "publication_year": 2020,
    "authors": "Young‐Seok Kim; Seyoung Kim; Chun-Chen Yeh; V. Narayanan; Jungwook Choi",
    "corresponding_authors": "",
    "abstract": "Recent advances in deep neural network demand more than millions of parameters to handle and mandate the high-performance computing resources with improved efficiency. The cross-bar array architecture has been considered as one of the promising deep learning architectures that shows a significant computing gain over the conventional processors. To investigate the feasibility of the architecture, we examine non-idealities and their impact on the performance. Specifically, we study the impact of failed cells due to the initialization process of the resistive memory-based cross-bar array. Unlike the conventional memory array, individual memory elements cannot be rerouted and, thus, may have a critical impact on model accuracy. We categorize the possible failures and propose hardware implementation that minimizes catastrophic failures. Such hardware optimization bounds the possible logical value of the failed cells and allows us to compensate for the loss of accuracy via off-line training. By introducing the random weight defects during the training, we show that the model becomes more resilient on the device initialization failures, therefore, less prone to degrade the inference performance due to the failed devices. Our study sheds light on the hardware and software co-optimization procedure to cope with potentially catastrophic failures in the cross-bar array.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W3006306922",
    "type": "article"
  },
  {
    "title": "Permutation Network De-obfuscation",
    "doi": "https://doi.org/10.1145/3371407",
    "publication_date": "2020-01-28",
    "publication_year": 2020,
    "authors": "Zimu Guo; Sreeja Chowdhury; Mark Tehranipoor; Domenic Forte",
    "corresponding_authors": "",
    "abstract": "Permutation-based obfuscation has been proposed to protect hardware against cloning, overproduction, reverse engineering, and unauthorized operation. To prevent key extraction from memory, the key used by the obfuscation is usually stored in volatile memory. Since the key is erased after the system loses power, this scheme is often considered the best way to prevent a key from being stolen, since many attacks would require power. However, in this article, we propose a new attack where the key is determined by exploring path aging within the permutation network used for obfuscation. Both the theoretical analysis and experimental results are provided. A practical procedure to achieve the proposed attack is also discussed in the context of an attacker’s capabilities and knowledge. The proposed attack is executed in both simulation and hardware. The experimental results show the accuracy of identifying the key is over 80% and more than enough to reduce the number of brute-force combinations required by an attacker. This attack accuracy reaches 100% when the permutation network has experienced sufficient degradations. Besides the attack, we also propose a low-cost countermeasure that sweeps the permutation network configurations. Incorporating this countermeasure, the proposed attack becomes no better than brute-force guessing.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W3010140161",
    "type": "article"
  },
  {
    "title": "On Providing OS Support to Allow Transparent Use of Traditional Programming Models for Persistent Memory",
    "doi": "https://doi.org/10.1145/3388637",
    "publication_date": "2020-06-23",
    "publication_year": 2020,
    "authors": "J. Hyun Kim; Young Je Moon; Hyunsub Song; Jay Park; Sam H. Noh",
    "corresponding_authors": "",
    "abstract": "The advent of persistent memory (PM) into our everyday computing environment is now imminent. New programming models and algorithms based on these models are being developed for such systems. However, current models require programs to be rewritten with persistence related primitives such as clflush and clwb or at least recompiled so that persistent mechanisms can be automatically inserted. This is a burden to program developers. Furthermore, executing legacy programs as-is can lead to application and system inconsistencies as unexpected faults occur. In this article, we propose µSnap, an operating system support that is based on checkpointing that allows legacy applications to be executed as-is without compromising consistency in systems that deploy PM. We implement a prototype of µSnap in the Linux kernel version 4.3.3, and measure and quantify the effect of µSnap for a wide range of applications. We find that µSnap incurs overhead for application execution compared to applications run without any notion of persistency, but that the overhead can be controlled to be minimal by appropriately setting the checkpointing interval. We argue that the benefit for paying this small cost can be tremendous in the sense that one can transparently guarantee the consistency of all legacy software written under the traditional programming model.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W3037414872",
    "type": "article"
  },
  {
    "title": "Parallel Computing of Graph-based Functions in ReRAM",
    "doi": "https://doi.org/10.1145/3453163",
    "publication_date": "2022-01-12",
    "publication_year": 2022,
    "authors": "Saman Froehlich; Saeideh Shirinzadeh; Rolf Drechsler",
    "corresponding_authors": "",
    "abstract": "Resistive Random Access Memory (ReRAM) is an emerging non-volatile memory technology. Besides its low power consumption and its high scalability, its inherent computation capabilities make ReRAM especially interesting for future computer architectures. Merging computations into the memory is a promising solution for overcoming the memory bottleneck. To perform computations in ReRAM, efficient synthesis strategies for Boolean functions have to be developed. In this article, we give a thorough presentation of how to employ parallel computing capabilities of ReRAM for the synthesis of functions given state-of-the-art graph-based representations AIGs or BDDs. Additionally, we introduce a new graph-based representation called m-And-Inverter Graph (m-AIGs), which allows us to fully exploit the computing capabilities of ReRAM. In the simulations, we show that our proposed approaches outperform state-of-the art synthesis strategies, and we show the superiority of m-AIGs over the standard AIG representation for ReRAM-based synthesis.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4205545244",
    "type": "article"
  },
  {
    "title": "Early Design Space Exploration Framework for Memristive Crossbar Arrays",
    "doi": "https://doi.org/10.1145/3461644",
    "publication_date": "2022-01-12",
    "publication_year": 2022,
    "authors": "Md Adnan Zaman; Rajeev Joshi; Srinivas Katkoori",
    "corresponding_authors": "",
    "abstract": "For memristive crossbar arrays, currently, no high-level design validation and early space exploration tools exist in the literature. Such tools are essential to quickly verify the design functionality as well as compare design alternatives in terms of power and performance. In this work, we propose a VHDL-based framework that enables us to quickly perform behavioral simulation as well as estimate dynamic energy consumption and speed of any large memristive crossbar array. We propose a high-level (VHDL) model of a memristor based on which crossbar architectures can be modeled. The individual memristor model is embedded with power and delay numbers obtained from a detailed memristor model. We demonstrate the framework for MAGIC-style memristive crossbars. We validate the framework against detailed Verilog-A based model on fifteen combinational benchmarks. For the single row model, we obtained 153x simulation speedup over HSPICE, average estimation errors of 6.64% and 0% for dynamic energy consumption and cycle-time, respectively. For the transpose model, we obtained average estimation errors of 5.51% and 10.90% for dynamic energy consumption and cycle-time, respectively. We also extend our framework to support another prominent logic style and validate through a case study. The proposed framework can be easily extended to other emerging technologies.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4206136645",
    "type": "article"
  },
  {
    "title": "Diverse, Neural Trojan Resilient Ecosystem of Neural Network IP",
    "doi": "https://doi.org/10.1145/3471189",
    "publication_date": "2022-02-02",
    "publication_year": 2022,
    "authors": "Brooks Olney; Robert Karam",
    "corresponding_authors": "",
    "abstract": "Adversarial machine learning is a prominent research area aimed towards exposing and mitigating security vulnerabilities in AI/ML algorithms and their implementations. Data poisoning and neural Trojans enable an attacker to drastically change the behavior and performance of a Convolutional Neural Network (CNN) merely by altering some of the input data during training. Such attacks can be catastrophic in the field, e.g. for self-driving vehicles. In this paper, we propose deploying a CNN as an ecosystem of variants , rather than a singular model. The ecosystem is derived from the original trained model, and though every derived model is structurally different, they are all functionally equivalent to the original and each other. We propose two complementary techniques: stochastic parameter mutation , where the weights θ of the original are shifted by a small, random amount, and a delta-update procedure which functions by XOR’ing all of the parameters with an update file containing the Δ θ values. This technique is effective against transferability of a neural Trojan to the greater ecosystem by amplifying the Trojan’s malicious impact to easily detectable levels; thus, deploying a model as an ecosystem can render the ecosystem more resilient against a neural Trojan attack.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4210545534",
    "type": "article"
  },
  {
    "title": "Unsupervised Digit Recognition Using Cosine Similarity In A Neuromemristive Competitive Learning System",
    "doi": "https://doi.org/10.1145/3473036",
    "publication_date": "2022-03-10",
    "publication_year": 2022,
    "authors": "Bon Woong Ku; Catherine D. Schuman; Md Musabbir Adnan; Tiffany M. Mintz; Raphael C. Pooser; Kathleen E. Hamilton; Garrett S. Rose; Sung Kyu Lim",
    "corresponding_authors": "",
    "abstract": "This work addresses how to naturally adopt the l 2 -norm cosine similarity in the neuromemristive system and studies the unsupervised learning performance on handwritten digit image recognition. Proposed architecture is a two-layer fully connected neural network with a hard winner-take-all (WTA) learning module. For input layer, we propose single-spike temporal code that transforms input stimuli into the set of single spikes with different latencies and voltage levels. For a synapse model, we employ a compound memristor where stochastically switching binary-state memristors connected in parallel, which offers a reliable and scalable multi-state solution for synaptic weight storage. Hardware-friendly synaptic adaptation mechanism is proposed to realize spike-timing-dependent plasticity learning. Input spikes are sent out through those memristive synapses to each and every integrate-and-fire neuron in the fully connected output layer, where the hard WTA network motif introduces the competition based on cosine similarity for the given input stimuli. Finally, we present 92.64% accuracy performance on unsupervised digit recognition with only single-epoch MNIST dataset training via high-level simulations, including extensive analysis on the impact of system parameters.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4220824231",
    "type": "article"
  },
  {
    "title": "Security Assessment of Phase-Based Ranging Systems in a Multipath Environment",
    "doi": "https://doi.org/10.1145/3517809",
    "publication_date": "2022-03-23",
    "publication_year": 2022,
    "authors": "Arslan Riaz; Dylan Nash; Jonathan Ngo; Chiraag Juvekar; Phillip Nadeau; Tao Yu; Rabia Tugce Yazicigil",
    "corresponding_authors": "",
    "abstract": "Phase-based ranging has been widely deployed in proximity detection scenarios including security-critical applications due to their low implementation complexity on existing transceivers. In this work, the security of multi-carrier phase-based ranging systems in a multipath propagation environment is investigated. We present a threat model that can successfully target any decreasing distance in different multipath environmental conditions rendering the phase-based ranging method insecure. We assess the feasibility of attacks in various attack scenarios through simulations using a multipath channel and demonstrate a simplified version of the attacker model implemented in hardware. We show that the attacker can spoof the measured distance to less than one meter when the devices are separated by 30 meters. The evaluation of possible countermeasures and their limitations for different threat models is performed.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4220920509",
    "type": "article"
  },
  {
    "title": "Editorial",
    "doi": "https://doi.org/10.1145/1063803.1063804",
    "publication_date": "2005-03-01",
    "publication_year": 2005,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "editorial Free AccessEditorial Share on Editors: Mary Jane Irwin View Profile , Vijaykrishnan Narayanan View Profile Authors Info & Claims ACM Journal on Emerging Technologies in Computing SystemsVolume 1Issue 1April 2005 pp 1–6https://doi.org/10.1145/1063803.1063804Online:01 March 2005Publication History 1citation1,491DownloadsMetricsTotal Citations1Total Downloads1,491Last 12 Months44Last 6 weeks2 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4245279092",
    "type": "editorial"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1116696",
    "publication_date": "2005-10-01",
    "publication_year": 2005,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "The design of circuits and systems in Quantum-dot Cellular Automata (QCA) is still in infancy. The basic logic primitive in QCA is the majority voter (MV), that is not a universal function; so, inverters (INV) are also required. Blocks (referred to as ...",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4246607237",
    "type": "paratext"
  },
  {
    "title": "A CNN Hardware Accelerator Using Triangle-based Convolution",
    "doi": "https://doi.org/10.1145/3544975",
    "publication_date": "2022-06-27",
    "publication_year": 2022,
    "authors": "Amal Thomas K; Soumyajit Poddar; Hemanta Kumar Mondal",
    "corresponding_authors": "",
    "abstract": "Convolutional neural networks (CNNs) have gained a massive impression in the fields of computer vision and especially in the embedded applications because of their high accuracy and performance. However, high computational complexity and power consumption due to convolution operations causes a high demand for low-power accelerators. A 3D geometric optimization strategy is proposed to alleviate the area and power requirements of Multiply Accumulate operations prevalent in all spatial CNNs. The proposed technique is generic and may be easily scaled for accelerators performing spatial 2D convolution.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4283575489",
    "type": "article"
  },
  {
    "title": "Testable cross-power domain interface (CPDI) circuit design in monolithic 3D technology",
    "doi": "https://doi.org/10.1145/2629516",
    "publication_date": "2014-10-06",
    "publication_year": 2014,
    "authors": "Jing Xie; Yang Du; Yuan Xie",
    "corresponding_authors": "",
    "abstract": "Optimizing energy consumption for electronic systems has been an important design consideration. Multipower domain design is widely used for low-power and high-performance applications. Data transfer between power domains needs a cross-power domain interface (CPDI). The existing level-conversion flip-flop (LCFF) structures all need dual power rails, which lead to large area and performance overhead. In this article, we propose a scanable CPDI circuit, utilizing monolithic 3D technology. This interface functions as a flip-flop and provides reliable data conversion from one power domain to another. It has a built-in scan feature, which makes it a testable design. Our design separates power rails in each tier, substantially reducing physical design complexity and area penalty. The design is implemented in a 20nm, 28nm, and 45nm low-power technology. It shows a 20%--35% smaller insertion delay compared to normal designs. This proposed design also shows scalability and better energy consumption than previous LCFF circuits.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W1984606362",
    "type": "article"
  },
  {
    "title": "Introduction to",
    "doi": "https://doi.org/10.1145/2767131",
    "publication_date": "2015-09-21",
    "publication_year": 2015,
    "authors": "Yiyu Shi; Takashi Satō",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2047574584",
    "type": "article"
  },
  {
    "title": "Application-Specific Cross-Layer Optimization Based on Predictive Variable-Latency VLSI Design",
    "doi": "https://doi.org/10.1145/2746341",
    "publication_date": "2015-09-21",
    "publication_year": 2015,
    "authors": "Vivek De; Andrew B. Kahng; Tanay Karnik; Bao Liu; Milad Maleki; Lu Wang",
    "corresponding_authors": "",
    "abstract": "Traditional synchronous VLSI design requires that all computations in a logic stage complete in one clock cycle. This leads to increasingly pessimistic design as technology scaling introduces increasingly significant parametric variations that result in an increasing performance variability. Alternatively, by allowing computations in a logic stage to complete in a variable number of clock cycles, variable-latency design provides relaxed timing constraints for average performance, area, and power consumption optimization. In this article, we present improved variable-latency design techniques including: (1) a generic minimum-intrusion variable-latency VLSI design paradigm, (2) a signal probability-based approximate prediction logic construction method for minimum misprediction rate at minimum cost, and (3) an application-specific cross-layer analysis methodology. Our experiments show that the proposed variable-latency design methodology on average reduces the computation latency by 26.80%(14.65%) at cost of 0.08%(3.4%) area and 0.4%(2.2%) energy consumption increase for the interger (floating point) unit of an open-source SPARC V8 processor LEON2 synthesized with a clock-cycle time between 1.97ns(3.49ns) and 5.96ns(13.74ns) based on the 45nm Nangate open cell library, while an automotive application-specific design further achieves an average latency reduction of 41.8%.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2063640396",
    "type": "article"
  },
  {
    "title": "A Cross-Layer Approach to Measure the Robustness of Integrated Circuits",
    "doi": "https://doi.org/10.1145/2743022",
    "publication_date": "2015-09-21",
    "publication_year": 2015,
    "authors": "Martin Barke; Ulf Schlichtmann",
    "corresponding_authors": "",
    "abstract": "The demands on system robustness and its immunity against perturbations are getting increasingly important. Nearly everybody has an intuitive understanding of what robustness means, but there is no proper way how to measure robustness of integrated circuits already during the design phase. Therefore, a general cross-layer robustness model and methods to quantitatively measure robustness are presented. Moreover, these methods are refined to predict the robustness against degradation of digital circuits due to aging effects.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2071443552",
    "type": "article"
  },
  {
    "title": "Special Issue on Emerging Many-Core Systems for Exascale Computing",
    "doi": "https://doi.org/10.1145/2717312",
    "publication_date": "2015-04-27",
    "publication_year": 2015,
    "authors": "Masoud Daneshtalab; Farhad Mehdipour; Zhiyi Yu; Hannu Tenhunen",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2094938062",
    "type": "article"
  },
  {
    "title": "Introduction to the Special Issue on Reversible Computation",
    "doi": "https://doi.org/10.1145/2663349",
    "publication_date": "2014-11-18",
    "publication_year": 2014,
    "authors": "Robert Wille; Rolf Drechsler; Mehdi B. Tahoori",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2102997815",
    "type": "article"
  },
  {
    "title": "Effect of the Active Layer on Carbon Nanotube-Based Cells for Yield Analysis",
    "doi": "https://doi.org/10.1145/2602157",
    "publication_date": "2014-05-01",
    "publication_year": 2014,
    "authors": "Matthias Beste; Mehdi B. Tahoori",
    "corresponding_authors": "",
    "abstract": "Carbon Nanotube Field Effect Transistor (CNTFET)--based technologies become more and more a concurrent alternative to Metal Oxide Semiconductor Field Effect Transistors (MOSFET) technologies. In contrast to a MOSFET technology, the active layer of a CNTFET technology is not a regular silicon film with homogeneous doping and rectangular dimensions, but an array of mostly aligned carbon nanotubes (CNTs). The quality of this active layer, which depends on various technology process parameters, is expressed by parameters such as CNT alignment and array density. These parameters affect the electrical properties of the logic cells placed on top of the active layer and hence the overall CNTFET circuit yield. Although not all parameters in CNT fabrication process can be fully controlled, designers still need to assure a very high yield of their cell layouts, that is, a high reproducibility of the electrical characteristics to achieve a reasonable manufacturing yield for the entire chip. In this work we close the gap between CNTFET process fabrication and circuit design by presenting a novel accurate model for active layers in CNTFET--based technologies. Our model enables the designers to obtain technology--dependent driver strength of the custom cell layouts under realistic conditions. The new model can also be used to extract and evaluate CNTFET Design for Manufacturing (DfM) and Design for Robustness (DfR) design rules, and provide feedback to adjust process technology parameters to achieve desirable functional yield.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2135391845",
    "type": "article"
  },
  {
    "title": "SCKVdd",
    "doi": "https://doi.org/10.1145/2790754",
    "publication_date": "2015-08-03",
    "publication_year": 2015,
    "authors": "Ching-Hwa Cheng",
    "corresponding_authors": "Ching-Hwa Cheng",
    "abstract": "It has been proposed that small amounts of energy dissipate when transfer through a rising Vdd. In typical power gate circuits, the PMOS transistors (P SW ) reduce the leakage of power by shutting off outer Vdd to the idle blocks. We expand this technique by utilizing active P SW , which are turned on and off by a clock signal. The proposed SCKVdd technique combines the power source gated mechanism and clock signal to generate stable progressive rising voltage to suppress peak and average currents effectively. The SCKVdd technique is a scalable, clock-controlled, self-stabilized voltage technique. This technique is easily implemented in generic digital circuits to reduce power dissipation. A normal CMOS circuit shows a dynamic power consumption increase proportional to the clock frequency. SCKVdd results in a lower-than-usual frequency dependency, and is suitable for high speed clock circuits. SCKVdd can be integrated with frequency, voltage scaling and an activated P SW number to implement an efficient power-performance trade-off mechanism. In experiments that investigated constant Vdd for MPEG VLD chips, power dissipation savings were in the range of 42% to 54% with only a small delay penalty.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2213258033",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2767119",
    "publication_date": "2015-04-27",
    "publication_year": 2015,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Neurobiological systems have often been a source of inspiration for computational science and engineering, but in the past their impact has also been limited by the understanding of biological models. Today, new technologies lead to an equilibrium ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4229971664",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2820112",
    "publication_date": "2015-09-02",
    "publication_year": 2015,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Nowadays, power consumption is one of the main limitations of electronic systems. In this context, novel and emerging devices provide new opportunities to extend the trend toward low-power design. In this survey article, we present a transversal survey ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4230079036",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2856147",
    "publication_date": "2016-07-26",
    "publication_year": 2016,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Improving the endurance of phase change memory (PCM) is a fundamental issue when PCM technology is considered as an alternative to main memory usage. Existing wear-leveling techniques overcome this challenge through constantly remapping hot virtual ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4231162160",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2810396",
    "publication_date": "2015-08-03",
    "publication_year": 2015,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Moore's law and the continuity of device scaling have led to an increasing number of cores/nodes on a chip, creating a need for new mechanisms to achieve high-performance and power-efficient Network-on-Chip (NoC). Nanophotonics based NoCs provide for ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4236695451",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2628070",
    "publication_date": "2014-05-01",
    "publication_year": 2014,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Wireless Network-on-Chip (WiNoC) has emerged as an enabling technology to design low power and high bandwidth massive multicore chips. WiNoCs based on small-world network architecture and designed with incorporating millimeter (mm)-wave on-chip wireless ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4239074373",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2614448",
    "publication_date": "2014-04-01",
    "publication_year": 2014,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "In this article, we investigate the impact of process variations on the speedup and maximum frequency of the extended ISA processor. First, without considering process variations, a custom functional unit (CFU) is designed based on nominal timing ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4240878416",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2828988",
    "publication_date": "2015-09-21",
    "publication_year": 2015,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Traditional synchronous VLSI design requires that all computations in a logic stage complete in one clock cycle. This leads to increasingly pessimistic design as technology scaling introduces increasingly significant parametric variations that result in ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4242171933",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2917757",
    "publication_date": "2016-12-06",
    "publication_year": 2016,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "In this work, we have studied two novel techniques to enhance the performance of existing geometry-based magnetoresistive RAM physically unclonable function (MRAM PUF). Geometry-based MRAM PUFs rely only on geometric variations in MRAM cells that ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4242363283",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2676581",
    "publication_date": "2014-10-06",
    "publication_year": 2014,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Mobility is the primary device parameter affecting circuit performance in flexible thin-film transistor (TFT) technologies, and is particularly sensitive to the change of mechanical strain and temperature. However, existing algorithms only consider the ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4254418032",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2711453",
    "publication_date": "2014-12-30",
    "publication_year": 2014,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "The goal of this special issue is to introduce the field of computational synthetic biology to engineers and computer scientists. The first article gives an introduction to the key biological principles and experimental techniques that support synthetic ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4255789203",
    "type": "paratext"
  },
  {
    "title": "Quit When You Can: Efficient Evaluation of Ensembles by Optimized Ordering",
    "doi": "https://doi.org/10.1145/3451209",
    "publication_date": "2021-07-14",
    "publication_year": 2021,
    "authors": "Serena Wang; Maya R. Gupta; Seungil You",
    "corresponding_authors": "",
    "abstract": "Given a classifier ensemble and a dataset, many examples may be confidently and accurately classified after only a subset of the base models in the ensemble is evaluated. Dynamically deciding to classify early can reduce both mean latency and CPU without harming the accuracy of the original ensemble. To achieve such gains, we propose jointly optimizing the evaluation order of the base models and early-stopping thresholds. Our proposed objective is a combinatorial optimization problem, but we provide a greedy algorithm that achieves a 4-approximation of the optimal solution under certain assumptions, which is also the best achievable polynomial-time approximation bound. Experiments on benchmark and real-world problems show that the proposed Quit When You Can (QWYC) algorithm can speed up average evaluation time by 1.8–2.7 times on even jointly trained ensembles, which are more difficult to speed up than independently or sequentially trained ensembles. QWYC’s joint optimization of ordering and thresholds also performed better in experiments than previous fixed orderings, including gradient boosted trees’ ordering.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W3177691784",
    "type": "article"
  },
  {
    "title": "Introduction to the Special Issue on Hardware-Assisted Security for Emerging Internet of Things",
    "doi": "https://doi.org/10.1145/3475952",
    "publication_date": "2021-09-29",
    "publication_year": 2021,
    "authors": "Saraju P. Mohanty; Jim Plusquellic; Garrett S. Rose; Wei Zhang; Maria K. Michael",
    "corresponding_authors": "",
    "abstract": "introduction Share on Introduction to the Special Issue on Hardware-Assisted Security for Emerging Internet of Things Editors: Saraju P. Mohanty University of North Texas University of North TexasView Profile , Jim Plusquellic University of New Mexico University of New MexicoView Profile , Garrett S. Rose University of Tennessee, Knoxville University of Tennessee, KnoxvilleView Profile , Wei Zhang Hong Kong University of Science and Technology Hong Kong University of Science and TechnologyView Profile , Maria K. Michael University of Cyprus University of CyprusView Profile Authors Info & Claims ACM Journal on Emerging Technologies in Computing SystemsVolume 18Issue 1January 2022 Article No.: 1pp 1–3https://doi.org/10.1145/3475952Online:29 September 2021Publication History 0citation90DownloadsMetricsTotal Citations0Total Downloads90Last 12 Months90Last 6 weeks12 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteGet Access",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W3203758958",
    "type": "article"
  },
  {
    "title": "Towards All-optical Stochastic Computing Using Photonic Crystal Nanocavities",
    "doi": "https://doi.org/10.1145/3484871",
    "publication_date": "2021-10-22",
    "publication_year": 2021,
    "authors": "Hassnaa El-Derhalli; Léa Constans; Sébastien Le Beux; Alfredo De Rossi; Fabrice Raineri; Sofiène Tahar",
    "corresponding_authors": "",
    "abstract": "Stochastic computing allows a drastic reduction in hardware complexity using serial processing of bit streams. While the induced high computing latency can be overcome using integrated optics technology, the design of realistic optical stochastic computing architectures calls for energy efficient switching devices. Photonics Crystal (PhC) nanocavities are μm 2 scale devices offering 100fJ switching operation under picoseconds-scale switching speed. Fabrication process allows controlling the Quality factor of each nanocavity resonance, leading to opportunities to implement architectures involving cascaded gates and multi-wavelength signaling. In this paper, we investigate the design of cascaded gates architecture using nanocavities in the context of stochastic computing. We propose a transmission model considering key nanocavity device parameters, such as Quality factors, resonance wavelength, and switching efficiency. The model is calibrated with experimental measurements. We propose the design of XOR gate and multiplexer. We illustrate the use of the gates to design an edge detection filter. System-level exploration of laser power, bit-stream length and bit-error rate is carried out for the processing of gray-scale images. The results show that the proposed architecture leads to 8.5nJ/pixel energy consumption and 512ns/pixel processing time.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W3208552176",
    "type": "article"
  },
  {
    "title": "A ReRAM Memory Compiler for Monolithic 3D Integrated Circuits in a Carbon Nanotube Process",
    "doi": "https://doi.org/10.1145/3466681",
    "publication_date": "2021-11-03",
    "publication_year": 2021,
    "authors": "Edward Lee; Daehyun Kim; Jinwoo Kim; Sung Kyu Lim; Saibal Mukhopadhyay",
    "corresponding_authors": "",
    "abstract": "We present a ReRAM memory compiler for monolithic 3D (M3D) integrated circuits (IC). We develop ReRAM architectures for M3D ICs using 1T-1R bit cells and single and multiple tiers of transistors for access and peripheral circuits. The compiler includes an automated flow for generation of subarrays of different dimensions and larger arrays of a target capacity by integrating multiple subarrays. The compiler is demonstrated using an M3D process design kit (PDK) based on a Carbon Nanotube Transistor technology. The PDK includes multiple layers of transistors and back-end-of-the-line integrated ReRAM. Simulations show the compiled ReRAM macros with multiple tiers of transistors reduces footprint and improves performance over the macros with single-tier transistors. The compiler creates layout views that are exported into library exchange format or graphic data system for full-array assembly and schematic/symbol views to extract per-bit read/write energy and read latency. Comparison of the proposed M3D subarray architectures with baseline 2D subarrays, generated with a custom-designed set of bit cells and peripherals, demonstrate up to 48% area reduction and 13% latency improvement.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W3208912666",
    "type": "article"
  },
  {
    "title": "Hardware Implementation of Hierarchical Temporal Memory Algorithm",
    "doi": "https://doi.org/10.1145/3479430",
    "publication_date": "2021-10-22",
    "publication_year": 2021,
    "authors": "Weifu Li; Paul D. Franzon; Sumon Dey; Joshua Schabel",
    "corresponding_authors": "",
    "abstract": "Hierarchical temporal memory (HTM) is an un-supervised machine learning algorithm that can learn both spatial and temporal information of input. It has been successfully applied to multiple areas. In this paper, we propose a multi-level hierarchical ASIC implementation of HTM, referred to as processor core, to support both spatial and temporal pooling. To improve the unbalanced workload in HTM, the proposed design provides different mapping methods for the spatial and temporal pooling, respectively. In the proposed design, we implement a distributed memory system by assigning one dedicated memory bank to each level of hierarchy to improve the memory bandwidth utilization efficiency. Finally, the hot-spot operations are optimized using a series of customized units. Regarding scalability, we propose a ring-based network consisting of multiple processor cores to support a larger HTM network. To evaluate the performance of our proposed design, we map an HTM network that includes 2,048 columns and 65,536 cells on both the proposed design and NVIDIA Tesla K40c GPU using the KTH database as input. The latency and power of the proposed design is 6.04 ms and 4.1 W using GP 65 nm technology. Compared to the equivalent GPU implementation, the latency and power is improved 12.45× and 57.32×, respectively.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W3210400199",
    "type": "article"
  },
  {
    "title": "Guest Editorial: Computation-In-Memory (CIM): from Device to Applications",
    "doi": "https://doi.org/10.1145/3503263",
    "publication_date": "2021-12-31",
    "publication_year": 2021,
    "authors": "Said Hamdioui; Elena Ioana Vatajelu; Alberto Bosio",
    "corresponding_authors": "",
    "abstract": "introduction Share on Guest Editorial: Computation-In-Memory (CIM): from Device to Applications Editors: Said Hamdioui Delft University of Technology, The Netherlands Delft University of Technology, The NetherlandsSearch about this author , Elena-Ioana Vatajelu TIMA, CNRS, INPG Université Grenoble Alpes, France TIMA, CNRS, INPG Université Grenoble Alpes, FranceSearch about this author , Alberto Bosio École Centrale de Lyon, Institute of nanotechnology, France École Centrale de Lyon, Institute of nanotechnology, FranceSearch about this author Authors Info & Claims ACM Journal on Emerging Technologies in Computing SystemsVolume 18Issue 2April 2022 Article No.: 31pp 1–3https://doi.org/10.1145/3503263Online:31 December 2021Publication History 0citation252DownloadsMetricsTotal Citations0Total Downloads252Last 12 Months252Last 6 weeks37 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteGet Access",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4205250363",
    "type": "editorial"
  },
  {
    "title": "ANT-UNet: Accurate and Noise-Tolerant Segmentation for Pathology Image Processing",
    "doi": "https://doi.org/10.1145/3451213",
    "publication_date": "2021-12-31",
    "publication_year": 2021,
    "authors": "Yufei Chen; Tingtao Li; Qinming Zhang; Wei Mao; Nan Guan; Mei Tian; Hao Yu; Cheng Zhuo",
    "corresponding_authors": "",
    "abstract": "Pathology image segmentation is an essential step in early detection and diagnosis for various diseases. Due to its complex nature, precise segmentation is not a trivial task. Recently, deep learning has been proved as an effective option for pathology image processing. However, its efficiency is highly restricted by inconsistent annotation quality. In this article, we propose an accurate and noise-tolerant segmentation approach to overcome the aforementioned issues. This approach consists of two main parts: a preprocessing module for data augmentation and a new neural network architecture, ANT-UNet. Experimental results demonstrate that, even on a noisy dataset, the proposed approach can achieve more accurate segmentation with 6% to 35% accuracy improvement versus other commonly used segmentation methods. In addition, the proposed architecture is hardware friendly, which can reduce the amount of parameters to one-tenth of the original and achieve 1.7× speed-up.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4225260191",
    "type": "article"
  },
  {
    "title": "Hybrid Redundancy for Defect Tolerance in Molecular Crossbar Memory",
    "doi": "https://doi.org/10.1145/2422094.2422101",
    "publication_date": "2013-02-01",
    "publication_year": 2013,
    "authors": "Shuo Wang; Jianwei Dai; Lei Wang",
    "corresponding_authors": "",
    "abstract": "Nano/molecular technologies have emerged as the potential fabrics for building future integrated systems. However, due to the imperfect fabrication process, these extremely scaled devices are vulnerable to a large number of defects and transient faults. Memory systems, which are the primary application targeted by these technologies, are particularly exposed to this problem due to the ultra-high integration density and elevated error sensitivity. In this article, we propose a defect-tolerant technique, referred to as hybrid redundancy allocation , for the design of molecular crossbar memory systems. By using soft redundancy (runtime exploitation of memory spatial/temporal locality) in combination with hardware redundancy (spare memory cells), the proposed technique can achieve better error management at a low cost as compared with conventional techniques. Simulation results demonstrate the significant improvement in defect tolerance, efficiency, and scalability of the proposed technique.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W1989508890",
    "type": "article"
  },
  {
    "title": "Introduction to Special Issue on Bioinformatics",
    "doi": "https://doi.org/10.1145/2536744.2536745",
    "publication_date": "2013-11-01",
    "publication_year": 2013,
    "authors": "Carlotta Guiducci",
    "corresponding_authors": "Carlotta Guiducci",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2073144547",
    "type": "article"
  },
  {
    "title": "Electrothermal analysis of spin-transfer-torque random access memory arrays",
    "doi": "https://doi.org/10.1145/2463585.2463591",
    "publication_date": "2013-05-01",
    "publication_year": 2013,
    "authors": "Subho Chatterjee; Sayeef Salahuddin; Satish Kumar; Saibal Mukhopadhyay",
    "corresponding_authors": "",
    "abstract": "Spin Transfer Torque RAM (STTRAM) is a promising candidate for fast, scalable, high-density, nonvolatile memory in nanometer technology. However, relatively high write current density and small volume of the memory device indicate the possibility of significant self-heating in the STTRAM structure. This article performs a critical analysis of the self-heating induced temperature variations in STTRAM. We perform a 3D finite volume method based study to characterize self-heating effect in a single cell. The analysis is extended for STTRAM arrays by developing a computationally efficient RC compact model based thermal analyzer. The analysis shows that self-heating can results in considerable increase in both steady-state value and transient change in temperature of individual cells. The effect is less pronounced at the array level and depends on the activity level, that is, number of active cells within an array size. The analysis further illustrates that self-heating negatively impacts electrical reliability metrics namely, read margin and detection accuracy; degrades cell performance; and modulates energy dissipation.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2080579980",
    "type": "article"
  },
  {
    "title": "Introduction to Special Issue",
    "doi": "https://doi.org/10.1145/2043643.2043644",
    "publication_date": "2011-12-01",
    "publication_year": 2011,
    "authors": "Montek Singh; Steven M. Nowick",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2123850654",
    "type": "article"
  },
  {
    "title": "Introduction to the special issue on memory technologies",
    "doi": "https://doi.org/10.1145/2463585.2463586",
    "publication_date": "2013-05-01",
    "publication_year": 2013,
    "authors": "Bipul C. Paul; Arijit Raychowdhury",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2151854801",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2043643",
    "publication_date": "2011-12-01",
    "publication_year": 2011,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "In the years to come new solutions will be required to overcome the limitations of scaled CMOS technology. One approach is to adopt Nano-Magnetic Logic Circuits, highly appealing for their extremely reduced power consumption. Despite the interesting ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4231108885",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2422094",
    "publication_date": "2013-02-01",
    "publication_year": 2013,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "DNA microarrays are used extensively for biochemical analysis that includes genomics and drug discovery. This increased usage demands large microarrays, thus complicating their computer aided design (CAD) and manufacturing methodologies. One such time-...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4237525929",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1899390",
    "publication_date": "2011-01-01",
    "publication_year": 2011,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "This article quantitatively considers the performance of nanomagnetic logic circuits within the context of realistic drive circuitry. We also demonstrate how one of the five fundamental tenets of digital logic---preventing unwanted feedback---can be ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4240166323",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2533711",
    "publication_date": "2013-09-01",
    "publication_year": 2013,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Reversible logic is gaining significance in the context of emerging technologies such as quantum computing since reversible circuits do not lose information during computation and there is one-to-one mapping between the inputs and outputs. In this work, ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4241163949",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2536744",
    "publication_date": "2013-11-01",
    "publication_year": 2013,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Genome annotation is one of the most important issues in the genomic era. The exponential growth rate of newly sequenced genomes and proteomes urges the development of fast and reliable annotation methods, suited to exploit all the information available ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4242524425",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2463585",
    "publication_date": "2013-05-01",
    "publication_year": 2013,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Memristive devices with a simple structure are not only very small but also very versatile, which makes them an ideal candidate used for the next generation computing system in the post-Si era. The working mechanism of the devices and a family of ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4250201624",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2000502",
    "publication_date": "2011-08-01",
    "publication_year": 2011,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Differential power analysis (DPA) is a side-channel attack that statistically analyzes the power consumption of a cryptographic system to obtain secret information. This type of attack is well known as a major threat to information security. Effective ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4253993780",
    "type": "paratext"
  },
  {
    "title": "Modeling and Designing for Accuracy and Energy Efficiency in Wireless Electroencephalography Systems",
    "doi": "https://doi.org/10.1145/2093145.2093148",
    "publication_date": "2012-02-01",
    "publication_year": 2012,
    "authors": "Jeremy R. Tolbert; Pratik Kabali; Simeranjit Brar; Saibal Mukhopadhyay",
    "corresponding_authors": "",
    "abstract": "Remote wireless monitoring of physiological signals has emerged as a key enabler for biotelemetry and can significantly improve the delivery of healthcare. Improving the energy efficiency and battery lifetime of the monitoring units without sacrificing the acquired signal quality is a key challenge in large-scale deployment of bioelectronic systems for remote wireless monitoring. In this article, we present a design methodology for accuracy aware, energy efficient wireless monitoring of electroencephalography (EEG) data. The proposed design performs a real-time accuracy energy trade-off by controlling the volume of transmitted data based on the information content in the EEG signal. We consider the effect of different system parameters in order to design an optimal system. We analyze the impact of noise of the wireless channel. Our analysis shows that the proposed system design approach can provide up to 10X energy savings in a 32 channel wireless EEG system with minimal impact on the monitored EEG signal accuracy.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W1969562058",
    "type": "article"
  },
  {
    "title": "Introduction to special section",
    "doi": "https://doi.org/10.1145/1543438.1543439",
    "publication_date": "2009-07-01",
    "publication_year": 2009,
    "authors": "R. Iris Bahar",
    "corresponding_authors": "R. Iris Bahar",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2058733836",
    "type": "article"
  },
  {
    "title": "Special section on new circuit and architecture-level solutions for multidiscipline systems",
    "doi": "https://doi.org/10.1145/2287696.2287697",
    "publication_date": "2012-08-01",
    "publication_year": 2012,
    "authors": "Saraju P. Mohanty",
    "corresponding_authors": "Saraju P. Mohanty",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2069803896",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1543438",
    "publication_date": "2009-07-01",
    "publication_year": 2009,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4230041313",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2367736",
    "publication_date": "2012-10-01",
    "publication_year": 2012,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "A world consisting of billions of service-oriented client devices and thousands of data centers can deliver a diverse range of services, from social networking to management of our natural resources. However, these services must scale in order to meet ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4232577996",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1482613",
    "publication_date": "2009-01-01",
    "publication_year": 2009,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Nanoelectronic devices are considered to be the computational fabrics for the emerging nanocomputing systems due to their ultra-high speed and integration density. However, the imperfect bottom-up self-assembly fabrication leads to excessive defects ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4233661385",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1629091",
    "publication_date": "2009-11-01",
    "publication_year": 2009,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Rapid progress on nanodevices points to a promising direction for future circuit design. However, since nanofabrication techniques are not yet mature, implementation of nanocircuits, at least on a large scale, in the near future is infeasible. To ease ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4239625863",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2287696",
    "publication_date": "2012-08-01",
    "publication_year": 2012,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "We have utilized our Multiwalled Carbon NanoTube (MWCNT) and Single-Walled Carbon NanoTube (SWCNT) bundle interconnects model in a widely used π model to study the performances of MWCNT and SWCNT bundle wire inductors and compared these with copper (Cu) ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4239736276",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1568485",
    "publication_date": "2009-08-01",
    "publication_year": 2009,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Among the emerging alternatives to CMOS, molecular electronics based diode-resistor crossbar fabric has generated considerable interest in recent times. Logic circuit design with future nano-scale molecular devices using dense and regular crossbar ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4240614805",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1777401",
    "publication_date": "2010-08-01",
    "publication_year": 2010,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4247734787",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2180878",
    "publication_date": "2012-06-01",
    "publication_year": 2012,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Implantable systems for biomedical research and clinical care are now a flourishing field of activities in academia as well as industrial institutions. The broad field includes experimental explorations in electronics, mechanical, chemical, and ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4248868174",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1721650",
    "publication_date": "2010-03-01",
    "publication_year": 2010,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4254319053",
    "type": "paratext"
  },
  {
    "title": "Editorial to special issue DAC 2006",
    "doi": "https://doi.org/10.1145/1295231.1295232",
    "publication_date": "2007-11-01",
    "publication_year": 2007,
    "authors": "Krishnendu Chakrabarty; Sachin S. Sapatnekar",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2027113660",
    "type": "article"
  },
  {
    "title": "Call for Papers DEADLINE",
    "doi": "https://doi.org/10.1145/1877745.1877749",
    "publication_date": "2008-12-21",
    "publication_year": 2008,
    "authors": "Montek Singh; Steven M. Nowick",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2046385713",
    "type": "paratext"
  },
  {
    "title": "Editorial",
    "doi": "https://doi.org/10.1145/1412587.1412588",
    "publication_date": "2008-10-01",
    "publication_year": 2008,
    "authors": "Yuan Xie; Jason Cong; Paul D. Franzon",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2050536866",
    "type": "editorial"
  },
  {
    "title": "Introduction to DAC 2007 special section",
    "doi": "https://doi.org/10.1145/1389089.1389090",
    "publication_date": "2008-08-01",
    "publication_year": 2008,
    "authors": "Krishnendu Chakrabarty",
    "corresponding_authors": "Krishnendu Chakrabarty",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2051576688",
    "type": "article"
  },
  {
    "title": "Introduction to design techniques for energy harvesting",
    "doi": "https://doi.org/10.1145/1773814.1773815",
    "publication_date": "2008-06-18",
    "publication_year": 2008,
    "authors": "Taşkın Koçak; Dhiraj K. Pradhan",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2063313664",
    "type": "article"
  },
  {
    "title": "Introduction to joint ACM JETC/TODAES special issue on new, emerging, and specialized technologies",
    "doi": "https://doi.org/10.1145/1350763.1350765",
    "publication_date": "2008-04-01",
    "publication_year": 2008,
    "authors": "R. Iris Bahar; Krishnendu Chakrabarty",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2066962525",
    "type": "article"
  },
  {
    "title": "SCT",
    "doi": "https://doi.org/10.1145/1389089.1389094",
    "publication_date": "2008-08-01",
    "publication_year": 2008,
    "authors": "Reza Rad; Mohammad Tehranipoor",
    "corresponding_authors": "",
    "abstract": "Novel strategies are necessary to efficiently test and configure emerging reconfigurable nanoscale devices, in addition to providing defect tolerance. This is mainly due to the high defect densities that are expected for these devices. Among different approaches, reconfiguration-based defect avoidance has proven to be a practical solution. However, configuration time, test time, and defect-map size remain among the major challenges for these new devices. In this article, we propose a new approach (called SCT) that simultaneously performs test and configuration. The proposed method uses a built-in self-test (BIST) scheme for test and defect tolerance. The method is based on testing reconfigurable nanoblocks at the time of implementing a function of a desired application on that block. The SCT method considerably reduces the total test and configuration time. It also eliminates the need for storing the location of defects in a defect map on- or off-chip. The presented probabilistic analysis results show the effectiveness of this method in terms of test and configuration time for architectures with rich interconnect resources. Also, a Verilog simulation model is developed for crossbar-based nano-architectures. This model is used to implement several MCNC benchmarks based on the proposed SCT method. The simulation results demonstrate efficiency of the method in terms of test time and yield under different defect rates.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2171136174",
    "type": "article"
  },
  {
    "title": "Guest Editorial Special Issue on Nanoelectronic Circuit and System Design Methods for the Mobile Computing Era",
    "doi": "https://doi.org/10.1145/3003370",
    "publication_date": "2017-02-03",
    "publication_year": 2017,
    "authors": "Aida Todri‐Sanial; Saraju P. Mohanty; Mariane Comte; Marc Belleville",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2584589659",
    "type": "editorial"
  },
  {
    "title": "Guest Editors’ Introduction",
    "doi": "https://doi.org/10.1145/3022193",
    "publication_date": "2017-02-09",
    "publication_year": 2017,
    "authors": "Yu Cao; Xin Li; Taemin Kim; Suyog Gupta",
    "corresponding_authors": "",
    "abstract": "editorial Free Access Share on Guest Editors’ Introduction: Hardware and Algorithms for On-Chip Learning Authors: Yu Cao Arizona State University, Tempe, Arizona Arizona State University, Tempe, ArizonaView Profile , Xin Li Carnegie Mellon University, Pittsburgh, PA Carnegie Mellon University, Pittsburgh, PAView Profile , Taemin Kim Intel, Hillsboro, OR Intel, Hillsboro, ORView Profile , Suyog Gupta Google, Mountain View, CA Google, Mountain View, CAView Profile Authors Info & Claims ACM Journal on Emerging Technologies in Computing SystemsVolume 13Issue 3July 2017 Article No.: 30pp 1–3https://doi.org/10.1145/3022193Published:09 February 2017Publication History 0citation335DownloadsMetricsTotal Citations0Total Downloads335Last 12 Months17Last 6 weeks1 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2587619888",
    "type": "article"
  },
  {
    "title": "Alleviate Chip Pin Constraint for Multicore Processor by On/Off-Chip Power Delivery System Codesign",
    "doi": "https://doi.org/10.1145/2914791",
    "publication_date": "2017-03-02",
    "publication_year": 2017,
    "authors": "Xuan Wang; Jiang Xu; Zhe Wang; Haoran Li; Zhehui Wang; Peng Yang; Luan H. K. Duong; Rafael K. V. Maeda; Zhifei Wang",
    "corresponding_authors": "",
    "abstract": "The number of chip pins is limited due to the cost and reliability issues of sophisticated packages, and it is predicted that the chip pin count will be overstretched to satisfy the requirements of both power delivery and memory access. The gap between the achievable pin count and the demand will increase as the technology scales, due to the increasing computation resources and supply current. Pin reduction techniques are thus required for continued computing performance growth. In this article, we propose a chip pin constraint alleviation strategy, through on/off-chip power delivery system co-design, to effectively reduce the demand for power pins. An analytical model of a power delivery system, consisting of on/off-chip regulators and a power delivery network, is proposed to evaluate the influence of regulator design and package conduction loss. By combining this model with a multi-core processor model of performance and memory bandwidth requirements, we characterize the entire multi-core processor system to investigate the relationship between the chip pin constraint and performance in multi-core processor scaling and the effectiveness of our strategy. Experiments show that with the conventional power delivery system design, the chip pin constraint severely limits the performance growth as the technology scales. Using the on/off-chip power delivery system co-design, our strategy achieves a significant pin count reduction, for example, 31.3% at the 8nm technology node, compared to the conventional design with the same chip performance, while, provided with the same chip pin count, it is able to improve, by 35.0%, the chip performance at 8nm compared to the conventional design. For real applications of different parallelism, our strategy outperforms its counterpart, with a 23.7% performance improvement on average at the 8nm technology node.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2591911176",
    "type": "article"
  },
  {
    "title": "Editorial for JETC Special Issue on Alternative Computing Systems",
    "doi": "https://doi.org/10.1145/3022700",
    "publication_date": "2017-03-17",
    "publication_year": 2017,
    "authors": "Rasit Onur Topaloglu; Naveen Verma",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2602711843",
    "type": "article"
  },
  {
    "title": "PPU",
    "doi": "https://doi.org/10.1145/2990502",
    "publication_date": "2017-04-14",
    "publication_year": 2017,
    "authors": "Pareesa Ameneh Golnari; Yavuz Yetim; Margaret Martonosi; Yakir Vizel; Sharad Malik",
    "corresponding_authors": "",
    "abstract": "With increasing technology scaling and design complexity there are increasing threats from device and circuit failures. This is expected to worsen with post-CMOS devices. Current error-resilient solutions ensure reliability of circuits through protection mechanisms such as redundancy, error correction, and recovery. However, the costs of these solutions may be high, rendering them impractical. In contrast, error-tolerant solutions allow errors in the computation and are positioned to be suitable for error-tolerant applications such as media applications. For such programmable error-tolerant processors, the Instruction-Set-Architecture (ISA) no longer serves as a specification since it is acceptable for the processor to allow for errors during the execution of instructions. In this work, we address this specification gap by defining the basic requirements needed for an error-tolerant processor to provide acceptable results. Furthermore, we formally define properties that capture these requirements. Based on this, we propose the Partially Protected Uniprocessor (PPU), an error-tolerant processor that aims to meet these requirements with low-cost microarchitectural support. These protection mechanisms convert potentially fatal control errors to potentially tolerable data errors instead of ensuring instruction-level or byte-level correctness. The protection mechanisms in PPU protect the system against crashes, unresponsiveness, and external device corruption. In addition, they also provide support for achieving acceptable result quality. Additionally, we provide a methodology that formally proves the specification properties on PPU using model checking. This methodology uses models for the hardware and software that are integrated with the fault and recovery models. Finally, we experimentally demonstrate the results of model checking and the application-level quality of results for PPU.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2607011034",
    "type": "article"
  },
  {
    "title": "Impact of Process Variation on Self-Reference Sensing Scheme and Adaptive Current Modulation for Robust STTRAM Sensing",
    "doi": "https://doi.org/10.1145/3132577",
    "publication_date": "2017-10-25",
    "publication_year": 2017,
    "authors": "Seyedhamidreza Motaman; Swaroop Ghosh; Jaydeep P. Kulkarni",
    "corresponding_authors": "",
    "abstract": "Spin-Transfer-Torque RAM (STTRAM) is a promising technology for high-density on-chip cache due to low standby power and high speed. However, the process variation of the Magnetic Tunnel Junction (MTJ) and access transistor poses a serious challenge to sensing. Nondestructive sensing suffers from reference resistance variation, whereas destructive sensing suffers from failures due to unoptimized selection of data and reference currents. Furthermore, the sense speed is tightly coupled with the reference/data current requirement. In this work, we study the process variation effect on a self-reference sensing scheme to eliminate bit-to-bit process variation in MTJ resistance. Read current modulation is proposed to overcome the failures due to process variation. Simulation results reveal &lt;0.01% failures at the cost of 9ns sense time and 190uW power consumption.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2766580201",
    "type": "article"
  },
  {
    "title": "Editorial",
    "doi": "https://doi.org/10.1145/1350763.1350764",
    "publication_date": "2008-04-01",
    "publication_year": 2008,
    "authors": "Vijaykrishnan Narayanan",
    "corresponding_authors": "Vijaykrishnan Narayanan",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3155825544",
    "type": "editorial"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3098274",
    "publication_date": "2017-08-11",
    "publication_year": 2017,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Quantum computing is a new computational paradigm that promises an exponential speed-up over classical algorithms. To develop efficient quantum algorithms for problems of a non-deterministic nature, random walk is one of the most successful concepts ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4236083765",
    "type": "paratext"
  },
  {
    "title": "Editorial",
    "doi": "https://doi.org/10.1145/1721650.1721651",
    "publication_date": "2008-03-16",
    "publication_year": 2008,
    "authors": "Krishnendu Chakrabarty",
    "corresponding_authors": "Krishnendu Chakrabarty",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4236239333",
    "type": "editorial"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1295231",
    "publication_date": "2007-11-01",
    "publication_year": 2007,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4237438843",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3051701",
    "publication_date": "2017-05-13",
    "publication_year": 2017,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Deep neural networks have been shown to outperform prior state-of-the-art solutions that often relied heavily on hand-engineered feature extraction techniques coupled with simple classification algorithms. In particular, deep convolutional neural ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4241910553",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1324177",
    "publication_date": "2008-01-01",
    "publication_year": 2008,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Microfluidic biochips offer a promising platform for massively parallel DNA analysis, automated drug discovery, and real-time biomolecular recognition. Current techniques for full-custom design of droplet-based “digital” biochips do not scale well for ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4243036508",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1350763",
    "publication_date": "2008-04-01",
    "publication_year": 2008,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "The need to determine electrostatic fields in domains bounded by molecular surfaces arises in a number of nanotechnology applications including: biomolecule design, carbon nanotube simulation, and molecular electron transport analysis. Molecular ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4245157990",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1330521",
    "publication_date": "2008-03-01",
    "publication_year": 2008,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "We summarize the main characteristics of the quantum logic array (QLA) architecture with a careful look at the key issues not described in the original conference publications: primarily, the teleportation-based logical interconnect. The design goal of ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4245453589",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1412587",
    "publication_date": "2008-10-01",
    "publication_year": 2008,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "This article extends our prior work to show that a straightforward use of 3D stacking technology enables the design of compact energy-efficient servers. Our proposed architecture, called PicoServer, employs 3D technology to bond one die containing ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4247459566",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1229175",
    "publication_date": "2007-04-01",
    "publication_year": 2007,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "A predictive MOSFET model is critical for early circuit design research. In this work, a new generation of Predictive Technology Model (PTM) is developed, covering emerging physical effects and alternative structures, such as the double-gate device (...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4248414346",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1265949",
    "publication_date": "2007-07-01",
    "publication_year": 2007,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "In this article, we present a nanoscale reconfigurable mesh which is interconnected by ferromagnetic spin-wave buses. In this architecture, unlike the traditional spin-based nano structures which transmit charge, waves are transmitted. As a result, the ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4250121156",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1389089",
    "publication_date": "2008-08-01",
    "publication_year": 2008,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Microfluidic biochips are revolutionizing high-throughput DNA sequencing, immunoassays, and clinical diagnostics. As high-throughput bioassays are mapped to digital microfluidic platforms, the need for design automation techniques is being increasingly ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4251006228",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3014160",
    "publication_date": "2017-03-10",
    "publication_year": 2017,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Because of technology scaling, the soft error rate has been increasing in digital circuits, which affects system reliability. Therefore, modern processors, including VLIW architectures, must have means to mitigate such effects to guarantee reliable ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4254280803",
    "type": "paratext"
  },
  {
    "title": "Low-Rank Gradient Descent for Memory-Efficient Training of Deep In-Memory Arrays",
    "doi": "https://doi.org/10.1145/3577214",
    "publication_date": "2023-01-14",
    "publication_year": 2023,
    "authors": "Siyuan Huang; Brian D. Hoskins; Matthew W. Daniels; M. D. Stiles; Gina C. Adam",
    "corresponding_authors": "",
    "abstract": "The movement of large quantities of data during the training of a deep neural network presents immense challenges for machine learning workloads, especially those based on future functional memories deployed to store network models. As the size of network models begins to vastly outstrip traditional silicon computing resources, functional memories based on flash, resistive switches, magnetic tunnel junctions, and other technologies can store these new ultra-large models. However, new approaches are then needed to minimize hardware overhead, especially on the movement and calculation of gradient information that cannot be efficiently contained in these new memory resources. To do this, we introduce streaming batch principal component analysis (SBPCA) as an update algorithm. Streaming batch principal component analysis uses stochastic power iterations to generate a stochastic rank- k approximation of the network gradient. We demonstrate that the low-rank updates produced by streaming batch principal component analysis can effectively train convolutional neural networks on a variety of common datasets, with performance comparable to standard mini-batch gradient descent. Our approximation is made in an expanded vector form that can efficiently be applied to the rows and columns of crossbars for array-level updates. These results promise improvements in the design of application-specific integrated circuits based around large vector-matrix multiplier memories.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4315977500",
    "type": "article"
  },
  {
    "title": "A Hybrid Optical-Electrical Analog Deep Learning Accelerator Using Incoherent Optical Signals",
    "doi": "https://doi.org/10.1145/3584183",
    "publication_date": "2023-02-18",
    "publication_year": 2023,
    "authors": "Mingdai Yang; Qiuwen Lou; Ramin Rajaei; Mohammad Reza Jokar; Junyi Qiu; Yuming Liu; Aditi Udupa; Frederic T. Chong; John M. Dallesasse; M. Feng; Lynford L. Goddard; Xiaobo Sharon Hu; Yanjing Li",
    "corresponding_authors": "",
    "abstract": "Optical deep learning (DL) accelerators have attracted significant interests due to their latency and power advantages. In this article, we focus on incoherent optical designs. A significant challenge is that there is no known solution to perform single-wavelength accumulation (a key operation required for DL workloads) using incoherent optical signals efficiently. Therefore, we devise a hybrid approach, where accumulation is done in the electrical domain, and multiplication is performed in the optical domain. The key technology enabler of our design is the transistor laser, which performs electrical-to-optical and optical-to-electrical conversions efficiently. Through detailed design and evaluation of our design, along with a comprehensive benchmarking study against state-of-the-art RRAM-based designs, we derive the following key results: (1) For a four-layer multilayer perceptron network, our design achieves 115× and 17.11× improvements in latency and energy, respectively, compared to the RRAM-based design. We can take full advantage of the speed and energy benefits of the optical technology because the inference task can be entirely mapped onto our design. (2) For a complex workload (Resnet50), weight reprogramming is needed, and intermediate results need to be stored/re-fetched to/from memories. In this case, for the same area, our design still outperforms the RRAM-based design by 15.92× in inference latency, and 8.99× in energy.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4321329569",
    "type": "article"
  },
  {
    "title": "Introduction to the Special Issue on CAD for Security: Pre-silicon Security Sign-off Solutions Through Design Cycle",
    "doi": "https://doi.org/10.1145/3584317",
    "publication_date": "2023-01-31",
    "publication_year": 2023,
    "authors": "Farimah Farahmandi; Ankur Srivastava; Giorgio Di Natale; Mark Tehranipoor",
    "corresponding_authors": "",
    "abstract": "This introduction welcomes all readers to this ACM JETC special issue on CAD for Security: Pre-silicon Security Sign-off Solutions Through Design Cycle. The articles published in this special issue reflect how computer-aided design (CAD) tools are developed to expand the notion of automated security verification throughout the system-on-chip (SoC) design cycle. This special issue aims to demonstrate how the semiconductor industry must look for security-oriented metrics and evaluation as part of automatic CAD solution development to aid analysis, identifying, root-causing, and mitigating SoC security problems. Throughout this introductory note, we first represent the need for such a security-oriented sign-off solution for the ASIC design flow, then it is followed by providing an overview of the articles published in this special issue and how they address such requirements.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4327728746",
    "type": "article"
  },
  {
    "title": "Guest Editors Introduction: Special Issue on Network-on-Chip Architectures of the Future (NoCArc)",
    "doi": "https://doi.org/10.1145/3609500",
    "publication_date": "2023-07-27",
    "publication_year": 2023,
    "authors": "Amlan Ganguly; Salvatore Monteleone; Diana Goehringer; Cristinel Ababei",
    "corresponding_authors": "",
    "abstract": "introduction Share on Guest Editors Introduction: Special Issue on Network-on-Chip Architectures of the Future (NoCArc) Editors: Amlan Ganguly Computer Engineering, Rochester Institute of Technology, USA Computer Engineering, Rochester Institute of Technology, USASearch about this author , Salvatore Monteleone Department of Engineering, Niccolò Cusano University, Italy Department of Engineering, Niccolò Cusano University, ItalySearch about this author , Diana Goehringer Technische Universität Dresden, Germany Technische Universität Dresden, GermanySearch about this author , Cristinel Ababei Electrical and Computer Engineering, Marquette University, USA Electrical and Computer Engineering, Marquette University, USASearch about this author Authors Info & Claims ACM Journal on Emerging Technologies in Computing SystemsVolume 19Issue 3Article No.: 19pp 1–3https://doi.org/10.1145/3609500Published:27 July 2023Publication History 0citation97DownloadsMetricsTotal Citations0Total Downloads97Last 12 Months97Last 6 weeks9 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteGet Access",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4385305309",
    "type": "article"
  },
  {
    "title": "SkyBridge 2.0: A Fine-grained Vertical 3D-IC Technology for Future ICs",
    "doi": "https://doi.org/10.1145/3617501",
    "publication_date": "2023-08-31",
    "publication_year": 2023,
    "authors": "Sachin Bhat; Mingyu Li; Sourabh Kulkarni; Csaba Andras Moritz",
    "corresponding_authors": "",
    "abstract": "Gate-all-around field effect transistors (FETs) are set to replace FinFETs to enable continued miniaturization of ICs in the deep nanometer regime. IMEC and IRDS roadmaps project that 3D integration of gate-all-around FETs is a key path for the IC industry beyond 2024. In this article, we present SkyBridge 2.0, an IC technology featuring high density fine-grained 3D integration of vertical gate-all-around nanowire FETs, contacts, and interconnect while also solving 3D routability. We utilize industry-standard EDA tools to develop a customized design and technology co-optimization (DTCO) flow to design and evaluate SkyBridge 2.0. This DTCO flow covers process emulation of standard cells and SRAM to enable scalable manufacturing pathway, TCAD characterization of vertical nanowire FETs to obtain IV and CV characteristics, compact modeling accurately the device behavior, RC parasitic extraction of 3D interconnects and performance, and power and area assessment using ring oscillators. The technology assessment using ring oscillators shows that SkyBridge 2.0 at the chosen design point, using 10 nm nanowires, achieves ∼18% performance and 31% energy efficiency benefits compared to 7 nm FinFET technology. Area analysis of logic cells shows up to six times density benefits versus aggressively scaled 2D-CMOS cells. In addition to logic, we architect 3D SRAM to support low-power memory designs. SkyBridge 2.0 SRAM shows ∼20% improvement in read and write static noise margin, up to three times lower leakage current, and up to four times density benefits compared to 7 nm FinFET technology.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4386326777",
    "type": "article"
  },
  {
    "title": "Introduction to the Special Issue on Next-Generation On-Chip and Off-Chip Communication Architectures for Edge, Cloud and HPC",
    "doi": "https://doi.org/10.1145/3631144",
    "publication_date": "2023-10-31",
    "publication_year": 2023,
    "authors": "John Kim; Tushar Krishna",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4388872196",
    "type": "article"
  },
  {
    "title": "Silicon Photonics for Computing Systems",
    "doi": "https://doi.org/10.1145/3208198",
    "publication_date": "2018-04-30",
    "publication_year": 2018,
    "authors": "Jiang Xu; Yuichi Nakamura; Andrew B. Kahng",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2861987464",
    "type": "article"
  },
  {
    "title": "Guest Editors’ Introduction",
    "doi": "https://doi.org/10.1145/3205944",
    "publication_date": "2018-04-30",
    "publication_year": 2018,
    "authors": "Yu Cao; Xin Li; Jae-sun Seo; Ganesh Dasika",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2883834223",
    "type": "article"
  },
  {
    "title": "Limit of Hardware Solutions for Self-Protecting Fault-Tolerant NoCs",
    "doi": "https://doi.org/10.1145/3233986",
    "publication_date": "2019-01-07",
    "publication_year": 2019,
    "authors": "Ahmed Louri; Jacques Henri Collet; Avinash Kodi",
    "corresponding_authors": "",
    "abstract": "We study the ultimate limits of hardware solutions for the self-protection strategies against permanent faults in networks on chips (NoCs). NoCs reliability is improved by replacing each base router by an augmented router which includes extra protection circuitry. We compare the protection achieved by the self-test and self-protect (STAP) architectures to that of triple modular redundancy with voting (TMR). Two STAP architectures are considered. In the first one, a defective router self-disconnects from the network, while it self-heals in the second one. In practice, none of the considered architectures (STAP or TMR) can tolerate all the permanent faults, especially faults in the extra-circuitry for protection or voting, and consequently, there will always be some unidentified defective augmented routers which are going to transmit errors in an unpredictable manner. This study consists of tackling this fundamental problem. Specifically, we study and determine the average percentage of &lt;underline&gt;residual&lt;/underline&gt; unidentified defective routers (UDRs) and their impact on the overall reliability of the NoC in light of self-protection strategies. Our study shows that TMR is the most efficient solution to limit the average percentage of UDRs when there are typically less than a 0.1 percent of defective base routers. However, TMR is also the most cost prohibitive and the least power efficient. Above 1% of defective base routers, the STAP approaches are more efficient although the protection efficiency decreases inexorably in the very defective technologies (e.g. when there is 10% or more of defective base routers). For instance, if the chip includes 10% of defective base routers, our study shows that there will remain on the average 1% of UDRs, which causes a major challenge for NoC reliability.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2910999631",
    "type": "article"
  },
  {
    "title": "Guest Editors’ Introduction",
    "doi": "https://doi.org/10.1145/3296021",
    "publication_date": "2019-01-31",
    "publication_year": 2019,
    "authors": "Edoardo Fusella; Mahdi Nikdast; Ian O’Connor; José Flich; Sudeep Pasricha",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2912923492",
    "type": "article"
  },
  {
    "title": "Language Support for Navigating Architecture Design in Closed Form",
    "doi": "https://doi.org/10.1145/3360047",
    "publication_date": "2019-10-25",
    "publication_year": 2019,
    "authors": "Weilong Cui; Georgios Tzimpragos; Yu Tao; Joseph McMahan; Deeksha Dangwal; Nestan Tsiskaridze; George Michelogiannakis; Dilip Vasudevan; Timothy Sherwood",
    "corresponding_authors": "",
    "abstract": "As computer architecture continues to expand beyond software-agnostic microarchitecture to specialized and heterogeneous logic or even radically different emerging computing models (e.g., quantum cores, DNA storage units), detailed cycle-level simulation is no longer presupposed. Exploring designs under such complex interacting relationships (e.g., performance, energy, thermal, frequency) calls for a more integrative but higher-level approach. We propose Charm, a modeling language supporting closed-form high-level architecture modeling. Charm enables mathematical representations of mutually dependent architectural relationships to be specified, composed, checked, evaluated, reused, and shared. The language is interpreted through a combination of automatic symbolic evaluation, scalable graph transformation, and efficient compiler techniques, generating executable DAGs and optimized analysis procedures. Charm also exploits the advancements in satisfiability modulo theory solvers to automatically search the design space to help architects explore multiple design knobs simultaneously (e.g., different CNN tiling configurations). Through two case studies, we demonstrate that Charm allows one to define high-level architecture models in a clean and concise format, maximize reusability and shareability, capture unreasonable assumptions, and significantly ease design space exploration at a high level.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2982088742",
    "type": "article"
  },
  {
    "title": "Guest Editors’ Introduction",
    "doi": "https://doi.org/10.1145/3359336",
    "publication_date": "2019-10-31",
    "publication_year": 2019,
    "authors": "Jae-sun Seo; Yu Cao; Xin Li; Paul N. Whatmough",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2996129448",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1126257",
    "publication_date": "2006-01-01",
    "publication_year": 2006,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "This article explores the architectural challenges introduced by emerging bottom-up fabrication of nanoelectronic circuits. The specific nanotechnology we explore proposes patterned DNA nanostructures as a scaffold for the placement and interconnection ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4231596960",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3327966",
    "publication_date": "2019-06-29",
    "publication_year": 2019,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Reversible circuits employ a computational paradigm that is beneficial for several applications, including the design of encoding and decoding devices, low-power design, and emerging applications in quantum computation. However, similarly to ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4234299609",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3365593",
    "publication_date": "2019-12-18",
    "publication_year": 2019,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4234805385",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3227199",
    "publication_date": "2018-07-27",
    "publication_year": 2018,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Artificial Neural Network computation relies on intensive vector-matrix multiplications. Recently, the emerging nonvolatile memory (NVM) crossbar array showed a feasibility of implementing such operations with high energy efficiency. Thus, there have ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4236345563",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3143783",
    "publication_date": "2018-03-13",
    "publication_year": 2018,
    "authors": "Mesbah Uddin; Md. Badruddoja Majumder; Karsten Beckmann; Harika Manem; Zahiruddin Alamgir; Nathaniel C. Cady; Garrett S. Rose; G. Majumder",
    "corresponding_authors": "",
    "abstract": "As we enter an era witnessing the closer end of Dennard scaling, where further reduction in power supply-voltage to reduce power consumption becomes more challenging in conventional systems, a goal of developing a system capable of performing large ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4240385344",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3294068",
    "publication_date": "2018-12-11",
    "publication_year": 2018,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "We study the applicability of spiking neural networks and neuromorphic hardware for solving general opti- mization problems without the use of adaptive training or learning algorithms. We leverage the dynamics of Hopfield networks and spin-glass systems ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4240588835",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3365594",
    "publication_date": "2019-12-16",
    "publication_year": 2019,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4241005957",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3287773",
    "publication_date": "2018-11-01",
    "publication_year": 2018,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "High-performance and energy-efficient Network-on-Chip (NoC) architecture is one of the crucial components of the manycore processing platforms. A very promising NoC architecture recently proposed in the literature is the three-dimensional small-world ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4242009900",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3303864",
    "publication_date": "2019-02-18",
    "publication_year": 2019,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "A Mixed Criticality System (MCS) combines real-time software tasks with different criticality levels. In a MCS, the criticality level specifies the level of assurance against system failure. For high-critical flows of messages, it is imperative to meet ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4247886708",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3375712",
    "publication_date": "2019-12-12",
    "publication_year": 2019,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Image sensors are widely used in various applications. With the increasing requirement for high resolutions and frame rates, power consumption has become a critical issue, which limits the use of image sensors in mobile devices and IoT applications. ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4251359613",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3322429",
    "publication_date": "2019-06-04",
    "publication_year": 2019,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Recent works have demonstrated the promise of using resistive random access memory (ReRAM) to perform neural network computations in memory. In particular, ReRAM-based crossbar structures can perform matrix-vector multiplication directly in the analog ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4252936864",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1167943",
    "publication_date": "2006-07-01",
    "publication_year": 2006,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4253918015",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1148015",
    "publication_date": "2006-04-01",
    "publication_year": 2006,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "As technology scales, interconnects have become a major performance bottleneck and a major source of power consumption for microprocessors. Increasing interconnect costs make it necessary to consider alternate ways of building modern microprocessors. ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4254001262",
    "type": "paratext"
  },
  {
    "title": "Guest Editor Introduction",
    "doi": "https://doi.org/10.1145/3283217",
    "publication_date": "2018-10-31",
    "publication_year": 2018,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "editorial Free Access Share on Guest Editor Introduction: Neuromorphic ComputingACM Journal on Emerging Technologies in Computing SystemsVolume 14Issue 4October 2018 Article No.: 39pp 1–3https://doi.org/10.1145/3283217Published:27 November 2018Publication History 0citation363DownloadsMetricsTotal Citations0Total Downloads363Last 12 Months31Last 6 weeks5 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteView all FormatsPDF",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4289122622",
    "type": "article"
  },
  {
    "title": "PEAL",
    "doi": "https://doi.org/10.1145/3405430",
    "publication_date": "2020-10-01",
    "publication_year": 2020,
    "authors": "Muhammad Kamran Ayub; Muhammad Abdullah Hanif; Osman Hasan; Muhammad Shafique",
    "corresponding_authors": "",
    "abstract": "Approximate computing has emerged as an efficient design approach for applications with inherent error resilience. Low-power approximate adders (LPAAs), for instance, IMPACT and InXA, are being advocated as building blocks for approximate computing hardware. For their practical adoption, the error caused by these units needs to be pre-evaluated and compared with maximum allowable error bounds for an application. To address this problem, we present PEAL, a Probabilistic error analysis methodology for Low-power Approximate Single and Multi-layered Adder Architectures , while considering variable probabilities for each bit of input operands for a given multi-bit adder design. PEAL is highly generic, linearly scalable, and applicable to any adder type. The analysis provides probability of success, which is accurate for single-layered adder architectures and provides a lower bound for multi-layered architectures. We have shown that state-of-the-art LPAAs can serve as effective building blocks of approximate computing only when the input probabilities are either very high (&gt;0.8) or very low (&lt;0.2). Interestingly, none of the state-of-the-art LPAA units, which to the best of our knowledge are the most widely adopted, has demonstrated effectiveness for mid-range probabilities (0.3–0.7). We have also analytically explained the cause of this usability limitation and proposed its solution. Moreover, we have proposed a method for estimating the Mean-squared Error of datapaths composed of LPAAs, to quantify the magnitude of error introduced in the output due to approximation of the adder units.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3089541503",
    "type": "article"
  },
  {
    "title": "Guest Editorial",
    "doi": "https://doi.org/10.1145/3412343",
    "publication_date": "2020-09-23",
    "publication_year": 2020,
    "authors": "Wei Zhang; Helen Li; Wujie Wen; Swarup Bhunia",
    "corresponding_authors": "",
    "abstract": "introduction Free Access Share on Guest Editorial: ACM JETC Special Issue on New Trends in Nanolectronic Device, Circuit, and Architecture Design: Part 2 Editors: Wei Zhang The Hong Kong University of Science and Technology, Clear Water Bay, NT, Hong Kong SAR The Hong Kong University of Science and Technology, Clear Water Bay, NT, Hong Kong SARView Profile , Helen Li Duke University Durham, NC 27708 USA Duke University Durham, NC 27708 USAView Profile , Wujie Wen Lehigh University Bethlehem, PA 18015 USA Lehigh University Bethlehem, PA 18015 USAView Profile , Swarup Bhunia University of Florida Gainesville, FL 32611 University of Florida Gainesville, FL 32611View Profile Authors Info & Claims ACM Journal on Emerging Technologies in Computing SystemsVolume 16Issue 4October 2020 Article No.: 35pp 1–3https://doi.org/10.1145/3412343Published:23 September 2020Publication History 0citation232DownloadsMetricsTotal Citations0Total Downloads232Last 12 Months40Last 6 weeks2 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteView all FormatsPDF",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3108169102",
    "type": "editorial"
  },
  {
    "title": "STDPベース学習によるロバストなメモリスタティブニューロモルフィックシステムのためのデバイスを意識した回路設計【JST・京大機械翻訳】",
    "doi": null,
    "publication_date": "2020-01-01",
    "publication_year": 2020,
    "authors": "Sayyaparaju Sagarvarma; Adnan Md Musabbir; Amer Sherif; S Rose Garrett",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3179525168",
    "type": "article"
  },
  {
    "title": "Editorial",
    "doi": "https://doi.org/10.1145/3378024",
    "publication_date": "2020-01-31",
    "publication_year": 2020,
    "authors": "Ramesh Karri",
    "corresponding_authors": "Ramesh Karri",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4238666002",
    "type": "editorial"
  },
  {
    "title": "High-level Modeling and Verification Platform for Elastic Circuits with Process Variation Considerations",
    "doi": "https://doi.org/10.1145/3534971",
    "publication_date": "2022-05-16",
    "publication_year": 2022,
    "authors": "Meysam Zaeemi; Siamak Mohammadi",
    "corresponding_authors": "",
    "abstract": "In addition to the advantages of asynchronous circuits, compatibility with synchronous EDA tools is another strength point of synchronous elastic circuits. Synchronous elastic circuits face some challenges, such as process variations that can compromise its performance and functionality, and the multitude of available implementations based on elastic elements’ combinations, meaning that choosing the best combination could not be simple. In this paper, a novel method is introduced to model and verify synchronous elastic circuits in the presence of variations. The model is based on xMAS, which is a new formal modeling paradigm to synthesize, test, and verify circuits and networks. In this method, various elastic elements are modeled and available in the form of a library in xMAS, so the designer can build complicated elastic circuits by combining different elastic elements. Additionally, by translating a high-level xMAS model into a SAN statistical model and using its capabilities, elements’ internal delays will be embedded, which makes the high-level modeling and elastic circuits’ high-resolution time analysis available. Based on the obtained results, elastic circuits are highly capable of tolerating variations. However, this phenomenon could lead to a maximum of 2.35% error in synchronization control units and data in these circuits.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4280627223",
    "type": "article"
  },
  {
    "title": "Guest Editorial: Trustworthy AI",
    "doi": "https://doi.org/10.1145/3534957",
    "publication_date": "2022-06-03",
    "publication_year": 2022,
    "authors": "Yier Jin; Tsung-Yi Ho; Stjepan Picek; Siddharth Garg",
    "corresponding_authors": "",
    "abstract": "introduction Share on Guest Editorial: Trustworthy AI Editors: Yier Jin University of Florida, USA University of Florida, USAView Profile , Tsung-Yi Ho The Chinese University of Hong Kong, Hong Kong The Chinese University of Hong Kong, Hong KongView Profile , Stjepan Picek Radboud University & Delft University of Technology, The Netherlands Radboud University & Delft University of Technology, The NetherlandsView Profile , Siddharth Garg New York University, UAE New York University, UAEView Profile Authors Info & Claims ACM Journal on Emerging Technologies in Computing SystemsVolume 18Issue 3July 2022 Article No.: 55pp 1–3https://doi.org/10.1145/3534957Published:03 June 2022Publication History 0citation143DownloadsMetricsTotal Citations0Total Downloads143Last 12 Months143Last 6 weeks33 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my Alerts New Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteGet Access",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4281758289",
    "type": "editorial"
  },
  {
    "title": "Zallocator: A High Throughput Write-Optimized Persistent Allocator for Non-Volatile Memory",
    "doi": "https://doi.org/10.1145/3549528",
    "publication_date": "2022-07-19",
    "publication_year": 2022,
    "authors": "You Wu; Lin Li",
    "corresponding_authors": "",
    "abstract": "Non-volatile main memory (NVRAM) is likely to break the bottleneck caused by data transferring between main memory and extern storage, and fundamentally change the way applications do data persistence. We can build persistent data structures directly on NVRAM. To do this correctly and efficiently, we need the support of persistent allocators guaranteeing failure-consistency. However, existing persistent allocators pay huge persistence overhead for failure-consistency. In this article, we present Zallocator, a write-optimized failure-consistency allocator for NVRAM. Zallocator hardly brings write operations to NVRAM. It keeps all the heap management metadata in DRAM, and rebuild them after a crash. Experimental results show that Zallocator achieves a throughput comparable to state-of-the-art transient allocators, and reduces the average number of NVRAM writes per allocation/deallocation to almost zero.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4285797368",
    "type": "article"
  },
  {
    "title": "Defending against Adversarial Attacks in Deep Learning with Robust Auxiliary Classifiers Utilizing Bit-plane Slicing",
    "doi": "https://doi.org/10.1145/3510855",
    "publication_date": "2022-07-21",
    "publication_year": 2022,
    "authors": "Yuan Liu; Jinxin Dong; Pingqiang Zhou",
    "corresponding_authors": "",
    "abstract": "Deep Neural Networks (DNNs) have been widely used in variety of fields with great success. However, recent research indicates that DNNs are susceptible to adversarial attacks, which can easily fool the well-trained DNN-based classifiers without being detected by human eyes. In this article, we propose to integrate the target DNN model with our robust bit-plane classifiers to defend against adversarial attacks. The bit-plane classifiers take bit-planes of input images for convolution, which is motivated by our observation that successful attacks aim to generate imperceptible perturbations, and they mainly affect the low-order bits of pixels in clean images when adding the perturbations. We also propose two metrics, bit-plane perturbation rate and channel modification rate, to further explain the robustness of bit-plane classifiers. We discuss potential adaptive attack and find that our defense can be effective as long as the adversarial examples are qualified. We conduct experiments on dataset CIFAR-10 and GTSRB under white-box attack and black-box attack. The results show that our defense method can effectively increase the average model accuracy from 16.23% to 83.53% under white-box attack and from 40.65% to 88.14% under black-box attack on CIFAR-10 without sacrificing the accuracy of clean images.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4286494888",
    "type": "article"
  },
  {
    "title": "Virtualizing Existing Fluidic Programs",
    "doi": "https://doi.org/10.1145/3558550",
    "publication_date": "2022-08-30",
    "publication_year": 2022,
    "authors": "Caleb Winston; Max Willsey; Luís Ceze",
    "corresponding_authors": "",
    "abstract": "Fluidic automation, the practice of programmatically manipulating small fluids to execute laboratory protocols, has led to vastly increased productivity for biologists and chemists. Most fluidic programs, commonly referred to as protocols, are written using APIs that couple the protocol to specific hardware by referring to the physical locations on the device. This coupling makes isolation impossible, preventing portability, concurrent execution, and composition of protocols on the same device. We propose a system for virtualizing existing fluidic protocols on top of a single runtime system without modification. Our system presents an isolated view of the device to each running protocol, allowing it to assume it has sole access to hardware. We provide a proof-of-concept implementation that can concurrently execute and compose protocols written using the popular Opentrons Python API. Concurrent execution achieves near-linear speedup over serial execution, since protocols spend much of their time waiting.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4293568976",
    "type": "article"
  },
  {
    "title": "Guest Editorial: Secure Radio-Frequency (RF)-Analog Electronics and Electromagnetics",
    "doi": "https://doi.org/10.1145/3564261",
    "publication_date": "2022-10-25",
    "publication_year": 2022,
    "authors": "Vanessa Chen; Mohammad Abdullah Al Faruque; Fadi Kurdahi",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4307201120",
    "type": "editorial"
  },
  {
    "title": "A Neoteric Approach for Logic with Embedded Memory Leveraging Crosstalk Computing",
    "doi": "https://doi.org/10.1145/3569917",
    "publication_date": "2022-11-01",
    "publication_year": 2022,
    "authors": "Prerana Samant; Naveen Kumar Macha; Mostafizur Rahman",
    "corresponding_authors": "",
    "abstract": "One of the essential elements of computing is the memory element. Flip-flops form an integral part of a System-on-Chip (SoC) and consume most of the area on the die. To meet the high-speed performance demands by the data-intensive applications such as artificial intelligence, cloud computing, and machine learning, we propose to integrate memory with the logic to get built-in memory Logic circuits that operate based on the crosstalk computing logic. These circuits are called Crosstalk Built-in Memory Logic (CBML) circuits, which exploit the detrimental interconnect crosstalk and astutely turn this unwanted effect into a computing principle with embedded memory. By virtue of our novel CBML circuit technique, the logic is computed, and the result is stored intrinsically within these complex circuits. The stored values will be retained irrespective of the change in input until the next logic evaluation cycle. This neoteric embedding of memory in logic provides high-speed operation with a reduced number of transistors. In this article, we have manifested the built-in memory feature of the complex CBML circuits using 16 nanometer (nm) PTM models in HSPICE. Benchmarking is performed by comparing with the equivalent static CMOS circuits to compare the number of transistors, power, and performance. It is observed that the number of transistors consumed by CBML 4-bit Full-Adder (the key element prevalent in Arithmetic circuits, e.g., ALU, Counters) is up to 46% less, and performance is improved by 27% over the equivalent CMOS circuits. This circuit serves as an example of a large-scale CBML circuit. Also, the performance improvement achieved by other circuits such as 3-input AND and the CARRY logic is up to 60% along with a 40% reduction in the number of transistors. CBML circuits have the potential to pave the way for special high-speed macros with specifically engineered structures.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4307780775",
    "type": "article"
  },
  {
    "title": "Diagnosis for Reconfigurable Single-Electron Transistor Arrays with a More Generalized Defect Model",
    "doi": "https://doi.org/10.1145/3444751",
    "publication_date": "2021-01-21",
    "publication_year": 2021,
    "authors": "Chia‐Cheng Wu; Yi-Hsiang Hu; Chia-Chun Lin; Yung‐Chih Chen; Juinn-Dar Huang; Chun-Yao Wang",
    "corresponding_authors": "",
    "abstract": "Singe-Electron Transistor (SET) is considered as a promising candidate of low-power devices for replacement or co-existence with Complementary Metal-Oxide-Semiconductor (CMOS) transistors/circuits. In this work, we propose a diagnosis approach for SET array under a more generalized defect model. With the more generalized defect model, the diagnosis approach will become more practical but complicated. We conducted experiments on a set of SET arrays with different dimensions and defect rates. The experimental results show that our approach only has 3.8% false-negative rate and 0.7% misjudged-category rate on average without reporting any false-positive edge when the defect rate is 4%. Therefore, the proposed diagnosis approach can diagnose the defective SET arrays and elevate the reliability of the SET arrays in the synthesis flow.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3122572853",
    "type": "article"
  },
  {
    "title": "Introduction of Special Issue on Hardware and Algorithms for Efficient Machine Learning–Part 1",
    "doi": "https://doi.org/10.1145/3449045",
    "publication_date": "2021-04-05",
    "publication_year": 2021,
    "authors": "Yiran Chen; Qinru Qiu; Yingyan Lin",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3141139583",
    "type": "article"
  },
  {
    "title": "A Scalable Cluster-based Hierarchical Hardware Accelerator for a Cortically Inspired Algorithm",
    "doi": "https://doi.org/10.1145/3447777",
    "publication_date": "2021-06-30",
    "publication_year": 2021,
    "authors": "Sumon Dey; Lee B. Baker; Joshua Schabel; Weifu Li; Paul D. Franzon",
    "corresponding_authors": "",
    "abstract": "This article describes a scalable, configurable and cluster-based hierarchical hardware accelerator through custom hardware architecture for Sparsey, a cortical learning algorithm. Sparsey is inspired by the operation of the human cortex and uses a Sparse Distributed Representation to enable unsupervised learning and inference in the same algorithm. A distributed on-chip memory organization is designed and implemented in custom hardware to improve memory bandwidth and accelerate the memory read/write operations for synaptic weight matrices. Bit-level data are processed from distributed on-chip memory and custom multiply-accumulate hardware is implemented for binary and fixed-point multiply-accumulation operations. The fixed-point arithmetic and fixed-point storage are also adapted in this implementation. At 16 nm, the custom hardware of Sparsey achieved an overall 24.39× speedup, 353.12× energy efficiency per frame, and 1.43× reduction in silicon area against a state-of-the-art GPU.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3173780594",
    "type": "article"
  },
  {
    "title": "Introduction to the Special Issue on Emerging Challenges and Solutions in Hardware Security",
    "doi": "https://doi.org/10.1145/3464326",
    "publication_date": "2021-06-30",
    "publication_year": 2021,
    "authors": "Domenic Forte; Debdeep Mukhopadhyay; Ilia Polian; Yunsi Fei; Rosario Cammarota",
    "corresponding_authors": "",
    "abstract": "introduction Introduction to the Special Issue on Emerging Challenges and Solutions in Hardware Security Share on Editors: Domenic Forte View Profile , Debdeep Mukhopadhyay View Profile , Ilia Polian View Profile , Yunsi Fei View Profile , Rosario Cammarota View Profile Authors Info & Claims ACM Journal on Emerging Technologies in Computing SystemsVolume 17Issue 3July 2021 Article No.: 29pp 1–4https://doi.org/10.1145/3464326Online:30 June 2021Publication History 0citation108DownloadsMetricsTotal Citations0Total Downloads108Last 12 Months108Last 6 weeks4 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteGet Access",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3175624838",
    "type": "article"
  },
  {
    "title": "Multi-Cycle-Consistent Adversarial Networks for Edge Denoising of Computed Tomography Images",
    "doi": "https://doi.org/10.1145/3462328",
    "publication_date": "2021-07-21",
    "publication_year": 2021,
    "authors": "Xiaowei Xu; Jiawei Zhang; Jinglan Liu; Yukun Ding; Tianchen Wang; Hailong Qiu; Haiyun Yuan; Jian Zhuang; Wen Xie; Yuhao Dong; Qianjun Jia; Meiping Huang; Yiyu Shi",
    "corresponding_authors": "",
    "abstract": "As one of the most commonly ordered imaging tests, the computed tomography (CT) scan comes with inevitable radiation exposure that increases cancer risk to patients. However, CT image quality is directly related to radiation dose, and thus it is desirable to obtain high-quality CT images with as little dose as possible. CT image denoising tries to obtain high-dose-like high-quality CT images (domain Y ) from low dose low-quality CT images (domain X ), which can be treated as an image-to-image translation task where the goal is to learn the transform between a source domain X (noisy images) and a target domain Y (clean images). Recently, the cycle-consistent adversarial denoising network (CCADN) has achieved state-of-the-art results by enforcing cycle-consistent loss without the need of paired training data, since the paired data is hard to collect due to patients’ interests and cardiac motion. However, out of concerns on patients’ privacy and data security, protocols typically require clinics to perform medical image processing tasks including CT image denoising locally (i.e., edge denoising). Therefore, the network models need to achieve high performance under various computation resource constraints including memory and performance. Our detailed analysis of CCADN raises a number of interesting questions that point to potential ways to further improve its performance using the same or even fewer computation resources. For example, if the noise is large leading to a significant difference between domain X and domain Y , can we bridge X and Y with a intermediate domain Z such that both the denoising process between X and Z and that between Z and Y are easier to learn? As such intermediate domains lead to multiple cycles, how do we best enforce cycle- consistency? Driven by these questions, we propose a multi-cycle-consistent adversarial network (MCCAN) that builds intermediate domains and enforces both local and global cycle-consistency for edge denoising of CT images. The global cycle-consistency couples all generators together to model the whole denoising process, whereas the local cycle-consistency imposes effective supervision on the process between adjacent domains. Experiments show that both local and global cycle-consistency are important for the success of MCCAN, which outperforms CCADN in terms of denoising quality with slightly less computation resource consumption.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3186218892",
    "type": "article"
  },
  {
    "title": "Introduction to the Special Issue on Hardware and Algorithms for Efficient Machine Learning—Part 2",
    "doi": "https://doi.org/10.1145/3464917",
    "publication_date": "2021-07-14",
    "publication_year": 2021,
    "authors": "Yiran Chen; Qinru Qiu; Yingyan Lin",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3191656903",
    "type": "article"
  },
  {
    "title": "A Holistic Solution for Reliability of 3D Parallel Systems",
    "doi": "https://doi.org/10.1145/3488900",
    "publication_date": "2021-11-16",
    "publication_year": 2021,
    "authors": "Javad Bagherzadeh; Aporva Amarnath; Jielun Tan; Subhankar Pal; Ronald Dreslinski",
    "corresponding_authors": "",
    "abstract": "Monolithic 3D technology is emerging as a promising solution that can bring massive opportunities, but the gains can be hindered due to the reliability issues exaggerated by high temperature. Conventional reliability solutions focus on one specific feature and assume that the other required features would be provided by different solutions. Hence, this assumption has resulted in solutions that are proposed in isolation of each other and fail to consider the overall compatibility and the implied overheads of multiple isolated solutions for one system. This article proposes a holistic reliability management engine, R2D3, for post-Moore’s M3D parallel systems that have low yield and high failure rate. The proposed engine, comprising a controller, reconfigurable crossbars, and detection circuitry, provides concurrent single-replay detection and diagnosis, fault-mitigating repair, and aging-aware lifetime management at runtime. This holistic view enables us to create a solution that is highly effective while achieving a low overhead. Our solution achieves 96% coverage of defect; reduces V th degradation by 53%, leading to a 78% performance improvement on average over 8 years for an eight-core system; and ultimately yields a 2.16× longer mean-time-to-failure (MTTF) while incurring an overhead of 7.4% in area, 6.5% in power, and an 8.2% decrease in frequency.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3193699051",
    "type": "article"
  },
  {
    "title": "SCALPEL: Exploring the Limits of Tag-enforced Compartmentalization",
    "doi": "https://doi.org/10.1145/3461673",
    "publication_date": "2021-09-29",
    "publication_year": 2021,
    "authors": "Nick Roessler; André DeHon",
    "corresponding_authors": "",
    "abstract": "We present Secure Compartments Automatically Learned and Protected by Execution using Lightweight metadata (SCALPEL), a tool for automatically deriving compartmentalization policies and lowering them to a tagged architecture for hardware-accelerated enforcement. SCALPEL allows a designer to explore high-quality points in the privilege-reduction vs. performance overhead tradeoff space using analysis tools and a detailed knowledge of the target architecture to make best use of the available hardware. SCALPEL automatically implements hundreds of compartmentalization strategies across the privilege-performance tradeoff space, all without manual tagging or code restructuring. SCALPEL uses two novel optimizations for achieving highly performant policies: the first is an algorithm for packing policies into working sets of rules for favorable rule cache characteristics, and the second is a rule prefetching system that allows it to exploit the highly predictable nature of compartmentalization rules. To create policies, SCALPEL introduces a quantitative privilege metric (the Overprivilege Ratio) that is used to drive its algorithmic compartment generation. We implement SCALPEL on a FreeRTOS stack and target a tag-extended RISC-V core. Our results show that SCALPEL-created policies can reduce overprivilege by orders of magnitude with hundreds of logical compartments while imposing low overheads (&lt;5%).",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3202481135",
    "type": "article"
  },
  {
    "title": "アナログスパイキングニューラルネットワーク分類器を用いた電力効率の良いスパイクソーティング方式【JST・京大機械翻訳】",
    "doi": null,
    "publication_date": "2021-01-01",
    "publication_year": 2021,
    "authors": "Mukhopadhyay Anand Kumar; Atul Sharma; Chakrabarti Indrajit; Basu Arindam; Mrigank Sharad",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3203171796",
    "type": "article"
  },
  {
    "title": "Introduction to the Special Issue on Monolithic 3D: Technology, Design and Computing Systems Applications Perspectives",
    "doi": "https://doi.org/10.1145/3487869",
    "publication_date": "2021-11-03",
    "publication_year": 2021,
    "authors": "Sébastien Thuries; Aida Todri‐Sanial",
    "corresponding_authors": "",
    "abstract": "introduction Share on Introduction to the Special Issue on Monolithic 3D: Technology, Design and Computing Systems Applications Perspectives Editors: Sébastien Thuries CEA LIST - France CEA LIST - FranceView Profile , Aida Todri-Sanial CNRS/LIRMM - France CNRS/LIRMM - FranceView Profile Authors Info & Claims ACM Journal on Emerging Technologies in Computing SystemsVolume 18Issue 1January 2022 Article No.: 19pp 1–3https://doi.org/10.1145/3487869Online:03 November 2021Publication History 0citation29DownloadsMetricsTotal Citations0Total Downloads29Last 12 Months29Last 6 weeks2 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteGet Access",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3208907719",
    "type": "article"
  },
  {
    "title": "A Spiking Neuromorphic Architecture Using Gated-RRAM for Associative Memory",
    "doi": "https://doi.org/10.1145/3461667",
    "publication_date": "2021-12-31",
    "publication_year": 2021,
    "authors": "Alexander Jones; Aaron Ruen; Rashmi Jha",
    "corresponding_authors": "",
    "abstract": "This work reports a spiking neuromorphic architecture for associative memory simulated in a SPICE environment using recently reported gated-RRAM (resistive random-access memory) devices as synapses alongside neurons based on complementary metal-oxide semiconductors (CMOSs). The network utilizes a Verilog A model to capture the behavior of the gated-RRAM devices within the architecture. The model uses parameters obtained from experimental gated-RRAM devices that were fabricated and tested in this work. Using these devices in tandem with CMOS neuron circuitry, our results indicate that the proposed architecture can learn an association in real time and retrieve the learned association when incomplete information is provided. These results show the promise for gated-RRAM devices for associative memory tasks within a spiking neuromorphic architecture framework.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4205235009",
    "type": "article"
  },
  {
    "title": "Guest Editorial: ACM JETC Special Issue on Hardware-Aware Learning for Medical Applications",
    "doi": "https://doi.org/10.1145/3503262",
    "publication_date": "2021-12-31",
    "publication_year": 2021,
    "authors": "Yiyu Shi; Yongpan Liu; Jianxu Chen; Steve Jiang",
    "corresponding_authors": "",
    "abstract": "introduction Share on Guest Editorial: ACM JETC Special Issue on Hardware-Aware Learning for Medical Applications Editors: Yiyu Shi University of Notre Dame, Notre Dame, Indiana, USA University of Notre Dame, Notre Dame, Indiana, USAView Profile , Yongpan Liu Tsinghua University, Beijing, China Tsinghua University, Beijing, ChinaView Profile , Jianxu Chen Leibniz-Institut für Analytische Wissenschaften – ISAS – e.V, Dortmund, Germany Leibniz-Institut für Analytische Wissenschaften – ISAS – e.V, Dortmund, GermanyView Profile , Steve Jiang University of Texas Southwestern Medical Center Dallas, Texas, USA University of Texas Southwestern Medical Center Dallas, Texas, USAView Profile Authors Info & Claims ACM Journal on Emerging Technologies in Computing SystemsVolume 18Issue 2April 2022 Article No.: 24pp 1–3https://doi.org/10.1145/3503262Online:31 December 2021Publication History 0citation60DownloadsMetricsTotal Citations0Total Downloads60Last 12 Months60Last 6 weeks5 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteGet Access",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4205756824",
    "type": "editorial"
  }
]
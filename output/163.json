[
  {
    "title": "The immersed boundary method",
    "doi": "https://doi.org/10.1017/s0962492902000077",
    "publication_date": "2002-01-01",
    "publication_year": 2002,
    "authors": "Charles S. Peskin",
    "corresponding_authors": "Charles S. Peskin",
    "abstract": "This paper is concerned with the mathematical structure of the immersed boundary (IB) method, which is intended for the computer simulation of fluid–structure interaction, especially in biological fluid dynamics. The IB formulation of such problems, derived here from the principle of least action, involves both Eulerian and Lagrangian variables, linked by the Dirac delta function. Spatial discretization of the IB equations is based on a fixed Cartesian mesh for the Eulerian variables, and a moving curvilinear mesh for the Lagrangian variables. The two types of variables are linked by interaction equations that involve a smoothed approximation to the Dirac delta function. Eulerian/Lagrangian identities govern the transfer of data from one mesh to the other. Temporal discretization is by a second-order Runge–Kutta method. Current and future research directions are pointed out, and applications of the IB method are briefly discussed.",
    "cited_by_count": 4280,
    "openalex_id": "https://openalex.org/W2084131634",
    "type": "article"
  },
  {
    "title": "Numerical solution of saddle point problems",
    "doi": "https://doi.org/10.1017/s0962492904000212",
    "publication_date": "2005-04-19",
    "publication_year": 2005,
    "authors": "Michele Benzi; Gene H. Golub; Jörg Liesen",
    "corresponding_authors": "",
    "abstract": "Large linear systems of saddle point type arise in a wide variety of applications throughout computational science and engineering. Due to their indefiniteness and often poor spectral properties, such linear systems represent a significant challenge for solver developers. In recent years there has been a surge of interest in saddle point problems, and numerous solution techniques have been proposed for this type of system. The aim of this paper is to present and discuss a large selection of solution methods for linear systems in saddle point form, with an emphasis on iterative methods for large and sparse problems.",
    "cited_by_count": 2267,
    "openalex_id": "https://openalex.org/W2141870784",
    "type": "article"
  },
  {
    "title": "Inverse problems: A Bayesian perspective",
    "doi": "https://doi.org/10.1017/s0962492910000061",
    "publication_date": "2010-05-01",
    "publication_year": 2010,
    "authors": "Andrew M. Stuart",
    "corresponding_authors": "Andrew M. Stuart",
    "abstract": "The subject of inverse problems in differential equations is of enormous practical importance, and has also generated substantial mathematical and computational innovation. Typically some form of regularization is required to ameliorate ill-posed behaviour. In this article we review the Bayesian approach to regularization, developing a function space viewpoint on the subject. This approach allows for a full characterization of all possible solutions, and their relative probabilities, whilst simultaneously forcing significant modelling issues to be addressed in a clear and precise fashion. Although expensive to implement, this approach is starting to lie within the range of the available computational resources in many application areas. It also allows for the quantification of uncertainty and risk, something which is increasingly demanded by these applications. Furthermore, the approach is conceptually important for the understanding of simpler, computationally expedient approaches to inverse problems.",
    "cited_by_count": 1742,
    "openalex_id": "https://openalex.org/W2149498546",
    "type": "article"
  },
  {
    "title": "Sequential Quadratic Programming",
    "doi": "https://doi.org/10.1017/s0962492900002518",
    "publication_date": "1995-01-01",
    "publication_year": 1995,
    "authors": "Paul T. Boggs; Jon W. Tolle",
    "corresponding_authors": "",
    "abstract": "Since its popularization in the late 1970s, Sequential Quadratic Programming (SQP) has arguably become the most successful method for solving nonlinearly constrained optimization problems. As with most optimization methods, SQP is not a single algorithm, but rather a conceptual method from which numerous specific algorithms have evolved. Backed by a solid theoretical and computational foundation, both commercial and public-domain SQP algorithms have been developed and used to solve a remarkably large set of important practical problems. Recently large-scale versions have been devised and tested with promising results.",
    "cited_by_count": 1720,
    "openalex_id": "https://openalex.org/W2149416133",
    "type": "article"
  },
  {
    "title": "Monte Carlo and quasi-Monte Carlo methods",
    "doi": "https://doi.org/10.1017/s0962492900002804",
    "publication_date": "1998-01-01",
    "publication_year": 1998,
    "authors": "Russel E. Caflisch",
    "corresponding_authors": "Russel E. Caflisch",
    "abstract": "Monte Carlo is one of the most versatile and widely used numerical methods. Its convergence rate, O ( N −1/2 ), is independent of dimension, which shows Monte Carlo to be very robust but also slow. This article presents an introduction to Monte Carlo methods for integration problems, including convergence theory, sampling methods and variance reduction techniques. Accelerated convergence for Monte Carlo quadrature is attained using quasi-random (also called low-discrepancy) sequences, which are a deterministic alternative to random or pseudo-random sequences. The points in a quasi-random sequence are correlated to provide greater uniformity. The resulting quadrature method, called quasi-Monte Carlo, has a convergence rate of approximately O ((log N ) k N −1 ). For quasi-Monte Carlo, both theoretical error estimates and practical limitations are presented. Although the emphasis in this article is on integration, Monte Carlo simulation of rarefied gas dynamics is also discussed. In the limit of small mean free path (that is, the fluid dynamic limit), Monte Carlo loses its effectiveness because the collisional distance is much less than the fluid dynamic length scale. Computational examples are presented throughout the text to illustrate the theory. A number of open problems are described.",
    "cited_by_count": 1688,
    "openalex_id": "https://openalex.org/W2151084831",
    "type": "article"
  },
  {
    "title": "Discrete mechanics and variational integrators",
    "doi": "https://doi.org/10.1017/s096249290100006x",
    "publication_date": "2001-05-01",
    "publication_year": 2001,
    "authors": "Jerrold E. Marsden; Matthew West",
    "corresponding_authors": "",
    "abstract": "This paper gives a review of integration algorithms for finite dimensional mechanical systems that are based on discrete variational principles. The variational technique gives a unified treatment of many symplectic schemes, including those of higher order, as well as a natural treatment of the discrete Noether theorem. The approach also allows us to include forces, dissipation and constraints in a natural way. Amongst the many specific schemes treated as examples, the Verlet, SHAKE, RATTLE, Newmark, and the symplectic partitioned Runge–Kutta schemes are presented.",
    "cited_by_count": 1540,
    "openalex_id": "https://openalex.org/W2170039048",
    "type": "article"
  },
  {
    "title": "Radial basis functions",
    "doi": "https://doi.org/10.1017/s0962492900000015",
    "publication_date": "2000-01-01",
    "publication_year": 2000,
    "authors": "M. D. Buhmann",
    "corresponding_authors": "M. D. Buhmann",
    "abstract": "Radial basis function methods are modern ways to approximate multivariate functions, especially in the absence of grid data. They have been known, tested and analysed for several years now and many positive properties have been identified. This paper gives a selective but up-to-date survey of several recent developments that explains their usefulness from the theoretical point of view and contributes useful new classes of radial basis function. We consider particularly the new results on convergence rates of interpolation with radial basis functions, as well as some of the various achievements on approximation on spheres, and the efficient numerical computation of interpolants for very large sets of data. Several examples of useful applications are stated at the end of the paper.",
    "cited_by_count": 1494,
    "openalex_id": "https://openalex.org/W2107699930",
    "type": "article"
  },
  {
    "title": "Approximation theory of the MLP model in neural networks",
    "doi": "https://doi.org/10.1017/s0962492900002919",
    "publication_date": "1999-01-01",
    "publication_year": 1999,
    "authors": "Allan Pinkus",
    "corresponding_authors": "Allan Pinkus",
    "abstract": "In this survey we discuss various approximation-theoretic problems that arise in the multilayer feedforward perceptron (MLP) model in neural networks. The MLP model is one of the more popular and practical of the many neural network models. Mathematically it is also one of the simpler models. Nonetheless the mathematics of this model is not well understood, and many of these problems are approximation-theoretic in character. Most of the research we will discuss is of very recent vintage. We will report on what has been done and on various unanswered questions. We will not be presenting practical (algorithmic) methods. We will, however, be exploring the capabilities and limitations of this model.",
    "cited_by_count": 1332,
    "openalex_id": "https://openalex.org/W2158581396",
    "type": "article"
  },
  {
    "title": "An optimal control approach to <i>a posteriori</i> error estimation in finite element methods",
    "doi": "https://doi.org/10.1017/s0962492901000010",
    "publication_date": "2001-05-01",
    "publication_year": 2001,
    "authors": "Roland Becker; Rolf Rannacher",
    "corresponding_authors": "",
    "abstract": "This article surveys a general approach to error control and adaptive mesh design in Galerkin finite element methods that is based on duality principles as used in optimal control. Most of the existing work on a posteriori error analysis deals with error estimation in global norms like the ‘energy norm’ or the L 2 norm, involving usually unknown ‘stability constants’. However, in most applications, the error in a global norm does not provide useful bounds for the errors in the quantities of real physical interest. Further, their sensitivity to local error sources is not properly represented by global stability constants. These deficiencies are overcome by employing duality techniques, as is common in a priori error analysis of finite element methods, and replacing the global stability constants by computationally obtained local sensitivity factors. Combining this with Galerkin orthogonality, a posteriori estimates can be derived directly for the error in the target quantity. In these estimates local residuals of the computed solution are multiplied by weights which measure the dependence of the error on the local residuals. Those, in turn, can be controlled by locally refining or coarsening the computational mesh. The weights are obtained by approximately solving a linear adjoint problem. The resulting a posteriori error estimates provide the basis of a feedback process for successively constructing economical meshes and corresponding error bounds tailored to the particular goal of the computation. This approach, called the ‘dual-weighted-residual method’, is introduced initially within an abstract functional analytic setting, and is then developed in detail for several model situations featuring the characteristic properties of elliptic, parabolic and hyperbolic problems. After having discussed the basic properties of duality-based adaptivity, we demonstrate the potential of this approach by presenting a selection of results obtained for practical test cases. These include problems from viscous fluid flow, chemically reactive flow, elasto-plasticity, radiative transfer, and optimal control. Throughout the paper, open theoretical and practical problems are stated together with references to the relevant literature.",
    "cited_by_count": 1194,
    "openalex_id": "https://openalex.org/W2133147107",
    "type": "article"
  },
  {
    "title": "Finite element exterior calculus, homological techniques, and applications",
    "doi": "https://doi.org/10.1017/s0962492906210018",
    "publication_date": "2006-05-01",
    "publication_year": 2006,
    "authors": "Douglas N. Arnold; Richard S. Falk; Ragnar Winther",
    "corresponding_authors": "",
    "abstract": "Finite element exterior calculus is an approach to the design and understanding of finite element discretizations for a wide variety of systems of partial differential equations. This approach brings to bear tools from differential geometry, algebraic topology, and homological algebra to develop discretizations which are compatible with the geometric, topological, and algebraic structures which underlie well-posedness of the PDE problem being solved. In the finite element exterior calculus, many finite element spaces are revealed as spaces of piecewise polynomial differential forms. These connect to each other in discrete subcomplexes of elliptic differential complexes, and are also related to the continuous elliptic complex through projections which commute with the complex differential. Applications are made to the finite element discretization of a variety of problems, including the Hodge Laplacian, Maxwell’s equations, the equations of elasticity, and elliptic eigenvalue problems, and also to preconditioners.",
    "cited_by_count": 1005,
    "openalex_id": "https://openalex.org/W2138486270",
    "type": "article"
  },
  {
    "title": "Sparse grids",
    "doi": "https://doi.org/10.1017/s0962492904000182",
    "publication_date": "2004-05-01",
    "publication_year": 2004,
    "authors": "Hans‐Joachim Bungartz; Michael Griebel",
    "corresponding_authors": "",
    "abstract": "We present a survey of the fundamentals and the applications of sparse grids, with a focus on the solution of partial differential equations (PDEs). The sparse grid approach, introduced in Zenger (1991), is based on a higher-dimensional multiscale basis, which is derived from a one-dimensional multi-scale basis by a tensor product construction. Discretizations on sparse grids involve . That is why sparse grids are especially well-suited for problems of very high dimensionality.The sparse grid approach can be extended to nonsmooth solutions by adaptive refinement methods. Furthermore, it can be generalized from piecewise linear to higher-order polynomials. Also, more sophisticated basis functions like interpolets, prewavelets, or wavelets can be used in a straightforward way.We describe the basic features of sparse grids and report the results of various numerical experiments for the solution of elliptic PDEs as well as for other selected problems such as numerical quadrature and data mining.",
    "cited_by_count": 963,
    "openalex_id": "https://openalex.org/W4255975175",
    "type": "article"
  },
  {
    "title": "Exponential integrators",
    "doi": "https://doi.org/10.1017/s0962492910000048",
    "publication_date": "2010-05-01",
    "publication_year": 2010,
    "authors": "Marlis Hochbruck; Alexander Ostermann",
    "corresponding_authors": "",
    "abstract": "In this paper we consider the construction, analysis, implementation and application of exponential integrators. The focus will be on two types of stiff problems. The first one is characterized by a Jacobian that possesses eigenvalues with large negative real parts. Parabolic partial differential equations and their spatial discretization are typical examples. The second class consists of highly oscillatory problems with purely imaginary eigenvalues of large modulus. Apart from motivating the construction of exponential integrators for various classes of problems, our main intention in this article is to present the mathematics behind these methods. We will derive error bounds that are independent of stiffness or highest frequencies in the system. Since the implementation of exponential integrators requires the evaluation of the product of a matrix function with a vector, we will briefly discuss some possible approaches as well. The paper concludes with some applications, in which exponential integrators are used.",
    "cited_by_count": 930,
    "openalex_id": "https://openalex.org/W4211077197",
    "type": "article"
  },
  {
    "title": "Finite elements in computational electromagnetism",
    "doi": "https://doi.org/10.1017/s0962492902000041",
    "publication_date": "2002-01-01",
    "publication_year": 2002,
    "authors": "Ralf Hiptmair",
    "corresponding_authors": "Ralf Hiptmair",
    "abstract": "This article discusses finite element Galerkin schemes for a number of linear model problems in electromagnetism. The finite element schemes are introduced as discrete differential forms, matching the coordinate-independent statement of Maxwell's equations in the calculus of differential forms. The asymptotic convergence of discrete solutions is investigated theoretically. As discrete differential forms represent a genuine generalization of conventional Lagrangian finite elements, the analysis is based upon a judicious adaptation of established techniques in the theory of finite elements. Risks and difficulties haunting finite element schemes that do not fit the framework of discrete differential forms are highlighted.",
    "cited_by_count": 878,
    "openalex_id": "https://openalex.org/W2143783905",
    "type": "article"
  },
  {
    "title": "A new version of the Fast Multipole Method for the Laplace equation in three dimensions",
    "doi": "https://doi.org/10.1017/s0962492900002725",
    "publication_date": "1997-01-01",
    "publication_year": 1997,
    "authors": "Leslie Greengard; Vladimir Rokhlin",
    "corresponding_authors": "",
    "abstract": "We introduce a new version of the Fast Multipole Method for the evaluation of potential fields in three dimensions. It is based on a new diagonal form for translation operators and yields high accuracy at a reasonable cost.",
    "cited_by_count": 871,
    "openalex_id": "https://openalex.org/W2132820941",
    "type": "article"
  },
  {
    "title": "Nonlinear approximation",
    "doi": "https://doi.org/10.1017/s0962492900002816",
    "publication_date": "1998-01-01",
    "publication_year": 1998,
    "authors": "Ronald DeVore",
    "corresponding_authors": "Ronald DeVore",
    "abstract": "This is a survey of nonlinear approximation, especially that part of the subject which is important in numerical computation. Nonlinear approximation means that the approximants do not come from linear spaces but rather from nonlinear manifolds. The central question to be studied is what, if any, are the advantages of nonlinear approximation over the simpler, more established, linear methods. This question is answered by studying the rate of approximation which is the decrease in error versus the number of parameters in the approximant. The number of parameters usually correlates well with computational effort. It is shown that in many settings the rate of nonlinear approximation can be characterized by certain smoothness conditions which are significantly weaker than required in the linear theory. Emphasis in the survey will be placed on approximation by piecewise polynomials and wavelets as well as their numerical implementation. Results on highly nonlinear methods such as optimal basis selection and greedy algorithms (adaptive pursuit) are also given. Applications to image processing, statistical estimation, regularity for PDEs, and adaptive algorithms are discussed.",
    "cited_by_count": 809,
    "openalex_id": "https://openalex.org/W4231428347",
    "type": "article"
  },
  {
    "title": "Multilevel Monte Carlo methods",
    "doi": "https://doi.org/10.1017/s096249291500001x",
    "publication_date": "2015-04-27",
    "publication_year": 2015,
    "authors": "Michael B. Giles",
    "corresponding_authors": "Michael B. Giles",
    "abstract": "Monte Carlo methods are a very general and useful approach for the estimation of expectations arising from stochastic simulation. However, they can be computationally expensive, particularly when the cost of generating individual stochastic samples is very high, as in the case of stochastic PDEs. Multilevel Monte Carlo is a recently developed approach which greatly reduces the computational cost by performing most simulations with low accuracy at a correspondingly low cost, with relatively few simulations being performed at high accuracy and a high cost. In this article, we review the ideas behind the multilevel Monte Carlo method, and various recent generalizations and extensions, and discuss a number of applications which illustrate the flexibility and generality of the approach and the challenges in developing more efficient implementations with a faster rate of convergence of the multilevel correction variance.",
    "cited_by_count": 789,
    "openalex_id": "https://openalex.org/W2014945091",
    "type": "article"
  },
  {
    "title": "Lie-group methods",
    "doi": "https://doi.org/10.1017/s0962492900002154",
    "publication_date": "2000-01-01",
    "publication_year": 2000,
    "authors": "Arieh Iserles; Hans Munthe–Kaas; Syvert P. Nørsett; Antonella Zanna",
    "corresponding_authors": "",
    "abstract": "Many differential equations of practical interest evolve on Lie groups or on manifolds acted upon by Lie groups. The retention of Lie-group structure under discretization is often vital in the recovery of qualitatively correct geometry and dynamics and in the minimization of numerical error. Having introduced requisite elements of differential geometry, this paper surveys the novel theory of numerical integrators that respect Lie-group structure, highlighting theory, algorithmic issues and a number of applications.",
    "cited_by_count": 752,
    "openalex_id": "https://openalex.org/W2061356302",
    "type": "article"
  },
  {
    "title": "Mixed-integer nonlinear optimization",
    "doi": "https://doi.org/10.1017/s0962492913000032",
    "publication_date": "2013-04-02",
    "publication_year": 2013,
    "authors": "Pietro Belotti; Christian Kirches; Sven Leyffer; Jeff Linderoth; James Luedtke; Ashutosh Mahajan",
    "corresponding_authors": "",
    "abstract": "Many optimal decision problems in scientific, engineering, and public sector applications involve both discrete decisions and nonlinear system dynamics that affect the quality of the final design or plan. These decision problems lead to mixed-integer nonlinear programming (MINLP) problems that combine the combinatorial difficulty of optimizing over discrete variable sets with the challenges of handling nonlinear functions. We review models and applications of MINLP, and survey the state of the art in methods for solving this challenging class of problems. Most solution methods for MINLP apply some form of tree search. We distinguish two broad classes of methods: single-tree and multitree methods. We discuss these two classes of methods first in the case where the underlying problem functions are convex. Classical single-tree methods include nonlinear branch-and-bound and branch-and-cut methods, while classical multitree methods include outer approximation and Benders decomposition. The most efficient class of methods for convex MINLP are hybrid methods that combine the strengths of both classes of classical techniques. Non-convex MINLPs pose additional challenges, because they contain non-convex functions in the objective function or the constraints; hence even when the integer variables are relaxed to be continuous, the feasible region is generally non-convex, resulting in many local minima. We discuss a range of approaches for tackling this challenging class of problems, including piecewise linear approximations, generic strategies for obtaining convex relaxations for non-convex functions, spatial branch-and-bound methods, and a small sample of techniques that exploit particular types of non-convex structures to obtain improved convex relaxations. We finish our survey with a brief discussion of three important aspects of MINLP. First, we review heuristic techniques that can obtain good feasible solution in situations where the search-tree has grown too large or we require real-time solutions. Second, we describe an emerging area of mixed-integer optimal control that adds systems of ordinary differential equations to MINLP. Third, we survey the state of the art in software for MINLP.",
    "cited_by_count": 635,
    "openalex_id": "https://openalex.org/W2133304166",
    "type": "article"
  },
  {
    "title": "Introduction to Adaptive Methods for Differential Equations",
    "doi": "https://doi.org/10.1017/s0962492900002531",
    "publication_date": "1995-01-01",
    "publication_year": 1995,
    "authors": "Kenneth Eriksson; D. Estep; Peter Hansbo; Claes Johnson",
    "corresponding_authors": "",
    "abstract": "Knowing thus the Algorithm of this calculus, which I call Differential Calculus, all differential equations can be solved by a common method (Gottfried Wilhelm von Leibniz, 1646–1719). When, several years ago, I saw for the first time an instrument which, when carried, automatically records the number of steps taken by a pedestrian, it occurred to me at once that the entire arithmetic could be subjected to a similar kind of machinery so that not only addition and subtraction, but also multiplication and division, could be accomplished by a suitably arranged machine easily, promptly and with sure results…. For it is unworthy of excellent men to lose hours like slaves in the labour of calculations, which could safely be left to anyone else if the machine was used…. And now that we may give final praise to the machine, we may say that it will be desirable to all who are engaged in computations which, as is well known, are the managers of financial affairs, the administrators of others estates, merchants, surveyors, navigators, astronomers, and those connected with any of the crafts that use mathematics (Leibniz).",
    "cited_by_count": 633,
    "openalex_id": "https://openalex.org/W2148639620",
    "type": "article"
  },
  {
    "title": "High-dimensional integration: The quasi-Monte Carlo way",
    "doi": "https://doi.org/10.1017/s0962492913000044",
    "publication_date": "2013-04-02",
    "publication_year": 2013,
    "authors": "Josef Dick; Frances Y. Kuo; Ian H. Sloan",
    "corresponding_authors": "",
    "abstract": "This paper is a contemporary review of QMC (‘quasi-Monte Carlo’) methods, that is, equal-weight rules for the approximate evaluation of high-dimensional integrals over the unit cube [0,1] s , where s may be large, or even infinite. After a general introduction, the paper surveys recent developments in lattice methods, digital nets, and related themes. Among those recent developments are methods of construction of both lattices and digital nets, to yield QMC rules that have a prescribed rate of convergence for sufficiently smooth functions, and ideally also guaranteed slow growth (or no growth) of the worst-case error as s increases. A crucial role is played by parameters called ‘weights’, since a careful use of the weight parameters is needed to ensure that the worst-case errors in an appropriately weighted function space are bounded, or grow only slowly, as the dimension s increases. Important tools for the analysis are weighted function spaces, reproducing kernel Hilbert spaces, and discrepancy, all of which are discussed with an appropriate level of detail.",
    "cited_by_count": 632,
    "openalex_id": "https://openalex.org/W1978501336",
    "type": "article"
  },
  {
    "title": "Finite element methods for surface PDEs",
    "doi": "https://doi.org/10.1017/s0962492913000056",
    "publication_date": "2013-04-02",
    "publication_year": 2013,
    "authors": "Gerhard Dziuk; Charles M. Elliott",
    "corresponding_authors": "",
    "abstract": "In this article we consider finite element methods for approximating the solution of partial differential equations on surfaces. We focus on surface finite elements on triangulated surfaces, implicit surface methods using level set descriptions of the surface, unfitted finite element methods and diffuse interface methods. In order to formulate the methods we present the necessary geometric analysis and, in the context of evolving surfaces, the necessary transport formulae. A wide variety of equations and applications are covered. Some ideas of the numerical analysis are presented along with illustrative numerical examples.",
    "cited_by_count": 621,
    "openalex_id": "https://openalex.org/W2157670588",
    "type": "article"
  },
  {
    "title": "The heterogeneous multiscale method",
    "doi": "https://doi.org/10.1017/s0962492912000025",
    "publication_date": "2012-04-19",
    "publication_year": 2012,
    "authors": "Assyr Abdulle; E Weinan; Björn Engquist; Eric Vanden‐Eijnden",
    "corresponding_authors": "",
    "abstract": "The heterogeneous multiscale method (HMM), a general framework for designing multiscale algorithms, is reviewed. Emphasis is given to the error analysis that comes naturally with the framework. Examples of finite element and finite difference HMM are presented. Applications to dynamical systems and stochastic simulation algorithms with multiple time scales, spall fracture and heat conduction in microprocessors are discussed.",
    "cited_by_count": 607,
    "openalex_id": "https://openalex.org/W2138940269",
    "type": "article"
  },
  {
    "title": "Geometric numerical integration illustrated by the Störmer–Verlet method",
    "doi": "https://doi.org/10.1017/s0962492902000144",
    "publication_date": "2003-05-01",
    "publication_year": 2003,
    "authors": "Ernst Hairer; Christian Lubich; Gerhard Wanner",
    "corresponding_authors": "",
    "abstract": "The subject of geometric numerical integration deals with numerical integrators that preserve geometric properties of the flow of a differential equation, and it explains how structure preservation leads to improved long-time behaviour. This article illustrates concepts and results of geometric numerical integration on the important example of the Störmer–Verlet method. It thus presents a cross-section of the recent monograph by the authors, enriched by some additional material. After an introduction to the Newton–Störmer–Verlet–leapfrog method and its various interpretations, there follows a discussion of geometric properties: reversibility, symplecticity, volume preservation, and conservation of first integrals. The extension to Hamiltonian systems on manifolds is also described. The theoretical foundation relies on a backward error analysis, which translates the geometric properties of the method into the structure of a modified differential equation, whose flow is nearly identical to the numerical method. Combined with results from perturbation theory, this explains the excellent long-time behaviour of the method: long-time energy conservation, linear error growth and preservation of invariant tori in near-integrable systems, a discrete virial theorem, and preservation of adiabatic invariants.",
    "cited_by_count": 604,
    "openalex_id": "https://openalex.org/W2142274086",
    "type": "article"
  },
  {
    "title": "Splitting methods",
    "doi": "https://doi.org/10.1017/s0962492902000053",
    "publication_date": "2002-01-01",
    "publication_year": 2002,
    "authors": "Robert I. McLachlan; G. Quispel",
    "corresponding_authors": "",
    "abstract": "I thought that instead of the great number of precepts of which logic is composed, I would have enough with the four following ones, provided that I made a firm and unalterable resolution not to violate them even in a single instance. The first rule was never to accept anything as true unless I recognized it to be certainly and evidently such …. The second was to divide each of the difficulties which I encountered into as many parts as possible, and as might be required for an easier solution . (Descartes) We survey splitting methods for the numerical integration of ordinary differential equations (ODEs). Splitting methods arise when a vector field can be split into a sum of two or more parts that are each simpler to integrate than the original (in a sense to be made precise). One of the main applications of splitting methods is in geometric integration, that is, the integration of vector fields that possess a certain geometric property ( e.g. , being Hamiltonian, or divergence-free, or possessing a symmetry or first integral) that one wants to preserve. We first survey the classification of geometric properties of dynamical systems, before considering the theory and applications of splitting in each case. Once a splitting is constructed, the pieces are composed to form the integrator; we discuss the theory of such ‘composition methods’ and summarize the best currently known methods. Finally, we survey applications from celestial mechanics, quantum mechanics, accelerator physics, molecular dynamics, and fluid dynamics, and examples from dynamical systems, biology and reaction–diffusion systems.",
    "cited_by_count": 603,
    "openalex_id": "https://openalex.org/W4245463005",
    "type": "article"
  },
  {
    "title": "Domain decomposition algorithms",
    "doi": "https://doi.org/10.1017/s0962492900002427",
    "publication_date": "1994-01-01",
    "publication_year": 1994,
    "authors": "Tony F. Chan; Tarek P. Mathew",
    "corresponding_authors": "",
    "abstract": "Domain decomposition refers to divide and conquer techniques for solving partial differential equations by iteratively solving subproblems defined on smaller subdomains. The principal advantages include enhancement of parallelism and localized treatment of complex and irregular geometries, singularities and anomalous regions. Additionally, domain decomposition can sometimes reduce the computational complexity of the underlying solution method. In this article, we survey iterative domain decomposition techniques that have been developed in recent years for solving several kinds of partial differential equations, including elliptic, parabolic, and differential systems such as the Stokes problem and mixed formulations of elliptic problems. We focus on describing the salient features of the algorithms and describe them using easy to understand matrix notation. In the case of elliptic problems, we also provide an introduction to the convergence theory, which requires some knowledge of finite element spaces and elementary functional analysis.",
    "cited_by_count": 589,
    "openalex_id": "https://openalex.org/W2104126767",
    "type": "article"
  },
  {
    "title": "Solving inverse problems using data-driven models",
    "doi": "https://doi.org/10.1017/s0962492919000059",
    "publication_date": "2019-05-01",
    "publication_year": 2019,
    "authors": "Simon Arridge; Peter Maaß; Ozan Öktem; Carola‐Bibiane Schönlieb",
    "corresponding_authors": "",
    "abstract": "Recent research in inverse problems seeks to develop a mathematically coherent foundation for combining data-driven models, and in particular those based on deep learning, with domain-specific knowledge contained in physical–analytical models. The focus is on solving ill-posed inverse problems that are at the core of many challenging applications in the natural sciences, medicine and life sciences, as well as in engineering and industrial applications. This survey paper aims to give an account of some of the main contributions in data-driven inverse problems.",
    "cited_by_count": 586,
    "openalex_id": "https://openalex.org/W2952020389",
    "type": "article"
  },
  {
    "title": "Random matrix theory",
    "doi": "https://doi.org/10.1017/s0962492904000236",
    "publication_date": "2005-04-19",
    "publication_year": 2005,
    "authors": "Alan Edelman; N. Raj Rao",
    "corresponding_authors": "",
    "abstract": "Random matrix theory is now a big subject with applications in many disciplines of science, engineering and finance. This article is a survey specifically oriented towards the needs and interests of a numerical analyst. This survey includes some original material not found anywhere else. We include the important mathematics which is a very modern development, as well as the computational software that is transforming the theory into useful practice.",
    "cited_by_count": 548,
    "openalex_id": "https://openalex.org/W2046351805",
    "type": "article"
  },
  {
    "title": "Direct search algorithms for optimization calculations",
    "doi": "https://doi.org/10.1017/s0962492900002841",
    "publication_date": "1998-01-01",
    "publication_year": 1998,
    "authors": "M. J. D. Powell",
    "corresponding_authors": "M. J. D. Powell",
    "abstract": "Many different procedures have been proposed for optimization calculations when first derivatives are not available. Further, several researchers have contributed to the subject, including some who wish to prove convergence theorems, and some who wish to make any reduction in the least calculated value of the objective function. There is not even a key idea that can be used as a foundation of a review, except for the problem itself, which is the adjustment of variables so that a function becomes least, where each value of the function is returned by a subroutine for each trial vector of variables. Therefore the paper is a collection of essays on particular strategies and algorithms, in order to consider the advantages, limitations and theory of several techniques. The subjects addressed are line search methods, the restriction of vectors of variables to discrete grids, the use of geometric simplices, conjugate direction procedures, trust region algorithms that form linear or quadratic approximations to the objective function, and simulated annealing. We study the main features of the methods themselves, instead of providing a catalogue of references to published work, because an understanding of these features may be very helpful to future research.",
    "cited_by_count": 541,
    "openalex_id": "https://openalex.org/W2079777091",
    "type": "article"
  },
  {
    "title": "An introduction to continuous optimization for imaging",
    "doi": "https://doi.org/10.1017/s096249291600009x",
    "publication_date": "2016-05-01",
    "publication_year": 2016,
    "authors": "Antonin Chambolle; Thomas Pock",
    "corresponding_authors": "",
    "abstract": "A large number of imaging problems reduce to the optimization of a cost function, with typical structural properties. The aim of this paper is to describe the state of the art in continuous optimization methods for such problems, and present the most successful approaches and their interconnections. We place particular emphasis on optimal first-order schemes that can deal with typical non-smooth and large-scale objective functions used in imaging problems. We illustrate and compare the different algorithms using classical non-smooth problems in imaging, such as denoising and deblurring. Moreover, we present applications of the algorithms to more advanced problems, such as magnetic resonance imaging, multilabel image segmentation, optical flow estimation, stereo matching, and classification.",
    "cited_by_count": 530,
    "openalex_id": "https://openalex.org/W2405803404",
    "type": "article"
  },
  {
    "title": "Entropy stability theory for difference approximations of nonlinear conservation laws and related time-dependent problems",
    "doi": "https://doi.org/10.1017/s0962492902000156",
    "publication_date": "2003-05-01",
    "publication_year": 2003,
    "authors": "Eitan Tadmor",
    "corresponding_authors": "Eitan Tadmor",
    "abstract": "We study the entropy stability of difference approximations to nonlinear hyperbolic conservation laws, and related time-dependent problems governed by additional dissipative and dispersive forcing terms. We employ a comparison principle as the main tool for entropy stability analysis, comparing the entropy production of a given scheme against properly chosen entropy-conservative schemes. To this end, we introduce general families of entropy-conservative schemes, interesting in their own right. The present treatment of such schemes extends our earlier recipe for construction of entropy-conservative schemes, introduced in Tadmor (1987 b ). The new families of entropy-conservative schemes offer two main advantages, namely, (i) their numerical fluxes admit an explicit, closed-form expression, and (ii) by a proper choice of their path of integration in phase space, we can distinguish between different families of waves within the same computational cell; in particular, entropy stability can be enforced on rarefactions while keeping the sharp resolution of shock discontinuities. A comparison with the numerical viscosities associated with entropy-conservative schemes provides a useful framework for the construction and analysis of entropy-stable schemes. We employ this framework for a detailed study of entropy stability for a host of first- and second-order accurate schemes. The comparison approach yields a precise characterization of the entropy stability of semi-discrete schemes for both scalar problems and systems of equations. We extend these results to fully discrete schemes. Here, spatial entropy dissipation is balanced by the entropy production due to time discretization with a suffciently small time-step, satisfying a suitable CFL condition. Finally, we revisit the question of entropy stability for fully discrete schemes using a different approach based on homotopy arguments. We prove entropy stability under optimal CFL conditions.",
    "cited_by_count": 490,
    "openalex_id": "https://openalex.org/W2072226973",
    "type": "article"
  },
  {
    "title": "Adjoint methods for PDEs: <i>a posteriori</i> error analysis and postprocessing by duality",
    "doi": "https://doi.org/10.1017/s096249290200003x",
    "publication_date": "2002-01-01",
    "publication_year": 2002,
    "authors": "Michael B. Giles; Endre Süli",
    "corresponding_authors": "",
    "abstract": "We give an overview of recent developments concerning the use of adjoint methods in two areas: the a posteriori error analysis of finite element methods for the numerical solution of partial differential equations where the quantity of interest is a functional of the solution, and superconvergent extraction of integral functionals by postprocessing.",
    "cited_by_count": 489,
    "openalex_id": "https://openalex.org/W2027619967",
    "type": "article"
  },
  {
    "title": "Finite element approximation of eigenvalue problems",
    "doi": "https://doi.org/10.1017/s0962492910000012",
    "publication_date": "2010-05-01",
    "publication_year": 2010,
    "authors": "Daniele Boffi",
    "corresponding_authors": "Daniele Boffi",
    "abstract": "We discuss the finite element approximation of eigenvalue problems associated with compact operators. While the main emphasis is on symmetric problems, some comments are present for non-self-adjoint operators as well. The topics covered include standard Galerkin approximations, non-conforming approximations, and approximation of eigenvalue problems in mixed form. Some applications of the theory are presented and, in particular, the approximation of the Maxwell eigenvalue problem is discussed in detail. The final part tries to introduce the reader to the fascinating setting of differential forms and homological techniques with the description of the Hodge–Laplace eigenvalue problem and its mixed equivalent formulations. Several examples and numerical computations complete the paper, ranging from very basic exercises to more significant applications of the developed theory.",
    "cited_by_count": 476,
    "openalex_id": "https://openalex.org/W2157129549",
    "type": "article"
  },
  {
    "title": "Wavelet and multiscale methods for operator equations",
    "doi": "https://doi.org/10.1017/s0962492900002713",
    "publication_date": "1997-01-01",
    "publication_year": 1997,
    "authors": "Wolfgang Dahmen",
    "corresponding_authors": "Wolfgang Dahmen",
    "abstract": "More than anything else, the increase of computing power seems to stimulate the greed for tackling ever larger problems involving large-scale numerical simulation. As a consequence, the need for understanding something like the intrinsic complexity of a problem occupies a more and more pivotal position. Moreover, computability often only becomes feasible if an algorithm can be found that is asymptotically optimal . This means that storage and the number of floating point operations needed to resolve the problem with desired accuracy remain proportional to the problem size when the resolution of the discretization is refined. A significant reduction of complexity is indeed often possible, when the underlying problem admits a continuous model in terms of differential or integral equations. The physical phenomena behind such a model usually exhibit characteristic features over a wide range of scales. Accordingly, the most successful numerical schemes exploit in one way or another the interaction of different scales of discretization. A very prominent representative is the multigrid methodology; see, for instance, Hackbusch (1985) and Bramble (1993). In a way it has caused a breakthrough in numerical analysis since, in an important range of cases, it does indeed provide asymptotically optimal schemes. For closely related multilevel techniques and a unified treatment of several variants, such as multiplicative or additive subspace correction methods, see Bramble, Pasciak and Xu (1990), Oswald (1994), Xu (1992), and Yserentant (1993). Although there remain many unresolved problems, multigrid or multilevel schemes in the classical framework of finite difference and finite element discretizations exhibit by now a comparatively clear profile. They are particularly powerful for elliptic and parabolic problems.",
    "cited_by_count": 461,
    "openalex_id": "https://openalex.org/W2115566547",
    "type": "article"
  },
  {
    "title": "Iterative solution of linear systems",
    "doi": "https://doi.org/10.1017/s0962492900002245",
    "publication_date": "1992-01-01",
    "publication_year": 1992,
    "authors": "Roland W. Freund; Gene H. Golub; Noël M. Nachtigal",
    "corresponding_authors": "",
    "abstract": "Recent advances in the field of iterative methods for solving large linear systems are reviewed. The main focus is on developments in the area of conjugate gradient-type algorithms and Krylov subspace methods for nonHermitian matrices.",
    "cited_by_count": 444,
    "openalex_id": "https://openalex.org/W2100384730",
    "type": "article"
  },
  {
    "title": "Complete search in continuous global optimization and constraint satisfaction",
    "doi": "https://doi.org/10.1017/s0962492904000194",
    "publication_date": "2004-05-01",
    "publication_year": 2004,
    "authors": "Arnold Neumaier",
    "corresponding_authors": "Arnold Neumaier",
    "abstract": "This survey covers the state of the art of techniques for solving general-purpose constrained global optimization problems and continuous constraint satisfaction problems, with emphasis on complete techniques that provably find all solutions (if there are finitely many). The core of the material is presented in sufficient detail that the survey may serve as a text for teaching constrained global optimization.After giving motivations for and important examples of applications of global optimization, a precise problem definition is given, and a general form of the traditional first-order necessary conditions for a solution. Then more than a dozen software packages for complete global search are described.A quick review of incomplete methods for bound-constrained problems and recipes for their use in the constrained case follows; an explicit example is discussed, introducing the main techniques used within branch and bound techniques. Sections on interval arithmetic, constrained propagation and local optimization are followed by a discussion of how to avoid the cluster problem. Then a discussion of important problem transformations follows, in particular of linear, convex, and semilinear (= mixed integer linear) relaxations that are important for handling larger problems.Next, reliability issues – centring on rounding error handling and testing methodologies – are discussed, and the COCONUT framework for the integration of the different techniques is introduced. A list of challenges facing the field in the near future concludes the survey.",
    "cited_by_count": 430,
    "openalex_id": "https://openalex.org/W2154904851",
    "type": "article"
  },
  {
    "title": "Computation of geometric partial differential equations and mean curvature flow",
    "doi": "https://doi.org/10.1017/s0962492904000224",
    "publication_date": "2005-04-19",
    "publication_year": 2005,
    "authors": "Klaus Deckelnick; Gerhard Dziuk; Charles M. Elliott",
    "corresponding_authors": "",
    "abstract": "This review concerns the computation of curvature-dependent interface motion governed by geometric partial differential equations. The canonical problem of mean curvature flow is that of finding a surface which evolves so that, at every point on the surface, the normal velocity is given by the mean curvature. In recent years the interest in geometric PDEs involving curvature has burgeoned. Examples of applications are, amongst others, the motion of grain boundaries in alloys, phase transitions and image processing. The methods of analysis, discretization and numerical analysis depend on how the surface is represented. The simplest approach is when the surface is a graph over a base domain. This is an example of a sharp interface approach which, in the general parametric approach , involves seeking a parametrization of the surface over a base surface, such as a sphere. On the other hand an interface can be represented implicitly as a level surface of a function, and this idea gives rise to the so-called level set method . Another implicit approach is the phase field method , which approximates the interface by a zero level set of a phase field satisfying a PDE depending on a new parameter. Each approach has its own advantages and disadvantages. In the article we describe the mathematical formulations of these approaches and their discretizations. Algorithms are set out for each approach, convergence results are given and are supported by computational results and numerous graphical figures. Besides mean curvature flow, the topics of anisotropy and the higher order geometric PDEs for Willmore flow and surface diffusion are covered.",
    "cited_by_count": 412,
    "openalex_id": "https://openalex.org/W2115218270",
    "type": "article"
  },
  {
    "title": "A survey of structure from motion.",
    "doi": "https://doi.org/10.1017/s096249291700006x",
    "publication_date": "2017-05-01",
    "publication_year": 2017,
    "authors": "Onur Özyeşil; Vladislav Voroninski; Ronen Basri; Amit Singer",
    "corresponding_authors": "",
    "abstract": "The structure from motion (SfM) problem in computer vision is to recover the three-dimensional (3D) structure of a stationary scene from a set of projective measurements, represented as a collection of two-dimensional (2D) images, via estimation of motion of the cameras corresponding to these images. In essence, SfM involves the three main stages of (i) extracting features in images ( e.g. points of interest, lines, etc. ) and matching these features between images, (ii) camera motion estimation ( e.g. using relative pairwise camera positions estimated from the extracted features), and (iii) recovery of the 3D structure using the estimated motion and features ( e.g. by minimizing the so-called reprojection error ). This survey mainly focuses on relatively recent developments in the literature pertaining to stages (ii) and (iii). More specifically, after touching upon the early factorization-based techniques for motion and structure estimation, we provide a detailed account of some of the recent camera location estimation methods in the literature, followed by discussion of notable techniques for 3D structure recovery. We also cover the basics of the simultaneous localization and mapping (SLAM) problem, which can be viewed as a specific case of the SfM problem. Further, our survey includes a review of the fundamentals of feature extraction and matching ( i.e. stage (i) above), various recent methods for handling ambiguities in 3D scenes, SfM techniques involving relatively uncommon camera models and image features, and popular sources of data and SfM software.",
    "cited_by_count": 408,
    "openalex_id": "https://openalex.org/W2963221299",
    "type": "article"
  },
  {
    "title": "Radiation boundary conditions for the numerical simulation of waves",
    "doi": "https://doi.org/10.1017/s0962492900002890",
    "publication_date": "1999-01-01",
    "publication_year": 1999,
    "authors": "Thomas Hagstrom",
    "corresponding_authors": "Thomas Hagstrom",
    "abstract": "We consider the efficient evaluation of accurate radiation boundary conditions for time domain simulations of wave propagation on unbounded spatial domains. This issue has long been a primary stumbling block for the reliable solution of this important class of problems. In recent years, a number of new approaches have been introduced which have radically changed the situation. These include methods for the fast evaluation of the exact nonlocal operators in special geometries, novel sponge layers with reflectionless interfaces, and improved techniques for applying sequences of approximate conditions to higher order. For the primary isotropic, constant coefficient equations of wave theory, these new developments provide an essentially complete solution of the numerical radiation condition problem.",
    "cited_by_count": 395,
    "openalex_id": "https://openalex.org/W2022171568",
    "type": "article"
  },
  {
    "title": "Symplectic integrators for Hamiltonian problems: an overview",
    "doi": "https://doi.org/10.1017/s0962492900002282",
    "publication_date": "1992-01-01",
    "publication_year": 1992,
    "authors": "J. M. Sanz‐Serna",
    "corresponding_authors": "J. M. Sanz‐Serna",
    "abstract": "In the sciences, situations where dissipation is not significant may invariably be modelled by Hamiltonian systems of ordinary, or partial, differential equations. Symplectic integrators are numerical methods specifically aimed at advancing in time the solution of Hamiltonian systems. Roughly speaking, ‘symplecticness’ is a characteristic property possessed by the solutions of Hamiltonian problems. A numerical method is called symplectic if, when applied to Hamiltonian problems, it generates numerical solutions which inherit the property of symplecticness.",
    "cited_by_count": 388,
    "openalex_id": "https://openalex.org/W2148437017",
    "type": "article"
  },
  {
    "title": "Derivative-free optimization methods",
    "doi": "https://doi.org/10.1017/s0962492919000060",
    "publication_date": "2019-05-01",
    "publication_year": 2019,
    "authors": "Jeffrey Larson; Matt Menickelly; Stefan M. Wild",
    "corresponding_authors": "",
    "abstract": "In many optimization problems arising from scientific, engineering and artificial intelligence applications, objective and constraint functions are available only as the output of a black-box or simulation oracle that does not provide derivative information. Such settings necessitate the use of methods for derivative-free, or zeroth-order, optimization. We provide a review and perspectives on developments in these methods, with an emphasis on highlighting recent developments and on unifying treatment of such problems in the non-linear optimization and machine learning literature. We categorize methods based on assumed properties of the black-box functions, as well as features of the methods. We first overview the primary setting of deterministic methods applied to unconstrained, non-convex optimization problems where the objective function is defined by a deterministic black-box oracle. We then discuss developments in randomized methods, methods that assume some additional structure about the objective (including convexity, separability and general non-smooth compositions), methods for problems where the output of the black-box oracle is stochastic, and methods for handling different types of constraints.",
    "cited_by_count": 370,
    "openalex_id": "https://openalex.org/W3102143361",
    "type": "article"
  },
  {
    "title": "Numerical methods for kinetic equations",
    "doi": "https://doi.org/10.1017/s0962492914000063",
    "publication_date": "2014-05-01",
    "publication_year": 2014,
    "authors": "Giacomo Dimarco; Lorenzo Pareschi",
    "corresponding_authors": "",
    "abstract": "In this survey we consider the development and mathematical analysis of numerical methods for kinetic partial differential equations. Kinetic equations represent a way of describing the time evolution of a system consisting of a large number of particles. Due to the high number of dimensions and their intrinsic physical properties, the construction of numerical methods represents a challenge and requires a careful balance between accuracy and computational complexity. Here we review the basic numerical techniques for dealing with such equations, including the case of semi-Lagrangian methods, discrete-velocity models and spectral methods. In addition we give an overview of the current state of the art of numerical methods for kinetic equations. This covers the derivation of fast algorithms, the notion of asymptotic-preserving methods and the construction of hybrid schemes.",
    "cited_by_count": 353,
    "openalex_id": "https://openalex.org/W1974987146",
    "type": "article"
  },
  {
    "title": "Modern regularization methods for inverse problems",
    "doi": "https://doi.org/10.1017/s0962492918000016",
    "publication_date": "2018-05-01",
    "publication_year": 2018,
    "authors": "Martin Benning; Martin Burger",
    "corresponding_authors": "",
    "abstract": "Regularization methods are a key tool in the solution of inverse problems. They are used to introduce prior knowledge and allow a robust approximation of ill-posed (pseudo-) inverses. In the last two decades interest has shifted from linear to nonlinear regularization methods, even for linear inverse problems. The aim of this paper is to provide a reasonably comprehensive overview of this shift towards modern nonlinear regularization methods, including their analysis, applications and issues for future research. In particular we will discuss variational methods and techniques derived from them, since they have attracted much recent interest and link to other fields, such as image processing and compressed sensing. We further point to developments related to statistical inverse problems, multiscale decompositions and learning theory.",
    "cited_by_count": 347,
    "openalex_id": "https://openalex.org/W2963399478",
    "type": "article"
  },
  {
    "title": "Tsunami modelling with adaptively refined finite volume methods",
    "doi": "https://doi.org/10.1017/s0962492911000043",
    "publication_date": "2011-04-28",
    "publication_year": 2011,
    "authors": "Randall J. LeVeque; David L. George; Marsha Berger",
    "corresponding_authors": "",
    "abstract": "Numerical modelling of transoceanic tsunami propagation, together with the detailed modelling of inundation of small-scale coastal regions, poses a number of algorithmic challenges. The depth-averaged shallow water equations can be used to reduce this to a time-dependent problem in two space dimensions, but even so it is crucial to use adaptive mesh refinement in order to efficiently handle the vast differences in spatial scales. This must be done in a ‘wellbalanced’ manner that accurately captures very small perturbations to the steady state of the ocean at rest. Inundation can be modelled by allowing cells to dynamically change from dry to wet, but this must also be done carefully near refinement boundaries. We discuss these issues in the context of Riemann-solver-based finite volume methods for tsunami modelling. Several examples are presented using the GeoClaw software, and sample codes are available to accompany the paper. The techniques discussed also apply to a variety of other geophysical flows.",
    "cited_by_count": 299,
    "openalex_id": "https://openalex.org/W2106839265",
    "type": "article"
  },
  {
    "title": "Mathematical analysis of variational isogeometric methods",
    "doi": "https://doi.org/10.1017/s096249291400004x",
    "publication_date": "2014-05-01",
    "publication_year": 2014,
    "authors": "L. Beirão da Veiga; Annalisa Buffa; Giancarlo Sangalli; Rafael Vázquez",
    "corresponding_authors": "",
    "abstract": "This review paper collects several results that form part of the theoretical foundation of isogeometric methods. We analyse variational techniques for the numerical resolution of PDEs based on splines or NURBS and we provide optimal approximation and error estimates in several cases of interest. The theory presented also includes estimates for T-splines, which are an extension of splines allowing for local refinement. In particular, we focus our attention on elliptic and saddle point problems, and we define spline edge and face elements. Our theoretical results are demonstrated by a rich set of numerical examples. Finally, we discuss implementation and efficiency together with preconditioning issues for the final linear system.",
    "cited_by_count": 290,
    "openalex_id": "https://openalex.org/W2001440251",
    "type": "article"
  },
  {
    "title": "Solving PDEs with radial basis functions",
    "doi": "https://doi.org/10.1017/s0962492914000130",
    "publication_date": "2015-04-27",
    "publication_year": 2015,
    "authors": "Bengt Fornberg; Natasha Flyer",
    "corresponding_authors": "",
    "abstract": "Finite differences provided the first numerical approach that permitted large-scale simulations in many applications areas, such as geophysical fluid dynamics. As accuracy and integration time requirements gradually increased, the focus shifted from finite differences to a variety of different spectral methods. During the last few years, radial basis functions, in particular in their ‘local’ RBF-FD form, have taken the major step from being mostly a curiosity approach for small-scale PDE ‘toy problems’ to becoming a major contender also for very large simulations on advanced distributed memory computer systems. Being entirely mesh-free, RBF-FD discretizations are also particularly easy to implement, even when local refinements are needed. This article gives some background to this development, and highlights some recent results.",
    "cited_by_count": 282,
    "openalex_id": "https://openalex.org/W2020462115",
    "type": "article"
  },
  {
    "title": "Sparse tensor discretizations of high-dimensional parametric and stochastic PDEs",
    "doi": "https://doi.org/10.1017/s0962492911000055",
    "publication_date": "2011-04-28",
    "publication_year": 2011,
    "authors": "Christoph Schwab; Claude Jeffrey Gittelson",
    "corresponding_authors": "",
    "abstract": "Partial differential equations (PDEs) with random input data, such as random loadings and coefficients, are reformulated as parametric, deterministic PDEs on parameter spaces of high, possibly infinite dimension. Tensorized operator equations for spatial and temporal k -point correlation functions of their random solutions are derived. Parametric, deterministic PDEs for the laws of the random solutions are derived. Representations of the random solutions' laws on infinite-dimensional parameter spaces in terms of ‘generalized polynomial chaos’ (GPC) series are established. Recent results on the regularity of solutions of these parametric PDEs are presented. Convergence rates of best N -term approximations, for adaptive stochastic Galerkin and collocation discretizations of the parametric, deterministic PDEs, are established. Sparse tensor products of hierarchical (multi-level) discretizations in physical space (and time), and GPC expansions in parameter space, are shown to converge at rates which are independent of the dimension of the parameter space. A convergence analysis of multi-level Monte Carlo (MLMC) discretizations of PDEs with random coefficients is presented. Sufficient conditions on the random inputs for superiority of sparse tensor discretizations over MLMC discretizations are established for linear elliptic, parabolic and hyperbolic PDEs with random coefficients.",
    "cited_by_count": 279,
    "openalex_id": "https://openalex.org/W2083754610",
    "type": "article"
  },
  {
    "title": "Adaptivity with moving grids",
    "doi": "https://doi.org/10.1017/s0962492906400015",
    "publication_date": "2009-05-01",
    "publication_year": 2009,
    "authors": "Chris Budd; Weizhang Huang; Robert D. Russell",
    "corresponding_authors": "",
    "abstract": "In this article we survey r -adaptive (or moving grid) methods for solving time-dependent partial differential equations (PDEs). Although these methods have received much less attention than their h - and p -adaptive counterparts, particularly within the finite element community, we review the substantial progress that has been made in developing more robust and reliable algorithms and in understanding the basic principles behind these methods, and we give some numerical examples illustrative of the wide classes of problems for which these methods are suitable alternatives to the traditional ones. More specifically, we first examine the basic geometric properties of moving meshes in both one and higher spatial dimensions, and discuss the discretization process for PDEs on such moving meshes (both structured and unstructured). In particular, we consider the issues of mesh regularity, equidistribution, alignment, and associated variational methods. An overview is given of the general interpolation error analysis for a function or a truncation error on such an adaptive mesh. Guided by these principles, we show how to design effective moving mesh strategies. We then examine in more detail how these strategies can be implemented in practice. The first class of methods which we consider are based upon controlling mesh density and hence are called position-based methods. These make use of a so-called moving mesh PDE (MMPDE) approach and variational methods, as well as optimal transport methods. This is followed by an analysis of methods which have a more Lagrange-like interpretation, and due to this focus are called velocity-based methods. These include the moving finite element method (MFE), the geometric conservation law (GCL) methods, and the deformation map method. Finally, we present a number of specific types of examples for which the use of a moving mesh method is particularly effective in applications. These include scale-invariant problems, blow-up problems, problems with moving fronts and problems in meteorology. We conclude that, whilst r -adaptive methods are still in their relatively early stages of development, with many outstanding questions remaining, they have enormous potential and indeed can produce an optimal form of adaptivity for many problems.",
    "cited_by_count": 272,
    "openalex_id": "https://openalex.org/W2122180808",
    "type": "article"
  },
  {
    "title": "Verification methods: Rigorous results using floating-point arithmetic",
    "doi": "https://doi.org/10.1017/s096249291000005x",
    "publication_date": "2010-05-01",
    "publication_year": 2010,
    "authors": "Siegfried M. Rump",
    "corresponding_authors": "Siegfried M. Rump",
    "abstract": "A classical mathematical proof is constructed using pencil and paper. However, there are many ways in which computers may be used in a mathematical proof. But ‘proof by computer’, or even the use of computers in the course of a proof, is not so readily accepted (the December 2008 issue of the Notices of the American Mathematical Society is devoted to formal proofs by computer). In the following we introduce verification methods and discuss how they can assist in achieving a mathematically rigorous result. In particular we emphasize how floating-point arithmetic is used.",
    "cited_by_count": 266,
    "openalex_id": "https://openalex.org/W2170345902",
    "type": "article"
  },
  {
    "title": "Topological pattern recognition for point cloud data",
    "doi": "https://doi.org/10.1017/s0962492914000051",
    "publication_date": "2014-05-01",
    "publication_year": 2014,
    "authors": "Gunnar Carlsson",
    "corresponding_authors": "Gunnar Carlsson",
    "abstract": "In this paper we discuss the adaptation of the methods of homology from algebraic topology to the problem of pattern recognition in point cloud data sets. The method is referred to as persistent homology , and has numerous applications to scientific problems. We discuss the definition and computation of homology in the standard setting of simplicial complexes and topological spaces, then show how one can obtain useful signatures, called barcodes, from finite metric spaces, thought of as sampled from a continuous object. We present several different cases where persistent homology is used, to illustrate the different ways in which the method can be applied.",
    "cited_by_count": 249,
    "openalex_id": "https://openalex.org/W2148676644",
    "type": "article"
  },
  {
    "title": "Approximation of high-dimensional parametric PDEs",
    "doi": "https://doi.org/10.1017/s0962492915000033",
    "publication_date": "2015-04-27",
    "publication_year": 2015,
    "authors": "Albert Cohen; Ronald DeVore",
    "corresponding_authors": "",
    "abstract": "Parametrized families of PDEs arise in various contexts such as inverse problems, control and optimization, risk assessment, and uncertainty quantification. In most of these applications, the number of parameters is large or perhaps even infinite. Thus, the development of numerical methods for these parametric problems is faced with the possible curse of dimensionality. This article is directed at (i) identifying and understanding which properties of parametric equations allow one to avoid this curse and (ii) developing and analysing effective numerical methods which fully exploit these properties and, in turn, are immune to the growth in dimensionality. Part I of this article studies the smoothness and approximability of the solution map, that is, the map $a\\mapsto u(a)$ , where $a$ is the parameter value and $u(a)$ is the corresponding solution to the PDE. It is shown that for many relevant parametric PDEs, the parametric smoothness of this map is typically holomorphic and also highly anisotropic, in that the relevant parameters are of widely varying importance in describing the solution. These two properties are then exploited to establish convergence rates of $n$ -term approximations to the solution map, for which each term is separable in the parametric and physical variables. These results reveal that, at least on a theoretical level, the solution map can be well approximated by discretizations of moderate complexity, thereby showing how the curse of dimensionality is broken. This theoretical analysis is carried out through concepts of approximation theory such as best $n$ -term approximation, sparsity, and $n$ -widths. These notions determine a priori the best possible performance of numerical methods and thus serve as a benchmark for concrete algorithms. Part II of this article turns to the development of numerical algorithms based on the theoretically established sparse separable approximations. The numerical methods studied fall into two general categories. The first uses polynomial expansions in terms of the parameters to approximate the solution map. The second one searches for suitable low-dimensional spaces for simultaneously approximating all members of the parametric family. The numerical implementation of these approaches is carried out through adaptive and greedy algorithms. An a priori analysis of the performance of these algorithms establishes how well they meet the theoretical benchmarks.",
    "cited_by_count": 249,
    "openalex_id": "https://openalex.org/W2963798430",
    "type": "article"
  },
  {
    "title": "Numerical-asymptotic boundary integral methods in high-frequency acoustic scattering",
    "doi": "https://doi.org/10.1017/s0962492912000037",
    "publication_date": "2012-04-19",
    "publication_year": 2012,
    "authors": "Simon N. Chandler‐Wilde; Ivan G. Graham; S. Langdon; Euan A. Spence",
    "corresponding_authors": "",
    "abstract": "In this article we describe recent progress on the design, analysis and implementation of hybrid numerical-asymptotic boundary integral methods for boundary value problems for the Helmholtz equation that model time harmonic acoustic wave scattering in domains exterior to impenetrable obstacles. These hybrid methods combine conventional piecewise polynomial approximations with high-frequency asymptotics to build basis functions suitable for representing the oscillatory solutions. They have the potential to solve scattering problems accurately in a computation time that is (almost) independent of frequency and this has been realized for many model problems. The design and analysis of this class of methods requires new results on the analysis and numerical analysis of highly oscillatory boundary integral operators and on the high-frequency asymptotics of scattering problems. The implementation requires the development of appropriate quadrature rules for highly oscillatory integrals. This article contains a historical account of the development of this currently very active field, a detailed account of recent progress and, in addition, a number of original research results on the design, analysis and implementation of these methods.",
    "cited_by_count": 236,
    "openalex_id": "https://openalex.org/W2038870672",
    "type": "article"
  },
  {
    "title": "Randomized numerical linear algebra: Foundations and algorithms",
    "doi": "https://doi.org/10.1017/s0962492920000021",
    "publication_date": "2020-05-01",
    "publication_year": 2020,
    "authors": "Per‐Gunnar Martinsson; Joel A. Tropp",
    "corresponding_authors": "",
    "abstract": "This survey describes probabilistic algorithms for linear algebraic computations, such as factorizing matrices and solving linear systems. It focuses on techniques that have a proven track record for real-world problems. The paper treats both the theoretical foundations of the subject and practical computational issues. Topics include norm estimation, matrix approximation by sampling, structured and unstructured random embeddings, linear regression problems, low-rank approximation, subspace iteration and Krylov methods, error estimation and adaptivity, interpolatory and CUR factorizations, Nyström approximation of positive semidefinite matrices, single-view (‘streaming’) algorithms, full rank-revealing factorizations, solvers for linear systems, and approximation of kernel matrices that arise in machine learning and in scientific computing.",
    "cited_by_count": 234,
    "openalex_id": "https://openalex.org/W3108353645",
    "type": "article"
  },
  {
    "title": "Stochastic finite element methods for partial differential equations with random input data",
    "doi": "https://doi.org/10.1017/s0962492914000075",
    "publication_date": "2014-05-01",
    "publication_year": 2014,
    "authors": "Max Gunzburger; Clayton Webster; Guannan Zhang",
    "corresponding_authors": "",
    "abstract": "The quantification of probabilistic uncertainties in the outputs of physical, biological, and social systems governed by partial differential equations with random inputs require, in practice, the discretization of those equations. Stochastic finite element methods refer to an extensive class of algorithms for the approximate solution of partial differential equations having random input data, for which spatial discretization is effected by a finite element method. Fully discrete approximations require further discretization with respect to solution dependences on the random variables. For this purpose several approaches have been developed, including intrusive approaches such as stochastic Galerkin methods, for which the physical and probabilistic degrees of freedom are coupled, and non-intrusive approaches such as stochastic sampling and interpolatory-type stochastic collocation methods, for which the physical and probabilistic degrees of freedom are uncoupled. All these method classes are surveyed in this article, including some novel recent developments. Details about the construction of the various algorithms and about theoretical error estimates and complexity analyses of the algorithms are provided. Throughout, numerical examples are used to illustrate the theoretical results and to provide further insights into the methodologies.",
    "cited_by_count": 225,
    "openalex_id": "https://openalex.org/W2072205359",
    "type": "article"
  },
  {
    "title": "Algebraic multigrid methods",
    "doi": "https://doi.org/10.1017/s0962492917000083",
    "publication_date": "2017-05-01",
    "publication_year": 2017,
    "authors": "Jinchao Xu; Ludmil Zikatanov",
    "corresponding_authors": "",
    "abstract": "This paper provides an overview of AMG methods for solving large-scale systems of equations, such as those from discretizations of partial differential equations. AMG is often understood as the acronym of ‘algebraic multigrid’, but it can also be understood as ‘abstract multigrid’. Indeed, we demonstrate in this paper how and why an algebraic multigrid method can be better understood at a more abstract level. In the literature, there are many different algebraic multigrid methods that have been developed from different perspectives. In this paper we try to develop a unified framework and theory that can be used to derive and analyse different algebraic multigrid methods in a coherent manner. Given a smoother $R$ for a matrix $A$ , such as Gauss–Seidel or Jacobi, we prove that the optimal coarse space of dimension $n_{c}$ is the span of the eigenvectors corresponding to the first $n_{c}$ eigenvectors $\\bar{R}A$ (with $\\bar{R}=R+R^{T}-R^{T}AR$ ). We also prove that this optimal coarse space can be obtained via a constrained trace-minimization problem for a matrix associated with $\\bar{R}A$ , and demonstrate that coarse spaces of most existing AMG methods can be viewed as approximate solutions of this trace-minimization problem. Furthermore, we provide a general approach to the construction of quasi-optimal coarse spaces, and we prove that under appropriate assumptions the resulting two-level AMG method for the underlying linear system converges uniformly with respect to the size of the problem, the coefficient variation and the anisotropy. Our theory applies to most existing multigrid methods, including the standard geometric multigrid method, classical AMG, energy-minimization AMG, unsmoothed and smoothed aggregation AMG and spectral AMGe.",
    "cited_by_count": 223,
    "openalex_id": "https://openalex.org/W2963889991",
    "type": "article"
  },
  {
    "title": "A survey of direct methods for sparse linear systems",
    "doi": "https://doi.org/10.1017/s0962492916000076",
    "publication_date": "2016-05-01",
    "publication_year": 2016,
    "authors": "Timothy A. Davis; Sivasankaran Rajamanickam; Wissam M. Sid-Lakhdar",
    "corresponding_authors": "",
    "abstract": "Wilkinson defined a sparse matrix as one with enough zeros that it pays to take advantage of them. 1 This informal yet practical definition captures the essence of the goal of direct methods for solving sparse matrix problems. They exploit the sparsity of a matrix to solve problems economically: much faster and using far less memory than if all the entries of a matrix were stored and took part in explicit computations. These methods form the backbone of a wide range of problems in computational science. A glimpse of the breadth of applications relying on sparse solvers can be seen in the origins of matrices in published matrix benchmark collections (Duff and Reid 1979 a , Duff, Grimes and Lewis 1989 a , Davis and Hu 2011). The goal of this survey article is to impart a working knowledge of the underlying theory and practice of sparse direct methods for solving linear systems and least-squares problems, and to provide an overview of the algorithms, data structures, and software available to solve these problems, so that the reader can both understand the methods and know how best to use them.",
    "cited_by_count": 211,
    "openalex_id": "https://openalex.org/W2397636522",
    "type": "article"
  },
  {
    "title": "The cardiovascular system: Mathematical modelling, numerical algorithms and clinical applications",
    "doi": "https://doi.org/10.1017/s0962492917000046",
    "publication_date": "2017-05-01",
    "publication_year": 2017,
    "authors": "Alfio Quarteroni; Andrea Manzoni; Christian Vergara",
    "corresponding_authors": "",
    "abstract": "Mathematical and numerical modelling of the cardiovascular system is a research topic that has attracted remarkable interest from the mathematical community because of its intrinsic mathematical difficulty and the increasing impact of cardiovascular diseases worldwide. In this review article we will address the two principal components of the cardiovascular system: arterial circulation and heart function. We will systematically describe all aspects of the problem, ranging from data imaging acquisition, stating the basic physical principles, analysing the associated mathematical models that comprise PDE and ODE systems, proposing sound and efficient numerical methods for their approximation, and simulating both benchmark problems and clinically inspired problems. Mathematical modelling itself imposes tremendous challenges, due to the amazing complexity of the cardiocirculatory system, the multiscale nature of the physiological processes involved, and the need to devise computational methods that are stable, reliable and efficient. Critical issues involve filtering the data, identifying the parameters of mathematical models, devising optimal treatments and accounting for uncertainties. For this reason, we will devote the last part of the paper to control and inverse problems, including parameter estimation, uncertainty quantification and the development of reduced-order models that are of paramount importance when solving problems with high complexity, which would otherwise be out of reach.",
    "cited_by_count": 211,
    "openalex_id": "https://openalex.org/W2611710652",
    "type": "article"
  },
  {
    "title": "The nonlinear eigenvalue problem",
    "doi": "https://doi.org/10.1017/s0962492917000034",
    "publication_date": "2017-05-01",
    "publication_year": 2017,
    "authors": "Stefan Güttel; Françoise Tisseur",
    "corresponding_authors": "",
    "abstract": "Nonlinear eigenvalue problems arise in a variety of science and engineering applications, and in the past ten years there have been numerous breakthroughs in the development of numerical methods. This article surveys nonlinear eigenvalue problems associated with matrix-valued functions which depend nonlinearly on a single scalar parameter, with a particular emphasis on their mathematical properties and available numerical solution techniques. Solvers based on Newton’s method, contour integration and sampling via rational interpolation are reviewed. Problems of selecting the appropriate parameters for each of the solver classes are discussed and illustrated with numerical examples. This survey also contains numerous MATLAB code snippets that can be used for interactive exploration of the discussed methods.",
    "cited_by_count": 205,
    "openalex_id": "https://openalex.org/W2598027716",
    "type": "article"
  },
  {
    "title": "Generalized barycentric coordinates and applications",
    "doi": "https://doi.org/10.1017/s0962492914000129",
    "publication_date": "2015-04-27",
    "publication_year": 2015,
    "authors": "Michael S. Floater",
    "corresponding_authors": "Michael S. Floater",
    "abstract": "This paper surveys the construction, properties, and applications of generalized barycentric coordinates on polygons and polyhedra. Applications include: surface mesh parametrization in geometric modelling; image, curve, and surface deformation in computer graphics; and polygonal and polyhedral finite element methods.",
    "cited_by_count": 192,
    "openalex_id": "https://openalex.org/W2328294984",
    "type": "article"
  },
  {
    "title": "Partial differential equations and stochastic methods in molecular dynamics",
    "doi": "https://doi.org/10.1017/s0962492916000039",
    "publication_date": "2016-05-01",
    "publication_year": 2016,
    "authors": "Tony Lelièvre; Gabriel Stoltz",
    "corresponding_authors": "",
    "abstract": "The objective of molecular dynamics computations is to infer macroscopic properties of matter from atomistic models via averages with respect to probability measures dictated by the principles of statistical physics. Obtaining accurate results requires efficient sampling of atomistic configurations, which are typically generated using very long trajectories of stochastic differential equations in high dimensions, such as Langevin dynamics and its overdamped limit. Depending on the quantities of interest at the macroscopic level, one may also be interested in dynamical properties computed from averages over paths of these dynamics. This review describes how techniques from the analysis of partial differential equations can be used to devise good algorithms and to quantify their efficiency and accuracy. In particular, a crucial role is played by the study of the long-time behaviour of the solution to the Fokker–Planck equation associated with the stochastic dynamics.",
    "cited_by_count": 177,
    "openalex_id": "https://openalex.org/W2401363764",
    "type": "article"
  },
  {
    "title": "Essentially non-oscillatory and weighted essentially non-oscillatory schemes",
    "doi": "https://doi.org/10.1017/s0962492920000057",
    "publication_date": "2020-05-01",
    "publication_year": 2020,
    "authors": "Chi‐Wang Shu",
    "corresponding_authors": "Chi‐Wang Shu",
    "abstract": "Essentially non-oscillatory (ENO) and weighted ENO (WENO) schemes were designed for solving hyperbolic and convection–diffusion equations with possibly discontinuous solutions or solutions with sharp gradient regions. The main idea of ENO and WENO schemes is actually an approximation procedure, aimed at achieving arbitrarily high-order accuracy in smooth regions and resolving shocks or other discontinuities sharply and in an essentially non-oscillatory fashion. Both finite volume and finite difference schemes have been designed using the ENO or WENO procedure, and these schemes are very popular in applications, most noticeably in computational fluid dynamics but also in other areas of computational physics and engineering. Since the main idea of the ENO and WENO schemes is an approximation procedure not directly related to partial differential equations (PDEs), ENO and WENO schemes also have non-PDE applications. In this paper we will survey the basic ideas behind ENO and WENO schemes, discuss their properties, and present examples of their applications to different types of PDEs as well as to non-PDE problems.",
    "cited_by_count": 154,
    "openalex_id": "https://openalex.org/W3110038039",
    "type": "article"
  },
  {
    "title": "Deep learning: a statistical viewpoint",
    "doi": "https://doi.org/10.1017/s0962492921000027",
    "publication_date": "2021-05-01",
    "publication_year": 2021,
    "authors": "Peter L. Bartlett; Andrea Montanari; Alexander Rakhlin",
    "corresponding_authors": "",
    "abstract": "The remarkable practical success of deep learning has revealed some major surprises from a theoretical perspective. In particular, simple gradient methods easily find near-optimal solutions to non-convex optimization problems, and despite giving a near-perfect fit to training data without any explicit effort to control model complexity, these methods exhibit excellent predictive accuracy. We conjecture that specific principles underlie these phenomena: that overparametrization allows gradient methods to find interpolating solutions, that these methods implicitly impose regularization, and that overparametrization leads to benign overfitting, that is, accurate predictions despite overfitting training data. In this article, we survey recent progress in statistical learning theory that provides examples illustrating these principles in simpler settings. We first review classical uniform convergence results and why they fall short of explaining aspects of the behaviour of deep learning methods. We give examples of implicit regularization in simple settings, where gradient methods lead to minimal norm functions that perfectly fit the training data. Then we review prediction methods that exhibit benign overfitting, focusing on regression problems with quadratic loss. For these methods, we can decompose the prediction rule into a simple component that is useful for prediction and a spiky component that is useful for overfitting but, in a favourable setting, does not harm prediction accuracy. We focus specifically on the linear regime for neural networks, where the network can be approximated by a linear model. In this regime, we demonstrate the success of gradient flow, and we consider benign overfitting with two-layer networks, giving an exact asymptotic analysis that precisely demonstrates the impact of overparametrization. We conclude by highlighting the key challenges that arise in extending these insights to realistic deep learning settings.",
    "cited_by_count": 137,
    "openalex_id": "https://openalex.org/W3191067499",
    "type": "article"
  },
  {
    "title": "Neural network approximation",
    "doi": "https://doi.org/10.1017/s0962492921000052",
    "publication_date": "2021-05-01",
    "publication_year": 2021,
    "authors": "Ronald DeVore; Boris Hanin; Guergana Petrova",
    "corresponding_authors": "",
    "abstract": "Neural networks (NNs) are the method of choice for building learning algorithms. They are now being investigated for other numerical tasks such as solving high-dimensional partial differential equations. Their popularity stems from their empirical success on several challenging learning problems (computer chess/Go, autonomous navigation, face recognition). However, most scholars agree that a convincing theoretical explanation for this success is still lacking. Since these applications revolve around approximating an unknown function from data observations, part of the answer must involve the ability of NNs to produce accurate approximations. This article surveys the known approximation properties of the outputs of NNs with the aim of uncovering the properties that are not present in the more traditional methods of approximation used in numerical analysis, such as approximations using polynomials, wavelets, rational functions and splines. Comparisons are made with traditional approximation methods from the viewpoint of rate distortion, i.e. error versus the number of parameters used to create the approximant. Another major component in the analysis of numerical approximation is the computational time needed to construct the approximation, and this in turn is intimately connected with the stability of the approximation algorithm. So the stability of numerical approximation using NNs is a large part of the analysis put forward. The survey, for the most part, is concerned with NNs using the popular ReLU activation function. In this case the outputs of the NNs are piecewise linear functions on rather complicated partitions of the domain of f into cells that are convex polytopes. When the architecture of the NN is fixed and the parameters are allowed to vary, the set of output functions of the NN is a parametrized nonlinear manifold. It is shown that this manifold has certain space-filling properties leading to an increased ability to approximate (better rate distortion) but at the expense of numerical stability. The space filling creates the challenge to the numerical method of finding best or good parameter choices when trying to approximate.",
    "cited_by_count": 137,
    "openalex_id": "https://openalex.org/W3194828218",
    "type": "article"
  },
  {
    "title": "Control of port-Hamiltonian differential-algebraic systems and applications",
    "doi": "https://doi.org/10.1017/s0962492922000083",
    "publication_date": "2023-05-01",
    "publication_year": 2023,
    "authors": "Volker Mehrmann; Benjamin Unger",
    "corresponding_authors": "",
    "abstract": "We discuss the modelling framework of port-Hamiltonian descriptor systems and their use in numerical simulation and control. The structure is ideal for automated network-based modelling since it is invariant under power-conserving interconnection, congruence transformations and Galerkin projection. Moreover, stability and passivity properties are easily shown. Condensed forms under orthogonal transformations present easy analysis tools for existence, uniqueness, regularity and numerical methods to check these properties. After recalling the concepts for general linear and nonlinear descriptor systems, we demonstrate that many difficulties that arise in general descriptor systems can be easily overcome within the port-Hamiltonian framework. The properties of port-Hamiltonian descriptor systems are analysed, and time discretization and numerical linear algebra techniques are discussed. Structure-preserving regularization procedures for descriptor systems are presented to make them suitable for simulation and control. Model reduction techniques that preserve the structure and stabilization and optimal control techniques are discussed. The properties of port-Hamiltonian descriptor systems and their use in modelling simulation and control methods are illustrated with several examples from different physical domains. The survey concludes with open problems and research topics that deserve further attention.",
    "cited_by_count": 68,
    "openalex_id": "https://openalex.org/W4376137587",
    "type": "article"
  },
  {
    "title": "Subdivision schemes in geometric modelling",
    "doi": "https://doi.org/10.1017/s0962492902000028",
    "publication_date": "2002-01-01",
    "publication_year": 2002,
    "authors": "Nira Dyn; David Levin",
    "corresponding_authors": "",
    "abstract": "Subdivision schemes are efficient computational methods for the design and representation of 3D surfaces of arbitrary topology. They are also a tool for the generation of refinable functions, which are instrumental in the construction of wavelets. This paper presents various flavours of subdivision, seasoned by the personal viewpoint of the authors, which is mainly concerned with geometric modelling. Our starting point is the general setting of scalar multivariate nonstationary schemes on regular grids. We also briefly review other classes of schemes, such as schemes on general nets, matrix schemes, non-uniform schemes and nonlinear schemes. Different representations of subdivision schemes, and several tools for the analysis of convergence, smoothness and approximation order are discussed, followed by explanatory examples.",
    "cited_by_count": 368,
    "openalex_id": "https://openalex.org/W2157787988",
    "type": "article"
  },
  {
    "title": "Survey of meshless and generalized finite element methods: A unified approach",
    "doi": "https://doi.org/10.1017/s0962492902000090",
    "publication_date": "2003-05-01",
    "publication_year": 2003,
    "authors": "Ivo Babuška; Uday Banerjee; John E. Osborn",
    "corresponding_authors": "",
    "abstract": "In the past few years meshless methods for numerically solving partial differential equations have come into the focus of interest, especially in the engineering community. This class of methods was essentially stimulated by difficulties related to mesh generation. Mesh generation is delicate in many situations, for instance, when the domain has complicated geometry; when the mesh changes with time, as in crack propagation, and remeshing is required at each time step; when a Lagrangian formulation is employed, especially with nonlinear PDEs. In addition, the need for flexibility in the selection of approximating functions ( e.g. , the flexibility to use non-polynomial approximating functions), has played a significant role in the development of meshless methods. There are many recent papers, and two books, on meshless methods; most of them are of an engineering character, without any mathematical analysis. In this paper we address meshless methods and the closely related generalized finite element methods for solving linear elliptic equations, using variational principles. We give a unified mathematical theory with proofs, briefly address implementational aspects, present illustrative numerical examples, and provide a list of references to the current literature. The aim of the paper is to provide a survey of a part of this new field, with emphasis on mathematics. We present proofs of essential theorems because we feel these proofs are essential for the understanding of the mathematical aspects of meshless methods, which has approximation theory as a major ingredient. As always, any new field is stimulated by and related to older ideas. This will be visible in our paper.",
    "cited_by_count": 356,
    "openalex_id": "https://openalex.org/W2009934830",
    "type": "article"
  },
  {
    "title": "Semidefinite optimization",
    "doi": "https://doi.org/10.1017/s0962492901000071",
    "publication_date": "2001-05-01",
    "publication_year": 2001,
    "authors": "Michael J. Todd",
    "corresponding_authors": "Michael J. Todd",
    "abstract": "Optimization problems in which the variable is not a vector but a symmetric matrix which is required to be positive semidefinite have been intensely studied in the last ten years. Part of the reason for the interest stems from the applicability of such problems to such diverse areas as designing the strongest column, checking the stability of a differential inclusion, and obtaining tight bounds for hard combinatorial optimization problems. Part also derives from great advances in our ability to solve such problems efficiently in theory and in practice (perhaps ‘or’ would be more appropriate: the most effective computational methods are not always provably efficient in theory, and vice versa ). Here we describe this class of optimization problems, give a number of examples demonstrating its significance, outline its duality theory, and discuss algorithms for solving such problems.",
    "cited_by_count": 347,
    "openalex_id": "https://openalex.org/W4243539849",
    "type": "article"
  },
  {
    "title": "Model reduction methods based on Krylov subspaces",
    "doi": "https://doi.org/10.1017/s0962492902000120",
    "publication_date": "2003-05-01",
    "publication_year": 2003,
    "authors": "Roland W. Freund",
    "corresponding_authors": "Roland W. Freund",
    "abstract": "In recent years, reduced-order modelling techniques based on Krylov-subspace iterations, especially the Lanczos algorithm and the Arnoldi process, have become popular tools for tackling the large-scale time-invariant linear dynamical systems that arise in the simulation of electronic circuits. This paper reviews the main ideas of reduced-order modelling techniques based on Krylov subspaces and describes some applications of reduced-order modelling in circuit simulation.",
    "cited_by_count": 341,
    "openalex_id": "https://openalex.org/W2161344224",
    "type": "article"
  },
  {
    "title": "Theory of algorithms for unconstrained optimization",
    "doi": "https://doi.org/10.1017/s0962492900002270",
    "publication_date": "1992-01-01",
    "publication_year": 1992,
    "authors": "Jorge Nocedal",
    "corresponding_authors": "Jorge Nocedal",
    "abstract": "A few months ago, while preparing a lecture to an audience that included engineers and numerical analysts, I asked myself the question: from the point of view of a user of nonlinear optimization routines, how interesting and practical is the body of theoretical analysis developed in this field? To make the question a bit more precise, I decided to select the best optimization methods known to date – those methods that deserve to be in a subroutine library – and for each method ask: what do we know about the behaviour of this method, as implemented in practice ? To make my task more tractable, I decided to consider only algorithms for unconstrained optimization.",
    "cited_by_count": 333,
    "openalex_id": "https://openalex.org/W2069752241",
    "type": "article"
  },
  {
    "title": "Interior methods for constrained optimization",
    "doi": "https://doi.org/10.1017/s0962492900002300",
    "publication_date": "1992-01-01",
    "publication_year": 1992,
    "authors": "Margaret H. Wright",
    "corresponding_authors": "Margaret H. Wright",
    "abstract": "Interior methods for optimization were widely used in the 1960s, primarily in the form of barrier methods. However, they were not seriously applied to linear programming because of the dominance of the simplex method. Barrier methods fell from favour during the 1970s for a variety of reasons, including their apparent inefficiency compared with the best available alternatives. In 1984, Karmarkar's announcement of a fast polynomial-time interior method for linear programming caused tremendous excitement in the field of optimization. A formal connection can be shown between his method and classical barrier methods, which have consequently undergone a renaissance in interest and popularity. Most papers published since 1984 have concentrated on issues of computational complexity in interior methods for linear programming. During the same period, implementations of interior methods have displayed great efficiency in solving many large linear programs of ever-increasing size. Interior methods have also been applied with notable success to nonlinear and combinatorial problems. This paper presents a self-contained survey of major themes in both classical material and recent developments related to the theory and practice of interior methods.",
    "cited_by_count": 275,
    "openalex_id": "https://openalex.org/W2157590940",
    "type": "article"
  },
  {
    "title": "Kernel techniques: From machine learning to meshless methods",
    "doi": "https://doi.org/10.1017/s0962492906270016",
    "publication_date": "2006-05-01",
    "publication_year": 2006,
    "authors": "Robert Schaback; Holger Wendland",
    "corresponding_authors": "",
    "abstract": "Kernels are valuable tools in various fields of numerical analysis, including approximation, interpolation, meshless methods for solving partial differential equations, neural networks, and machine learning. This contribution explains why and how kernels are applied in these disciplines. It uncovers the links between them, in so far as they are related to kernel techniques. It addresses non-expert readers and focuses on practical guidelines for using kernels in applications.",
    "cited_by_count": 272,
    "openalex_id": "https://openalex.org/W2089245375",
    "type": "article"
  },
  {
    "title": "Continuation and path following",
    "doi": "https://doi.org/10.1017/s0962492900002336",
    "publication_date": "1993-01-01",
    "publication_year": 1993,
    "authors": "Eugene L. Allgower; Kurt Georg",
    "corresponding_authors": "",
    "abstract": "The main ideas of path following by predictor–corrector and piecewise-linear methods, and their application in the direction of homotopy methods and nonlinear eigenvalue problems are reviewed. Further new applications to areas such as polynomial systems of equations, linear eigenvalue problems, interior methods for linear programming, parametric programming and complex bifurcation are surveyed. Complexity issues and available software are also discussed.",
    "cited_by_count": 271,
    "openalex_id": "https://openalex.org/W2143628714",
    "type": "article"
  },
  {
    "title": "Structured inverse eigenvalue problems",
    "doi": "https://doi.org/10.1017/s0962492902000016",
    "publication_date": "2002-01-01",
    "publication_year": 2002,
    "authors": "Moody T. Chu; Gene H. Golub",
    "corresponding_authors": "",
    "abstract": "An inverse eigenvalue problem concerns the reconstruction of a structured matrix from prescribed spectral data. Such an inverse problem arises in many applications where parameters of a certain physical system are to be determined from the knowledge or expectation of its dynamical behaviour. Spectral information is entailed because the dynamical behaviour is often governed by the underlying natural frequencies and normal modes. Structural stipulation is designated because the physical system is often subject to some feasibility constraints. The spectral data involved may consist of complete or only partial information on eigenvalues or eigenvectors. The structure embodied by the matrices can take many forms. The objective of an inverse eigenvalue problem is to construct a matrix that maintains both the specific structure as well as the given spectral property. In this expository paper the emphasis is to provide an overview of the vast scope of this intriguing problem, treating some of its many applications, its mathematical properties, and a variety of numerical techniques.",
    "cited_by_count": 267,
    "openalex_id": "https://openalex.org/W1991136704",
    "type": "article"
  },
  {
    "title": "An introduction to numerical methods for stochastic differential equations",
    "doi": "https://doi.org/10.1017/s0962492900002920",
    "publication_date": "1999-01-01",
    "publication_year": 1999,
    "authors": "Eckhard Platen",
    "corresponding_authors": "Eckhard Platen",
    "abstract": "This paper aims to give an overview and summary of numerical methods for the solution of stochastic differential equations. It covers discrete time strong and weak approximation methods that are suitable for different applications. A range of approaches and results is discussed within a unified framework. On the one hand, these methods can be interpreted as generalizing the well-developed theory on numerical analysis for deterministic ordinary differential equations. On the other hand they highlight the specific stochastic nature of the equations. In some cases these methods lead to completely new and challenging problems.",
    "cited_by_count": 266,
    "openalex_id": "https://openalex.org/W1521946947",
    "type": "article"
  },
  {
    "title": "Interior-point methods for optimization",
    "doi": "https://doi.org/10.1017/s0962492906370018",
    "publication_date": "2008-04-25",
    "publication_year": 2008,
    "authors": "Arkadi Nemirovski; Michael J. Todd",
    "corresponding_authors": "",
    "abstract": "This article describes the current state of the art of interior-point methods (IPMs) for convex, conic, and general nonlinear optimization. We discuss the theory, outline the algorithms, and comment on the applicability of this class of methods, which have revolutionized the field over the last twenty years.",
    "cited_by_count": 255,
    "openalex_id": "https://openalex.org/W2124488712",
    "type": "article"
  },
  {
    "title": "Theory, algorithms, and applications of level set methods for propagating interfaces",
    "doi": "https://doi.org/10.1017/s0962492900002671",
    "publication_date": "1996-01-01",
    "publication_year": 1996,
    "authors": "James A. Sethian",
    "corresponding_authors": "James A. Sethian",
    "abstract": "We review recent work on level set methods for following the evolution of complex interfaces. These techniques are based on solving initial value partial differential equations for level set functions, using techniques borrowed from hyperbolic conservation laws. Topological changes, corner and cusp development, and accurate determination of geometric properties such as curvature and normal direction are naturally obtained in this setting. The methodology results in robust, accurate, and efficient numerical algorithms for propagating interfaces in highly complex settings. We review the basic theory and approximations, describe a hierarchy of fast methods, including an extremely fast marching level set scheme for monotonically advancing fronts, based on a stationary formulation of the problem, and discuss extensions to multiple interfaces and triple points. Finally, we demonstrate the technique applied to a series of examples from geometry, material science and computer vision, including mean curvature flow, minimal surfaces, grid generation, fluid mechanics, combustion, image processing, computer vision, and etching, deposition and lithography in the microfabrication of electronic components.",
    "cited_by_count": 248,
    "openalex_id": "https://openalex.org/W2081820511",
    "type": "article"
  },
  {
    "title": "Computational high frequency wave propagation",
    "doi": "https://doi.org/10.1017/s0962492902000119",
    "publication_date": "2003-05-01",
    "publication_year": 2003,
    "authors": "Björn Engquist; Olof Runborg",
    "corresponding_authors": "",
    "abstract": "Numerical simulation of high frequency acoustic, elastic or electro-magnetic wave propagation is important in many applications. Recently the traditional techniques of ray tracing based on geometrical optics have been augmented by numerical procedures based on partial differential equations. Direct simulations of solutions to the eikonal equation have been used in seismology, and lately approximations of the Liouville or Vlasov equation formulations of geometrical optics have generated impressive results. There are basically two techniques that follow from this latter approach: one is wave front methods and the other moment methods. We shall develop these methods in some detail after a brief review of more traditional algorithms for simulating high frequency wave propagation.",
    "cited_by_count": 236,
    "openalex_id": "https://openalex.org/W2169501376",
    "type": "article"
  },
  {
    "title": "Numerical solution of multivariate polynomial systems by homotopy continuation methods",
    "doi": "https://doi.org/10.1017/s0962492900002749",
    "publication_date": "1997-01-01",
    "publication_year": 1997,
    "authors": "Tony Y. Li",
    "corresponding_authors": "Tony Y. Li",
    "abstract": "Let P ( x ) = 0 be a system of n polynomial equations in n unknowns. Denoting P = ( p 1 ,…, p n ), we want to find all isolated solutions of for x = ( x 1 ,…, x n ). This problem is very common in many fields of science and engineering, such as formula construction, geometric intersection problems, inverse kinematics, power flow problems with PQ-specified bases, computation of equilibrium states, etc. Elimination theory-based methods, most notably the Buchberger algorithm (Buchberger 1985) for constructing Gröbner bases, are the classical approach to solving (1.1), but their reliance on symbolic manipulation makes those methods seem somewhat unsuitable for all but small problems.",
    "cited_by_count": 222,
    "openalex_id": "https://openalex.org/W1985548249",
    "type": "article"
  },
  {
    "title": "Old and new convergence proofs for multigrid methods",
    "doi": "https://doi.org/10.1017/s0962492900002385",
    "publication_date": "1993-01-01",
    "publication_year": 1993,
    "authors": "Harry Yserentant",
    "corresponding_authors": "Harry Yserentant",
    "abstract": "Multigrid methods are the fastest known methods for the solution of the large systems of equations arising from the discretization of partial differential equations. For self-adjoint and coercive linear elliptic boundary value problems (with Laplace's equation and the equations of linear elasticity as two typical examples), the convergence theory reached a mature, if not its final state. The present article reviews old and new developments for this type of equation and describes the recent advances.",
    "cited_by_count": 220,
    "openalex_id": "https://openalex.org/W2153127767",
    "type": "article"
  },
  {
    "title": "Exact and approximate controllability for distributed parameter systems",
    "doi": "https://doi.org/10.1017/s0962492900002452",
    "publication_date": "1994-01-01",
    "publication_year": 1994,
    "authors": "Roland Glowinski; J. L. Lions",
    "corresponding_authors": "",
    "abstract": "We consider a system whose state is given by the solution y to a Partial Differential Equation (PDE) of evolution, and which contains control functions , denoted by v .",
    "cited_by_count": 219,
    "openalex_id": "https://openalex.org/W2112649070",
    "type": "article"
  },
  {
    "title": "Computation of pseudospectra",
    "doi": "https://doi.org/10.1017/s0962492900002932",
    "publication_date": "1999-01-01",
    "publication_year": 1999,
    "authors": "Lloyd N. Trefethen",
    "corresponding_authors": "Lloyd N. Trefethen",
    "abstract": "There is more to the computation of pseudospectra than the obvious algorithm of computing singular value decompositions on a grid and sending the results to a contour plotter. Other methods may be hundreds of times faster. The state of the art is reviewed, with emphasis on methods for dense matrices, and a Matlab code is given.",
    "cited_by_count": 214,
    "openalex_id": "https://openalex.org/W2167193748",
    "type": "article"
  },
  {
    "title": "Variationally consistent discretization schemes and numerical algorithms for contact problems",
    "doi": "https://doi.org/10.1017/s0962492911000079",
    "publication_date": "2011-04-28",
    "publication_year": 2011,
    "authors": "Barbara Wohlmuth",
    "corresponding_authors": "Barbara Wohlmuth",
    "abstract": "We consider variationally consistent discretization schemes for mechanical contact problems. Most of the results can also be applied to other variational inequalities, such as those for phase transition problems in porous media, for plasticity or for option pricing applications from finance. The starting point is to weakly incorporate the constraint into the setting and to reformulate the inequality in the displacement in terms of a saddle-point problem. Here, the Lagrange multiplier represents the surface forces, and the constraints are restricted to the boundary of the simulation domain. Having a uniform inf-sup bound, one can then establish optimal low-order a priori convergence rates for the discretization error in the primal and dual variables. In addition to the abstract framework of linear saddle-point theory, complementarity terms have to be taken into account. The resulting inequality system is solved by rewriting it equivalently by means of the non-linear complementarity function as a system of equations. Although it is not differentiable in the classical sense, semi-smooth Newton methods, yielding super-linear convergence rates, can be applied and easily implemented in terms of a primal–dual active set strategy. Quite often the solution of contact problems has a low regularity, and the efficiency of the approach can be improved by using adaptive refinement techniques. Different standard types, such as residual- and equilibrated-based a posteriori error estimators, can be designed based on the interpretation of the dual variable as Neumann boundary condition. For the fully dynamic setting it is of interest to apply energy-preserving time-integration schemes. However, the differential algebraic character of the system can result in high oscillations if standard methods are applied. A possible remedy is to modify the fully discretized system by a local redistribution of the mass. Numerical results in two and three dimensions illustrate the wide range of possible applications and show the performance of the space discretization scheme, non-linear solver, adaptive refinement process and time integration.",
    "cited_by_count": 203,
    "openalex_id": "https://openalex.org/W2314187005",
    "type": "article"
  },
  {
    "title": "Secrets of image denoising cuisine",
    "doi": "https://doi.org/10.1017/s0962492912000062",
    "publication_date": "2012-04-19",
    "publication_year": 2012,
    "authors": "Marc Lebrun; Miguel Colom; Antoni Buades; Jean‐Michel Morel",
    "corresponding_authors": "",
    "abstract": "Digital images are matrices of equally spaced pixels, each containing a photon count. This photon count is a stochastic process due to the quantum nature of light. It follows that all images are noisy. Ever since digital images have existed, numerical methods have been proposed to improve the signal-to-noise ratio. Such ‘denoising’ methods require a noise model and an image model. It is relatively easy to obtain a noise model. As will be explained in the present paper, it is even possible to estimate it from a single noisy image.",
    "cited_by_count": 201,
    "openalex_id": "https://openalex.org/W2068902206",
    "type": "article"
  },
  {
    "title": "Constructing cubature formulae: the science behind the art",
    "doi": "https://doi.org/10.1017/s0962492900002701",
    "publication_date": "1997-01-01",
    "publication_year": 1997,
    "authors": "Ronald Cools",
    "corresponding_authors": "Ronald Cools",
    "abstract": "In this paper we present a general, theoretical foundation for the construction of cubature formulae to approximate multivariate integrals. The focus is on cubature formulae that are exact for certain vector spaces of polynomials. Our main quality criteria are the algebraic and trigonometric degrees. The constructions using ideal theory and invariant theory are outlined. The known lower bounds for the number of points are surveyed and characterizations of minimal cubature formulae are given. We include references to all known minimal cubature formulae. Finally, some methods to construct cubature formulae illustrate the previously introduced concepts and theorems.",
    "cited_by_count": 200,
    "openalex_id": "https://openalex.org/W2160346753",
    "type": "article"
  },
  {
    "title": "Parallel numerical linear algebra",
    "doi": "https://doi.org/10.1017/s096249290000235x",
    "publication_date": "1993-01-01",
    "publication_year": 1993,
    "authors": "James Demmel; Michael T. Heath; H.A. van der Vorst",
    "corresponding_authors": "",
    "abstract": "We survey general techniques and open problems in numerical linear algebra on parallel architectures. We first discuss basic principles of paralled processing, describing the costs of basic operations on parallel machines, including general principles for constructing efficient algorithms. We illustrate these principles using current architectures and software systems, and by showing how one would implement matrix multiplication. Then, we present direct and iterative algorithms for solving linear systems of equations, linear least squares problems, the symmetric eigenvalue problem, the nonsymmetric eigenvalue problem, and the singular value decomposition. We consider dense, band and sparse matrices.",
    "cited_by_count": 192,
    "openalex_id": "https://openalex.org/W1980677368",
    "type": "article"
  },
  {
    "title": "Hierarchical bases and the finite element method",
    "doi": "https://doi.org/10.1017/s0962492900002610",
    "publication_date": "1996-01-01",
    "publication_year": 1996,
    "authors": "Randolph E. Bank",
    "corresponding_authors": "Randolph E. Bank",
    "abstract": "In this work we present a brief introduction to hierarchical bases, and the important part they play in contemporary finite element calculations. In particular, we examine their role in a posteriori error estimation, and in the formulation of iterative methods for solving the large sparse sets of linear equations arising from finite element discretization.",
    "cited_by_count": 191,
    "openalex_id": "https://openalex.org/W2163694039",
    "type": "article"
  },
  {
    "title": "Steady-state convection-diffusion problems",
    "doi": "https://doi.org/10.1017/s0962492904000261",
    "publication_date": "2005-04-19",
    "publication_year": 2005,
    "authors": "Martin Stynes",
    "corresponding_authors": "Martin Stynes",
    "abstract": "In convection-diffusion problems, transport processes dominate while diffusion effects are confined to a relatively small part of the domain. This state of affairs means that one cannot rely on the formal ellipticity of the differential operator to ensure the convergence of standard numerical algorithms. Thus new ideas and approaches are required. The survey begins by examining the asymptotic nature of solutions to stationary convection-diffusion problems. This provides a suitable framework for the understanding of these solutions and the difficulties that numerical techniques will face. Various numerical methods expressly designed for convection-diffusion problems are then presented and extensively discussed. These include finite difference and finite element methods and the use of special meshes.",
    "cited_by_count": 190,
    "openalex_id": "https://openalex.org/W2132719389",
    "type": "article"
  },
  {
    "title": "Fast direct solvers for integral equations in complex three-dimensional domains",
    "doi": "https://doi.org/10.1017/s0962492906410011",
    "publication_date": "2009-05-01",
    "publication_year": 2009,
    "authors": "Leslie Greengard; Denis Gueyffier; Per‐Gunnar Martinsson; Vladimir Rokhlin",
    "corresponding_authors": "",
    "abstract": "Methods for the solution of boundary integral equations have changed significantly during the last two decades. This is due, in part, to improvements in computer hardware, but more importantly, to the development of fast algorithms which scale linearly or nearly linearly with the number of degrees of freedom required. These methods are typically iterative, based on coupling fast matrix-vector multiplication routines with conjugate-gradient-type schemes. Here, we discuss methods that are currently under development for the fast, direct solution of boundary integral equations in three dimensions. After reviewing the mathematical foundations of such schemes, we illustrate their performance with some numerical examples, and discuss the potential impact of the overall approach in a variety of settings.",
    "cited_by_count": 183,
    "openalex_id": "https://openalex.org/W2125439985",
    "type": "article"
  },
  {
    "title": "Preconditioning",
    "doi": "https://doi.org/10.1017/s0962492915000021",
    "publication_date": "2015-04-27",
    "publication_year": 2015,
    "authors": "Andy Wathen",
    "corresponding_authors": "Andy Wathen",
    "abstract": "The computational solution of problems can be restricted by the availability of solution methods for linear(ized) systems of equations. In conjunction with iterative methods, preconditioning is often the vital component in enabling the solution of such systems when the dimension is large. We attempt a broad review of preconditioning methods.",
    "cited_by_count": 175,
    "openalex_id": "https://openalex.org/W4211094263",
    "type": "article"
  },
  {
    "title": "Mathematical and computational methods for semiclassical Schrödinger equations",
    "doi": "https://doi.org/10.1017/s0962492911000031",
    "publication_date": "2011-04-28",
    "publication_year": 2011,
    "authors": "Shi Jin; Peter A. Markowich; Christof Sparber",
    "corresponding_authors": "",
    "abstract": "We consider time-dependent (linear and nonlinear) Schrödinger equations in a semiclassical scaling. These equations form a canonical class of (nonlinear) dispersive models whose solutions exhibit high-frequency oscillations. The design of efficient numerical methods which produce an accurate approximation of the solutions, or at least of the associated physical observables, is a formidable mathematical challenge. In this article we shall review the basic analytical methods for dealing with such equations, including WKB asymptotics, Wigner measure techniques and Gaussian beams. Moreover, we shall give an overview of the current state of the art of numerical methods (most of which are based on the described analytical techniques) for the Schrödinger equation in the semiclassical regime.",
    "cited_by_count": 158,
    "openalex_id": "https://openalex.org/W2056979287",
    "type": "article"
  },
  {
    "title": "Asymptotic and numerical homogenization",
    "doi": "https://doi.org/10.1017/s0962492906360011",
    "publication_date": "2008-04-25",
    "publication_year": 2008,
    "authors": "B. Engquist; Panagiotis E. Souganidis",
    "corresponding_authors": "",
    "abstract": "Homogenization is an important mathematical framework for developing effective models of differential equations with oscillations. We include in the presentation techniques for deriving effective equations, a brief discussion on analysis of related limit processes and numerical methods that are based on homogenization principles. We concentrate on first- and second-order partial differential equations and present results concerning both periodic and random media for linear as well as nonlinear problems. In the numerical sections, we comment on computations of multi-scale problems in general and then focus on projection-based numerical homogenization and the heterogeneous multi-scale method.",
    "cited_by_count": 148,
    "openalex_id": "https://openalex.org/W2125887644",
    "type": "article"
  },
  {
    "title": "Topics in structure-preserving discretization",
    "doi": "https://doi.org/10.1017/s096249291100002x",
    "publication_date": "2011-04-28",
    "publication_year": 2011,
    "authors": "Snorre H. Christiansen; Hans Munthe–Kaas; Brynjulf Owren",
    "corresponding_authors": "",
    "abstract": "We develop the theory of mixed finite elements in terms of special inverse systems of complexes of differential forms, defined over cellular complexes. Inclusion of cells corresponds to pullback of forms. The theory covers for instance composite piecewise polynomial finite elements of variable order over polyhedral grids. Under natural algebraic and metric conditions, interpolators and smoothers are constructed, which commute with the exterior derivative and whose product is uniformly stable in Lebesgue spaces. As a consequence we obtain not only eigenpair approximation for the Hodge-Laplacian in mixed form, but also variants of Sobolev injections and translation estimates adapted to variational discretizations.",
    "cited_by_count": 136,
    "openalex_id": "https://openalex.org/W3099687355",
    "type": "article"
  },
  {
    "title": "Communication lower bounds and optimal algorithms for numerical linear algebra",
    "doi": "https://doi.org/10.1017/s0962492914000038",
    "publication_date": "2014-05-01",
    "publication_year": 2014,
    "authors": "Grey Ballard; Erin Carson; James Demmel; Mark Frederick Hoemmen; Nicholas Knight; Oded Schwartz",
    "corresponding_authors": "",
    "abstract": "The traditional metric for the efficiency of a numerical algorithm has been the number of arithmetic operations it performs. Technological trends have long been reducing the time to perform an arithmetic operation, so it is no longer the bottleneck in many algorithms; rather, communication , or moving data, is the bottleneck. This motivates us to seek algorithms that move as little data as possible, either between levels of a memory hierarchy or between parallel processors over a network. In this paper we summarize recent progress in three aspects of this problem. First we describe lower bounds on communication. Some of these generalize known lower bounds for dense classical (O(n 3 )) matrix multiplication to all direct methods of linear algebra, to sequential and parallel algorithms, and to dense and sparse matrices. We also present lower bounds for Strassen-like algorithms, and for iterative methods, in particular Krylov subspace methods applied to sparse matrices. Second, we compare these lower bounds to widely used versions of these algorithms, and note that these widely used algorithms usually communicate asymptotically more than is necessary. Third, we identify or invent new algorithms for most linear algebra problems that do attain these lower bounds, and demonstrate large speed-ups in theory and practice.",
    "cited_by_count": 130,
    "openalex_id": "https://openalex.org/W2099611016",
    "type": "article"
  },
  {
    "title": "Atomistic-to-continuum coupling",
    "doi": "https://doi.org/10.1017/s0962492913000068",
    "publication_date": "2013-04-02",
    "publication_year": 2013,
    "authors": "Mitchell Luskin; Christoph Ortner",
    "corresponding_authors": "",
    "abstract": "Atomistic-to-continuum (a/c) coupling methods are a class of computational multiscale schemes that combine the accuracy of atomistic models with the efficiency of continuum elasticity. They are increasingly being utilized in materials science to study the fundamental mechanisms of material failure such as crack propagation and plasticity, which are governed by the interaction between crystal defects and long-range elastic fields. In the construction of a/c coupling methods, various approximation errors are committed. A rigorous numerical analysis approach that classifies and quantifies these errors can give confidence in the simulation results, as well as enable optimization of the numerical methods for accuracy and computational cost. In this article, we present such a numerical analysis framework, which is inspired by recent research activity.",
    "cited_by_count": 116,
    "openalex_id": "https://openalex.org/W2053087016",
    "type": "article"
  },
  {
    "title": "Numerical analysis of hemivariational inequalities in contact mechanics",
    "doi": "https://doi.org/10.1017/s0962492919000023",
    "publication_date": "2019-05-01",
    "publication_year": 2019,
    "authors": "Weimin Han; Mircea Sofonea",
    "corresponding_authors": "",
    "abstract": "Contact phenomena arise in a variety of industrial process and engineering applications. For this reason, contact mechanics has attracted substantial attention from research communities. Mathematical problems from contact mechanics have been studied extensively for over half a century. Effort was initially focused on variational inequality formulations, and in the past ten years considerable effort has been devoted to contact problems in the form of hemivariational inequalities. This article surveys recent development in studies of hemivariational inequalities arising in contact mechanics. We focus on contact problems with elastic and viscoelastic materials, in the framework of linearized strain theory, with a particular emphasis on their numerical analysis. We begin by introducing three representative mathematical models which describe the contact between a deformable body in contact with a foundation, in static, history-dependent and dynamic cases. In weak formulations, the models we consider lead to various forms of hemivariational inequalities in which the unknown is either the displacement or the velocity field. Based on these examples, we introduce and study three abstract hemivariational inequalities for which we present existence and uniqueness results, together with convergence analysis and error estimates for numerical solutions. The results on the abstract hemivariational inequalities are general and can be applied to the study of a variety of problems in contact mechanics; in particular, they are applied to the three representative mathematical models. We present numerical simulation results giving numerical evidence on the theoretically predicted optimal convergence order; we also provide mechanical interpretations of simulation results.",
    "cited_by_count": 116,
    "openalex_id": "https://openalex.org/W2950328413",
    "type": "article"
  },
  {
    "title": "Fit without fear: remarkable mathematical phenomena of deep learning through the prism of interpolation",
    "doi": "https://doi.org/10.1017/s0962492921000039",
    "publication_date": "2021-05-01",
    "publication_year": 2021,
    "authors": "Mikhail A. Belkin",
    "corresponding_authors": "Mikhail A. Belkin",
    "abstract": "In the past decade the mathematical theory of machine learning has lagged far behind the triumphs of deep neural networks on practical challenges. However, the gap between theory and practice is gradually starting to close. In this paper I will attempt to assemble some pieces of the remarkable and still incomplete mathematical mosaic emerging from the efforts to understand the foundations of deep learning. The two key themes will be interpolation and its sibling over-parametrization. Interpolation corresponds to fitting data, even noisy data, exactly. Over-parametrization enables interpolation and provides flexibility to select a suitable interpolating model. As we will see, just as a physical prism separates colours mixed within a ray of light, the figurative prism of interpolation helps to disentangle generalization and optimization properties within the complex picture of modern machine learning. This article is written in the belief and hope that clearer understanding of these issues will bring us a step closer towards a general theory of deep learning and machine learning.",
    "cited_by_count": 109,
    "openalex_id": "https://openalex.org/W3197744105",
    "type": "article"
  },
  {
    "title": "Learning physics-based models from data: perspectives from inverse problems and model reduction",
    "doi": "https://doi.org/10.1017/s0962492921000064",
    "publication_date": "2021-05-01",
    "publication_year": 2021,
    "authors": "Omar Ghattas; Karen Willcox",
    "corresponding_authors": "",
    "abstract": "This article addresses the inference of physics models from data, from the perspectives of inverse problems and model reduction. These fields develop formulations that integrate data into physics-based models while exploiting the fact that many mathematical models of natural and engineered systems exhibit an intrinsically low-dimensional solution manifold. In inverse problems, we seek to infer uncertain components of the inputs from observations of the outputs, while in model reduction we seek low-dimensional models that explicitly capture the salient features of the input–output map through approximation in a low-dimensional subspace. In both cases, the result is a predictive model that reflects data-driven learning yet deeply embeds the underlying physics, and thus can be used for design, control and decision-making, often with quantified uncertainties. We highlight recent developments in scalable and efficient algorithms for inverse problems and model reduction governed by large-scale models in the form of partial differential equations. Several illustrative applications to large-scale complex problems across different domains of science and engineering are provided.",
    "cited_by_count": 108,
    "openalex_id": "https://openalex.org/W3194724611",
    "type": "article"
  },
  {
    "title": "Numerical methods for nonlinear equations",
    "doi": "https://doi.org/10.1017/s0962492917000113",
    "publication_date": "2018-05-01",
    "publication_year": 2018,
    "authors": "C. T. Kelley",
    "corresponding_authors": "C. T. Kelley",
    "abstract": "This article is about numerical methods for the solution of nonlinear equations. We consider both the fixed-point form $\\mathbf{x}=\\mathbf{G}(\\mathbf{x})$ and the equations form $\\mathbf{F}(\\mathbf{x})=0$ and explain why both versions are necessary to understand the solvers. We include the classical methods to make the presentation complete and discuss less familiar topics such as Anderson acceleration, semi-smooth Newton’s method, and pseudo-arclength and pseudo-transient continuation methods.",
    "cited_by_count": 99,
    "openalex_id": "https://openalex.org/W2802921497",
    "type": "article"
  },
  {
    "title": "On the computation of measure-valued solutions",
    "doi": "https://doi.org/10.1017/s0962492916000088",
    "publication_date": "2016-05-01",
    "publication_year": 2016,
    "authors": "Ulrik Skre Fjordholm; Siddhartha Mishra; Eitan Tadmor",
    "corresponding_authors": "",
    "abstract": "A standard paradigm for the existence of solutions in fluid dynamics is based on the construction of sequences of approximate solutions or approximate minimizers. This approach faces serious obstacles, most notably in multi-dimensional problems, where the persistence of oscillations at ever finer scales prevents compactness. Indeed, these oscillations are an indication, consistent with recent theoretical results, of the possible lack of existence/uniqueness of solutions within the standard framework of integrable functions. It is in this context that Young measures – parametrized probability measures which can describe the limits of such oscillatory sequences – offer the more general paradigm of measure-valued solutions for these problems. We present viable numerical algorithms to compute approximate measure-valued solutions, based on the realization of approximate measures as laws of Monte Carlo sampled random fields. We prove convergence of these algorithms to measure-valued solutions for the equations of compressible and incompressible inviscid fluid dynamics, and present a large number of numerical experiments which provide convincing evidence for the viability of the new paradigm. We also discuss the use of these algorithms, and their extensions, in uncertainty quantification and contexts other than fluid dynamics, such as non-convex variational problems in materials science.",
    "cited_by_count": 96,
    "openalex_id": "https://openalex.org/W2399363852",
    "type": "article"
  },
  {
    "title": "Finite-volume schemes for shallow-water equations",
    "doi": "https://doi.org/10.1017/s0962492918000028",
    "publication_date": "2018-05-01",
    "publication_year": 2018,
    "authors": "Alexander Kurganov",
    "corresponding_authors": "Alexander Kurganov",
    "abstract": "Shallow-water equations are widely used to model water flow in rivers, lakes, reservoirs, coastal areas, and other situations in which the water depth is much smaller than the horizontal length scale of motion. The classical shallow-water equations, the Saint-Venant system, were originally proposed about 150 years ago and still are used in a variety of applications. For many practical purposes, it is extremely important to have an accurate, efficient and robust numerical solver for the Saint-Venant system and related models. As their solutions are typically non-smooth and even discontinuous, finite-volume schemes are among the most popular tools. In this paper, we review such schemes and focus on one of the simplest (yet highly accurate and robust) methods: central-upwind schemes. These schemes belong to the family of Godunov-type Riemann-problem-solver-free central schemes, but incorporate some upwinding information about the local speeds of propagation, which helps to reduce an excessive amount of numerical diffusion typically present in classical (staggered) non-oscillatory central schemes. Besides the classical one- and two-dimensional Saint-Venant systems, we will consider the shallow-water equations with friction terms, models with moving bottom topography, the two-layer shallow-water system as well as general non-conservative hyperbolic systems.",
    "cited_by_count": 94,
    "openalex_id": "https://openalex.org/W2799904623",
    "type": "article"
  },
  {
    "title": "The numerics of phase retrieval",
    "doi": "https://doi.org/10.1017/s0962492920000069",
    "publication_date": "2020-05-01",
    "publication_year": 2020,
    "authors": "Albert Fannjiang; Thomas Strohmer",
    "corresponding_authors": "",
    "abstract": "Phase retrieval, i.e., the problem of recovering a function from the squared magnitude of its Fourier transform, arises in many applications such as X-ray crystallography, diffraction imaging, optics, quantum mechanics, and astronomy. This problem has confounded engineers, physicists, and mathematicians for many decades. Recently, phase retrieval has seen a resurgence in research activity, ignited by new imaging modalities and novel mathematical concepts. As our scientific experiments produce larger and larger datasets and we aim for faster and faster throughput, it becomes increasingly important to study the involved numerical algorithms in a systematic and principled manner. Indeed, the last decade has witnessed a surge in the systematic study of computational algorithms for phase retrieval. In this paper we will review these recent advances from a numerical viewpoint.",
    "cited_by_count": 88,
    "openalex_id": "https://openalex.org/W3106678933",
    "type": "article"
  },
  {
    "title": "Mixed precision algorithms in numerical linear algebra",
    "doi": "https://doi.org/10.1017/s0962492922000022",
    "publication_date": "2022-05-01",
    "publication_year": 2022,
    "authors": "Nicholas J. Higham; Théo Mary",
    "corresponding_authors": "",
    "abstract": "Today’s floating-point arithmetic landscape is broader than ever. While scientific computing has traditionally used single precision and double precision floating-point arithmetics, half precision is increasingly available in hardware and quadruple precision is supported in software. Lower precision arithmetic brings increased speed and reduced communication and energy costs, but it produces results of correspondingly low accuracy. Higher precisions are more expensive but can potentially provide great benefits, even if used sparingly. A variety of mixed precision algorithms have been developed that combine the superior performance of lower precisions with the better accuracy of higher precisions. Some of these algorithms aim to provide results of the same quality as algorithms running in a fixed precision but at a much lower cost; others use a little higher precision to improve the accuracy of an algorithm. This survey treats a broad range of mixed precision algorithms in numerical linear algebra, both direct and iterative, for problems including matrix multiplication, matrix factorization, linear systems, least squares, eigenvalue decomposition and singular value decomposition. We identify key algorithmic ideas, such as iterative refinement, adapting the precision to the data, and exploiting mixed precision block fused multiply–add operations. We also describe the possible performance benefits and explain what is known about the numerical stability of the algorithms. This survey should be useful to a wide community of researchers and practitioners who wish to develop or benefit from mixed precision numerical linear algebra algorithms.",
    "cited_by_count": 75,
    "openalex_id": "https://openalex.org/W4283270874",
    "type": "article"
  },
  {
    "title": "Numerical homogenization beyond scale separation",
    "doi": "https://doi.org/10.1017/s0962492921000015",
    "publication_date": "2021-05-01",
    "publication_year": 2021,
    "authors": "Robert Altmann; Patrick Henning; Daniel Peterseim",
    "corresponding_authors": "",
    "abstract": "Numerical homogenization is a methodology for the computational solution of multiscale partial differential equations. It aims at reducing complex large-scale problems to simplified numerical models valid on some target scale of interest, thereby accounting for the impact of features on smaller scales that are otherwise not resolved. While constructive approaches in the mathematical theory of homogenization are restricted to problems with a clear scale separation, modern numerical homogenization methods can accurately handle problems with a continuum of scales. This paper reviews such approaches embedded in a historical context and provides a unified variational framework for their design and numerical analysis. Apart from prototypical elliptic model problems, the class of partial differential equations covered here includes wave scattering in heterogeneous media and serves as a template for more general multi-physics problems.",
    "cited_by_count": 71,
    "openalex_id": "https://openalex.org/W3198272795",
    "type": "article"
  },
  {
    "title": "Reduced basis methods for time-dependent problems",
    "doi": "https://doi.org/10.1017/s0962492922000058",
    "publication_date": "2022-05-01",
    "publication_year": 2022,
    "authors": "Jan S. Hesthaven; Cecilia Pagliantini; Gianluigi Rozza",
    "corresponding_authors": "",
    "abstract": "Numerical simulation of parametrized differential equations is of crucial importance in the study of real-world phenomena in applied science and engineering. Computational methods for real-time and many-query simulation of such problems often require prohibitively high computational costs to achieve sufficiently accurate numerical solutions. During the last few decades, model order reduction has proved successful in providing low-complexity high-fidelity surrogate models that allow rapid and accurate simulations under parameter variation, thus enabling the numerical simulation of increasingly complex problems. However, many challenges remain to secure the robustness and efficiency needed for the numerical simulation of nonlinear time-dependent problems. The purpose of this article is to survey the state of the art of reduced basis methods for time-dependent problems and draw together recent advances in three main directions. First, we discuss structure-preserving reduced order models designed to retain key physical properties of the continuous problem. Second, we survey localized and adaptive methods based on nonlinear approximations of the solution space. Finally, we consider data-driven techniques based on non-intrusive reduced order models in which an approximation of the map between parameter space and coefficients of the reduced basis is learned. Within each class of methods, we describe different approaches and provide a comparative discussion that lends insights to advantages, disadvantages and potential open questions.",
    "cited_by_count": 71,
    "openalex_id": "https://openalex.org/W4281695078",
    "type": "article"
  },
  {
    "title": "Asymptotic-preserving schemes for multiscale physical problems",
    "doi": "https://doi.org/10.1017/s0962492922000010",
    "publication_date": "2022-05-01",
    "publication_year": 2022,
    "authors": "Shi Jin",
    "corresponding_authors": "Shi Jin",
    "abstract": "We present the asymptotic transitions from microscopic to macroscopic physics, their computational challenges and the asymptotic-preserving (AP) strategies to compute multiscale physical problems efficiently. Specifically, we will first study the asymptotic transition from quantum to classical mechanics, from classical mechanics to kinetic theory, and then from kinetic theory to hydrodynamics. We then review some representative AP schemes that mimic these asymptotic transitions at the discrete level, and hence can be used crossing scales and, in particular, capture the macroscopic behaviour without resolving the microscopic physical scale numerically.",
    "cited_by_count": 52,
    "openalex_id": "https://openalex.org/W4200633982",
    "type": "article"
  },
  {
    "title": "The virtual element method",
    "doi": "https://doi.org/10.1017/s0962492922000095",
    "publication_date": "2023-05-01",
    "publication_year": 2023,
    "authors": "L. Beirão da Veiga; Franco Brezzi; L. D. Marini; A. Russo",
    "corresponding_authors": "",
    "abstract": "The present review paper has several objectives. Its primary aim is to give an idea of the general features of virtual element methods (VEMs), which were introduced about a decade ago in the field of numerical methods for partial differential equations, in order to allow decompositions of the computational domain into polygons or polyhedra of a very general shape. Nonetheless, the paper is also addressed to readers who have already heard (and possibly read) about VEMs and are interested in gaining more precise information, in particular concerning their application in specific subfields such as ${C}^1$ -approximations of plate bending problems or approximations to problems in solid and fluid mechanics.",
    "cited_by_count": 33,
    "openalex_id": "https://openalex.org/W4376137479",
    "type": "article"
  },
  {
    "title": "Adaptive finite element methods",
    "doi": "https://doi.org/10.1017/s0962492924000011",
    "publication_date": "2024-07-01",
    "publication_year": 2024,
    "authors": "Andrea Bonito; Claudio Canuto; Ricardo H. Nochetto; Andreas Veeser",
    "corresponding_authors": "",
    "abstract": "This is a survey of the theory of adaptive finite element methods (AFEMs), which are fundamental to modern computational science and engineering but whose mathematical assessment is a formidable challenge. We present a self-contained and up-to-date discussion of AFEMs for linear second-order elliptic PDEs and dimension d &gt; 1 , with emphasis on foundational issues. After a brief review of functional analysis and basic finite element theory, including piecewise polynomial approximation in graded meshes, we present the core material for coercive problems. We start with a novel a posteriori error analysis applicable to rough data, which delivers estimators fully equivalent to the solution error. They are used in the design and study of three AFEMs depending on the structure of data. We prove linear convergence of these algorithms and rate-optimality provided the solution and data belong to suitable approximation classes. We also address the relation between approximation and regularity classes. We finally extend this theory to discontinuous Galerkin methods as prototypes of non-conforming AFEMs, and beyond coercive problems to inf-sup stable AFEMs.",
    "cited_by_count": 26,
    "openalex_id": "https://openalex.org/W4402230359",
    "type": "article"
  },
  {
    "title": "Numerical analysis of physics-informed neural networks and related models in physics-informed machine learning",
    "doi": "https://doi.org/10.1017/s0962492923000089",
    "publication_date": "2024-07-01",
    "publication_year": 2024,
    "authors": "Tim De Ryck; Siddhartha Mishra",
    "corresponding_authors": "",
    "abstract": "Physics-informed neural networks (PINNs) and their variants have been very popular in recent years as algorithms for the numerical simulation of both forward and inverse problems for partial differential equations. This article aims to provide a comprehensive review of currently available results on the numerical analysis of PINNs and related models that constitute the backbone of physics-informed machine learning. We provide a unified framework in which analysis of the various components of the error incurred by PINNs in approximating PDEs can be effectively carried out. We present a detailed review of available results on approximation, generalization and training errors and their behaviour with respect to the type of the PDE and the dimension of the underlying domain. In particular, we elucidate the role of the regularity of the solutions and their stability to perturbations in the error analysis. Numerical results are also presented to illustrate the theory. We identify training errors as a key bottleneck which can adversely affect the overall performance of various models in physics-informed machine learning.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W4402234893",
    "type": "article"
  },
  {
    "title": "Complexity theory and numerical analysis",
    "doi": "https://doi.org/10.1017/s0962492900002774",
    "publication_date": "1997-01-01",
    "publication_year": 1997,
    "authors": "Steve Smale",
    "corresponding_authors": "Steve Smale",
    "abstract": "Complexity theory of numerical analysis is the study of the number of arithmetic operations required to pass from the input to the output of a numerical problem.",
    "cited_by_count": 181,
    "openalex_id": "https://openalex.org/W2140137938",
    "type": "article"
  },
  {
    "title": "On the computation of crystalline microstructure",
    "doi": "https://doi.org/10.1017/s0962492900002658",
    "publication_date": "1996-01-01",
    "publication_year": 1996,
    "authors": "Mitchell Luskin",
    "corresponding_authors": "Mitchell Luskin",
    "abstract": "Microstructure is a feature of crystals with multiple symmetry-related energy-minimizing states. Continuum models have been developed explaining microstructure as the mixture of these symmetry-related states on a fine scale to minimize energy. This article is a review of numerical methods and the numerical analysis for the computation of crystalline microstructure.",
    "cited_by_count": 180,
    "openalex_id": "https://openalex.org/W2070108649",
    "type": "article"
  },
  {
    "title": "Eigenvalue optimization",
    "doi": "https://doi.org/10.1017/s0962492900002646",
    "publication_date": "1996-01-01",
    "publication_year": 1996,
    "authors": "Adrian S. Lewis; Michael L. Overton",
    "corresponding_authors": "",
    "abstract": "Optimization problems involving eigenvalues arise in many different mathematical disciplines. This article is divided into two parts. Part I gives a historical account of the development of the field. We discuss various applications that have been especially influential, from structural analysis to combinatorial optimization, and we survey algorithmic developments, including the recent advance of interior-point methods for a specific problem class: semidefinite programming. In Part II we primarily address optimization of convex functions of eigenvalues of symmetric matrices subject to linear constraints. We derive a fairly complete mathematical theory, some of it classical and some of it new. Using the elegant language of conjugate duality theory, we highlight the parallels between the analysis of invariant matrix norms and weakly invariant convex matrix functions. We then restrict our attention further to linear and semidefinite programming, emphasizing the parallel duality theory and comparing primal-dual interior-point methods for the two problem classes. The final section presents some apparently new variational results about eigenvalues of nonsymmetric matrices, unifying known characterizations of the spectral abscissa (related to Lyapunov theory) and the spectral radius (as an infimum of matrix norms).",
    "cited_by_count": 180,
    "openalex_id": "https://openalex.org/W4253016148",
    "type": "article"
  },
  {
    "title": "Orthogonal polynomials: applications and computation",
    "doi": "https://doi.org/10.1017/s0962492900002622",
    "publication_date": "1996-01-01",
    "publication_year": 1996,
    "authors": "Walter Gautschi",
    "corresponding_authors": "Walter Gautschi",
    "abstract": "We give examples of problem areas in interpolation, approximation, and quadrature, that call for orthogonal polynomials not of the classical kind. We then discuss numerical methods of computing the respective Gauss-type quadrature rules and orthogonal polynomials. The basic task is to compute the coefficients in the three-term recurrence relation for the orthogonal polynomials. This can be done by methods relying either on moment information or on discretization procedures. The effect on the recurrence coefficients of multiplying the weight function by a rational function is also discussed. Similar methods are applicable to computing Sobolev orthogonal polynomials, although their recurrence relations are more complicated. The paper concludes with a brief account of available software.",
    "cited_by_count": 161,
    "openalex_id": "https://openalex.org/W2041634741",
    "type": "article"
  },
  {
    "title": "The Lanczos and conjugate gradient algorithms in finite precision arithmetic",
    "doi": "https://doi.org/10.1017/s096249290626001x",
    "publication_date": "2006-05-01",
    "publication_year": 2006,
    "authors": "Gérard Meurant; Zdeněk Strakoš",
    "corresponding_authors": "",
    "abstract": "The Lanczos and conjugate gradient algorithms were introduced more than five decades ago as tools for numerical computation of dominant eigenvalues of symmetric matrices and for solving linear algebraic systems with symmetric positive definite matrices, respectively. Because of their fundamental relationship with the theory of orthogonal polynomials and Gauss quadrature of the Riemann-Stieltjes integral, the Lanczos and conjugate gradient algorithms represent very interesting general mathematical objects, with highly nonlinear properties which can be conveniently translated from algebraic language into the language of mathematical analysis, and vice versa . The algorithms are also very interesting numerically, since their numerical behaviour can be explained by an elegant mathematical theory, and the interplay between analysis and algebra is useful there too. Motivated by this view, the present contribution wishes to pay a tribute to those who have made an understanding of the Lanczos and conjugate gradient algorithms possible through their pioneering work, and to review recent solutions of several open problems that have also contributed to knowledge of the subject.",
    "cited_by_count": 147,
    "openalex_id": "https://openalex.org/W2125426869",
    "type": "article"
  },
  {
    "title": "A review of pseudospectral methods for solving partial differential equations",
    "doi": "https://doi.org/10.1017/s0962492900002440",
    "publication_date": "1994-01-01",
    "publication_year": 1994,
    "authors": "Bengt Fornberg; D. M. Sloan",
    "corresponding_authors": "",
    "abstract": "Finite Difference (FD) methods approximate derivatives of a function by local arguments (such as d u ( x ) / d x ≈ ( u ( x + h ) − u ( x − h ))/2 h , where h is a small grid spacing) – these methods are typically designed to be exact for polynomials of low orders. This approach is very reasonable: since the derivative is a local property of a function, it makes little sense (and is costly) to invoke many function values far away from the point of interest.",
    "cited_by_count": 146,
    "openalex_id": "https://openalex.org/W2090043357",
    "type": "review"
  },
  {
    "title": "Numerical solution of highly oscillatory ordinary differential equations",
    "doi": "https://doi.org/10.1017/s0962492900002750",
    "publication_date": "1997-01-01",
    "publication_year": 1997,
    "authors": "Linda Petzold; Laurent O. Jay; Jeng Yen",
    "corresponding_authors": "",
    "abstract": "One of the most difficult problems in the numerical solution of ordinary differential equations (ODEs) and in differential-algebraic equations (DAEs) is the development of methods for dealing with highly oscillatory systems. These types of systems arise, for example, in vehicle simulation when modelling the suspension system or tyres, in models for contact and impact, in flexible body simulation from vibrations in the structural model, in molecular dynamics, in orbital mechanics, and in circuit simulation. Standard numerical methods can require a huge number of time-steps to track the oscillations, and even with small stepsizes they can alter the dynamics, unless the method is chosen very carefully.",
    "cited_by_count": 143,
    "openalex_id": "https://openalex.org/W2037721359",
    "type": "article"
  },
  {
    "title": "Numerical methods for large-scale nonlinear optimization",
    "doi": "https://doi.org/10.1017/s0962492904000248",
    "publication_date": "2005-04-19",
    "publication_year": 2005,
    "authors": "Nicholas I. M. Gould; Dominique Orban; Philippe L. Toint",
    "corresponding_authors": "",
    "abstract": "Recent developments in numerical methods for solving large differentiable nonlinear optimization problems are reviewed. State-of-the-art algorithms for solving unconstrained, bound-constrained, linearly constrained and non-linearly constrained problems are discussed. As well as important conceptual advances and theoretical aspects, emphasis is also placed on more practical issues, such as software availability.",
    "cited_by_count": 143,
    "openalex_id": "https://openalex.org/W2150116987",
    "type": "article"
  },
  {
    "title": "Numerical methods for large eigenvalue problems",
    "doi": "https://doi.org/10.1017/s0962492902000089",
    "publication_date": "2002-01-01",
    "publication_year": 2002,
    "authors": "Danny C. Sorensen",
    "corresponding_authors": "Danny C. Sorensen",
    "abstract": "Over the past decade considerable progress has been made towards the numerical solution of large-scale eigenvalue problems, particularly for nonsymmetric matrices. Krylov methods and variants of subspace iteration have been improved to the point that problems of the order of several million variables can be solved. The methods and software that have led to these advances are surveyed.",
    "cited_by_count": 136,
    "openalex_id": "https://openalex.org/W2110458413",
    "type": "article"
  },
  {
    "title": "Numerical methods for differential algebraic equations",
    "doi": "https://doi.org/10.1017/s0962492900002269",
    "publication_date": "1992-01-01",
    "publication_year": 1992,
    "authors": "Roswitha März",
    "corresponding_authors": "Roswitha März",
    "abstract": "Differential algebraic equations (DAE) are special implicit ordinary differential equations (ODE) where the partial Jacobian f ′ y ( y, x, t ) is singular for all values of its arguments.",
    "cited_by_count": 136,
    "openalex_id": "https://openalex.org/W2153957100",
    "type": "article"
  },
  {
    "title": "General linear methods",
    "doi": "https://doi.org/10.1017/s0962492906220014",
    "publication_date": "2006-05-01",
    "publication_year": 2006,
    "authors": "J. C. Butcher",
    "corresponding_authors": "J. C. Butcher",
    "abstract": "General linear methods, as multistage multivalue methods, are the natural generalizations of linear multistep and Runge-Kutta methods. This survey contains a discussion of the traditional methods and a motivation for the general linear type of generalization. The new methods are introduced in terms of their formulation and the basic properties of consistency, stability and convergence. The order of general linear methods has to be looked at from a new point of view and it is shown how to use an algebraic structure (equivalent to B-series) to express conditions for a given order. Linear and non-linear stability for the new methods brings the theories for the classical methods into a comprehensive formulation and known results are outlined. Recently a number of subfamilies have been introduced and some of these are considered in detail. This applies in particular to methods with the property known as ‘inherent Runge-Kutta stability’. These seem to have prospects of yielding useful and efficient methods, and some progress towards their practical implementation is outlined. Finally, the relationship between stability functions and order of methods is discussed in a setting wide enough to include general linear methods as well as multiderivative methods, such as Obreshkov methods. The classical barriers due to Ehle, Daniel-Moore and Dahlquist (second barrier) all fit into a common pattern and these are explored in a general setting.",
    "cited_by_count": 129,
    "openalex_id": "https://openalex.org/W2050296550",
    "type": "article"
  },
  {
    "title": "Semi-analytic geometry with R-functions",
    "doi": "https://doi.org/10.1017/s096249290631001x",
    "publication_date": "2007-04-24",
    "publication_year": 2007,
    "authors": "Vadim Shapiro",
    "corresponding_authors": "Vadim Shapiro",
    "abstract": "V. L. Rvachev called R-functions ‘logically charged functions’ because they encode complete logical information within the standard setting of real analysis. He invented them in the 1960s as a means for unifying logic, geometry, and analysis within a common computational framework – in an effort to develop a new computationally effective language for modelling and solving boundary value problems. Over the last forty years, R-functions have been accepted as a valuable tool in computer graphics, geometric modelling, computational physics, and in many areas of engineering design, analysis, and optimization. Yet, many elements of the theory of R-functions continue to be rediscovered in different application areas and special situations. The purpose of this survey is to expose the key ideas and concepts behind the theory of R-functions, explain the utility of R-functions in a broad range of applications, and to discuss selected algorithmic issues arising in connection with their use.",
    "cited_by_count": 128,
    "openalex_id": "https://openalex.org/W2114952079",
    "type": "article"
  },
  {
    "title": "Modern statistical estimation via oracle inequalities",
    "doi": "https://doi.org/10.1017/s0962492906230010",
    "publication_date": "2006-05-01",
    "publication_year": 2006,
    "authors": "Emmanuel J. Candès",
    "corresponding_authors": "Emmanuel J. Candès",
    "abstract": "A number of fundamental results in modern statistical theory involve thresholding estimators. This survey paper aims at reconstructing the history of how thresholding rules came to be popular in statistics and describing, in a not overly technical way, the domain of their application. Two notions play a fundamental role in our narrative: sparsity and oracle inequalities. Sparsity is a property of the object to estimate, which seems to be characteristic of many modern problems, in statistics as well as applied mathematics and theoretical computer science, to name a few. ‘Oracle inequalities’ are a powerful decision-theoretic tool which has served to understand the optimality of thresholding rules, but which has many other potential applications, some of which we will discuss. Our story is also the story of the dialogue between statistics and applied harmonic analysis. Starting with the work of Wiener, we will see that certain representations emerge as being optimal for estimation. A leitmotif throughout our exposition is that efficient representations lead to efficient estimation.",
    "cited_by_count": 127,
    "openalex_id": "https://openalex.org/W2032013306",
    "type": "article"
  },
  {
    "title": "Greedy approximation",
    "doi": "https://doi.org/10.1017/s0962492906380014",
    "publication_date": "2008-04-25",
    "publication_year": 2008,
    "authors": "Vladimir Temlyakov",
    "corresponding_authors": "Vladimir Temlyakov",
    "abstract": "In this survey we discuss properties of specific methods of approximation that belong to a family of greedy approximation methods (greedy algorithms). It is now well understood that we need to study nonlinear sparse representations in order to significantly increase our ability to process (compress, denoise, etc. ) large data sets. Sparse representations of a function are not only a powerful analytic tool but they are utilized in many application areas such as image/signal processing and numerical computation. The key to finding sparse representations is the concept of m -term approximation of the target function by the elements of a given system of functions (dictionary). The fundamental question is how to construct good methods (algorithms) of approximation. Recent results have established that greedy-type algorithms are suitable methods of nonlinear approximation in both m -term approximation with regard to bases, and m -term approximation with regard to redundant systems. It turns out that there is one fundamental principle that allows us to build good algorithms, both for arbitrary redundant systems and for very simple well-structured bases, such as the Haar basis. This principle is the use of a greedy step in searching for a new element to be added to a given m -term approximant.",
    "cited_by_count": 127,
    "openalex_id": "https://openalex.org/W4211080438",
    "type": "article"
  },
  {
    "title": "Formalization and computational aspects of image analysis",
    "doi": "https://doi.org/10.1017/s0962492900002415",
    "publication_date": "1994-01-01",
    "publication_year": 1994,
    "authors": "Luis Álvarez; Jean‐Michel Morel",
    "corresponding_authors": "",
    "abstract": "In this article we shall present a unified and axiomatized view of several theories and algorithms of image multiscale analysis (and low level vision) which have been developed in the past twenty years. We shall show that under reasonable invariance and assumptions, all image (and shape) analyses can be reduced to a single partial differential equation. In the same way, movie analysis leads to a single parabolic differential equation. We discuss some applications to image segmentation and movie restoration. The experiments show how accurate and invariant the numerical schemes must be and we compare several (old and new) algorithms by discussing how well they match the axiomatic invariance requirements.",
    "cited_by_count": 126,
    "openalex_id": "https://openalex.org/W1980055624",
    "type": "article"
  },
  {
    "title": "Computing matrix functions",
    "doi": "https://doi.org/10.1017/s0962492910000036",
    "publication_date": "2010-05-01",
    "publication_year": 2010,
    "authors": "Nicholas J. Higham; Awad H. Al-Mohy",
    "corresponding_authors": "",
    "abstract": "The need to evaluate a function f(A) ∈ ℂ n × n of a matrix A ∈ ℂ n × n arises in a wide and growing number of applications, ranging from the numerical solution of differential equations to measures of the complexity of networks. We give a survey of numerical methods for evaluating matrix functions, along with a brief treatment of the underlying theory and a description of two recent applications. The survey is organized by classes of methods, which are broadly those based on similarity transformations, those employing approximation by polynomial or rational functions, and matrix iterations. Computation of the Fréchet derivative, which is important for condition number estimation, is also treated, along with the problem of computing f(A)b without computing f(A) . A summary of available software completes the survey.",
    "cited_by_count": 107,
    "openalex_id": "https://openalex.org/W2142597043",
    "type": "article"
  },
  {
    "title": "Linear algebra algorithms as dynamical systems",
    "doi": "https://doi.org/10.1017/s0962492906340019",
    "publication_date": "2008-04-25",
    "publication_year": 2008,
    "authors": "Moody T. Chu",
    "corresponding_authors": "Moody T. Chu",
    "abstract": "Any logical procedure that is used to reason or to infer either deductively or inductively, so as to draw conclusions or make decisions, can be called, in a broad sense, a realization process. A realization process usually assumes the recursive form that one state develops into another state by following a certain specific rule. Such an action is generally formalized as a dynamical system. In mathematics, especially for existence questions, a realization process often appears in the form of an iterative procedure or a differential equation. For years researchers have taken great effort to describe, analyse, and modify realization processes for various applications. The thrust in this exposition is to exploit the notion of dynamical systems as a special realization process for problems arising from the field of linear algebra. Several differential equations whose solutions evolve in submanifolds of matrices are cast in fairly general frameworks, of which special cases have been found to afford unified and fundamental insights into the structure and behaviour of existing discrete methods and, now and then, suggest new and improved numerical methods. In some cases, there are remarkable connections between smooth flows and discrete numerical algorithms. In other cases, the flow approach seems advantageous in tackling very difficult open problems. Various aspects of the recent development and application in this direction are discussed in this paper.",
    "cited_by_count": 102,
    "openalex_id": "https://openalex.org/W2034169759",
    "type": "article"
  },
  {
    "title": "Numerical algebraic geometry and algebraic kinematics",
    "doi": "https://doi.org/10.1017/s0962492911000067",
    "publication_date": "2011-04-28",
    "publication_year": 2011,
    "authors": "Charles W. Wampler; Andrew J. Sommese",
    "corresponding_authors": "",
    "abstract": "In this article, the basic constructs of algebraic kinematics (links, joints, and mechanism spaces) are introduced. This provides a common schema for many kinds of problems that are of interest in kinematic studies. Once the problems are cast in this algebraic framework, they can be attacked by tools from algebraic geometry. In particular, we review the techniques of numerical algebraic geometry, which are primarily based on homotopy methods. We include a review of the main developments of recent years and outline some of the frontiers where further research is occurring. While numerical algebraic geometry applies broadly to any system of polynomial equations, algebraic kinematics provides a body of interesting examples for testing algorithms and for inspiring new avenues of work.",
    "cited_by_count": 89,
    "openalex_id": "https://openalex.org/W1982227707",
    "type": "article"
  },
  {
    "title": "Numerical methods for nonlocal and fractional models",
    "doi": "https://doi.org/10.1017/s096249292000001x",
    "publication_date": "2020-05-01",
    "publication_year": 2020,
    "authors": "Marta D’Elia; Qiang Du; Christian Glusa; Max Gunzburger; Xiaochuan Tian; Zhi Zhou",
    "corresponding_authors": "",
    "abstract": "Partial differential equations (PDEs) are used, with huge success, to model phenomena arising across all scientific and engineering disciplines. However, across an equally wide swath, there exist situations in which PDE models fail to adequately model observed phenomena or are not the best available model for that purpose. On the other hand, in many situations, nonlocal models that account for interaction occurring at a distance have been shown to more faithfully and effectively model observed phenomena that involve possible singularities and other anomalies. In this article, we consider a generic nonlocal model, beginning with a short review of its definition, the properties of its solution, its mathematical analysis, and specific concrete examples. We then provide extensive discussions about numerical methods, including finite element, finite difference, and spectral methods, for determining approximate solutions of the nonlocal models considered. In that discussion, we pay particular attention to a special class of nonlocal models that are the most widely studied in the literature, namely those involving fractional derivatives. The article ends with brief considerations of several modeling and algorithmic extensions which serve to show the wide applicability of nonlocal modeling.",
    "cited_by_count": 63,
    "openalex_id": "https://openalex.org/W3005347120",
    "type": "article"
  },
  {
    "title": "Data assimilation: The Schrödinger perspective",
    "doi": "https://doi.org/10.1017/s0962492919000011",
    "publication_date": "2019-05-01",
    "publication_year": 2019,
    "authors": "Sebastian Reich",
    "corresponding_authors": "Sebastian Reich",
    "abstract": "Data assimilation addresses the general problem of how to combine model-based predictions with partial and noisy observations of the process in an optimal manner. This survey focuses on sequential data assimilation techniques using probabilistic particle-based algorithms. In addition to surveying recent developments for discrete- and continuous-time data assimilation, both in terms of mathematical foundations and algorithmic implementations, we also provide a unifying framework from the perspective of coupling of measures, and Schrödinger’s boundary value problem for stochastic processes in particular.",
    "cited_by_count": 59,
    "openalex_id": "https://openalex.org/W3101653947",
    "type": "article"
  },
  {
    "title": "Modelling and computation of liquid crystals",
    "doi": "https://doi.org/10.1017/s0962492921000088",
    "publication_date": "2021-05-01",
    "publication_year": 2021,
    "authors": "Wei Wang; Lei Zhang; Pingwen Zhang",
    "corresponding_authors": "",
    "abstract": "Liquid crystals are a type of soft matter that is intermediate between crystalline solids and isotropic fluids. The study of liquid crystals has made tremendous progress over the past four decades, which is of great importance for fundamental scientific research and has widespread applications in industry. In this paper we review the mathematical models and their connections to liquid crystals, and survey the developments of numerical methods for finding rich configurations of liquid crystals.",
    "cited_by_count": 54,
    "openalex_id": "https://openalex.org/W3195520978",
    "type": "article"
  },
  {
    "title": "Overcoming the timescale barrier in molecular dynamics: Transfer operators, variational principles and machine learning",
    "doi": "https://doi.org/10.1017/s0962492923000016",
    "publication_date": "2023-05-01",
    "publication_year": 2023,
    "authors": "Christof Schütte; Stefan Klus; Carsten Hartmann",
    "corresponding_authors": "",
    "abstract": "One of the main challenges in molecular dynamics is overcoming the ‘timescale barrier’: in many realistic molecular systems, biologically important rare transitions occur on timescales that are not accessible to direct numerical simulation, even on the largest or specifically dedicated supercomputers. This article discusses how to circumvent the timescale barrier by a collection of transfer operator-based techniques that have emerged from dynamical systems theory, numerical mathematics and machine learning over the last two decades. We will focus on how transfer operators can be used to approximate the dynamical behaviour on long timescales, review the introduction of this approach into molecular dynamics, and outline the respective theory, as well as the algorithmic development, from the early numerics-based methods, via variational reformulations, to modern data-based techniques utilizing and improving concepts from machine learning. Furthermore, its relation to rare event simulation techniques will be explained, revealing a broad equivalence of variational principles for long-time quantities in molecular dynamics. The article will mainly take a mathematical perspective and will leave the application to real-world molecular systems to the more than 1000 research articles already written on this subject.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W4376144230",
    "type": "article"
  },
  {
    "title": "Splitting methods for differential equations",
    "doi": "https://doi.org/10.1017/s0962492923000077",
    "publication_date": "2024-07-01",
    "publication_year": 2024,
    "authors": "Sergio Blanes; Fernando Casas; Ander Murua",
    "corresponding_authors": "",
    "abstract": "This overview is devoted to splitting methods, a class of numerical integrators intended for differential equations that can be subdivided into different problems easier to solve than the original system. Closely connected with this class of integrators are composition methods, in which one or several low-order schemes are composed to construct higher-order numerical approximations to the exact solution. We analyse in detail the order conditions that have to be satisfied by these classes of methods to achieve a given order, and provide some insight about their qualitative properties in connection with geometric numerical integration and the treatment of highly oscillatory problems. Since splitting methods have received considerable attention in the realm of partial differential equations, we also cover this subject in the present survey, with special attention to parabolic equations and their problems. An exhaustive list of methods of different orders is collected and tested on simple examples. Finally, some applications of splitting methods in different areas, ranging from celestial mechanics to statistics, are also provided.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W4402228362",
    "type": "article"
  },
  {
    "title": "Optimal experimental design: Formulations and computations",
    "doi": "https://doi.org/10.1017/s0962492924000023",
    "publication_date": "2024-07-01",
    "publication_year": 2024,
    "authors": "Xun Huan; Jayanth Jagalur; Youssef Marzouk",
    "corresponding_authors": "",
    "abstract": "Questions of ‘how best to acquire data’ are essential to modelling and prediction in the natural and social sciences, engineering applications, and beyond. Optimal experimental design (OED) formalizes these questions and creates computational methods to answer them. This article presents a systematic survey of modern OED, from its foundations in classical design theory to current research involving OED for complex models. We begin by reviewing criteria used to formulate an OED problem and thus to encode the goal of performing an experiment. We emphasize the flexibility of the Bayesian and decision-theoretic approach, which encompasses information-based criteria that are well-suited to nonlinear and non-Gaussian statistical models. We then discuss methods for estimating or bounding the values of these design criteria; this endeavour can be quite challenging due to strong nonlinearities, high parameter dimension, large per-sample costs, or settings where the model is implicit. A complementary set of computational issues involves optimization methods used to find a design; we discuss such methods in the discrete (combinatorial) setting of observation selection and in settings where an exact design can be continuously parametrized. Finally we present emerging methods for sequential OED that build non-myopic design policies, rather than explicit designs; these methods naturally adapt to the outcomes of past experiments in proposing new experiments, while seeking coordination among all experiments to be performed. Throughout, we highlight important open questions and challenges.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W4402229381",
    "type": "article"
  },
  {
    "title": "Distributionally robust optimization",
    "doi": "https://doi.org/10.1017/s0962492924000084",
    "publication_date": "2025-07-01",
    "publication_year": 2025,
    "authors": "Daniel Kühn; Soroosh Shafieezadeh-Abadeh; Wolfram Wiesemann",
    "corresponding_authors": "",
    "abstract": "Distributionally robust optimization (DRO) studies decision problems under uncertainty where the probability distribution governing the uncertain problem parameters is itself uncertain. A key component of any DRO model is its ambiguity set, that is, a family of probability distributions consistent with any available structural or statistical information. DRO seeks decisions that perform best under the worst distribution in the ambiguity set. This worst case criterion is supported by findings in psychology and neuroscience, which indicate that many decision-makers have a low tolerance for distributional ambiguity. DRO is rooted in statistics, operations research and control theory, and recent research has uncovered its deep connections to regularization techniques and adversarial training in machine learning. This survey presents the key findings of the field in a unified and self-contained manner.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4411917733",
    "type": "article"
  },
  {
    "title": "The numerical analysis of bifurcation problems with application to fluid mechanics",
    "doi": "https://doi.org/10.1017/s0962492900000398",
    "publication_date": "2000-01-01",
    "publication_year": 2000,
    "authors": "K. A. Cliffe; A. Spence; Simon Tavener",
    "corresponding_authors": "",
    "abstract": "In this review we discuss bifurcation theory in a Banach space setting using the singularity theory developed by Golubitsky and Schaeffer to classify bifurcation points. The numerical analysis of bifurcation problems is discussed and the convergence theory for several important bifurcations is described for both projection and finite difference methods. These results are used to provide a convergence theory for the mixed finite element method applied to the steady incompressible Navier–Stokes equations. Numerical methods for the calculation of several common bifurcations are described and the performance of these methods is illustrated by application to several problems in fluid mechanics. A detailed description of the Taylor–Couette problem is given, and extensive numerical and experimental results are provided for comparison and discussion.",
    "cited_by_count": 133,
    "openalex_id": "https://openalex.org/W2109314821",
    "type": "article"
  },
  {
    "title": "Geometric aspects of the theory of Krylov subspace methods",
    "doi": "https://doi.org/10.1017/s0962492901000046",
    "publication_date": "2001-05-01",
    "publication_year": 2001,
    "authors": "Michael Eiermann; Oliver G. Ernst",
    "corresponding_authors": "",
    "abstract": "The development of Krylov subspace methods for the solution of operator equations has shown that two basic construction principles underlie the most commonly used algorithms: the orthogonal residual (OR) and minimal residual (MR) approaches. It is shown that these can both be formulated as techniques for solving an approximation problem on a sequence of nested subspaces of a Hilbert space, an abstract problem not necessarily related to an operator equation. Essentially all Krylov subspace algorithms result when these subspaces form a Krylov sequence. The well-known relations among the iterates and residuals of MR/OR pairs are shown to hold also in this rather general setting. We further show that a common error analysis for these methods involving the canonical angles between subspaces allows many of the known residual and error bounds to be derived in a simple and consistent manner. An application of this analysis to compact perturbations of the identity shows that MR/OR pairs of Krylov subspace methods converge q -superlinearly when applied to such operator equations.",
    "cited_by_count": 128,
    "openalex_id": "https://openalex.org/W2139940635",
    "type": "article"
  },
  {
    "title": "Numerical analysis of dynamical systems",
    "doi": "https://doi.org/10.1017/s0962492900002488",
    "publication_date": "1994-01-01",
    "publication_year": 1994,
    "authors": "Andrew M. Stuart",
    "corresponding_authors": "Andrew M. Stuart",
    "abstract": "This article reviews the application of various notions from the theory of dynamical systems to the analysis of numerical approximation of initial value problems over long-time intervals. Standard error estimates comparing individual trajectories are of no direct use in this context since the error constant typically grows like the exponential of the time interval under consideration. Instead of comparing trajectories, the effect of discretization on various sets which are invariant under the evolution of the underlying differential equation is studied. Such invariant sets are crucial in determining long-time dynamics. The particular invariant sets which are studied are equilibrium points, together with their unstable manifolds and local phase portraits, periodic solutions, quasi-periodic solutions and strange attractors. Particular attention is paid to the development of a unified theory and to the development of an existence theory for invariant sets of the underlying differential equation which may be used directly to construct an analogous existence theory (and hence a simple approximation theory) for the numerical method.",
    "cited_by_count": 114,
    "openalex_id": "https://openalex.org/W2071701027",
    "type": "article"
  },
  {
    "title": "Lanczos-type solvers for nonsymmetric linear systems of equations",
    "doi": "https://doi.org/10.1017/s0962492900002737",
    "publication_date": "1997-01-01",
    "publication_year": 1997,
    "authors": "Martin H. Gutknecht",
    "corresponding_authors": "Martin H. Gutknecht",
    "abstract": "Among the iterative methods for solving large linear systems with a sparse (or, possibly, structured) nonsymmetric matrix, those that are based on the Lanczos process feature short recurrences for the generation of the Krylov space. This means low cost and low memory requirement. This review article introduces the reader not only to the basic forms of the Lanczos process and some of the related theory, but also describes in detail a number of solvers that are based on it, including those that are considered to be the most efficient ones. Possible breakdowns of the algorithms and ways to cure them by look-ahead are also discussed.",
    "cited_by_count": 114,
    "openalex_id": "https://openalex.org/W2104309019",
    "type": "article"
  },
  {
    "title": "Multiscale computational modelling of the heart",
    "doi": "https://doi.org/10.1017/s0962492904000200",
    "publication_date": "2004-05-01",
    "publication_year": 2004,
    "authors": "Nicolas P. Smith; David Nickerson; Edmund J. Crampin; Peter Hunter",
    "corresponding_authors": "",
    "abstract": "A computational framework is presented for integrating the electrical, mechanical and biochemical functions of the heart. Finite element techniques are used to solve the large-deformation soft tissue mechanics using orthotropic constitutive laws based in the measured fibre-sheet structure of myocardial (heart muscle) tissue. The reaction-diffusion equations governing electrical current flow in the heart are solved on a grid of deforming material points which access systems of ODEs representing the cellular processes underlying the cardiac action potential. Navier-Stokes equations are solved for coronary blood flow in a system of branching blood vessels embedded in the deforming myocardium and the delivery of oxygen and metabolites is coupled to the energy-dependent cellular processes. The framework presented here for modelling coupled physical conservation laws at the tissue and organ levels is also appropriate for other organ systems in the body and we briefly discuss applications to the lungs and the musculo-skeletal system. The computational framework is also designed to reach down to subcellular processes, including signal transduction cascades and metabolic pathways as well as ion channel electrophysiology, and we discuss the development of ontologies and markup language standards that will help link the tissue and organ level models to the vast array of gene and protein data that are now available in web-accessible databases.",
    "cited_by_count": 112,
    "openalex_id": "https://openalex.org/W1969822366",
    "type": "article"
  },
  {
    "title": "Computational chemistry from the perspective of numerical analysis",
    "doi": "https://doi.org/10.1017/s096249290400025x",
    "publication_date": "2005-04-19",
    "publication_year": 2005,
    "authors": "Claude Le Bris",
    "corresponding_authors": "Claude Le Bris",
    "abstract": "We present the field of computational chemistry from the standpoint of numerical analysis. We introduce the most commonly used models and comment on their applicability. We briefly outline the results of mathematical analysis and then mostly concentrate on the main issues raised by numerical simulations. A special emphasis is laid on recent results in numerical analysis, recent developments of new methods and challenging open issues.",
    "cited_by_count": 112,
    "openalex_id": "https://openalex.org/W2046434053",
    "type": "article"
  },
  {
    "title": "A mathematical view of automatic differentiation",
    "doi": "https://doi.org/10.1017/s0962492902000132",
    "publication_date": "2003-05-01",
    "publication_year": 2003,
    "authors": "Andreas Griewank",
    "corresponding_authors": "Andreas Griewank",
    "abstract": "Automatic, or algorithmic, differentiation addresses the need for the accurate and efficient calculation of derivative values in scientific computing. To this end procedural programs for the evaluation of problem-specific functions are transformed into programs that also compute the required derivative values at the same numerical arguments in floating point arithmetic. Disregarding many important implementation issues, we examine in this article complexity bounds and other more mathematical aspects of the program transformation task sketched above.",
    "cited_by_count": 102,
    "openalex_id": "https://openalex.org/W2157488230",
    "type": "article"
  },
  {
    "title": "Filters, mollifiers and the computation of the Gibbs phenomenon",
    "doi": "https://doi.org/10.1017/s0962492906320016",
    "publication_date": "2007-04-24",
    "publication_year": 2007,
    "authors": "Eitan Tadmor",
    "corresponding_authors": "Eitan Tadmor",
    "abstract": "We are concerned here with processing discontinuous functions from their spectral information. We focus on two main aspects of processing such piecewise smooth data: detecting the edges of a piecewise smooth f , namely, the location and amplitudes of its discontinuities; and recovering with high accuracy the underlying function in between those edges. If f is a smooth function, say analytic, then classical Fourier projections recover f with exponential accuracy. However, if f contains one or more discontinuities, its global Fourier projections produce spurious Gibbs oscillations which spread throughout the smooth regions, enforcing local loss of resolution and global loss of accuracy. Our aim in the computation of the Gibbs phenomenon is to detect edges and to reconstruct piecewise smooth functions, while regaining the high accuracy encoded in the spectral data. To detect edges, we utilize a general family of edge detectors based on concentration kernels . Each kernel forms an approximate derivative of the delta function, which detects edges by separation of scales . We show how such kernels can be adapted to detect edges with one- and two-dimensional discrete data, with noisy data, and with incomplete spectral information. The main feature is concentration kernels which enable us to convert global spectral moments into local information in physical space. To reconstruct f with high accuracy we discuss novel families of mollifiers and filters . The main feature here is making these mollifiers and filters adapted to the local region of smoothness while increasing their accuracy together with the dimension of the data. These mollifiers and filters form approximate delta functions which are properly parametrized to recover f with (root-) exponential accuracy.",
    "cited_by_count": 97,
    "openalex_id": "https://openalex.org/W2167651376",
    "type": "article"
  },
  {
    "title": "Numerical tensor calculus",
    "doi": "https://doi.org/10.1017/s0962492914000087",
    "publication_date": "2014-05-01",
    "publication_year": 2014,
    "authors": "Wolfgang Hackbusch",
    "corresponding_authors": "Wolfgang Hackbusch",
    "abstract": "The usual large-scale discretizations are applied to two or three spatial dimensions. The standard methods fail for higher dimensions because the data size increases exponentially with the dimension. In the case of a regular grid with n grid points per direction, a spatial dimension d yields n d grid points. A grid function defined on such a grid is an example of a tensor of order d . Here, suitable tensor formats help, since they try to approximate these huge objects by a much smaller number of parameters, which increases only linearly in d . In this way, data of size n d = 1000 1000 can also be treated. This paper introduces the algebraic and analytical aspects of tensor spaces. The main part concerns the numerical representation of tensors and the numerical performance of tensor operations.",
    "cited_by_count": 67,
    "openalex_id": "https://openalex.org/W2168071446",
    "type": "article"
  },
  {
    "title": "Numerical analysis of strongly nonlinear PDEs",
    "doi": "https://doi.org/10.1017/s0962492917000071",
    "publication_date": "2017-05-01",
    "publication_year": 2017,
    "authors": "Michael Neilan; Abner J. Salgado; Wujun Zhang",
    "corresponding_authors": "",
    "abstract": "We review the construction and analysis of numerical methods for strongly nonlinear PDEs, with an emphasis on convex and non-convex fully nonlinear equations and the convergence to viscosity solutions. We begin by describing a fundamental result in this area which states that stable, consistent and monotone schemes converge as the discretization parameter tends to zero. We review methodologies to construct finite difference, finite element and semi-Lagrangian schemes that satisfy these criteria, and, in addition, discuss some rather novel tools that have paved the way to derive rates of convergence within this framework.",
    "cited_by_count": 64,
    "openalex_id": "https://openalex.org/W2963243433",
    "type": "article"
  },
  {
    "title": "Adaptive multiscale predictive modelling",
    "doi": "https://doi.org/10.1017/s096249291800003x",
    "publication_date": "2018-05-01",
    "publication_year": 2018,
    "authors": "J. Tinsley Oden",
    "corresponding_authors": "J. Tinsley Oden",
    "abstract": "The use of computational models and simulations to predict events that take place in our physical universe, or to predict the behaviour of engineered systems, has significantly advanced the pace of scientific discovery and the creation of new technologies for the benefit of humankind over recent decades, at least up to a point. That ‘point’ in recent history occurred around the time that the scientific community began to realize that true predictive science must deal with many formidable obstacles, including the determination of the reliability of the models in the presence of many uncertainties. To develop meaningful predictions one needs relevant data, itself possessing uncertainty due to experimental noise; in addition, one must determine model parameters, and concomitantly, there is the overriding need to select and validate models given the data and the goals of the simulation. This article provides a broad overview of predictive computational science within the framework of what is often called the science of uncertainty quantification. The exposition is divided into three major parts. In Part 1, philosophical and statistical foundations of predictive science are developed within a Bayesian framework. There the case is made that the Bayesian framework provides, perhaps, a unique setting for handling all of the uncertainties encountered in scientific prediction. In Part 2, general frameworks and procedures for the calculation and validation of mathematical models of physical realities are given, all in a Bayesian setting. But beyond Bayes, an introduction to information theory, the maximum entropy principle, model sensitivity analysis and sampling methods such as MCMC are presented. In Part 3, the central problem of predictive computational science is addressed: the selection, adaptive control and validation of mathematical and computational models of complex systems. The Occam Plausibility Algorithm, OPAL, is introduced as a framework for model selection, calibration and validation. Applications to complex models of tumour growth are discussed.",
    "cited_by_count": 59,
    "openalex_id": "https://openalex.org/W2799419481",
    "type": "article"
  },
  {
    "title": "Randomized algorithms in numerical linear algebra",
    "doi": "https://doi.org/10.1017/s0962492917000058",
    "publication_date": "2017-05-01",
    "publication_year": 2017,
    "authors": "Ravindran Kannan; Santosh Vempala",
    "corresponding_authors": "",
    "abstract": "This survey provides an introduction to the use of randomization in the design of fast algorithms for numerical linear algebra. These algorithms typically examine only a subset of the input to solve basic problems approximately, including matrix multiplication, regression and low-rank approximation. The survey describes the key ideas and gives complete proofs of the main results in the field. A central unifying idea is sampling the columns (or rows) of a matrix according to their squared lengths.",
    "cited_by_count": 55,
    "openalex_id": "https://openalex.org/W2611027513",
    "type": "article"
  },
  {
    "title": "Geometric integrators and the Hamiltonian Monte Carlo method",
    "doi": "https://doi.org/10.1017/s0962492917000101",
    "publication_date": "2018-05-01",
    "publication_year": 2018,
    "authors": "Nawaf Bou‐Rabee; J. M. Sanz‐Serna",
    "corresponding_authors": "",
    "abstract": "This paper surveys in detail the relations between numerical integration and the Hamiltonian (or hybrid) Monte Carlo method (HMC). Since the computational cost of HMC mainly lies in the numerical integrations, these should be performed as efficiently as possible. However, HMC requires methods that have the geometric properties of being volume-preserving and reversible, and this limits the number of integrators that may be used. On the other hand, these geometric properties have important quantitative implications for the integration error, which in turn have an impact on the acceptance rate of the proposal. While at present the velocity Verlet algorithm is the method of choice for good reasons, we argue that Verlet can be improved upon. We also discuss in detail the behaviour of HMC as the dimensionality of the target distribution increases.",
    "cited_by_count": 53,
    "openalex_id": "https://openalex.org/W2768877132",
    "type": "article"
  },
  {
    "title": "Numerical methods for Kohn–Sham density functional theory",
    "doi": "https://doi.org/10.1017/s0962492919000047",
    "publication_date": "2019-05-01",
    "publication_year": 2019,
    "authors": "Lin Lin; Jianfeng Lu; Lexing Ying",
    "corresponding_authors": "",
    "abstract": "Kohn–Sham density functional theory (DFT) is the most widely used electronic structure theory. Despite significant progress in the past few decades, the numerical solution of Kohn–Sham DFT problems remains challenging, especially for large-scale systems. In this paper we review the basics as well as state-of-the-art numerical methods, and focus on the unique numerical challenges of DFT.",
    "cited_by_count": 46,
    "openalex_id": "https://openalex.org/W2950768258",
    "type": "article"
  },
  {
    "title": "Turnpike in optimal control of PDEs, ResNets, and beyond",
    "doi": "https://doi.org/10.1017/s0962492922000046",
    "publication_date": "2022-05-01",
    "publication_year": 2022,
    "authors": "Borjan Geshkovski; Enrique Zuazua",
    "corresponding_authors": "",
    "abstract": "The turnpike property in contemporary macroeconomics asserts that if an economic planner seeks to move an economy from one level of capital to another, then the most efficient path, as long as the planner has enough time, is to rapidly move stock to a level close to the optimal stationary or constant path, then allow for capital to develop along that path until the desired term is nearly reached, at which point the stock ought to be moved to the final target. Motivated in part by its nature as a resource allocation strategy, over the past decade, the turnpike property has also been shown to hold for several classes of partial differential equations arising in mechanics. When formalized mathematically, the turnpike theory corroborates insights from economics: for an optimal control problem set in a finite-time horizon, optimal controls and corresponding states are close (often exponentially) most of the time, except near the initial and final times, to the optimal control and the corresponding state for the associated stationary optimal control problem. In particular, the former are mostly constant over time. This fact provides a rigorous meaning to the asymptotic simplification that some optimal control problems appear to enjoy over long time intervals, allowing the consideration of the corresponding stationary problem for computing and applications. We review a slice of the theory developed over the past decade – the controllability of the underlying system is an important ingredient, and can even be used to devise simple turnpike-like strategies which are nearly optimal – and present several novel applications, including, among many others, the characterization of Hamilton–Jacobi–Bellman asymptotics, and stability estimates in deep learning via residual neural networks.",
    "cited_by_count": 28,
    "openalex_id": "https://openalex.org/W4281870568",
    "type": "article"
  },
  {
    "title": "Low-rank tensor methods for partial differential equations",
    "doi": "https://doi.org/10.1017/s0962492922000125",
    "publication_date": "2023-05-01",
    "publication_year": 2023,
    "authors": "Markus Bachmayr",
    "corresponding_authors": "Markus Bachmayr",
    "abstract": "Low-rank tensor representations can provide highly compressed approximations of functions. These concepts, which essentially amount to generalizations of classical techniques of separation of variables, have proved to be particularly fruitful for functions of many variables. We focus here on problems where the target function is given only implicitly as the solution of a partial differential equation. A first natural question is under which conditions we should expect such solutions to be efficiently approximated in low-rank form. Due to the highly nonlinear nature of the resulting low-rank approximations, a crucial second question is at what expense such approximations can be computed in practice. This article surveys basic construction principles of numerical methods based on low-rank representations as well as the analysis of their convergence and computational complexity.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W4376148906",
    "type": "article"
  },
  {
    "title": "Compatible finite element methods for geophysical fluid dynamics",
    "doi": "https://doi.org/10.1017/s0962492923000028",
    "publication_date": "2023-05-01",
    "publication_year": 2023,
    "authors": "Colin J. Cotter",
    "corresponding_authors": "Colin J. Cotter",
    "abstract": "This article surveys research on the application of compatible finite element methods to large-scale atmosphere and ocean simulation. Compatible finite element methods extend Arakawa’s C-grid finite difference scheme to the finite element world. They are constructed from a discrete de Rham complex, which is a sequence of finite element spaces linked by the operators of differential calculus. The use of discrete de Rham complexes to solve partial differential equations is well established, but in this article we focus on the specifics of dynamical cores for simulating weather, oceans and climate. The most important consequence of the discrete de Rham complex is the Hodge–Helmholtz decomposition, which has been used to exclude the possibility of several types of spurious oscillations from linear equations of geophysical flow. This means that compatible finite element spaces provide a useful framework for building dynamical cores. In this article we introduce the main concepts of compatible finite element spaces, and discuss their wave propagation properties. We survey some methods for discretizing the transport terms that arise in dynamical core equation systems, and provide some example discretizations, briefly discussing their iterative solution. Then we focus on the recent use of compatible finite element spaces in designing structure preserving methods, surveying variational discretizations, Poisson bracket discretizations and consistent vorticity transport.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W4376144221",
    "type": "article"
  },
  {
    "title": "Triangulations and meshes in computational geometry",
    "doi": "https://doi.org/10.1017/s0962492900001331",
    "publication_date": "2000-01-01",
    "publication_year": 2000,
    "authors": "Herbert Edelsbrunner",
    "corresponding_authors": "Herbert Edelsbrunner",
    "abstract": "The Delaunay triangulation of a finite point set is a central theme in computational geometry. It finds its major application in the generation of meshes used in the simulation of physical processes. This paper connects the predominantly combinatorial work in classical computational geometry with the numerical interest in mesh generation. It focuses on the two- and three-dimensional case and covers results obtained during the twentieth century.",
    "cited_by_count": 98,
    "openalex_id": "https://openalex.org/W1999340585",
    "type": "article"
  },
  {
    "title": "Exact and approximate controllability for distributed parameter systems",
    "doi": "https://doi.org/10.1017/s0962492900002543",
    "publication_date": "1995-01-01",
    "publication_year": 1995,
    "authors": "Roland Glowinski; J. L. Lions",
    "corresponding_authors": "",
    "abstract": "This is the second part of an article which was started in the previous volume of Acta Numerica . References in the text to Section 1 refer to the preceding article.",
    "cited_by_count": 96,
    "openalex_id": "https://openalex.org/W4255657275",
    "type": "article"
  },
  {
    "title": "Linear stability analysis in the numerical solution of initial value problems",
    "doi": "https://doi.org/10.1017/s0962492900002361",
    "publication_date": "1993-01-01",
    "publication_year": 1993,
    "authors": "Jos L. M. van Dorsselaer; J. F. B. M. Kraaijevanger; M. N. Spijker",
    "corresponding_authors": "",
    "abstract": "This article addresses the general problem of establishing upper bounds for the norms of the n th powers of square matrices. The focus is on upper bounds that grow only moderately (or stay constant) where n , or the order of the matrices, increases. The so-called resolvant condition, occuring in the famous Kreiss matrix theorem, is a classical tool for deriving such bounds. Recently the classical upper bounds known to be valid under Kreiss's resolvant condition have been improved. Moreover, generalizations of this resolvant condition have been considered so as to widen the range of applications. The main purpose of this article is to review and extend some of these new developments. The upper bounds for the powers of matrices discussed in this article are intimately connected with the stability analysis of numerical processes for solving initial(-boundary) value problems in ordinary and partial linear differential equations. The article highlights this connection. The article concludes with numerical illustrations in the solution of a simple initial-boundary value problem for a partial differential equation.",
    "cited_by_count": 90,
    "openalex_id": "https://openalex.org/W2165808880",
    "type": "article"
  },
  {
    "title": "Error analysis of boundary integral methods",
    "doi": "https://doi.org/10.1017/s0962492900002294",
    "publication_date": "1992-01-01",
    "publication_year": 1992,
    "authors": "Ian H. Sloan",
    "corresponding_authors": "Ian H. Sloan",
    "abstract": "Many of the boundary value problems traditionally cast as partial differential equations can be reformulated as integral equations over the boundary. After an introduction to boundary integral equations, this review describes some of the methods which have been proposed for their approximate solution. It discusses, as simply as possible, some of the techniques used in their error analysis, and points to areas in which the theory is still unsatisfactory.",
    "cited_by_count": 84,
    "openalex_id": "https://openalex.org/W2011448430",
    "type": "article"
  },
  {
    "title": "Relative perturbation results for matrix eigenvalues and singular values",
    "doi": "https://doi.org/10.1017/s0962492900002828",
    "publication_date": "1998-01-01",
    "publication_year": 1998,
    "authors": "Ilse C. F. Ipsen",
    "corresponding_authors": "Ilse C. F. Ipsen",
    "abstract": "It used to be good enough to bound absolute of matrix eigenvalues and singular values. Not any more. Now it is fashionable to bound relative errors. We present a collection of relative perturbation results which have emerged during the past ten years. No need to throw away all those absolute error bound, though. Deep down, the derivation of many relative bounds can be based on absolute bounds. This means that relative bounds are not always better. They may just be better sometimes – and exactly when depends on the perturbation.",
    "cited_by_count": 83,
    "openalex_id": "https://openalex.org/W2142907115",
    "type": "article"
  },
  {
    "title": "On the numerical evaluation of electrostatic fields in composite materials",
    "doi": "https://doi.org/10.1017/s0962492900002464",
    "publication_date": "1994-01-01",
    "publication_year": 1994,
    "authors": "Leslie Greengard; Monique Moura",
    "corresponding_authors": "",
    "abstract": "A classical problem in electrostatics is the determination of the effective electrical conductivity in a composite material consisting of a collection of piecewise homogeneous inclusions embedded in a uniform background. We discuss recently developed fast algorithms for the evaluation of the potential and electrostatic fields induced in multiphase composites by an applied potential, from which the desired effective properties may be easily obtained. The schemes are based on combining a suitable boundary integral equation with the Fast Multipole Method and the GMRES iterative method; the CPU time required grows linearly with the number of points in the discretization of the interface between the inclusions and the background material. A variety of other questions in electrostatics, magnetostatics and diffusion can be formulated in terms of interface problems. These include the evaluation of electrostatic fields in the presence of dielectric inclusions, the determination of magnetostatic fields in media with variable magnetic permeability, and the calculation of the effective thermal conductivity of a composite material. The methods presented here apply with minor modification to these other situations as well.",
    "cited_by_count": 77,
    "openalex_id": "https://openalex.org/W2168694898",
    "type": "article"
  },
  {
    "title": "Blow-up or no blow-up? A unified computational and analytic approach to 3D incompressible Euler and Navier–Stokes equations",
    "doi": "https://doi.org/10.1017/s0962492906420018",
    "publication_date": "2009-05-01",
    "publication_year": 2009,
    "authors": "Thomas Y. Hou",
    "corresponding_authors": "Thomas Y. Hou",
    "abstract": "Whether the 3D incompressible Euler and Navier–Stokes equations can develop a finite-time singularity from smooth initial data with finite energy has been one of the most long-standing open questions. We review some recent theoretical and computational studies which show that there is a subtle dynamic depletion of nonlinear vortex stretching due to local geometric regularity of vortex filaments. We also investigate the dynamic stability of the 3D Navier–Stokes equations and the stabilizing effect of convection. A unique feature of our approach is the interplay between computation and analysis. Guided by our local non-blow-up theory, we have performed large-scale computations of the 3D Euler equations using a novel pseudo-spectral method on some of the most promising blow-up candidates. Our results show that there is tremendous dynamic depletion of vortex stretching. Moreover, we observe that the support of maximum vorticity becomes severely flattened as the maximum vorticity increases and the direction of the vortex filaments near the support of maximum vorticity is very regular. Our numerical observations in turn provide valuable insight, which leads to further theoretical breakthrough. Finally, we present a new class of solutions for the 3D Euler and Navier–Stokes equations, which exhibit very interesting dynamic growth properties. By exploiting the special nonlinear structure of the equations, we prove nonlinear stability and the global regularity of this class of solutions.",
    "cited_by_count": 61,
    "openalex_id": "https://openalex.org/W2115331483",
    "type": "article"
  },
  {
    "title": "High-performance computing systems: Status and outlook",
    "doi": "https://doi.org/10.1017/s0962492912000050",
    "publication_date": "2012-04-19",
    "publication_year": 2012,
    "authors": "Jack Dongarra; Aad J. van der Steen",
    "corresponding_authors": "",
    "abstract": "This article describes the current state of the art of high-performance computing systems, and attempts to shed light on near-future developments that might prolong the steady growth in speed of such systems, which has been one of their most remarkable characteristics. We review the different ways devised to speed them up, both with regard to components and their architecture. In addition, we discuss the requirements for software that can take advantage of existing and future architectures.",
    "cited_by_count": 57,
    "openalex_id": "https://openalex.org/W2009082387",
    "type": "article"
  },
  {
    "title": "On first-order algorithms for<i>l</i><sub>1</sub>/nuclear norm minimization",
    "doi": "https://doi.org/10.1017/s096249291300007x",
    "publication_date": "2013-04-02",
    "publication_year": 2013,
    "authors": "Yurii Nesterov; Arkadi Nemirovski",
    "corresponding_authors": "",
    "abstract": "In the past decade, problems related to l 1 /nuclear norm minimization have attracted much attention in the signal processing, machine learning and optimization communities. In this paper, devoted to l 1 /nuclear norm minimization as ‘optimization beasts’, we give a detailed description of two attractive first-order optimization techniques for solving problems of this type. The first one, aimed primarily at lasso-type problems, comprises fast gradient methods applied to composite minimization formulations. The second approach, aimed at Dantzig-selector-type problems, utilizes saddle-point first-order algorithms and reformulation of the problem of interest as a generalized bilinear saddle-point problem . For both approaches, we give complete and detailed complexity analyses and discuss the application domains.",
    "cited_by_count": 48,
    "openalex_id": "https://openalex.org/W2059602082",
    "type": "article"
  },
  {
    "title": "Fast algorithms using orthogonal polynomials",
    "doi": "https://doi.org/10.1017/s0962492920000045",
    "publication_date": "2020-05-01",
    "publication_year": 2020,
    "authors": "Sheehan Olver; Richard Mikaël Slevinsky; Alex Townsend",
    "corresponding_authors": "",
    "abstract": "We review recent advances in algorithms for quadrature, transforms, differential equations and singular integral equations using orthogonal polynomials. Quadrature based on asymptotics has facilitated optimal complexity quadrature rules, allowing for efficient computation of quadrature rules with millions of nodes. Transforms based on rank structures in change-of-basis operators allow for quasi-optimal complexity, including in multivariate settings such as on triangles and for spherical harmonics. Ordinary and partial differential equations can be solved via sparse linear algebra when set up using orthogonal polynomials as a basis, provided that care is taken with the weights of orthogonality. A similar idea, together with low-rank approximation, gives an efficient method for solving singular integral equations. These techniques can be combined to produce high-performance codes for a wide range of problems that appear in applications.",
    "cited_by_count": 41,
    "openalex_id": "https://openalex.org/W3109089832",
    "type": "article"
  },
  {
    "title": "Floating-point arithmetic",
    "doi": "https://doi.org/10.1017/s0962492922000101",
    "publication_date": "2023-05-01",
    "publication_year": 2023,
    "authors": "Sylvie Boldo; Claude-Pierre Jeannerod; Guillaume Melquiond; Jean‐Michel Muller",
    "corresponding_authors": "",
    "abstract": "Floating-point numbers have an intuitive meaning when it comes to physics-based numerical computations, and they have thus become the most common way of approximating real numbers in computers. The IEEE-754 Standard has played a large part in making floating-point arithmetic ubiquitous today, by specifying its semantics in a strict yet useful way as early as 1985. In particular, floating-point operations should be performed as if their results were first computed with an infinite precision and then rounded to the target format. A consequence is that floating-point arithmetic satisfies the ‘standard model’ that is often used for analysing the accuracy of floating-point algorithms. But that is only scraping the surface, and floating-point arithmetic offers much more. In this survey we recall the history of floating-point arithmetic as well as its specification mandated by the IEEE-754 Standard. We also recall what properties it entails and what every programmer should know when designing a floating-point algorithm. We provide various basic blocks that can be implemented with floating-point arithmetic. In particular, one can actually compute the rounding error caused by some floating-point operations, which paves the way to designing more accurate algorithms. More generally, properties of floating-point arithmetic make it possible to extend the accuracy of computations beyond working precision.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W4376144198",
    "type": "article"
  },
  {
    "title": "The geometry of monotone operator splitting methods",
    "doi": "https://doi.org/10.1017/s0962492923000065",
    "publication_date": "2024-07-01",
    "publication_year": 2024,
    "authors": "Patrick L. Combettes",
    "corresponding_authors": "Patrick L. Combettes",
    "abstract": "We propose a geometric framework to describe and analyse a wide array of operator splitting methods for solving monotone inclusion problems. The initial inclusion problem, which typically involves several operators combined through monotonicity-preserving operations, is seldom solvable in its original form. We embed it in an auxiliary space, where it is associated with a surrogate monotone inclusion problem with a more tractable structure and which allows for easy recovery of solutions to the initial problem. The surrogate problem is solved by successive projections onto half-spaces containing its solution set. The outer approximation half-spaces are constructed by using the individual operators present in the model separately. This geometric framework is shown to encompass traditional methods as well as state-of-the-art asynchronous block-iterative algorithms, and its flexible structure provides a pattern to design new ones.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W4402231568",
    "type": "article"
  },
  {
    "title": "Data mining techniques",
    "doi": "https://doi.org/10.1017/s0962492901000058",
    "publication_date": "2001-05-01",
    "publication_year": 2001,
    "authors": "Markus Hegland",
    "corresponding_authors": "Markus Hegland",
    "abstract": "Methods for knowledge discovery in data bases (KDD) have been studied for more than a decade. New methods are required owing to the size and complexity of data collections in administration, business and science. They include procedures for data query and extraction, for data cleaning, data analysis, and methods of knowledge representation. The part of KDD dealing with the analysis of the data has been termed data mining. Common data mining tasks include the induction of association rules, the discovery of functional relationships (classification and regression) and the exploration of groups of similar data objects in clustering. This review provides a discussion of and pointers to efficient algorithms for the common data mining tasks in a mathematical framework. Because of the size and complexity of the data sets, efficient algorithms and often crude approximations play an important role.",
    "cited_by_count": 81,
    "openalex_id": "https://openalex.org/W2131834667",
    "type": "article"
  },
  {
    "title": "The calculation of linear least squares problems",
    "doi": "https://doi.org/10.1017/s0962492904000169",
    "publication_date": "2004-05-01",
    "publication_year": 2004,
    "authors": "Åke Björck",
    "corresponding_authors": "Åke Björck",
    "abstract": "We first survey componentwise and normwise perturbation bounds for the standard least squares (LS) and minimum norm problems. Then some recent estimates of the optimal backward error for an alleged solution to an LS problem are presented. These results are particularly interesting when the algorithm used is not backward stable.The QR factorization and the singular value decomposition (SVD), developed in the 1960s and early 1970s, remain the basic tools for solving both the LS and the total least squares (TLS) problems. Current algorithms based on Householder or Gram-Schmidt QR factorizations are reviewed. The use of the SVD to determine the numerical rank of a matrix, as well as for computing a sequence of regularized solutions, is then discussed. The solution of the TLS problem in terms of the SVD of the compound matrix to upper bidiagonal form, this becomes a powerful tool for solving various LS and TLS problems. This bidiagonal decomposition gives a core regular subproblem for the TLS problem. When implemented by the Lanczos process it forms the kernel in the iterative method LSQR. It is also the basis of the partial least squares (PLS) method, which has become a standard tool in statistics.We present some generalized QR factorizations which can be used to solve different generalized least squares problems. Many applications lead to LS problems where the solution is subject to constraints. This includes linear equality and inequality constraints. Quadratic constraints are used to regularize solutions to discrete ill-posed LS problems. We survey these classes of problems and discuss their solution.As in all scientific computing, there is a trend that the size and complexity of the problems being solved is steadily growing. Large problems are often sparse or structured. Algorithms for the efficient solution of banded and block-angular LS problems are given, followed by a brief discussion of the general sparse case. Iterative methods are attractive, in particular when matrix-vector multiplication is cheap.",
    "cited_by_count": 74,
    "openalex_id": "https://openalex.org/W2128770615",
    "type": "article"
  },
  {
    "title": "Recent trends in the numerical solution of retarded functional differential equations",
    "doi": "https://doi.org/10.1017/s0962492906390010",
    "publication_date": "2009-05-01",
    "publication_year": 2009,
    "authors": "Alfredo Bellen; Stefano Maset; Marino Zennaro; Nicola Guglielmi",
    "corresponding_authors": "",
    "abstract": "Retarded functional differential equations (RFDEs) form a wide class of evolution equations which share the property that, at any point, the rate of the solution depends on a discrete or distributed set of values attained by the solution itself in the past. Thus the initial problem for RFDEs is an infinite-dimensional problem, taking its theoretical and numerical analysis beyond the classical schemes developed for differential equations with no functional elements. In particular, numerically solving initial problems for RFDEs is a diffcult task that cannot be founded on the mere adaptation of well-known methods for ordinary, partial or integro-differential equations to the presence of retarded arguments. Indeed, efficient codes for their numerical integration need speciffc approaches designed according to the nature of the equation and the behaviour of the solution. By defining the numerical method as a suitable approximation of the solution map of the given equation, we present an original and unifying theory for the convergence and accuracy analysis of the approximate solution. Two particular approaches, both inspired by Runge–Kutta methods, are described. Despite being apparently similar, they are intrinsically different. Indeed, in the presence of speciffc types of functionals on the right-hand side, only one of them can have an explicit character, whereas the other gives rise to an overall procedure which is implicit in any case, even for non-stiff problems. In the panorama of numerical RFDEs, some critical situations have been recently investigated in connection to speciffc classes of equations, such as the accurate location of discontinuity points, the termination and bifurcation of the solutions of neutral equations, with state-dependent delays, the regularization of the equation and the generalization of the solution behind possible termination points, and the treatment of equations stated in the implicit form, which include singularly perturbed problems and delay differential-algebraic equations as well. All these issues are tackled in the last three sections. In this paper we have not considered the important issue of stability, for which we refer the interested reader to the comprehensive book by Bellen and Zennaro (2003).",
    "cited_by_count": 53,
    "openalex_id": "https://openalex.org/W2070252545",
    "type": "article"
  },
  {
    "title": "Ensemble Kalman methods: A mean-field perspective",
    "doi": "https://doi.org/10.1017/s0962492924000060",
    "publication_date": "2025-07-01",
    "publication_year": 2025,
    "authors": "Edoardo Calvello; Stephanie Reich; Andrew M. Stuart",
    "corresponding_authors": "",
    "abstract": "Ensemble Kalman methods, introduced in 1994 in the context of ocean state estimation, are now widely used for state estimation and parameter estimation (inverse problems) in many arenae. Their success stems from the fact that they take an underlying computational model as a black box to provide a systematic, derivative-free methodology for incorporating observations; furthermore the ensemble approach allows for sensitivities and uncertainties to be calculated. Analysis of the accuracy of ensemble Kalman methods, especially in terms of uncertainty quantification, is lagging behind empirical success; this paper provides a unifying mean-field-based framework for their analysis. Both state estimation and parameter estimation problems are considered, and formulations in both discrete and continuous time are employed. For state estimation problems, both the control and filtering approaches are considered; analogously for parameter estimation problems, the optimization and Bayesian perspectives are both studied. As well as providing an elegant framework, the mean-field perspective also allows for the derivation of a variety of methods used in practice. In addition it unifies a wide-ranging literature in the field and suggests open problems.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4411917706",
    "type": "article"
  },
  {
    "title": "Acceleration methods for fixed-point iterations",
    "doi": "https://doi.org/10.1017/s0962492924000096",
    "publication_date": "2025-07-01",
    "publication_year": 2025,
    "authors": "Yousef Saad",
    "corresponding_authors": "Yousef Saad",
    "abstract": "A pervasive approach in scientific computing is to express the solution to a given problem as the limit of a sequence of vectors or other mathematical objects. In many situations these sequences are generated by slowly converging iterative procedures, and this led practitioners to seek faster alternatives to reach the limit. ‘Acceleration techniques’ comprise a broad array of methods specifically designed with this goal in mind. They started as a means of improving the convergence of general scalar sequences by various forms of ‘extrapolation to the limit’, i.e. by extrapolating the most recent iterates to the limit via linear combinations. Extrapolation methods of this type, the best-known of which is Aitken’s delta-squared process, require only the sequence of vectors as input. However, limiting methods to use only the iterates is too restrictive. Accelerating sequences generated by fixed-point iterations by utilizing both the iterates and the fixed-point mapping itself has proved highly successful across various areas of physics. A notable example of these fixed-point accelerators (FP-accelerators) is a method developed by Donald Anderson in 1965 and now widely known as Anderson acceleration (AA). Furthermore, quasi-Newton and inexact Newton methods can also be placed in this category since they can be invoked to find limits of fixed-point iteration sequences by employing exactly the same ingredients as those of the FP-accelerators. This paper presents an overview of these methods – with an emphasis on those, such as AA, that are geared toward accelerating fixed-point iterations. We will navigate through existing variants of accelerators, their implementations and their applications, to unravel the close connections between them. These connections were often not recognized by the originators of certain methods, who sometimes stumbled on slight variations of already established ideas. Furthermore, even though new accelerators were invented in different corners of science, the underlying principles behind them are strikingly similar or identical. The plan of this article will approximately follow the historical trajectory of extrapolation and acceleration methods, beginning with a brief description of extrapolation ideas, followed by the special case of linear systems, the application to self-consistent field (SCF) iterations, and a detailed view of Anderson acceleration. The last part of the paper is concerned with more recent developments, including theoretical aspects, and a few thoughts on accelerating machine learning algorithms.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4411917721",
    "type": "article"
  },
  {
    "title": "Particle Methods for the Boltzmann Equation",
    "doi": "https://doi.org/10.1017/s0962492900002579",
    "publication_date": "1995-01-01",
    "publication_year": 1995,
    "authors": "Helmut Neunzert; Jens Struckmeier",
    "corresponding_authors": "",
    "abstract": "In the following chapters we will discuss particle methods for the numerical simulation of rarefied gas flows. We will mainly treat a billiard game, that is, our particles will be hard spheres. But we will also touch upon cases where particles have internal energies due to rotation or vibration, which they exchange in a collision, and we will talk about chemical reactions happening during a collision. Due to the limited size of this paper, we are only able to mention the principles of these real-gas effects. On the other hand, the general concepts of particle methods to be presented may be used for other kinds of kinetic equations, such as the semiconductor device simulation. We leave this part of the research to subsequent papers.",
    "cited_by_count": 63,
    "openalex_id": "https://openalex.org/W2052051477",
    "type": "article"
  },
  {
    "title": "The New qd Algorithms",
    "doi": "https://doi.org/10.1017/s0962492900002580",
    "publication_date": "1995-01-01",
    "publication_year": 1995,
    "authors": "Beresford Ν. Parlett",
    "corresponding_authors": "Beresford Ν. Parlett",
    "abstract": "Let us think about ways to find both eigenvalues and eigenvectors of tridiagonal matrices. An important special case is the computation of singular values and singular vectors of bidiagonal matrices. The discussion is addressed both to specialists in matrix computation and to other scientists whose main interests lie elsewhere. The reason for hoping to communicate with two such diverse sets of readers at the same time is that the content of the survey, though of recent origin, is quite elementary and does not demand familiarity with much beyond triangular factorization and the Gram-Schmidt process for orthogonalizing a set of vectors. For some readers the survey will cover familiar territory but from a novel perspective. The justification for presenting these ideas is that they lead to new variations of current methods that run a lot faster while achieving greater accuracy.",
    "cited_by_count": 61,
    "openalex_id": "https://openalex.org/W2163901420",
    "type": "article"
  },
  {
    "title": "Wavelets",
    "doi": "https://doi.org/10.1017/s0962492900002233",
    "publication_date": "1992-01-01",
    "publication_year": 1992,
    "authors": "Ronald DeVore; Bradley J. Lucier",
    "corresponding_authors": "",
    "abstract": "The subject of ‘wavelets’ is expanding at such a tremendous rate that it is impossible to give, within these few pages, a complete introduction to all aspects of its theory. We hope, however, to allow the reader to become sufficiently acquainted with the subject to understand, in part, the enthusiasm of its proponents toward its potential application to various numerical problems. Furthermore, we hope that our exposition can guide the reader who wishes to make more serious excursions into the subject. Our viewpoint is biased by our experience in approximation theory and data compression; we warn the reader that there are other viewpoints that are either not represented here or discussed only briefly. For example, orthogonal wavelets were developed primarily in the context of signal processing, an application upon which we touch only indirectly. However, there are several good expositions (e.g. Daubechies (1990) and Rioul and Vetterli (1991)) of this application. A discussion of wavelet decompositions in the context of Littlewood-Paley theory can be found in the monograph of Frazier et al . (1991). We shall also not attempt to give a complete discussion of the history of wavelets. Historical accounts can be found in the book of Meyer (1990) and the introduction of the article of Daubechies (1990). We shall try to give sufficient historical commentary in the course of our presentation to provide some feeling for the subject's development.",
    "cited_by_count": 59,
    "openalex_id": "https://openalex.org/W4240594399",
    "type": "article"
  },
  {
    "title": "Molecular dynamics and the accuracy of numerically computed averages",
    "doi": "https://doi.org/10.1017/s0962492906280012",
    "publication_date": "2007-04-24",
    "publication_year": 2007,
    "authors": "Stephen Bond; Benedict Leimkuhler",
    "corresponding_authors": "",
    "abstract": "Molecular dynamics is discussed from a mathematical perspective. The recent history of method development is briefly surveyed with an emphasis on the use of geometric integration as a guiding principle. The recovery of statistical mechanical averages from molecular dynamics is then introduced, and the use of backward error analysis as a technique for analysing the accuracy of numerical averages is described. This article gives the first rigorous estimates for the error in statistical averages computed from molecular dynamics simulation based on backward error analysis. It is shown that molecular dynamics introduces an appreciable bias at stepsizes which are below the stability threshold. Simulations performed in such a regime can be corrected by use of a stepsize-dependent reweighting factor. Numerical experiments illustrate the efficacy of this approach. In the final section, several open problems in dynamics-based molecular sampling are considered.",
    "cited_by_count": 49,
    "openalex_id": "https://openalex.org/W2058727322",
    "type": "article"
  },
  {
    "title": "Modelling atmospheric flows",
    "doi": "https://doi.org/10.1017/s0962492906290019",
    "publication_date": "2007-04-24",
    "publication_year": 2007,
    "authors": "Mike Cullen",
    "corresponding_authors": "Mike Cullen",
    "abstract": "This article demonstrates how numerical methods for atmospheric models can be validated by showing that they give the theoretically predicted rate of convergence to relevant asymptotic limit solutions. This procedure is necessary because the exact solution of the Navier–Stokes equations cannot be resolved by production models. The limit solutions chosen are those most important for weather and climate prediction. While the best numerical algorithms for this purpose largely reflect current practice, some important limit solutions cannot be captured by existing methods. The use of Lagrangian rather than Eulerian averaging may be required in these cases.",
    "cited_by_count": 46,
    "openalex_id": "https://openalex.org/W2152775103",
    "type": "article"
  },
  {
    "title": "Finite volume methods for hyperbolic conservation laws",
    "doi": "https://doi.org/10.1017/s0962492906300013",
    "publication_date": "2007-04-24",
    "publication_year": 2007,
    "authors": "K. W. Morton; Thomas Sonar",
    "corresponding_authors": "",
    "abstract": "Finite volume methods apply directly to the conservation law form of a differential equation system; and they commonly yield cell average approximations to the unknowns rather than point values. The discrete equations that they generate on a regular mesh look rather like finite difference equations; but they are really much closer to finite element methods, sharing with them a natural formulation on unstructured meshes. The typical projection onto a piecewise constant trial space leads naturally into the theory of optimal recovery to achieve higher than first-order accuracy. They have dominated aerodynamics computation for over forty years, but they have never before been the subject of an Acta Numerica article. We shall therefore survey their early formulations before describing powerful developments in both their theory and practice that have taken place in the last few years.",
    "cited_by_count": 45,
    "openalex_id": "https://openalex.org/W1975648235",
    "type": "article"
  },
  {
    "title": "Numerical methods with controlled dissipation for small-scale dependent shocks",
    "doi": "https://doi.org/10.1017/s0962492914000099",
    "publication_date": "2014-05-01",
    "publication_year": 2014,
    "authors": "Philippe G. LeFloch; Siddhartha Mishra",
    "corresponding_authors": "",
    "abstract": "We provide a ‘user guide’ to the literature of the past twenty years concerning the modelling and approximation of discontinuous solutions to nonlinear hyperbolic systems that admit small-scale dependent shock waves. We cover several classes of problems and solutions: nonclassical undercompressive shocks, hyperbolic systems in nonconservative form, and boundary layer problems. We review the relevant models arising in continuum physics and describe the numerical methods that have been proposed to capture small-scale dependent solutions. In agreement with general well-posedness theory, small-scale dependent solutions are characterized by a kinetic relation, a family of paths , or an admissible boundary set . We provide a review of numerical methods (front-tracking schemes, finite difference schemes, finite volume schemes), which, at the discrete level, reproduce the effect of the physically meaningful dissipation mechanisms of interest in the applications. An essential role is played by the equivalent equation associated with discrete schemes, which is found to be relevant even for solutions containing shock waves.",
    "cited_by_count": 33,
    "openalex_id": "https://openalex.org/W2964266246",
    "type": "article"
  },
  {
    "title": "Computing quantum dynamics in the semiclassical regime",
    "doi": "https://doi.org/10.1017/s0962492920000033",
    "publication_date": "2020-05-01",
    "publication_year": 2020,
    "authors": "Caroline Lasser; Christian Lubich",
    "corresponding_authors": "",
    "abstract": "The semiclassically scaled time-dependent multi-particle Schr\\\"odinger equation describes, inter alia, quantum dynamics of nuclei in a molecule. It poses the combined computational challenges of high oscillations and high dimensions. This paper reviews and studies numerical approaches that are robust to the small semiclassical parameter. We present and analyse variationally evolving Gaussian wave packets, Hagedorn's semiclassical wave packets, continuous superpositions of both thawed and frozen Gaussians, and Wigner function approaches to the direct computation of expectation values of observables. Making good use of classical mechanics is essential for all these approaches. The arising aspects of time integration and high-dimensional quadrature are also discussed.",
    "cited_by_count": 26,
    "openalex_id": "https://openalex.org/W3003292238",
    "type": "article"
  },
  {
    "title": "Schwarz methods by domain truncation",
    "doi": "https://doi.org/10.1017/s0962492922000034",
    "publication_date": "2022-05-01",
    "publication_year": 2022,
    "authors": "Martin J. Gander; Hui Zhang",
    "corresponding_authors": "",
    "abstract": "Schwarz methods use a decomposition of the computational domain into subdomains and need to impose boundary conditions on the subdomain boundaries. In domain truncation one restricts the unbounded domain to a bounded computational domain and must also put boundary conditions on the computational domain boundaries. In both fields there are vast bodies of literature and research is very active and ongoing. It turns out to be fruitful to think of the domain decomposition in Schwarz methods as a truncation of the domain onto subdomains. Seminal precursors of this fundamental idea are papers by Hagstrom, Tewarson and Jazcilevich (1988), Després (1990) and Lions (1990). The first truly optimal Schwarz method that converges in a finite number of steps was proposed by Nataf (1993), and used precisely transparent boundary conditions as transmission conditions between subdomains. Approximating these transparent boundary conditions for fast convergence of Schwarz methods led to the development of optimized Schwarz methods – a name that has become common for Schwarz methods based on domain truncation. Compared to classical Schwarz methods, which use simple Dirichlet transmission conditions and have been successfully used in a wide range of applications, optimized Schwarz methods are much less well understood, mainly due to their more sophisticated transmission conditions. A key application of Schwarz methods with such sophisticated transmission conditions turned out to be time-harmonic wave propagation problems, because classical Schwarz methods simply do not work in this case. The past decade has given us many new Schwarz methods based on domain truncation. One review from an algorithmic perspective (Gander and Zhang 2019) showed the equivalence of many of these new methods to optimized Schwarz methods. The analysis of optimized Schwarz methods, however, is lagging behind their algorithmic development. The general abstract Schwarz framework cannot be used for the analysis of these methods, and thus there are many open theoretical questions about their convergence. Just as for practical multigrid methods, Fourier analysis has been instrumental for understanding the convergence of optimized Schwarz methods and for tuning their transmission conditions. Similar to local Fourier mode analysis in multigrid, the unbounded two-subdomain case is used as a model for Fourier analysis of optimized Schwarz methods due to its simplicity. Many aspects of the actual situation, e.g. boundary conditions of the original problem and the number of subdomains, were thus neglected in the unbounded two-subdomain analysis. While this gave important insight, new phenomena beyond the unbounded two-subdomain models were discovered. This present situation is the motivation for our survey: to give a comprehensive review and precise exploration of convergence behaviours of optimized Schwarz methods based on Fourier analysis, taking into account the original boundary conditions, many-subdomain decompositions and layered media. We consider as our model problem the operator $-\\Delta + \\eta $ in the diffusive case $\\eta&gt;0$ (screened Laplace equation) or the oscillatory case $\\eta &lt;0$ (Helmholtz equation), in order to show the fundamental difference in behaviour of Schwarz solvers for these problems. The transmission conditions we study include the lowest-order absorbing conditions (Robin), and also more advanced perfectly matched layers (PMLs), both developed first for domain truncation. Our intensive work over the last two years on this review has led to several new results presented here for the first time: in the bounded two-subdomain analysis for the Helmholtz equation, we see strong influence of the original boundary conditions imposed on the global problem on the convergence factor of the Schwarz methods, and the asymptotic convergence factors with small overlap can differ from the unbounded two-subdomain analysis. In the many-subdomain analysis, we find the scaling with the number of subdomains, e.g. when the subdomain size is fixed, robust convergence of the double-sweep Schwarz method for the free-space wave problem, either with fixed overlap and zeroth-order Taylor conditions or with a logarithmically growing PML, and we find that Schwarz methods with PMLs work like smoothers that converge faster for higher Fourier frequencies; in particular, for the free-space wave problem, plane waves (in the error) passing through interfaces at a right angle converge more slowly. In addition to our main focus on analysis in Sections 2 and 3, we start in Section 1 with an expository historical introduction to Schwarz methods, and in Section 4 we give a brief interpretation of the recently proposed optimal Schwarz methods for decompositions with cross-points from the viewpoint of transmission conditions. We conclude in Section 5 with a summary of open research problems. In Appendix A we provide a Matlab program for a block LU form of an optimal Schwarz method with cross-points, and in Appendix B we give the Maple program for the two-subdomain Fourier analysis.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W4281611113",
    "type": "article"
  },
  {
    "title": "Aspects of the numerical analysis of neural networks",
    "doi": "https://doi.org/10.1017/s0962492900002439",
    "publication_date": "1994-01-01",
    "publication_year": 1994,
    "authors": "S. W. Ellacott",
    "corresponding_authors": "S. W. Ellacott",
    "abstract": "This article starts with a brief introduction to neural networks for those unfamiliar with the basic concepts, together with a very brief overview of mathematical approaches to the subject. This is followed by a more detailed look at three areas of research which are of particular interest to numerical analysts. The first area is approximation theory. If K is a compact set in ℝ n , for some n , then it is proved that a semilinear feedforward network with one hidden layer can uniformly approximate any continuous function in C ( K ) to any required accuracy. A discussion of known results and open questions on the degree of approximation is included. We also consider the relevance of radial basis functions to neural networks. The second area considered is that of learning algorithms. A detailed analysis of one popular algorithm (the delta rule) will be given, indicating why one implementation leads to a stable numerical process, whereas an initially attractive variant (essentially a form of steepest descent) does not. Similar considerations apply to the backpropagation algorithm. The effect of filtering and other preprocessing of the input data will also be discussed systematically. Finally some applications of neural networks to numerical computation are considered.",
    "cited_by_count": 54,
    "openalex_id": "https://openalex.org/W2126001294",
    "type": "article"
  },
  {
    "title": "Topological techniques for efficient rigorous computation in dynamics",
    "doi": "https://doi.org/10.1017/s0962492902000065",
    "publication_date": "2002-01-01",
    "publication_year": 2002,
    "authors": "Konstantin Mischaikow",
    "corresponding_authors": "Konstantin Mischaikow",
    "abstract": "We describe topological methods for the efficient, rigorous computation of dynamical systems. In particular, we indicate how Conley's Fundamental Decomposition Theorem is naturally related to combinatorial approximations of dynamical systems. Furthermore, we show that computations of Morse decompositions and isolating blocks can be performed efficiently. We conclude with examples indicating how these ideas can be applied to finite- and infinite-dimensional discrete and continuous dynamical systems.",
    "cited_by_count": 52,
    "openalex_id": "https://openalex.org/W2011095097",
    "type": "article"
  },
  {
    "title": "Finite element solution of the Navier—Stokes equations",
    "doi": "https://doi.org/10.1017/s0962492900002373",
    "publication_date": "1993-01-01",
    "publication_year": 1993,
    "authors": "Michel Fortin",
    "corresponding_authors": "Michel Fortin",
    "abstract": "Viscous incompressible flows are of considerable interest for applications. Let us mention, for example, the design of hydraulic turbines or rheologically complex flows appearing in many processes involving plastics or molten metals. Their simulation raises a number of difficulties, some of which are likely to remain while others are now resolved. Among the latter are those related to incompressibility which are also present in the simulation of incompressible or nearly incompressible elastic materials. Among the still unresolved are those associated with high Reynolds numbers which are also met in compressible flows. They involve the formation of boundary layers and turbulence, an ever present phenomenon in fluid mechanics, implying that we have to simulate unsteady, highly unstable phenomena.",
    "cited_by_count": 47,
    "openalex_id": "https://openalex.org/W2120893653",
    "type": "article"
  },
  {
    "title": "Total variation and level set methods in image science",
    "doi": "https://doi.org/10.1017/s0962492904000273",
    "publication_date": "2005-04-19",
    "publication_year": 2005,
    "authors": "Yen‐Hsi Richard Tsai; Stanley Osher",
    "corresponding_authors": "",
    "abstract": "We review level set methods and the related techniques that are common in many PDE-based image models. Many of these techniques involve minimizing the total variation of the solution and admit regularizations on the curvature of its level sets. We examine the scope of these techniques in image science, in particular in image segmentation, interpolation, and decomposition, and introduce some relevant level set techniques that are useful for this class of applications. Many of the standard problems are formulated as variational models. We observe increasing synergistic progression of new tools and ideas between the inverse problem community and the ‘imagers’. We show that image science demands multi-disciplinary knowledge and flexible, but still robust methods. That is why the level set method and total variation methods have become thriving techniques in this field. Our goal is to survey recently developed techniques in various fields of research that are relevant to diverse objectives in image science. We begin by reviewing some typical PDE-based applications in image processing. In typical PDE methods, images are assumed to be continuous functions sampled on a grid. We will show that these methods all share a common feature, which is the emphasis on processing the level lines of the underlying image. The importance of level lines has been known for some time. See, e.g. , Alvarez, Guichard, Morel and Lions (1993). This feature places our slightly general definition of the level set method for image science in context. In Section 2 we describe the building blocks of a typical level set method in the continuum setting. Each important task that we need to do is formulated as the solution to certain PDEs. Then, in Section 3, we briefly describe the finite difference methods developed to construct approximate solutions to these PDEs. Some approaches to interpolation into small subdomains of an image are reviewed in Section 4. In Section 5 we describe the Chan–Vese segmentation algorithm and two new fast implementation methods. Finally, in Section 6, we describe some new techniques developed in the level set community.",
    "cited_by_count": 46,
    "openalex_id": "https://openalex.org/W2070014465",
    "type": "article"
  },
  {
    "title": "Numerical linear algebra in data mining",
    "doi": "https://doi.org/10.1017/s0962492906240017",
    "publication_date": "2006-05-01",
    "publication_year": 2006,
    "authors": "Lars Eldén",
    "corresponding_authors": "Lars Eldén",
    "abstract": "Ideas and algorithms from numerical linear algebra are important in several areas of data mining. We give an overview of linear algebra methods in text mining (information retrieval), pattern recognition (classification of handwritten digits), and PageRank computations for web search engines. The emphasis is on rank reduction as a method of extracting information from a data matrix, low-rank approximation of matrices using the singular value decomposition and clustering, and on eigenvalue methods for network analysis.",
    "cited_by_count": 42,
    "openalex_id": "https://openalex.org/W2098972539",
    "type": "article"
  },
  {
    "title": "Accurate and efficient expression evaluation and linear algebra",
    "doi": "https://doi.org/10.1017/s0962492906350015",
    "publication_date": "2008-04-25",
    "publication_year": 2008,
    "authors": "James Demmel; Ioana Dumitriu; Olga Holtz; Plamen Koev",
    "corresponding_authors": "",
    "abstract": "We survey and unify recent results on the existence of accurate algorithms for evaluating multivariate polynomials, and more generally for accurate numerical linear algebra with structured matrices. By ‘accurate’ we mean that the computed answer has relative error less than 1, i.e. , has some correct leading digits. We also address efficiency, by which we mean algorithms that run in polynomial time in the size of the input. Our results will depend strongly on the model of arithmetic: most of our results will use the so-called traditional model (TM), where the computed result of op( a , b ), a binary operation like a + b , is given by op( a , b ) * (1+δ) where all we know is that |δ| ≤ ε ≪ 1. Here ε is a constant also known as machine epsilon. We will see a common reason for the following disparate problems to permit accurate and efficient algorithms using only the four basic arithmetic operations: finding the eigenvalues of a suitably discretized scalar elliptic PDE, finding eigenvalues of arbitrary products, inverses, or Schur complements of totally non-negative matrices (such as Cauchy and Vandermonde), and evaluating the Motzkin polynomial. Furthermore, in all these cases the high accuracy is ‘deserved’, i.e. , the answer is determined much more accurately by the data than the conventional condition number would suggest. In contrast, we will see that evaluating even the simple polynomial x + y + z accurately is impossible in the TM, using only the basic arithmetic operations. We give a set of necessary and sufficient conditions to decide whether a high accuracy algorithm exists in the TM, and describe progress toward a decision procedure that will take any problem and provide either a high-accuracy algorithm or a proof that none exists. When no accurate algorithm exists in the TM, it is natural to extend the set of available accurate operations by a library of additional operations, such as x + y + z , dot products, or indeed any enumerable set which could then be used to build further accurate algorithms. We show how our accurate algorithms and decision procedure for finding them extend to this case. Finally, we address other models of arithmetic, and the relationship between (im)possibility in the TM and (in)efficient algorithms operating on numbers represented as bit strings.",
    "cited_by_count": 37,
    "openalex_id": "https://openalex.org/W2156792823",
    "type": "article"
  },
  {
    "title": "Approximation algorithms in combinatorial scientific computing",
    "doi": "https://doi.org/10.1017/s0962492919000035",
    "publication_date": "2019-05-01",
    "publication_year": 2019,
    "authors": "Alex Pothen; S M Ferdous; Fredrik Manne",
    "corresponding_authors": "",
    "abstract": "We survey recent work on approximation algorithms for computing degree-constrained subgraphs in graphs and their applications in combinatorial scientific computing. The problems we consider include maximization versions of cardinality matching, edge-weighted matching, vertex-weighted matching and edge-weighted $b$ -matching, and minimization versions of weighted edge cover and $b$ -edge cover. Exact algorithms for these problems are impractical for massive graphs with several millions of edges. For each problem we discuss theoretical foundations, the design of several linear or near-linear time approximation algorithms, their implementations on serial and parallel computers, and applications. Our focus is on practical algorithms that yield good performance on modern computer architectures with multiple threads and interconnected processors. We also include information about the software available for these problems.",
    "cited_by_count": 26,
    "openalex_id": "https://openalex.org/W2950905676",
    "type": "article"
  },
  {
    "title": "Numerical methods in tomography",
    "doi": "https://doi.org/10.1017/s0962492900002907",
    "publication_date": "1999-01-01",
    "publication_year": 1999,
    "authors": "Frank Natterer",
    "corresponding_authors": "Frank Natterer",
    "abstract": "In this article we review the image reconstruction algorithms used in tomography. We restrict ourselves to the standard problems in the reconstruction of function from line or plane integrals as they occur in X-ray tomography, nuclear medicine, magnetic resonance imaging, and electron microscopy. Nonstandard situations, such as incomplete data, unknown orientations, local tomography, and discrete tomography are not dealt with. Nor do we treat nonlinear tomographic techniques such as impedance, ultrasound, and near-infrared imaging.",
    "cited_by_count": 48,
    "openalex_id": "https://openalex.org/W2126124940",
    "type": "article"
  },
  {
    "title": "Numerical Solutions to Free Boundary Problems",
    "doi": "https://doi.org/10.1017/s0962492900002567",
    "publication_date": "1995-01-01",
    "publication_year": 1995,
    "authors": "Thomas Y. Hou",
    "corresponding_authors": "Thomas Y. Hou",
    "abstract": "Many physically interesting problems involve propagation of free surfaces. Vortex-sheet roll-up in hydrodynamic instability, wave interactions on the ocean's free surface, the solidification problem for crystal growth and Hele-Shaw cells for pattern formation are some of the significant examples. These problems present a great challenge to physicists and applied mathematicians because the underlying problem is very singular. The physical solution is sensitive to small perturbations. Naïve discretisations may lead to numerical instabilities. Other numerical difficulties include singularity formation and possible change of topology in the moving free surfaces, and the severe time-stepping stability constraint due to the stiffness of high-order regularisation effects, such as surface tension. This paper reviews some of the recent advances in developing stable and efficient numerical algorithms for solving free boundary-value problems arising from fluid dynamics and materials science. In particular, we will consider boundary integral methods and the level-set approach for water waves, general multi-fluid interfaces, Hele–Shaw cells, crystal growth and solidification. We will also consider the stabilising effect of surface tension and curvature regularisation. The issue of numerical stability and convergence will be discussed, and the related theoretical results for the continuum equations will be addressed. This paper is not intended to be a detailed survey and the discussion is limited by both the taste and expertise of the author.",
    "cited_by_count": 42,
    "openalex_id": "https://openalex.org/W2098012793",
    "type": "article"
  },
  {
    "title": "Computational methods for semiclassical and quantum transport in semiconductor devices",
    "doi": "https://doi.org/10.1017/s0962492900002762",
    "publication_date": "1997-01-01",
    "publication_year": 1997,
    "authors": "Christian Ringhofer",
    "corresponding_authors": "Christian Ringhofer",
    "abstract": "The progressive miniaturization of semiconductor devices, and the use of bulk materials other than silicon, necessitates the use of a wide variety of models in semiconductor device simulation. These include classical and semiclassical models, such as the Boltzmann equation and the hydrodynamic system, as well as quantum transport models such as the quantum Boltzmann equation and the quantum hydrodynamic system. This paper gives an overview of recently developed numerical methods for these systems. The focus is on Galerkin methods for the semiclassical and quantum kinetic systems and on difference methods for the classical and quantum hydrodynamic systems. The stability and convergence properties of these methods and their relation to the analytical properties of the continuous systems are discussed.",
    "cited_by_count": 42,
    "openalex_id": "https://openalex.org/W2162140009",
    "type": "article"
  },
  {
    "title": "Multivariate piecewise polynomials",
    "doi": "https://doi.org/10.1017/s0962492900002348",
    "publication_date": "1993-01-01",
    "publication_year": 1993,
    "authors": "Carl de Boor",
    "corresponding_authors": "Carl de Boor",
    "abstract": "This article was supposed to be on ‘multivariate splines». An informal survey, taken recently by asking various people in Approximation Theory what they consider to be a ‘multivariate spline’, resulted in the answer that a multivariate spline is a possibly smooth piecewise polynomial function of several arguments. In particular the potentially very useful thin-plate spline was thought to belong more to the subject of radial basis funtions than in the present article. This is all the more surprising to me since I am convinced that the variational approach to splines will play a much greater role in multivariate spline theory than it did or should have in the univariate theory. Still, as there is more than enough material for a survey of multivariate piecewise polynomials, this article is restricted to this topic, as is indicated by the (changed) title.",
    "cited_by_count": 39,
    "openalex_id": "https://openalex.org/W2133973990",
    "type": "article"
  },
  {
    "title": "A Taste of Padé Approximation",
    "doi": "https://doi.org/10.1017/s096249290000252x",
    "publication_date": "1995-01-01",
    "publication_year": 1995,
    "authors": "Claude Brezinski; Ufr Ieea; Jeannette Van Iseghem",
    "corresponding_authors": "",
    "abstract": "The aim of this paper is to provide an introduction to Padé approximation and related topics. The emphasis is put on questions relevant to numerical analysis and applications.",
    "cited_by_count": 35,
    "openalex_id": "https://openalex.org/W1995027698",
    "type": "article"
  },
  {
    "title": "Problems with different time scales",
    "doi": "https://doi.org/10.1017/s0962492900002257",
    "publication_date": "1992-01-01",
    "publication_year": 1992,
    "authors": "Heinz‐Otto Kreiss",
    "corresponding_authors": "Heinz‐Otto Kreiss",
    "abstract": "In this section we discuss a very simple problem. Consider the scalar initial value problem Here ε &gt; 0 is a small constant and a = a 1 + i a 2 , a 1 , a 2 real, is a complex number with | a | = 1. We can write down the solution of (1.1) explicity. It is where is the forced solution and is a solution of the homogeneous equation y S varies on the time scale ‘1’ while y F varies on the much faster scale 1/ε. We say that y S , y F vary on the slow and fast scale, respectively. We use also the phrase: y S and y F are the slow and the fast part of the solution, respectively.",
    "cited_by_count": 33,
    "openalex_id": "https://openalex.org/W3023125581",
    "type": "article"
  },
  {
    "title": "Continuous dependence and error estimation for viscosity methods",
    "doi": "https://doi.org/10.1017/s0962492902000107",
    "publication_date": "2003-05-01",
    "publication_year": 2003,
    "authors": "Bernardo Cockburn",
    "corresponding_authors": "Bernardo Cockburn",
    "abstract": "In this paper, we review some ideas on continuous dependence results for the entropy solution of hyperbolic scalar conservation laws. They lead to a complete L^\\infty(L^1) -approximation theory with which error estimates for numerical methods for this type of equation can be obtained. The approach we consider consists in obtaining continuous dependence results for the solutions of parabolic conservation laws and deducing from them the corresponding results for the entropy solution. This is a natural approach, as the entropy solution is nothing but the limit of solutions of parabolic scalar conservation laws as the viscosity coefficient goes to zero.",
    "cited_by_count": 32,
    "openalex_id": "https://openalex.org/W1988934539",
    "type": "article"
  },
  {
    "title": "The numerical analysis of functional integral and integro-differential equations of Volterra type",
    "doi": "https://doi.org/10.1017/s0962492904000170",
    "publication_date": "2004-05-01",
    "publication_year": 2004,
    "authors": "Hermann Brunner",
    "corresponding_authors": "Hermann Brunner",
    "abstract": "The qualitative and quantitative analysis of numerical methods for delay differential equations is now quite well understood, as reflected in the recent monograph by Bellen and Zennaro (2003). This is in remarkable contrast to the situation in the numerical analysis of functional equations, in which delays occur in connection with memory terms described by Volterra integral operators. The complexity of the convergence and asymptotic stability analyses has its roots in new ‘dimensions’ not present in DDEs: the problems have distributed delays; kernels in the Volterra operators may be weakly singular; a second discretization step (approximation of the memory term by feasible quadrature processes) will in general be necessary before solution approximations can be computed. The purpose of this review is to introduce the reader to functional integral and integro-differential equations of Volterra type and their discretization, focusing on collocation techniques; to describe the ‘state of the art’ in the numerical analysis of such problems; and to show that – especially for many ‘classical’ equations whose analysis dates back more than 100 years – we still have a long way to go before we reach a level of insight into their discretized versions to compare with that achieved for DDEs.",
    "cited_by_count": 29,
    "openalex_id": "https://openalex.org/W2274863082",
    "type": "article"
  },
  {
    "title": "Mathematical cancer therapy planning in deep regional hyperthermia",
    "doi": "https://doi.org/10.1017/s0962492912000049",
    "publication_date": "2012-04-19",
    "publication_year": 2012,
    "authors": "Peter Deuflhard; Anton Schiela; Martin Weiser",
    "corresponding_authors": "",
    "abstract": "This paper surveys the mathematics required for a typically challenging problem from computational medicine: cancer therapy planning in deep regional hyperthermia. In the course of many years of close cooperation with clinics, the medical problem has given rise to many subtle mathematical problems, some of which were unsolved when the project started. Efficiency of numerical algorithms, i.e. , computational speed and monitored reliability, plays a decisive role in the medical treatment. Off-the-shelf software had turned out to be insufficient to meet the requirements of medicine. Instead, new mathematical theory as well as new numerical algorithms had to be developed. In order to make our algorithms useful in the clinical environment, new visualization software, i.e. , a ‘virtual lab’, including three-dimensional geometry processing of individual virtual patients, had to be designed and implemented. Moreover, before the problems could be attacked by numerical algorithms, careful mathematical modelling had to be done. Finally, parameter identification and constrained optimization for the PDEs had to be newly analysed and realized over the individual patient's geometry. Our new techniques had an impact on the specificity of the treatment of individual patients and on the construction of an improved hyperthermia applicator.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W2086491906",
    "type": "article"
  },
  {
    "title": "Numerical modelling of ocean circulation",
    "doi": "https://doi.org/10.1017/s0962492906250013",
    "publication_date": "2006-05-01",
    "publication_year": 2006,
    "authors": "Robert L. Higdon",
    "corresponding_authors": "Robert L. Higdon",
    "abstract": "Computational simulations of ocean circulation rely on the numerical solution of partial differential equations of fluid dynamics, as applied to a relatively thin layer of stratified fluid on a rotating globe. This paper describes some of the physical and mathematical properties of the solutions being sought, some of the issues that are encountered when the governing equations are solved numerically, and some of the numerical methods that are being used in this area.",
    "cited_by_count": 25,
    "openalex_id": "https://openalex.org/W2076045637",
    "type": "article"
  },
  {
    "title": "Linear algebra software for large-scale accelerated multicore computing",
    "doi": "https://doi.org/10.1017/s0962492916000015",
    "publication_date": "2016-05-01",
    "publication_year": 2016,
    "authors": "Ahmad Abdelfattah; Hartwig Anzt; Jack Dongarra; Mark Gates; Azzam Haidar; Jakub Kurzak; Piotr Łuszczek; Stanimire Tomov; Ichitaro Yamazaki; Asim YarKhan",
    "corresponding_authors": "",
    "abstract": "Many crucial scientific computing applications, ranging from national security to medical advances, rely on high-performance linear algebra algorithms and technologies, underscoring their importance and broad impact. Here we present the state-of-the-art design and implementation practices for the acceleration of the predominant linear algebra algorithms on large-scale accelerated multicore systems. Examples are given with fundamental dense linear algebra algorithms – from the LU, QR, Cholesky, and LDLT factorizations needed for solving linear systems of equations, to eigenvalue and singular value decomposition (SVD) problems. The implementations presented are readily available via the open-source PLASMA and MAGMA libraries, which represent the next generation modernization of the popular LAPACK library for accelerated multicore systems. To generate the extreme level of parallelism needed for the efficient use of these systems, algorithms of interest are redesigned and then split into well-chosen computational tasks. The task execution is scheduled over the computational components of a hybrid system of multicore CPUs with GPU accelerators and/or Xeon Phi coprocessors, using either static scheduling or light-weight runtime systems. The use of light-weight runtime systems keeps scheduling overheads low, similar to static scheduling, while enabling the expression of parallelism through sequential-like code. This simplifies the development effort and allows exploration of the unique strengths of the various hardware components. Finally, we emphasize the development of innovative linear algebra algorithms using three technologies – mixed precision arithmetic, batched operations, and asynchronous iterations – that are currently of high interest for accelerated multicore systems.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2407804532",
    "type": "article"
  },
  {
    "title": "The Moment-SOS hierarchy: Applications and related topics",
    "doi": "https://doi.org/10.1017/s0962492923000053",
    "publication_date": "2024-07-01",
    "publication_year": 2024,
    "authors": "Jean B. Lasserre",
    "corresponding_authors": "Jean B. Lasserre",
    "abstract": "The Moment-SOS hierarchy, first introduced in optimization in 2000, is based on the theory of the S -moment problem and its dual counterpart: polynomials that are positive on S . It turns out that this methodology can also be used to solve problems with positivity constraints ‘ f (x) ≥ 0 for all $\\mathbf{x}\\in S$ ’ or linear constraints on Borel measures. Such problems can be viewed as specific instances of the generalized moment problem (GMP), whose list of important applications in various domains of science and engineering is almost endless. We describe this methodology in optimization and also in two other applications for illustration. Finally we also introduce the Christoffel function and reveal its links with the Moment-SOS hierarchy and positive polynomials.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4386623328",
    "type": "article"
  },
  {
    "title": "Iterative solution of systems of linear differential equations",
    "doi": "https://doi.org/10.1017/s096249290000266x",
    "publication_date": "1996-01-01",
    "publication_year": 1996,
    "authors": "Ulla Miekkala; Olavi Nevanlinna",
    "corresponding_authors": "",
    "abstract": "Parallel processing has made iterative methods an attractive alternative for solving large systems of initial value problems. Iterative methods for initial value problems have a history of more than a century, and in the works of Picard (1893) and Lindelöf (1894) they were given a firm theoretical basis. In particular, the superlinear convergence on finite intervals is included in Lindelöf (1894).",
    "cited_by_count": 27,
    "openalex_id": "https://openalex.org/W2079095130",
    "type": "article"
  },
  {
    "title": "Numerical aspects of special functions",
    "doi": "https://doi.org/10.1017/s0962492906330012",
    "publication_date": "2007-04-24",
    "publication_year": 2007,
    "authors": "Nico Μ. Τemme",
    "corresponding_authors": "Nico Μ. Τemme",
    "abstract": "This paper describes methods that are important for the numerical evaluation of certain functions that frequently occur in applied mathematics, physics and mathematical statistics. This includes what we consider to be the basic methods, such as recurrence relations, series expansions (both convergent and asymptotic), and numerical quadrature. Several other methods are available and some of these will be discussed in less detail. Examples will be given on the use of special functions in certain problems from mathematical physics and mathematical statistics (integrals and series with special functions).",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W2569314303",
    "type": "article"
  },
  {
    "title": "Cut finite element methods",
    "doi": "https://doi.org/10.1017/s0962492925000017",
    "publication_date": "2025-07-01",
    "publication_year": 2025,
    "authors": "Erik Burman; Peter Hansbo; Mats G. Larson; Sara Zahedi",
    "corresponding_authors": "",
    "abstract": "Cut finite element methods (CutFEM) extend the standard finite element method to unfitted meshes, enabling the accurate resolution of domain boundaries and interfaces without requiring the mesh to conform to them. This approach preserves the key properties and accuracy of the standard method while addressing challenges posed by complex geometries and moving interfaces. In recent years, CutFEM has gained significant attention for its ability to discretize partial differential equations in domains with intricate geometries. This paper provides a comprehensive review of the core concepts and key developments in CutFEM, beginning with its formulation for common model problems and the presentation of fundamental analytical results, including error estimates and condition number estimates for the resulting algebraic systems. Stabilization techniques for cut elements, which ensure numerical robustness, are also explored. Finally, extensions to methods involving Lagrange multipliers and applications to time-dependent problems are discussed.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4411917698",
    "type": "article"
  },
  {
    "title": "Optimization problems governed by systems of PDEs with uncertainties",
    "doi": "https://doi.org/10.1017/s0962492925000029",
    "publication_date": "2025-07-01",
    "publication_year": 2025,
    "authors": "Matthias Heinkenschloss; Drew Kouri",
    "corresponding_authors": "",
    "abstract": "This paper reviews current theoretical and numerical approaches to optimization problems governed by partial differential equations (PDEs) that depend on random variables or random fields. Such problems arise in many engineering, science, economics and societal decision-making tasks. This paper focuses on problems in which the governing PDEs are parametrized by the random variables/fields, and the decisions are made at the beginning and are not revised once uncertainty is revealed. Examples of such problems are presented to motivate the topic of this paper, and to illustrate the impact of different ways to model uncertainty in the formulations of the optimization problem and their impact on the solution. A linear–quadratic elliptic optimal control problem is used to provide a detailed discussion of the set-up for the risk-neutral optimization problem formulation, study the existence and characterization of its solution, and survey numerical methods for computing it. Different ways to model uncertainty in the PDE-constrained optimization problem are surveyed in an abstract setting, including risk measures, distributionally robust optimization formulations, probabilistic functions and chance constraints, and stochastic orders. Furthermore, approximation-based optimization approaches and stochastic methods for the solution of the large-scale PDE-constrained optimization problems under uncertainty are described. Some possible future research directions are outlined.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4411917701",
    "type": "article"
  },
  {
    "title": "The discontinuous Petrov–Galerkin method",
    "doi": "https://doi.org/10.1017/s0962492924000102",
    "publication_date": "2025-07-01",
    "publication_year": 2025,
    "authors": "Leszek Demkowicz; Jay Gopalakrishnan",
    "corresponding_authors": "",
    "abstract": "The discontinuous Petrov–Galerkin (DPG) method is a Petrov–Galerkin finite element method with test functions designed for obtaining stability. These test functions are computable locally, element by element, and are motivated by optimal test functions which attain the supremum in an inf-sup condition. A profound consequence of the use of nearly optimal test functions is that the DPG method can inherit the stability of the (undiscretized) variational formulation, be it coercive or not. This paper combines a presentation of the fundamentals of the DPG ideas with a review of the ongoing research on theory and applications of the DPG methodology. The scope of the presented theory is restricted to linear problems on Hilbert spaces, but pointers to extensions are provided. Multiple viewpoints to the basic theory are provided. They show that the DPG method is equivalent to a method which minimizes a residual in a dual norm, as well as to a mixed method where one solution component is an approximate error representation function. Being a residual minimization method, the DPG method yields Hermitian positive definite stiffness matrix systems even for non-self-adjoint boundary value problems. Having a built-in error representation, the method has the out-of-the-box feature that it can immediately be used in automatic adaptive algorithms. Contrary to standard Galerkin methods, which are uninformed about test and trial norms, the DPG method must be equipped with a concrete test norm which enters the computations. Of particular interest are variational formulations in which one can tailor the norm to obtain robust stability. Key techniques to rigorously prove convergence of DPG schemes, including construction of Fortin operators, which in the DPG case can be done element by element, are discussed in detail. Pointers to open frontiers are presented.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4411917711",
    "type": "article"
  },
  {
    "title": "Time parallelization for hyperbolic and parabolic problems",
    "doi": "https://doi.org/10.1017/s0962492924000072",
    "publication_date": "2025-07-01",
    "publication_year": 2025,
    "authors": "Martin J. Gander; Shu‐Lin Wu; Tao Zhou",
    "corresponding_authors": "",
    "abstract": "Time parallelization, also known as PinT (parallel-in-time), is a new research direction for the development of algorithms used for solving very large-scale evolution problems on highly parallel computing architectures. Despite the fact that interesting theoretical work on PinT appeared as early as 1964, it was not until 2004, when processor clock speeds reached their physical limit, that research in PinT took off. A distinctive characteristic of parallelization in time is that information flow only goes forward in time, meaning that time evolution processes seem necessarily to be sequential. Nevertheless, many algorithms have been developed for PinT computations over the past two decades, and they are often grouped into four basic classes according to how the techniques work and are used: shooting-type methods; waveform relaxation methods based on domain decomposition; multigrid methods in space–time; and direct time parallel methods. However, over the past few years, it has been recognized that highly successful PinT algorithms for parabolic problems struggle when applied to hyperbolic problems. We will therefore focus on this important aspect, first by providing a summary of the fundamental differences between parabolic and hyperbolic problems for time parallelization. We then group PinT algorithms into two basic groups. The first group contains four effective PinT techniques for hyperbolic problems: Schwarz waveform relaxation (SWR) with its relation to tent pitching; parallel integral deferred correction; ParaExp; and ParaDiag. While the methods in the first group also work well for parabolic problems, we then present PinT methods specifically designed for parabolic problems in the second group: Parareal; the parallel full approximation scheme in space–time (PFASST); multigrid reduction in time (MGRiT); and space–time multigrid (STMG). We complement our analysis with numerical illustrations using four time-dependent PDEs: the heat equation; the advection–diffusion equation; Burgers’ equation; and the second-order wave equation.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4411917713",
    "type": "article"
  },
  {
    "title": "Sparse linear least-squares problems",
    "doi": "https://doi.org/10.1017/s0962492924000059",
    "publication_date": "2025-07-01",
    "publication_year": 2025,
    "authors": "J. A. Scott; Miroslav Tůma",
    "corresponding_authors": "",
    "abstract": "Least-squares problems are a cornerstone of computational science and engineering. Over the years, the size of the problems that researchers and practitioners face has constantly increased, making it essential that sparsity is exploited in the solution process. The goal of this article is to present a broad review of key algorithms for solving large-scale linear least-squares problems. This includes sparse direct methods and algebraic preconditioners that are used in combination with iterative solvers. Where software is available, this is highlighted.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4411917729",
    "type": "article"
  },
  {
    "title": "Choice of norms for data fitting and function approximation",
    "doi": "https://doi.org/10.1017/s0962492900002853",
    "publication_date": "1998-01-01",
    "publication_year": 1998,
    "authors": "G. A. Watson",
    "corresponding_authors": "G. A. Watson",
    "abstract": "For the approximation of functions and data, it is often appropriate to minimize a norm. Many norms have been considered, and a review is presented of methods for solving a range of problems using a wide variety of norms.",
    "cited_by_count": 25,
    "openalex_id": "https://openalex.org/W2000550690",
    "type": "article"
  },
  {
    "title": "Automatic grid generation",
    "doi": "https://doi.org/10.1017/s0962492900002634",
    "publication_date": "1996-01-01",
    "publication_year": 1996,
    "authors": "William D. Henshaw",
    "corresponding_authors": "William D. Henshaw",
    "abstract": "Current methods for the automatic generation of grids are reviewed. The approaches to grid generation that are discussed include Cartesian, multi-block-structured, overlapping and unstructured. Emphasis is placed on those methods that can create high-quality grids appropriate for the solution of equations of a hyperbolic nature, such as those that arise in fluid dynamics. Numerous figures illustrate the different grid generation techniques.",
    "cited_by_count": 25,
    "openalex_id": "https://openalex.org/W2032477593",
    "type": "article"
  },
  {
    "title": "Optimal transportation, modelling and numerical simulation",
    "doi": "https://doi.org/10.1017/s0962492921000040",
    "publication_date": "2021-05-01",
    "publication_year": 2021,
    "authors": "Jean‐David Benamou",
    "corresponding_authors": "Jean‐David Benamou",
    "abstract": "We present an overviewof the basic theory, modern optimal transportation extensions and recent algorithmic advances. Selected modelling and numerical applications illustrate the impact of optimal transportation in numerical analysis.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W3207466733",
    "type": "article"
  },
  {
    "title": "Stability for time-dependent differential equations",
    "doi": "https://doi.org/10.1017/s096249290000283x",
    "publication_date": "1998-01-01",
    "publication_year": 1998,
    "authors": "Heinz‐Otto Kreiss; Jens Lorenz",
    "corresponding_authors": "",
    "abstract": "In this paper we review results on asymptotic stability of stationary states of PDEs. After scaling, our normal form is u t = P u + ε f ( u, u x ,…) + F ( x, t ), where the (vector-valued) function u ( x, t ) depends on the space variable x and time t. The differential operator P is linear, F ( x, t ) is a smooth forcing, which decays to zero for t → ∞, and ε f ( u , …) is a nonlinear perturbation. We will discuss conditions that ensure u → 0 for t → ∞ when |ε| is sufficiently small. If this holds, we call the problem asymptotically stable. While there are many approaches to show asymptotic stability, we mainly concentrate on the resolvent technique. However, comparisons with the Lyapunov technique will also be given. The emphasis on the resolvent technique is motivated by the recent interest in pseudospectra.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W2106871975",
    "type": "article"
  },
  {
    "title": "Linear optimization over homogeneous matrix cones",
    "doi": "https://doi.org/10.1017/s0962492922000113",
    "publication_date": "2023-05-01",
    "publication_year": 2023,
    "authors": "Levent Tunçel; Lieven Vandenberghe",
    "corresponding_authors": "",
    "abstract": "A convex cone is homogeneous if its automorphism group acts transitively on the interior of the cone. Cones that are homogeneous and self-dual are called symmetric. Conic optimization problems over symmetric cones have been extensively studied, particularly in the literature on interior-point algorithms, and as the foundation of modelling tools for convex optimization. In this paper we consider the less well-studied conic optimization problems over cones that are homogeneous but not necessarily self-dual. We start with cones of positive semidefinite symmetric matrices with a given sparsity pattern. Homogeneous cones in this class are characterized by nested block-arrow sparsity patterns, a subset of the chordal sparsity patterns. Chordal sparsity guarantees that positive define matrices in the cone have zero-fill Cholesky factorizations. The stronger properties that make the cone homogeneous guarantee that the inverse Cholesky factors have the same zero-fill pattern. We describe transitive subsets of the cone automorphism groups, and important properties of the composition of log-det barriers with the automorphisms. Next, we consider extensions to linear slices of the positive semidefinite cone, and review conditions that make such cones homogeneous. An important example is the matrix norm cone, the epigraph of a quadratic-over-linear matrix function. The properties of homogeneous sparse matrix cones are shown to extend to this more general class of homogeneous matrix cones. We then give an overview of the algebraic theory of homogeneous cones due to Vinberg and Rothaus. A fundamental consequence of this theory is that every homogeneous cone admits a spectrahedral (linear matrix inequality) representation. We conclude by discussing the role of homogeneous structure in primal–dual symmetric interior-point methods, contrasting this with the well-developed algorithms for symmetric cones that exploit the strong properties of self-scaled barriers, and with symmetric primal–dual methods for general convex cones.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4376148934",
    "type": "article"
  },
  {
    "title": "Binary separation and training support vector machines",
    "doi": "https://doi.org/10.1017/s0962492910000024",
    "publication_date": "2010-05-01",
    "publication_year": 2010,
    "authors": "R. Fletcher; Gaetano Zanghirati",
    "corresponding_authors": "",
    "abstract": "We introduce basic ideas of binary separation by a linear hyperplane, which is a technique exploited in the support vector machine (SVM) concept. This is a decision-making tool for pattern recognition and related problems. We describe a fundamental standard problem (SP) and show how this is used in most existing research to develop a dual-based algorithm for its solution. This algorithm is shown to be deficient in certain aspects, and we develop a new primal-based SQP-like algorithm, which has some interesting features. Most practical SVM problems are not adequately handled by a linear hyperplane. We describe the nonlinear SVM technique, which enables a nonlinear separating surface to be computed, and we propose a new primal algorithm based on the use of low-rank Cholesky factors. It may be, however, that exact separation is not desirable due to the presence of uncertain or mislabelled data. Dealing with this situation is the main challenge in developing suitable algorithms. Existing dual-based algorithms use the idea of L 1 penalties, which has merit. We suggest how penalties can be incorporated into a primal-based algorithm. Another aspect of practical SVM problems is often the huge size of the data set, which poses severe challenges both for software package development and for control of ill-conditioning. We illustrate some of these issues with numerical experiments on a range of problems.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2009530383",
    "type": "article"
  },
  {
    "title": "Probabilistic analyses of condition numbers",
    "doi": "https://doi.org/10.1017/s0962492916000027",
    "publication_date": "2016-05-01",
    "publication_year": 2016,
    "authors": "Felipe Cucker",
    "corresponding_authors": "Felipe Cucker",
    "abstract": "In recent decades, condition numbers have joined forces with probabilistic analysis to give rise to a form of condition-based analysis of algorithms. In this paper we survey how this analysis is done via a number of examples. We precede this catalogue of examples with short primers on both condition numbers and probabilistic analyses.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2394869563",
    "type": "article"
  },
  {
    "title": "Some new results and current challenges in the finite element analysis of shells",
    "doi": "https://doi.org/10.1017/s0962492901000034",
    "publication_date": "2001-05-01",
    "publication_year": 2001,
    "authors": "Dominique Chapelle",
    "corresponding_authors": "Dominique Chapelle",
    "abstract": "This article, a companion to the article by Philippe G. Ciarlet on the mathematical modelling of shells also in this issue of Acta Numerica , focuses on numerical issues raised by the analysis of shells. Finite element procedures are widely used in engineering practice to analyse the behaviour of shell structures. However, the concept of ‘shell finite element’ is still somewhat fuzzy, as it may correspond to very different ideas and techniques in various actual implementations. In particular, a significant distinction can be made between shell elements that are obtained via the discretization of shell models, and shell elements – such as the general shell elements – derived from 3D formulations using some kinematic assumptions, without the use of any shell theory. Our first objective in this paper is to give a unified perspective of these two families of shell elements. This is expected to be very useful as it paves the way for further thorough mathematical analyses of shell elements. A particularly important motivation for this is the understanding and treatment of the deficiencies associated with the analysis of thin shells (among which is the locking phenomenon). We then survey these deficiencies, in the framework of the asymptotic behaviour of shell models. We conclude the article by giving some detailed guidelines to numerically assess the performance of shell finite elements when faced with these pathological phenomena, which is essential for the design of improved procedures.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W1977050762",
    "type": "article"
  },
  {
    "title": "Kepler, Newton and numerical analysis",
    "doi": "https://doi.org/10.1017/s0962492910000073",
    "publication_date": "2010-05-01",
    "publication_year": 2010,
    "authors": "Gerhard Wanner",
    "corresponding_authors": "Gerhard Wanner",
    "abstract": "Numerical methods are usually constructed for solving mathematical problems such as differential equations or optimization problems. In this contribution we discuss the fact that numerical methods, applied inversely, were also important in establishing these models. We show in detail the discovery of the laws of planetary motion by Kepler and Newton, which stood at the beginning of modern science. The 400th anniversary of the publication of Kepler's laws (1609) is a good occasion for this investigation.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2118736932",
    "type": "article"
  },
  {
    "title": "Numerical relativity: challenges for computational science",
    "doi": "https://doi.org/10.1017/s0962492900002889",
    "publication_date": "1999-01-01",
    "publication_year": 1999,
    "authors": "Gregory B. Cook; Saul A. Teukolsky",
    "corresponding_authors": "",
    "abstract": "We describe the burgeoning field of numerical relativity, which aims to solve Einstein's equations of general relativity numerically. The field presents many questions that may interest numerical analysts, especially problems related to nonlinear partial differential equations: elliptic systems, hyperbolic systems, and mixed systems. There are many novel features, such as dealing with boundaries when black holes are excised from the computational domain, or how even to pose the problem computationally when the coordinates must be determined during the evolution from initial data. The most important unsolved problem is that there is no known general 3-dimensional algorithm that can evolve Einstein's equations with black holes that is stable. This review is meant to be an introduction that will enable numerical analysts and other computational scientists to enter the field. No previous knowledge of special or general relativity is assumed.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W2022735766",
    "type": "article"
  },
  {
    "title": "Mathematical modelling of linearly elastic shells",
    "doi": "https://doi.org/10.1017/s0962492901000022",
    "publication_date": "2001-05-01",
    "publication_year": 2001,
    "authors": "Philippe G. Ciarlet",
    "corresponding_authors": "Philippe G. Ciarlet",
    "abstract": "The objective of this article is to lay down the proper mathematical foundations of the two-dimensional theory of linearly elastic shells . To this end, it provides, without any recourse to any a priori assumptions of a geometrical or mechanical nature, a mathematical justification of two-dimensional linear shell theories , by means of asymptotic methods , with the thickness as the ‘small’ parameter . A major virtue of this approach is that it naturally leads to precise mathematical definitions of linearly elastic ‘membrane’ and ‘flexural’ shells . Another noteworthy feature is that it highlights in particular the role played by two fundamental tensors , each associated with a displacement field of the middle surface, the linearized change of metric and linearized change of curvature tensors . More specifically, under fundamentally distinct sets of assumptions bearing on the geometry of the middle surface , on the boundary conditions , and on the order of magnitude of the applied forces , it is shown that the three-dimensional displacements, once properly scaled, converge (in H 1 , or in L 2 , or in ad hoc completions) as the thickness approaches zero towards a ‘two-dimensional’ limit that satisfies either the linear two-dimensional equations of a ‘membrane’ shell (themselves divided into two subclasses) or the linear two-dimensional equations of a ‘flexural’ shell . Note that this asymptotic analysis automatically provides in each case the ‘limit’ two-dimensional equations , together with the function space over which they are well-posed. The linear two-dimensional shell equations that are most commonly used in numerical simulations, namely Koiter's equations , Naghdi's equations , and ‘shallow’ shell equations , are then carefully described, mathematically analysed, and likewise justified by means of asymptotic analyses. The existence and uniqueness of solutions to each one of these linear two-dimensional shell equations are also established by means of crucial inequalities of Korn's type on surfaces , which are proved in detail at the beginning of the article. This article serves as a mathematical basis for the numerically oriented companion article by Dominique Chapelle, also in this issue of Acta Numerica .",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W1995411275",
    "type": "article"
  },
  {
    "title": "Pricing futures by deterministic methods",
    "doi": "https://doi.org/10.1017/s0962492912000074",
    "publication_date": "2012-04-19",
    "publication_year": 2012,
    "authors": "Olivier Pironneau",
    "corresponding_authors": "Olivier Pironneau",
    "abstract": "In this article we will focus on only a small part of financial mathematics, namely the use of partial differential equations for pricing futures. Even within this narrow range it is hard to be systematic and complete, or even to do better than existing books such as Wilmott, Howison and Dewynne (1995), Achdou and Pironneau (2005), or software manuals such as Lapeyre, Martini and Sulem (2010). So this article may be valuable only to the extent that it reflects ten years of teaching, conferences and interaction with the protagonists of financial mathematics. Also, because the theory of partial differential equations is not always well known, we have chosen a pragmatic approach and left out the details of the theory or the proofs of some results, and refer the reader to other books. The numerical algorithms, on the other hand, are given in detail.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2080699607",
    "type": "article"
  },
  {
    "title": "Computational Modelling of the Heart",
    "doi": null,
    "publication_date": "2004-01-01",
    "publication_year": 2004,
    "authors": "Nic Smith",
    "corresponding_authors": "Nic Smith",
    "abstract": "",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2501929468",
    "type": "article"
  },
  {
    "title": "ANU volume 25 Cover and Back matter",
    "doi": "https://doi.org/10.1017/s0962492916000064",
    "publication_date": "2016-05-01",
    "publication_year": 2016,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "An abstract is not available for this content so a preview has been provided. As you have access to this content, a full PDF is available via the ‘Save PDF’ action button.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4252557075",
    "type": "paratext"
  },
  {
    "title": "ANU volume 21 Cover and Back matter",
    "doi": "https://doi.org/10.1017/s0962492911999966",
    "publication_date": "2012-04-24",
    "publication_year": 2012,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "An abstract is not available for this content so a preview has been provided. As you have access to this content, a full PDF is available via the ‘Save PDF’ action button.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4231920567",
    "type": "paratext"
  },
  {
    "title": "ANU volume 26 Cover and Back matter",
    "doi": "https://doi.org/10.1017/s0962492917000095",
    "publication_date": "2017-05-01",
    "publication_year": 2017,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "An abstract is not available for this content so a preview has been provided. As you have access to this content, a full PDF is available via the ‘Save PDF’ action button.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4247177056",
    "type": "paratext"
  },
  {
    "title": "ANU volume 33 Cover and Front matter",
    "doi": "https://doi.org/10.1017/s0962492924000035",
    "publication_date": "2024-07-01",
    "publication_year": 2024,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4402253587",
    "type": "article"
  },
  {
    "title": "ANU volume 33 Cover and Back matter",
    "doi": "https://doi.org/10.1017/s0962492924000047",
    "publication_date": "2024-07-01",
    "publication_year": 2024,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4402233038",
    "type": "paratext"
  },
  {
    "title": "ANU volume 25 Cover and Front matter",
    "doi": "https://doi.org/10.1017/s0962492916000052",
    "publication_date": "2016-05-01",
    "publication_year": 2016,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "An abstract is not available for this content so a preview has been provided. As you have access to this content, a full PDF is available via the ‘Save PDF’ action button.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4234180471",
    "type": "article"
  },
  {
    "title": "ANU volume 23 Cover and Back matter",
    "doi": "https://doi.org/10.1017/s0962492914999986",
    "publication_date": "2014-05-01",
    "publication_year": 2014,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "An abstract is not available for this content so a preview has been provided. As you have access to this content, a full PDF is available via the ‘Save PDF’ action button.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4240935844",
    "type": "paratext"
  },
  {
    "title": "ANU volume 23 Cover and Front matter",
    "doi": "https://doi.org/10.1017/s0962492914999998",
    "publication_date": "2014-05-01",
    "publication_year": 2014,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "An abstract is not available for this content so a preview has been provided. As you have access to this content, a full PDF is available via the ‘Save PDF’ action button.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4245699079",
    "type": "article"
  },
  {
    "title": "ANU volume 24 Cover and Front matter",
    "doi": "https://doi.org/10.1017/s0962492915000045",
    "publication_date": "2015-04-27",
    "publication_year": 2015,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "An abstract is not available for this content so a preview has been provided. As you have access to this content, a full PDF is available via the ‘Save PDF’ action button.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4253644588",
    "type": "article"
  },
  {
    "title": "ANU volume 24 Cover and Back matter",
    "doi": "https://doi.org/10.1017/s0962492915000069",
    "publication_date": "2015-04-27",
    "publication_year": 2015,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "An abstract is not available for this content so a preview has been provided. As you have access to this content, a full PDF is available via the ‘Save PDF’ action button.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4255312724",
    "type": "paratext"
  },
  {
    "title": "Tensors in computations",
    "doi": "https://doi.org/10.1017/s0962492921000076",
    "publication_date": "2021-05-01",
    "publication_year": 2021,
    "authors": "Lek‐Heng Lim",
    "corresponding_authors": "Lek‐Heng Lim",
    "abstract": "The notion of a tensor captures three great ideas: equivariance, multilinearity, separability. But trying to be three things at once makes the notion difficult to understand. We will explain tensors in an accessible and elementary way through the lens of linear algebra and numerical linear algebra, elucidated with examples from computational and applied mathematics.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W3169240678",
    "type": "article"
  },
  {
    "title": "ANU volume 22 Cover and Back matter",
    "doi": "https://doi.org/10.1017/s0962492913999943",
    "publication_date": "2013-04-02",
    "publication_year": 2013,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "An abstract is not available for this content so a preview has been provided. As you have access to this content, a full PDF is available via the ‘Save PDF’ action button.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4234599555",
    "type": "paratext"
  },
  {
    "title": "ANU volume 20 Cover and Front matter",
    "doi": "https://doi.org/10.1017/s0962492911999991",
    "publication_date": "2011-04-28",
    "publication_year": 2011,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "An abstract is not available for this content so a preview has been provided. As you have access to this content, a full PDF is available via the ‘Save PDF’ action button.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4242747002",
    "type": "article"
  },
  {
    "title": "ANU volume 22 Cover and Front matter",
    "doi": "https://doi.org/10.1017/s0962492913999955",
    "publication_date": "2013-04-02",
    "publication_year": 2013,
    "authors": "Pietro Belotti; Christian Kirches; Sven Leyffer; Jeff Linderoth; James Luedtke; Ashutosh Mahajan; Yurii Nesterov; Arkadi Nemirovski",
    "corresponding_authors": "",
    "abstract": "An abstract is not available for this content so a preview has been provided. As you have access to this content, a full PDF is available via the ‘Save PDF’ action button.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4253643501",
    "type": "article"
  },
  {
    "title": "ANU volume 20 Cover and Back matter",
    "doi": "https://doi.org/10.1017/s096249291199998x",
    "publication_date": "2011-04-28",
    "publication_year": 2011,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "An abstract is not available for this content so a preview has been provided. As you have access to this content, a full PDF is available via the ‘Save PDF’ action button.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4256143540",
    "type": "paratext"
  },
  {
    "title": "ANU volume 21 Cover and Front matter",
    "doi": "https://doi.org/10.1017/s0962492911999978",
    "publication_date": "2012-04-19",
    "publication_year": 2012,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "An abstract is not available for this content so a preview has been provided. As you have access to this content, a full PDF is available via the ‘Save PDF’ action button.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4213030119",
    "type": "article"
  },
  {
    "title": "ANU volume 18 issue 1 Cover and Back matter",
    "doi": "https://doi.org/10.1017/s0962492909999986",
    "publication_date": "2009-05-01",
    "publication_year": 2009,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "An abstract is not available for this content so a preview has been provided. As you have access to this content, a full PDF is available via the ‘Save PDF’ action button.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4214581533",
    "type": "paratext"
  },
  {
    "title": "ANU volume 18 issue 1 Cover and Front matter",
    "doi": "https://doi.org/10.1017/s0962492909999998",
    "publication_date": "2009-05-01",
    "publication_year": 2009,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "An abstract is not available for this content so a preview has been provided. As you have access to this content, a full PDF is available via the ‘Save PDF’ action button.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4244542380",
    "type": "article"
  },
  {
    "title": "ANU volume 19 Cover and Front matter",
    "doi": "https://doi.org/10.1017/s0962492910999984",
    "publication_date": "2010-05-01",
    "publication_year": 2010,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "An abstract is not available for this content so a preview has been provided. As you have access to this content, a full PDF is available via the ‘Save PDF’ action button.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4244562437",
    "type": "article"
  },
  {
    "title": "ANU volume 19 Cover and Back matter",
    "doi": "https://doi.org/10.1017/s0962492910999996",
    "publication_date": "2010-05-01",
    "publication_year": 2010,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "An abstract is not available for this content so a preview has been provided. As you have access to this content, a full PDF is available via the ‘Save PDF’ action button.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4256469987",
    "type": "paratext"
  },
  {
    "title": "ANU volume 26 Cover and Front matter",
    "doi": "https://doi.org/10.1017/s0962492917000010",
    "publication_date": "2017-05-01",
    "publication_year": 2017,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "An abstract is not available for this content so a preview has been provided. As you have access to this content, a full PDF is available via the ‘Save PDF’ action button.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4247313511",
    "type": "article"
  },
  {
    "title": "ANU volume 32 Cover and Back matter",
    "doi": "https://doi.org/10.1017/s0962492923000041",
    "publication_date": "2023-05-01",
    "publication_year": 2023,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "An abstract is not available for this content so a preview has been provided. As you have access to this content, a full PDF is available via the ‘Save PDF’ action button.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4376144208",
    "type": "paratext"
  },
  {
    "title": "ANU volume 32 Cover and Front matter",
    "doi": "https://doi.org/10.1017/s096249292300003x",
    "publication_date": "2023-05-01",
    "publication_year": 2023,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "An abstract is not available for this content so a preview has been provided. As you have access to this content, a full PDF is available via the ‘Save PDF’ action button.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4376148947",
    "type": "article"
  },
  {
    "title": "Numerical geometry of surfaces",
    "doi": "https://doi.org/10.1017/s0962492900002476",
    "publication_date": "1994-01-01",
    "publication_year": 1994,
    "authors": "Malcolm Sabin",
    "corresponding_authors": "Malcolm Sabin",
    "abstract": "The mathematical techniques used within Computer Aided Design software for the representation and calculation of surfaces of objects are described. First the main techniques for dealing with surfaces as computational objects are described, and then the methods for enquiring of such surfaces the properties required for their assessment and manufacture.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2168767509",
    "type": "article"
  },
  {
    "title": "ANU volume 3 issue 1 Cover and Back matter",
    "doi": "https://doi.org/10.1017/s0962492900002403",
    "publication_date": "1994-01-01",
    "publication_year": 1994,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "An abstract is not available for this content so a preview has been provided. As you have access to this content, a full PDF is available via the ‘Save PDF’ action button.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4231299783",
    "type": "paratext"
  },
  {
    "title": "ANU volume 27 Cover and Back matter",
    "doi": "https://doi.org/10.1017/s0962492918000053",
    "publication_date": "2018-05-01",
    "publication_year": 2018,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "An abstract is not available for this content so a preview has been provided. As you have access to this content, a full PDF is available via the ‘Save PDF’ action button.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4232267053",
    "type": "paratext"
  },
  {
    "title": "ANU volume 27 Cover and Front matter",
    "doi": "https://doi.org/10.1017/s0962492918000041",
    "publication_date": "2018-05-01",
    "publication_year": 2018,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "An abstract is not available for this content so a preview has been provided. As you have access to this content, a full PDF is available via the ‘Save PDF’ action button.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4234839008",
    "type": "article"
  },
  {
    "title": "ANU volume 28 Cover and Front matter",
    "doi": "https://doi.org/10.1017/s0962492919000072",
    "publication_date": "2019-05-01",
    "publication_year": 2019,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "An abstract is not available for this content so a preview has been provided. As you have access to this content, a full PDF is available via the ‘Save PDF’ action button.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4235551135",
    "type": "article"
  },
  {
    "title": "ANU volume 28 Cover and Back matter",
    "doi": "https://doi.org/10.1017/s0962492919000084",
    "publication_date": "2019-05-01",
    "publication_year": 2019,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "An abstract is not available for this content so a preview has been provided. As you have access to this content, a full PDF is available via the ‘Save PDF’ action button.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4255687252",
    "type": "paratext"
  },
  {
    "title": "ANU volume 29 Cover and Back matter",
    "doi": "https://doi.org/10.1017/s0962492920000082",
    "publication_date": "2020-05-01",
    "publication_year": 2020,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "An abstract is not available for this content so a preview has been provided. As you have access to this content, a full PDF is available via the ‘Save PDF’ action button.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4237981624",
    "type": "paratext"
  },
  {
    "title": "ANU volume 29 Cover and Front matter",
    "doi": "https://doi.org/10.1017/s0962492920000070",
    "publication_date": "2020-05-01",
    "publication_year": 2020,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "An abstract is not available for this content so a preview has been provided. As you have access to this content, a full PDF is available via the ‘Save PDF’ action button.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4251729379",
    "type": "article"
  },
  {
    "title": "ANU volume 31 Cover and Back matter",
    "doi": "https://doi.org/10.1017/s0962492922000071",
    "publication_date": "2022-05-01",
    "publication_year": 2022,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "An abstract is not available for this content so a preview has been provided. As you have access to this content, a full PDF is available via the ‘Save PDF’ action button.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4281715329",
    "type": "paratext"
  },
  {
    "title": "ANU volume 31 Cover and Front matter",
    "doi": "https://doi.org/10.1017/s096249292200006x",
    "publication_date": "2022-05-01",
    "publication_year": 2022,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "An abstract is not available for this content so a preview has been provided. As you have access to this content, a full PDF is available via the ‘Save PDF’ action button.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4281790375",
    "type": "article"
  },
  {
    "title": "ANU volume 30 Cover and Front matter",
    "doi": "https://doi.org/10.1017/s096249292100009x",
    "publication_date": "2021-05-01",
    "publication_year": 2021,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "An abstract is not available for this content so a preview has been provided. As you have access to this content, a full PDF is available via the ‘Save PDF’ action button.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4205997312",
    "type": "article"
  },
  {
    "title": "ANU volume 30 Cover and Back matter",
    "doi": "https://doi.org/10.1017/s0962492921000106",
    "publication_date": "2021-05-01",
    "publication_year": 2021,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "An abstract is not available for this content so a preview has been provided. As you have access to this content, a full PDF is available via the ‘Save PDF’ action button.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4206022629",
    "type": "paratext"
  },
  {
    "title": "ANU volume 8 issue 1 Cover and Back matter",
    "doi": "https://doi.org/10.1017/s0962492900002877",
    "publication_date": "1999-01-01",
    "publication_year": 1999,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "An abstract is not available for this content so a preview has been provided. As you have access to this content, a full PDF is available via the ‘Save PDF’ action button.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4214639212",
    "type": "paratext"
  },
  {
    "title": "ANU volume 7 issue 1 Cover and Front matter",
    "doi": "https://doi.org/10.1017/s0962492900002786",
    "publication_date": "1998-01-01",
    "publication_year": 1998,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "An abstract is not available for this content so a preview has been provided. Please use the Get access link above for information on how to access this content.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4235102695",
    "type": "article"
  },
  {
    "title": "ANU volume 8 issue 1 Cover and Front matter",
    "doi": "https://doi.org/10.1017/s0962492900002865",
    "publication_date": "1999-01-01",
    "publication_year": 1999,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "An abstract is not available for this content so a preview has been provided. As you have access to this content, a full PDF is available via the ‘Save PDF’ action button.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4242804892",
    "type": "article"
  },
  {
    "title": "ANU volume 7 issue 1 Cover and Back matter",
    "doi": "https://doi.org/10.1017/s0962492900002798",
    "publication_date": "1998-01-01",
    "publication_year": 1998,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "An abstract is not available for this content so a preview has been provided. As you have access to this content, a full PDF is available via the ‘Save PDF’ action button.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4256066044",
    "type": "paratext"
  },
  {
    "title": "ANU volume 6 issue 1 Cover and Front matter",
    "doi": "https://doi.org/10.1017/s0962492900002683",
    "publication_date": "1997-01-01",
    "publication_year": 1997,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "An abstract is not available for this content so a preview has been provided. As you have access to this content, a full PDF is available via the ‘Save PDF’ action button.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4234418842",
    "type": "article"
  },
  {
    "title": "ANU volume 6 issue 1 Cover and Back matter",
    "doi": "https://doi.org/10.1017/s0962492900002695",
    "publication_date": "1997-01-01",
    "publication_year": 1997,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "An abstract is not available for this content so a preview has been provided. As you have access to this content, a full PDF is available via the ‘Save PDF’ action button.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4254378752",
    "type": "paratext"
  },
  {
    "title": "ANU volume 5 issue 1 Cover and Front matter",
    "doi": "https://doi.org/10.1017/s0962492900002592",
    "publication_date": "1996-01-01",
    "publication_year": 1996,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "An abstract is not available for this content so a preview has been provided. As you have access to this content, a full PDF is available via the ‘Save PDF’ action button.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4239822900",
    "type": "article"
  },
  {
    "title": "ANU volume 4 issue 1 Cover and Back matter",
    "doi": "https://doi.org/10.1017/s0962492900002506",
    "publication_date": "1995-01-01",
    "publication_year": 1995,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "An abstract is not available for this content so a preview has been provided. As you have access to this content, a full PDF is available via the ‘Save PDF’ action button.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4240964956",
    "type": "paratext"
  },
  {
    "title": "ANU volume 4 issue 1 Cover and Front matter",
    "doi": "https://doi.org/10.1017/s096249290000249x",
    "publication_date": "1995-01-01",
    "publication_year": 1995,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "An abstract is not available for this content so a preview has been provided. As you have access to this content, a full PDF is available via the ‘Save PDF’ action button.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4243177063",
    "type": "article"
  },
  {
    "title": "Errata for Section 1.10.7",
    "doi": "https://doi.org/10.1017/s0962492900002555",
    "publication_date": "1995-01-01",
    "publication_year": 1995,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "(1) Due to a coding mistake the algorithm used to solve the test problems in Sections 1.10.7.2 and 1.10.7.3 of Part I (see Acta Numerica 1994 ) was not a genuine conjugate gradient algorithm. Indeed, the search direction sequence { w n } n ≥0 was improperly defined leading to a slow convergence; for the ‘small’ values of k (e.g. 10 2 , 10 3 ) the computed results were essentially correct, but for larger values the slow convergence prevented us from reaching the correct limit since we stopped iterating after a fixed number of iterations (300 or 500, depending of the test problem).",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4250288323",
    "type": "article"
  },
  {
    "title": "ANU volume 5 issue 1 Cover and Back matter",
    "doi": "https://doi.org/10.1017/s0962492900002609",
    "publication_date": "1996-01-01",
    "publication_year": 1996,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "An abstract is not available for this content so a preview has been provided. As you have access to this content, a full PDF is available via the ‘Save PDF’ action button.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4254885208",
    "type": "paratext"
  },
  {
    "title": "Preface",
    "doi": "https://doi.org/10.1017/s0962492900002221",
    "publication_date": "1992-01-01",
    "publication_year": 1992,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "An abstract is not available for this content so a preview has been provided. As you have access to this content, a full PDF is available via the ‘Save PDF’ action button.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4230647393",
    "type": "article"
  },
  {
    "title": "ANU volume 2 issue 1 Cover and Back matter",
    "doi": "https://doi.org/10.1017/s0962492900002324",
    "publication_date": "1993-01-01",
    "publication_year": 1993,
    "authors": "Ronald DeVore; Bradley J. Lucier; R. Freund; Gennadii Golub; Noël M. Nachtigal; J. M. Sanz‐Serna; Ian H. Sloan; Margaret J. Wright; Eugene L. Allgower; Kurt George; Carl de Boor; James Demmel; Michael T. Heath; Henk van der Vorst; J. Van Dorsselaer; J. F. B. M. Kraaijevanger; M. N. Spijker; Michel Fortin",
    "corresponding_authors": "",
    "abstract": "An abstract is not available for this content so a preview has been provided. As you have access to this content, a full PDF is available via the ‘Save PDF’ action button.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4232925336",
    "type": "paratext"
  },
  {
    "title": "ANU volume 1 issue 1 Cover and Back matter",
    "doi": "https://doi.org/10.1017/s096249290000221x",
    "publication_date": "1992-01-01",
    "publication_year": 1992,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "An abstract is not available for this content so a preview has been provided. As you have access to this content, a full PDF is available via the ‘Save PDF’ action button.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4245615322",
    "type": "paratext"
  },
  {
    "title": "ANU volume 2 issue 1 Cover and Front matter",
    "doi": "https://doi.org/10.1017/s0962492900002312",
    "publication_date": "1993-01-01",
    "publication_year": 1993,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "An abstract is not available for this content so a preview has been provided. As you have access to this content, a full PDF is available via the ‘Save PDF’ action button.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4248478290",
    "type": "article"
  },
  {
    "title": "ANU volume 1 issue 1 Cover and Front matter",
    "doi": "https://doi.org/10.1017/s0962492900002208",
    "publication_date": "1992-01-01",
    "publication_year": 1992,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "An abstract is not available for this content so a preview has been provided. As you have access to this content, a full PDF is available via the ‘Save PDF’ action button.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4251304104",
    "type": "article"
  },
  {
    "title": "ANU volume 3 issue 1 Cover and Front matter",
    "doi": "https://doi.org/10.1017/s0962492900002397",
    "publication_date": "1994-01-01",
    "publication_year": 1994,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "An abstract is not available for this content so a preview has been provided. As you have access to this content, a full PDF is available via the ‘Save PDF’ action button.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4252612142",
    "type": "article"
  }
]
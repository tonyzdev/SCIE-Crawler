[
  {
    "title": "Power minimization in IC design",
    "doi": "https://doi.org/10.1145/225871.225877",
    "publication_date": "1996-01-01",
    "publication_year": 1996,
    "authors": "Massoud Pedram",
    "corresponding_authors": "Massoud Pedram",
    "abstract": "Low power has emerged as a principal theme in today's electronics industry. The need for low power has caused a major paradigm shift in which power dissipation is as important as performance and area. This article presents an in-depth survey of CAD methodologies and techniques for designing low power digital CMOS circuits and systems and describes the many issues facing designers at architectural, logical, and physical levels of design abstraction. It reviews some of the techniques and tools that have been proposed to overcome these difficulties and outlines the future challenges that must be met to design low power, high performance systems.",
    "cited_by_count": 504,
    "openalex_id": "https://openalex.org/W2079170559",
    "type": "article"
  },
  {
    "title": "Hardware Trojans",
    "doi": "https://doi.org/10.1145/2906147",
    "publication_date": "2016-05-27",
    "publication_year": 2016,
    "authors": "Kun Xiao; Domenic Forte; Yier Jin; Ramesh Karri; Swarup Bhunia; Mark Tehranipoor",
    "corresponding_authors": "",
    "abstract": "Given the increasing complexity of modern electronics and the cost of fabrication, entities from around the globe have become more heavily involved in all phases of the electronics supply chain. In this environment, hardware Trojans (i.e., malicious modifications or inclusions made by untrusted third parties) pose major security concerns, especially for those integrated circuits (ICs) and systems used in critical applications and cyber infrastructure. While hardware Trojans have been explored significantly in academia over the last decade, there remains room for improvement. In this article, we examine the research on hardware Trojans from the last decade and attempt to capture the lessons learned. A comprehensive adversarial model taxonomy is introduced and used to examine the current state of the art. Then the past countermeasures and publication trends are categorized based on the adversarial model and topic. Through this analysis, we identify what has been covered and the important problems that are underinvestigated. We also identify the most critical lessons for those new to the field and suggest a roadmap for future hardware Trojan research.",
    "cited_by_count": 397,
    "openalex_id": "https://openalex.org/W2464661970",
    "type": "article"
  },
  {
    "title": "Machine Learning for Electronic Design Automation: A Survey",
    "doi": "https://doi.org/10.1145/3451179",
    "publication_date": "2021-06-05",
    "publication_year": 2021,
    "authors": "Guyue Huang; Jingbo Hu; Yifan He; Jialong Liu; Mingyuan Ma; Zhaoyang Shen; Juejian Wu; Yuanfan Xu; Hengrui Zhang; Kai Zhong; Xuefei Ning; Yuzhe Ma; Haoyu Yang; Bei Yu; Huazhong Yang; Yu Wang",
    "corresponding_authors": "",
    "abstract": "With the down-scaling of CMOS technology, the design complexity of very large-scale integrated is increasing. Although the application of machine learning (ML) techniques in electronic design automation (EDA) can trace its history back to the 1990s, the recent breakthrough of ML and the increasing complexity of EDA tasks have aroused more interest in incorporating ML to solve EDA tasks. In this article, we present a comprehensive review of existing ML for EDA studies, organized following the EDA hierarchy.",
    "cited_by_count": 207,
    "openalex_id": "https://openalex.org/W3169517138",
    "type": "article"
  },
  {
    "title": "Enable Deep Learning on Mobile Devices: Methods, Systems, and Applications",
    "doi": "https://doi.org/10.1145/3486618",
    "publication_date": "2022-03-04",
    "publication_year": 2022,
    "authors": "Han Cai; Ji Lin; Yujun Lin; Zhijian Liu; Haotian Tang; Hanrui Wang; Ligeng Zhu; Song Han",
    "corresponding_authors": "",
    "abstract": "Deep neural networks (DNNs) have achieved unprecedented success in the field of artificial intelligence (AI), including computer vision, natural language processing, and speech recognition. However, their superior performance comes at the considerable cost of computational complexity, which greatly hinders their applications in many resource-constrained devices, such as mobile phones and Internet of Things (IoT) devices. Therefore, methods and techniques that are able to lift the efficiency bottleneck while preserving the high accuracy of DNNs are in great demand to enable numerous edge AI applications. This article provides an overview of efficient deep learning methods, systems, and applications. We start from introducing popular model compression methods, including pruning, factorization, quantization, as well as compact model design. To reduce the large design cost of these manual solutions, we discuss the AutoML framework for each of them, such as neural architecture search (NAS) and automated pruning and quantization. We then cover efficient on-device training to enable user customization based on the local data on mobile devices. Apart from general acceleration techniques, we also showcase several task-specific accelerations for point cloud, video, and natural language processing by exploiting their spatial sparsity and temporal/token redundancy. Finally, to support all these algorithmic advancements, we introduce the efficient deep learning system design from both software and hardware perspectives.",
    "cited_by_count": 88,
    "openalex_id": "https://openalex.org/W4214951654",
    "type": "article"
  },
  {
    "title": "VeriGen: A Large Language Model for Verilog Code Generation",
    "doi": "https://doi.org/10.1145/3643681",
    "publication_date": "2024-02-09",
    "publication_year": 2024,
    "authors": "Shailja Thakur; Baleegh Ahmad; Hammond Pearce; Benjamin Tan; Brendan Dolan-Gavitt; Ramesh Karri; Siddharth Garg",
    "corresponding_authors": "",
    "abstract": "In this study, we explore the capability of Large Language Models (LLMs) to automate hardware design by automatically completing partial Verilog code, a common language for designing and modeling digital systems. We fine-tune pre-existing LLMs on Verilog datasets compiled from GitHub and Verilog textbooks. We evaluate the functional correctness of the generated Verilog code using a specially designed test suite, featuring a custom problem set and testing benches. Here, our fine-tuned open-source CodeGen-16B model outperforms the commercial state-of-the-art GPT-3.5-turbo model with a 1.1% overall increase. Upon testing with a more diverse and complex problem set, we find that the fine-tuned model shows competitive performance against state-of-the-art gpt-3.5-turbo, excelling in certain scenarios. Notably, it demonstrates a 41% improvement in generating syntactically correct Verilog code across various problem categories compared to its pre-trained counterpart, highlighting the potential of smaller, in-house LLMs in hardware design automation. We release our training/evaluation scripts and LLM checkpoints as open-source contributions.",
    "cited_by_count": 53,
    "openalex_id": "https://openalex.org/W4391681217",
    "type": "article"
  },
  {
    "title": "System-level power optimization",
    "doi": "https://doi.org/10.1145/335043.335044",
    "publication_date": "2000-04-01",
    "publication_year": 2000,
    "authors": "Luca Benini; Giovanni De Micheli",
    "corresponding_authors": "",
    "abstract": "This tutorial surveys design methods for energy-efficient system-level design. We consider electronic sytems consisting of a hardware platform and software layers. We consider the three major constituents of hardware that consume energy, namely computation, communication, and storage units, and we review methods of reducing their energy consumption. We also study models for analyzing the energy cost of software, and methods for energy-efficient software design and compilation. This survery is organized around three main phases of a system design: conceptualization and modeling design and implementation, and runtime management. For each phase, we review recent techniques for energy-efficient design of both hardware and software.",
    "cited_by_count": 401,
    "openalex_id": "https://openalex.org/W2034674049",
    "type": "article"
  },
  {
    "title": "Data and memory optimization techniques for embedded systems",
    "doi": "https://doi.org/10.1145/375977.375978",
    "publication_date": "2001-04-01",
    "publication_year": 2001,
    "authors": "Preeti Ranjan Panda; Francky Catthoor; Nikil Dutt; Koen Danckaert; Erik Brockmeyer; Chidamber Kulkarni; A. Vandercappelle; Per Gunnar Kjeldsberg",
    "corresponding_authors": "",
    "abstract": "We present a survey of the state-of-the-art techniques used in performing data and memory-related optimizations in embedded systems. The optimizations are targeted directly or indirectly at the memory subsystem, and impact one or more out of three important cost metrics: area, performance, and power dissipation of the resulting implementation. We first examine architecture-independent optimizations in the form of code transoformations. We next cover a broad spectrum of optimization techniques that address memory architectures at varying levels of granularity, ranging from register files to on-chip memory, data caches, and dynamic memory (DRAM). We end with memory addressing related issues.",
    "cited_by_count": 377,
    "openalex_id": "https://openalex.org/W1994115836",
    "type": "article"
  },
  {
    "title": "Formal verification in hardware design",
    "doi": "https://doi.org/10.1145/307988.307989",
    "publication_date": "1999-04-01",
    "publication_year": 1999,
    "authors": "Christoph Kern; Mark R. Greenstreet",
    "corresponding_authors": "",
    "abstract": "In recent years, formal methods have emerged as an alternative approach to ensuring the quality and correctness of hardware designs, overcoming some of the limitations of traditional validation techniques such as simulation and testing. There are two main aspects to the application of formal methods in a design process: the formal framework used to specify desired properties of a design and the verification techniques and tools used to reason about the relationship between a specification and a corresponding implementation. We survey a variety of frameworks and techniques proposed in the literature and applied to actual designs. The specification frameworks we describe include temporal logics, predicate logic, abstraction and refinement, as well as containment between ω-regular languages. The verification techniques presented include model checking, automata-theoretic techniques, automated theorem proving, and approaches that integrate the above methods. In order to provide insight into the scope and limitations of currently available techniques, we present a selection of case studies where formal methods were applied to industrial-scale designs, such as microprocessors, floating-point hardware, protocols, memory subsystems, and communications hardware.",
    "cited_by_count": 260,
    "openalex_id": "https://openalex.org/W2096455207",
    "type": "article"
  },
  {
    "title": "SystemCoDesigner—an automatic ESL synthesis approach by design space exploration and behavioral synthesis for streaming applications",
    "doi": "https://doi.org/10.1145/1455229.1455230",
    "publication_date": "2009-01-01",
    "publication_year": 2009,
    "authors": "Joachim Keinert; Martin Streubühr; Thomas Schlichter; Joachim Falk; Jens Gladigau; Christian Haubelt; Jürgen Teich; Michael P. Meredith",
    "corresponding_authors": "",
    "abstract": "With increasing design complexity, the gap from ESL (Electronic System Level) design to RTL synthesis becomes more and more crucial to many industrial projects. Although several behavioral synthesis tools exist to automatically generate synthesizable RTL code from C/C++/SystemC-based input descriptions and software generation for embedded processors is automated as well, an efficient ESL synthesis methodology combining both is still missing. This article presents SystemCoDesigner, a novel SystemC-based ESL tool to automatically optimize a hardware/software SoC (System on Chip) implementation with respect to several objectives. Starting from a SystemC behavioral model, SystemCoDesigner automatically extracts the mathematical model, performs a behavioral synthesis step, and explores the multiobjective design space using state-of-the-art multiobjective optimization algorithms. During design space exploration, a single design point is evaluated by simulating highly accurate performance models, which are automatically generated from the SystemC behavioral model and the behavioral synthesis results. Moreover, SystemCoDesigner permits the automatic generation of bit streams for FPGA targets from any previously optimized SoC implementation. Thus SystemCoDesigner is the first fully automated ESL synthesis tool providing a correct-by-construction generation of hardware/software SoC implementations. As a case study, a model of a Motion-JPEG decoder was automatically optimized and implemented using SystemCoDesigner. Several synthesized SoC variants based on this model show different tradeoffs between required hardware costs and achieved system throughput, ranging from software-only solutions to pure hardware implementations that reach real-time performance for QCIF streams on a 50MHz FPGA.",
    "cited_by_count": 241,
    "openalex_id": "https://openalex.org/W2064115172",
    "type": "article"
  },
  {
    "title": "On-chip communication architecture exploration",
    "doi": "https://doi.org/10.1145/1255456.1255460",
    "publication_date": "2007-08-17",
    "publication_year": 2007,
    "authors": "Hyung Gyu Lee; Naehyuck Chang; Ümit Y. Ogras; Radu Mărculescu",
    "corresponding_authors": "",
    "abstract": "Traditionally, design-space exploration for systems-on-chip (SoCs) has focused on the computational aspects of the problem at hand. However, as the number of components on a single chip and their performance continue to increase, a shift from computation-based to communication-based design becomes mandatory. As a result, the communication architecture plays a major role in the area, performance, and energy consumption of the overall system. This article presents a comprehensive evaluation of three on-chip communication architectures targeting multimedia applications. Specifically, we compare and contrast the network-on-chip (NoC) with point-to-point (P2P) and bus-based communication architectures in terms of area, performance, and energy consumption. As the main contribution, we present complete P2P, bus-, and NoC-based implementations of a real multimedia application (i. e. the MPEG-2 encoder), and provide direct measurements using an FPGA prototype and actual video clips, rather than simulation and synthetic workloads. We also support the experimental findings through a theoretical analysis. Both experimental and analysis results show that the NoC architecture scales very well in terms of area, performance, energy, and design effort, while the P2P and bus-based architectures scale poorly on all accounts except for performance and area, respectively.",
    "cited_by_count": 232,
    "openalex_id": "https://openalex.org/W1963638851",
    "type": "article"
  },
  {
    "title": "On-chip vs. off-chip memory",
    "doi": "https://doi.org/10.1145/348019.348570",
    "publication_date": "2000-07-01",
    "publication_year": 2000,
    "authors": "Preeti Ranjan Panda; Nikil Dutt; Alexandru Nicolau",
    "corresponding_authors": "",
    "abstract": "Efficient utilization of on-chip memory space is extremely important in modern embedded system applications based on processor cores. In addition to a data cache that interfaces with slower off-chip memory, a fast on-chip SRAM, called Scratch-Pad memory, is often used in several applications, so that critical data can be stored there with a guaranteed fast access time. We present a technique for efficiently exploiting on-chip Scratch-Pad memory by partitioning the application's scalar and arrayed variables into off-chip DRAM and on-chip Scratch-Pad SRAM, with the goal of minimizing the total execution time of embedded applications. We also present extensions of our proposed memory assignment strategy to handle context switching between multiple programs, as well as a generalized memory hierarchy. Our experiments on code kernels from typical applications show that our technique results in significant performance improvements.",
    "cited_by_count": 232,
    "openalex_id": "https://openalex.org/W2086807722",
    "type": "article"
  },
  {
    "title": "Cost minimization while satisfying hard/soft timing constraints for heterogeneous embedded systems",
    "doi": "https://doi.org/10.1145/1497561.1497568",
    "publication_date": "2009-03-01",
    "publication_year": 2009,
    "authors": "Meikang Qiu; Edwin H.‐M. Sha",
    "corresponding_authors": "",
    "abstract": "In high-level synthesis for real-time embedded systems using heterogeneous functional units (FUs), it is critical to select the best FU type for each task. However, some tasks may not have fixed execution times. This article models each varied execution time as a probabilistic random variable and solves heterogeneous assignment with probability (HAP) problem. The solution of the HAP problem assigns a proper FU type to each task such that the total cost is minimized while the timing constraint is satisfied with a guaranteed confidence probability. The solutions to the HAP problem are useful for both hard real-time and soft real-time systems. Optimal algorithms are proposed to find the optimal solutions for the HAP problem when the input is a tree or a simple path. Two other algorithms, one is optimal and the other is near-optimal heuristic, are proposed to solve the general problem. The experiments show that our algorithms can effectively reduce the total cost while satisfying timing constraints with guaranteed confidence probabilities. For example, our algorithms achieve an average reduction of 33.0% on total cost with 0.90 confidence probability satisfying timing constraints compared with the previous work using worst-case scenario.",
    "cited_by_count": 229,
    "openalex_id": "https://openalex.org/W1969550765",
    "type": "article"
  },
  {
    "title": "A predictive system shutdown method for energy saving of event-driven computation",
    "doi": "https://doi.org/10.1145/335043.335046",
    "publication_date": "2000-04-01",
    "publication_year": 2000,
    "authors": "Chi-Hong Hwang; Allen C.-H. Wu",
    "corresponding_authors": "",
    "abstract": "This paper presents a system-level power management technique for energy savings of event-driven application. We present a new predictive system-shutdown method to exploit sleep mode operations for energy saving. We use an exponential-average approach to predict the upcoming idle period. We introduce two mechanisms, prediction-miss correction and prewake-up, to improve the hit ratio and to reduce the delay overhead. Experiments on four different event-driven applications show that our proposed method achieves high hit ratios in a wide range of delay overheads, which results in a high degree of energy with low delay penaties.",
    "cited_by_count": 224,
    "openalex_id": "https://openalex.org/W2053784242",
    "type": "article"
  },
  {
    "title": "Techniques for the synthesis of reversible Toffoli networks",
    "doi": "https://doi.org/10.1145/1278349.1278355",
    "publication_date": "2007-09-01",
    "publication_year": 2007,
    "authors": "Dmitri Maslov; Gerhard W. Dueck; D. Michael Miller",
    "corresponding_authors": "",
    "abstract": "This paper presents novel techniques for the synthesis of reversible networks of Toffoli gates, as well as improvements to previous methods. Gate count and technology oriented cost metrics are used. Our synthesis techniques are independent of the cost metrics. Two new iterative synthesis procedure employing Reed-Muller spectra are introduced and shown to complement earlier synthesis approaches. The template simplification suggested in earlier work is enhanced through introduction of a faster and more efficient template application algorithm, updated (shorter) classification of the templates, and presentation of the new templates of sizes 7 and 9. A novel ``resynthesis'' approach is introduced wherein a sequence of gates is chosen from a network, and the reversible specification it realizes is resynthesized as an independent problem in hopes of reducing the network cost. Empirical results are presented to show that the methods are effective both in terms of the realization of all 3x3 reversible functions and larger reversible benchmark specifications.",
    "cited_by_count": 191,
    "openalex_id": "https://openalex.org/W2116385615",
    "type": "article"
  },
  {
    "title": "CoMPSoC",
    "doi": "https://doi.org/10.1145/1455229.1455231",
    "publication_date": "2009-01-01",
    "publication_year": 2009,
    "authors": "Andreas Hansson; Kees Goossens; Marco J.G. Bekooij; Jos Huisken",
    "corresponding_authors": "",
    "abstract": "A growing number of applications, often with firm or soft real-time requirements, are integrated on the same System on Chip, in the form of either hardware or software intellectual property. The applications are started and stopped at run time, creating different use-cases. Resources, such as interconnects and memories, are shared between different applications, both within and between use-cases, to reduce silicon cost and power consumption. The functional and temporal behaviour of the applications is verified by simulation and formal methods. Traditionally, designers resort to monolithic verification of the system as whole, since the applications interfere in shared resources, and thus affect each other's behaviour. Due to interference between applications, the integration and verification complexity grows exponentially in the number of applications, and the task to verify correct behaviour of concurrent applications is on the system designer rather than the application designers. In this work, we propose a Composable and Predictable Multi-Processor System on Chip (CoMPSoC) platform template. This scalable hardware and software template removes all interference between applications through resource reservations. We demonstrate how this enables a divide-and-conquer design strategy, where all applications, potentially using different programming models and communication paradigms, are developed and verified independently of one another. Performance is analyzed per application, using state-of-the-art dataflow techniques or simulation, depending on the requirements of the application. These results still apply when the applications are integrated onto the platform, thus separating system-level design and application design.",
    "cited_by_count": 179,
    "openalex_id": "https://openalex.org/W2069195425",
    "type": "article"
  },
  {
    "title": "System-scenario-based design of dynamic embedded systems",
    "doi": "https://doi.org/10.1145/1455229.1455232",
    "publication_date": "2009-01-01",
    "publication_year": 2009,
    "authors": "Stefan Valentin Gheorghita; Martin Palkovič; J. Hamers; Arnout Vandecappelle; Stelios Mamagkakis; Twan Basten; Lieven Eeckhout; Henk Corporaal; Francky Catthoor; Frederik Vandeputte; Koen De Bosschere",
    "corresponding_authors": "",
    "abstract": "In the past decade, real-time embedded systems have become much more complex due to the introduction of a lot of new functionality in one application, and due to running multiple applications concurrently. This increases the dynamic nature of today's applications and systems, and tightens the requirements for their constraints in terms of deadlines and energy consumption. State-of-the-art design methodologies try to cope with these novel issues by identifying several most used cases and dealing with them separately, reducing the newly introduced complexity. This article presents a generic and systematic design-time/run-time methodology for handling the dynamic nature of modern embedded systems, which can be utilized by existing design methodologies to increase their efficiency. It is based on the concept of system scenarios , which group system behaviors that are similar from a multidimensional cost perspective—such as resource requirements, delay, and energy consumption—in such a way that the system can be configured to exploit this cost similarity. At design-time, these scenarios are individually optimized. Mechanisms for predicting the current scenario at run-time, and for switching between scenarios, are also derived. This design trajectory is augmented with a run-time calibration mechanism, which allows the system to learn on-the-fly during its execution, and to adapt itself to the current input stimuli, by extending the scenario set, changing the scenario definitions, and both the prediction and switching mechanisms. To show the generality of our methodology, we show how it has been applied on four very different real-life design problems. In all presented case studies, substantial energy reductions were obtained by exploiting scenarios.",
    "cited_by_count": 173,
    "openalex_id": "https://openalex.org/W2112281596",
    "type": "article"
  },
  {
    "title": "A detailed power model for field-programmable gate arrays",
    "doi": "https://doi.org/10.1145/1059876.1059881",
    "publication_date": "2005-04-01",
    "publication_year": 2005,
    "authors": "Kara K.W. Poon; Steven J. E. Wilton; Andy Yan",
    "corresponding_authors": "",
    "abstract": "Power has become a critical issue for field-programmable gate array (FPGA) vendors. Understanding the power dissipation within FPGAs is the first step in developing power-efficient architectures and computer-aided design (CAD) tools for FPGAs. This article describes a detailed and flexible power model which has been integrated in the widely used Versatile Place and Route (VPR) CAD tool. This power model estimates the dynamic, short-circuit, and leakage power consumed by FPGAs. It is the first flexible power model developed to evaluate architectural tradeoffs and the efficiency of power-aware CAD tools for a variety of FPGA architectures, and is freely available for noncommercial use. The model is flexible, in that it can estimate the power for a wide variety of FPGA architectures, and it is fast, in that it does not require extensive simulation, meaning it can be used to explore a large architectural space. We show how the model can be used to investigate the impact of various architectural parameters on the energy consumed by the FPGA, focusing on the segment length, switch block topology, lookuptable size, and cluster size.",
    "cited_by_count": 170,
    "openalex_id": "https://openalex.org/W2095558812",
    "type": "article"
  },
  {
    "title": "Computer Generation of Hardware for Linear Digital Signal Processing Transforms",
    "doi": "https://doi.org/10.1145/2159542.2159547",
    "publication_date": "2012-04-01",
    "publication_year": 2012,
    "authors": "Peter Milder; Franz Franchetti; James C. Hoe; Markus Püschel",
    "corresponding_authors": "",
    "abstract": "Linear signal transforms such as the discrete Fourier transform (DFT) are very widely used in digital signal processing and other domains. Due to high performance or efficiency requirements, these transforms are often implemented in hardware. This implementation is challenging due to the large number of algorithmic options (e.g., fast Fourier transform algorithms or FFTs), the variety of ways that a fixed algorithm can be mapped to a sequential datapath, and the design of the components of this datapath. The best choices depend heavily on the resource budget and the performance goals of the target application. Thus, it is difficult for a designer to determine which set of options will best meet a given set of requirements. In this article we introduce the Spiral hardware generation framework and system for linear transforms. The system takes a problem specification as input as well as directives that define characteristics of the desired datapath. Using a mathematical language to represent and explore transform algorithms and datapath characteristics, the system automatically generates an algorithm, maps it to a datapath, and outputs a synthesizable register transfer level Verilog description suitable for FPGA or ASIC implementation. The quality of the generated designs rivals the best available handwritten IP cores.",
    "cited_by_count": 116,
    "openalex_id": "https://openalex.org/W2024381286",
    "type": "article"
  },
  {
    "title": "ePlace",
    "doi": "https://doi.org/10.1145/2699873",
    "publication_date": "2015-03-02",
    "publication_year": 2015,
    "authors": "Jingwei Lu; Pengwen Chen; Chin-Chih Chang; Sha Lu; Dennis J.-H. Huang; Chin-Chi Teng; Chung‐Kuan Cheng",
    "corresponding_authors": "",
    "abstract": "We develop a flat, analytic, and nonlinear placement algorithm, ePlace , which is more effective, generalized, simpler, and faster than previous works. Based on the analogy between placement instance and electrostatic system, we develop a novel placement density function eDensity , which models every object as positive charge and the density cost as the potential energy of the electrostatic system. The electric potential and field distribution are coupled with density using a well-defined Poisson's equation, which is numerically solved by spectral methods based on fast Fourier transform (FFT). Instead of using the conjugate gradient (CG) nonlinear solver in previous placers, we propose to use Nesterov's method which achieves faster convergence. The efficiency bottleneck on line search is resolved by predicting the steplength using a closed-form equation of Lipschitz constant. The placement performance is validated through experiments on the ISPD 2005 and ISPD 2006 benchmark suites, where ePlace outperforms all state-of-the-art placers (Capo10.5, FastPlace3.0, RQL, MAPLE, ComPLx, BonnPlace, POLAR, APlace3, NTUPlace3, mPL6) with much shorter wirelength and shorter or comparable runtime. On average, of all the ISPD 2005 benchmarks, ePlace outperforms the leading placer BonnPlace with 2.83% shorter wirelength and runs 3.05× faster; and on average, of all the ISPD 2006 benchmarks, ePlace outperforms the leading placer MAPLE with 4.59% shorter wirelength and runs 2.84× faster.",
    "cited_by_count": 115,
    "openalex_id": "https://openalex.org/W1985292881",
    "type": "article"
  },
  {
    "title": "Emerging NVM",
    "doi": "https://doi.org/10.1145/3131848",
    "publication_date": "2017-11-14",
    "publication_year": 2017,
    "authors": "Jalil Boukhobza; Stéphane Rubini; Renhai Chen; Zili Shao",
    "corresponding_authors": "",
    "abstract": "There has been a surge of interest in Non-Volatile Memory (NVM) in recent years. With many advantages, such as density and power consumption, NVM is carving out a place in the memory hierarchy and may eventually change our view of computer architecture. Many NVMs have emerged, such as Magnetoresistive random access memory (MRAM), Phase Change random access memory (PCM), Resistive random access memory (ReRAM), and Ferroelectric random access memory (FeRAM), each with its own peculiar properties and specific challenges. The scientific community has carried out a substantial amount of work on integrating those technologies in the memory hierarchy. As many companies are announcing the imminent mass production of NVMs, we think that it is time to have a step back and discuss the body of literature related to NVM integration. This article surveys state-of-the-art work on integrating NVM into the memory hierarchy. Specially, we introduce the four types of NVM, namely, MRAM, PCM, ReRAM, and FeRAM, and investigate different ways of integrating them into the memory hierarchy from the horizontal or vertical perspectives. Here, horizontal integration means that the new memory is placed at the same level as an existing one, while vertical integration means that the new memory is interleaved between two existing levels. In addition, we describe challenges and opportunities with each NVM technique.",
    "cited_by_count": 108,
    "openalex_id": "https://openalex.org/W2769084511",
    "type": "article"
  },
  {
    "title": "IP Protection and Supply Chain Security through Logic Obfuscation",
    "doi": "https://doi.org/10.1145/3342099",
    "publication_date": "2019-09-27",
    "publication_year": 2019,
    "authors": "Kaveh Shamsi; Meng Li; Kenneth Plaks; Saverio Fazzari; David Z. Pan; Yier Jin",
    "corresponding_authors": "",
    "abstract": "The globalization of the semiconductor supply chain introduces ever-increasing security and privacy risks. Two major concerns are IP theft through reverse engineering and malicious modification of the design. The latter concern in part relies on successful reverse engineering of the design as well. IC camouflaging and logic locking are two of the techniques under research that can thwart reverse engineering by end-users or foundries. However, developing low overhead locking/camouflaging schemes that can resist the ever-evolving state-of-the-art attacks has been a challenge for several years. This article provides a comprehensive review of the state of the art with respect to locking/camouflaging techniques. We start by defining a systematic threat model for these techniques and discuss how various real-world scenarios relate to each threat model. We then discuss the evolution of generic algorithmic attacks under each threat model eventually leading to the strongest existing attacks. The article then systematizes defences and along the way discusses attacks that are more specific to certain kinds of locking/camouflaging. The article then concludes by discussing open problems and future directions.",
    "cited_by_count": 84,
    "openalex_id": "https://openalex.org/W2976174142",
    "type": "article"
  },
  {
    "title": "Electronics Supply Chain Integrity Enabled by Blockchain",
    "doi": "https://doi.org/10.1145/3315571",
    "publication_date": "2019-05-09",
    "publication_year": 2019,
    "authors": "Xiaolin Xu; Fahim Rahman; Bicky Shakya; Apostol Vassilev; Domenic Forte; Mark Tehranipoor",
    "corresponding_authors": "",
    "abstract": "Electronic systems are ubiquitous today, playing an irreplaceable role in our personal lives, as well as in critical infrastructures such as power grids, satellite communications, and public transportation. In the past few decades, the security of software running on these systems has received significant attention. However, hardware has been assumed to be trustworthy and reliable “by default” without really analyzing the vulnerabilities in the electronics supply chain. With the rapid globalization of the semiconductor industry, it has become challenging to ensure the integrity and security of hardware. In this article, we discuss the integrity concerns associated with a globalized electronics supply chain. More specifically, we divide the supply chain into six distinct entities: IP owner/foundry (OCM), distributor, assembler, integrator, end user, and electronics recycler, and analyze the vulnerabilities and threats associated with each stage. To address the concerns of the supply chain integrity, we propose a blockchain-based certificate authority framework that can be used to manage critical chip information such as electronic chip identification, chip grade, and transaction time. The decentralized nature of the proposed framework can mitigate most threats of the electronics supply chain, such as recycling, remarking, cloning, and overproduction.",
    "cited_by_count": 83,
    "openalex_id": "https://openalex.org/W2944303466",
    "type": "article"
  },
  {
    "title": "AutoDSE: Enabling Software Programmers to Design Efficient FPGA Accelerators",
    "doi": "https://doi.org/10.1145/3494534",
    "publication_date": "2022-02-12",
    "publication_year": 2022,
    "authors": "Atefeh Sohrabizadeh; Cody Hao Yu; Min Gao; Jason Cong",
    "corresponding_authors": "",
    "abstract": "Adopting FPGA as an accelerator in datacenters is becoming mainstream for customized computing, but the fact that FPGAs are hard to program creates a steep learning curve for software programmers. Even with the help of high-level synthesis (HLS) , accelerator designers still have to manually perform code reconstruction and cumbersome parameter tuning to achieve optimal performance. While many learning models have been leveraged by existing work to automate the design of efficient accelerators, the unpredictability of modern HLS tools becomes a major obstacle for them to maintain high accuracy. To address this problem, we propose an automated DSE framework— AutoDSE —that leverages a bottleneck-guided coordinate optimizer to systematically find a better design point. AutoDSE detects the bottleneck of the design in each step and focuses on high-impact parameters to overcome it. The experimental results show that AutoDSE is able to identify the design point that achieves, on the geometric mean, 19.9× speedup over one CPU core for MachSuite and Rodinia benchmarks. Compared to the manually optimized HLS vision kernels in Xilinx Vitis libraries, AutoDSE can reduce their optimization pragmas by 26.38× while achieving similar performance. With less than one optimization pragma per design on average, we are making progress towards democratizing customizable computing by enabling software programmers to design efficient FPGA accelerators.",
    "cited_by_count": 55,
    "openalex_id": "https://openalex.org/W3090389586",
    "type": "article"
  },
  {
    "title": "Non-Preemptive Scheduling of Periodic Tasks with Data Dependencies in Heterogeneous Multiprocessor Embedded Systems",
    "doi": "https://doi.org/10.1145/3711849",
    "publication_date": "2025-01-09",
    "publication_year": 2025,
    "authors": "Jinchao Chen; Yang Wang; Ying Zhang; Yantao Lu; Qing Li; Qiuhao Shu",
    "corresponding_authors": "",
    "abstract": "Heterogeneous multiprocessor architecture is frequently employed as an economical and efficient means of providing excellent parallel processing capabilities while keeping production cost and power consumption under control. Although this architecture achieves significant performance enhancement and cost reduction, it results in a serious task allocation and scheduling problem, especially for periodic tasks with data dependencies, all of which should be reasonably scheduled and executed in a timely manner such that their deadlines and dependence requirements could be satisfied even if the worst happens. In this article, we concentrate on the non-preemptive scheduling problem of periodic tasks with data dependencies upon heterogeneous multiprocessor platforms. First, with models of data-dependent tasks and heterogeneous processors, we analyze the time, space, precedence, and data dependence constraints of tasks and design an exact formulation based on the mixed integer linear programming to completely explore the solution space and produce the optimal solutions. Then, by constructing a directed acyclic graph to depict the dependence relationship of jobs generated by tasks, we propose an efficient off-line list-based scheduling algorithm to provide a reasonable time and processor allocation for each job, with a view to minimizing the completion time of jobs. Experiments with randomly generated tasks are performed to evaluate the effectiveness and efficiency of the proposed algorithm, and the experimental results show that our algorithm can averagely enhance the scheduling success ratio by 28.5%, and, respectively, reduce the task completion time and the deviation ratio by 23.3% and 17.2%, on average.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4406220612",
    "type": "article"
  },
  {
    "title": "A Survey of Research in Large Language Models for Electronic Design Automation",
    "doi": "https://doi.org/10.1145/3715324",
    "publication_date": "2025-02-03",
    "publication_year": 2025,
    "authors": "Jingyu Pan; G.-S. Zhou; Chen-Chia Chang; Isaac Jacobson; Jiang Hu; Yiran Chen",
    "corresponding_authors": "",
    "abstract": "Within the rapidly evolving domain of Electronic Design Automation (EDA), Large Language Models (LLMs) have emerged as transformative technologies, offering unprecedented capabilities for optimizing and automating various aspects of electronic design. This survey provides a comprehensive exploration of LLM applications in EDA, focusing on advancements in model architectures, the implications of varying model sizes, and innovative customization techniques that enable tailored analytical insights. By examining the intersection of LLM capabilities and EDA requirements, the paper highlights the significant impact these models have on extracting nuanced understandings from complex datasets. Furthermore, it addresses the challenges and opportunities in integrating LLMs into EDA workflows, paving the way for future research and application in this dynamic field. Through this detailed analysis, the survey aims to offer valuable insights to professionals in the EDA industry, AI researchers, and anyone interested in the convergence of advanced AI technologies and electronic design.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4407114703",
    "type": "article"
  },
  {
    "title": "Deep Reinforcement Learning-Based Resource Allocation with Enhanced Perception and Low-Latency for Autonomous Driving in ISAC-aided VEC",
    "doi": "https://doi.org/10.1145/3727146",
    "publication_date": "2025-04-01",
    "publication_year": 2025,
    "authors": "Chunlin Li; Long Chai; Yong Zhang; Mengjie Yang; Ruidong Zhao; Zihao Zhang; Denghua Li; Shaohua Wan",
    "corresponding_authors": "",
    "abstract": "As autonomous driving technology advances, the intelligence levels of vehicles continue to increase. However, meeting the demands of autonomous driving in various scenarios requires improved wireless communication and vehicle perception capabilities. Integrated sensing and vehicular edge computing (VEC) technology can provide collaborative perception and computing resources for vehicles. Nevertheless, the high-speed mobility of vehicles leads to frequent changes in channel state information and distances between vehicles and roadside units (RSUs), which poses challenges for low-latency perception processing. Additionally, most research overlooks the impact of vehicle mobility on perception accuracy and lacks effective resource allocation strategies for multi-source perception data fusion tasks. Addressing existing research shortcomings, this paper proposes a deep reinforcement learning(DRL)-based resource allocation method. It first adopts Integrated Sensing and Communication (ISAC) technology in the same frequency band to improve spectrum efficiency and integration. Secondly, it constructs a data fusion model to enhance vehicle perception capabilities and describes the data fusion process between vehicle terminals and RSU terminals. Furthermore, this paper designs a resource allocation algorithm for multi-source perception data fusion tasks with the optimization goal of minimizing task completion delay and system average energy consumption. Considering the mobility of vehicles and the frequent changes in communication channel states, this paper transforms the constructed problem into a Markov decision process (MDP). It solves it using the Improved Dueling Twin Delayed Deep Deterministic policy gradient (ID-TD3) algorithm. Experiment results demonstrate that the proposed strategy can reasonably allocate system resources, effectively reducing task completion delay and system average energy consumption.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4409062322",
    "type": "article"
  },
  {
    "title": "Instruction generation for hybrid reconfigurable systems",
    "doi": "https://doi.org/10.1145/605440.605446",
    "publication_date": "2002-10-01",
    "publication_year": 2002,
    "authors": "Ryan Kastner; Adam Kaplan; Seda Öǧrenci Memik; Eli Bozorgzadeh",
    "corresponding_authors": "",
    "abstract": "Future computing systems need to balance flexibility, specialization, and performance in order to meet market demands and the computing power required by new applications. Instruction generation is a vital component for determining these trade-offs. In this work, we present theory and an algorithm for instruction generation. The algorithm profiles a dataflow graph and iteratively contracts edges to create the templates. We discuss how to target the algorithm toward the novel problem of instruction generation for hybrid reconfigurable systems. In particular, we target the Strategically Programmable System, which embeds complex computational units such as ALUs, IP blocks, and so on into a configurable fabric. We argue that an essential compilation step for these systems is instruction generation, as it is needed to specify the functionality of the embedded computational units. In addition, instruction generation can be used to create soft reconfigurable macros---tightly sequenced prespecified operations placed in the reconfigurable fabric.",
    "cited_by_count": 184,
    "openalex_id": "https://openalex.org/W2022341273",
    "type": "article"
  },
  {
    "title": "Experimental analysis of the fastest optimum cycle ratio and mean algorithms",
    "doi": "https://doi.org/10.1145/1027084.1027085",
    "publication_date": "2004-10-01",
    "publication_year": 2004,
    "authors": "Ali Dasdan",
    "corresponding_authors": "Ali Dasdan",
    "abstract": "Optimum cycle ratio (OCR) algorithms are fundamental to the performance analysis of (digital or manufacturing) systems with cycles. Some applications in the computer-aided design field include cycle time and slack optimization for circuits, retiming, timing separation analysis, and rate analysis. There are many OCR algorithms, and since a superior time complexity in theory does not mean a superior time complexity in practice, or vice-versa, it is important to know how these algorithms perform in practice on real circuit benchmarks. A recent published study experimentally evaluated almost all the known OCR algorithms, and determined the fastest one among them. This article improves on that study in the following ways: (1) it focuses on the fastest OCR algorithms only; (2) it provides a unified theoretical framework and a few new results; (3) it runs these algorithms on the largest circuit benchmarks available; (4) it compares the algorithms in terms of many properties in addition to running times such as operation counts, convergence behavior, space requirements, generality, simplicity, and robustness; (5) it analyzes the experimental results using statistical techniques and provides asymptotic time complexity of each algorithm in practice; and (6) it provides clear guidance to the use and implementation of these algorithms together with our algorithmic improvements.",
    "cited_by_count": 168,
    "openalex_id": "https://openalex.org/W1983093080",
    "type": "article"
  },
  {
    "title": "Bounded-skew clock and Steiner routing",
    "doi": "https://doi.org/10.1145/293625.293628",
    "publication_date": "1998-07-01",
    "publication_year": 1998,
    "authors": "Jason Cong; Andrew B. Kahng; Cheng‐Kok Koh; C.-W. Albert Tsao",
    "corresponding_authors": "",
    "abstract": "We study the minimum-cost bounded-skew routing tree problem under the pathlength (linear) and Elmore delay models. This problem captures several engineering tradeoffs in the design of routing topologies with controlled skew. Our bounded-skew routing algorithm, called the BST/DME algorithm, extends the DME algorithm for exact zero-skew trees via the concept of a merging region . For a prescribed topology , BST/DME constructs a bounded-skew tree (BST) in two phases: (i) a bottom-up phase to construct a binary tree of merging regions which represent the loci of possible embedding points of the internal nodes, and (ii) a top-down phase to determine the exact locations of the internal nodes. We present two approaches to construct the merging regions: (i) the Boundary Merging and Embedding (BME) method which utilizes merging points that are restricted to the boundaries of merging regions, and (ii) the Interior Merging and Embedding (IME) algorithm which employs a sampling strategy and a dynamic programming-based selection technique to consider merging points that are interior to, as well as on the boundary of, the merging regions. When the topology is not prescribed, we propose a new Greedy -BST/DME algorithm which combines the merging region computation with topology generation. The Greedy-BST/DME algorithm very closely matches the best known heuristics for the zero-skew case and for the unbounded-skew case (i.e., the Steiner minimal tree problem). Experimental results show that our BST algorithms can produce a set of routing solutions with smooth skew and wire length tradeoffs.",
    "cited_by_count": 158,
    "openalex_id": "https://openalex.org/W2128237591",
    "type": "article"
  },
  {
    "title": "Constraints-driven scheduling and resource assignment",
    "doi": "https://doi.org/10.1145/785411.785416",
    "publication_date": "2003-07-01",
    "publication_year": 2003,
    "authors": "Krzysztof Kuchciński",
    "corresponding_authors": "Krzysztof Kuchciński",
    "abstract": "This paper describes a new method for modeling and solving different scheduling and resource assignment problems that are common in high-level synthesis (HLS) and system-level synthesis. It addresses assignment of resources for operations and tasks as well as their static, off-line scheduling. Different heterogeneous constraints are considered for these problems. These constraints can be grouped into two classes: problem-specific constraints and design-oriented constraints. They are uniformly modeled, in our approach, by finite domain (FD) constraints and solved using related constrained programming (CP) techniques. This provides a way to improve quality of final solutions. We have developed in Java a constraint solver engine, JaCoP ( Ja va Co nstraint P rogramming), to evaluate this approach. This solver and a related framework make it possible to model different resource assignment and scheduling problems, and handle them uniformly. The JaCoP prototype system has been extensively evaluated on a number of HLS and system-level synthesis benchmarks. We have been able to obtain optimal results together with related proofs of optimality for all HLS scheduling benchmarks and for all explored design styles (except one functional pipeline design). Many system-level benchmarks can also be solved optimally. For large randomly generated task graphs, we have used heuristic search methods and obtained results that are 1--3% worse than lower bounds or optimal results. These experiments have proved the feasibility of the presented approach.",
    "cited_by_count": 157,
    "openalex_id": "https://openalex.org/W1980310053",
    "type": "article"
  },
  {
    "title": "Behavioral synthesis techniques for intellectual property protection",
    "doi": "https://doi.org/10.1145/1080334.1080338",
    "publication_date": "2005-07-01",
    "publication_year": 2005,
    "authors": "Farinaz Koushanfar; Inki Hong; Miodrag Potkonjak",
    "corresponding_authors": "",
    "abstract": "We introduce dynamic watermarking techniques for protecting the value of intellectual property of CAD and compilation tools and reusable design components. The essence of the new approach is the addition of a set of design and timing constraints which encodes the author's signature. The constraints are selected in such a way that they result in a minimal hardware overhead while embedding a unique signature that is difficult to remove and forge. Techniques are applicable in conjunction with an arbitrary behavioral synthesis task such as scheduling, assignment, allocation, transformation, and template matching.On a large set of design examples, studies indicate the effectiveness of the new approach that results in signature data that is highly resilient, difficult to detect and remove, and yet is easy to verify and can be embedded in designs with very low hardware overhead. For example, the probability that the same design with the embedded signature is obtained by any other designers by themselves is less than 1 in 10 102 , and no register overhead was incurred. The probability of tampering, the probability that part of the embedded signature can be removed by random attempts, is shown to be extremely low, and the watermark is additionally protected from such tampering with error-correcting codes.",
    "cited_by_count": 157,
    "openalex_id": "https://openalex.org/W2006275946",
    "type": "article"
  },
  {
    "title": "Automatic generation of functional vectors using the extended finite state machine model",
    "doi": "https://doi.org/10.1145/225871.225880",
    "publication_date": "1996-01-01",
    "publication_year": 1996,
    "authors": "Kwang‐Ting Cheng; A. S. Krishnakumar",
    "corresponding_authors": "",
    "abstract": "We present a method of automatic generation of functional vectors for sequential circuits. These vectors can be used for design verification, manufacturing testing, or power estimation. A high-level description of the circuit in VHDL or C is assumed available. Our method automatically transforms the high-level description of a circuit in VHDL or C into an extended finite state machine (EFSM) model that is used to generate functional vectors. The EFSM model is a generalization of the traditional state machine model. It is a compact representation of models with local data variables and preserves many nice properties of a traditional state machine model. The theoretical background of the EFSM model is addressed in this article. Our method guarantees that the generated vectors cover every statement in the high-level description at least once. Experimental results show that a set of comprehensive functional vectors for sequential circuits with more than a hundred flip-flops can be generated automatically in a few minutes of CPU time using our prototype system.",
    "cited_by_count": 153,
    "openalex_id": "https://openalex.org/W2060461359",
    "type": "article"
  },
  {
    "title": "Warp Processors",
    "doi": "https://doi.org/10.1145/1142980.1142986",
    "publication_date": "2004-06-07",
    "publication_year": 2004,
    "authors": "Roman Lysecky; Greg Stitt; Frank Vahid",
    "corresponding_authors": "",
    "abstract": "We describe a new processing architecture, known as a warp processor, that utilizes a field-programmable gate array (FPGA) to improve the speed and energy consumption of a software binary executing on a microprocessor. Unlike previous approaches that also improve software using an FPGA but do so using a special compiler, a warp processor achieves these improvements completely transparently and operates from a standard binary. A warp processor dynamically detects the binary's critical regions, reimplements those regions as a custom hardware circuit in the FPGA, and replaces the software region by a call to the new hardware implementation of that region. While not all benchmarks can be improved using warp processing, many can, and the improvements are dramatically better than those achievable by more traditional architecture improvements. The hardest part of warp processing is that of dynamically reimplementing code regions on an FPGA, requiring partitioning, decompilation, synthesis, placement, and routing tools, all having to execute with minimal computation time and data memory so as to coexist on chip with the main processor. We describe the results of developing our warp processor. We developed a custom FPGA fabric specifically designed to enable lean place and route tools, and we developed extremely fast and efficient versions of partitioning, decompilation, synthesis, technology mapping, placement, and routing. Warp processors achieve overall application speedups of 6.3X with energy savings of 66% across a set of embedded benchmark applications. We further show that our tools utilize acceptably small amounts of computation and memory which are far less than traditional tools. Our work illustrates the feasibility and potential of warp processing, and we can foresee the possibility of warp processing becoming a feature in a variety of computing domains, including desktop, server, and embedded applications.",
    "cited_by_count": 153,
    "openalex_id": "https://openalex.org/W2293877842",
    "type": "article"
  },
  {
    "title": "Universal switch modules for FPGA design",
    "doi": "https://doi.org/10.1145/225871.225886",
    "publication_date": "1996-01-01",
    "publication_year": 1996,
    "authors": "Yao‐Wen Chang; Martin D. F. Wong; Carmen Wong",
    "corresponding_authors": "",
    "abstract": "A switch module M with W terminals on each side is said to be universal if every set of nets satisfying the dimensional constraint (i.e., the number of nets on each side of M is at most W ) is simultaneously rout able through M . In this article, we present a class of universal switch modules. Each of our switch modules has 6 W switches and switch-module flexibility three (i.e, F s =3). We prove that no switch module with less than 6 W switches can be universal. We also compare our switch modules with those used in the Xilinx XC4000 family FPGAs and the antisymmetric switch modules (with F S =3) suggested by Rose and Brown [1991]. Although these two kinds of switch modules also have F S =3 and 6 W switches, we show that they are not universal. Based on combinatorial counting techniques, we show that each of our universal switch modules can accommodate up to 25% more routing instances, compared with the XC4000-type switch module of the same size. Experimental results demonstrate that our universal switch modules improve routability at the chip level. Finally, our work also provides a theoretical insight into the important observation by Rose and Brown [1991] (based on extensive experiments) that F S =3 is often sufficient to provide high routability.",
    "cited_by_count": 149,
    "openalex_id": "https://openalex.org/W2076729972",
    "type": "article"
  },
  {
    "title": "Probabilistic transfer matrices in symbolic reliability analysis of logic circuits",
    "doi": "https://doi.org/10.1145/1297666.1297674",
    "publication_date": "2008-01-01",
    "publication_year": 2008,
    "authors": "Smita Krishnaswamy; George F. Viamontes; Igor L. Markov; John P. Hayes",
    "corresponding_authors": "",
    "abstract": "We propose the probabilistic transfer matrix (PTM) framework to capture nondeterministic behavior in logic circuits. PTMs provide a concise description of both normal and faulty behavior, and are well-suited to reliability and error susceptibility calculations. A few simple composition rules based on connectivity can be used to recursively build larger PTMs (representing entire logic circuits) from smaller gate PTMs. PTMs for gates in series are combined using matrix multiplication, and PTMs for gates in parallel are combined using the tensor product operation. PTMs can accurately calculate joint output probabilities in the presence of reconvergent fanout and inseparable joint input distributions. To improve computational efficiency, we encode PTMs as algebraic decision diagrams (ADDs). We also develop equivalent ADD algorithms for newly defined matrix operations such as eliminate_variables and eliminate_redundant_variables , which aid in the numerical computation of circuit PTMs. We use PTMs to evaluate circuit reliability and derive polynomial approximations for circuit error probabilities in terms of gate error probabilities. PTMs can also analyze the effects of logic and electrical masking on error mitigation. We show that ignoring logic masking can overestimate errors by an order of magnitude. We incorporate electrical masking by computing error attenuation probabilities, based on analytical models, into an extended PTM framework for reliability computation. We further define a susceptibility measure to identify gates whose errors are not well masked. We show that hardening a few gates can significantly improve circuit reliability.",
    "cited_by_count": 141,
    "openalex_id": "https://openalex.org/W2143674663",
    "type": "article"
  },
  {
    "title": "Performance estimation of embedded software with instruction cache modeling",
    "doi": "https://doi.org/10.1145/315773.315778",
    "publication_date": "1999-07-01",
    "publication_year": 1999,
    "authors": "Yau-Tsun Steven Li; Sharad Malik; Andrew Wolfe",
    "corresponding_authors": "",
    "abstract": "Embedded systems generally interact in some way with the outside world. This may involve measuring sensors and controlling actuators, communicating with other systems, or interacting with users. These functions impose real-time constraints on system design. Verification of these specifications requires computing an upper bound on the worst-case execution time (WCET) of a hardware/software system. Furthermore, it is critical to derive a tight upper bound on WCET in order to make efficient use of system resources. The problem of bounding WCET is particularly difficult on modern processors. These processors use cache-based memory systems that vary memory access time based on the dynamic memory access pattern of the program. This must be accurately modeled in order to tightly bound WCET. Several analysis methods have been proposed to bound WCET on processors with instruction caches. Existing approaches either search all possible program paths, an intractable problem, or they use highly pessimistic assumptions to limit the search space. In this paper we present a more effective method for modeling instruction cache activity and computing a tight bound on WCET. The method uses an integer linear programming formulation and does not require explicit enumeration of program paths. The method is implemented in the program cinderella and we present some experimental results of this implementation.",
    "cited_by_count": 135,
    "openalex_id": "https://openalex.org/W2044638745",
    "type": "article"
  },
  {
    "title": "RL-huffman encoding for test compression and power reduction in scan applications",
    "doi": "https://doi.org/10.1145/1044111.1044117",
    "publication_date": "2005-01-01",
    "publication_year": 2005,
    "authors": "Mehrdad Nourani; M.H. Tehranipour",
    "corresponding_authors": "",
    "abstract": "This article mixes two encoding techniques to reduce test data volume, test pattern delivery time, and power dissipation in scan test applications. This is achieved by using run-length encoding followed by Huffman encoding. This combination is especially effective when the percentage of don't cares in a test set is high, which is a common case in today's large systems-on-chips (SoCs). Our analysis and experimental results confirm that achieving up to an 89% compression ratio and a 93% scan-in power reduction is possible for scan-testable circuits such as ISCAS89 benchmarks.",
    "cited_by_count": 133,
    "openalex_id": "https://openalex.org/W2143404021",
    "type": "article"
  },
  {
    "title": "Combinational logic synthesis for LUT based field programmable gate arrays",
    "doi": "https://doi.org/10.1145/233539.233540",
    "publication_date": "1996-04-01",
    "publication_year": 1996,
    "authors": "Jason Cong; Yuzheng Ding",
    "corresponding_authors": "",
    "abstract": "The increasing popularity of the field programmable gate-array (FPGA) technology has generated a great deal of interest in the algorithmic study and tool development for FPGA-specific design automation problems. The most widely used FPGAs are LUT based FPGAs, in which the basic logic element is a K -input one-output lookup-table (LUT) that can implement any Boolean function of up to K variables. This unique feature of the LUT has brought new challenges to logic synthesis and optimization, resulting in many new techniques reported in recent years. This article summarizes the research results on combinational logic synthesis for LUT based FPGAs under a coherent framework. These results were dispersed in various conference proceedings and journals and under various formulations and terminologies. We first present general problem formulations, various optimization objectives and measurements, then focus on a set of commonly used basic concepts and techniques, and finally summarize existing synthesis algorithms and systems. We classify and summarize the basic techniques into two categories, namely, logic optimization and technology mapping , and describe the existing algorithms and systems in terms of how they use the classified basic techniques. A comprehensive list of references is compiled in the attached bibliography.",
    "cited_by_count": 131,
    "openalex_id": "https://openalex.org/W2052067881",
    "type": "article"
  },
  {
    "title": "Achieving autonomous power management using reinforcement learning",
    "doi": "https://doi.org/10.1145/2442087.2442095",
    "publication_date": "2013-03-01",
    "publication_year": 2013,
    "authors": "Hao Shen; Ying Tan; Jun Lu; Qing Wu; Qinru Qiu",
    "corresponding_authors": "",
    "abstract": "System level power management must consider the uncertainty and variability that come from the environment, the application and the hardware. A robust power management technique must be able to learn the optimal decision from past events and improve itself as the environment changes. This article presents a novel on-line power management technique based on model-free constrained reinforcement learning (Q-learning). The proposed learning algorithm requires no prior information of the workload and dynamically adapts to the environment to achieve autonomous power management. We focus on the power management of the peripheral device and the microprocessor, two of the basic components of a computer. Due to their different operating behaviors and performance considerations, these two types of devices require different designs of Q-learning agent. The article discusses system modeling and cost function construction for both types of Q-learning agent. Enhancement techniques are also proposed to speed up the convergence and better maintain the required performance (or power) constraint in a dynamic system with large variations. Compared with the existing machine learning based power management techniques, the Q-learning based power management is more flexible in adapting to different workload and hardware and provides a wider range of power-performance tradeoff.",
    "cited_by_count": 101,
    "openalex_id": "https://openalex.org/W1975844231",
    "type": "article"
  },
  {
    "title": "Shared recovery for energy efficiency and reliability enhancements in real-time applications with precedence constraints",
    "doi": "https://doi.org/10.1145/2442087.2442094",
    "publication_date": "2013-03-01",
    "publication_year": 2013,
    "authors": "Baoxian Zhao; Hakan Aydın; Dakai Zhu",
    "corresponding_authors": "",
    "abstract": "While Dynamic Voltage Scaling (DVS) remains as a popular energy management technique for modern computing systems, recent research has identified significant and negative impacts of voltage scaling on system reliability. To preserve system reliability under DVS settings, a number of reliability-aware power management (RA-PM) schemes have been recently studied. However, the existing RA-PM schemes normally schedule a separate recovery for each task whose execution is scaled down and are rather conservative. To overcome such conservativeness, we study in this article novel RA-PM schemes based on the shared recovery (SHR) technique. Specifically, we consider a set of frame-based real-time tasks with individual deadlines and a common period where the precedence constraints are represented by a directed acyclic graph (DAG). We first show that the earliest deadline first (EDF) algorithm can always yield a schedule where all timing and precedence constraints are met by considering the effective deadlines of tasks derived from as late as possible (ALAP) policy, provided that the task set is feasible. Then, we propose a shared recovery based frequency assignment technique (namely SHR-DAG) and prove its optimality to minimize energy consumption while preserving the system reliability. To exploit additional slack that arises from early completion of tasks, we also study a dynamic extension for SHR-DAG to improve energy efficiency and system reliability at runtime. The results from our extensive simulations show that, compared to the existing RA-PM schemes, SHR-DAG can achieve up to 35% energy savings, which is very close to the maximum achievable energy savings. More interestingly, our extensive evaluation also indicates that the new schemes offer non-trivial improvements on system reliability over the existing RA-PM schemes as well.",
    "cited_by_count": 98,
    "openalex_id": "https://openalex.org/W2119744277",
    "type": "article"
  },
  {
    "title": "Enabling IC Traceability via Blockchain Pegged to Embedded PUF",
    "doi": "https://doi.org/10.1145/3315669",
    "publication_date": "2019-04-05",
    "publication_year": 2019,
    "authors": "Md Nazmul Islam; Sandip Kundu",
    "corresponding_authors": "",
    "abstract": "Globalization of IC supply chain has increased the risk of counterfeit, tampered, and re-packaged chips in the market. Counterfeit electronics poses a security risk in safety critical applications like avionics, SCADA systems, and defense. It also affects the reputation of legitimate suppliers and causes financial losses. Hence, it becomes necessary to develop traceability solutions to ensure the integrity of supply chain, from the time of fabrication to the end of product-life, which allows a customer to verify the provenance of a device or a system. In this article, we present an IC traceability solution based on blockchain. A blockchain is a public immutable database that maintains a continuously growing list of data records secured from tampering and revision. Over the lifetime of an IC, all ownership transfer information is recorded and archived in a blockchain. This safe, verifiable method prevents any party from altering or challenging the legitimacy of the information being exchanged. However, a chain of sales record is not enough to ensure provenance of an IC. There is a need for clone-proof method for securely binding the identity of an IC to the blockchain information. In this article, we propose a method of IC supply chain traceability via blockchain pegged to embedded physically unclonable function (PUF). The blockchain provides ownership transfer record, while the PUF provides unique identification for an IC allowing it to be linked uniquely to a blockchain. Our proposed solution automates hardware and software protocols using blockchain-powered Smart Contract that allows supply chain participants to authenticate, track, trace, analyze, and provision chips throughout their entire life cycle.",
    "cited_by_count": 75,
    "openalex_id": "https://openalex.org/W2939511003",
    "type": "article"
  },
  {
    "title": "FORTIS",
    "doi": "https://doi.org/10.1145/2893183",
    "publication_date": "2016-05-27",
    "publication_year": 2016,
    "authors": "Ujjwal Guin; Qihang Shi; Domenic Forte; Mark Tehranipoor",
    "corresponding_authors": "",
    "abstract": "With the advent of globalization in the semiconductor industry, it is necessary to prevent unauthorized usage of third-party IPs (3PIPs), cloning and unwanted modification of 3PIPs, and unauthorized production of ICs. Due to the increasing complexity of ICs, system-on-chip (SoC) designers use various 3PIPs in their design to reduce time-to-market and development costs, which creates a trust issue between the SoC designer and the IP owners. In addition, as the ICs are fabricated around the globe, the SoC designers give fabrication contracts to offshore foundries to manufacture ICs and have little control over the fabrication process, including the total number of chips fabricated. Similarly, the 3PIP owners lack control over the number of fabricated chips and/or the usage of their IPs in an SoC. Existing research only partially addresses the problems of IP piracy and IC overproduction, and to the best of our knowledge, there is no work that considers IP overuse. In this article, we present a comprehensive solution for preventing IP piracy and IC overproduction by assuring forward trust between all entities involved in the SoC design and fabrication process. We propose a novel design flow to prevent IC overproduction and IP overuse. We use an existing logic encryption technique to obfuscate the netlist of an SoC or a 3PIP and propose a modification to enable manufacturing tests before the activation of chips which is absolutely necessary to prevent overproduction. We have used asymmetric and symmetric key encryption, in a fashion similar to Pretty Good Privacy (PGP), to transfer keys from the SoC designer or 3PIP owners to the chips. In addition, we also propose to attach an IP digest (a cryptographic hash of the entire IP) to the header of an IP to prevent modification of the IP by the SoC designers. We have shown that our approach is resistant to various attacks with the cost of minimal area overhead.",
    "cited_by_count": 74,
    "openalex_id": "https://openalex.org/W2400748972",
    "type": "article"
  },
  {
    "title": "Security in Automotive Networks",
    "doi": "https://doi.org/10.1145/2960407",
    "publication_date": "2017-03-13",
    "publication_year": 2017,
    "authors": "Philipp Mundhenk; Andrew Paverd; Artur Mrowca; Sebastian Steinhorst; Martin Lukasiewycz; Suhaib A. Fahmy; Samarjit Chakraborty",
    "corresponding_authors": "",
    "abstract": "With the increasing amount of interconnections between vehicles, the attack surface of internal vehicle networks is rising steeply. Although these networks are shielded against external attacks, they often do not have any internal security to protect against malicious components or adversaries who can breach the network perimeter. To secure the in-vehicle network, all communicating components must be authenticated, and only authorized components should be allowed to send and receive messages. This is achieved through the use of an authentication framework. Cryptography is widely used to authenticate communicating parties and provide secure communication channels (e.g., Internet communication). However, the real-time performance requirements of in-vehicle networks restrict the types of cryptographic algorithms and protocols that may be used. In particular, asymmetric cryptography is computationally infeasible during vehicle operation. In this work, we address the challenges of designing authentication protocols for automotive systems. We present Lightweight Authentication for Secure Automotive Networks (LASAN), a full lifecycle authentication approach. We describe the core LASAN protocols and show how they protect the internal vehicle network while complying with the real-time constraints and low computational resources of this domain. By leveraging the fixed structure of automotive networks, we minimize bandwidth and computation requirements. Unlike previous work, we also explain how this framework can be integrated into all aspects of the automotive product lifecycle, including manufacturing, vehicle maintenance, and software updates. We evaluate LASAN in two different ways: First, we analyze the security properties of the protocols using established protocol verification techniques based on formal methods. Second, we evaluate the timing requirements of LASAN and compare these to other frameworks using a new highly modular discrete event simulator for in-vehicle networks, which we have developed for this evaluation.",
    "cited_by_count": 66,
    "openalex_id": "https://openalex.org/W4293108682",
    "type": "article"
  },
  {
    "title": "Measurement-Based Worst-Case Execution Time Estimation Using the Coefficient of Variation",
    "doi": "https://doi.org/10.1145/3065924",
    "publication_date": "2017-06-13",
    "publication_year": 2017,
    "authors": "Jaume Abella; Maria Padilla; Joan del Castillo; Francisco J. Cazorla",
    "corresponding_authors": "",
    "abstract": "Extreme Value Theory (EVT) has been historically used in domains such as finance and hydrology to model worst-case events (e.g., major stock market incidences). EVT takes as input a sample of the distribution of the variable to model and fits the tail of that sample to either the Generalised Extreme Value (GEV) or the Generalised Pareto Distribution (GPD). Recently, EVT has become popular in real-time systems to derive worst-case execution time (WCET) estimates of programs. However, the application of EVT is not straightforward and requires a detailed analysis of, and customisation for, the particular problem at hand. In this article, we tailor the application of EVT to timing analysis. To that end, (1) we analyse the response time of different hardware resources (e.g., cache memories) and identify those that may lead to radically different types of execution time distributions. (2) We show that one of these distributions, known as mixture distribution, causes problems in the use of EVT. In particular, mixture distributions challenge not only properly selecting GEV/GPD parameters (i.e., location, scale and shape) but also determining the size of the sample to ensure that enough tail values are passed to EVT and that only tail values are used by EVT to fit GEV/GPD. Failing to select these parameters has a negative impact on the quality of the derived WCET estimates. We tackle these problems, by (3) proposing Measurement-Based Probabilistic Timing Analysis using the Coefficient of Variation (MBPTA-CV), a new mixture-distribution aware, WCET-suited MBPTA method that builds on recent EVT developments in other fields (e.g., finance) to automatically select the distribution parameters that best fit the maxima of the observed execution times. Our results on a simulation environment and a real board show that MBPTA-CV produces high-quality WCET estimates.",
    "cited_by_count": 65,
    "openalex_id": "https://openalex.org/W2625709394",
    "type": "article"
  },
  {
    "title": "A Tensor Network based Decision Diagram for Representation of Quantum Circuits",
    "doi": "https://doi.org/10.1145/3514355",
    "publication_date": "2022-02-18",
    "publication_year": 2022,
    "authors": "Xin Hong; Xiangzhen Zhou; Sanjiang Li; Yuan Feng; Mingsheng Ying",
    "corresponding_authors": "",
    "abstract": "Tensor networks have been successfully applied in simulation of quantum physical systems for decades. Recently, they have also been employed in classical simulation of quantum computing, in particular, random quantum circuits. This article proposes a decision diagram style data structure, called Tensor Decision Diagram (TDD), for more principled and convenient applications of tensor networks. This new data structure provides a compact and canonical representation for quantum circuits. By exploiting circuit partition, the TDD of a quantum circuit can be computed efficiently. Furthermore, we show that the operations of tensor networks essential in their applications (e.g., addition and contraction) can also be implemented efficiently in TDDs. A proof-of-concept implementation of TDDs is presented and its efficiency is evaluated on a set of benchmark quantum circuits. It is expected that TDDs will play an important role in various design automation tasks related to quantum circuits, including but not limited to equivalence checking, error detection, synthesis, simulation, and verification.",
    "cited_by_count": 35,
    "openalex_id": "https://openalex.org/W3083463047",
    "type": "article"
  },
  {
    "title": "A Survey on Approximate Multiplier Designs for Energy Efficiency: From Algorithms to Circuits",
    "doi": "https://doi.org/10.1145/3610291",
    "publication_date": "2023-07-24",
    "publication_year": 2023,
    "authors": "Ying Wu; Chuangtao Chen; Weihua Xiao; Xuan Wang; Chenyi Wen; Jie Han; Xunzhao Yin; Weikang Qian; Cheng Zhuo",
    "corresponding_authors": "",
    "abstract": "Given the stringent requirements of energy efficiency for Internet-of-Things edge devices, approximate multipliers, as a basic component of many processors and accelerators, have been constantly proposed and studied for decades, especially in error-resilient applications. The computation error and energy efficiency largely depend on how and where the approximation is introduced into a design. Thus, this article aims to provide a comprehensive review of the approximation techniques in multiplier designs ranging from algorithms and architectures to circuits. We have implemented representative approximate multiplier designs in each category to understand the impact of the design techniques on accuracy and efficiency. The designs can then be effectively deployed in high-level applications, such as machine learning, to gain energy efficiency at the cost of slight accuracy loss.",
    "cited_by_count": 25,
    "openalex_id": "https://openalex.org/W4385214089",
    "type": "article"
  },
  {
    "title": "Deep Reinforcement Learning-based Mining Task Offloading Scheme for Intelligent Connected Vehicles in UAV-aided MEC",
    "doi": "https://doi.org/10.1145/3653451",
    "publication_date": "2024-03-20",
    "publication_year": 2024,
    "authors": "Chunlin Li; Kun Jiang; Yong Zhang; Lincheng Jiang; Youlong Luo; Shaohua Wan",
    "corresponding_authors": "",
    "abstract": "The convergence of unmanned aerial vehicle (UAV)-aided mobile edge computing (MEC) networks and blockchain transforms the existing mobile networking paradigm. However, in the temporary hotspot scenario for intelligent connected vehicles (ICVs) in UAV-aided MEC networks, deploying blockchain-based services and applications in vehicles is generally impossible due to its high computational resource and storage requirements. One possible solution is to offload part of all the computational tasks to MEC servers wherever possible. Unfortunately, due to the limited availability and high mobility of the vehicles, there is still lacking simple solutions that can support low-latency and higher reliability networking services for ICVs. In this article, we study the task offloading problem of minimizing the total system latency and the optimal task offloading scheme, subject to constraints on the hover position coordinates of the UAV, the fixed bonuses, flexible transaction fees, transaction rates, mining difficulty, costs and battery energy consumption of the UAV. The problem is confirmed to be a challenging linear integer planning problem, we formulate the problem as a constrained Markov decision process. Deep Reinforcement Learning (DRL) has excellently solved sequential decision-making problems in dynamic ICVs environment, therefore, we propose a novel distributed DRL-based P-D3QN approach by using Prioritized Experience Replay strategy and the dueling double deep Q-network (D3QN) algorithm to solve the optimal task offloading policy effectively. Finally, experiment results show that compared with the benchmark scheme, the P-D3QN algorithm can bring about 26.24% latency improvement and increase about 42.26% offloading utility.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W4393002679",
    "type": "article"
  },
  {
    "title": "HDLdebugger: Streamlining HDL debugging with Large Language Models",
    "doi": "https://doi.org/10.1145/3735638",
    "publication_date": "2025-05-15",
    "publication_year": 2025,
    "authors": "Xufeng Yao; Haoyang Li; Tszho Chan; Wenyi Xiao; Mingxuan Yuan; Yu Huang; Lei Chen; Bei Yu",
    "corresponding_authors": "",
    "abstract": "In the domain of chip design, Hardware Description Languages (HDLs) play a pivotal role. However, due to the complex syntax of HDLs and the limited availability of online resources, debugging HDL codes remains a difficult and time-intensive task, even for seasoned engineers. Consequently, there is a pressing need to develop automated HDL code debugging models, which can alleviate the burden on hardware engineers. Despite the strong capabilities of Large Language Models (LLMs) in generating, completing, and debugging software code, their utilization in the specialized field of HDL debugging has been limited and, to date, has not yielded satisfactory results. In this paper, we propose an LLM-assisted HDL debugging framework, namely HDLdebugger, which consists of HDL debugging data generation via a reverse engineering approach, a search engine for retrieval-augmented generation, and a retrieval-augmented LLM fine-tuning approach. Through the integration of these components, HDLdebugger can automate and streamline HDL debugging for chip design. Our comprehensive experiments, conducted on an HDL code dataset sourced from Huawei, reveal that HDLdebugger outperforms 13 cutting-edge LLM baselines, displaying exceptional effectiveness in HDL code debugging.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4410407476",
    "type": "article"
  },
  {
    "title": "On the hardware-software partitioning problem",
    "doi": "https://doi.org/10.1145/785411.785412",
    "publication_date": "2003-07-01",
    "publication_year": 2003,
    "authors": "Marisa López‐Vallejo; Juan Carlos López",
    "corresponding_authors": "",
    "abstract": "This paper presents an in-depth study of several system partitioning procedures. It is based on the appropriate formulation of a general system model, being therefore independent of either the particular co-design problem or the specific partitioning procedure. The techniques under study are a knowledge-based system and three classical circuit partitioning algorithms (Simulated Annealing, Kernighan&amp;Lin and Hierarchical Clustering). The former has been entirely proposed by the authors in previous works while the later have been properly extended to deal with system level issues. We will show how the way the problem is solved biases the results obtained, regarding both quality and convergence rate. Consequently it is extremely important to choose the most suitable technique for the particular co-design problem that is being confronted.",
    "cited_by_count": 124,
    "openalex_id": "https://openalex.org/W1972513740",
    "type": "article"
  },
  {
    "title": "Recent developments in high-level synthesis",
    "doi": "https://doi.org/10.1145/250243.250245",
    "publication_date": "1997-01-01",
    "publication_year": 1997,
    "authors": "Youn-Long Lin",
    "corresponding_authors": "Youn-Long Lin",
    "abstract": "We survey recent developments in high level synthesis technology for VLSI design. The need for higher-level design automation tools are discussed first. We then describe some basic techniques for various subtasks of high-level synthesis. Techniques that have been proposed in the past few years (since 1994) for various subtasks of high-level synthesis are surveyed. We also survey some new synthesis objectives including testability, power efficiency, and reliability.",
    "cited_by_count": 119,
    "openalex_id": "https://openalex.org/W2134963129",
    "type": "article"
  },
  {
    "title": "Module placement for fault-tolerant microfluidics-based biochips",
    "doi": "https://doi.org/10.1145/1142980.1142987",
    "publication_date": "2004-06-07",
    "publication_year": 2004,
    "authors": "Fei Su; Krishnendu Chakrabarty",
    "corresponding_authors": "",
    "abstract": "Microfluidics-based biochips are soon expected to revolutionize clinical diagnosis, DNA sequencing, and other laboratory procedures involving molecular biology. Most microfluidic biochips today are based on the principle of continuous fluid flow and they rely on permanently etched microchannels, micropumps, and microvalves. We focus here on the automated design of “digital” droplet-based microfluidic biochips. In contrast to conventional continuous-flow systems, digital microfluidics offers dynamic reconfigurability; groups of cells in a microfluidics array can be reconfigured to change their functionality during the concurrent execution of a set of bioassays. We present a simulated annealing-based technique for module placement in such biochips. The placement procedure not only addresses chip area, but also considers fault tolerance, which allows a microfluidic module to be relocated elsewhere in the system when a single cell is detected to be faulty. Simulation results are presented for case studies involving the polymerase chain reaction and multiplexed in vitro clinical diagnostics.",
    "cited_by_count": 118,
    "openalex_id": "https://openalex.org/W2151013793",
    "type": "article"
  },
  {
    "title": "A survey of Boolean matching techniques for library binding",
    "doi": "https://doi.org/10.1145/264995.264996",
    "publication_date": "1997-07-01",
    "publication_year": 1997,
    "authors": "Luca Benini; Giovanni De Micheli",
    "corresponding_authors": "",
    "abstract": "When binding a logic network to a set of cells, a fundamental problem is recognizing whether a cell can implement a portion of the network. Boolean matching means solving this task using a formalism based on Boolean algebra. In its simplest form, Boolean matching can be posed as a tautology check. We review several approaches to Boolean matching as well as to its generalization to cases involving don't care conditions and its restriction to specific libraries such as those typical of anti-fuse based FPGAs. We then present a general formulation of Boolean matching supporting multiple-output logic cells.",
    "cited_by_count": 116,
    "openalex_id": "https://openalex.org/W2039485990",
    "type": "article"
  },
  {
    "title": "Bus-based communication synthesis on system level",
    "doi": "https://doi.org/10.1145/298865.298866",
    "publication_date": "1999-01-01",
    "publication_year": 1999,
    "authors": "Michael Gasteier; Manfred Glesner",
    "corresponding_authors": "",
    "abstract": "In this article, we present an approach to automatic generation of communication topologies for statically scheduled systems of subsystems. Given a specification containing a set of processes that communicate via abstract send and receive functions, we show how a cost-efficient communication topology consisting of one or more buses without arbitration scheme can be set up for such applications.",
    "cited_by_count": 114,
    "openalex_id": "https://openalex.org/W2137185684",
    "type": "article"
  },
  {
    "title": "Optimal test access architectures for system-on-a-chip",
    "doi": "https://doi.org/10.1145/371254.371258",
    "publication_date": "2001-01-01",
    "publication_year": 2001,
    "authors": "Krishnendu Chakrabarty",
    "corresponding_authors": "Krishnendu Chakrabarty",
    "abstract": "Test access is a major problem for core-based system-on-a-chip (SOC) designs. Since embedded cores in an SOC are not directly accessible via chip inputs and outputs, special access mechanisms are required to test them at the system level. An efficient test access architecture should also reduce test cost by minimizing test application time. We address several issues related to the design of optimal test access architectures that minimize testing time., including the assignment of cores to test buses, distribution of test data width between multiple test buses, and analysis of test data width required to satisfy an upper bound on the testing time. Even though the decision versions of all these problems are shown to be NP-complete, they can be solved exactly for practical instances using integer linear programming (ILP). As a case study, the ILP models for two hypothetical but nontrivial systems are solved using a public-domain ILP software package.",
    "cited_by_count": 113,
    "openalex_id": "https://openalex.org/W2103799547",
    "type": "article"
  },
  {
    "title": "Algorithmic aspects of hardware/software partitioning",
    "doi": "https://doi.org/10.1145/1044111.1044119",
    "publication_date": "2005-01-01",
    "publication_year": 2005,
    "authors": "Péter Arató; Zoltán Ádám Mann; András Orbán",
    "corresponding_authors": "",
    "abstract": "One of the most crucial steps in the design of embedded systems is hardware/software partitioning, that is, deciding which components of the system should be implemented in hardware and which ones in software. Most formulations of the hardware/software partitioning problem are NP-hard, so the majority of research efforts on hardware/software partitioning has focused on developing efficient heuristics.This article considers the combinatorial structure behind hardware/software partitioning. Two similar versions of the partitioning problem are defined, one of which turns out to be NP-hard, whereas the other one can be solved in polynomial time. This helps in understanding the real cause of complexity in hardware/software partitioning. Moreover, the polynomial-time algorithm serves as the basis for a highly efficient novel heuristic for the NP-hard version of the problem. Unlike general-purpose heuristics such as genetic algorithms or simulated annealing, this heuristic makes use of problem-specific knowledge, and can thus find high-quality solutions rapidly. Moreover, it has the unique characteristic that it also calculates lower bounds on the optimum solution . It is demonstrated on several benchmarks and also large random examples that the new algorithm clearly outperforms other heuristics that are generally applied to hardware/software partitioning.",
    "cited_by_count": 108,
    "openalex_id": "https://openalex.org/W2026000735",
    "type": "article"
  },
  {
    "title": "SOC test architecture design for efficient utilization of test bandwidth",
    "doi": "https://doi.org/10.1145/944027.944029",
    "publication_date": "2003-10-01",
    "publication_year": 2003,
    "authors": "Sandeep Goel; Erik Jan Marinissen",
    "corresponding_authors": "",
    "abstract": "This article deals with the design of on-chip architectures for testing large system chips (SOCs) for manufacturing defects in a modular fashion. These architectures consist of wrappers and test access mechanisms (TAMs). For an SOC with specified parameters of modules and their tests, we design an architecture that minimizes the required tester vector memory depth and test application time. In this article, we formulate the test architecture design problems for both modules with fixed- and flexible-length scan chains, assuming the relevant module parameters and a maximal SOC TAM width are given. Subsequently, we derive a formulation for an architecture-independent lower bound for the SOC test time. We analyze three types of TAM under-utilization that make the theoretical lower bound unachievable in most practical architecture instances. We present a novel architecture-independent heuristic algorithm that effectively optimizes the test architecture for a given SOC. The algorithm efficiently determines the number of TAMs and their widths, the assignment of modules to TAMs, and the wrapper design per module. We show how this algorithm can be used for optimizing both test bus and TestRail architectures with either serial or parallel test schedules. Experimental results for the ITC'02 SOC Test Benchmarks show that, compared to manual best-effort engineering approaches, we can save up to 75% in test times, while compared to previously published algorithms, we obtain comparable or better test times at negligible compute time.",
    "cited_by_count": 108,
    "openalex_id": "https://openalex.org/W2074730724",
    "type": "article"
  },
  {
    "title": "Datapath scheduling with multiple supply voltages and level converters",
    "doi": "https://doi.org/10.1145/264995.264997",
    "publication_date": "1997-07-01",
    "publication_year": 1997,
    "authors": "Mark C. Johnson; Kaushik Roy",
    "corresponding_authors": "",
    "abstract": "We present an algorithm called MOVER (Multiple Operating Voltage Energy Reduction) to minimize datapath energy dissipation through use of multiple supply voltages. In a single voltage design, the critical path length, clock period, and number of control steps limit minimization of voltage and power. Multiple supply voltages permit localized voltage reductions to take up remaining schedule slack. MOVER initially finds one minimum voltage for an entire datapath. It then determines a second voltage for operations where there is still schedule slack. New voltages con be introduced and minimized until no schedule slack remains. MOVER was exercised for a variety of DSP datapath examples. Energy savings ranged from 0% to 50% when comparing dual to single voltage results. The benefit of going from two to three voltages never exceeded 15%. Power supply costs are not reflected in these savings, but a simple analysis shows that energy savings can be achieved even with relatively inefficient DC-DC converters. Datapath resource requirements were found to vary greatly with respect to number of supplies. Area penalties ranged from 0% to 170%. Implications of multiple voltage design for IC layout and power supply requirements are discussed.",
    "cited_by_count": 107,
    "openalex_id": "https://openalex.org/W2011579672",
    "type": "article"
  },
  {
    "title": "A survey of fault tolerant methodologies for FPGAs",
    "doi": "https://doi.org/10.1145/1142155.1142167",
    "publication_date": "2006-04-01",
    "publication_year": 2006,
    "authors": "J.A. Cheatham; John M. Emmert; Stan Baumgart",
    "corresponding_authors": "",
    "abstract": "A wide range of fault tolerance methods for FPGAs have been proposed. Approaches range from simple architectural redundancy to fully on-line adaptive implementations. The applications of these methods also differ; some are used only for manufacturing yield enhancement, while others can be used in-system. This survey attempts to provide an overview of the current state of the art for fault tolerance in FPGAs. It is assumed that faults have been previously detected and diagnosed; the methods presented are targeted towards tolerating the faults. A detailed description of each method is presented. Where applicable, the methods are compared using common metrics. Results are summarized to present a succinct, comprehensive comparison of the different approaches.",
    "cited_by_count": 104,
    "openalex_id": "https://openalex.org/W1993237560",
    "type": "article"
  },
  {
    "title": "Test data compression using dictionaries with selective entries and fixed-length indices",
    "doi": "https://doi.org/10.1145/944027.944032",
    "publication_date": "2003-10-01",
    "publication_year": 2003,
    "authors": "Lei Li; Krishnendu Chakrabarty; Nur A. Touba",
    "corresponding_authors": "",
    "abstract": "We present a dictionary-based test data compression approach for reducing test data volume in SOCs. The proposed method is based on the use of a small number of ATE channels to deliver compressed test patterns from the tester to the chip and to drive a large number of internal scan chains in the circuit under test. Therefore, it is especially suitable for a reduced pin-count and low-cost DFT test environment, where a narrow interface between the tester and the SOC is desirable. The dictionary-based approach not only reduces test data volume but it also eliminates the need for additional synchronization and handshaking between the SOC and the ATE. The dictionary entries are determined during the compression procedure by solving a variant of the well-known clique partitioning problem from graph theory. Experimental results for the ISCAS-89 benchmarks and representative test data from IBM show that the proposed method outperforms a number of recently-proposed test data compression techniques. Compared to the previously proposed test data compression approach based on selective Huffman coding with variable-length indices, the proposed approach generally provides higher compression for the same amount of hardware overhead.",
    "cited_by_count": 104,
    "openalex_id": "https://openalex.org/W2108481929",
    "type": "article"
  },
  {
    "title": "PeaCE",
    "doi": "https://doi.org/10.1145/1255456.1255461",
    "publication_date": "2007-08-17",
    "publication_year": 2007,
    "authors": "Soonhoi Ha; Sungchan Kim; Choonseung Lee; Youngmin Yi; Seongnam Kwon; Young-Pyo Joo",
    "corresponding_authors": "",
    "abstract": "Existent hardware-software (HW-SW) codesign tools mainly focus on HW-SW cosimulation to build a virtual prototyping environment that enables software design and system verification without need of making a hardware prototype. Not only HW-SW cosimulation, but also HW-SW codesign methodology involves system specification, functional simulation, design-space exploration, and hardware-software cosynthesis. The PeaCE codesign environment is the first full-fledged HW-SW codesign environment that provides seamless codesign flow from functional simulation to system synthesis. Targeting for multimedia applications with real-time constraints, PeaCE specifies the system behavior with a heterogeneous composition of three models of computation and utilizes features of the formal models maximally during the whole design process. It is also a reconfigurable framework in the sense that third-party design tools can be integrated to build a customized tool chain. Experiments with industry-strength examples prove the viability of the proposed technique.",
    "cited_by_count": 99,
    "openalex_id": "https://openalex.org/W2077224773",
    "type": "article"
  },
  {
    "title": "Coordinated parallelizing compiler optimizations and high-level synthesis",
    "doi": "https://doi.org/10.1145/1027084.1027087",
    "publication_date": "2004-10-01",
    "publication_year": 2004,
    "authors": "Sumit Kumar Gupta; Rajesh K. Gupta; Nikil Dutt; Alexandru Nicolau",
    "corresponding_authors": "",
    "abstract": "We present a high-level synthesis methodology that applies a coordinated set of coarse-grain and fine-grain parallelizing transformations. The transformations are applied both during a pre-synthesis phase and during scheduling, with the objective of optimizing the results of synthesis and reducing the impact of control flow constructs on the quality of results. We first apply a set of source level presynthesis transformations that include common sub-expression elimination (CSE), copy propagation, dead code elimination and loop-invariant code motion, along with more coarse-level code restructuring transformations such as loop unrolling. We then explore scheduling techniques that use a set of aggressive speculative code motions to maximally parallelize the design by re-ordering, speculating and sometimes even duplicating operations in the design. In particular, we present a new technique called \"Dynamic CSE\" that dynamically coordinates CSE and code motions such as speculation and conditional speculation during scheduling. We implemented our parallelizing high-level synthesis in the &lt;i&gt;SPARK&lt;/i&gt; framework. This framework takes a behavioral description in ANSI-C as input and generates synthesizable register-transfer level VHDL. Our results from computationally expensive portions of three moderately complex design targets, namely, MPEG-1, MPEG-2 and the GIMP image processing tool, validate the utility of our approach to the behavioral synthesis of designs with complex control flows.",
    "cited_by_count": 98,
    "openalex_id": "https://openalex.org/W2082085231",
    "type": "article"
  },
  {
    "title": "Automata-based assertion-checker synthesis of PSL properties",
    "doi": "https://doi.org/10.1145/1297666.1297670",
    "publication_date": "2008-01-01",
    "publication_year": 2008,
    "authors": "Marc Boulé; Željko Žilić",
    "corresponding_authors": "",
    "abstract": "Assertion-based verification with languages such as PSL is gaining in importance. From assertions, one can generate hardware assertion checkers for use in emulation, simulation acceleration and silicon debug. We present techniques for checker generation of the complete set of PSL properties , including all variants of operators, both strong and weak. A full automata-based approach allows an entire assertion to be represented by a single automaton, hence allowing optimizations that can not be done in a modular approach where subcircuits are created only for individual operators. For this purpose, automata algorithms are developed for the base cases, and a complete set of rewrite rules is derived for other operators. Automata splitting is introduced for an efficient implementation of the eventually! operator.",
    "cited_by_count": 91,
    "openalex_id": "https://openalex.org/W2105167627",
    "type": "article"
  },
  {
    "title": "Power gating",
    "doi": "https://doi.org/10.1145/1835420.1835421",
    "publication_date": "2010-09-01",
    "publication_year": 2010,
    "authors": "Youngsoo Shin; Jun Seomun; Kyu-Myung Choi; Takayasu Sakurai",
    "corresponding_authors": "",
    "abstract": "Power Gating has become one of the most widely used circuit design techniques for reducing leakage current. Its concept is very simple, but its application to standard-cell VLSI designs involves many careful considerations. The great complexity of designing a power-gated circuit originates from the side effects of inserting current switches, which have to be resolved by a combination of extra circuitry and customized tools and methodologies. In this tutorial we survey these design considerations and look at the best practice within industry and academia. Topics include output isolation and data retention, current switch design and sizing, and physical design issues such as power networks, increases in area and wirelength, and power grid analysis. Designers can benefit from this tutorial by obtaining a better understanding of implications of power gating during an early stage of VLSI designs. We also review the ways in which power gating has been improved. These include reducing the sizes of switches, cutting transition delays, applying power gating to smaller blocks of circuitry, and reducing the energy dissipated in mode transitions. Power Gating has also been combined with other circuit techniques, and these hybrids are also reviewed. Important open problems are identified as a stimulus to research.",
    "cited_by_count": 82,
    "openalex_id": "https://openalex.org/W2086775835",
    "type": "article"
  },
  {
    "title": "Overhead-aware energy optimization for real-time streaming applications on multiprocessor System-on-Chip",
    "doi": "https://doi.org/10.1145/1929943.1929946",
    "publication_date": "2011-03-01",
    "publication_year": 2011,
    "authors": "Yi Wang; Hui Liu; Duo Liu; Zhiwei Qin; Zili Shao; Edwin H.‐M. Sha",
    "corresponding_authors": "",
    "abstract": "In this article, we focus on solving the energy optimization problem for real-time streaming applications on multiprocessor System-on-Chip by combining task-level coarse-grained software pipelining with DVS (Dynamic Voltage Scaling) and DPM (Dynamic Power Management) considering transition overhead, inter-core communication and discrete voltage levels. We propose a two-phase approach to solve the problem. In the first phase, we propose a coarse-grained task parallelization algorithm called RDAG to transform a periodic dependent task graph into a set of independent tasks by exploiting the periodic feature of streaming applications. In the second phase, we propose a scheduling algorithm, GeneS, to optimize energy consumption. GeneS is a genetic algorithm that can search and find the best schedule within the solution space generated by gene evolution. We conduct experiments with a set of benchmarks from E3S and TGFF. The experimental results show that our approach can achieve a 24.4% reduction in energy consumption on average compared with the previous work.",
    "cited_by_count": 76,
    "openalex_id": "https://openalex.org/W2012569660",
    "type": "article"
  },
  {
    "title": "Automatic memory partitioning and scheduling for throughput and power optimization",
    "doi": "https://doi.org/10.1145/1929943.1929947",
    "publication_date": "2011-03-01",
    "publication_year": 2011,
    "authors": "Jason Cong; Wei Jiang; Bin Liu; Yi Zou",
    "corresponding_authors": "",
    "abstract": "Memory bottleneck has become a limiting factor in satisfying the explosive demands on performance and cost in modern embedded system design. Selected computation kernels for acceleration are usually captured by nest loops, which are optimized by state-of-the-art techniques like loop tiling and loop pipelining. However, memory bandwidth bottlenecks prevent designs from reaching optimal throughput with respect to available parallelism. In this paper we present an automatic memory partitioning technique which can efficiently improve throughput and reduce energy consumption of pipelined loop kernels for given throughput constraints and platform requirements. Also, our proposed algorithm can handle general array access beyond affine array references. Our partition scheme consists of two steps. The first step considers cycle accurate scheduling information to meet the hard constraints on memory bandwidth requirements specifically for synchronized hardware designs. An ILP formulation is proposed to solve the memory partitioning and scheduling problem optimally for small designs, followed by a heuristic algorithm which is more scalable and equally effective for solving large scale problems. Experimental results show an average 6× throughput improvement on a set of real-world designs with moderate area increase (about 45% on average), given that less resource sharing opportunities exist with higher throughput in optimized designs. The second step further partitions the memory banks for reducing the dynamic power consumption of the final design. In contrast to previous approaches, our technique can statically compute memory access frequencies in polynomial time with little or no profiling. Experimental results show about 30% power reduction on the same set of benchmarks.",
    "cited_by_count": 75,
    "openalex_id": "https://openalex.org/W1988382391",
    "type": "article"
  },
  {
    "title": "Accelerating throughput-aware runtime mapping for heterogeneous MPSoCs",
    "doi": "https://doi.org/10.1145/2390191.2390200",
    "publication_date": "2013-01-01",
    "publication_year": 2013,
    "authors": "Amit Kumar Singh; Akash Kumar; Thambipillai Srikanthan",
    "corresponding_authors": "",
    "abstract": "Modern embedded systems need to support multiple time-constrained multimedia applications that often employ multiprocessor-systems-on-chip (MPSoCs). Such systems need to be optimized for resource usage and energy consumption. It is well understood that a design-time approach cannot provide timing guarantees for all the applications due to its inability to cater for dynamism in applications. However, a runtime approach consumes large computation requirements at runtime and hence may not lend well to constrained-aware mapping. In this article, we present a hybrid approach for efficient mapping of applications in such systems. For each application to be supported in the system, the approach performs extensive design-space exploration (DSE) at design time to derive multiple design points representing throughput and energy consumption at different resource combinations. One of these points is selected at runtime efficiently, depending upon the desired throughput while optimizing for energy consumption and resource usage. While most of the existing DSE strategies consider a fixed multiprocessor platform architecture, our DSE considers a generic architecture, making DSE results applicable to any target platform. All the compute-intensive analysis is performed during DSE, which leaves for minimum computation at runtime. The approach is capable of handling dynamism in applications by considering their runtime aspects and providing timing guarantees. The presented approach is used to carry out a DSE case study for models of real-life multimedia applications: H.263 decoder, H.263 encoder, MPEG-4 decoder, JPEG decoder, sample rate converter, and MP3 decoder. At runtime, the design points are used to map the applications on a heterogeneous MPSoC. Experimental results reveal that the proposed approach provides faster DSE, better design points, and efficient runtime mapping when compared to other approaches. In particular, we show that DSE is faster by 83% and runtime mapping is accelerated by 93% for some cases. Further, we study the scalability of the approach by considering applications with large numbers of tasks.",
    "cited_by_count": 67,
    "openalex_id": "https://openalex.org/W1968130443",
    "type": "article"
  },
  {
    "title": "Power Modeling for GPU Architectures Using McPAT",
    "doi": "https://doi.org/10.1145/2611758",
    "publication_date": "2014-06-01",
    "publication_year": 2014,
    "authors": "Ji‐Eun Lim; Nagesh B. Lakshminarayana; Hyesoon Kim; William J. Song; Sudhakar Yalamanchili; Wonyong Sung",
    "corresponding_authors": "",
    "abstract": "Graphics Processing Units (GPUs) are very popular for both graphics and general-purpose applications. Since GPUs operate many processing units and manage multiple levels of memory hierarchy, they consume a significant amount of power. Although several power models for CPUs are available, the power consumption of GPUs has not been studied much yet. In this article we develop a new power model for GPUs by utilizing McPAT, a CPU power tool. We generate initial power model data from McPAT with a detailed GPU configuration, and then adjust the models by comparing them with empirical data. We use the NVIDIA's Fermi architecture for building the power model, and our model estimates the GPU power consumption with an average error of 7.7% and 12.8% for the microbenchmarks and Merge benchmarks, respectively.",
    "cited_by_count": 67,
    "openalex_id": "https://openalex.org/W2043083835",
    "type": "article"
  },
  {
    "title": "Obstacle-Avoiding Algorithm in X-Architecture Based on Discrete Particle Swarm Optimization for VLSI Design",
    "doi": "https://doi.org/10.1145/2699862",
    "publication_date": "2015-03-02",
    "publication_year": 2015,
    "authors": "Xing Huang; Genggeng Liu; Wenzhong Guo; Yuzhen Niu; Guolong Chen",
    "corresponding_authors": "",
    "abstract": "Obstacle-avoiding Steiner minimal tree (OASMT) construction has become a focus problem in the physical design of modern very large-scale integration (VLSI) chips. In this article, an effective algorithm is presented to construct an OASMT based on X-architecturex for a given set of pins and obstacles. First, a kind of special particle swarm optimization (PSO) algorithm is proposed that successfully combines the classic genetic algorithm (GA), and greatly improves its own search capability. Second, a pretreatment strategy is put forward to deal with obstacles and pins, which can provide a fast information inquiry for the whole algorithm by generating a precomputed lookup table. Third, we present an efficient adjustment method, which enables particles to avoid all the obstacles by introducing some corner points of obstacles. Finally, an excellent refinement method is discussed to further enhance the quality of the final routing tree, which can improve the quality of the solution by 7.93% on average. To our best knowledge, this is the first time to specially solve the single-layer obstacle-avoiding problem in X-architecture. Experimental results show that the proposed algorithm can further shorten wirelength in the presence of obstacles. And it achieves the best solution quality in a reasonable runtime among the existing algorithms.",
    "cited_by_count": 63,
    "openalex_id": "https://openalex.org/W2072005378",
    "type": "article"
  },
  {
    "title": "A novel differential scan attack on advanced DFT structures",
    "doi": "https://doi.org/10.1145/2505014",
    "publication_date": "2013-10-01",
    "publication_year": 2013,
    "authors": "Jean Da Rolt; Giorgio Di Natale; Marie-Lise Flottes; Bruno Rouzeyre",
    "corresponding_authors": "",
    "abstract": "Scan chains insertion is the most common technique to ensure the testability of digital cores, providing high fault coverage. However, for ICs dealing with secret information, scan chains can be used as back doors for accessing secret data thus becoming a threat to system security. So far, advanced test structures used to reduce test costs (e.g., response compaction) and achieve high fault coverage (e.g., X's masking decoder) have been considered as intrinsic countermeasures against these threats. This work proposes a new generic scan-based attack demonstrating that these test structures are not sufficiently effective to prevent leakage through the test infrastructure. This generic attack can be easily adapted to several cryptographic implementations for both symmetric and public key algorithms. The proposed attack is demonstrated on several ciphers.",
    "cited_by_count": 58,
    "openalex_id": "https://openalex.org/W2025669099",
    "type": "article"
  },
  {
    "title": "Hierarchical Dynamic Thermal Management Method for High-Performance Many-Core Microprocessors",
    "doi": "https://doi.org/10.1145/2891409",
    "publication_date": "2016-08-10",
    "publication_year": 2016,
    "authors": "Hai Wang; Jian Ma; Sheldon X.-D. Tan; Chi Zhang; He Tang; Keheng Huang; Zhenghong Zhang",
    "corresponding_authors": "",
    "abstract": "It is challenging to manage the thermal behavior of many-core microprocessors while still keeping them running at high performance since the control complexity increases as the core number increases. In this article, a novel hierarchical dynamic thermal management method is proposed to overcome this challenge. The new method employs model predictive control (MPC) with task migration and a DVFS scheme to ensure smooth control behavior and negligible computing performance sacrifice. In order to be scalable to many-core systems, the hierarchical control scheme is designed with two levels. At the lower level, the cores are spatially clustered into blocks, and local task migration is used to match current power distribution with the optimal distribution calculated by MPC. At the upper level, global task migration is used with the unmatched powers from the lower level. A modified iterative minimum cut algorithm is used to assist the task migration decision making if the power number is large at the upper level. Finally, DVFS is applied to regulate the remaining unmatched powers. Experiments show that the new method outperforms existing methods and is very scalable to manage many-core microprocessors with small performance degradation.",
    "cited_by_count": 57,
    "openalex_id": "https://openalex.org/W2510850517",
    "type": "article"
  },
  {
    "title": "FH-OAOS",
    "doi": "https://doi.org/10.1145/2856033",
    "publication_date": "2016-04-20",
    "publication_year": 2016,
    "authors": "Xing Huang; Wenzhong Guo; Genggeng Liu; Guolong Chen",
    "corresponding_authors": "",
    "abstract": "With the sharp increase of very large-scale integrated (VLSI) circuit density, we are faced with many knotty issues. Particularly in the routing phase of VLSI physical design, the interconnection effects directly relate to the final performance of circuits. However, the optimization capability of traditional rectilinear architecture is limited; thus, both academia and industry have been devoted to nonrectilinear architecture in recent years, especially octilinear architecture, which is the most promising because it can greatly improve the performance of modern chips. In this article, we design FH-OAOS, an obstacle-avoiding algorithm in octilinear architecture, by constructing an obstacle-avoiding the octilinear Steiner minimal tree (OAOSMT). Our approach first constructs an obstacle-free Euclidean minimal spanning tree (OFEMST) on the given pins based on Delaunay triangulation (DT). Then, two lookup tables about OFEMST’s edge are generated, which can be seen as the information center of FH-OAOS and can provide information support for algorithm operation. Next, an efficient obstacle-avoiding strategy is proposed to convert the OFEMST into an obstacle-avoiding octilinear Steiner tree (OAOST). Finally, the generated OAOST is refined to construct the final OAOSMT by applying three effective strategies. Experimental results on various benchmarks show that FH-OAOS achieves 66.39 times speedup on average, while the average wirelength of the final OAOSMT is only 0.36% larger than the best existing solution.",
    "cited_by_count": 52,
    "openalex_id": "https://openalex.org/W2336682439",
    "type": "article"
  },
  {
    "title": "Power, Area, and Performance Optimization of Standard Cell Memory Arrays Through Controlled Placement",
    "doi": "https://doi.org/10.1145/2890498",
    "publication_date": "2016-05-27",
    "publication_year": 2016,
    "authors": "Adam Teman; Davide Rossi; Pascal Meinerzhagen; Luca Benini; Andreas Burg",
    "corresponding_authors": "",
    "abstract": "Embedded memory remains a major bottleneck in current integrated circuit design in terms of silicon area, power dissipation, and performance; however, static random access memories (SRAMs) are almost exclusively supplied by a small number of vendors through memory generators, targeted at rather generic design specifications. As an alternative, standard cell memories (SCMs) can be defined, synthesized, and placed and routed as an integral part of a given digital system, providing complete design flexibility, good energy efficiency, low-voltage operation, and even area efficiency for small memory blocks. Yet implementing an SCM block with a standard digital flow often fails to exploit the distinct and regular structure of such an array, leaving room for optimization. In this article, we present a design methodology for optimizing the physical implementation of SCM macros as part of the standard design flow. This methodology introduces controlled placement, leading to a structured, noncongested layout with close to 100% placement utilization, resulting in a smaller silicon footprint, reduced wire length, and lower power consumption compared to SCMs without controlled placement. This methodology is demonstrated on SCM macros of various sizes and aspect ratios in a state-of-the-art 28nm fully depleted silicon-on-insulator technology, and compared with equivalent macros designed with the noncontrolled, standard flow, as well as with foundry-supplied SRAM macros. The controlled SCMs provide an average 25% reduction in area as compared to noncontrolled implementations while achieving a smaller size than SRAM macros of up to 1Kbyte. Power and performance comparisons of controlled SCM blocks of a commonly found 256 × 32 (1 Kbyte) memory with foundry-provided SRAMs show greater than 65% and 10% reduction in read and write power, respectively, while providing faster access than their SRAM counterparts, despite being of an aspect ratio that is typically unfavorable for SCMs. In addition, the SCM blocks function correctly with a supply voltage as low as 0.3V, well below the lower limit of even the SRAM macros optimized for low-voltage operation. The controlled placement methodology is applied within a full-chip physical implementation flow of an OpenRISC-based test chip, providing more than 50% power reduction compared to equivalently sized compiled SRAMs under a benchmark application.",
    "cited_by_count": 52,
    "openalex_id": "https://openalex.org/W2402693132",
    "type": "article"
  },
  {
    "title": "GPlace3.0",
    "doi": "https://doi.org/10.1145/3233244",
    "publication_date": "2018-09-30",
    "publication_year": 2018,
    "authors": "Ziad Abuowaimer; Dani Maarouf; Timothy J. Martin; Jeremy Foxcroft; Gary Gréwal; Shawki Areibi; Anthony Vannelli",
    "corresponding_authors": "",
    "abstract": "Optimizing for routability during FPGA placement is becoming increasingly important, as failure to spread and resolve congestion hotspots throughout the chip, especially in the case of large designs, may result in placements that either cannot be routed or that require the router to work excessively hard to obtain success. In this article, we introduce a new, analytic routability-aware placement algorithm for Xilinx UltraScale FPGA architectures. The proposed algorithm, called GPlace3.0, seeks to optimize both wirelength and routability. Our work contains several unique features including a novel window-based procedure for satisfying legality constraints in lieu of packing, an accurate congestion estimation method based on modifications to the pathfinder global router, and a novel detailed placement algorithm that optimizes both wirelength and external pin count. Experimental results show that compared to the top three winners at the recent ISPD’16 FPGA placement contest, GPlace3.0 is able to achieve (on average) a 7.53%, 15.15%, and 33.50% reduction in routed wirelength, respectively, while requiring less overall runtime. As well, an additional 360 benchmarks were provided directly from Xilinx Inc. These benchmarks were used to compare GPlace3.0 to the most recently improved versions of the first- and second-place contest winners. Subsequent experimental results show that GPlace3.0 is able to outperform the improved placers in a variety of areas including number of best solutions found, fewest number of benchmarks that cannot be routed, runtime required to perform placement, and runtime required to perform routing.",
    "cited_by_count": 51,
    "openalex_id": "https://openalex.org/W2897505503",
    "type": "article"
  },
  {
    "title": "H3D-Transformer: A Heterogeneous 3D (H3D) Computing Platform for Transformer Model Acceleration on Edge Devices",
    "doi": "https://doi.org/10.1145/3649219",
    "publication_date": "2024-02-28",
    "publication_year": 2024,
    "authors": "Yandong Luo; Shimeng Yu",
    "corresponding_authors": "",
    "abstract": "Prior hardware accelerator designs primarily focused on single-chip solutions for 10 MB-class computer vision models. The GB-class transformer models for natural language processing (NLP) impose challenges on existing accelerator design due to the massive number of parameters and the diverse matrix multiplication (MatMul) workloads involved. This work proposes a heterogeneous 3D-based accelerator design for transformer models, which adopts an interposer substrate with multiple 3D memory/logic hybrid cubes optimized for accelerating different MatMul workloads. An approximate computing scheme is proposed to take advantage of heterogeneous computing paradigms of mixed-signal compute-in-memory (CIM) and digital tensor processing units (TPU). From the system-level evaluation results, 10 TOPS/W energy efficiency is achieved for the BERT and GPT2 model, which is about 2.6× ∼ 3.1× higher than the baseline with 7 nm TPU and stacked FeFET memory.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W4392240059",
    "type": "article"
  },
  {
    "title": "G-kway: Multilevel GPU-Accelerated k-way Graph Partitioner using Task Graph Parallelism",
    "doi": "https://doi.org/10.1145/3734522",
    "publication_date": "2025-05-03",
    "publication_year": 2025,
    "authors": "Wan Luan Lee; Dian-Lun Lin; Shui Jiang; Cheng-Hsiang Chiu; Yibo Lin; Bei Yu; Tsung-Yi Ho; Tsung‐Wei Huang",
    "corresponding_authors": "",
    "abstract": "Graph partitioning is important for the design of many CAD algorithms. However, as the graph size continues to grow, graph partitioning becomes increasingly time-consuming. Recent research has introduced parallel graph partitioners using either multi-core CPUs or GPUs. However, the speedup of existing CPU graph partitioners is typically limited to a few cores, while the performance of GPU-based solutions is algorithmically limited by available GPU memory. To overcome these challenges, we propose G-kway, an efficient multilevel GPU-accelerated k -way graph partitioner. G-kway introduces an effective union find-based coarsening and a novel independent set-based refinement algorithm to significantly accelerate both the coarsening and uncoarsening stages. Furthermore, when kernel launch overhead becomes substantial in the refinement algorithm, G-kway employs CUDA Graph-based uncoarsening to reduce the overhead and improve performance. Experimental results have shown that G-kway outperforms both the state-of-the-art CPU-based and GPU-based parallel partitioners with an average speedup of 8.6 × and 3.8 ×, respectively, while achieving comparable partitioning quality. Additionally, G-kway with CUDA Graph-based uncoarsening can further accelerate graph partitioning, achieving up to 1.93 × speedup over the default G-kway.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4410057699",
    "type": "article"
  },
  {
    "title": "FLAG: <u>F</u> inding <u>L</u> ine <u>A</u> nomalies (in RTL code) with <u>G</u> enerative AI",
    "doi": "https://doi.org/10.1145/3736411",
    "publication_date": "2025-05-20",
    "publication_year": 2025,
    "authors": "Baleegh Ahmad; Joey Ah-kiow; Benjamin Tan; Ramesh Karri; Hammond Pearce",
    "corresponding_authors": "",
    "abstract": "Bug detection in Hardware Design Languages (HDLs) is an important problem in the System-on-Chip (SoC) development cycle. It is crucial to find defects at the earliest stage possible. While most fault localization requires the use of ‘tests’ (e.g. test benches, fuzzing and assertions) and a simulation or emulation framework, the advent of Large Language Models (LLMs) provides an opportunity for a test-free fault localization approach. This paper proposes such a tool, called FLAG, which can identify functional and security defects in Register Transfer Level (RTL) code without synthesis or simulation. FLAG combines syntactic and generative AI techniques to implement fault localization in RTL code. It takes an RTL design as an input and outputs a set of line(s) that likely contain defects. It targets elements of RTL code most likely to contain bugs through static analysis means and then implements token-level and line-level analysis to obtain differences in original code and code generated by LLM to identify a line as buggy or not. The token-level approach evaluates each generated token (one at a time) and the line level approach evaluates the entire line generated by the LLM. We evaluate our approach on a corpus of synthetic and real-world bugs, of both functional and security related issues, in Verilog and SystemVerilog. Using line-level analysis, FLAG can identify 38 out of 120 real-world bugs and using token-level analysis, FLAG can identify 32 out of 81 synthetic bugs through the top-5 most likely bug locations identified without tests.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4410519228",
    "type": "article"
  },
  {
    "title": "AMSnet-KG: A Netlist Dataset for LLM-based AMS Circuit Auto-Design Using Knowledge Graph RAG",
    "doi": "https://doi.org/10.1145/3736166",
    "publication_date": "2025-05-23",
    "publication_year": 2025,
    "authors": "Yichen Shi; Zhuofu Tao; Y. Gao; Tianjia Zhou; Cheng Chang; Yaxin Wang; Bingyu Chen; Genhao Zhang; A Y Liu; Zhiping Yu; Ting-Jung Lin; Lei He",
    "corresponding_authors": "",
    "abstract": "High-performance analog and mixed-signal (AMS) circuits are mainly full-custom designed, which is time-consuming and labor-intensive. A significant portion of the effort is experience-driven, which makes the automation of AMS circuit design a formidable challenge. Large language models (LLMs) have emerged as powerful tools for Electronic Design Automation (EDA) applications, fostering advancements in the automatic design process for large-scale AMS circuits. However, the absence of high-quality datasets has led to issues such as model hallucination, which undermines the robustness of automatically generated circuit designs. To address this issue, this paper introduces AMSnet-KG, a dataset encompassing various AMS circuit schematics and netlists. We construct a knowledge graph with annotations on detailed functional and performance characteristics. Facilitated by AMSnet-KG, we propose an automated AMS circuit generation framework that utilizes the comprehensive knowledge embedded in LLMs. The flow first formulate a design strategy (e.g., circuit architecture using a number of circuit components) based on required specifications. Next, matched subcircuits are retrieved and assembled into a complete topology, and transistor sizing is obtained through Bayesian optimization. Simulation results of the netlist are automatically fed back to the LLM for further topology refinement, ensuring the circuit design specifications are met. We perform case studies of operational amplifier and comparator design to verify the automatic design flow from specifications to netlists with minimal human effort. The dataset used in this paper is available at https://ams-net.github.io/.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4410683950",
    "type": "article"
  },
  {
    "title": "Scheduling techniques for variable voltage low power designs",
    "doi": "https://doi.org/10.1145/253052.253054",
    "publication_date": "1997-04-01",
    "publication_year": 1997,
    "authors": "Yann-Rue Lin; Cheng-Tsung Hwang; Allen C.-H. Wu",
    "corresponding_authors": "",
    "abstract": "This paper presents an integer linear programming (ILP) model and a heuristic for the variable voltage scheduling problem. We present the variable voltage scheduling techniques that consider in turn timing constraints alone, resource constraints alone, and timing and resource constraints together for design space exploration. Experimental results show that our heuristic produces results competitive with those of the ILP method in a fraction of the run-time. The results also show that a wide range of design alternatives can be generated using our design space exploration method. Using different cost/delay combinations, power consumption in a single design can differ by as much as a factor of 6 when using mixed 3.3V and 5V supply voltages.",
    "cited_by_count": 95,
    "openalex_id": "https://openalex.org/W2068447851",
    "type": "article"
  },
  {
    "title": "Memory data organization for improved cache performance in embedded processor applications",
    "doi": "https://doi.org/10.1145/268424.268464",
    "publication_date": "1997-10-01",
    "publication_year": 1997,
    "authors": "Preeti Ranjan Panda; Nikil Dutt; Alexandru Nicolau",
    "corresponding_authors": "",
    "abstract": "Code generation for embedded processors opens up the possibility for several performance optimization techniques that have been ignored by traditional compilers due to compilation time constraints. We present techniques that take into account the parameters of the data caches for organizing scalar and array variables declared in embedded code into memory, with the objective of improving data cache performance. We present techniques for clustering variables to minimize compulsory cache misses, and for solving the memory assignment problem to minimize conflict cache misses. Our experiments with benchmark code kernels from DSP and other domains on the CW4001 embedded processor from LSI Logic indicate significant improvements in data cache performance by the application of our memory organization technique.",
    "cited_by_count": 89,
    "openalex_id": "https://openalex.org/W1971514468",
    "type": "article"
  },
  {
    "title": "Regression-based RTL power modeling",
    "doi": "https://doi.org/10.1145/348019.348081",
    "publication_date": "2000-07-01",
    "publication_year": 2000,
    "authors": "Alessandro Bogliolo; Luca Benini; Giovanni De Micheli",
    "corresponding_authors": "",
    "abstract": "Register-transfer level (RTL) power estimation is a key feature for synthesis-based design flows. The main challenge in establishing a sound RTL power estimation methodology is the construction of accurate, yet efficient, models of the power dissipation of functional macros. Such models should be automatically built, and should produce reliable average power estimates. In this paper we propose a general methodology for building and tuning RTL power models. We address both hard macros (presynthesized functional blocks)and soft macros (functional units for which only a synthesizable HDL description is provided). We exploit linear regression and its nonparametric extensions to express the dependency of power dissipation on input and output activity. Bottom-up off-line characterization of regression-based power macromodels is discussed in detail. Moreover, we introduce a low overhead on-line characterization method for enhancing the accuracy of off-line characterization.",
    "cited_by_count": 89,
    "openalex_id": "https://openalex.org/W2083022823",
    "type": "article"
  },
  {
    "title": "Low power realization of finite state machines—a decomposition approach",
    "doi": "https://doi.org/10.1145/234860.234862",
    "publication_date": "1996-07-01",
    "publication_year": 1996,
    "authors": "Sue-Hong Chow; Yi‐Cheng Ho; TingTing Hwang; C. L. Liu",
    "corresponding_authors": "",
    "abstract": "We present in this article a new approach to the synthesis problem for finite state machines with the reduction of power dissipation as a design objective. A finite state machine is decomposed into a number of coupled submachines. Most of the time, only one of the submachines will be activated which, consequently, could lead to substantial savings in power consumption. The key steps in our approach are: (1) decomposition of a finite state machine into submachines so that there is a high probability that state transitions will be confined to the smaller of the submachines most of the time, and (2) synthesis of the coupled submachines to optimize the logic circuits. Experimental results confirmed that our approach produced very good results (in particular, for finite state machines with a large number of states.)",
    "cited_by_count": 83,
    "openalex_id": "https://openalex.org/W2048076817",
    "type": "article"
  },
  {
    "title": "Reusing an on-chip network for the test of core-based systems",
    "doi": "https://doi.org/10.1145/1027084.1027088",
    "publication_date": "2004-10-01",
    "publication_year": 2004,
    "authors": "Érika Cota; Luigi Carro; Marcelo Lubaszewski",
    "corresponding_authors": "",
    "abstract": "Networks-on-chip are likely to become the main communication platform of systems-on-chip. To cope with the growing complexity of the test of such systems, the authors propose the reuse of the on-chip network as a test access mechanism to the cores embedded into systems that use this communication platform. An algorithm exploiting the network characteristics to minimize test time is presented. Then, the reuse strategy is evaluated considering a number of system configurations, such as different positions of the cores in the network, power consumption constraints and number of interfaces with the tester. Experimental results for the ITC'02 SOC Test Benchmarks show that the parallelization capability of the network can be exploited to reduce the system test time, whereas area and pin overhead are strongly minimized.",
    "cited_by_count": 76,
    "openalex_id": "https://openalex.org/W2036743800",
    "type": "article"
  },
  {
    "title": "A framework for heterogeneous specification and design of electronic embedded systems in SystemC",
    "doi": "https://doi.org/10.1145/1255456.1255459",
    "publication_date": "2007-08-17",
    "publication_year": 2007,
    "authors": "Fernando Herrera; Eugenio Villar",
    "corresponding_authors": "",
    "abstract": "This work proposes a methodology which enables heterogeneous specification of complex, electronic systems in SystemC supporting the integration of components under different models of computation (MoCs). This feature is necessary in order to deal with the growing complexity, concurrency, and heterogeneity of electronic embedded systems. The specification methodology is based on the SystemC standard language. Nevertheless, the use of SystemC for heterogeneous system specification is not straightforward. The first problem to be addressed is the efficient and predictable mapping of untimed events required by abstract MoCs over the discrete-event MoC on which the SystemC simulation kernel is based. This mapping is essential in order to understand the simulation results provided by the SystemC model of those MoCs. The specification methodology proposes the set of rules and guidelines required by each specific MoC. Moreover, the methodology supports a smooth integration of several MoCs in the same system specification. A set of facilities is provided covering the deficiencies of the language. These facilities constitute the methodology-specific library called HetSC. The methodology and associated library have been demonstrated to be useful for the specification of complex, heterogeneous embedded systems supporting essential design tasks such as performance analysis and SW generation.",
    "cited_by_count": 66,
    "openalex_id": "https://openalex.org/W1985142635",
    "type": "article"
  },
  {
    "title": "Multiprocessor systems synthesis for multiple use-cases of multiple applications on FPGA",
    "doi": "https://doi.org/10.1145/1367045.1367049",
    "publication_date": "2008-07-01",
    "publication_year": 2008,
    "authors": "Akash Kumar; Shakith Fernando; Yajun Ha; Bart Mesman; Henk Corporaal",
    "corresponding_authors": "",
    "abstract": "Future applications for embedded systems demand chip multiprocessor designs to meet real-time deadlines. The large number of applications in these systems generates an exponential number of use-cases. The key design automation challenges are designing systems for these use-cases and fast exploration of software and hardware implementation alternatives with accurate performance evaluation of these use-cases. These challenges cannot be overcome by current design methodologies which are semiautomated, time consuming, and error prone. In this article, we present a design methodology to generate multiprocessor systems in a systematic and fully automated way for multiple use-cases . Techniques are presented to merge multiple use-cases into one hardware design to minimize cost and design time, making it well suited for fast design-space exploration (DSE) in MPSoC systems. Heuristics to partition use-cases are also presented such that each partition can fit in an FPGA, and all use-cases can be catered for. The proposed methodology is implemented into a tool for Xilinx FPGAs for evaluation. The tool is also made available online for the benefit of the research community and is used to carry out a DSE case study with multiple use-cases of real-life applications: H263 and JPEG decoders. The generation of the entire design takes about 100 ms, and the whole DSE was completed in 45 minutes, including FPGA mapping and synthesis. The heuristics used for use-case partitioning reduce the design-exploration time elevenfold in a case study with mobile-phone applications.",
    "cited_by_count": 66,
    "openalex_id": "https://openalex.org/W2119856332",
    "type": "article"
  },
  {
    "title": "Probabilistic system-on-a-chip architectures",
    "doi": "https://doi.org/10.1145/1255456.1255466",
    "publication_date": "2007-08-17",
    "publication_year": 2007,
    "authors": "Lakshmi Narasimhan Chakrapani; Pinar Korkmaz; Bilge E. S. Akgul; Krishna V. Palem",
    "corresponding_authors": "",
    "abstract": "Parameter variations, noise susceptibility, and increasing energy dissipation of cmos devices have been recognized as major challenges in circuit and microarchitecture design in the nanometer regime. Among these, parameter variations and noise susceptibility are increasingly causing cmos devices to behave in an “unreliable” or “probabilistic” manner. To address these challenges, a shift in design paradigm from current-day deterministic designs to “statistical” or “probabilistic” designs is deemed inevitable. To respond to this need, in this article, we introduce and study an entirely novel family of probabilistic architectures: the probabilistic system-on-a-chip (psoc). psoc architectures are based on cmos devices rendered probabilistic due to noise, referred to as probabilistic CMOS or PCMOS devices. We demonstrate that in addition to harnessing the probabilistic behavior of pcmos devices, psoc architectures yield significant improvements, both in energy consumed as well as performance in the context of probabilistic or randomized applications with broad utility. All of our application and architectural savings are quantified using the product of the energy and performance, denoted (energy × performance): The pcmos-based gains are as high as a substantial multiplicative factor of over 560 when compared to a competing energy-efficient cmos-based realization. Our architectural design is application specific and involves navigating design space spanning the algorithm (application), its architecture (psoc), and the probabilistic technology (pcmos).",
    "cited_by_count": 65,
    "openalex_id": "https://openalex.org/W2030020312",
    "type": "article"
  },
  {
    "title": "Impact of intercluster communication mechanisms on ILP in clustered VLIW architectures",
    "doi": "https://doi.org/10.1145/1188275.1188276",
    "publication_date": "2007-01-01",
    "publication_year": 2007,
    "authors": "Anup Gangwar; S. Balakrishnan; Anshul Kumar",
    "corresponding_authors": "",
    "abstract": "VLIW processors have started gaining acceptance in the embedded systems domain. However, monolithic register file VLIW processors with a large number of functional units are not viable. This is because of the need for a large number of ports to support FU requirements, which makes them expensive and extremely slow. A simple solution is to break the register file into a number of smaller register files with a subset of FUs connected to it. These architectures are termed clustered VLIW processors . In this article, we first build a case for clustered VLIW processors with four or more clusters by showing that the achievable ILP in most of the media applications for a 16 ALU and 8 LD/ST VLIW processor is around 20. We then provide a classification of the intercluster interconnection design space, and show that a large part of this design space is currently unexplored. Next, using our performance evaluation methodology, we evaluate a subset of this design space and show that the most commonly used type of interconnection, RF-to-RF, fails to meet achievable performance by a large factor, while certain other types of interconnections can lower this gap considerably. We also establish that this behavior is heavily application dependent, emphasizing the importance of application-specific architecture exploration. We also present results about the statistical behavior of these different architectures by varying the number of clusters in our framework from 4 to 16. These results clearly show the advantages of one specific architecture over others. Finally, based on our results, we propose a new interconnection network, which should lower this performance gap.",
    "cited_by_count": 65,
    "openalex_id": "https://openalex.org/W2091306634",
    "type": "article"
  },
  {
    "title": "Instruction set synthesis with efficient instruction encoding for configurable processors",
    "doi": "https://doi.org/10.1145/1188275.1188283",
    "publication_date": "2007-01-01",
    "publication_year": 2007,
    "authors": "Jongeun Lee; Ki‐Young Choi; Nikil Dutt",
    "corresponding_authors": "",
    "abstract": "Application-specific instructions can significantly improve the performance, energy-efficiency, and code size of configurable processors. While generating new instructions from application-specific operation patterns has been a common way to improve the instruction set (IS) of a configurable processor, automating the design of ISs for given applications poses new challenges---how to create as well as utilize new instructions in a systematic manner, and how to choose the best set of application-specific instructions considering the various effects the new instructions may have on the data path and the compilation? To address these problems, we present a novel IS synthesis framework that optimizes the IS through an efficient instruction encoding for the given application as well as for the given data path architecture. We first build a library of new instructions created with various encoding alternatives taking into account the data path architecture constraints, and then select the best set of instructions while satisfying the instruction bitwidth constraint. We formulate the problem using integer linear programming and also present an effective heuristic algorithm. Experimental results using our technique generate ISs that show improvements of up to about 40% over the native IS for several application benchmarks running on typical embedded RISC processors.",
    "cited_by_count": 63,
    "openalex_id": "https://openalex.org/W2052329921",
    "type": "article"
  },
  {
    "title": "A retargetable parallel-programming framework for MPSoC",
    "doi": "https://doi.org/10.1145/1367045.1367048",
    "publication_date": "2008-07-01",
    "publication_year": 2008,
    "authors": "Seongnam Kwon; Yong‐Joo Kim; Woo-Chul Jeun; Soonhoi Ha; Yunheung Paek",
    "corresponding_authors": "",
    "abstract": "As more processing elements are integrated in a single chip, embedded software design becomes more challenging: It becomes a parallel programming for nontrivial heterogeneous multiprocessors with diverse communication architectures, and design constraints such as hardware cost, power, and timeliness. In the current practice of parallel programming with MPI or OpenMP, the programmer should manually optimize the parallel code for each target architecture and for the design constraints. Thus, the design-space exploration of MPSoC (multiprocessor systems-on-chip) costs become prohibitively large as software development overhead increases drastically. To solve this problem, we develop a parallel-programming framework based on a novel programming model called common intermediate code (CIC). In a CIC, functional parallelism and data parallelism of application tasks are specified independently of the target architecture and design constraints. Then, the CIC translator translates the CIC into the final parallel code, considering the target architecture and design constraints to make the CIC retargetable. Experiments with preliminary examples, including the H.263 decoder, show that the proposed parallel-programming framework increases the design productivity of MPSoC software significantly.",
    "cited_by_count": 61,
    "openalex_id": "https://openalex.org/W2134782192",
    "type": "article"
  },
  {
    "title": "BoxRouter 2.0",
    "doi": "https://doi.org/10.1145/1497561.1497575",
    "publication_date": "2009-03-01",
    "publication_year": 2009,
    "authors": "Minsik Cho; Katrina Lu; Kun Yuan; David Z. Pan",
    "corresponding_authors": "",
    "abstract": "In this article, we present BoxRouter 2.0, and discuss its architecture and implementation. As high-performance VLSI design becomes more interconnect-dominant, efficient congestion elimination in global routing is in greater demand. Hence, we propose a global router which has a strong ability to improve routability and minimize the number of vias with blockages, while minimizing wirelength. BoxRouter 2.0 is extended from BoxRouter 1.0, but can perform multi-layer routing with 2D global routing and layer assignment. Our 2D global routing is equipped with two ideas: node shifting for congestion-aware Steiner tree and robust negotiation-based A* search for routing stability. After 2D global routing, 2D-to-3D mapping is done by the layer assignment which is powered by progressive via/blockage-aware integer linear programming. Experimental results show that BoxRouter 2.0 has better routability with comparable wirelength than other routers on ISPD07 benchmark, and it can complete (no overflow) the widely used ISPD98 benchmark for the first time in the literature with the shortest wirelength. We further generate a set of harder ISPD98 benchmarks to push the limit of BoxRouter 2.0, and propose the hardened ISPD98 benchmarks to map state-of-the-art solutions for future routing research.",
    "cited_by_count": 61,
    "openalex_id": "https://openalex.org/W2155957882",
    "type": "article"
  },
  {
    "title": "Coverage-Directed Test Generation Automated by Machine Learning -- A Review",
    "doi": "https://doi.org/10.1145/2071356.2071363",
    "publication_date": "2012-01-01",
    "publication_year": 2012,
    "authors": "Charalambos Ioannides; Kerstin Eder",
    "corresponding_authors": "",
    "abstract": "The increasing complexity and size of digital designs, in conjunction with the lack of a potent verification methodology that can effectively cope with this trend, continue to inspire engineers and academics in seeking ways to further automate design verification. In an effort to increase performance and to decrease engineering effort, research has turned to artificial intelligence (AI) techniques for effective solutions. The generation of tests for simulation-based verification can be guided by machine-learning techniques. In fact, recent advances demonstrate that embedding machine-learning (ML) techniques into a coverage-directed test generation (CDG) framework can effectively automate the test generation process, making it more effective and less error-prone. This article reviews some of the most promising approaches in this field, aiming to evaluate the approaches and to further stimulate more directed research in this area.",
    "cited_by_count": 58,
    "openalex_id": "https://openalex.org/W2075599280",
    "type": "review"
  },
  {
    "title": "Divide and conquer high-level synthesis design space exploration",
    "doi": "https://doi.org/10.1145/2209291.2209302",
    "publication_date": "2012-06-01",
    "publication_year": 2012,
    "authors": "Benjamin Carrión Schäfer; Kazutoshi Wakabayashi",
    "corresponding_authors": "",
    "abstract": "A method to accelerate the Design Space Exploration (DSE) of behavioral descriptions for high-level synthesis based on a divide and conquer method called Divide and Conquer Exploration Algorithm (DC-ExpA) is presented. DC-ExpA parses an untimed behavioral description given in C or SystemC and clusters interdependent operations which are in turn explored independently by inserting synthesis directives automatically in the source code. The method then continues by combining the exploration results to obtain only Pareto-optimal designs. This method accelerates the design space exploration considerably and is compared against two previous methods: an Adaptive Simulated Annealer Exploration Algorithm (ASA-ExpA) that shows good optimality at high runtimes, and a pattern matching method called Clustering Design Space Exploration Acceleration (CDS-ExpA) that is fast but suboptimal. Our proposed method is orthogonal to previous exploration methods that focus on the exploration of resource constraints, allocation, binding, and/or scheduling. Our proposed method on contrary sets local synthesis directives that decide upon the overall architectural structure of the design (e.g., mapping certain arrays to memories or registers). Results show that DC-ExpA explores the design space on average 61% faster than ASA-ExpA, obtaining comparable results indicated by several quality indicators, for example, distance to reference Pareto-front, hypervolume, and Pareto dominance. Compared to CDS-ExpA it is 69% slower, but obtains much betters results compared to the same quality indicators.",
    "cited_by_count": 57,
    "openalex_id": "https://openalex.org/W2112748402",
    "type": "article"
  },
  {
    "title": "Scan-based attacks on linear feedback shift register based stream ciphers",
    "doi": "https://doi.org/10.1145/1929943.1929952",
    "publication_date": "2011-03-01",
    "publication_year": 2011,
    "authors": "Yu Liu; Kaijie Wu; Ramesh Karri",
    "corresponding_authors": "",
    "abstract": "Stream cipher is an important class of encryption algorithm that encrypts plaintext messages one bit at a time. Various stream ciphers are deployed in wireless telecommunication applications because they have simple hardware circuitry, are generally fast and consume very low power. On the other hand, scan-based Design-for-Test (DFT) is one of the most popular methods to test IC devices. All flip-flops in the Design Under Test are connected to one or more scan chains and the states of the flip-flops can be scanned out through these chains. In this paper, we present an attack on stream cipher implementations by determining the scan chain structure of the Linear Feedback Shift Registers in their implementations. Although scan-based DFT is a powerful testing scheme, we show that it can be used to retrieve the information stored in a crypto chip thus compromising its theoretically proven security.",
    "cited_by_count": 50,
    "openalex_id": "https://openalex.org/W2116881166",
    "type": "article"
  },
  {
    "title": "Conditional Diagnosability of k-Ary n-Cubes under the PMC Model",
    "doi": "https://doi.org/10.1145/2348839.2348850",
    "publication_date": "2012-10-01",
    "publication_year": 2012,
    "authors": "Nai-Wen Chang; Tzu-Yin Lin; Sun‐Yuan Hsieh",
    "corresponding_authors": "",
    "abstract": "Processor fault diagnosis plays an important role in measuring the reliability of multiprocessor systems and the diagnosis of many well-known interconnection networks. The conditional diagnosability, which is more general than the classical diagnosability, is to measure the diagnosability of a multiprocessor system under the assumption that all of the neighbors of any node in the system cannot fail at the same time. This study shows that the conditional diagnosability for k -ary n -cubes under the PMC model is 8 n − 7 for k ≥ 4 and n ≥ 4.",
    "cited_by_count": 49,
    "openalex_id": "https://openalex.org/W2007866826",
    "type": "article"
  },
  {
    "title": "Security-Aware Design Methodology and Optimization for Automotive Systems",
    "doi": "https://doi.org/10.1145/2803174",
    "publication_date": "2015-12-02",
    "publication_year": 2015,
    "authors": "Chung‐Wei Lin; Bowen Zheng; Qi Zhu; Alberto Sangiovanni‐Vincentelli",
    "corresponding_authors": "",
    "abstract": "In this article, we address both security and safety requirements and solve security-aware design problems for the controller area network (CAN) protocol and time division multiple access (TDMA)-based protocols. To provide insights and guidelines for other similar security problems with limited resources and strict timing constraints, we propose a general security-aware design methodology to address security with other design constraints in a holistic framework and optimize design objectives. The security-aware design methodology is further applied to solve a security-aware design problem for vehicle-to-vehicle (V2V) communications with dedicated short-range communication (DSRC) technology. Experimental results demonstrate the effectiveness of our approaches in system design without violating design constraints and indicate that it is necessary to consider security together with other metrics during design stages.",
    "cited_by_count": 49,
    "openalex_id": "https://openalex.org/W2196434470",
    "type": "article"
  },
  {
    "title": "Dynamic power management for multidomain system-on-chip platforms",
    "doi": "https://doi.org/10.1145/2504904",
    "publication_date": "2013-10-01",
    "publication_year": 2013,
    "authors": "Paul Bogdan; Radu Mărculescu; Siddharth Jain",
    "corresponding_authors": "",
    "abstract": "Reducing energy consumption in multiprocessor systems-on-chip (MPSoCs) where communication happens via the network-on-chip (NoC) approach calls for multiple voltage/frequency island (VFI)-based designs. In turn, such multi-VFI architectures need efficient, robust, and accurate runtime control mechanisms that can exploit the workload characteristics in order to save power. Despite being tractable, the linear control models for power management cannot capture some important workload characteristics (e.g., fractality, nonstationarity) observed in heterogeneous NoCs; if ignored, such characteristics lead to inefficient communication and resources allocation, as well as high power dissipation in MPSoCs. To mitigate such limitations, we propose a new paradigm shift from power optimization based on linear models to control approaches based on fractal-state equations. As such, our approach is the first to propose a controller for fractal workloads with precise constraints on state and control variables and specific time bounds. Our results show that significant power savings can be achieved at runtime while running a variety of benchmark applications.",
    "cited_by_count": 47,
    "openalex_id": "https://openalex.org/W2006288141",
    "type": "article"
  },
  {
    "title": "CDTA",
    "doi": "https://doi.org/10.1145/3005346",
    "publication_date": "2017-04-03",
    "publication_year": 2017,
    "authors": "Kun Yang; Domenic Forte; Mark Tehranipoor",
    "corresponding_authors": "",
    "abstract": "The Internet of Things (IoT) is transforming the way we live and work by increasing the connectedness of people and things on a scale that was once unimaginable. However, the vulnerabilities in the IoT supply chain have raised serious concerns about the security and trustworthiness of IoT devices and components within them. Testing for device provenance, detection of counterfeit integrated circuits (ICs) and systems, and traceability of IoT devices are challenging issues to address. In this article, we develop a novel radio-frequency identification (RFID)-based system suitable for counterfeit detection, traceability, and authentication in the IoT supply chain called CDTA . CDTA is composed of different types of on-chip sensors and in-system structures that collect necessary information to detect multiple counterfeit IC types (recycled, cloned, etc.), track and trace IoT devices, and verify the overall system authenticity. Central to CDTA is an RFID tag employed as storage and a channel to read the information from different types of chips on the printed circuit board (PCB) in both power-on and power-off scenarios. CDTA sensor data can also be sent to the remote server for authentication via an encrypted Ethernet channel when the IoT device is deployed in the field. A novel board ID generator is implemented by combining outputs of physical unclonable functions (PUFs) embedded in the RFID tag and different chips on the PCB. A light-weight RFID protocol is proposed to enable mutual authentication between RFID readers and tags. We also implement a secure interchip communication on the PCB. Simulations and experimental results using Spartan 3E FPGAs demonstrate the effectiveness of this system. The efficiency of the radio-frequency (RF) communication has also been verified via a PCB prototype with a printed slot antenna.",
    "cited_by_count": 44,
    "openalex_id": "https://openalex.org/W2604603188",
    "type": "article"
  },
  {
    "title": "CAD-Base",
    "doi": "https://doi.org/10.1145/3315574",
    "publication_date": "2019-04-18",
    "publication_year": 2019,
    "authors": "Kanad Basu; Samah Mohamed Saeed; Christian Pilato; Mohammed Ashraf; Mohammed Thari Nabeel; Krishnendu Chakrabarty; Ramesh Karri",
    "corresponding_authors": "",
    "abstract": "Fabless semiconductor companies design system-on-chips (SoC) by using third-party intellectual property (IP) cores and fabricate them in offshore, potentially untrustworthy foundries. Owing to the globally distributed electronics supply chain, security has emerged as a serious concern. In this article, we explore electronics computer-aided design (CAD) software as a threat vector that can be exploited to introduce vulnerabilities into the SoC. We show that all electronics CAD tools—high-level synthesis, logic synthesis, physical design, verification, test, and post-silicon validation—are potential threat vectors to different degrees. We have demonstrated CAD-based attacks on several benchmarks, including the commercial ARM Cortex M0 processor [1].",
    "cited_by_count": 44,
    "openalex_id": "https://openalex.org/W2936148765",
    "type": "article"
  },
  {
    "title": "Thermal-Sensor-Based Occupancy Detection for Smart Buildings Using Machine-Learning Methods",
    "doi": "https://doi.org/10.1145/3200904",
    "publication_date": "2018-06-28",
    "publication_year": 2018,
    "authors": "Hengyang Zhao; Qi Hua; Hai‐Bao Chen; Yaoyao Ye; Hai Wang; Sheldon X.-D. Tan; Esteban Tlelo‐Cuautle",
    "corresponding_authors": "",
    "abstract": "In this article, we propose a novel approach to detect the occupancy behavior of a building through the temperature and/or possible heat source information. The new method can be used for energy reduction and security monitoring for emerging smart buildings. Our work is based on a building simulation program, EnergyPlus, from the Department of Energy. EnergyPlus can model various time-series inputs to a building such as ambient temperature; heating, ventilation, and air-conditioning (HVAC) inputs; power consumption of electronic equipment; lighting; and number of occupants in a room, sampled each hour, and produce resulting temperature traces of zones (rooms). Two machine-learning-based approaches for detecting human occupancy of a smart building are applied herein, namely support vector regression (SVR) and recurrent neural network (RNN). Experimental results with SVR show that the four-feature model provides accurate detection rates, giving a 0.638 average error and 5.32% error rate, and the five-feature model delivers a 0.317 average error and 2.64% error rate. This indicates that SVR is a viable option for occupancy detection. In the RNN method, Elman’s RNN can estimate occupancy information of each room of a building with high accuracy. It has local feedback in each layer and, for a five-zone building, it is very accurate for occupancy behavior estimation. The error level, in terms of number of people, can be as low as 0.0056 on average and 0.288 at maximum, considering ambient, room temperatures, and HVAC powers as detectable information. Without knowing HVAC powers, the estimation error can still be 0.044 on average, and only 0.71% estimated points have errors greater than 0.5. Our article further shows that both methods deliver similar accuracy in the occupancy detection. But the SVR model is more stable for adding or removing features of the system, while the RNN method can deliver more accuracy when the features used in the model do not change a lot.",
    "cited_by_count": 43,
    "openalex_id": "https://openalex.org/W2810361442",
    "type": "article"
  },
  {
    "title": "Reconfigurable Scan Networks",
    "doi": "https://doi.org/10.1145/2699863",
    "publication_date": "2015-03-02",
    "publication_year": 2015,
    "authors": "Rafał Baranowski; Michael A. Kochte; Hans-Joachim Wunderlich",
    "corresponding_authors": "",
    "abstract": "Efficient access to on-chip instrumentation is a key requirement for post-silicon validation, test, debug, bringup, and diagnosis. Reconfigurable scan networks, as proposed by, for example, IEEE Std 1687-2014 and IEEE Std 1149.1-2013, emerge as an effective and affordable means to cope with the increasing complexity of on-chip infrastructure. Reconfigurable scan networks are often hierarchical and may have complex structural and functional dependencies. Common approaches for scan verification based on static structural analysis and functional simulation are not sufficient to ensure correct operation of these types of architectures. To access an instrument in a reconfigurable scan network, a scan-in bit sequence must be generated according to the current state and structure of the network. Due to sequential and combinational dependencies, the access pattern generation process ( pattern retargeting ) poses a complex decision and optimization problem. This article presents the first generalized formal model that considers structural and functional dependencies of reconfigurable scan networks and is directly applicable to 1687-2014-based and 1149.1-2013-based scan architectures. This model enables efficient formal verification of complex scan networks, as well as automatic generation of access patterns. The proposed pattern generation method supports concurrent access to multiple target scan registers ( access merging ) and generates short scan-in sequences.",
    "cited_by_count": 42,
    "openalex_id": "https://openalex.org/W2040760679",
    "type": "article"
  },
  {
    "title": "Security Assessment of Dynamically Obfuscated Scan Chain Against Oracle-guided Attacks",
    "doi": "https://doi.org/10.1145/3444960",
    "publication_date": "2021-03-13",
    "publication_year": 2021,
    "authors": "M. Sazadur Rahman; Adib Nahiyan; Fahim Rahman; Saverio Fazzari; Kenneth Plaks; Farimah Farahmandi; Domenic Forte; Mark Tehranipoor",
    "corresponding_authors": "",
    "abstract": "Logic locking has emerged as a promising solution to protect integrated circuits against piracy and tampering. However, the security provided by existing logic locking techniques is often thwarted by Boolean satisfiability (SAT)-based oracle-guided attacks. Criteria for successful SAT attacks on locked circuits include: (i) the circuit under attack is fully combinational, or (ii) the attacker has scan chain access. To address the threat posed by SAT-based attacks, we adopt the dynamically obfuscated scan chain (DOSC) architecture and illustrate its resiliency against the SAT attacks when inserted into the scan chain of an obfuscated design. We demonstrate, both mathematically and experimentally, that DOSC exponentially increases the resiliency against key extraction by SAT attack and its variants. Our results show that the mathematical estimation of attack complexity correlates to the experimental results with an accuracy of 95% or better. Along with the formal proof, we model DOSC architecture to its equivalent combinational circuit and perform SAT attack to evaluate its resiliency empirically. Our experiments demonstrate that SAT attack on DOSC-inserted benchmark circuits timeout at minimal test time overhead, and while DOSC requires less than 1% area and power overhead.",
    "cited_by_count": 36,
    "openalex_id": "https://openalex.org/W3139374995",
    "type": "article"
  },
  {
    "title": "Correlated Multi-objective Multi-fidelity Optimization for HLS Directives Design",
    "doi": "https://doi.org/10.1145/3503540",
    "publication_date": "2022-03-08",
    "publication_year": 2022,
    "authors": "Qi Sun; Tinghuan Chen; Siting Liu; Jianli Chen; Hao Yu; Bei Yu",
    "corresponding_authors": "",
    "abstract": "High-level synthesis (HLS) tools have gained great attention in recent years because it emancipates engineers from the complicated and heavy hardware description language writing and facilitates the implementations of modern applications (e.g., deep learning models) on Field-programmable Gate Array (FPGA) , by using high-level languages and HLS directives. However, finding good HLS directives is challenging, due to the time-consuming design processes, the balances among different design objectives, and the diverse fidelities (accuracies of data) of the performance values between the consecutive FPGA design stages. To find good HLS directives, a novel automatic optimization algorithm is proposed to explore the Pareto designs of the multiple objectives while making full use of the data with different fidelities from different FPGA design stages. Firstly, a non-linear Gaussian process (GP) is proposed to model the relationships among the different FPGA design stages. Secondly, for the first time, the GP model is enhanced as correlated GP (CGP) by considering the correlations between the multiple design objectives, to find better Pareto designs. Furthermore, we extend our model to be a deep version deep CGP (DCGP) by using the deep neural network to improve the kernel functions in Gaussian process models, to improve the characterization capability of the models, and learn better feature representations. We test our design method on some public benchmarks (including general matrix multiplication and sparse matrix-vector multiplication) and deep learning-based object detection model iSmart2 on FPGA. Experimental results show that our methods outperform the baselines significantly and facilitate the deep learning designs on FPGA.",
    "cited_by_count": 26,
    "openalex_id": "https://openalex.org/W4221000689",
    "type": "article"
  },
  {
    "title": "A Comprehensive Survey on Electronic Design Automation and Graph Neural Networks: Theory and Applications",
    "doi": "https://doi.org/10.1145/3543853",
    "publication_date": "2022-06-14",
    "publication_year": 2022,
    "authors": "Daniela Sánchez Lopera; Lorenzo Servadei; Gamze Naz Kiprit; Robert Wille; Wolfgang Ecker",
    "corresponding_authors": "",
    "abstract": "Driven by Moore’s law, the chip design complexity is steadily increasing. Electronic Design Automation (EDA) has been able to cope with the challenging very large-scale integration process, assuring scalability, reliability, and proper time-to-market. However, EDA approaches are time and resource demanding, and they often do not guarantee optimal solutions. To alleviate these, Machine Learning (ML) has been incorporated into many stages of the design flow, such as in placement and routing. Many solutions employ Euclidean data and ML techniques without considering that many EDA objects are represented naturally as graphs. The trending Graph Neural Networks (GNNs) are an opportunity to solve EDA problems directly using graph structures for circuits, intermediate Register Transfer Levels, and netlists. In this article, we present a comprehensive review of the existing works linking the EDA flow for chip design and GNNs. We map those works to a design pipeline by defining graphs, tasks, and model types. Furthermore, we analyze their practical implications and outcomes. We conclude by summarizing challenges faced when applying GNNs within the EDA design flow.",
    "cited_by_count": 25,
    "openalex_id": "https://openalex.org/W4282821489",
    "type": "article"
  },
  {
    "title": "A Survey on Security of Digital Microfluidic Biochips: Technology, Attack, and Defense",
    "doi": "https://doi.org/10.1145/3494697",
    "publication_date": "2022-02-12",
    "publication_year": 2022,
    "authors": "Wenzhong Guo; Sihuang Lian; Chen Dong; Zhenyi Chen; Xing Huang",
    "corresponding_authors": "",
    "abstract": "As an emerging lab-on-a-chip technology platform, digital microfluidic biochips (DMFBs) have been widely used for executing various laboratory procedures in biochemistry and biomedicine such as gene sequencing and near-patient diagnosis, with the advantages of low reagent consumption, high precision, and miniaturization and integration. With the ongoing rapid deployment of DMFBs, however, these devices are now facing serious and complicated security challenges that not only damage their functional integrity but also affect their system reliability. In this article, we present a systematic review of DMFB security, focusing on both the state-of-the-art attack and defense techniques. First, the overall security situation, the working principle, and the corresponding fabrication technology of DMFBs are introduced. Afterwards, existing attack approaches are divided into several categories and discussed in detail, including denial of service, intellectual property piracy, bioassay tampering, layout modification, actuation sequence tampering, concentration altering, parameter modification, reading forgery, and information leakage. To prevent biochips from being damaged by these attack behaviors, a number of defense measures have been proposed in recent years. Accordingly, we further classify these techniques into three categories according to their respective defense purposes, including confidentiality protection, integrity protection, and availability protection. These measures, to varying degrees, can provide effective protection for DMFBs. Finally, key trends and directions for future research that are related to the security of DMFBs are discussed from several aspects, e.g., manufacturing materials, biochip structure, and usage environment, thus providing new ideas for future biochip protection.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W4211260778",
    "type": "article"
  },
  {
    "title": "A High-Performance Accelerator for Real-Time Super-Resolution on Edge FPGAs",
    "doi": "https://doi.org/10.1145/3652855",
    "publication_date": "2024-03-16",
    "publication_year": 2024,
    "authors": "Hongduo Liu; Yijian Qian; Youqiang Liang; Bin Zhang; Z. Liu; Tao He; Wenqian Zhao; Jiangbo Lu; Bei Yu",
    "corresponding_authors": "",
    "abstract": "In the digital era, the prevalence of low-quality images contrasts with the widespread use of high-definition displays, primarily due to low-resolution cameras and compression technologies. Image super-resolution (SR) techniques, particularly those leveraging deep learning, aim to enhance these images for high-definition presentation. However, real-time execution of deep neural network (DNN)-based SR methods at the edge poses challenges due to their high computational and storage requirements. To address this, field-programmable gate arrays (FPGAs) have emerged as a promising platform, offering flexibility, programmability, and adaptability to evolving models. Previous FPGA-based SR solutions have focused on reducing computational and memory costs through aggressive simplification techniques, often sacrificing the quality of the reconstructed images. This paper introduces a novel SR network specifically designed for edge applications, which maintains reconstruction performance while managing computation costs effectively. Additionally, we propose an architectural design that enables the real-time and end-to-end inference of the proposed SR network on embedded FPGAs. Our key contributions include a tailored SR algorithm optimized for embedded FPGAs, a DSP-enhanced design that achieves a significant four-fold speedup, a novel scalable cache strategy for handling large feature maps, optimization of DSP cascade consumption, and a constraint optimization approach for resource allocation. Experimental results demonstrate that our FPGA-specific accelerator surpasses existing solutions, delivering superior throughput, energy efficiency, and image quality.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W4392885482",
    "type": "article"
  },
  {
    "title": "Survey of Machine Learning for Software-assisted Hardware Design Verification: Past, Present, and Prospect",
    "doi": "https://doi.org/10.1145/3661308",
    "publication_date": "2024-04-24",
    "publication_year": 2024,
    "authors": "Nan Wu; Yingjie Li; Hang Yang; Hanqiu Chen; Steve Dai; Cong Hao; Cunxi Yu; Yuan Xie",
    "corresponding_authors": "",
    "abstract": "With the ever-increasing hardware design complexity comes the realization that efforts required for hardware verification increase at an even faster rate. Driven by the push from the desired verification productivity boost and the pull from leap-ahead capabilities of machine learning (ML), recent years have witnessed the emergence of exploiting ML-based techniques to improve the efficiency of hardware verification. In this article, we present a panoramic view of how ML-based techniques are embraced in hardware design verification, from formal verification to simulation-based verification, from academia to industry, and from current progress to future prospects. We envision that the adoption of ML-based techniques will pave the road for more scalable, more intelligent, and more productive hardware verification.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W4395074196",
    "type": "article"
  },
  {
    "title": "BDD-based logic synthesis for LUT-based FPGAs",
    "doi": "https://doi.org/10.1145/605440.605442",
    "publication_date": "2002-10-01",
    "publication_year": 2002,
    "authors": "Navin Vemuri; Priyank Kalla; Russell Tessier",
    "corresponding_authors": "",
    "abstract": "Contemporary FPGA synthesis is a multiphase process that involves technology-independent logic optimization followed by FPGA-specific mapping to a target FPGA technology. Conventional technology-independent transformations target standard cells and are unable to optimize circuits with constraints and goals specific to FPGA architectures. This article describes an FPGA-specific logic synthesis approach, which unites multilevel logic transformation, decomposition, and optimization techniques into a single synthesis framework. This system performs network transformation, decomposition, and optimization at an early stage to generate a network that can be directly mapped onto FPGAs. Our techniques are built upon a BDD-based logic decomposition system. With this system, both AND-OR decompositions and AND-XOR decompositions can be identified, resulting in large area savings for synthesized XOR-intensive circuits. To induce good decompositions, a maximum fanout free cone (MFFC) -based partial clustering and collapsing technique is used. This step is followed by an area-minimizing variable partitioning heuristic that decomposes collapsed nodes into LUT-feasible subfunctions. As a postprocessing step, a performance-driven resynthesis phase is performed to alleviate increased delay caused by excessive logic sharing. We compare the quality of results obtained using our techniques with those of academic (BoolMap, SIS) and industry (Altera Quartus) FPGA synthesis tools. Experimental results indicate that the circuits generated by our techniques are not only smaller, but are also significantly faster than those synthesized by conventional FPGA synthesis tools. Furthermore, the computation times required by our techniques are significantly smaller than those of previous techniques.",
    "cited_by_count": 76,
    "openalex_id": "https://openalex.org/W2056693747",
    "type": "article"
  },
  {
    "title": "Floorplan representations",
    "doi": "https://doi.org/10.1145/606603.606607",
    "publication_date": "2003-01-01",
    "publication_year": 2003,
    "authors": "Bo Yao; Hongyu Chen; Chung‐Kuan Cheng; Ronald Graham",
    "corresponding_authors": "",
    "abstract": "Floorplan representation is a fundamental issue in designing a floorplanning algorithm. In this paper, we first present a twin binary trees structure for mosaic floorplans. It is a nonredundant representation. We then derive the exact number of configurations for mosaic floorplans and slicing floorplans. Finally, the relationships between various state-of-the-art floorplan representations are discussed and explored.",
    "cited_by_count": 76,
    "openalex_id": "https://openalex.org/W2165891825",
    "type": "article"
  },
  {
    "title": "Efficient scheduling of conditional behaviors for high-level synthesis",
    "doi": "https://doi.org/10.1145/567270.567272",
    "publication_date": "2002-07-01",
    "publication_year": 2002,
    "authors": "Apostolos Kountouris; Christophe Wolinski",
    "corresponding_authors": "",
    "abstract": "As hardware designs get increasingly complex and time-to-market constraints get tighter there is strong motivation for high-level synthesis (HLS). HLS must efficiently handle both dataflow-dominated and controlflow-dominated designs as well as designs of a mixed nature. In the past efficient tools for the former type have been developed but so far HLS of conditional behaviors lags behind. To bridge this gap an efficient scheduling heuristic for conditional behaviors is presented. Our heuristic and the techniques it utilizes are based on a unifying design representation appropriate for both types of behavioral descriptions, enabling the proposed heuristic to exploit under the same framework several well-established techniques (chaining, multicycling) as well as conditional resource sharing and speculative execution which are essential in efficiently scheduling conditional behaviors. Preliminary experiments confirm the effectiveness of our approach and prompted the development of the CODESIS HLS tool for further experimentation.",
    "cited_by_count": 69,
    "openalex_id": "https://openalex.org/W1982480183",
    "type": "article"
  },
  {
    "title": "Large-scale circuit placement",
    "doi": "https://doi.org/10.1145/1059876.1059886",
    "publication_date": "2005-04-01",
    "publication_year": 2005,
    "authors": "Jason Cong; Joseph R. Shinnerl; Min Xie; Tim Kong; Xin Yuan",
    "corresponding_authors": "",
    "abstract": "Placement is one of the most important steps in the RTL-to-GDSII synthesis process, as it directly defines the interconnects, which have become the bottleneck in circuit and system performance in deep submicron technologies. The placement problem has been studied extensively in the past 30 years. However, recent studies show that existing placement solutions are surprisingly far from optimal. The first part of this tutorial summarizes results from recent optimality and scalability studies of existing placement tools. These studies show that the results of leading placement tools from both industry and academia may be up to 50% to 150% away from optimal in total wirelength. If such a gap can be closed, the corresponding performance improvement will be equivalent to several technology-generation advancements. The second part of the tutorial highlights the recent progress on large-scale circuit placement, including techniques for wirelength minimization, routability optimization, and performance optimization.",
    "cited_by_count": 68,
    "openalex_id": "https://openalex.org/W2164007237",
    "type": "article"
  },
  {
    "title": "Cache optimization for embedded processor cores",
    "doi": "https://doi.org/10.1145/1027084.1027086",
    "publication_date": "2004-10-01",
    "publication_year": 2004,
    "authors": "Arijit Ghosh; Tony Givargis",
    "corresponding_authors": "",
    "abstract": "Embedded microprocessor cores are increasingly being used in embedded and mobile devices. The software running on these embedded microprocessor cores is often a priori known; thus, there is an opportunity for customizing the cache subsystem for improved performance. In this work, we propose an efficient algorithm to directly compute cache parameters satisfying desired performance criteria. Our approach avoids simulation and exhaustive exploration, and, instead, relies on an exact algorithmic approach. We demonstrate the feasibility of our algorithm by applying it to a large number of embedded system benchmarks.",
    "cited_by_count": 67,
    "openalex_id": "https://openalex.org/W2112096947",
    "type": "article"
  },
  {
    "title": "Optimal wiresizing for interconnects with multiple sources",
    "doi": "https://doi.org/10.1145/238997.239018",
    "publication_date": "1996-10-01",
    "publication_year": 1996,
    "authors": "Jason Cong; Lei He",
    "corresponding_authors": "",
    "abstract": "In this paper, we study the optimal wiresizing problem for nets with multiple sources under the RC tree model and the Elmore delay model. We decompose the routing tree for a multisource net into the source subtree (SST) and a set of loading subtrees (LSTs), and show that the optimal wiresizing solution satisfies a number of interesting properties, including: LST separability, the LST monotone property, the SST local monotone property, and the dominance property. Furthermore, we study the optimal wiresizing problem using a variable segment-division rather than an a priori fixed segment-division as in all previous works and reveal the bundled refinement property. These properties lead to efficient algorithms to compute the optimal solutions. We have tested our algorithm on nets extracted from the multilayer layout for a high-performance Intel microprocessor. Accurate SPICE simulation shows that our methods reduce the average delay by up to 23.5% and the maximum delay by up to 37.8%, respectively, for the submicron CMOS technology when compared to the minimal wire width solution. In addition, the algorithm based on the variable segment-division yields a speedup of over 100× time and does not lose any accuracy, when compared with the algorithm based on the a priori fixed segment-division.",
    "cited_by_count": 66,
    "openalex_id": "https://openalex.org/W2024993977",
    "type": "article"
  },
  {
    "title": "Frequent value encoding for low power data buses",
    "doi": "https://doi.org/10.1145/1013948.1013953",
    "publication_date": "2004-07-01",
    "publication_year": 2004,
    "authors": "Jun Yang; Rajiv Gupta; Chuanjun Zhang",
    "corresponding_authors": "",
    "abstract": "Since the I/O pins of a CPU are a significant source of energy consumption, work has been done on developing encoding schemes for reducing switching activity on external buses. Modest reductions in switching can be achieved for data and address buses using a number of general purpose encoding schemes. However, by exploiting the characteristic of memory reference locality, switching activity on the address bus can be reduced by as much as 66%. Till now no characteristic has been identified that can be used to achieve similar reductions in switching activity on the data bus. We have discovered a characteristic of values transmitted over the data bus according to which a small number of distinct values, called frequent values , account for 32% of transmissions over the external data bus. Exploiting this characteristic we have developed an encoding scheme that we call the FV encoding scheme. To implement this scheme we have also developed a technique for dynamically identifying the frequent values which compares quite favorably with an optimal offline algorithm. Our experiments show that FV encoding of 32 frequent values yields an average reduction of 30% (with on-chip data cache) and 49% (without on-chip data cache) in data bus switching activity for SPEC95 and mediabench programs. Moreover the reduction in switching achieved by FV encoding is 2 to 4 times the reduction achieved by the bus-invert coding scheme and 1.5 to 3 times the reduction achieved by the adaptive method . The overall energy savings on data bus we attained considering the coder overhead is 29%.",
    "cited_by_count": 63,
    "openalex_id": "https://openalex.org/W2028362246",
    "type": "article"
  },
  {
    "title": "Handling inverted temperature dependence in static timing analysis",
    "doi": "https://doi.org/10.1145/1142155.1142158",
    "publication_date": "2006-04-01",
    "publication_year": 2006,
    "authors": "Ali Dasdan; Ivan Hom",
    "corresponding_authors": "",
    "abstract": "In digital circuit design, it is typically assumed that cell delay increases with decreasing voltage and increasing temperature. This assumption is the basis of the cornering approach with cell libraries in static timing analysis (STA). However, this assumption breaks down at low supply voltages because cell delay can decrease with increasing temperature. This phenomenon is caused by a competition between mobility and threshold voltage to dominate cell delay. We refer to this phenomenon as the inverted temperature dependence (ITD). Due to ITD, it becomes very difficult to analytically determine the temperatures that maximize or minimize the delay of a cell or a path. As such, ITD has profound consequences for STA: (1) ITD essentially invalidates the approach of defining corners by independently varying voltage and temperature; (2) ITD makes it more difficult to find short paths, leading to difficulties in detecting hold time violations; and (3) the effect of ITD will worsen as supply voltages decrease and threshold voltage variations increase. This article analyzes the consequences of ITD in STA and proposes a proper handling of ITD in an industrial sign-off STA tool. To the best of our knowledge, this article is the first such work.",
    "cited_by_count": 62,
    "openalex_id": "https://openalex.org/W2150322402",
    "type": "article"
  },
  {
    "title": "DRDU",
    "doi": "https://doi.org/10.1145/1230800.1230807",
    "publication_date": "2007-04-01",
    "publication_year": 2007,
    "authors": "Ilya Issenin; Erik Brockmeyer; Miguel Miranda; Nikil Dutt",
    "corresponding_authors": "",
    "abstract": "In multimedia and other streaming applications, a significant portion of energy is spent on data transfers. Exploiting data reuse opportunities in the application, we can reduce this energy by making copies of frequently used data in a small local memory and replacing speed- and power-inefficient transfers from main off-chip memory by more efficient local data transfers. In this article we present an automated approach for analyzing these opportunities in a program that allows modification of the program to use custom scratch-pad memory configurations comprising a hierarchical set of buffers for local storage of frequently reused data. Using our approach we are able to both reduce energy consumption of the memory subsystem when using a scratch-pad memory by about a factor of two, on average, and improve memory system performance compared to a cache of the same size.",
    "cited_by_count": 56,
    "openalex_id": "https://openalex.org/W2059843741",
    "type": "article"
  },
  {
    "title": "Allocating power ground vias in 3D ICs for simultaneous power and thermal integrity",
    "doi": "https://doi.org/10.1145/1529255.1529263",
    "publication_date": "2009-05-01",
    "publication_year": 2009,
    "authors": "Hao Yu; Joanna Ho; Lei He",
    "corresponding_authors": "",
    "abstract": "The existing work on via allocation in 3D ICs ignores power/ground vias' ability to simultaneously reduce voltage bounce and remove heat. This article develops the first in-depth study on the allocation of power/ground vias in 3D ICs with simultaneous consideration of power and thermal integrity. By identifying principal ports and parameters, effective electrical and thermal macromodels are employed to provide dynamic power and thermal integrity as well as sensitivity with respect to via density. With the use of sensitivity, an efficient via allocation simultaneously driven by power and thermal integrity is developed. Experiments show that, compared to sequential power and thermal optimization using static integrity, sequential optimization using the dynamic integrity reduces nonsignal vias by up to 18%, and simultaneous optimization using dynamic integrity further reduces nonsignal vias by up to 45.5%.",
    "cited_by_count": 54,
    "openalex_id": "https://openalex.org/W2002435556",
    "type": "article"
  },
  {
    "title": "Design and implementation of an efficient wear-leveling algorithm for solid-state-disk microcontrollers",
    "doi": "https://doi.org/10.1145/1640457.1640463",
    "publication_date": "2009-12-01",
    "publication_year": 2009,
    "authors": "Li-Pin Chang; Chun-Da Du",
    "corresponding_authors": "",
    "abstract": "Solid-state disks (SSDs) are storage devices that emulate hard drives with flash memory. They have been widely deployed in mobile computers as disk drive replacements. Flash memory is organized in terms of erase blocks. With the current technology, a block can reach the end of its lifetime after thousands of erasure operations. Wear leveling is a technique to evenly erase the entire flash memory so that all blocks remain alive as long as possible. This study introduces a new wear-leveling algorithm based the observation that, under a real-life mobile PC's workload, most erasure operations are contributed by a small fraction of blocks. Our key ideas are 1) moving rarely updated data to a block that is extraordinarily worn and 2) avoiding repeatedly involving a block in wear-leveling activities. This study presents a successful implementation of the proposed wear-leveling algorithm using about 200 bytes of RAM in an SSD controller rated at 33 MHz. Evaluation results show that this algorithm achieves even wear of the entire flash memory while reducing the overheads of extra flash-memory operations.",
    "cited_by_count": 54,
    "openalex_id": "https://openalex.org/W2007962663",
    "type": "article"
  },
  {
    "title": "A memetic approach to the automatic design of high-performance analog integrated circuits",
    "doi": "https://doi.org/10.1145/1529255.1529264",
    "publication_date": "2009-05-01",
    "publication_year": 2009,
    "authors": "Bo Liu; F.V. Fernández; Georges Gielen; R. Castro‐López; E. Roca",
    "corresponding_authors": "",
    "abstract": "This article introduces an evolution-based methodology, named memetic single-objective evolutionary algorithm (MSOEA), for automated sizing of high-performance analog integrated circuits. Memetic algorithms may achieve higher global and local search ability by properly combining operators from different standard evolutionary algorithms. By integrating operators from the differential evolution algorithm, from the real-coded genetic algorithm, operators inspired by the simulated annealing algorithm, and a set of constraint handling techniques, MSOEA specializes in handling analog circuit design problems with numerous and tight design constraints. The method has been tested through the sizing of several analog circuits. The results show that design specifications are met and objective functions are highly optimized. Comparisons with available methods like genetic algorithm and differential evolution in conjunction with static penalty functions, as well as with intelligent selection-based differential evolution, are also carried out, showing that the proposed algorithm has important advantages in terms of constraint handling ability and optimization quality.",
    "cited_by_count": 48,
    "openalex_id": "https://openalex.org/W2074625726",
    "type": "article"
  },
  {
    "title": "Efficient and Deterministic Parallel Placement for FPGAs",
    "doi": "https://doi.org/10.1145/1970353.1970355",
    "publication_date": "2011-06-01",
    "publication_year": 2011,
    "authors": "Adrian Ludwin; Vaughn Betz",
    "corresponding_authors": "",
    "abstract": "We describe a parallel simulated annealing algorithm for FPGA placement. The algorithm proposes and evaluates multiple moves in parallel, and has been incorporated into Altera’s Quartus II CAD system. Across a set of 18 industrial benchmark circuits, we achieve geometric average speedups during the quench of 2.7x and 4.0x on four and eight processors, respectively, with individual circuits achieving speedups of up to 3.6x and 5.9x. Over the course of the entire anneal, we achieve speedups of up to 2.8x and 3.7x, with geometric average speedups of 2.1x and 2.4x. Our algorithm is the first parallel placer to optimize for criteria other than wirelength, such as critical path length, and is one of the few deterministic parallel placement algorithms. We discuss the challenges involved in combining these two features and the new techniques we used to overcome them. We also quantify the impact of maintaining determinism on eight cores, and find that while it reduces performance by approximately 15% relative to an ideal speedup of 8.0x, hardware limitations are a larger factor and reduce performance by 30--40%. We then suggest possible enhancements to allow our approach to scale to 16 cores and beyond.",
    "cited_by_count": 48,
    "openalex_id": "https://openalex.org/W2114820519",
    "type": "article"
  },
  {
    "title": "Formal verification of code motion techniques using data-flow-driven equivalence checking",
    "doi": "https://doi.org/10.1145/2209291.2209303",
    "publication_date": "2012-06-01",
    "publication_year": 2012,
    "authors": "Chandan Karfa; Chittaranjan Mandal; Dipankar Sarkar",
    "corresponding_authors": "",
    "abstract": "A formal verification method for checking correctness of code motion techniques is presented in this article. Finite State Machine with Datapath (FSMD) models have been used to represent the input and the output behaviors of each synthesis step. The method introduces cutpoints in one FSMD, visualizes its computations as concatenation of paths from cutpoints to cutpoints, and then identifies equivalent finite path segments in the other FSMD; the process is then repeated with the FSMDs interchanged. Unlike many other reported techniques, the method is capable of verifying both uniform and nonuniform code motion techniques. It has been underlined in this work that for nonuniform code motions, identifying equivalent path segments involves model checking of some data-flow properties. Our method automatically identifies the situations where such properties are needed to be checked during equivalence checking, generates the appropriate properties, and invokes the model checking tool NuSMV to verify them. The correctness and the complexity of the method have been dealt with. Experimental results demonstrate the effectiveness of the method.",
    "cited_by_count": 40,
    "openalex_id": "https://openalex.org/W2060763196",
    "type": "article"
  },
  {
    "title": "A survey and taxonomy of on-chip monitoring of multicore systems-on-chip",
    "doi": "https://doi.org/10.1145/2442087.2442088",
    "publication_date": "2013-03-01",
    "publication_year": 2013,
    "authors": "George Kornaros; Dionisios Pnevmatikatos",
    "corresponding_authors": "",
    "abstract": "Billion transistor systems-on-chip increasingly require dynamic management of their hardware components and careful coordination of the tasks that they carry out. Diverse real-time monitoring functions assist towards this objective through the collection of important system metrics, such as throughput of processing elements, communication latency, or resource utilization for each application. The online evaluation of these metrics can result in localized or global decisions that attempt to improve aspects of system behavior, system performance, quality-of-service, power and thermal effects under nominal conditions. This work provides a comprehensive categorization of monitoring approaches used in multiprocessor SoCs. As adaptive systems are encountered in many disciplines, it is imperative to present the prominent research efforts in developing online monitoring methods. To this end we offer a taxonomy that groups strongly related techniques that designers increasingly use to produce more efficient and adaptive chips. The provided classification helps to understand and compare architectural mechanisms that can be used in systems, while one can envisage the innovations required to build real adaptive and intelligent systems-on-chip.",
    "cited_by_count": 39,
    "openalex_id": "https://openalex.org/W2044321560",
    "type": "article"
  },
  {
    "title": "Eh?Placer",
    "doi": "https://doi.org/10.1145/2899381",
    "publication_date": "2016-04-19",
    "publication_year": 2016,
    "authors": "Nima Karimpour Darav; Andrew Kennings; Aysa Fakheri Tabrizi; David T. Westwick; Laleh Behjat",
    "corresponding_authors": "",
    "abstract": "The placement problem has become more complex and challenging due to a wide variety of complicated constraints imposed by modern process technologies. Some of the most challenging constraints and objectives were highlighted during the most recent ACM/IEEE International Symposium on Physical Design (ISPD) contests. In this article, the framework of Eh?Placer and its developed algorithms are elaborated, with the main focus on modern technology constraints and runtime. The technology constraints considered as part of Eh?Placer are fence region, target density, and detailed routability constraints. We present a complete description on how these constraints are considered in different stages of Eh?Placer. The results obtained from the contests indicate that Eh?Placer is able to efficiently handle modern technology constraints and ranks highly among top academic placement tools.",
    "cited_by_count": 39,
    "openalex_id": "https://openalex.org/W2336236367",
    "type": "article"
  },
  {
    "title": "Adaptive virtual channel partitioning for network-on-chip in heterogeneous architectures",
    "doi": "https://doi.org/10.1145/2504906",
    "publication_date": "2013-10-01",
    "publication_year": 2013,
    "authors": "Jaekyu Lee; Si Li; Hyesoon Kim; Sudhakar Yalamanchili",
    "corresponding_authors": "",
    "abstract": "Current heterogeneous chip-multiprocessors (CMPs) integrate a GPU architecture on a die. However, the heterogeneity of this architecture inevitably exerts different pressures on shared resource management due to differing characteristics of CPU and GPU cores. We consider how to efficiently share on-chip resources between cores within the heterogeneous system, in particular the on-chip network. Heterogeneous architectures use an on-chip interconnection network to access shared resources such as last-level cache tiles and memory controllers, and this type of on-chip network will have a significant impact on performance. In this article, we propose a feedback-directed virtual channel partitioning (VCP) mechanism for on-chip routers to effectively share network bandwidth between CPU and GPU cores in a heterogeneous architecture. VCP dedicates a few virtual channels to CPU and GPU applications with separate injection queues. The proposed mechanism balances on-chip network bandwidth for applications running on CPU and GPU cores by adaptively choosing the best partitioning configuration. As a result, our mechanism improves system throughput by 15% over the baseline across 39 heterogeneous workloads.",
    "cited_by_count": 38,
    "openalex_id": "https://openalex.org/W2105572195",
    "type": "article"
  },
  {
    "title": "Streaming Sorting Networks",
    "doi": "https://doi.org/10.1145/2854150",
    "publication_date": "2016-05-27",
    "publication_year": 2016,
    "authors": "Marcela Zuluaga; Peter Milder; Markus Püschel",
    "corresponding_authors": "",
    "abstract": "Sorting is a fundamental problem in computer science and has been studied extensively. Thus, a large variety of sorting methods exist for both software and hardware implementations. For the latter, there is a trade-off between the throughput achieved and the cost (i.e., the logic and storage invested to sort n elements). Two popular solutions are bitonic sorting networks with O ( n log 2 n ) logic and storage, which sort n elements per cycle, and linear sorters with O ( n ) logic and storage, which sort n elements per n cycles. In this article, we present new hardware structures that we call streaming sorting networks , which we derive through a mathematical formalism that we introduce, and an accompanying domain-specific hardware generator that translates our formal mathematical description into synthesizable RTL Verilog. With the new networks, we achieve novel and improved cost-performance trade-offs. For example, assuming that n is a two-power and w is any divisor of n , one class of these networks can sort in n /; w cycles with O ( w log 2 n ) logic and O ( n log 2 n ) storage; the other class that we present sorts in n log 2 n /; w cycles with O ( w ) logic and O ( n ) storage. We carefully analyze the performance of these networks and their cost at three levels of abstraction: (1) asymptotically, (2) exactly in terms of the number of basic elements needed, and (3) in terms of the resources required by the actual circuit when mapped to a field-programmable gate array. The accompanying hardware generator allows us to explore the entire design space, identify the Pareto-optimal solutions, and show superior cost-performance trade-offs compared to prior work.",
    "cited_by_count": 38,
    "openalex_id": "https://openalex.org/W2472334012",
    "type": "article"
  },
  {
    "title": "Error-Correcting Sample Preparation with Cyberphysical Digital Microfluidic Lab-on-Chip",
    "doi": "https://doi.org/10.1145/2898999",
    "publication_date": "2016-08-10",
    "publication_year": 2016,
    "authors": "Sudip Poddar; Sarmishtha Ghoshal; Krishnendu Chakrabarty; Bhargab B. Bhattacharya",
    "corresponding_authors": "",
    "abstract": "Digital (droplet-based) microfluidic technology offers an attractive platform for implementing a wide variety of biochemical laboratory protocols, such as point-of-care diagnosis, DNA analysis, target detection, and drug discovery. A digital microfluidic biochip consists of a patterned array of electrodes on which tiny fluid droplets are manipulated by electrical actuation sequences to perform various fluidic operations, for example, dispense, transport, mix, or split. However, because of the inherent uncertainty of fluidic operations, the outcome of biochemical experiments performed on-chip can be erroneous even if the chip is tested a priori and deemed to be defect-free. In this article, we address an important error recoverability problem in the context of sample preparation. We assume a cyberphysical environment, in which the physical errors, when detected online at selected checkpoints with integrated sensors, can be corrected through recovery techniques. However, almost all prior work on error recoverability used checkpointing-based rollback approach, that is, re-execution of certain portions of the protocol starting from the previous checkpoint. Unfortunately, such techniques are expensive both in terms of assay completion time and reagent cost, and can never ensure full error-recovery in deterministic sense. We consider imprecise droplet mix-split operations and present a novel roll-forward approach where the erroneous droplets, thus produced, are used in the error-recovery process, instead of being discarded or remixed. All erroneous droplets participate in the dilution process and they mutually cancel or reduce the concentration-error when the target droplet is reached. We also present a rigorous analysis that reveals the role of volumetric-error on the concentration of a sample to be prepared, and we describe the layout of a lab-on-chip that can execute the proposed cyberphysical dilution algorithm. Our analysis reveals that fluidic errors caused by unbalanced droplet splitting can be classified as being either critical or non-critical , and only those of the former type require correction to achieve error-free sample dilution. Simulation experiments on various sample preparation test cases demonstrate the effectiveness of the proposed method.",
    "cited_by_count": 37,
    "openalex_id": "https://openalex.org/W2510233378",
    "type": "article"
  },
  {
    "title": "Gate-Level Information Flow Tracking for Security Lattices",
    "doi": "https://doi.org/10.1145/2676548",
    "publication_date": "2014-11-18",
    "publication_year": 2014,
    "authors": "Wei Hu; Dejun Mu; Jason Oberg; Baolei Mao; Mohit Tiwari; Timothy Sherwood; Ryan Kastner",
    "corresponding_authors": "",
    "abstract": "High-assurance systems found in safety-critical infrastructures are facing steadily increasing cyber threats. These critical systems require rigorous guarantees in information flow security to prevent confidential information from leaking to an unclassified domain and the root of trust from being violated by an untrusted party. To enforce bit-tight information flow control, gate-level information flow tracking (GLIFT) has recently been proposed to precisely measure and manage all digital information flows in the underlying hardware, including implicit flows through hardware-specific timing channels. However, existing work in this realm either restricts to two-level security labels or essentially targets two-input primitive gates and several simple multilevel security lattices. This article provides a general way to expand the GLIFT method for multilevel security. Specifically, it formalizes tracking logic for an arbitrary Boolean gate under finite security lattices, presents a precise tracking logic generation method for eliminating false positives in GLIFT logic created in a constructive manner, and illustrates application scenarios of GLIFT for enforcing multilevel information flow security. Experimental results show various trade-offs in precision and performance of GLIFT logic created using different methods. It also reveals the area and performance overheads that should be expected when expanding GLIFT for multilevel security.",
    "cited_by_count": 36,
    "openalex_id": "https://openalex.org/W2121894892",
    "type": "article"
  },
  {
    "title": "Security-Aware Obfuscated Priority Assignment for Automotive CAN Platforms",
    "doi": "https://doi.org/10.1145/2831232",
    "publication_date": "2016-01-28",
    "publication_year": 2016,
    "authors": "Martin Lukasiewycz; Philipp Mundhenk; Sebastian Steinhorst",
    "corresponding_authors": "",
    "abstract": "Security in automotive in-vehicle networks is an increasing problem with the growing connectedness of road vehicles. This article proposes a security-aware priority assignment for automotive controller area network (CAN) platforms with the aim of mitigating scaling effects of attacks on vehicle fleets. CAN is the dominating field bus in the automotive domain due to its simplicity, low cost, and robustness. While messages might be encrypted to enhance the security of CAN systems, their priorities are usually identical for automotive platforms, comprising generally a large number of vehicle models. As a result, the identifier uniquely defines which message is sent, allowing attacks to scale across a fleet of vehicles with the same platform. As a remedy, we propose a methodology that is capable of determining obfuscated message identifiers for each individual vehicle. Since identifiers directly represent message priorities, the approach has to take the resulting response time variations into account while satisfying application deadlines for each vehicle schedule separately. Our approach relies on Quadratically Constrained Quadratic Program (QCQP) solving in two stages, specifying first a set of feasible fixed priorities and subsequently bounded priorities for each message. With the obtained bounds, obfuscated identifiers are determined, using a very fast randomized sampling. The experimental results, consisting of a large set of synthetic test cases and a realistic case study, give evidence of the efficiency of the proposed approach in terms of scalability. The results also show that the diversity of obtained identifiers is effectively optimized with our approach, resulting in a very good obfuscation of CAN messages in in-vehicle communication.",
    "cited_by_count": 36,
    "openalex_id": "https://openalex.org/W2268537092",
    "type": "article"
  },
  {
    "title": "Reconfigurable Battery Systems",
    "doi": "https://doi.org/10.1145/3301301",
    "publication_date": "2019-03-07",
    "publication_year": 2019,
    "authors": "Shaheer Muhammad; Muhammad Usman Rafique; Shuai Li; Zili Shao; Qixin Wang; Xue Liu",
    "corresponding_authors": "",
    "abstract": "In a reconfigurable battery pack, the connections among cells can be changed during operation to form different configurations. This can lead a battery, a passive two-terminal device, to a smart battery that can reconfigure itself according to the requirement to enhance operational performance. Several hardware architectures with different levels of complexities have been proposed. Some researchers have used existing hardware and demonstrated improved performance on the basis of novel optimization and scheduling algorithms. The possibility of software techniques to benefit the energy storage systems is exciting, and it is the perfect time for such methods as the need for high-performance and long-lasting batteries is on the rise. This novel field requires new understanding, principles, and evaluation metrics of proposed schemes. In this article, we systematically discuss and critically review the state of the art. This is the first effort to compare the existing hardware topologies in terms of flexibility and functionality. We provide a comprehensive review that encompasses all existing research works, starting from the details of the individual battery including modeling and properties as well as fixed-topology traditional battery packs. To stimulate further research in this area, we highlight key challenges and open problems in this domain.",
    "cited_by_count": 36,
    "openalex_id": "https://openalex.org/W2921018162",
    "type": "article"
  },
  {
    "title": "High-Throughput Logic Timing Simulation on GPGPUs",
    "doi": "https://doi.org/10.1145/2714564",
    "publication_date": "2015-06-24",
    "publication_year": 2015,
    "authors": "Stefan Holst; Michael E. Imhof; Hans-Joachim Wunderlich",
    "corresponding_authors": "",
    "abstract": "Many EDA tasks such as test set characterization or the precise estimation of power consumption, power droop and temperature development, require a very large number of time-aware gate-level logic simulations. Until now, such characterizations have been feasible only for rather small designs or with reduced precision due to the high computational demands. The new simulation system presented here is able to accelerate such tasks by more than two orders of magnitude and provides for the first time fast and comprehensive timing simulations for industrial-sized designs. Hazards, pulse-filtering, and pin-to-pin delay are supported for the first time in a GPGPU accelerated simulator, and the system can easily be extended to even more realistic delay models and further applications. A sophisticated mapping with efficient memory utilization and access patterns as well as minimal synchronizations and control flow divergence is able to use the full potential of GPGPU architectures. To provide such a mapping, we combine for the first time the versatility of event-based timing simulation and multi-dimensional parallelism used in GPU-based gate-level simulators. The result is a throughput-optimized timing simulation algorithm, which runs many simulation instances in parallel and at the same time fully exploits gate-parallelism within the circuit.",
    "cited_by_count": 35,
    "openalex_id": "https://openalex.org/W2277653173",
    "type": "article"
  },
  {
    "title": "Performance and Thermal Tradeoffs for Energy-Efficient Monolithic 3D Network-on-Chip",
    "doi": "https://doi.org/10.1145/3223046",
    "publication_date": "2018-08-22",
    "publication_year": 2018,
    "authors": "Dongjin Lee; Sourav Das; Janardhan Rao Doppa; Partha Pratim Pande; Krishnendu Chakrabarty",
    "corresponding_authors": "",
    "abstract": "Three-dimensional (3D) integration enables the design of high-performance and energy-efficient network on chip (NoC) architectures as communication backbones for manycore chips. To exploit the benefits of the vertical dimension of 3D integration, through-silicon-via (TSV) has been predominantly used in state-of-the-art manycore chip design. However, for TSV-based systems, high power density and the resultant thermal hotspot remain major concerns from the perspectives of chip functionality and overall reliability. The power consumption and thermal profiles of 3D NoCs can be improved by incorporating a Voltage-Frequency-Island (VFI)-based power management strategy. However, due to inherent thermal constraints of a TSV-based 3D system, we are unable to fully exploit the benefits offered by the power management methodology. In this context, emergence of monolithic 3D (M3D) integration has opened up new possibility of designing ultra-low-power and high-performance circuits and systems. The smaller dimensions of the inter-layer dielectric (ILD) and monolithic inter-tier vias (MIVs) offer high-density integration, flexibility of partitioning logic blocks across multiple tiers, and significant reduction of total wire-length. In this work, we present the first-ever study of the performance-thermal tradeoffs for energy efficient monolithic 3D manycore chips. In particular, we present a comparative performance evaluation of M3D NoCs with respect to their conventional TSV-based counterparts. We demonstrate that the proposed M3D-based NoC architecture incorporating VFI-based power management achieves a maximum of 29.4% lower energy-delay-product (EDP) compared to the TSV-based designs for a large set of benchmarks. We also demonstrate that the M3D-based NoC shows up to 29.1% lower maximum temperature than the TSV-based counterpart for these benchmarks.",
    "cited_by_count": 34,
    "openalex_id": "https://openalex.org/W2888269620",
    "type": "article"
  },
  {
    "title": "An Energy-aware Online Learning Framework for Resource Management in Heterogeneous Platforms",
    "doi": "https://doi.org/10.1145/3386359",
    "publication_date": "2020-05-13",
    "publication_year": 2020,
    "authors": "Sumit K. Mandal; Ganapati Bhat; Janardhan Rao Doppa; Partha Pratim Pande; Ümit Y. Ogras",
    "corresponding_authors": "",
    "abstract": "Mobile platforms must satisfy the contradictory requirements of fast response time and minimum energy consumption as a function of dynamically changing applications. To address this need, systems-on-chip (SoC) that are at the heart of these devices provide a variety of control knobs, such as the number of active cores and their voltage/frequency levels. Controlling these knobs optimally at runtime is challenging for two reasons. First, the large configuration space prohibits exhaustive solutions. Second, control policies designed offline are at best sub-optimal, since many potential new applications are unknown at design-time. We address these challenges by proposing an online imitation learning approach. Our key idea is to construct an offline policy and adapt it online to new applications to optimize a given metric (e.g., energy). The proposed methodology leverages the supervision enabled by power-performance models learned at runtime. We demonstrate its effectiveness on a commercial mobile platform with 16 diverse benchmarks. Our approach successfully adapts the control policy to an unknown application after executing less than 25% of its instructions.",
    "cited_by_count": 32,
    "openalex_id": "https://openalex.org/W3026208461",
    "type": "article"
  },
  {
    "title": "Graph Neural Networks for High-Level Synthesis Design Space Exploration",
    "doi": "https://doi.org/10.1145/3570925",
    "publication_date": "2022-11-11",
    "publication_year": 2022,
    "authors": "Lorenzo Ferretti; Andrea Cini; Georgios Zacharopoulos; Cesare Alippi; Laura Pozzi",
    "corresponding_authors": "",
    "abstract": "High-level Synthesis (HLS) Design-Space Exploration (DSE) aims at identifying Pareto-optimal synthesis configurations whose exhaustive search is unfeasible due to the design-space dimensionality and the prohibitive computational cost of the synthesis process. Within this framework, we address the design automation problem by proposing graph neural networks that jointly predict acceleration performance and hardware costs of a synthesized behavioral specification given optimization directives. Learned models can be used to rapidly approach the Pareto curve by guiding the DSE, taking into account performance and cost estimates. The proposed method outperforms traditional HLS-driven DSE approaches, by accounting for the arbitrary length of computer programs and the invariant properties of the input. We propose a novel hybrid control and dataflow graph representation that enables training the graph neural network on specifications of different hardware accelerators. Our approach achieves prediction accuracy comparable with that of state-of-the-art simulators without having access to analytical models of the HLS compiler. Finally, the learned representation can be exploited for DSE in unexplored configuration spaces by fine-tuning on a small number of samples from the new target domain. The outcome of the empirical evaluation of this transfer learning shows strong results against state-of-the-art baselines in relevant benchmarks.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W4308916273",
    "type": "article"
  },
  {
    "title": "MOEA/D vs. NSGA-II: A Comprehensive Comparison for Multi/Many Objective Analog/RF Circuit Optimization through a Generic Benchmark",
    "doi": "https://doi.org/10.1145/3626096",
    "publication_date": "2023-09-28",
    "publication_year": 2023,
    "authors": "Enes Sağlıcan; Engín Afacan",
    "corresponding_authors": "",
    "abstract": "Thanks to the enhanced computational capacity of modern computers, even sophisticated analog/radio frequency (RF) circuit sizing problems can be solved via electronic design automation (EDA) tools. Recently, several analog/RF circuit optimization algorithms have been successfully applied to automatize the analog/RF circuit design process. Conventionally, metaheuristic algorithms are widely used in optimization process. Among various nature-inspired algorithms, evolutionary algorithms (EAs) have been more preferred due to their superiorities (robustness, efficiency, accuracy etc.) over the other algorithms. Furthermore, EAs have been diversified and several distinguished analog/RF circuit optimization approaches for single-, multi-, and many-objective problems have been reported in the literature. However, there are conflicting claims on the performance of these algorithms and no objective performance comparison has been revealed yet. In the previous work, only a few case study circuits have been under test to demonstrate the superiority of the utilized algorithm, so a limited comparison has been made for only these specific circuits. The underlying reason is that the literature lacks a generic benchmark for analog/RF circuit sizing problem. To address these issues, we propose a comprehensive comparison of the most popular two evolutionary computation algorithms, namely Non-Sorting Genetic Algorithm-II and Multi-Objective Evolutionary Algorithm based Decomposition, in this article. For that purpose, we introduce two ad hoc testbenches for analog and RF circuits including the common building blocks. The comparison has been made at both multi- and many-objective domains and the performances of algorithms have been quantitatively revealed through the well-known Pareto-optimal front quality metrics.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W4387130563",
    "type": "article"
  },
  {
    "title": "Automatic Hardware Pragma Insertion in High-Level Synthesis: A Non-Linear Programming Approach",
    "doi": "https://doi.org/10.1145/3711847",
    "publication_date": "2025-01-09",
    "publication_year": 2025,
    "authors": "Stéphane Pouget; Louis-Noël Pouchet; Jason Cong",
    "corresponding_authors": "",
    "abstract": "High-Level Synthesis enables the rapid prototyping of hardware accelerators, by combining a high-level description of the functional behavior of a kernel with a set of micro-architecture optimizations as inputs. Such optimizations can be described by inserting pragmas e.g., pipelining and replication of units, or even higher level transformations for HLS such as automatic data caching using the AMD/Xilinx Merlin compiler. Selecting the best combination of pragmas, even within a restricted set, remains particularly challenging and the typical state-of-practice uses design-space exploration to navigate this space. But due to the highly irregular performance distribution of pragma configurations, typical DSE approaches are either extremely time consuming, or operating on a severely restricted search space. This work proposes a framework to automatically insert HLS pragmas in regular loop-based programs, supporting pipelining, unit replication, and data caching. We develop an analytical performance and resource model as a function of the input program properties and pragmas inserted, using non-linear constraints and objectives. We prove this model provides a lower bound on the actual performance after HLS. We then encode this model as a Non-Linear Program, by making the pragma configuration unknowns of the system, which is computed optimally by solving this NLP. This approach can also be used during DSE, to quickly prune points with a (possibly partial) pragma configuration, driven by lower bounds on achievable latency. We extensively evaluate our end-to-end, fully implemented system, showing it can effectively manipulate spaces of billions of designs in seconds to minutes for the kernels evaluated.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4406220665",
    "type": "article"
  },
  {
    "title": "An efficient area and reliability optimization method for MPRM circuits based on high-dimensional genetic algorithm",
    "doi": "https://doi.org/10.1145/3712591",
    "publication_date": "2025-01-17",
    "publication_year": 2025,
    "authors": "Yuhao Zhou; Jianhui Jiang; Zhenxue He; Ying Zhang; Chengcheng Chen; Zhanhui Shi; Wei Zhang; Keying Yang",
    "corresponding_authors": "",
    "abstract": "Area and reliability optimization have become the primary constraints in circuits logic synthesis. To address the increasing area and transient fault susceptibility in combinational circuits, we propose a high-dimensional genetic algorithm (HGA). HGA adopts an evolutionary scheme based on ternary tree, and uses adaptive crossover operator and flight operator to jump out of local optimum. Moreover, based on the HGA, we propose an area and reliability optimization method (AROM) for mixed polarity Reed-Muller logic circuits, which searches the best polarity with minimum area and soft error rate. The experimental results confirm that AROM can search for more desirable nondominated solutions in less time compared to existing optimization methods, and can be used as an effective electronic design automation tool for multi-objective optimization.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4406536901",
    "type": "article"
  },
  {
    "title": "Effective Fault Effects Evaluation for Permanent Faults in GPUs executing DNNs",
    "doi": "https://doi.org/10.1145/3715327",
    "publication_date": "2025-01-25",
    "publication_year": 2025,
    "authors": "Juan-David Guerrero-Balaguera; Josie E. Rodriguez Condia; M. Sonza Reorda",
    "corresponding_authors": "",
    "abstract": "Deep Neural Networks (DNNs) have permeated multiple applications, including cutting-edge safety-critical domains, which require relevant computational power, often provided by Graphic Processing Units (GPUs). GPUs are manufactured with advanced semiconductor technologies that can be affected by faults during the operational phase (e.g., due to wear-out, aging, or environmental harshness), whose effects possibly reach the DNN outputs, in some cases leading to catastrophic consequences. Hence, hardware-aware reliability assessments of DNNs are crucial to be considered in the context of safety-critical systems (following regulations/standards of specific application domains). Application-level fault injection (FI) techniques (i.e., DNN parameter corruption) are often adopted for the reliability evaluation of DNNs; unfortunately, these approaches hardly represent fault effects from GPU hardware. This work proposes an FI strategy based on Hardware-Injection-Through-Program-Transformation (HITPT) to mimic the effect of permanent faults (PFs) at the GPU instruction level, enabling effective assessment of PFs on DNN’s reliability. Our approach provides a good trade-off between the fault effect evaluation’s accuracy and the required computational time. Using the proposed approach, for the first time, we systematically assessed the effects of PF in GPUs executing some DNN sample cases. The results indicate that the faults injected closer to the hardware, using our evaluation strategy, can produce a higher accuracy degradation than the evaluations performed by the typical application-level FI that modify only the DNN parameters. Furthermore, the proposed FI methodology provides insightful results to identify the most suitable fault-tolerance solutions (e.g., selective hardening or design diversity) for their application at thread levels inside GPU’s kernels.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4406825392",
    "type": "article"
  },
  {
    "title": "EDA-Copilot: A RAG-Powered Intelligent Assistant for EDA Tools",
    "doi": "https://doi.org/10.1145/3715326",
    "publication_date": "2025-01-27",
    "publication_year": 2025,
    "authors": "Zhe Xiao; Xu He; Haoying Wu; Bei Yu; Yang Guo",
    "corresponding_authors": "",
    "abstract": "With the rise of Large Language Models (LLMs), researchers have become increasingly interested in their applications in EDA flows, particularly in specific subdomains like serving as knowledge assistants and generating RTL code. In this study, we present a Retrieval-Augmented Generation (RAG) framework tailored to EDA task processing, named EDA-Adaptive RAG. This framework addresses the implicit semantics of EDA data and facilitates efficient knowledge acquisition through classification and enhanced retrieval, significantly enhancing LLMs ability to acquire EDA knowledge. Furthermore, we aim to integrate RAG into the design process as an EDA assistant application. Using RTL code generation as a case study, we demonstrate that the performance of RTL code generation can be enhanced through highly relevant retrievals provided by our RAG. The experimental analysis involves EDA Q&amp;A tasks and RTL code generation evaluation. It is shown that our method outperforms the latest works in terms of both answer stability and code quality.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4406874792",
    "type": "article"
  },
  {
    "title": "Data Privacy Made Easy: Enhancing Applications with Homomorphic Encryption",
    "doi": "https://doi.org/10.1145/3715877",
    "publication_date": "2025-02-03",
    "publication_year": 2025,
    "authors": "Charles Gouert; Nektarios Georgios Tsoutsos",
    "corresponding_authors": "",
    "abstract": "Homomorphic encryption is a powerful privacy-preserving technology that is notoriously difficult to configure and use, even for experts. The key difficulties include restrictive programming models of homomorphic schemes and choosing suitable parameters for an application. In this tutorial, we outline methodologies to solve these issues and allow for conversion of any application to the encrypted domain using both leveled and fully homomorphic encryption. The first approach, called Walrus, is suitable for arithmetic-intensive applications with limited depth and applications with high throughput requirements. Walrus provides an intuitive programming interface and handles parameterization automatically by analyzing the application and gathering statistics such as homomorphic noise growth to derive a parameter set tuned specifically for the application. We provide an in-depth example of this approach in the form of a neural network inference as well as guidelines for using Walrus effectively. Conversely, the second approach (HELM) takes existing HDL designs and converts them to the encrypted domain for secure outsourcing on powerful cloud servers. Unlike Walrus, HELM supports FHE backends and is well-suited for complex applications. At a high level, HELM consumes netlists and is capable of performing logic gate operations homomorphically on encryptions of individual bits. HELM incorporates both CPU and GPU acceleration by taking advantage of the inherent parallelism provided by Boolean circuits. As a case study, we walk through the process of taking an off-the-shelf HDL design in the form of AES-128 decryption and running it in the encrypted domain with HELM.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4407108590",
    "type": "article"
  },
  {
    "title": "A Novel Approach to Reducing Testing Costs and Minimizing Defect Escapes Using Dynamic Neighborhood Range and Shapley Values",
    "doi": "https://doi.org/10.1145/3716826",
    "publication_date": "2025-02-12",
    "publication_year": 2025,
    "authors": "Tianming Ni; Wangsheng Rui; Cheng Zhuo; Yu Li; Xiaoqing Wen; Mu Nie",
    "corresponding_authors": "",
    "abstract": "Wafer acceptance testing (WAT) is a process that is used to assess the quality and reliability of manufactured wafers. This technique for the early detection and screening of chips allows for improvements in their reliability and performance during the manufacture of semiconductor devices. The automatic test equipment (ATE) used for processing millions of wafers is susceptible to a number of issues, including the absence of data values, the presence of redundant parameters, and categorical imbalance. These issues increase the cost of data processing, and impede an investigation into the relationship between WAT and feature diagnostics. In this study, we propose a method with a low test escape rate based on a multi-objective optimization algorithm to reduce the cost of testing and minimize the number of defective dice that go undetected. The proposed method retains outliers, dynamically selects the range of the neighborhood to reduce the cost of testing, and uses Shapley values to analyze a WAT dataset to determine the importance of features of the data. The multi-objective optimization algorithm ranks features by their importance, and applies an adaptive method to eliminate features with a low overall correlation, thereby reducing the risk that defective dice are undetected.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4407411996",
    "type": "article"
  },
  {
    "title": "A Heterogeneous Chiplet Architecture for Accelerating End-to-End Transformer Models",
    "doi": "https://doi.org/10.1145/3718487",
    "publication_date": "2025-02-19",
    "publication_year": 2025,
    "authors": "Harsh Sharma; Pratyush Dhingra; Janardhan Rao Doppa; Ümit Y. Ogras; Partha Pratim Pande",
    "corresponding_authors": "",
    "abstract": "Transformers have revolutionized deep learning and generative modeling, enabling advancements in natural language processing tasks. However, the size of transformer models is increasing continuously, driven by enhanced capabilities across various deep learning tasks. This trend of ever-increasing model size has given rise to new challenges in terms of memory and compute requirements. Conventional computing platforms, including GPUs, suffer from suboptimal performance due to the memory demands imposed by models with millions/billions of parameters. The emerging chiplet-based platforms provide a new avenue for compute- and data-intensive machine learning (ML) applications enabled by a Network-on-Interposer (NoI). However, designing suitable hardware accelerators for executing Transformer inference workloads is challenging due to a wide variety of complex computing kernels in the Transformer architecture. In this paper, we leverage chiplet-based heterogeneous integration (HI) to design a high-performance and energy-efficient multi-chiplet platform to accelerate transformer workloads. We demonstrate that the proposed NoI architecture caters to the data access patterns inherent in a transformer model. The optimized placement of the chiplets and the associated NoI links and routers enable superior performance compared to the state-of-the-art hardware accelerators. The proposed NoI-based architecture demonstrates scalability across varying transformer models and improves latency and energy efficiency by up to 11.8 × and 2.36 ×, respectively when compared with the existing state-of-the-art architecture HAIMA .",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4407749891",
    "type": "article"
  },
  {
    "title": "Revisiting VerilogEval: A Year of Improvements in Large-Language Models for Hardware Code Generation",
    "doi": "https://doi.org/10.1145/3718088",
    "publication_date": "2025-02-19",
    "publication_year": 2025,
    "authors": "Nathaniel Pinckney; Christopher Batten; Mingjie Liu; Haoxing Ren; Brucek Khailany",
    "corresponding_authors": "",
    "abstract": "The application of large-language models (LLMs) to digital hardware code generation is an emerging field, with most LLMs primarily trained on natural language and software code. Hardware code like Verilog constitutes a small portion of training data, and few hardware benchmarks exist. The open-source VerilogEval benchmark, released in November 2023, provided a consistent evaluation framework for LLMs on code completion tasks. Since then, both commercial and open models have seen significant development. In this work, we evaluate new commercial and open models since VerilogEval’s original release—including GPT-4o, GPT-4 Turbo, Llama3.1 (8B/70B/405B), Llama3 70B, Mistral Large, DeepSeek Coder (33B and 6.7B), CodeGemma 7B, and RTL-Coder—against an improved VerilogEval benchmark suite. We find measurable improvements in state-of-the-art models: GPT-4o achieves a 63% pass rate on specification-to-RTL tasks. The recently released and open Llama3.1 405B achieves a 58% pass rate, almost matching GPT-4o, while the smaller domain-specific RTL-Coder 6.7B models achieve an impressive 34% pass rate. Additionally, we enhance VerilogEval’s infrastructure by automatically classifying failures, introducing in-context learning support, and extending the tasks to specification-to-RTL translation. We find that prompt engineering remains crucial for achieving good pass rates and varies widely with model and task. A benchmark infrastructure that allows for prompt engineering and failure analysis is essential for continued model development and deployment.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4407749900",
    "type": "article"
  },
  {
    "title": "Routing-aware Legal Hybrid Bonding Terminal Assignment for 3D Face-to-Face Stacked ICs",
    "doi": "https://doi.org/10.1145/3721131",
    "publication_date": "2025-03-06",
    "publication_year": 2025,
    "authors": "Siting Liu; Junyao Zhou; Jiaxi Jiang; Zhuolun He; Ziyi Wang; Yibo Lin; Bei Yu; Martin D. F. Wong",
    "corresponding_authors": "",
    "abstract": "Face-to-face (F2F) stacked 3D IC is a promising alternative for scaling beyond Moore’s Law. In F2F 3D ICs, dies are connected through bonding terminals whose positions can significantly impact routing performance. Further, there exists resource competition among all the 3D nets due to the constrained bonding terminal number. In advanced technology nodes, traditional bonding terminal planning may also introduce legality challenges of bonding terminals, as the metal pitches can be much smaller than the sizes of bonding terminals. Previous works attempt to insert bonding terminals automatically using existing 2D commercial P&amp;R tools and then consider inter-die connection legality, but they fail to take the legality and routing performance into account simultaneously. In this paper, we provide a novel bonding terminal assignment formulation for effective routing-aware bonding terminal planning. We explore the generalized assignment formulation and provide the routability guidance in our hybrid bonding terminal assignment problem. Our framework, BTAssign , offers a strict legality guarantee and an iterative solution. We provide two versions of the BTAssign framework, BTAssign-WL [1] and BTAssign-R, which BTAssign-R extends BTAssign-WL [1] by considering routability. The experiments are conducted on 18 open-source designs with various 3D net densities and the most advanced bonding scale. The results reveal that all the testing cases with different partitioning and placement strategies could gain benefits from our BTAssign framework.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4408198631",
    "type": "article"
  },
  {
    "title": "Automatically Improving LLM-based Verilog Generation using EDA Tool Feedback",
    "doi": "https://doi.org/10.1145/3723876",
    "publication_date": "2025-03-26",
    "publication_year": 2025,
    "authors": "Jason Blocklove; Shailja Thakur; Benjamin Tan; Hammond Pearce; Siddharth Garg; Ramesh Karri",
    "corresponding_authors": "",
    "abstract": "Traditionally, digital hardware designs are written in the Verilog hardware description language (HDL) and debugged manually by engineers. This can be time-consuming and error-prone for complex designs. Large Language Models (LLMs) are emerging as a potential tool to help generate fully functioning HDL code, but most works have focused on generation in the single-shot capacity: i.e., run and evaluate, a process that does not leverage debugging and, as such, does not adequately reflect a realistic development process. In this work, we evaluate the ability of LLMs to leverage feedback from electronic design automation (EDA) tools to fix mistakes in their own generated Verilog. To accomplish this, we present an open-source, highly customizable framework, AutoChip, which combines conversational LLMs with the output from Verilog compilers and simulations to iteratively generate and repair Verilog. To determine the success of these LLMs we leverage the VerilogEval benchmark set. We evaluate four state-of-the-art conversational LLMs, focusing on readily accessible commercial models. EDA tool feedback proved to be consistently more effective than zero-shot prompting only with GPT-4o, the most computationally complex model we evaluated. In the best case, we observed a 5.8% increase in the number of successful designs with a 34.2% decrease in cost over the best zero-shot results. Mixing smaller models with this larger model at the end of the feedback iterations resulted in equally as much success as with GPT-4o using feedback, but incurred 41.9% lower cost (corresponding to an overall decrease in cost over zero-shot by 89.6%).",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4408844959",
    "type": "article"
  },
  {
    "title": "Bridging Hotspot Detection and Mask Optimization via Domain-Crossing Masked Layout Modeling",
    "doi": "https://doi.org/10.1145/3728468",
    "publication_date": "2025-04-04",
    "publication_year": 2025,
    "authors": "Binwu Zhu; Su Zheng; Yuzhe Ma; Bei Yu; Martin D. F. Wong",
    "corresponding_authors": "",
    "abstract": "With the rapid development of semiconductors, the size of transistors is continuously scaling down. The shrinking circuit size poses great challenges to optical proximity correction (OPC) and hotspot detection (HSD). Recent advancements in OPC and HSD commonly employ deep neural networks, achieving impressive performance within a limited runtime. Based on these achievements, we observe that deep learning-based models of both HSD and OPC require knowledge of layout structure information. Furthermore, these two tasks are closely related to the lithography process during chip manufacturing. Observing such strong relationships, we propose that integrating OPC and HSD into a unified deep-learning model will contribute to the performance of both tasks. To bridge the relationship between OPC and HSD, we first pre-train a layout understanding model built on the mask modeling technique, which effectively captures the layout geometric information, and then the pre-trained model can be easily fine-tuned on HSD and OPC with limited data. To fully pre-train the layout understanding model (LUM), we create a large layout dataset using layout generation techniques, solving the data-hungry issues. Experimental results show that the fine-tuned LUM model achieves remarkable performance on both OPC and HSD tasks.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4409168397",
    "type": "article"
  },
  {
    "title": "PSCaps: High-Performance Pose-Sensitive Layout Hotspot Detector based on CapsNet",
    "doi": "https://doi.org/10.1145/3735132",
    "publication_date": "2025-05-09",
    "publication_year": 2025,
    "authors": "Ying Wang; Haopeng Yan; Yiwen Zhang; Peng Gao; Fei Yu; Xiaoming Xiong; Shuting Cai",
    "corresponding_authors": "",
    "abstract": "Advanced technology nodes face challenges with Design Rule Violations (DRVs), primarily due to the possibility of nm-level small variations that can lead to the occurrence of DRVs. Various Machine Learning (ML) techniques have been introduced to detect whether the layout design conforms to manufacturing rules, thus alleviating the time-consuming challenge associated with traditional lithography simulations. However, existing ML models still face challenges in detecting layout violations where there are pose variations among geometric shapes in the layout. In this study, we propose a hotspot detector called PSCaps based on the CapsNet, which consider the pose information of geometric shapes in the layout. The method effectively captures spatial information and hierarchical structures between geometric shapes in the layout. Through the dynamic routing mechanism, the model adaptively learns the relationships and weight allocations between different capsules. Additionally, we employ multiple data augmentation methods to alleviate the problem of imbalanced hotspot and non-hotspot data in the open-source dataset. The benchmarks of ICCAD-2012 and ICCAD-2019 are used to validate our method. The experimental results demonstrate that our proposed hotspot detector outperforms other state-of-the-art works.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4410238233",
    "type": "article"
  },
  {
    "title": "C2HLSC: Leveraging Large Language Models to Bridge the Software-to-Hardware Design Gap",
    "doi": "https://doi.org/10.1145/3734524",
    "publication_date": "2025-05-10",
    "publication_year": 2025,
    "authors": "Luca Collini; Siddharth Garg; Ramesh Karri",
    "corresponding_authors": "",
    "abstract": "High-Level Synthesis (HLS) tools offer rapid hardware design from C code, but their compatibility is limited by code constructs. This paper investigates Large Language Models (LLMs) for automatically refactoring C code into HLS-compatible formats. We present a case study using an LLM to rewrite C code for NIST 800-22 randomness tests, a QuickSort algorithm, and AES-128 into HLS-synthesizable C. The LLM iteratively transforms the C code guided by the system prompt and tool’s feedback, implementing functions like streaming data and hardware-specific signals. With the hindsight obtained from the case study, we implement a fully automated framework to refactor C code into HLS-compatible formats using LLMs. To tackle complex designs, we implement a preprocessing step that breaks down the hierarchy in order to approach the problem in a divide-and-conquer bottom-up way. We validated our framework on three ciphers, one hash function, five NIST 800-22 randomness tests, and a QuickSort algorithm. Our results show a high success rate on benchmarks that are orders of magnitude more complex than what has been achieved generating Verilog with LLMs.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4410250027",
    "type": "article"
  },
  {
    "title": "Empirical Guidelines for Deploying LLMs onto Resource-constrained Edge Devices",
    "doi": "https://doi.org/10.1145/3736721",
    "publication_date": "2025-05-21",
    "publication_year": 2025,
    "authors": "Ruiyang Qin; Dancheng Liu; Chongyang Xu; Zheyu Yan; Zhaoxuan Tan; Zhenge Jia; Amir Nassereldine; Jiajie Li; Meng Jiang; Ahmed Abbasi; Jinjun Xiong; Yiyu Shi",
    "corresponding_authors": "",
    "abstract": "The scaling laws have become the de facto guidelines for designing large language models (LLMs), but they were studied under the assumption of unlimited computing resources for both training and inference. As LLMs are increasingly used as personalized intelligent assistants, their customization (i.e., learning through fine-tuning) and deployment onto resource-constrained edge devices will become more and more prevalent. An urgent but open question is how a resource-constrained computing environment would affect the design choices for a personalized LLM. We study this problem empirically in this work. In particular, we consider the tradeoffs among a number of key design factors and their intertwined impacts on learning efficiency and accuracy. The factors include the learning methods for LLM customization, the amount of personalized data used for learning customization, the types and sizes of LLMs, the compression methods of LLMs, the amount of time afforded to learn, and the difficulty levels of the target use cases. Through extensive experimentation and benchmarking, we draw a number of surprisingly insightful guidelines for deploying LLMs onto resource-constrained devices. For example, an optimal choice between parameter learning and RAG may vary depending on the difficulty of the downstream task, the longer fine-tuning time does not necessarily help the model, and a compressed LLM may be a better choice than an uncompressed LLM to learn from limited personalized data.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4410564946",
    "type": "article"
  },
  {
    "title": "FV-LIDAC: Formally Verified Library of Input Data Aware Approximate Arithmetic Circuits",
    "doi": "https://doi.org/10.1145/3744710",
    "publication_date": "2025-06-12",
    "publication_year": 2025,
    "authors": "Sallar Ahmadi-Pour; Sajjad Parvin; Chandan Kumar Jha; Rolf Drechsler",
    "corresponding_authors": "",
    "abstract": "Approximate circuits have become ubiquitous in error-resilient applications. These circuits provide large reductions in area, power, and delay at the cost of erroneous computations. The error-resilient applications produce acceptable output quality, even after the introduction of erroneous computations. However, we observed that the error resilience of an application varies widely with respect to the applied inputs. Since prior works have mostly focused on using samples from a uniform distribution while designing the approximate circuits, they are unable to exploit input aware properties to design optimal circuits. Hence, in this work, we bridge this gap and propose Formally Verified Library of Input Data Aware Approximate Circuits (FV-LIDAC) . FV-LIDAC is the first formally verified library of input distribution aware approximate arithmetic circuits. We use three of the most widely occurring distributions, namely uniform, normal, and exponential distributions, to show that optimal design sets are heavily dependent on the input data. FV-LIDAC chooses the best designs among millions of functional approximated adder and multiplier circuits, depending upon the inputs. Since there are no existing input-aware approximate circuit libraries, we compared FV-LIDAC against state-of-the-art input-unaware EvoApproxLib, to further highlight the need for FV-LIDAC. Additionally, we perform case studies on real-world applications to further highlight the improvement over state-of-the-art. We aim to make the Pareto-optimal designs available as open source to stimulate further research.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4411292512",
    "type": "article"
  },
  {
    "title": "HAPE: Hardware-Aware LLM Pruning For Efficient On-Device Inference Optimization",
    "doi": "https://doi.org/10.1145/3744244",
    "publication_date": "2025-06-14",
    "publication_year": 2025,
    "authors": "Wenqian Zhao; Lancheng Zou; Zixiao Wang; Xufeng Yao; Bei Yu",
    "corresponding_authors": "",
    "abstract": "Over the past few years, large language models (LLMs) have demonstrated remarkable performance and versatility across a variety of complex tasks. However, their deployment has been challenged by their substantial model size and computational requirements. Pruning is a effective approach to make the model parameters sparse, thereby acquire inference acceleration. While not everyone requires training or fine-tuning large models, the diverse range of applications necessitates the deployment of LLMs on different devices. Model pruning and compression have emerged as areas of deep research interest to address these challenges. In consideration of versatility and practicality, we have designed a hardware-aware pruning process for general-purpose hardware/edge devices to enable efficient deployment and inference of LLMs. Instead of considering sparse ratio alone, we are motivated to design a pruning framework that incorporates genuine inference speed-up sensitivity from each pruning structure. Moreover, our framework breaks the layer-by-layer pruning setting and fuse several layers into one pruning stage to allow cross-layer optimization. Apart from that, we holds pragmatism by conducting compilation optimization during pruning. This step is critical because most sparsity patterns barely show distinct speed acceleration with corresponding dataflow and memory optimization. Our process operates within a post-training framework, obviating the need for additional training and thereby reducing resource requirements, while ensuring diverse inference speed and accuracy requirements on hardware.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4411309330",
    "type": "article"
  },
  {
    "title": "Simultaneous reference allocation in code generation for dual data memory bank ASIPs",
    "doi": "https://doi.org/10.1145/335043.335047",
    "publication_date": "2000-04-01",
    "publication_year": 2000,
    "authors": "Ashok Sudarsanam; Sharad Malik",
    "corresponding_authors": "",
    "abstract": "We address the problem of code generation for DSP systems on a chip. In such systems, the amount of silicon devoted of program ROM is limited, so application software must be sufficiently dense. Additionally, the software must be written so as to meet various high-performance constraints, which may include hard real-time constraints. Unfortunately, current compiler technology is unable to generate high-quality code for DSPs, whose architectures are highly irregular. Thus, designers often resort to programming application software in assembly—a time-consuming task. In this paper, we focus on providing support for architectural feature of DSPs that makes code generation difficult, namely multiple data memory banks. This feature increases memory bandwith by permitting multiple data memory accesses to occur in parallel when the referenced variables belong to different data memory banks and the registers involved conform to a strict set of conditions. We present an algorithm that attempst to maximize the benefit of this architectural feature. While previous approaches have decoupled the phases of register allocation and memory bank assignment, thereby compromising code quality, our algorithm performs these two phases simultaneously. Experimental results demonstrate that our algorithm not only generates high-quality compiled code, but also improves the quality of completely-referenced code.",
    "cited_by_count": 68,
    "openalex_id": "https://openalex.org/W1985672179",
    "type": "article"
  },
  {
    "title": "Closed form solutions to simultaneous buffer insertion/sizing and wire sizing",
    "doi": "https://doi.org/10.1145/383251.383256",
    "publication_date": "2001-07-01",
    "publication_year": 2001,
    "authors": "Chris Chu; Martin D. F. Wong",
    "corresponding_authors": "",
    "abstract": "In this paper, we consider the delay minimization problem of an interconnect wire by simultaneously considering buffer insertion, buffer sizing and wire sizing. We consider three cases, namely using no buffer (i.e., wire sizing alone), using a given number of buffers, and using the optimal number of buffers. We provide elegant closed form optimal solutions for all three problems. These closed form solutions are useful in early stages of the VLSI design flow such as logic synthesis and floorplanning.",
    "cited_by_count": 67,
    "openalex_id": "https://openalex.org/W2004809424",
    "type": "article"
  },
  {
    "title": "Symbolic synthesis of clock-gating logic for power optimization of synchronous controllers",
    "doi": "https://doi.org/10.1145/323480.323482",
    "publication_date": "1999-10-01",
    "publication_year": 1999,
    "authors": "Luca Benini; Giovanni De Micheli; Enrico Macii; Massimo Poncino; R. Scarsi",
    "corresponding_authors": "",
    "abstract": "Recent results have shown that dynamic power management is effective in reducing the total power consumption of sequential circuits. In this paper, we propose a bottom-up approach for the automatic extraction and synthesis of dynamic power management circuitry starting from structural logic-level specifications. Our techniques leverage the compact BDD-based representation of Boolean and pseudo-Boolean functions to detect idle conditions where the clock can be stopped without compromising functional correctness. Moreover, symbolic techniques allow accurate probabilistic computations; in particular, they enable the use of non-equiprobable primary input distributions, a key step in the construction of models that match the behavior of real hardware devices with a high degree of fidelity. The results are encouraging, since power savings of up to 34% have been obtained on standard benchmark circuits.",
    "cited_by_count": 66,
    "openalex_id": "https://openalex.org/W1996445094",
    "type": "article"
  },
  {
    "title": "UST/DME",
    "doi": "https://doi.org/10.1145/567270.567271",
    "publication_date": "2002-07-01",
    "publication_year": 2002,
    "authors": "Chung-Wen Albert Tsao; Cheng‐Kok Koh",
    "corresponding_authors": "",
    "abstract": "In this article, we propose new approaches for solving the useful-skew tree (UST) routing problem [Xi and Dai 1997]: clock routing subject to general skew constraints. The clock layout synthesis engine of our UST algorithms is based on the deferred-merge embedding (DME) paradigm for the zero-skew tree (ZST) [Edahiro 1992; Chao et al. 1992] and bounded-skew tree (BST) [Cong and Koh 1995; Huang et al. 1995; Kahng and Tsao 1997; Cong et al. 1998] routings; hence, the names UST/DME and Greedy-UST/DME for our UST algorithms. Our novel contribution is that we simultaneously perform skew scheduling and tree routing so that each local skew range is incrementally refined to a skew value that minimizes the wirelength increase during the bottom-up merging phase of DME. As a result, not only is the skew schedule feasible, but also the wirelength increase is minimized at each merging step of clock tree construction. The experimental results show very encouraging improvement over the previous BST/DME algorithm on three ISCAS89 benchmarks under general skew constraints in terms of total routing wirelength.",
    "cited_by_count": 61,
    "openalex_id": "https://openalex.org/W1983206124",
    "type": "article"
  },
  {
    "title": "Buffer merging—a powerful technique for reducing memory requirements of synchronous dataflow specifications",
    "doi": "https://doi.org/10.1145/989995.989999",
    "publication_date": "2004-04-01",
    "publication_year": 2004,
    "authors": "Praveen K. Murthy; Shuvra S. Bhattacharyya",
    "corresponding_authors": "",
    "abstract": "We develop a new technique called buffer merging for reducing memory requirements of synchronous dataflow (SDF) specifications. SDF has proven to be an attractive model for specifying DSP systems, and is used in many commercial tools like System Canvas, SPW, and Cocentric. Good synthesis from an SDF specification depends crucially on scheduling, and memory is an important metric for generating efficient schedules. Previous techniques on memory minimization have either not considered buffer sharing at all, or have done so at a fairly coarse level (the meaning of this will be made more precise in the article). In this article, we develop a buffer overlaying strategy that works at the level of an input/output edge pair of an actor. It works by algebraically encapsulating the lifetimes of the tokens on the input/output edge pair, and determines the maximum amount of the input buffer space that can be reused by the output. We develop the mathematical basis for performing merging operations, and develop several algorithms and heuristics for using the merging technique for generating efficient implementations. We show improvements of up to 48% over previous techniques.",
    "cited_by_count": 60,
    "openalex_id": "https://openalex.org/W2045373288",
    "type": "article"
  },
  {
    "title": "Rate analysis for embedded systems",
    "doi": "https://doi.org/10.1145/293625.293631",
    "publication_date": "1998-07-01",
    "publication_year": 1998,
    "authors": "Anmol Mathur; Ali Dasdan; Rajesh K. Gupta",
    "corresponding_authors": "",
    "abstract": "Embedded systems consist of interacting components that are required to deliver a specific functionality under constraints on execution rates and relative time separation of the components. In this article, we model an embedded system using concurrent processes interacting through synchronization. We assume that there are rate constraints on the execution rates of processes imposed by the designer or the environment of the system, where the execution rate of a process is the number of its executions per unit time. We address the problem of computing bounds on the execution rates of processes constituting an embedded system, and propose an interactive rate analysis framework. As part of the rate analysis framework we present an efficient algorithms for checking the consistency of the rate constraints. Bounds on the execution rate of each process are computed using an efficient algorithm based on the relationship between the execution rate of a process and the maximum mean delay cycles in the process graph. Finally, if the computed rates violate some of the rate constraints, some of the processes in the system are redesigned using information from the rate analysis step. This rate analysis framework is implemented in a tool called RATAN. We illustrate by an example how RATAN can be used in an embedded system design.",
    "cited_by_count": 59,
    "openalex_id": "https://openalex.org/W1978118906",
    "type": "article"
  },
  {
    "title": "System level design paradigms",
    "doi": "https://doi.org/10.1145/1142980.1142982",
    "publication_date": "2004-06-07",
    "publication_year": 2004,
    "authors": "Alessandro Pinto; A. Bonivento; Alberto Sangiovanni‐Vincentelli; Roberto Passerone; Marco Sgroi",
    "corresponding_authors": "",
    "abstract": "Embedded system level design must be based on paradigms that make formal foundations and unification a cornerstone of their construction. Platform-Based designs and communication synthesis are important components of the paradigm shift we advocate.Communication synthesis is a fundamental productivity tool in a design methodology where reuse is enforced. Communication design in a reuse methodology starts with a set of functional requirements and constraints on the interaction among components and then proceeds to build protocols, topology, and physical implementations that satisfy requirements and constraints while optimizing appropriate measures of efficiency of the implementation. Maximum efficiency can be reached when the communication specifications are entered at high levels of abstraction and the design process optimizes the implementation from this specification. Unfortunately, this process is very difficult if it is not cast in a rigorous framework. Platform-Based design helps define a successive refinement process where each step can be carried out automatically and optimized appropriately. We present two cases, an on-chip and a wireless sensor network design, where the resulting methodology gave encouraging results.",
    "cited_by_count": 59,
    "openalex_id": "https://openalex.org/W2068257545",
    "type": "article"
  },
  {
    "title": "A multiple bit upset tolerant SRAM memory",
    "doi": "https://doi.org/10.1145/944027.944038",
    "publication_date": "2003-10-01",
    "publication_year": 2003,
    "authors": "Gustavo Neuberger; Fernanda de Lima; Luigi Carro; Ricardo Reis",
    "corresponding_authors": "",
    "abstract": "SRAMs are used nowadays in almost every electronic product. However, as technology shrinks transistor sizes, single and multiple bit upsets only observable in space applications previously are now reported at ground level. This article presents a high level technique to protect SRAM memories against multiple upsets based on correcting codes. The proposed technique combines Reed Solomon code and Hamming code to assure reliability in presence of multiple bit flips with reduced area and performance penalties. Multiple upsets were randomly injected in various combinations of memory cells to evaluate the robustness of the method. The experiment was emulated in a Virtex FPGA platform. Results show that 100% of the injected double faults and a large amount of multiple faults were corrected by the method.",
    "cited_by_count": 58,
    "openalex_id": "https://openalex.org/W2054917929",
    "type": "article"
  },
  {
    "title": "Analysis and optimization of distributed real-time embedded systems",
    "doi": "https://doi.org/10.1145/1142980.1142984",
    "publication_date": "2004-06-07",
    "publication_year": 2004,
    "authors": "Paul Pop; Petru Eles; Zebo Peng; Traian Pop",
    "corresponding_authors": "",
    "abstract": "An increasing number of real-time applications are today implemented using distributed heterogeneous architectures composed of interconnected networks of processors. The systems are heterogeneous not only in terms of hardware and software components, but also in terms of communication protocols and scheduling policies. In this context, the task of designing such systems is becoming increasingly difficult. The success of new adequate design methods depends on the availability of efficient analysis as well as optimization techniques. In this article, we present both analysis and optimization approaches for such heterogeneous distributed real-time embedded systems. More specifically, we discuss the schedulability analysis of hard real-time systems, highlighting particular aspects related to the heterogeneous and distributed nature of the applications. We also introduce several design optimization problems characteristic of this class of systems: mapping of functionality, the optimization of access to communication channel, and the assignment of scheduling policies to processes. Optimization heuristics aiming at producing a schedulable system with a given amount of resources are presented.",
    "cited_by_count": 57,
    "openalex_id": "https://openalex.org/W2114606347",
    "type": "article"
  },
  {
    "title": "An event-based monitoring service for networks on chip",
    "doi": "https://doi.org/10.1145/1109118.1109126",
    "publication_date": "2005-10-01",
    "publication_year": 2005,
    "authors": "C. Ciordas; Twan Basten; A. Rădulescu; Kees Goossens; J. van Meerbergen",
    "corresponding_authors": "",
    "abstract": "Networks on chip (NoCs) are a scalable interconnect solution for multiprocessor systems on chip. We propose a generic reconfigurable online event-based NoC monitoring service, based on hardware probes attached to NoC components, offering run-time observability of NoC behavior and supporting system-level debugging. We present a probe architecture, its programming model, traffic management strategies, and a cost analysis. We prove feasibility via a prototype implementation for the Æthereal NoC. Two MPEG NoC examples show that the monitoring service area, without advanced optimizations, is 17--24% of the NoC area. Two realistic monitoring examples show that monitoring traffic is several orders of magnitude lower than the 2GB/s/link raw bandwidth.",
    "cited_by_count": 52,
    "openalex_id": "https://openalex.org/W2013010896",
    "type": "article"
  },
  {
    "title": "Compilers for leakage power reduction",
    "doi": "https://doi.org/10.1145/1124713.1124723",
    "publication_date": "2006-01-01",
    "publication_year": 2006,
    "authors": "Yi‐Ping You; Chingren Lee; Jenq Kuen Lee",
    "corresponding_authors": "",
    "abstract": "Power leakage constitutes an increasing fraction of the total power consumption in modern semiconductor technologies. Recent research efforts indicate that architectures, compilers, and software can be optimized so as to reduce the switching power (also known as dynamic power) in microprocessors. This has lead to interest in using architecture and compiler optimization to reduce leakage power (also known as static power) in microprocessors. In this article, we investigate compiler-analysis techniques that are related to reducing leakage power. The architecture model in our design is a system with an instruction set to support the control of power gating at the component level. Our compiler provides an analysis framework for utilizing instructions to reduce the leakage power. We present a framework for analyzing data flow for estimating the component activities at fixed points of programs whilst considering pipeline architectures. We also provide equations that can be used by the compiler to determine whether employing power-gating instructions in given program blocks will reduce the total energy requirements. As the duration of power gating on components when executing given program routines is related to the number and complexity of program branches, we propose a set of scheduling policies and evaluate their effectiveness. We performed experiments by incorporating our compiler analysis and scheduling policies into SUIF compiler tools and by simulating the energy consumptions on Wattch toolkits. The experimental results demonstrate that our mechanisms are effective in reducing leakage power in microprocessors.",
    "cited_by_count": 50,
    "openalex_id": "https://openalex.org/W2156348954",
    "type": "article"
  },
  {
    "title": "Concurrent testing of digital microfluidics-based biochips",
    "doi": "https://doi.org/10.1145/1142155.1142164",
    "publication_date": "2006-04-01",
    "publication_year": 2006,
    "authors": "Fei Su; Sule Ozev; Krishnendu Chakrabarty",
    "corresponding_authors": "",
    "abstract": "We present a concurrent testing methodology for detecting catastrophic faults in digital microfluidics-based biochips and investigate the related problems of test planning and resource optimization. We first show that an integer linear programming model can be used to minimize testing time for a given hardware overhead, for example, droplet dispensing sources and capacitive sensing circuitry. Due to the NP-complete nature of the problem, we also develop efficient heuristic procedures to solve this optimization problem. We apply the proposed concurrent testing methodology to a droplet-based microfluidic array that was fabricated and used to perform multiplexed glucose and lactate assays. Experimental results show that the proposed test approach interleaves test application with the biomedical assays and prevents resource conflicts. The proposed method is therefore directed at ensuring high reliability and availability of bio-MEMS and lab-on-a-chip systems, as they are increasingly deployed for safety-critical applications.",
    "cited_by_count": 48,
    "openalex_id": "https://openalex.org/W2110310907",
    "type": "article"
  },
  {
    "title": "Prediction of leakage power under process uncertainties",
    "doi": "https://doi.org/10.1145/1230800.1230804",
    "publication_date": "2007-04-01",
    "publication_year": 2007,
    "authors": "Hongliang Chang; Sachin S. Sapatnekar",
    "corresponding_authors": "",
    "abstract": "In this article, we present a method to analyze the total leakage current of a circuit under process variations, considering interdie and intradie variations as well as the effect of the spatial correlations of intradie variations. The approach considers both the subthreshold and gate tunneling leakage power, as well as their interactions. With process variations, each leakage component is approximated by a lognormal distribution, and the total chip leakage is computed as a sum of the correlated lognormals. Since the lognormals to be summed are large in number and have complicated correlation structures due to both spatial correlations and the correlation among different leakage mechanisms, we propose an efficient method to reduce the number of correlated lognormals for summation to a manageable quantity. We do so by identifying dominant states of leakage currents and taking advantage of the spatial correlation model and input states at the gates. An improved approach utilizing the principal components computed from spatially correlated process parameters is also proposed to further improve runtime efficiency. We show that the proposed methods are effective in predicting the probability distribution of total chip leakage, and that ignoring spatial correlations can underestimate the standard deviation of full-chip leakage power.",
    "cited_by_count": 45,
    "openalex_id": "https://openalex.org/W1994620586",
    "type": "article"
  },
  {
    "title": "Battery voltage modeling for portable systems",
    "doi": "https://doi.org/10.1145/1497561.1497572",
    "publication_date": "2009-03-01",
    "publication_year": 2009,
    "authors": "Daler Rakhmatov",
    "corresponding_authors": "Daler Rakhmatov",
    "abstract": "Limited battery life imposes stringent constraints on the operation of battery-powered portable systems. During battery discharge, the battery voltage decreases, until a certain cutoff value is reached, marking the end of battery life. The amount of discharge capacity and energy delivered by the battery during its life depends not only on the battery characteristics, but also on the load conditions. A different system design may result in a different battery current (load) profile over time, leading to a different battery voltage profile over time. This article presents an analytical model that relates the battery voltage to the battery current, thus facilitating system design optimizations with respect to the battery performance. It captures well-known nonlinear phenomena of capacity loss at high discharge rates, charge recovery, and capacity fading. The proposed model has been validated against measurements taken on Li-ion batteries. We also describe techniques for efficient calculations of model's estimates, which lets a user exploit accuracy-complexity tradeoffs.",
    "cited_by_count": 42,
    "openalex_id": "https://openalex.org/W2086633088",
    "type": "article"
  },
  {
    "title": "Race analysis for systemc using model checking",
    "doi": "https://doi.org/10.1145/1754405.1754406",
    "publication_date": "2010-05-01",
    "publication_year": 2010,
    "authors": "Nicolas Blanc; Daniel Kroening",
    "corresponding_authors": "",
    "abstract": "SystemC is a system-level modeling language that offers a wide range of features to describe concurrent systems at different levels of abstraction. The SystemC standard permits simulators to implement a deterministic scheduling policy, which often hides concurrency-related design flaws. We present a novel compiler for SystemC that integrates a very precise formal race analysis by means of model checking. Our compiler produces a simulator that uses the outcome of the analysis to perform partial order reduction. The key insight to make the model checking engine scale is to apply it only to tiny fractions of the SystemC model. We show that the outcome of the analysis is not only valuable to eliminate redundant context switches at runtime, but can also be used to diagnose race conditions statically. In particular, our analysis is able to reveal races that can remain undetected during simulation and is able to formally prove the absence of races.",
    "cited_by_count": 41,
    "openalex_id": "https://openalex.org/W2623612387",
    "type": "article"
  },
  {
    "title": "vGreen",
    "doi": "https://doi.org/10.1145/1870109.1870115",
    "publication_date": "2010-11-01",
    "publication_year": 2010,
    "authors": "Gaurav Dhiman; G. Marchetti; Tajana Rosing",
    "corresponding_authors": "",
    "abstract": "In this article, we present vGreen, a multitiered software system for energy-efficient virtual machine management in a clustered virtualized environment. The system leverages the use of novel hierarchical metrics that work across the different abstractions in a virtualized environment to capture power and performance characteristics of both the virtual and physical machines. These characteristics are then used to implement policies for scheduling and power management of virtual machines across the cluster. We show through real implementation of the system on a state-of-the-art testbed of server machines that vGreen improves both average performance and system-level energy savings by close to 40% across benchmarks with varying characteristics.",
    "cited_by_count": 38,
    "openalex_id": "https://openalex.org/W2052269857",
    "type": "article"
  },
  {
    "title": "BonnRoute",
    "doi": "https://doi.org/10.1145/2442087.2442103",
    "publication_date": "2013-03-01",
    "publication_year": 2013,
    "authors": "Michael Gester; Dirk Müller; Tim Nieberg; Christian Panten; Christian Schulte; Jens Vygen",
    "corresponding_authors": "",
    "abstract": "We present the core elements of BonnRoute: advanced data structures and algorithms for fast and high-quality routing in modern technologies. Global routing is based on a combinatorial approximation scheme for min-max resource sharing. Detailed routing uses exact shortest path algorithms, based on a shape-based data structure for pin access and a two-level track-based data structure for long-distance connections. All algorithms are very fast. Compared to an industrial router (on 32 nm and 22 nm chips), BonnRoute is over two times faster, has 5 % less netlength, 20 % less vias, and reduces detours by more than 90 %.",
    "cited_by_count": 37,
    "openalex_id": "https://openalex.org/W1977985432",
    "type": "article"
  },
  {
    "title": "Easy Formal Specification and Validation of Unbounded Networks-on-Chips Architectures",
    "doi": "https://doi.org/10.1145/2071356.2071357",
    "publication_date": "2012-01-01",
    "publication_year": 2012,
    "authors": "Freek Verbeek; Julien Schmaltz",
    "corresponding_authors": "",
    "abstract": "This article presents a formal specification and validation environment to prove safety and liveness properties of parametric -- unbounded -- NoCs architectures described at a high-level of abstraction. The environment improves the GeNoC approach with two new theorems, proving evacuation and starvation freedom. The application of the validation methodology is illustrated on a HERMES NoC with adaptive west-first routing and wormhole switching. This case study illustrates the strong compositional aspect of the GeNoC environment. The complete specification of this HERMES instance, together with the proof that the specification is deadlock-free, starvation free, and all messages eventually leave the network at their correct destination, could be achieved in about a week. Approximately 86% of this proof is automatically derived from the GeNoC model.",
    "cited_by_count": 36,
    "openalex_id": "https://openalex.org/W2092503884",
    "type": "article"
  },
  {
    "title": "A fast and scalable multidimensional multiple-choice knapsack heuristic",
    "doi": "https://doi.org/10.1145/2541012.2541014",
    "publication_date": "2013-10-01",
    "publication_year": 2013,
    "authors": "Hamid Shojaei; Twan Basten; Marc Geilen; Azadeh Davoodi",
    "corresponding_authors": "",
    "abstract": "Many combinatorial optimization problems in the embedded systems and design automation domains involve decision making in multidimensional spaces. The multidimensional multiple-choice knapsack problem (MMKP) is among the most challenging of the encountered optimization problems. MMKP problem instances appear for example in chip multiprocessor runtime resource management and in global routing of wiring in circuits. Chip multiprocessor resource management requires solving MMKP under real-time constraints, whereas global routing requires scalability of the solution approach to extremely large MMKP instances. This article presents a novel MMKP heuristic, CPH (for Compositional Pareto-algebraic Heuristic), which is a parameterized compositional heuristic based on the principles of Pareto algebra. Compositionality allows incremental computation of solutions. The parameterization allows tuning of the heuristic to the problem at hand. These aspects make CPH a very versatile heuristic. When tuning CPH for computation time, MMKP instances can be solved in real time with better results than the fastest MMKP heuristic so far. When tuning CPH for solution quality, it finds several new solutions for standard benchmarks that are not found by any existing heuristic. CPH furthermore scales to extremely large problem instances. We illustrate and evaluate the use of CPH in both chip multiprocessor resource management and in global routing.",
    "cited_by_count": 36,
    "openalex_id": "https://openalex.org/W2094860575",
    "type": "article"
  },
  {
    "title": "Clock Tree synthesis for TSV-based 3D IC designs",
    "doi": "https://doi.org/10.1145/2003695.2003708",
    "publication_date": "2011-10-01",
    "publication_year": 2011,
    "authors": "Tak-Yung Kim; Taewhan Kim",
    "corresponding_authors": "",
    "abstract": "For the cost-effective implementation of clock trees in through-silicon via (TSV)-based 3D IC designs, we propose core algorithms for 3D clock tree synthesis. For a given abstract tree topology, we propose DLE-3D ( d eferred l ayer e mbedding for 3D ICs), which optimally finds the embedding layers of tree nodes, so that the TSV cost required for a tree topology is minimized, and DME-3D ( d eferred m erge e mbedding for 3D ICs), which is an extended algorithm of the 2D merging segment, to minimize the total wirelength in 3D design space, with the consideration of the TSV effect on delay. In addition, when an abstract tree topology is not given, we propose NN-3D ( n earest n eighbor selection for 3D ICs), which constructs a (TSV and wirelength) cost-effective abstract tree topology for 3D ICs. Through experimentation, we have confirmed that the clock tree synthesis flow using the proposed algorithms is very effective, outperforming the existing 3D clock tree synthesis in terms of the number of TSVs, total wirelength, and clock power consumption.",
    "cited_by_count": 35,
    "openalex_id": "https://openalex.org/W1978169009",
    "type": "article"
  },
  {
    "title": "Massively Parallel Logic Simulation with GPUs",
    "doi": "https://doi.org/10.1145/1970353.1970362",
    "publication_date": "2011-06-01",
    "publication_year": 2011,
    "authors": "Yuhao Zhu; Bo Wang; Yangdong Deng",
    "corresponding_authors": "",
    "abstract": "In this article, we developed a massively parallel gate-level logical simulator to address the ever-increasing computing demand for VLSI verification. To the best of the authors’ knowledge, this work is the first one to leverage the power of modern GPUs to successfully unleash the massive parallelism of a conservative discrete event-driven algorithm, CMB algorithm. A novel data-parallel strategy is proposed to manipulate the fine-grain message passing mechanism required by the CMB protocol. To support robust and complete simulation for real VLSI designs, we establish both a memory paging mechanism and an adaptive issuing strategy to efficiently utilize the GPU memory with a limited capacity. A set of GPU architecture-specific optimizations are performed to further enhance the overall simulation performance. On average, our simulator outperforms a CPU baseline event-driven simulator by a factor of 47.4X. This work proves that the CMB algorithm can be efficiently and effectively deployed on modern GPUs without the performance overhead that had hindered its successful applications on previous parallel architectures.",
    "cited_by_count": 35,
    "openalex_id": "https://openalex.org/W2095266728",
    "type": "article"
  },
  {
    "title": "Reconfigurable Binding against FPGA Replay Attacks",
    "doi": "https://doi.org/10.1145/2699833",
    "publication_date": "2015-03-02",
    "publication_year": 2015,
    "authors": "Jiliang Zhang; Yaping Lin; Gang Qu",
    "corresponding_authors": "",
    "abstract": "The FPGA replay attack, where an attacker downgrades an FPGA-based system to the previous version with known vulnerabilities, has become a serious security and privacy concern for FPGA design. Current FPGA intellectual property (IP) protection mechanisms target the protection of FPGA configuration bitstreams by watermarking or encryption or binding. However, these mechanisms fail to prevent replay attacks. In this article, based on a recently reported PUF-FSM binding method that protects the usage of configuration bitstreams, we propose to reconfigure both the physical unclonable functions (PUFs) and the locking scheme of the finite state machine (FSM) in order to defeat the replay attack. We analyze the proposed scheme and demonstrate how replay attack would fail in attacking systems protected by the reconfigurable binding method. We implement two ways to build reconfigurable PUFs and propose two practical methods to reconfigure the locking scheme. Experimental results show that the two reconfigurable PUFs can generate significantly distinct responses with average reconfigurability of more than 40%. The reconfigurable locking schemes only incur a timing overhead less than 1%.",
    "cited_by_count": 33,
    "openalex_id": "https://openalex.org/W2013574495",
    "type": "article"
  },
  {
    "title": "Test compaction for small-delay defects using an effective path selection scheme",
    "doi": "https://doi.org/10.1145/2491477.2491488",
    "publication_date": "2013-07-01",
    "publication_year": 2013,
    "authors": "Dong Xiang; Jianbo Li; Krishnendu Chakrabarty; Xijiang Lin",
    "corresponding_authors": "",
    "abstract": "Testing for small-delay defects (SDDs) requires fault-effect propagation along the longest testable paths. However, identification of the longest testable paths requires high CPU time, and the sensitization of all such paths leads to large pattern counts. Dynamic test compaction for small-delay defects is therefore necessary to reduce test-data volume. We present a new technique for identifying the longest testable paths through each gate in order to accelerate test generation for SDDs. The resulting test patterns sensitize the longest testable paths that pass through each SDD site. An efficient dynamic test compaction method based on structural analysis is presented to reduce the pattern count substantially, while ensuring that all the longest paths for each SDD are sensitized. Simulation results for a set of ISCAS 89 and IWLS 05 benchmark circuits demonstrate the effectiveness of this method.",
    "cited_by_count": 32,
    "openalex_id": "https://openalex.org/W2041350247",
    "type": "article"
  },
  {
    "title": "Aging- and Variation-Aware Delay Monitoring Using Representative Critical Path Selection",
    "doi": "https://doi.org/10.1145/2746237",
    "publication_date": "2015-06-24",
    "publication_year": 2015,
    "authors": "Farshad Firouzi; Fangming Ye; Krishnendu Chakrabarty; Mehdi B. Tahoori",
    "corresponding_authors": "",
    "abstract": "Process together with runtime variations in temperature and voltage, as well as transistor aging, degrade path delay and may eventually induce circuit failure due to timing variations. Therefore, in-field tracking of path delays is essential, and to respond to this need, several delay sensor designs have been proposed in the literature. However, due to the significant overhead of these sensors and the large number of critical paths in today's IC, it is infeasible to monitor the delay of every critical path in silicon. We present an aging- and variationaware representative path selection technique based on machine learning that allows to measure the delay of a small set of paths and infer the delay of a larger pool of paths that are likely to fail due to delay variations. Simulation results for benchmark circuits highlight the accuracy of the proposed approach for predicting critical-path delay based on the selected representative paths.",
    "cited_by_count": 32,
    "openalex_id": "https://openalex.org/W2271673038",
    "type": "article"
  },
  {
    "title": "Instruction-Level Abstraction (ILA)",
    "doi": "https://doi.org/10.1145/3282444",
    "publication_date": "2018-12-21",
    "publication_year": 2018,
    "authors": "Bo-Yuan Huang; Hongce Zhang; Pramod Subramanyan; Yakir Vizel; Aarti Gupta; Sharad Malik",
    "corresponding_authors": "",
    "abstract": "Modern Systems-on-Chip (SoC) designs are increasingly heterogeneous and contain specialized semi-programmable accelerators in addition to programmable processors. In contrast to the pre-accelerator era, when the ISA played an important role in verification by enabling a clean separation of concerns between software and hardware, verification of these “accelerator-rich” SoCs presents new challenges. From the perspective of hardware designers, there is a lack of a common framework for formal functional specification of accelerator behavior. From the perspective of software developers, there exists no unified framework for reasoning about software/hardware interactions of programs that interact with accelerators. This article addresses these challenges by providing a formal specification and high-level abstraction for accelerator functional behavior. It formalizes the concept of an Instruction Level Abstraction (ILA), developed informally in our previous work, and shows its application in modeling and verification of accelerators. This formal ILA extends the familiar notion of instructions to accelerators and provides a uniform, modular, and hierarchical abstraction for modeling software-visible behavior of both accelerators and programmable processors. We demonstrate the applicability of the ILA through several case studies of accelerators (for image processing, machine learning, and cryptography), and a general-purpose processor (RISC-V). We show how the ILA model facilitates equivalence checking between two ILAs, and between an ILA and its hardware finite-state machine (FSM) implementation. Further, this equivalence checking supports accelerator upgrades using the notion of ILA compatibility, similar to processor upgrades using ISA compatibility.",
    "cited_by_count": 31,
    "openalex_id": "https://openalex.org/W4288637392",
    "type": "article"
  },
  {
    "title": "Security Analysis of Arbiter PUF and Its Lightweight Compositions Under Predictability Test",
    "doi": "https://doi.org/10.1145/2940326",
    "publication_date": "2016-12-26",
    "publication_year": 2016,
    "authors": "Phuong Ha Nguyen; Durga Prasad Sahoo; Rajat Subhra Chakraborty; Debdeep Mukhopadhyay",
    "corresponding_authors": "",
    "abstract": "Unpredictability is an important security property of Physically Unclonable Function (PUF) in the context of statistical attacks, where the correlation between challenge-response pairs is explicitly exploited. In the existing literature on PUFs, the Hamming Distance Test, denoted by HDT( t ), was proposed to evaluate the unpredictability of PUFs, which is a simplified case of the Propagation Criterion test PC( t ). The objective of these test schemes is to estimate the output transition probability when there are t or fewer than t bits flips, and ideally this probability value should be 0.5. In this work, we show that aforementioned two test schemes are not enough to ensure the unpredictability of a PUF design. We propose a new test, which is denoted as HDT( e , t ). This test scheme is a fine-tuned version of the previous schemes, as it considers the flipping bit pattern vector e along with parameter t . As a contribution, we provide a comprehensive discussion and analytic interpretation of HDT( t ), PC( t ), and HDT( e , t ) test schemes for Arbiter PUF (APUF), Exclusive-OR (XOR) PUF, and Lightweight Secure PUF (LSPUF). Our analysis establishes that HDT( e , t ) test is more general in comparison with HDT( t ) and PC( t ) tests. In addition, we demonstrate a few scenarios where the adversary can exploit the information obtained from the analysis of HDT( e , t ) properties of APUF, XOR PUF, and LSPUF to develop statistical attacks on them, if the ideal value of HDT( e , t ) = 0.5 is not achieved for a given PUF. We validate our theoretical observations using the simulated and Field Programmable Gate Array (FPGA) implemented APUF, XOR PUF, and LSPUF designs.",
    "cited_by_count": 29,
    "openalex_id": "https://openalex.org/W2562003427",
    "type": "article"
  },
  {
    "title": "SCRIPT",
    "doi": "https://doi.org/10.1145/3383445",
    "publication_date": "2020-05-13",
    "publication_year": 2020,
    "authors": "Adib Nahiyan; Jungmin Park; Miao He; Yousef Iskander; Farimah Farahmandi; Domenic Forte; Mark Tehranipoor",
    "corresponding_authors": "",
    "abstract": "Power side-channel attacks (SCAs) have been proven to be effective at extracting secret keys from hardware implementations of cryptographic algorithms. Ideally, the power side-channel leakage (PSCL) of hardware designs of a cryptographic algorithm should be evaluated as early as the pre-silicon stage (e.g., gate level). However, there has been little effort in developing computer-aided design (CAD) tools to accomplish this. In this article, we propose an automated CAD framework called SCRIPT to evaluate information leakage through side-channel analysis. SCRIPT starts by defining the underlying properties of the hardware implementation that can be exploited by side-channel attacks. It then utilizes information flow tracking (IFT) to identify registers that exhibit those properties and, therefore, leak information through the side-channel. Here, we develop an IFT-based side-channel vulnerability metric ( SCV ) that is utilized by SCRIPT for PSCL assessment. SCV is conceptually similar to the traditionally used signal-to-noise ratio (SNR) metric. However, unlike SNR, which requires thousands of traces from silicon measurements, SCRIPT utilizes formal methods to generate SCV-guided patterns/plaintexts, allowing us to derive SCV using only a few patterns (ideally as low as two) at gate level. SCV estimates PSCL vulnerability at pre-silicon stage based on the number of plaintexts required to attain a specific SCA success rate. The integration of IFT and pattern generation makes SCRIPT efficient, accurate, and generic to be applied to any hardware design. We validate the efficacy of the SCRIPT framework by demonstrating that it can effectively and accurately determine SCA success rates for different AES designs at pre-silicon stage. SCRIPT is orders of magnitude more efficient than traditional pre-silicon PSCL assessment (SNR-based), with an average evaluation time of 15 minutes; whereas, traditional PSCL assessment at pre-silicon stage would require more than a month. We also analyze the PSCL characteristic of the multiplication unit of RISC processor using SCRIPT to demonstrate SCRIPT’s applicability.",
    "cited_by_count": 28,
    "openalex_id": "https://openalex.org/W3028559075",
    "type": "article"
  },
  {
    "title": "Reconfigurable Network-on-Chip Security Architecture",
    "doi": "https://doi.org/10.1145/3406661",
    "publication_date": "2020-08-25",
    "publication_year": 2020,
    "authors": "Subodha Charles; Prabhat Mishra",
    "corresponding_authors": "",
    "abstract": "Growth of the Internet-of-things has led to complex system-on-chips (SoCs) being used in the edge devices in IoT applications. The increased complexity is demanding designers to consider several critical factors, such as dynamic requirement changes, long application life, mass production, and tight time-to-market deadlines. These requirements lead to more complex security concerns. SoC manufacturers outsource some of the intellectual property cores integrated on the SoC to untrusted third-party vendors. The untrusted intellectual properties can contain malicious implants, which can launch attacks using the resources provided by the on-chip interconnection network, commonly known as the network-on-chip (NoC). Existing efforts on securing NoC have considered lightweight encryption, authentication, and other attack detection mechanisms such as denial-of-service and buffer overflows. Unfortunately, these approaches focus on designing statically optimized security solutions. As a result, they are not suitable for many IoT systems with long application life and dynamic requirement changes. There is a critical need to design reconfigurable security architectures that can be dynamically tuned based on changing requirements. In this article, we propose a tier-based reconfigurable security architecture that can adapt to different use-case scenarios. We explore how to design an efficient reconfigurable architecture that can support three popular NoC security mechanisms (encryption, authentication, and denial-of-service attack detection and localization) and implement suitable dynamic reconfiguration techniques. We evaluate our proposed framework by running standard benchmarks enabling different tiers of security and provide a comprehensive analysis of how different levels of security can affect application performance, energy efficiency, and area overhead.",
    "cited_by_count": 27,
    "openalex_id": "https://openalex.org/W3080484431",
    "type": "article"
  },
  {
    "title": "TAAL",
    "doi": "https://doi.org/10.1145/3442379",
    "publication_date": "2021-03-09",
    "publication_year": 2021,
    "authors": "Ayush Jain; Ziqi Zhou; Ujjwal Guin",
    "corresponding_authors": "",
    "abstract": "Due to the globalization of semiconductor manufacturing and test processes, the system-on-a-chip (SoC) designers no longer design the complete SoC and manufacture chips on their own. This outsourcing of the design and manufacturing of Integrated Circuits (ICs) has resulted in several threats, such as overproduction of ICs, sale of out-of-specification/rejected ICs, and piracy of Intellectual Properties (IPs). Logic locking has emerged as a promising defense strategy against these threats. However, various attacks about the extraction of secret keys have undermined the security of logic locking techniques. Over the years, researchers have proposed different techniques to prevent existing attacks. In this article, we propose a novel attack that can break any logic locking techniques that rely on the stored secret key. This proposed TAAL attack is based on implanting a hardware Trojan in the netlist, which leaks the secret key to an adversary once activated. As an untrusted foundry can extract the netlist of a design from the layout/mask information, it is feasible to implement such a hardware Trojan. All three proposed types of TAAL attacks can be used for extracting secret keys. We have introduced the models for both the combinational and sequential hardware Trojans that evade manufacturing tests. An adversary only needs to choose one hardware Trojan out of a large set of all possible Trojans to launch the TAAL attack.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W3134156870",
    "type": "article"
  },
  {
    "title": "Compiler optimization on VLIW instruction scheduling for low power",
    "doi": "https://doi.org/10.1145/762488.762494",
    "publication_date": "2003-04-01",
    "publication_year": 2003,
    "authors": "Chingren Lee; Jenq Kuen Lee; TingTing Hwang; Shi‐Chun Tsai",
    "corresponding_authors": "",
    "abstract": "In this article, we investigate compiler transformation techniques regarding the problem of scheduling VLIW instructions aimed at reducing power consumption of VLIW architectures in the instruction bus. The problem can be categorized into two types: horizontal scheduling and vertical scheduling. For the case of horizontal scheduling, we propose a bipartite-matching scheme for instruction scheduling. We prove that our greedy bipartite-matching scheme always gives the optimal switching activities of the instruction bus for given VLIW instruction scheduling policies. For the case of vertical scheduling, we prove that the problem is NP-hard, and we further propose a heuristic algorithm to solve the problem. Our experiment is performed on Alpha-based VLIW architectures and an ATOM simulator, and the compiler incorporated in our proposed schemes is implemented based on SUIF and MachSUIF. Experimental results of horizontal scheduling optimization show an average 13.30% reduction with four-way issue architecture and an average 20.15% reduction with eight-way issue architecture for transitional activities of the instruction bus as compared with conventional list scheduling for an extensive set of benchmarks. The additional reduction for transitional activities of the instruction bus from horizontal to vertical scheduling with window size four is around 4.57 to 10.42%, and the average is 7.66%. Similarly, the additional reduction with window size eight is from 6.99 to 15.25%, and the average is 10.55%.",
    "cited_by_count": 56,
    "openalex_id": "https://openalex.org/W1970238527",
    "type": "article"
  },
  {
    "title": "Code placement techniques for cache miss rate reduction",
    "doi": "https://doi.org/10.1145/268424.268469",
    "publication_date": "1997-10-01",
    "publication_year": 1997,
    "authors": "Hiroyuki Tomiyama; Hiroto Yasuura",
    "corresponding_authors": "",
    "abstract": "In the design of embedded systems with cache memories, it is important to minimize the cache miss rates to reduce power consumption of the systems as well as improve the performance. In this article, we propose two code placement methods ( a simplified method and a refined one) to reduce miss rates of instruction caches. We first define a simplified code placement problem without an attempt to minimize the code size. The problem is formulated as an integer linear programming (ILP) problem, by which an optimal placement can be found. Experimental results show that the simplified method reduces cache misses by an average of 30% (max. 77%). However, the code size obtained by the simplified method tends to be large, which inevitably leads to a larger memory size. In order to overcome this limitation, we further propose a refined code placement method in which the code size provided by the system designers must be satisfied. The effectiveness of the refined method is also demonstrated.",
    "cited_by_count": 55,
    "openalex_id": "https://openalex.org/W1981013191",
    "type": "article"
  },
  {
    "title": "Fast placement approaches for FPGAs",
    "doi": "https://doi.org/10.1145/544536.544540",
    "publication_date": "2002-04-01",
    "publication_year": 2002,
    "authors": "Russell Tessier",
    "corresponding_authors": "Russell Tessier",
    "abstract": "Recent trends in FPGA development indicate a strong shift toward design reuse through the use of intellectual property (IP). This design shift has motivated the development of Frontier, a timing-driven FPGA placement system that uses design macroblocks in conjunction with a series of placement algorithms to achieve highly routable and high-performance layouts quickly. In the first stage of design placement, a macro-based floorplanner is used to quickly identify an initial layout based on intermacro connectivity. Next, FPGA routability and performance metrics are used to evaluate the quality of the initial placement. Finally, if the floorplan is determined to be insufficient from a routability or performance standpoint, a feedback-driven placement perturbation step is employed to achieve a lower cost placement. For a collection of large reconfigurable computing benchmark circuits our timing-driven placement system exhibits a 2.6× speedup in combined place and route time versus commercial FPGA CAD software with improved design performance for most designs. It is shown that floorplanning, placement evaluation, and backend optimization are all necessary to achieve high-performance placement solutions.",
    "cited_by_count": 54,
    "openalex_id": "https://openalex.org/W2008531154",
    "type": "article"
  },
  {
    "title": "Tutorial",
    "doi": "https://doi.org/10.1145/762488.762489",
    "publication_date": "2003-04-01",
    "publication_year": 2003,
    "authors": "Stephen A. Edwards",
    "corresponding_authors": "Stephen A. Edwards",
    "abstract": "Embedded systems often include a traditional processor capable of executing sequential code, but both control and data-dominated tasks are often more naturally expressed using one of the many domain-specific concurrent specification languages. This article surveys a variety of techniques for translating these concurrent specifications into sequential code. The techniques address compiling a wide variety of languages, ranging from dataflow to Petri nets. Each uses a different method, to some degree chosen to match the semantics of concurrent language. Each technique is considered to consist of a partial evaluator operating on an interpreter. This combination provides a clearer picture of how parts of each technique could be used in a different setting.",
    "cited_by_count": 54,
    "openalex_id": "https://openalex.org/W2156783651",
    "type": "article"
  },
  {
    "title": "Efficient circuit clustering for area and power reduction in FPGAs",
    "doi": "https://doi.org/10.1145/605440.605448",
    "publication_date": "2002-10-01",
    "publication_year": 2002,
    "authors": "Amit Singh; G. Parthasarathy; Malgorzata Marek-Sadowska",
    "corresponding_authors": "",
    "abstract": "We utilize Rent's rule as an empirical measure for efficient clustering and placement of circuits in clustered Field Programmable Gate Arrays (FPGAs). We show that careful matching of resource availability and design complexity during the clustering and placement processes can contribute to spatial uniformity in the placed design, leading to overall device decongestion after routing. We present experimental results to show that appropriate logic depopulation during clustering can have a positive impact on the overall FPGA device area. Our clustering and placement techniques can improve the overall device routing area by as much as 62%, 35% on average, for the same array size, when compared to state-of-the-art FPGA clustering, placement, and routing tools. Power dissipation simulations using a typical buffered pass-transistor-based FPGA interconnect model are also presented. They show that our clustering and placement techniques can reduce the overall device power dissipation by approximately 13%.",
    "cited_by_count": 53,
    "openalex_id": "https://openalex.org/W2055251702",
    "type": "article"
  },
  {
    "title": "Architecture-level power estimation and design experiments",
    "doi": "https://doi.org/10.1145/371254.371262",
    "publication_date": "2001-01-01",
    "publication_year": 2001,
    "authors": "Rita Yu Chen; M.J. Irwin; Raminder Bajwa",
    "corresponding_authors": "",
    "abstract": "Architecture-level power estimation has received more attention recently because of its efficiency. This article presents a technique used to do power analysis of processors at the architecture level. It provides cycle-by-cycle power consumption data of the architecture on the basis of the instruction/data flow stream. To characterize the power dissipation of control units, a novel hierarchical method has been developed. Using this technique, a power estimator is implemented for a commercial processor. The accuracy of the estimator is validated by comparing the power values it produces against measurements made by a gate-level power simulator for the same benchmark set. Our estimation approach is shown to provide very efficient and accurate power analysis at the architecture level. The energy models built for first-pass estimation (such as ALU, MAC unit, register files) are reusable for future architecture design modification. In this article, we demonstrate the application of the technique. Furthermore, this technique can evaluate various kinds of software to achieve hardware/software codesign for low power.",
    "cited_by_count": 50,
    "openalex_id": "https://openalex.org/W2000419842",
    "type": "article"
  },
  {
    "title": "Combinatorial techniques for mixed-size placement",
    "doi": "https://doi.org/10.1145/1044111.1044116",
    "publication_date": "2005-01-01",
    "publication_year": 2005,
    "authors": "Saurabh Adya; Igor L. Markov",
    "corresponding_authors": "",
    "abstract": "While recent literature on circuit layout addresses large-scale standard-cell placement, the authors typically assume that all macros are fixed. Floorplanning techniques are very good at handling macros, but do not scale to hundreds of thousands of placeable objects. Therefore we combine floorplanning techniques with placement techniques to solve the more general placement problem. Our work shows how to place macros consistently with large numbers of small standard cells. Proposed techniques can also be used to guide circuit designers who prefer to place macros by hand.We address the computational difficulty of layout problems involving large macros and numerous small logic cells at the same time. Proposed algorithms are evaluated in the context of wirelength minimization because a computational method that is not scalable in optimizing wirelength is unlikely to be successful for more complex objectives (congestion, delay, power, etc.)We propose several different design flows to place mixed-size placement instances. The first flow relies on an arbitrary black-box standard-cell placer to obtain an initial placement and then removes possible overlaps using a fixed-outline floorplanner. This results in valid placements for macros, which are considered fixed. Remaining standard cells are then placed by another call to the standard-cell placer. In the second flow a standard-cell placer generates an initial placement and a force-directed placer is used in the engineering change order (ECO) mode to generate an overlap-free placement. Empirical evaluation on ibm benchmarks shows that in most cases our proposed flows compare favorably with previously published mixed-size placers, Kraftwerk, and the mixed-size floor-placer proposed at the 2003 Conference on Design, Automation, and Test in Europe (DATE 2003), and are competitive with mPG-MS.",
    "cited_by_count": 48,
    "openalex_id": "https://openalex.org/W2024392966",
    "type": "article"
  },
  {
    "title": "Cluster assignment for high-performance embedded VLIW processors",
    "doi": "https://doi.org/10.1145/567270.567274",
    "publication_date": "2002-07-01",
    "publication_year": 2002,
    "authors": "Viktor S. Lapinskii; Margarida F. Jacome; G.A. de Veciana",
    "corresponding_authors": "",
    "abstract": "Clustering is an effective method to increase the available parallelism in VLIW datapaths without incurring severe penalties associated with a large number of register file ports. Efficient utilization of a clustered datapath requires careful binding/assignment of operations to clusters. The article proposes a binding algorithm that effectively explores trade-offs between in-cluster operation serialization and delays associated with data transfers between clusters. Extensive experimental evidence is provided showing that the algorithm generates high quality solutions for representative kernels, with up to 33% improvement over a state-of-the-art binding algorithm.",
    "cited_by_count": 48,
    "openalex_id": "https://openalex.org/W2069763700",
    "type": "article"
  },
  {
    "title": "I<sub>DDX</sub>-based test methods",
    "doi": "https://doi.org/10.1145/989995.989997",
    "publication_date": "2004-04-01",
    "publication_year": 2004,
    "authors": "S.S. Sabade; D.M.H. Walker",
    "corresponding_authors": "",
    "abstract": "Supply current measurement-based test is a valuable defect-based test method for semiconductor chips. Both static leakage current (I DDQ ) and transient current (I DDT ) based tests have the capability of detecting unique defects that improve the fault detection capacity of a test suite. Collectively these test methods are known as I DDX tests. However, due to advances in the semiconductor manufacturing process, the future of these test methods is uncertain. This paper presents a survey of the research reported in the literature to extend the use of I DDX tests to deep sub-micron (DSM) technologies.",
    "cited_by_count": 46,
    "openalex_id": "https://openalex.org/W2099807755",
    "type": "article"
  },
  {
    "title": "Compile-time area estimation for LUT-based FPGAs",
    "doi": "https://doi.org/10.1145/1124713.1124721",
    "publication_date": "2006-01-01",
    "publication_year": 2006,
    "authors": "Dhananjay Kulkarni; Walid Najjar; Robert Rinker; Fadi Kurdahi",
    "corresponding_authors": "",
    "abstract": "The Cameron Project has developed a system for compiling codes written in a high-level language called SA-C, to FPGA-based reconfigurable computing systems. In order to exploit the parallelism available on the FPGAs, the SA-C compiler performs a large number of optimizations such as full loop unrolling, loop fusion and strip-mining. However, since the area on an FPGA is limited, the compiler needs to know the effect of compiler optimizations on the FPGA area; this information is typically not available until after the synthesis and place and route stage, which can take hours. In this article, we present a compile-time area estimation technique to guide SA-C compiler optimizations. We demonstrate our technique for a variety of benchmarks written in SA-C. Experimental results show that our technique predicts the area required for a design to within 2.5% of actual for small image processing operators and to within 5.0% for larger benchmarks. The estimation time is in the order of milliseconds, compared with minutes for the synthesis tool.",
    "cited_by_count": 45,
    "openalex_id": "https://openalex.org/W2072453503",
    "type": "article"
  },
  {
    "title": "Efficient power modeling and software thermal sensing for runtime temperature monitoring",
    "doi": "https://doi.org/10.1145/1255456.1255462",
    "publication_date": "2007-08-17",
    "publication_year": 2007,
    "authors": "Wei Wu; Lingling Jin; Jun Yang; Pu Liu; Sheldon X.-D. Tan",
    "corresponding_authors": "",
    "abstract": "The evolution of microprocessors has been hindered by increasing power consumption and heat dissipation on die. An excessive amount of heat creates reliability problems, reduces the lifetime of a processor, and elevates the cost of cooling and packaging considerably. It is therefore imperative to be able to monitor the temperature variations across the die in a timely and accurate manner. Most current techniques rely on on-chip thermal sensors to report the temperature of the processor. Unfortunately, significant variation in chip temperature both spatially and temporally exposes the limitation of the sensors. We present a compensating approach to tracking chip temperature through an OS resident software module that generates live power and thermal profiles of the processor. We developed such a software thermal sensor (STS) in a Linux system with a Pentium 4 Northwood core. We employed highly efficient numerical methods in our model to minimize the overhead of temperature calculation. We also developed an efficient algorithm for functional unit power modeling. Our power and thermal models are calibrated and validated against on-chip sensor readings, thermal images of the Northwood heat spreader, and the thermometer measurements on the package. The resulting STS offers detailed power and temperature breakdowns of each functional unit at runtime, enabling more efficient online power and thermal monitoring and management at a higher level, such as the operating system.",
    "cited_by_count": 43,
    "openalex_id": "https://openalex.org/W2133804388",
    "type": "article"
  },
  {
    "title": "HW-SW emulation framework for temperature-aware design in MPSoCs",
    "doi": "https://doi.org/10.1145/1255456.1255463",
    "publication_date": "2007-08-17",
    "publication_year": 2007,
    "authors": "David Atienza; Pablo Valle; Giacomo Paci; Francesco Poletti; Luca Benini; Giovanni De Micheli; J.M. Mendı́as; R. Hermida",
    "corresponding_authors": "",
    "abstract": "New tendencies envisage multiprocessor systems-on-chips (MPSoCs) as a promising solution for the consumer electronics market. MPSoCs are complex to design, as they must execute multiple applications (games, video) while meeting additional design constraints (energy consumption, time-to-market). Moreover, the rise of temperature in the die for MPSoCs can seriously affect their final performance and reliability. In this article, we present a new hardware-software emulation framework that allows designers a complete exploration of the thermal behavior of final MPSoC designs early in the design flow. The proposed framework uses FPGA emulation as the key element to model hardware components of the considered MPSoC platform at multimegahertz speeds. It automatically extracts detailed system statistics that are used as input to our software thermal library running in a host computer. This library calculates at runtime the temperature of on-chip components, based on the collected statistics from the emulated system and final floorplan of the MPSoC. This enables fast testing of various thermal management techniques. Our results show speedups of three orders of magnitude compared to cycle-accurate MPSoC simulators.",
    "cited_by_count": 42,
    "openalex_id": "https://openalex.org/W2130770024",
    "type": "article"
  },
  {
    "title": "Specification-driven directed test generation for validation of pipelined processors",
    "doi": "https://doi.org/10.1145/1367045.1367051",
    "publication_date": "2008-07-01",
    "publication_year": 2008,
    "authors": "Prabhat Mishra; Nikil Dutt",
    "corresponding_authors": "",
    "abstract": "Functional validation is a major bottleneck in pipelined processor design due to the combined effects of increasing design complexity and lack of efficient techniques for directed test generation. Directed test vectors can reduce overall validation effort, since shorter tests can obtain the same coverage goal compared to the random tests. This article presents a specification-driven directed test generation methodology. The proposed methodology makes three important contributions. First, a general graph model is developed that can capture the structure and behavior (instruction set) of a wide variety of pipelined processors. The graph model is generated from the processor specification. Next, we propose a functional fault model that is used to define the functional coverage for pipelined architectures. Finally, we propose two complementary test generation techniques: test generation using model checking, and test generation using template-based procedures. These test generation techniques accept the graph model of the architecture as input and generate test programs to detect all the faults in the functional fault model. Our experimental results on two pipelined processor models demonstrate several orders-of-magnitude reduction in overall validation effort by drastically reducing both test-generation time and number of test programs required to achieve a coverage goal.",
    "cited_by_count": 41,
    "openalex_id": "https://openalex.org/W2046211462",
    "type": "article"
  },
  {
    "title": "Automatic design of application-specific reconfigurable processor extensions with UPaK synthesis kernel",
    "doi": "https://doi.org/10.1145/1640457.1640458",
    "publication_date": "2009-12-01",
    "publication_year": 2009,
    "authors": "Christophe Wolinski; Krzysztof Kuchciński; Erwan Raffin",
    "corresponding_authors": "",
    "abstract": "This article presents a new tool for automatic design of application-specific reconfigurable processor extensions based on UPaK (Abstract U nified Pa tterns Based Synthesis K ernel for Hardware and Software Systems). We introduce a complete design flow that identifies new instructions, selects specific instructions and schedules a considered application on the newly created reconfigurable architecture. The identified extensions are implemented as specialized sequential or parallel instructions. These instructions are executed on a reconfigurable unit implementing all merged patterns. Our method uses specially developed algorithms for subgraph isomorphism that are implemented as graph matching constraints. These constraints together with separate algorithms are able to efficiently identify computational patterns and carry out application mapping and scheduling. Our methods can handle both time-constrained and resource-constrained scheduling. Experimental results show that the presented method provides high coverage of application graphs with small number of patterns and ensures high application execution speedup both for sequential and parallel application execution with reconfigurable processor extensions implementing selected patterns.",
    "cited_by_count": 34,
    "openalex_id": "https://openalex.org/W2115179770",
    "type": "article"
  },
  {
    "title": "Dynamic data folding with parameterizable FPGA configurations",
    "doi": "https://doi.org/10.1145/2003695.2003703",
    "publication_date": "2011-10-01",
    "publication_year": 2011,
    "authors": "Karel Bruneel; Wim Heirman; Dirk Stroobandt",
    "corresponding_authors": "",
    "abstract": "In many applications, subsequent data manipulations differ only in a small set of parameter values. Because of their reconfigurability, FPGAs (field programmable gate arrays) can be configured with a specialized circuit each time the parameter values change. This technique is called dynamic data folding. The specialized circuits are smaller and faster than their generic counterparts. However, the overhead involved in generating the configurations for the specialized circuits at runtime is very large when conventional tools are used, and this overhead will in many cases negate the benefit of using optimized configurations. This article introduces an automatic method for generating runtime parameterizable configurations from arbitrary Boolean circuits. These configurations, in which some of the configuration bits are expressed as a closed-form Boolean expression of a set of parameters, enable very fast run-time specialization, since specialization only involves evaluating these expressions. Our approach is validated on a ternary content-addressable memory (TCAM). We show that the specialized configurations, produced by our method use 2.82 times fewer LUTs than the generic configuration, and even 1.41 times fewer LUTs than the implementation generated by Xilinx Coregen. Moreover, while Coregen needs hand-crafted generators for each type of circuit, our toolflow can be applied to any VHDL design. Using our automatic and generally applicable method, run-time hardware optimization suddenly becomes feasible for a large class of applications.",
    "cited_by_count": 31,
    "openalex_id": "https://openalex.org/W2048944807",
    "type": "article"
  },
  {
    "title": "Directed test generation for validation of multicore architectures",
    "doi": "https://doi.org/10.1145/2209291.2209297",
    "publication_date": "2012-06-01",
    "publication_year": 2012,
    "authors": "Xiaoke Qin; Prabhat Mishra",
    "corresponding_authors": "",
    "abstract": "Functional validation is widely acknowledged as a major challenge for multicore architectures. Directed tests are promising since a significantly smaller number of directed tests can achieve the same coverage goal compared to constrained-random tests. SAT-based bounded model checking is effective for automated generation of directed tests (counterexamples). While existing approaches focus on clause forwarding between different bounds to reduce the test generation time, this article proposes a novel technique that exploits temporal, structural, and spatial symmetry in multicore designs at the same time. Our proposed technique enables the reuse of the knowledge learned from one core to the remaining cores in multicore architectures (structural symmetry), from one bound to the next for a give property (temporal symmetry), as well as from one property to other properties (spatial symmetry). The experimental results demonstrate that our approach can significantly (3--10 times) reduce overall test generation time compared to existing approaches.",
    "cited_by_count": 29,
    "openalex_id": "https://openalex.org/W1970407306",
    "type": "article"
  },
  {
    "title": "In-network monitoring and control policy for DVFS of CMP networks-on-chip and last level caches",
    "doi": "https://doi.org/10.1145/2504905",
    "publication_date": "2013-10-01",
    "publication_year": 2013,
    "authors": "Xi Chen; Zheng Xu; Hyungjun Kim; Paul V. Gratz; Jiang Hu; Michael Kishinevsky; Ümit Y. Ogras",
    "corresponding_authors": "",
    "abstract": "In chip design today and for a foreseeable future, the last-level cache and on-chip interconnect is not only performance critical but also a substantial power consumer. This work focuses on employing dynamic voltage and frequency scaling (DVFS) policies for networks-on-chip (NoC) and shared, distributed last-level caches (LLC). In particular, we consider a practical system architecture where the distributed LLC and the NoC share a voltage/frequency domain that is separate from the core domain. This architecture enables the control of the relative speed between the cores and memory hierarchy without introducing synchronization delays within the NoC. DVFS for this architecture is more complex than individual link/core-based DVFS since it involves spatially distributed monitoring and control. We propose an average memory access time (AMAT)-based monitoring technique and integrate it with DVFS based on PID control theory. Simulations on PARSEC benchmarks yield a 27% energy savings with a negligible impact on system performance.",
    "cited_by_count": 29,
    "openalex_id": "https://openalex.org/W2096835107",
    "type": "article"
  },
  {
    "title": "A3MAP",
    "doi": "https://doi.org/10.1145/2209291.2209299",
    "publication_date": "2012-06-01",
    "publication_year": 2012,
    "authors": "Wooyoung Jang; David Z. Pan",
    "corresponding_authors": "",
    "abstract": "In this article, we propose novel and global Architecture-Aware Analytic MAPping (A3MAP) algorithms applied to Networks-on-Chip (NoCs) not only with homogeneous Processing Elements (PEs) on a regular mesh network as done by most previous application mapping algorithms but also with heterogeneous PEs on an irregular mesh or custom network. As the main contributions, we develop a simple yet efficient interconnection matrix that can easily model any core graph and network. Then, an application mapping problem is exactly formulated to Mixed Integer Quadratic Programming (MIQP). Since MIQP is NP-hard, we propose two effective heuristics, a successive relaxation algorithm achieving short runtime, called A3MAP-SR and a genetic algorithm achieving high mapping quality, called A3MAP-GA. We also propose a partition-based application mapping approach for large-scale NoCs, which provides better trade-off between performance and runtime. Experimental results show that A3MAP algorithms reduce total hop count, compared to the previous application mapping algorithms optimized for a regular mesh network, called NMAP [Murali and Micheli 2004] and for an irregular mesh and custom network, called CMAP [Tornero et al. 2008]. Furthermore, A3MAP algorithms make packets travel shorter distance than CMAP, which is related to energy consumption.",
    "cited_by_count": 29,
    "openalex_id": "https://openalex.org/W2622348669",
    "type": "article"
  },
  {
    "title": "Hybrid nonvolatile disk cache for energy-efficient and high-performance systems",
    "doi": "https://doi.org/10.1145/2390191.2390199",
    "publication_date": "2013-01-01",
    "publication_year": 2013,
    "authors": "Liang Shi; Jianhua Li; Chun Jason Xue; Xuehai Zhou",
    "corresponding_authors": "",
    "abstract": "NAND flash memory has been employed as disk cache in recent years. It has the advantages of high performance, low leakage power, and cost efficiency. However, flash memory's performance is limited by the inability of in-place updates, coarse access granularity, and a limited number of write/erase times. In this article, we propose a hybrid nonvolatile disk cache architecture for high-performance and energy-efficient systems, where the disk cache is implemented with a small-size phase change memory (PCM) and a large-size NAND flash memory. Compared with current flash memory-based disk cache, it has the following advantages. (1) System performance is improved as requests are carefully directed between PCM and flash memory; (2) the energy consumption of disk cache is substantially reduced with significant reduction of additional operations, such as garbage collections; (3) the efficiency of flash memory is improved with the reduction of write activities on flash memory; and (4) lifetime of NAND flash memory is increased with most of the write operations assigned to PCM, where PCM's lifetime is guaranteed to be longer than the lifetime of flash memory. Simulation results show that the proposed methods can substantially improve the system performance, energy consumption, and lifetime of the hybrid disk cache.",
    "cited_by_count": 28,
    "openalex_id": "https://openalex.org/W2035918546",
    "type": "article"
  },
  {
    "title": "An Efficient Hardware-Based Higher Radix Floating Point MAC Design",
    "doi": "https://doi.org/10.1145/2667224",
    "publication_date": "2014-11-18",
    "publication_year": 2014,
    "authors": "Mohamed Asan Basiri M; Noor Mahammad Sk",
    "corresponding_authors": "",
    "abstract": "This article proposes an effective way of implementing a multiply accumulate circuit (MAC) for high-speed floating point arithmetic operations. The real-world applications related to digital signal processing and the like demand high-performance computation with greater accuracy. In general, digital signals are represented as a sequence of signed/unsigned fixed/floating point numbers. The final result of a MAC operation can be computed by feeding the mantissa of the previous MAC result as one of the partial products to a Wallace tree multiplier or Braun multiplier. Thus, the separate accumulation circuit can be avoided by keeping the circuit depth still within the bounds of the Wallace tree multiplier, namely O ( log 2 n ), or Braun multiplier, namely O ( n ). In this article, three kinds of floating point MACs are proposed. The experimental results show 48.54% of improvement in worst path delay achieved by the proposed floating point MAC using a radix-2 Wallace structure compared with a conventional floating point MAC without a pipeline using a 45nm technology library. The same proposed design gives 39.92% of improvement in worst path delay without a pipeline using a radix-4 Braun structure as compared with a conventional design. In this article, a radix-32 Q 32.32 -format-based floating point MAC is proposed using a Wallace tree/Braun multiplier. Also this article discusses the msb prediction problem and its solution in floating point arithmetic that is not available in modern fused multiply-add designs. The performance results show comparisons between the proposed floating point MAC with various floating point MAC designs for radix-2,-4,-8, and -16. The proposed design has lesser depth than a conventional floating point MAC as well as a lower area requirement than other ways of floating point MAC implementation, both with/without a pipeline.",
    "cited_by_count": 28,
    "openalex_id": "https://openalex.org/W2138659811",
    "type": "article"
  },
  {
    "title": "Thermal prediction and adaptive control through workload phase detection",
    "doi": "https://doi.org/10.1145/2390191.2390198",
    "publication_date": "2013-01-01",
    "publication_year": 2013,
    "authors": "Ryan Cochran; Sherief Reda",
    "corresponding_authors": "",
    "abstract": "Elevated die temperature is a true limiter to the scalability of modern processors. With continued technology scaling in order to meet ever-increasing performance demands, it is no longer cost effective to design cooling systems that handle the worst-case thermal behaviors. Instead, cooling systems are designed to handle typical chip operation, while processors must detect and handle rare thermal emergencies. Most processors rely on measurements from integrated thermal sensors and dynamic thermal management (DTM) techniques in order to manage the trade-off between performance and thermal risk. Optimal management requires advanced knowledge of the thermal trajectory based on the current workload behaviors and operating conditions. In this work, we devise novel workload phase classification strategies that automatically discriminate among workload behaviors with respect to the thermal control response. We incorporate workload phase-detection and thermal models into a dynamic voltage and frequency scaling (DVFS) technique that can optimally control temperature during runtime based on thermal predictions. We demonstrate the effectiveness of our proposed techniques in predicting and adaptively controlling the thermal behavior of a real quad-core processor in response to a wide range of workloads. In comparison with state-of-the-art model predictive control (MPC) techniques in previous works on thermal prediction, we demonstrate a 5.8% improvement in instruction throughput with the same number of thermal violations. In comparison with simple proportional-integral (PI) feedback control techniques, we improve instruction throughput by 3.9%, while significantly reducing the number of thermal violations.",
    "cited_by_count": 27,
    "openalex_id": "https://openalex.org/W2063718160",
    "type": "article"
  },
  {
    "title": "Revisiting automated physical synthesis of high-performance clock networks",
    "doi": "https://doi.org/10.1145/2442087.2442102",
    "publication_date": "2013-03-01",
    "publication_year": 2013,
    "authors": "Matthew R. Guthaus; Gustavo Wilke; Ricardo Reis",
    "corresponding_authors": "",
    "abstract": "High-performance clock distribution has been a challenge for nearly three decades. During this time, clock synthesis tools and algorithms have strove to address a myriad of important issues helping designers to create faster, more reliable, and more power efficient chips. This work provides a complete discussion of the high-performance ASIC clock distribution using information gathered from both leading industrial clock designers and previous research publications. While many techniques are only briefly explained, the references summarize the most influential papers on a variety of topics for more in-depth investigation. This article also provides a thorough discussion of current issues in clock synthesis and concludes with insight into future research and design challenges for the community at large.",
    "cited_by_count": 27,
    "openalex_id": "https://openalex.org/W2069142841",
    "type": "article"
  },
  {
    "title": "Improving PCM Endurance with a Constant-Cost Wear Leveling Design",
    "doi": "https://doi.org/10.1145/2905364",
    "publication_date": "2016-06-28",
    "publication_year": 2016,
    "authors": "Yu-Ming Chang; Pi-Cheng Hsiu; Yuan-Hao Chang; Chi-Hao Chen; Tei‐Wei Kuo; Cheng-Yuan Michael Wang",
    "corresponding_authors": "",
    "abstract": "Improving PCM endurance is a fundamental issue when it is considered as an alternative to replace DRAM as main memory. Memory-based wear leveling (WL) is an effective way to improve PCM endurance, but its major challenge is how to efficiently determine the appropriate memory pages for allocation or swapping. In this article, we present a constant-cost WL design that is compatible with existing memory management. Two implementations, namely bucket-based and array-based WL, with constant-time (or nearly zero) search cost are proposed to be integrated into the OS layer and the hardware layer, respectively, as well as to trade between time and space complexity. The results of experiments conducted based on an implementation in Android, as well as simulations with popular benchmarks, to evaluate the effectiveness of the proposed design are very encouraging.",
    "cited_by_count": 27,
    "openalex_id": "https://openalex.org/W2462134012",
    "type": "article"
  },
  {
    "title": "Parallel High-Level Synthesis Design Space Exploration for Behavioral IPs of Exact Latencies",
    "doi": "https://doi.org/10.1145/3041219",
    "publication_date": "2017-05-20",
    "publication_year": 2017,
    "authors": "Benjamin Carrión Schäfer",
    "corresponding_authors": "Benjamin Carrión Schäfer",
    "abstract": "This works presents a Design Space Exploration (DSE) method for Behavioral IPs (BIPs) given in ANSI-C or SystemC to find the smallest micro-architecture for a specific target latency. Previous work on High-Level Synthesis (HLS) DSE mainly focused on finding a tradeoff curve with Pareto-optimal designs. HLS is, however, a single process (component) synthesis method. Very often, the latency of the components requires a specific fixed latency when inserted within a larger system. This work presents a fast multi-threaded method to find the smallest micro-architecture for a given BIP and target latency by discriminating between all different exploration knobs and exploring these concurrently. Experimental results show that our proposed method is very effective and comprehensive results compare the quality of results vs. the speedup of your proposed explorer.",
    "cited_by_count": 27,
    "openalex_id": "https://openalex.org/W2619340758",
    "type": "article"
  },
  {
    "title": "Cross-point Resistive Memory",
    "doi": "https://doi.org/10.1145/3325067",
    "publication_date": "2019-06-20",
    "publication_year": 2019,
    "authors": "Chengning Wang; Dan Feng; Wei Tong; Jingning Liu; Zheng Li; Jiayi Chang; Yang Zhang; Bing Wu; Jie Xu; Wei Zhao; Yilin Li; Ruoxi Ren",
    "corresponding_authors": "",
    "abstract": "Emerging computational resistive memory is promising to overcome the challenges of scalability and energy efficiency that DRAM faces and also break through the memory wall bottleneck. However, cell-level and array-level nonideal properties of resistive memory significantly degrade the reliability, performance, accuracy, and energy efficiency during memory access and analog computation. Cell-level nonidealities include nonlinearity, asymmetry, and variability. Array-level nonidealities include interconnect resistance, parasitic capacitance, and sneak current. This review summarizes practical solutions that can mitigate the impact of nonideal device and circuit properties of resistive memory. First, we introduce several typical resistive memory devices with focus on their switching modes and characteristics. Second, we review resistive memory cells and memory array structures, including 1T1R, 1R, 1S1R, 1TnR, and CMOL. We also overview three-dimensional (3D) cross-point arrays and their structural properties. Third, we analyze the impact of nonideal device and circuit properties during memory access and analog arithmetic operations with focus on dot-product and matrix-vector multiplication. Fourth, we discuss the methods that can mitigate these nonideal properties by static parameter and dynamic runtime co-optimization from the viewpoint of device and circuit interaction. Here, dynamic runtime operation schemes include line connection, voltage bias, logical-to-physical mapping, read reference setting, and switching mode reconfiguration. Then, we highlight challenges on multilevel cell cross-point arrays and 3D cross-point arrays during these operations. Finally, we investigate design considerations of memory array peripheral circuits. We also portray an unified reconfigurable computational memory architecture.",
    "cited_by_count": 27,
    "openalex_id": "https://openalex.org/W2951094271",
    "type": "article"
  },
  {
    "title": "Marching-Based Wear-Leveling for PCM-Based Storage Systems",
    "doi": "https://doi.org/10.1145/2699831",
    "publication_date": "2015-03-02",
    "publication_year": 2015,
    "authors": "Hung-Sheng Chang; Yuan-Hao Chang; Pi-Cheng Hsiu; Tei‐Wei Kuo; Hsiang-Pang Li",
    "corresponding_authors": "",
    "abstract": "Improving the performance of storage systems without losing the reliability and sanity/integrity of file systems is a major issue in storage system designs. In contrast to existing storage architectures, we consider a PCM-based storage architecture to enhance the reliability of storage systems. In PCM-based storage systems, the major challenge falls on how to prevent the frequently updated (meta)data from wearing out their residing PCM cells without excessively searching and moving metadata around the PCM space and without extensively updating the index structures of file systems. In this work, we propose an adaptive wear-leveling mechanism to prevent any PCM cell from being worn out prematurely by selecting appropriate data for swapping with constant search/sort cost. Meanwhile, the concept of indirect pointers is designed in the proposed mechanism to swap data without any modification to the file system's indexes. Experiments were conducted based on well-known benchmarks and realistic workloads to evaluate the effectiveness of the proposed design, for which the results are encouraging.",
    "cited_by_count": 26,
    "openalex_id": "https://openalex.org/W2092885536",
    "type": "article"
  },
  {
    "title": "Synthesizing Optimal Switching Lattices",
    "doi": "https://doi.org/10.1145/2661632",
    "publication_date": "2014-11-18",
    "publication_year": 2014,
    "authors": "Graeme Gange; Harald Søndergaard; Peter J. Stuckey",
    "corresponding_authors": "",
    "abstract": "The use of nanoscale technologies to create electronic devices has revived interest in the use of regular structures for defining complex logic functions. One such structure is the switching lattice, a two-dimensional lattice of four-terminal switches. We show how to directly construct switching lattices of polynomial size from arbitrary logic functions; we also show how to synthesize minimal-sized lattices by translating the problem to the satisfiability problem for a restricted class of quantified Boolean formulas. The synthesis method is an anytime algorithm that uses modern SAT solving technology and dichotomic search. It improves considerably on an earlier proposal for creating switching lattices for arbitrary logic functions.",
    "cited_by_count": 26,
    "openalex_id": "https://openalex.org/W2164136814",
    "type": "article"
  },
  {
    "title": "FuzzRoute",
    "doi": "https://doi.org/10.1145/2767127",
    "publication_date": "2015-12-02",
    "publication_year": 2015,
    "authors": "Debashri Roy; Prasun Ghosal; Saraju P. Mohanty",
    "corresponding_authors": "",
    "abstract": "The high density of interconnects, closer proximity of modules, and routing phase are pivotal during the layout of a performance-centric three-dimensional integrated circuit (3D IC). Heuristic-based approaches are typically used to handle such NP-complete problems of global routing in 3D ICs. To overcome the inherent limitations of deterministic approaches, a novel methodology for multi-objective global routing based on fuzzy logic has been proposed in this article. The guiding information generated after the placement phase is used during routing with the help of a fuzzy expert system to achieve thermally efficient and congestion-free routing. A complete global routing solution is designed based on the proposed algorithms and the results are compared with selected fully established global routers, namely Labyrinth, FastRoute3.0, NTHU-R, BoxRouter 2.0, FGR, NTHU-Route2.0, FastRoute4.0, NCTU-GR, MGR, and NCTU-GR2.0. Experiments are performed over ISPD 1998 and 2008 benchmarks. The proposed router, called FuzzRoute , achieves balanced superiority in terms of routability, runtime, and wirelength over others. The improvements on routing time for Labyrinth, BoxRouter 2.0, and FGR are 91.81%, 86.87%, and 32.16%, respectively, for ISPD 1998 benchmarks. It may be noted that, though FastRoute3.0 achieves fastest runtime, it fails to generate congestion-free solutions for all benchmarks, which is overcome by the proposed FuzzRoute of the current article. It also shows wirelength improvements of 17.35%, 2.88%, 2.44%, 2.83%, and 2.10%, respectively, over others for ISPD 1998 benchmarks. For ISPD 2008 benchmark circuits it also provides 2.5%, 2.6%, 1 %, 1.1%, and 0.3% lesser wirelength and averagely runs 1.68×, 6.42×, 2.21×, 0.76×, and 1.54× faster than NTHU-Route2.0, FastRoute4.0, NCTU-GR, MGR, and NCTU-GR2.0, respectively.",
    "cited_by_count": 26,
    "openalex_id": "https://openalex.org/W2182765545",
    "type": "article"
  },
  {
    "title": "A Survey of Techniques for Cache Locking",
    "doi": "https://doi.org/10.1145/2858792",
    "publication_date": "2016-05-16",
    "publication_year": 2016,
    "authors": "Sparsh Mittal",
    "corresponding_authors": "Sparsh Mittal",
    "abstract": "Cache memory, although important for boosting application performance, is also a source of execution time variability, and this makes its use difficult in systems requiring worst-case execution time (WCET) guarantees. Cache locking is a promising approach for simplifying WCET estimation and providing predictability, and hence, several commercial processors provide ability for locking cache. However, cache locking also has several disadvantages (e.g., extra misses for unlocked blocks, complex algorithms required for selection of locking contents) and hence, a careful management is required to realize the full potential of cache locking. In this article, we present a survey of techniques proposed for cache locking. We categorize the techniques into several groups to underscore their similarities and differences. We also discuss the opportunities and obstacles in using cache locking. We hope that this article will help researchers gain insight into cache locking schemes and will also stimulate further work in this area.",
    "cited_by_count": 26,
    "openalex_id": "https://openalex.org/W2269813923",
    "type": "article"
  },
  {
    "title": "On Battery Recovery Effect in Wireless Sensor Nodes",
    "doi": "https://doi.org/10.1145/2890501",
    "publication_date": "2016-05-18",
    "publication_year": 2016,
    "authors": "Swaminathan Narayanaswamy; Steffen Schlueter; Sebastian Steinhorst; Martin Lukasiewycz; Samarjit Chakraborty; Harry E. Hoster",
    "corresponding_authors": "",
    "abstract": "With the perennial demand for longer runtime of battery-powered Wireless Sensor Nodes (WSNs), several techniques have been proposed to increase the battery runtime. One such class of techniques exploiting the battery recovery effect phenomenon claims that performing an intermittent discharge instead of a continuous discharge will increase the usable battery capacity. Several works in the areas of embedded systems and wireless sensor networks have assumed the existence of this recovery effect and proposed different power management techniques in the form of power supply architectures (multiple battery setup) and communication protocols (burst mode transmission) in order to exploit it. However, until now, a systematic experimental evaluation of the recovery effect has not been performed with real battery cells, using high-accuracy battery testers to confirm the existence of this recovery phenomenon. In this article, a systematic evaluation procedure is developed to verify the existence of this battery recovery effect. Using our evaluation procedure, we investigated Alkaline, Nickel-Metal Hydride (NiMH), and Lithium-Ion (Li-Ion) battery chemistries, which are commonly used as power supplies for Wireless Sensor Node (WSN) applications. Our experimental results do not show any evidence of the aforementioned recovery effect in these battery chemistries. In particular, our results show a significant deviation from the stochastic battery models, which were used by many power management techniques. Therefore, the existing power management approaches that rely on this recovery effect do not hold in practice. Instead of a battery recovery effect, our experimental results show the existence of the rate capacity effect , which is the reduction of usable battery capacity with higher discharge power, to be the dominant electrochemical phenomenon that should be considered for maximizing the runtime of WSN applications. We outline power management techniques that minimize the rate capacity effect in order to obtain a higher energy output from the battery.",
    "cited_by_count": 26,
    "openalex_id": "https://openalex.org/W2396556882",
    "type": "article"
  },
  {
    "title": "PARR",
    "doi": "https://doi.org/10.1145/2842612",
    "publication_date": "2016-05-16",
    "publication_year": 2016,
    "authors": "Xiaoqing Xu; Bei Yu; Jhih-Rong Gao; Che-Lun Hsu; David Z. Pan",
    "corresponding_authors": "",
    "abstract": "Pin access has become one of the most difficult challenges for detailed routing in advanced technology nodes, for example, in 14nm and below, for which double-patterning lithography has to be used for manufacturing lower metal routing layers with tight pitches, such as M2 and M3. Self-aligned double patterning (SADP) provides better control on line edge roughness and overlay, but it has very restrictive design constraints and prefers regular layout patterns. This article presents a comprehensive pin-access planning and regular routing framework (PARR) for SADP friendliness. Our key techniques include precomputation of both intracell and intercell pin accessibility, as well as local and global pin-access planning to enable handshaking between standard cell-level pin access and detailed routing under SADP constraints. A pin access–driven rip-up and reroute scheme is proposed to improve the ultimate routability. Our experimental results demonstrate that PARR can achieve much better routability and overlay control compared with previous approaches.",
    "cited_by_count": 26,
    "openalex_id": "https://openalex.org/W2406038381",
    "type": "article"
  },
  {
    "title": "Distributed Machine Learning on Smart-Gateway Network toward Real-Time Smart-Grid Energy Management with Behavior Cognition",
    "doi": "https://doi.org/10.1145/3209888",
    "publication_date": "2018-09-30",
    "publication_year": 2018,
    "authors": "Hantao Huang; Hang Xu; Yuehua Cai; Rai Suleman Khalid; Hao Yu",
    "corresponding_authors": "",
    "abstract": "Real-time data analytics for smart-grid energy management is challenging with consideration of both occupant behavior profiles and energy profiles. This article proposes a distributed and networked machine-learning platform on smart-gateway-based smart-grid in residential buildings. It can analyze occupant behaviors, provide short-term load forecasting, and allocate renewable energy resources. First, occupant behavior profile is captured by real-time indoor positioning system with WiFi data analytics; and the energy profile is extracted by real-time meter system with electricity load data analytics. Then, the 24-hour occupant behavior profile and energy profile are fused with prediction using an online distributed machine-learning algorithm with real-time data update. Based on the forecasted occupant behavior profile and energy profile, solar energy source is allocated to reduce peak demand on the main electricity power-grid. The whole management flow can be operated on the distributed smart-gateway network with limited computational resources but with a supported general machine-learning engine. Experimental results on occupant behavior extraction show that the proposed algorithm can achieve 91.2% positioning accuracy within 3.64m. Moreover, 50× and 38× speed-up is obtained during data testing and training, respectively, when compared to traditional support vector machine (SVM) method. For short-term load forecasting, it is 14.83% more accurate when compared to SVM-based data analytics. Based on the predicted occupant behavior profile and energy profile, our proposed energy management system can achieve 19.66% more peak load reduction and 26.41% more cost saving as compared to the SVM-based method.",
    "cited_by_count": 26,
    "openalex_id": "https://openalex.org/W2897117324",
    "type": "article"
  },
  {
    "title": "An Elastic Mixed-Criticality Task Model and Early-Release EDF Scheduling Algorithms",
    "doi": "https://doi.org/10.1145/2984633",
    "publication_date": "2016-12-28",
    "publication_year": 2016,
    "authors": "Hang Su; Dakai Zhu; Scott Brandt",
    "corresponding_authors": "",
    "abstract": "Many algorithms have recently been studied for scheduling mixed-criticality (MC) tasks. However, most existing MC scheduling algorithms guarantee the timely executions of high-criticality (HC) tasks at the expense of discarding low-criticality (LC) tasks, which can cause serious service interruption for such tasks. In this work, aiming at providing guaranteed services for LC tasks, we study an elastic mixed-criticality (E-MC) task model for dual-criticality systems. Specifically, the model allows each LC task to specify its maximum period (i.e., minimum service level) and a set of early-release points. We propose an early-release (ER) mechanism that enables LC tasks to be released more frequently and thus improve their service levels at runtime, with both conservative and aggressive approaches to exploiting system slack being considered, which is applied to both earliest deadline first (EDF) and preference-oriented earliest-deadline schedulers. We formally prove the correctness of the proposed early-release--earliest deadline first scheduler on guaranteeing the timeliness of all tasks through judicious management of the early releases of LC tasks. The proposed model and schedulers are evaluated through extensive simulations. The results show that by moderately relaxing the service requirements of LC tasks in MC task sets (i.e., by having LC tasks’ maximum periods in the E-MC model be two to three times their desired MC periods), most transformed E-MC task sets can be successfully scheduled without sacrificing the timeliness of HC tasks. Moreover, with the proposed ER mechanism, the runtime performance of tasks (e.g., execution frequencies of LC tasks, response times, and jitters of HC tasks) can be significantly improved under the ER schedulers when compared to that of the state-of-the-art earliest deadline first—virtual deadline scheduler.",
    "cited_by_count": 25,
    "openalex_id": "https://openalex.org/W2562803701",
    "type": "article"
  },
  {
    "title": "Modular Neural Networks for Low-Power Image Classification on Embedded Devices",
    "doi": "https://doi.org/10.1145/3408062",
    "publication_date": "2020-10-15",
    "publication_year": 2020,
    "authors": "Abhinav Goel; Sara Aghajanzadeh; Caleb Tung; Shuo-Han Chen; George K. Thiruvathukal; Yung-Hsiang Lu",
    "corresponding_authors": "",
    "abstract": "Embedded devices are generally small, battery-powered computers with limited hardware resources. It is difficult to run deep neural networks (DNNs) on these devices, because DNNs perform millions of operations and consume significant amounts of energy. Prior research has shown that a considerable number of a DNN’s memory accesses and computation are redundant when performing tasks like image classification. To reduce this redundancy and thereby reduce the energy consumption of DNNs, we introduce the Modular Neural Network Tree architecture. Instead of using one large DNN for the classifier, this architecture uses multiple smaller DNNs (called modules ) to progressively classify images into groups of categories based on a novel visual similarity metric. Once a group of categories is selected by a module, another module then continues to distinguish among the similar categories within the selected group. This process is repeated over multiple modules until we are left with a single category. The computation needed to distinguish dissimilar groups is avoided, thus reducing redundant operations, memory accesses, and energy. Experimental results using several image datasets reveal the effectiveness of our proposed solution to reduce memory requirements by 50% to 99%, inference time by 55% to 95%, energy consumption by 52% to 94%, and the number of operations by 15% to 99% when compared with existing DNN architectures, running on two different embedded systems: Raspberry Pi 3 and Raspberry Pi Zero.",
    "cited_by_count": 24,
    "openalex_id": "https://openalex.org/W3093796538",
    "type": "article"
  },
  {
    "title": "Adversarial Perturbation Attacks on ML-based CAD",
    "doi": "https://doi.org/10.1145/3408288",
    "publication_date": "2020-08-21",
    "publication_year": 2020,
    "authors": "Kang Liu; Haoyu Yang; Yuzhe Ma; Benjamin Tan; Bei Yu; Evangeline F. Y. Young; Ramesh Karri; Siddharth Garg",
    "corresponding_authors": "",
    "abstract": "There is substantial interest in the use of machine learning (ML)-based techniques throughout the electronic computer-aided design (CAD) flow, particularly those based on deep learning. However, while deep learning methods have surpassed state-of-the-art performance in several applications, they have exhibited intrinsic susceptibility to adversarial perturbations—small but deliberate alterations to the input of a neural network, precipitating incorrect predictions. In this article, we seek to investigate whether adversarial perturbations pose risks to ML-based CAD tools, and if so, how these risks can be mitigated. To this end, we use a motivating case study of lithographic hotspot detection, for which convolutional neural networks (CNN) have shown great promise. In this context, we show the first adversarial perturbation attacks on state-of-the-art CNN-based hotspot detectors; specifically, we show that small (on average 0.5% modified area), functionality preserving, and design-constraint-satisfying changes to a layout can nonetheless trick a CNN-based hotspot detector into predicting the modified layout as hotspot free (with up to 99.7% success in finding perturbations that flip a detector’s output prediction, based on a given set of attack constraints). We propose an adversarial retraining strategy to improve the robustness of CNN-based hotspot detection and show that this strategy significantly improves robustness (by a factor of ~3) against adversarial attacks without compromising classification accuracy.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W4288079630",
    "type": "article"
  },
  {
    "title": "MaxSense",
    "doi": "https://doi.org/10.1145/3436820",
    "publication_date": "2021-01-06",
    "publication_year": 2021,
    "authors": "Yangdi Lyu; Prabhat Mishra",
    "corresponding_authors": "",
    "abstract": "Detection of hardware Trojans is vital to ensure the security and trustworthiness of System-on-Chip (SoC) designs. Side-channel analysis is effective for Trojan detection by analyzing various side-channel signatures such as power, current, and delay. In this article, we propose an efficient test generation technique to facilitate side-channel analysis utilizing dynamic current. While early work on current-aware test generation has proposed several promising ideas, there are two major challenges in applying it on large designs: (i) The test generation time grows exponentially with the design complexity, and (ii) it is infeasible to detect Trojans, since the side-channel sensitivity is marginal compared to the noise and process variations. Our proposed work addresses both challenges by effectively exploiting the affinity between the inputs and rare (suspicious) nodes. The basic idea is to quickly find the profitable ordered pairs of test vectors that can maximize side-channel sensitivity. This article makes two important contributions: (i) It proposed an efficient test generation algorithm that can produce the first patterns in the test vectors to maximize activation of suspicious nodes using an SMT solver, and (ii) it developed a genetic-algorithm based test generation technique to produce the second patterns in the test vectors to maximize the switching in the suspicious regions while minimizing the switching in the rest of the design. Our experimental results demonstrate that we can drastically improve both the side-channel sensitivity (62× on average) and time complexity (13× on average) compared to the state-of-the-art test generation techniques.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W3119752259",
    "type": "article"
  },
  {
    "title": "A Comprehensive Survey of Attacks without Physical Access Targeting Hardware Vulnerabilities in IoT/IIoT Devices, and Their Detection Mechanisms",
    "doi": "https://doi.org/10.1145/3471936",
    "publication_date": "2021-09-13",
    "publication_year": 2021,
    "authors": "Nikolaos-Foivos Polychronou; Pierre-Henri Thevenon; Maxime Puys; Vincent Beroulle",
    "corresponding_authors": "",
    "abstract": "With the advances in the field of the Internet of Things (IoT) and Industrial IoT (IIoT), these devices are increasingly used in daily life or industry. To reduce costs related to the time required to develop these devices, security features are usually not considered. This situation creates a major security concern. Many solutions have been proposed to protect IoT/IIoT against various attacks, most of which are based on attacks involving physical access. However, a new class of attacks has emerged targeting hardware vulnerabilities in the micro-architecture that do not require physical access. We present attacks based on micro-architectural hardware vulnerabilities and the side effects they produce in the system. In addition, we present security mechanisms that can be implemented to address some of these attacks. Most of the security mechanisms target a small set of attack vectors or a single specific attack vector. As many attack vectors exist, solutions must be found to protect against a wide variety of threats. This survey aims to inform designers about the side effects related to attacks and detection mechanisms that have been described in the literature. For this purpose, we present two tables listing and classifying the side effects and detection mechanisms based on the given criteria.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W3200015092",
    "type": "article"
  },
  {
    "title": "EF-Train: Enable Efficient On-device CNN Training on FPGA through Data Reshaping for Online Adaptation or Personalization",
    "doi": "https://doi.org/10.1145/3505633",
    "publication_date": "2022-02-24",
    "publication_year": 2022,
    "authors": "Yue Tang; Xinyi Zhang; Peipei Zhou; Jingtong Hu",
    "corresponding_authors": "",
    "abstract": "Conventionally, DNN models are trained once in the cloud and deployed in edge devices such as cars, robots, or unmanned aerial vehicles (UAVs) for real-time inference. However, there are many cases that require the models to adapt to new environments, domains, or users. In order to realize such domain adaption or personalization, the models on devices need to be continuously trained on the device. In this work, we design EF-Train, an efficient DNN training accelerator with a unified channel-level parallelism-based convolution kernel that can achieve end-to-end training on resource-limited low-power edge-level FPGAs. It is challenging to implement on-device training on resource-limited FPGAs due to the low efficiency caused by different memory access patterns among forward and backward propagation and weight update. Therefore, we developed a data reshaping approach with intra-tile continuous memory allocation and weight reuse. An analytical model is established to automatically schedule computation and memory resources to achieve high energy efficiency on edge FPGAs. The experimental results show that our design achieves 46.99 GFLOPS and 6.09 GFLOPS/W in terms of throughput and energy efficiency, respectively.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W4213446428",
    "type": "article"
  },
  {
    "title": "Sherlock: A Multi-Objective Design Space Exploration Framework",
    "doi": "https://doi.org/10.1145/3511472",
    "publication_date": "2022-02-09",
    "publication_year": 2022,
    "authors": "Q Gautier; Alric Althoff; Christopher Crutchfield; Ryan Kastner",
    "corresponding_authors": "",
    "abstract": "Design space exploration (DSE) provides intelligent methods to tune the large number of optimization parameters present in modern FPGA high-level synthesis tools. High-level synthesis parameter tuning is a time-consuming process due to lengthy hardware compilation times—synthesizing an FPGA design can take tens of hours. DSE helps find an optimal solution faster than brute-force methods without relying on designer intuition to achieve high-quality results. Sherlock is a DSE framework that can handle multiple conflicting optimization objectives and aggressively focuses on finding Pareto-optimal solutions. Sherlock integrates a model selection process to choose the regression model that helps reach the optimal solution faster. Sherlock designs a strategy based around the multi-armed bandit problem, opting to balance exploration and exploitation based on the learned and expected results. Sherlock can decrease the importance of models that do not provide correct estimates, reaching the optimal design faster. Sherlock is capable of tailoring its choice of regression models to the problem at hand, leading to a model that best reflects the application design space. We have tested the framework on a large dataset of FPGA design problems and found that Sherlock converges toward the set of optimal designs faster than similar frameworks.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W4210948071",
    "type": "article"
  },
  {
    "title": "Learning from the Past: Efficient High-level Synthesis Design Space Exploration for FPGAs",
    "doi": "https://doi.org/10.1145/3495531",
    "publication_date": "2022-02-12",
    "publication_year": 2022,
    "authors": "Zi Wang; Benjamin Carrión Schäfer",
    "corresponding_authors": "",
    "abstract": "The quest to democratize the use of Field-Programmable Gate Arrays (FPGAs) has given High-Level Synthesis (HLS) the final push to be widely accepted with FPGA vendors strongly supporting this VLSI design methodology to expand the FPGA user base. HLS takes as input an untimed behavioral description and generates efficient RTL (Verilog or VHDL). One major advantage of HLS is that it allows us to generate a variety of different micro-architectures from the same behavioral description by simply specifying different combination of synthesis options. In particular, commercial HLS tools make extensive use of synthesize directives in the form pragmas. This strength is also a weakness as it forces HLS users to fully understand how these synthesis options work and how they interact to efficiently set them to get a hardware implementation with the desired characteristics. Luckily, this process can be automated. Unfortunately, the search space grows supra-linearly with the number of synthesis options. To address this, this work proposes an automatic synthesis option tuner dedicated for FPGAs. We have explored a larger number of behavioral descriptions targeting ASICs and FPGAs and found out that due to the internal structure of the FPGA a large number of synthesis options combinations never lead to a Pareto-optimal design and, hence, the search space can be drastically reduced. Moreover, we make use of large database of DSE results that we have generated since we started working in this field to further accelerate the exploration process. For this, we use a technique based on perceptual hashing that allows our proposed explorer to recognize similar program structures in the new description to be explored and match them with structures in our database. This allows us to directly retrieve the pragma settings that lead to Pareto-optimal configurations. Experimental results show that the search space can be accelerated substantially while leading to finding most of the Pareto-optimal designs.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W4211236386",
    "type": "article"
  },
  {
    "title": "Security of Electrical, Optical, and Wireless On-chip Interconnects: A Survey",
    "doi": "https://doi.org/10.1145/3631117",
    "publication_date": "2023-10-30",
    "publication_year": 2023,
    "authors": "Hansika Weerasena; Prabhat Mishra",
    "corresponding_authors": "",
    "abstract": "The advancement of manufacturing technologies has enabled the integration of more intellectual property (IP) cores on the same system-on-chip (SoC). Scalable and high throughput on-chip communication architecture has become a vital component in today’s SoCs. Diverse technologies such as electrical, wireless, optical, and hybrid are available for on-chip communication with different architectures supporting them. On-chip communication sub-system is shared across all the IPs and continuously used throughout the lifetime of the SoC. Therefore, the security of the on-chip communication is crucial, because exploiting any vulnerability would be a goldmine for an attacker. In this survey, we provide a comprehensive review of threat models, attacks, and countermeasures over diverse on-chip communication technologies as well as sophisticated architectures.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W4388016616",
    "type": "article"
  },
  {
    "title": "A Mixed-Criticality Traffic Scheduler with Mitigating Congestion for CAN-to-TSN Gateway",
    "doi": "https://doi.org/10.1145/3656173",
    "publication_date": "2024-04-04",
    "publication_year": 2024,
    "authors": "Wenyan Yan; Dongsheng Wei; Bin Fu; Renfa Li; Guoqi Xie",
    "corresponding_authors": "",
    "abstract": "The network architecture that Time-Sensitive Networking (TSN) is used as the backbone network and the Controller Area Network (CAN) serves as the intra-domain network is considered as the CAN-TSN interconnection network architecture, which has gained considerable attention within industrial embedded networks, such as spacecraft, intelligent automobiles, and factory automation. The architecture employs the CAN-TSN gateway as a central hub for transmitting and managing a significant volume of communications between the CAN domains and TSN. However, the CAN-TSN gateway faces a high congestion challenge due to the rapid growth in data volume, making it difficult to effectively support different time planning mechanisms provided by TSN. In this article, we propose a two-stage mixed-criticality traffic scheduler. The scheduler in the first stage adopts a Message Optimization Algorithm (MOA) to aggregate multiple CAN messages into a single TSN message (including the aggregation of critical and non-critical CAN messages), which reduces the number of CAN messages requiring transmission. In the second stage, the scheduler proposes a Message Scheduling Optimization Algorithm (MSOA) to schedule critical TSN messages. This algorithm reassembles all the critical CAN messages (within the un-schedulable TSN messages) to generate new TSN messages for rescheduling. Experimental results show that our proposed scheduler effectively improves the acceptance ratio of critical and non-critical CAN messages and outperforms the state-of-the-art message scheduling method in terms of acceptance ratio while improving the bandwidth utilization and the number of schedule table entries. We further construct a hardware platform to evaluate the performance of MSOA. The consistency between practical results and theoretical results shows the effectiveness of MSOA.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4393934422",
    "type": "article"
  },
  {
    "title": "A text-compression-based method for code size minimization in embedded systems",
    "doi": "https://doi.org/10.1145/298865.298867",
    "publication_date": "1999-01-01",
    "publication_year": 1999,
    "authors": "Stan Liao; Srinivas Devadas; Kurt Keutzer",
    "corresponding_authors": "",
    "abstract": "We address the problem of code-size minimization in VLSI systems with embedded DSP processors. Reducing code size reduces the production cost of embedded systems we use data-compression methods to develop code-size minimization strategies. In our framework, the compressed program consists of a skeleton and a dictionary. We show that the dictionary can be computed by solving a set-covering problem derived from the original program. To execute the compressed code, we describe two methods that have different performance characteristics and different degrees of freedom in compressing the code. We also address performance considerations, and show that they can be incorporated easily into the set-covering formulation, and present experimental results obtained with Texas Instruments' optimizing TMS3220C25 compiler.",
    "cited_by_count": 51,
    "openalex_id": "https://openalex.org/W2090413701",
    "type": "article"
  },
  {
    "title": "Test vector decomposition-based static compaction algorithms for combinational circuits",
    "doi": "https://doi.org/10.1145/944027.944030",
    "publication_date": "2003-10-01",
    "publication_year": 2003,
    "authors": "Aiman H. El‐Maleh; Yahya Osais",
    "corresponding_authors": "",
    "abstract": "Testing system-on-chips involves applying huge amounts of test data, which is stored in the tester memory and then transferred to the chip under test during test application. Therefore, practical techniques, such as test compression and compaction, are required to reduce the amount of test data in order to reduce both the total testing time and memory requirements for the tester. In this article, a new approach to static compaction for combinational circuits, referred to as test vector decomposition (TVD) , is proposed. In addition, two new TVD based static compaction algorithms are presented. Experimental results for benchmark circuits demonstrate the effectiveness of the two new static compaction algorithms.",
    "cited_by_count": 47,
    "openalex_id": "https://openalex.org/W2089875208",
    "type": "article"
  },
  {
    "title": "Timing-driven routing for symmetrical array-based FPGAs",
    "doi": "https://doi.org/10.1145/348019.348101",
    "publication_date": "2000-07-01",
    "publication_year": 2000,
    "authors": "Yao‐Wen Chang; Kai Zhu; Martin D. F. Wong",
    "corresponding_authors": "",
    "abstract": "In this paper we present a timing-driven router for symmetrical array-based FPGAs. The routing resources in the FPGAs consist of segments of various lengths. Researchers have shown that the number of segments, instead of wirelength, used by a net is the most critical factor in controlling routing delay in an FPGA. Thus, the traditional measure of routing delay on the basis of geometric distance of a signal is not accurate. To consider wirelength and delay simultaneously, we study a model of timing-driven routing rees, arising from the special properties of FPGA routing architectures. Based on the solutions to the routing-tree problem, we present a routing algorithm that is able to utilize various routing segments with global considerations to meet timing constraints. Experimental results show that our approach is very effective in reducing timing violations.",
    "cited_by_count": 46,
    "openalex_id": "https://openalex.org/W1983950263",
    "type": "article"
  },
  {
    "title": "A recursive technique for computing lower-bound performance of schedules",
    "doi": "https://doi.org/10.1145/238997.239002",
    "publication_date": "1996-10-01",
    "publication_year": 1996,
    "authors": "M. Langevin; E. Cerny",
    "corresponding_authors": "",
    "abstract": "We present a fast recursive technique for estimating lower-bound performance of data path schedules. The method relies on the determination of an ASAPUC a(s Soon As Possible Under Constraint) time-step value for each node of the DFG (Data-Flow Graph) that is based on the ASAPUC values of its predecessor nodes. That is, the lower-bound estimation is applied to each subgraph permitting the derivation of a tight lower bound on the performance of the complete DFG. Applying the greedy lower-bound estimator of Rim and Jain [1994] to each subgraph improves the complete lower bound in more than 50% of the experiments reported in Rim and Jain [1994], and the CPU time is only about twice as long. The recursive methodology can be extended to exploit other lower-bound techniques, for example, considering other constraints such as the number of busses or registers.",
    "cited_by_count": 46,
    "openalex_id": "https://openalex.org/W2053505858",
    "type": "article"
  },
  {
    "title": "High-level modeling and simulation of single-chip programmable heterogeneous multiprocessors",
    "doi": "https://doi.org/10.1145/1080334.1080335",
    "publication_date": "2005-07-01",
    "publication_year": 2005,
    "authors": "JoAnn M. Paul; Donald E. Thomas; Andrew Cassidy",
    "corresponding_authors": "",
    "abstract": "Heterogeneous multiprocessing is the future of chip design with the potential for tens to hundreds of programmable elements on single chips within the next several years. These chips will have heterogeneous, programmable hardware elements that lead to different execution times for the same software executing on different resources as well as a mix of desktop-style and embedded-style software. They will also have a layer of programming across multiple programmable elements forming the basis of a new kind of programmable system which we refer to as a Programmable Heterogeneous Multiprocessor (PHM). Current modeling approaches use instruction set simulation for performance modeling, but this will become far too prohibitive in terms of simulation time for these larger designs. The fundamental question is what the next higher level of design will be. The high-level modeling, simulation and design required for these programmable systems poses unique challenges, representing a break from traditional hardware design. Programmable systems, including layered concurrent software executing via schedulers on concurrent hardware, are not characterizable with traditional component-based hierarchical composition approaches, including discrete event simulation. We describe the foundations of our layered approach to modeling and performance simulation of PHMs, showing an example design space of a network processor explored using our simulation approach.",
    "cited_by_count": 43,
    "openalex_id": "https://openalex.org/W2113311900",
    "type": "article"
  },
  {
    "title": "Word-length optimization for differentiable nonlinear systems",
    "doi": "https://doi.org/10.1145/1124713.1124716",
    "publication_date": "2006-01-01",
    "publication_year": 2006,
    "authors": "George A. Constantinides",
    "corresponding_authors": "George A. Constantinides",
    "abstract": "This article introduces an automatic design procedure for determining the sensitivity of outputs in a digital signal processing design to small errors introduced by rounding or truncation of internal variables. The proposed approach can be applied to both linear and nonlinear designs. By analyzing the resulting sensitivity values, the proposed procedure is able to determine an appropriate distinct word-length for each internal variable in a fixed-point hardware implementation. In addition, the power-optimizing capabilities of word-length optimization are studied. Application of the proposed procedure to adaptive filters and polynomial evaluation circuits realized in a Xilinx Virtex FPGA has resulted in area reductions of up to 80% (mean 66%) combined with power reductions of up to 98% (mean 87%) and speed-up of up to 36%(mean 20%) over common alternative design strategies.",
    "cited_by_count": 40,
    "openalex_id": "https://openalex.org/W2078782167",
    "type": "article"
  },
  {
    "title": "Systematic dynamic memory management design methodology for reduced memory footprint",
    "doi": "https://doi.org/10.1145/1142155.1142165",
    "publication_date": "2006-04-01",
    "publication_year": 2006,
    "authors": "David Atienza; J.M. Mendı́as; Stylianos Mamagkakis; Dimitrios Soudris; Francky Catthoor",
    "corresponding_authors": "",
    "abstract": "New portable consumer embedded devices must execute multimedia and wireless network applications that demand extensive memory footprint. Moreover, they must heavily rely on Dynamic Memory (DM) due to the unpredictability of the input data (e.g., 3D streams features) and system behavior (e.g., number of applications running concurrently defined by the user). Within this context, consistent design methodologies that can tackle efficiently the complex DM behavior of these multimedia and network applications are in great need. In this article, we present a new methodology that allows to design custom DM management mechanisms with a reduced memory footprint for such kind of dynamic applications. First, our methodology describes the large design space of DM management decisions for multimedia and wireless network applications. Then, we propose a suitable way to traverse the aforementioned design space and construct custom DM managers that minimize the DM used by these highly dynamic applications. As a result, our methodology achieves improvements of memory footprint by 60% on average in real case studies over the current state-of-the-art DM managers used for these types of dynamic applications.",
    "cited_by_count": 39,
    "openalex_id": "https://openalex.org/W2112457107",
    "type": "article"
  },
  {
    "title": "ReChannel",
    "doi": "https://doi.org/10.1145/1297666.1297681",
    "publication_date": "2008-01-01",
    "publication_year": 2008,
    "authors": "Andreas Raabe; Philipp A. Hartmann; Joachim K. Anlauf",
    "corresponding_authors": "",
    "abstract": "With the ongoing integration of (dynamic) reconfiguration into current system models, new methodologies and tools are needed to help the designer during the development process. This article introduces a language extension for SystemC along with a design methodology for describing and simulating dynamically reconfigurable systems at all levels of abstraction. The presented library provides maximum freedom of description of reconfiguration behavior and its control, while featuring simulation of runtime configuration, removal, and exchange of custom modules as well as third-party IP-cores during the complete architecture refinement process. When designing at RT-level, the resulting hardware description can easily be synthesized by standard synthesis tools.",
    "cited_by_count": 35,
    "openalex_id": "https://openalex.org/W1980377171",
    "type": "article"
  },
  {
    "title": "Transition-overhead-aware voltage scheduling for fixed-priority real-time systems",
    "doi": "https://doi.org/10.1145/1230800.1230803",
    "publication_date": "2007-04-01",
    "publication_year": 2007,
    "authors": "Bren Mochocki; Xiaobo Sharon Hu; Gang Quan",
    "corresponding_authors": "",
    "abstract": "Time transition overhead is a critical problem for hard real-time systems that employ dynamic voltage scaling (DVS) for power and energy management. While it is a common practice of much previous work to ignore transition overhead, these algorithms cannot guarantee deadlines and/or are less effective in saving energy when transition overhead is significant and not appropriately dealt with. In this article we introduce two techniques, one offline and one online, to correctly account for transition overhead in preemptive fixed-priority real-time systems. We present several DVS scheduling algorithms that implement these methods that can guarantee task deadlines under arbitrarily large transition time overheads and reduce energy consumption by as much as 40% when compared to previous methods.",
    "cited_by_count": 35,
    "openalex_id": "https://openalex.org/W1997682930",
    "type": "article"
  },
  {
    "title": "Analysis and optimization of prediction-based flow control in networks-on-chip",
    "doi": "https://doi.org/10.1145/1297666.1297677",
    "publication_date": "2008-01-01",
    "publication_year": 2008,
    "authors": "Ümit Y. Ogras; Radu Mărculescu",
    "corresponding_authors": "",
    "abstract": "Networks-on-Chip (NoC) communication architectures have emerged recently as a scalable solution to on-chip communication problems. While the NoC architectures may offer higher bandwidth compared to traditional bus-based communication, their performance can degrade significantly in the absence of effective flow control algorithms. Unfortunately, flow control algorithms developed for macronetworks, either rely on local information, or suffer from large communication overhead and unpredictable delays. Hence, using them in the NoC context is problematic at best. For this reason, we propose a predictive closed-loop flow control mechanism and make the following contributions: First, we develop traffic source and router models specifically targeted to NoCs. Then, we utilize these models to predict the possible congestion in the network. Based on this information, the proposed scheme controls the packet injection rate at traffic sources in order to regulate the total number of packets in the network. We also illustrate the proposed traffic source model and the applicability of the proposed flow controller to actual designs using real NoC implementations. Finally, simulations and experimental study using our FPGA prototype show that the proposed controller delivers a better performance compared to the traditional switch-to-switch flow control algorithms under various real and synthetic traffic patterns.",
    "cited_by_count": 32,
    "openalex_id": "https://openalex.org/W2032770447",
    "type": "article"
  },
  {
    "title": "Fast and accurate processor models for efficient MPSoC design",
    "doi": "https://doi.org/10.1145/1698759.1698760",
    "publication_date": "2010-02-01",
    "publication_year": 2010,
    "authors": "Gunar Schirner; Andreas Gerstlauer; Rainer Dömer",
    "corresponding_authors": "",
    "abstract": "With growing system complexity and ever-increasing software content, the development of embedded software for upcoming MPSoC architectures is a tremendous challenge. Traditional ISS-based validation becomes infeasible due to the large complexity. Addressing the need for flexible and fast simulating models, we introduce in this article our approach of abstract processor modeling in the context of multiprocessor architectures. We combine modeling of computation on processors with an abstract RTOS and accurate interrupt handling into a versatile, multifaceted processor model with several levels of features. Our processor models are utilized in a framework allowing designers to develop a system in a top-down manner using automatic model generation and compilation down to a given MPSoC architecture. During generation, instances of our processor models are integrated into a system model combining software, hardware, and bus communication. The generated system model serves for rapid design space exploration and a fast and accurate system validation. Our experimental results show the benefits of our processor modeling using an actual multiprocessor mobile phone baseband platform. Our abstract models of this complex system reach a simulation speed of 300MCycles/s within a high accuracy of less than 3% error. In addition, our results quantify the speed/accuracy trade-off at varying abstraction levels of our models to guide future processor model designers.",
    "cited_by_count": 31,
    "openalex_id": "https://openalex.org/W2014574783",
    "type": "article"
  },
  {
    "title": "Designing secure systems on reconfigurable hardware",
    "doi": "https://doi.org/10.1145/1367045.1367053",
    "publication_date": "2008-07-01",
    "publication_year": 2008,
    "authors": "Ted Huffmire; Brett Brotherton; Nick Callegari; Jonathan Valamehr; Jeff White; Ryan Kastner; Timothy Sherwood",
    "corresponding_authors": "",
    "abstract": "The extremely high cost of custom ASIC fabrication makes FPGAs an attractive alternative for deployment of custom hardware. Embedded systems based on reconfigurable hardware integrate many functions onto a single device. Since embedded designers often have no choice but to use soft IP cores obtained from third parties, the cores operate at different trust levels, resulting in mixed-trust designs. The goal of this project is to evaluate recently proposed security primitives for reconfigurable hardware by building a real embedded system with several cores on a single FPGA and implementing these primitives on the system. Overcoming the practical problems of integrating multiple cores together with security mechanisms will help us to develop realistic security-policy specifications that drive enforcement mechanisms on embedded systems.",
    "cited_by_count": 31,
    "openalex_id": "https://openalex.org/W2120602073",
    "type": "article"
  },
  {
    "title": "NBTI-Aware Clustered Power Gating",
    "doi": "https://doi.org/10.1145/1870109.1870112",
    "publication_date": "2010-11-01",
    "publication_year": 2010,
    "authors": "Andrea Calimera; Enrico Macii; Massimo Poncino",
    "corresponding_authors": "",
    "abstract": "The emergence of Negative Bias Temperature Instability (NBTI) as the most relevant source of reliability in sub-90nm technologies has led to a new facet of the traditional trade-off between power and reliability. NBTI effects in fact manifest themselves as an increase of the propagation delay of the devices over time, which adds up to the delay penalty incurred by most low-power design solutions. This implies that, given a desired lifetime of a circuit (i.e., a given performance target at some point in time), a power-managed component will fail earlier than a nonpower-managed one. In this work, we show how it is possible to partially overcome this conflict, by leveraging the benefits in terms of aging provided by power-gating (i.e., by using switches that disconnect a logic block from the ground). Thanks to some electrical properties, it is possible to nullify aging effects during standby periods. Based on this important property, we propose a methodology for a NBTI-aware power gating that allows synthesizing low-leakage circuits with maximum lifetime.",
    "cited_by_count": 30,
    "openalex_id": "https://openalex.org/W2032286916",
    "type": "article"
  },
  {
    "title": "Instrumenting AMS assertion verification on commercial platforms",
    "doi": "https://doi.org/10.1145/1497561.1497564",
    "publication_date": "2009-03-01",
    "publication_year": 2009,
    "authors": "Rajdeep Mukhopadhyay; S.K. Panda; Pallab Dasgupta; John Gough",
    "corresponding_authors": "",
    "abstract": "The industry trend appears to be moving towards designs that integrate large digital circuits with multiple analog/RF (radio frequency) interfaces. In the verification of these large integrated circuits, the number of nets that need to be monitored has been growing rapidly. Consequently, the mixed-signal design community has been feeling the need for AMS (Analog and Mixed Signal) assertions that can automatically monitor conformance with expected time-domain behavior and help in debugging deviations from the design intent. The main challenges in providing this support are (a) developing AMS assertion languages or AMS verification libraries, and (b) instrumenting existing commercial simulators to support assertion verification during simulation. In this article, we report two approaches: the first extends the Open Verification Library (OVL) to the AMS domain by integrating a new collection of AMS verification libraries; while the second extends SystemVerilog Assertions (SVA) by augmenting analog predicates into SVA. We demonstrate the use of AMS-OVL on the Cadence Virtuoso environment while emphasizing that our libraries can work in any environment that supports Verilog and Verilog-A. We also report the development of tool support for AMS-SVA using a combination of Cadence NCSIM and Synopsys VCS. We demonstrate the utility of both approaches on the verification of LP3918, an integrated power management unit (PMU) from National Semiconductors. We believe that in the absence of existing EDA (Electronic Design Automation) tools for AMS assertion verification, the proposed approaches of integrating our libraries and our tool sets with existing commercial simulators will be of considerable and immediate practical value.",
    "cited_by_count": 29,
    "openalex_id": "https://openalex.org/W2051874670",
    "type": "article"
  },
  {
    "title": "Static NBTI Reduction Using Internal Node Control",
    "doi": "https://doi.org/10.1145/2348839.2348849",
    "publication_date": "2012-10-01",
    "publication_year": 2012,
    "authors": "David R. Bild; Robert P. Dick; Gregory E. Bok",
    "corresponding_authors": "",
    "abstract": "Negative Bias Temperature Instability (NBTI) is a significant reliability concern for nanoscale CMOS circuits. Its effects on circuit timing can be especially pronounced for circuits with standby-mode equipped functional units, because these units can be subjected to static NBTI stress for extended periods of time. This article describes Internal Node Control (INC), in which the inputs to some individual gates are directly manipulated to prevent this static NBTI fatigue. We prove that the INC selection problem is NP -complete and present a linear-time heuristic that can quickly determine near-optimal placements. This near-optimality is confirmed by comparing results for small benchmarks against optimal solutions from a mixed integer linear programming formulation of our problem. We evaluate the heuristic on the ISCAS85 benchmarks and the Synopsys DesignWare Library. Our heuristic reduces static NBTI-induced delay over a ten year period by 30--60% and can reduce total path delay by an average 9.4% when NBTI degradation is severe. The INC placements and sleep signal routing require only a 1.6% increase in area.",
    "cited_by_count": 26,
    "openalex_id": "https://openalex.org/W2000301874",
    "type": "article"
  },
  {
    "title": "Conditional Diagnosability of Cayley Graphs Generated by Transposition Trees under the PMC Model",
    "doi": "https://doi.org/10.1145/2699854",
    "publication_date": "2015-03-02",
    "publication_year": 2015,
    "authors": "Nai-Wen Chang; Eddie Cheng; Sun‐Yuan Hsieh",
    "corresponding_authors": "",
    "abstract": "Processor fault diagnosis has played an essential role in measuring the reliability of a multiprocessor system. The diagnosability of many well-known multiprocessor systems has been widely investigated. Conditional diagnosability is a novel measure of diagnosability by adding a further condition that any fault set cannot contain all the neighbors of every node in the system. Several known structural properties of Cayley graphs are exhibited. Based on these properties, we investigate the conditional diagnosability of Cayley graphs generated by transposition trees under the PMC model and show that it is 4n-11 for n ≥ 4 except for the n -dimensional star graph for which it has been shown to be 8 n -21 for n ≥ 5 (refer to Chang and Hsieh [2014]).",
    "cited_by_count": 24,
    "openalex_id": "https://openalex.org/W2043960444",
    "type": "article"
  },
  {
    "title": "Built-In Self-Test and Test Scheduling for Interposer-Based 2.5D IC",
    "doi": "https://doi.org/10.1145/2757278",
    "publication_date": "2015-09-28",
    "publication_year": 2015,
    "authors": "Ran Wang; Krishnendu Chakrabarty; Sudipta Bhawmik",
    "corresponding_authors": "",
    "abstract": "Interposer-based 2.5D integrated circuits (ICs) are seen today as a precursor to 3D ICs based on through-silicon vias (TSVs). All the dies and the interposer in a 2.5D IC must be adequately tested for product qualification. We present an efficient built-in self-test (BIST) architecture for targeting defects in dies and in the interposer interconnects. The proposed BIST architecture can also be used for fault diagnosis during interconnect testing. To reduce the overall test cost, we describe a test scheduling and optimization technique under power constraints. We present simulation results to validate the BIST architecture and demonstrate fault detection, synthesis results to evaluate the area overhead of the proposed BIST architecture, and test scheduling results to highlight the effectiveness of the optimization approach.",
    "cited_by_count": 24,
    "openalex_id": "https://openalex.org/W2067111338",
    "type": "article"
  },
  {
    "title": "Lazy-RTGC",
    "doi": "https://doi.org/10.1145/2746236",
    "publication_date": "2015-06-24",
    "publication_year": 2015,
    "authors": "Qi Zhang; Xuandong Li; Linzhang Wang; Tian Zhang; Yi Wang; Zili Shao",
    "corresponding_authors": "",
    "abstract": "Due to many attractive and unique properties, NAND flash memory has been widely adopted in mission-critical hard real-time systems and some soft real-time systems. However, the nondeterministic garbage collection operation in NAND flash memory makes it difficult to predict the system response time of each data request. This article presents Lazy-RTGC , a real-time lazy garbage collection mechanism for NAND flash memory storage systems. Lazy-RTGC adopts two design optimization techniques: on-demand page-level address mappings, and partial garbage collection. On-demand page-level address mappings can achieve high performance of address translation and can effectively manage the flash space with the minimum RAM cost. On the other hand, partial garbage collection can provide the guaranteed system response time. By adopting these techniques, Lazy-RTGC jointly optimizes both the average and the worst system response time, and provides a lower bound of reclaimed free space. Lazy-RTGC is implemented in FlashSim and compared with representative real-time NAND flash memory management schemes. Experimental results show that our technique can significantly improve both the average and worst system performance with very low extra flash-space requirements.",
    "cited_by_count": 24,
    "openalex_id": "https://openalex.org/W2272962182",
    "type": "article"
  },
  {
    "title": "Fundamental Challenges Toward Making the IoT a Reachable Reality",
    "doi": "https://doi.org/10.1145/3001934",
    "publication_date": "2017-04-21",
    "publication_year": 2017,
    "authors": "Yuankun Xue; Ji Li; Shahin Nazarian; Paul Bogdan",
    "corresponding_authors": "",
    "abstract": "Constantly advancing integration capability is paving the way for the construction of the extremely large scale continuum of the Internet where entities or things from vastly varied domains are uniquely addressable and interacting seamlessly to form a giant networked system of systems known as the Internet-of-Things (IoT). In contrast to this visionary networked system paradigm, prior research efforts on the IoT are still very fragmented and confined to disjoint explorations of different applications, architecture, security, services, protocol, and economical domains, thus preventing design exploration and optimization from a unified and global perspective. In this context, this survey article first proposes a mathematical modeling framework that is rich in expressivity to capture IoT characteristics from a global perspective. It also sets forward a set of fundamental challenges in sensing, decentralized computation, robustness, energy efficiency, and hardware security based on the proposed modeling framework. Possible solutions are discussed to shed light on future development of the IoT system paradigm.",
    "cited_by_count": 24,
    "openalex_id": "https://openalex.org/W2606469231",
    "type": "article"
  },
  {
    "title": "VSSD",
    "doi": "https://doi.org/10.1145/2755560",
    "publication_date": "2015-09-28",
    "publication_year": 2015,
    "authors": "Da‐Wei Chang; Hsin-Hung Chen; Wei-Jian Su",
    "corresponding_authors": "",
    "abstract": "Performance isolation is critical in shared storage systems, a popular storage solution. In a shared storage system, interference between requests from different users can affect the accuracy of I/O cost accounting, resulting in poor performance isolation. Recently, NAND flash-memory-based solid-state drives (SSDs) have been increasingly used in shared storage systems. However, interference in SSD-based shared storage systems has not been addressed. In this article, two types of interference, namely, queuing delay (QD) interference and garbage collection (GC) interference, are identified in a shared SSD. Additionally, a framework called VSSD is proposed to address these types of interference. VSSD is composed of two components: the FACO credit-based I/O scheduler designed to address QD interference and the ViSA flash translation layer designed to address GC interference. The VSSD framework aims to be implemented in the firmware running on an SSD controller. With VSSD, interference in an SSD can be eliminated and performance isolation can be ensured. Both synthetic and application workloads are used to evaluate the effectiveness of the proposed VSSD framework. The performance results show the following. First, QD and GC interference exists and can result in poor performance isolation between users on SSD-based shared storage systems. Second, VSSD is effective in eliminating the interference and achieving performance isolation between users. Third, the overhead of VSSD is insignificant.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W2017896829",
    "type": "article"
  },
  {
    "title": "Avoiding Data Inconsistency in Energy Harvesting Powered Embedded Systems",
    "doi": "https://doi.org/10.1145/3182170",
    "publication_date": "2018-03-16",
    "publication_year": 2018,
    "authors": "Mimi Xie; Pan Chen; Mengying Zhao; Yongpan Liu; Chun Jason Xue; Jingtong Hu",
    "corresponding_authors": "",
    "abstract": "Energy harvesting is becoming a favorable alternative to power future generation embedded systems, as it is more environmentally and user friendly. However, energy harvesting powered embedded systems suffer from frequent execution interruption due to unstable energy supply. To tackle this problem, nonvolatile memory has been deployed to save the whole volatile state for computation. When power resumes, the processor can restore the state back to volatile memories and continue execution. However, without careful consideration, the process of checkpointing and resuming could cause inconsistency between volatile and nonvolatile memories, which leads to irreversible errors. In this article, we propose a consistency-aware adaptive checkpointing scheme that ensures correctness for all checkpoints. The proposed technique efficiently identifies all possible inconsistency positions in programs and inserts auxiliary code to ensure correctness by offline analysis. In addition, adaptive checkpointing assisted register file profiling and online tracking techniques further reduce the overhead of each checkpoint. Evaluation results show that the proposed checkpointing strategy can successfully eliminate inconsistency errors and greatly reduce the checkpointing overhead.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W2792363899",
    "type": "article"
  },
  {
    "title": "Flexible Droplet Routing in Active Matrix–Based Digital Microfluidic Biochips",
    "doi": "https://doi.org/10.1145/3184388",
    "publication_date": "2018-03-16",
    "publication_year": 2018,
    "authors": "Guan-Ruei Lu; Chun-Hao Kuo; Kuen-Cheng Chiang; Ansuman Banerjee; Bhargab B. Bhattacharya; Tsung-Yi Ho; Hung-Ming Chen",
    "corresponding_authors": "",
    "abstract": "The active matrix (AM)-based architecture offers many advantages over conventional digital electrowetting-on-dielectric (EWOD) microfluidic biochips, such as the capability of handling variable-size droplets, more flexible droplet movement, and precise control over droplet navigation. However, a major challenge in choosing the routing paths is to decide when the droplets are to be reshaped depending on the congestion of the intended path, or split- and route sub droplets,and merging them at their respective destinations. As the number of microelectrodes in AM-EWOD chips is large, the path selection problem becomes further complicated. In this article, we propose a negotiation-guided flow based on routing of subdroplets that obviates the explicit need for deciding when the droplets are to be manipulated, yet fully utilizing the power of droplet reshaping, splitting, and merging them to facilitate their journey. The proposed algorithm reduces routing cost and provides more freedom in deadlock avoidance in the presence of multiple routing tasks by assigning certain congestion penalty for sibling subdroplets and fluidic penalty for heterogeneous droplets. Compared to existing techniques, it reduces latest arrival time by an average of 29% for several benchmark and random test suites. Furthermore, our method is observed to provide 100% routability of nets for all test cases, whereas existing and baseline routers fail to produce feasible solutions in many instances. We also propose a reliable mode droplet routing strategy where the number of unreliable splitting operations can be reduced by paying a small penalty on latest arrival time.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W2793343517",
    "type": "article"
  },
  {
    "title": "Editorial",
    "doi": "https://doi.org/10.1145/2676865",
    "publication_date": "2014-11-18",
    "publication_year": 2014,
    "authors": "Naehyuck Chang; David Z. Pan; Yuan Xie",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W1981722103",
    "type": "editorial"
  },
  {
    "title": "Layout-Aware Mixture Preparation of Biochemical Fluids on Application-Specific Digital Microfluidic Biochips",
    "doi": "https://doi.org/10.1145/2714562",
    "publication_date": "2015-06-24",
    "publication_year": 2015,
    "authors": "Sudip Roy; P. P. Chakrabarti; Srijan Kumar; Krishnendu Chakrabarty; Bhargab B. Bhattacharya",
    "corresponding_authors": "",
    "abstract": "The recent proliferation of digital microfluidic (DMF) biochips has enabled rapid on-chip implementation of many biochemical laboratory assays or protocols. Sample preprocessing, which includes dilution and mixing of reagents, plays an important role in the preparation of assays. The automation of sample preparation on a digital microfluidic platform often mandates the execution of a mixing algorithm, which determines a sequence of droplet mix-split steps (usually represented as a mixing graph). However, the overall cost and performance of on-chip mixture preparation not only depends on the mixing graph but also on the resource allocation and scheduling strategy, for instance, the placement of boundary reservoirs or dispensers, mixer modules, storage units, and physical design of droplet-routing pathways. In this article, we first present a new mixing algorithm based on a number-partitioning technique that determines a layout-aware mixing tree corresponding to a given target ratio of a number of fluids. The mixing graph produced by the proposed method can be implemented on a chip with a fewer number of crossovers among droplet-routing paths as well as with a reduced reservoir-to-mixer transportation distance. Second, we propose a routing-aware resource-allocation scheme that can be used to improve the performance of a given mixing algorithm on a chip layout. The design methodology is evaluated on various test cases to demonstrate its effectiveness in mixture preparation with the help of two representative mixing algorithms. Simulation results show that on average, the proposed scheme can reduce the number of crossovers among droplet-routing paths by 89.7% when used in conjunction with the new mixing algorithm, and by 75.4% when an earlier algorithm [Thies et al. 2008] is used.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W2201606084",
    "type": "article"
  },
  {
    "title": "Security-aware Routing and Scheduling for Control Applications on Ethernet TSN Networks",
    "doi": "https://doi.org/10.1145/3358604",
    "publication_date": "2019-11-22",
    "publication_year": 2019,
    "authors": "Rouhollah Mahfouzi; Amir Aminifar; Soheil Samii; Petru Eles; Zebo Peng",
    "corresponding_authors": "",
    "abstract": "Today, it is common knowledge in the cyber-physical systems domain that the tight interaction between the cyber and physical elements provides the possibility of substantially improving the performance of these systems that is otherwise impossible. On the downside, however, this tight interaction with cyber elements makes it easier for an adversary to compromise the safety of the system. This becomes particularly important, since such systems typically are composed of several critical physical components, e.g., adaptive cruise control or engine control that allow deep intervention in the driving of a vehicle. As a result, it is important to ensure not only the reliability of such systems, e.g., in terms of schedulability and stability of control plants, but also resilience to adversarial attacks. In this article, we propose a security-aware methodology for routing and scheduling for control applications in Ethernet networks. The goal is to maximize the resilience of control applications within these networked control systems to malicious interference while guaranteeing the stability of all control plants, despite the stringent resource constraints in such cyber-physical systems. Our experimental evaluations demonstrate that careful optimization of available resources can significantly improve the resilience of these networked control systems to attacks.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W2990700142",
    "type": "article"
  },
  {
    "title": "High-Level Synthesis of Key-Obfuscated RTL IP with Design Lockout and Camouflaging",
    "doi": "https://doi.org/10.1145/3410337",
    "publication_date": "2020-10-22",
    "publication_year": 2020,
    "authors": "Sheikh Ariful Islam; Love Kumar Sah; Srinivas Katkoori",
    "corresponding_authors": "",
    "abstract": "We propose three orthogonal techniques to secure Register-Transfer-Level (RTL) Intellectual Property (IP). In the first technique, the key-based RTL obfuscation scheme is proposed at an early design phase during High-Level Synthesis (HLS). Given a control-dataflow graph, we identify operations on non-critical paths and leverage synthesis information during and after HLS to insert obfuscation logic. In the second approach, we propose a robust design lockout mechanism for a key-obfuscated RTL IP when an incorrect key is applied more than the allowed number of attempts. We embed comparators on obfuscation logic output to check if the applied key is correct or not and a finite-state machine checker to enforce design lockout. Once locked out, only an authorized user (designer) can unlock the locked IP. In the third technique, we design four variants of the obfuscating module to camouflage the RTL design. We analyze the security properties of obfuscation, design lockout, and camouflaging. We demonstrate the feasibility on four datapath-intensive IPs and one crypto core for 32-, 64-, and 128-bit key lengths under three design corners (best, typical, and worst) with reasonable area, power, and delay overheads on both ASIC and FPGA platforms.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W3093692137",
    "type": "article"
  },
  {
    "title": "Performance Evaluation of NoC-Based Multicore Systems",
    "doi": "https://doi.org/10.1145/2870633",
    "publication_date": "2016-05-11",
    "publication_year": 2016,
    "authors": "Zhiliang Qian; Paul Bogdan; Chi-Ying Tsui; Radu Mărculescu",
    "corresponding_authors": "",
    "abstract": "In this survey, we review several approaches for predicting performance of Network-on-Chip (NoC)-based multicore systems, starting from the traffic models to the complex NoC models for latency evaluation. We first review typical traffic models to represent the application workloads in NoC. Specifically, we review Markovian and non-Markovian (e.g., self-similar or long-range memory-dependent) traffic models and discuss their applications on multicore platform design. Then, we review the analytical techniques to predict NoC performance under given input traffic. We investigate analytical models for average as well as maximum delay evaluation. We also review the developments and design challenges of NoC simulators. One interesting research direction in NoC performance evaluation consists of combining simulation and analytical models in order to exploit their advantages together. Toward this end, we discuss several newly proposed approaches that use hardware-based or learning-based techniques. Finally, we summarize several open problems and our perspective to address these challenges.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W2375937484",
    "type": "article"
  },
  {
    "title": "Cyber-Physical Co-Simulation Framework for Smart Cells in Scalable Battery Packs",
    "doi": "https://doi.org/10.1145/2891407",
    "publication_date": "2016-06-21",
    "publication_year": 2016,
    "authors": "Sebastian Steinhorst; Matthias Kauer; Arne Meeuw; Swaminathan Narayanaswamy; Martin Lukasiewycz; Samarjit Chakraborty",
    "corresponding_authors": "",
    "abstract": "This article introduces a Cyber-physical Co-Simulation Framework (CPCSF) for design and analysis of smart cells that enable scalable battery pack and Battery Management System (BMS) architectures. In contrast to conventional cells in battery packs, where all cells are monitored and controlled centrally, each smart cell is equipped with its own electronics in the form of a Cell Management Unit (CMU). The CMU maintains the cell in a safe and healthy operating state, while system-level battery management functions are performed by cooperation of the smart cells via communication. Here, the smart cells collaborate in a self-organizing fashion without a central controller instance. This enables maximum scalability and modularity, significantly simplifying integration of battery packs. However, for this emerging architecture, system-level design methodologies and tools have not been investigated yet. By contrast, components are developed individually and then manually tested in a hardware development platform. Consequently, the systematic design of the hardware/software architecture of smart cells requires a cyber-physical multi-level co-simulation of the network of smart cells that has to include all the components from the software, electronic, electric, and electrochemical domains. This comprises distributed BMS algorithms running on the CMUs, the communication network, control circuitry, cell balancing hardware, and battery cell behavior. For this purpose, we introduce a CPCSF that enables rapid design and analysis of smart cell hardware/software architectures. Our framework is then applied to investigate request-driven active cell balancing strategies that make use of the decentralized system architecture. In an exhaustive analysis on a realistic 21.6kW h Electric Vehicle (EV) battery pack containing 96 smart cells in series, the CPCSF is able to simulate hundreds of balancing runs together with all system characteristics, using the proposed request-driven balancing strategies at highest accuracy within an overall time frame of several hours. Consequently, the presented CPCSF for the first time allows us to quantitatively and qualitatively analyze the behavior of smart cell architectures for real-world applications.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W2462786435",
    "type": "article"
  },
  {
    "title": "Voltage-Based Covert Channels Using FPGAs",
    "doi": "https://doi.org/10.1145/3460229",
    "publication_date": "2021-06-28",
    "publication_year": 2021,
    "authors": "Dennis R. E. Gnad; Cong Dang Khoa Nguyen; Syed Hashim Gillani; Mehdi B. Tahoori",
    "corresponding_authors": "",
    "abstract": "Field Programmable Gate Arrays ( FPGAs ) are increasingly used in cloud applications and being integrated into Systems-on-Chip. For these systems, various side-channel attacks on cryptographic implementations have been reported, motivating one to apply proper countermeasures. Beyond cryptographic implementations, maliciously introduced covert channel receivers and transmitters can allow one to exfiltrate other secret information from the FPGA. In this article, we present a fast covert channel on FPGAs, which exploits the on-chip power distribution network. This can be achieved without any logical connection between the transmitter and receiver blocks. Compared to a recently published covert channel with an estimated 4.8 Mbit/s transmission speed, we show 8 Mbit/s transmission and reduced errors from around 3% to less than 0.003%. Furthermore, we demonstrate proper transmissions of word-size messages and test the channel in the presence of noise generated from other residing tenants’ modules in the FPGA. When we place and operate other co-tenant modules that require 85% of the total FPGA area, the error rate increases to 0.02%, depending on the platform and setup. This error rate is still reasonably low for a covert channel. Overall, the transmitter and receiver work with less than 3–5% FPGA LUT resources together. We also show the feasibility of other types of covert channel transmitters, in the form of synchronous circuits within the FPGA.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W3175162501",
    "type": "article"
  },
  {
    "title": "CeMux: Maximizing the Accuracy of Stochastic Mux Adders and an Application to Filter Design",
    "doi": "https://doi.org/10.1145/3491213",
    "publication_date": "2022-01-28",
    "publication_year": 2022,
    "authors": "Timothy J. Baker; John P. Hayes",
    "corresponding_authors": "",
    "abstract": "Stochastic computing (SC) is a low-cost computational paradigm that has promising applications in digital filter design, image processing, and neural networks. Fundamental to these applications is the weighted addition operation, which is most often implemented by a multiplexer (mux) tree. Mux-based adders have very low area but typically require long bitstreams to reach practical accuracy thresholds when the number of summands is large. In this work, we first identify the main contributors to mux adder error. We then demonstrate with analysis and experiment that two new techniques, precise sampling and full correlation, can target and mitigate these error sources. Implementing these techniques in hardware leads to the design of CeMux (Correlation-enhanced Multiplexer), a stochastic mux adder that is significantly more accurate and uses much less area than traditional weighted adders. We compare CeMux to other SC and hybrid designs for an electrocardiogram filtering case study that employs a large digital filter. One major result is that CeMux is shown to be accurate even for large input sizes. CeMux's higher accuracy leads to a latency reduction of 4× to 16× over other designs. Furthermore, CeMux uses about 35% less area than existing designs, and we demonstrate that a small amount of accuracy can be traded for a further 50% reduction in area. Finally, we compare CeMux to a conventional binary design and we show that CeMux can achieve a 50% to 73% area reduction for similar power and latency as the conventional design but at a slightly higher level of error.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W4225985809",
    "type": "article"
  },
  {
    "title": "High-Level Synthesis Implementation of an Embedded Real-Time HEVC Intra Encoder on FPGA for Media Applications",
    "doi": "https://doi.org/10.1145/3491215",
    "publication_date": "2022-03-08",
    "publication_year": 2022,
    "authors": "Panu Sjövall; Ari Lemmetti; Jarno Vanne; Sakari Lahti; Timo D. Hämäläinen",
    "corresponding_authors": "",
    "abstract": "High Efficiency Video Coding (HEVC) is the key enabling technology for numerous modern media applications. Overcoming its computational complexity and customizing its rich features for real-time HEVC encoder implementations, calls for automated design methodologies. This article introduces the first complete High-Level Synthesis (HLS) implementation for HEVC intra encoder on FPGA. The C source code of our open-source Kvazaar HEVC encoder is used as a design entry point for HLS that is applied throughout the whole encoder design process, from data-intensive coding tools like intra prediction and discrete transforms to more control-oriented tools such as context-adaptive binary arithmetic coding (CABAC). Our prototype is run on Nokia AirFrame Cloud Server equipped with 2.4 GHz dual 14-core Intel Xeon processors and two Intel Arria 10 PCIe FPGA accelerator cards with 40 Gigabit Ethernet. This proof-of-concept system is designed for hardware-accelerated HEVC encoding and it achieves real-time 4K coding speed up to 120 fps. The coding performance can be easily scaled up by adding practically any number of network-connected FPGA cards to the system. These results indicate that our HLS proposal not only boosts development time, but also provides previously unseen design scalability with competitive performance over the existing FPGA and ASIC encoder implementations.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W4220750011",
    "type": "article"
  },
  {
    "title": "A Survey and Perspective on Artificial Intelligence for Security-Aware Electronic Design Automation",
    "doi": "https://doi.org/10.1145/3563391",
    "publication_date": "2022-09-13",
    "publication_year": 2022,
    "authors": "David S. Koblah; Rabin Yu Acharya; Daniel E. Capecci; Olivia P. Dizon-Paradis; Shahin Tajik; Fatemeh Ganji; Damon L. Woodard; Domenic Forte",
    "corresponding_authors": "",
    "abstract": "Artificial intelligence (AI) and machine learning (ML) techniques have been increasingly used in several fields to improve performance and the level of automation. In recent years, this use has exponentially increased due to the advancement of high-performance computing and the ever increasing size of data. One of such fields is that of hardware design—specifically the design of digital and analog integrated circuits, where AI/ ML techniques have been extensively used to address ever-increasing design complexity, aggressive time to market, and the growing number of ubiquitous interconnected devices. However, the security concerns and issues related to integrated circuit design have been highly overlooked. In this article, we summarize the state-of-the-art in AI/ML for circuit design/optimization, security and engineering challenges, research in security-aware computer-aided design/electronic design automation, and future research directions and needs for using AI/ML for security-aware circuit design.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W4296593671",
    "type": "article"
  },
  {
    "title": "An Efficient Ring Oscillator PUF Using Programmable Delay Units on FPGA",
    "doi": "https://doi.org/10.1145/3593807",
    "publication_date": "2023-05-01",
    "publication_year": 2023,
    "authors": "Yijun Cui; Jiang Li; Yunpeng Chen; Chenghua Wang; Chongyan Gu; Máire O’Neill; Weiqiang Liu",
    "corresponding_authors": "",
    "abstract": "The ring oscillator (RO) PUF can be implemented on different FPGA platforms with high uniqueness and reliability. To decrease the hardware cost of conventional RO PUFs, a new design using the programmable delay units is proposed, namely, PRO PUF. The programmable interconnect points (PIPs) of programmable delay units are used to enhance the configurability. The PUF cell of the proposed design has the ability to be efficiently programmed to an RO PUF at any stage by adjusting the propagation paths of the delay units. A significant number of responses can be generated by the proposed PRO PUF while consuming fewer hardware resources. To verify the performance, the proposed design has been implemented on Xilinx FPGAs and also simulated using a standard 40nm technology. The experimental results have shown that the proposed design achieves high uniqueness, reliability, and hardware efficiency. Moreover, the PRO PUF has been evaluated using a machine learning attack, the CMA-ES attack. The results have shown that the proposed structure is more resistant to common modeling attacks when compared to conventional RO-related PUF designs.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W4367604228",
    "type": "article"
  },
  {
    "title": "Hardware Security Risks and Threat Analyses in Advanced Manufacturing Industry",
    "doi": "https://doi.org/10.1145/3603502",
    "publication_date": "2023-06-18",
    "publication_year": 2023,
    "authors": "Mohammad Monjur; Joshua Calzadillas; Qiaoyan Yu",
    "corresponding_authors": "",
    "abstract": "The advanced manufacturing industry (AMI) faces many unique challenges from the cyber-physical domain. Security threats are originated from two integral parts: software and hardware. Over the past decade, software security has been addressed extensively, but hardware security has not received enough attention. This work analyzes the security vulnerabilities of typical electronic devices deployed to AMI and proposes three attack models for sensing nodes, local storage and processing edge devices, and wired/wireless communication interfaces, respectively. Practical security attacks on hardware are demonstrated in this work to inspire the development of feasible countermeasures against hardware Trojans, fault injection attacks, and external signal interference. Moreover, this work highlights the unique security challenges posed by advanced manufacturing applications. To mitigate those security attacks in AMI, this work suggests guidelines for the defense method design that can effectively protect the hardware in AMI.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W4381123618",
    "type": "article"
  },
  {
    "title": "TROP: TRust-aware OPportunistic Routing in NoC with Hardware Trojans",
    "doi": "https://doi.org/10.1145/3639821",
    "publication_date": "2024-01-08",
    "publication_year": 2024,
    "authors": "Syam Sankar; Ruchika Gupta; John Jose; Sukumar Nandi",
    "corresponding_authors": "",
    "abstract": "Multiple software and hardware intellectual property (IP) components are combined on a single chip to form Multi-Processor Systems-on-Chips (MPSoCs). Due to the rigid time-to-market constraints, some of the IPs are from outsourced third parties. Due to the supply-chain management of IP blocks being handled by unreliable third-party vendors, security has grown as a crucial design concern in the MPSoC. These IPs may get exposed to certain unwanted practises like the insertion of malicious circuits called Hardware Trojan (HT) leading to security threats and attacks, including sensitive data leakage or integrity violations. A Network-on-Chip (NoC) connects various units of an MPSoC. Since it serves as the interface between various units in an MPSoC, it has complete access to all the data flowing through the system. This makes NoC security a paramount design issue. Our research focuses on a threat model where the NoC is infiltrated by multiple HTs that can corrupt packets. Data integrity verified at the destination’s network interface (NI) triggers re-transmissions of packets if the verification results in an error. In this article, we propose an opportunistic trust-aware routing strategy that efficiently avoids HT while ensuring that the packets arrive at their destination unaltered. Experimental results demonstrate the successful movement of packets through opportunistically selected neighbours along a trust-aware path free from the HT effect. We also observe a significant reduction in the rate of packet re-transmissions and latency at the expense of incurring minimum area and power overhead.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4390658773",
    "type": "article"
  },
  {
    "title": "Pareto Optimization of Analog Circuits Using Reinforcement Learning",
    "doi": "https://doi.org/10.1145/3640463",
    "publication_date": "2024-01-17",
    "publication_year": 2024,
    "authors": "Karthik Somayaji NS; Peng Li",
    "corresponding_authors": "",
    "abstract": "Analog circuit optimization and design presents a unique set of challenges in the IC design process. Many applications require the designer to optimize for multiple competing objectives, which poses a crucial challenge. Motivated by these practical aspects, we propose a novel method to tackle multi-objective optimization for analog circuit design in continuous action spaces. In particular, we propose to (i) extrapolate current techniques in Multi-Objective Reinforcement Learning to continuous state and action spaces and (ii) provide for a dynamically tunable trained model to query user defined preferences in multi-objective optimization in the analog circuit design context.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4390946435",
    "type": "article"
  },
  {
    "title": "Estimating Power, Performance, and Area for On-Sensor Deployment of AR/VR Workloads Using an Analytical Framework",
    "doi": "https://doi.org/10.1145/3670404",
    "publication_date": "2024-06-07",
    "publication_year": 2024,
    "authors": "Xiaoyu Sun; Xiaochen Peng; Sai Zhang; Jorge Marx Gómez; Win-San Khwa; Syed Shakib Sarwar; Ziyun Li; Weidong Cao; Zhao Wang; Chiao Liu; Meng‐Fan Chang; B. De Salvo; Kerem Akarvardar; H.‐S. Philip Wong",
    "corresponding_authors": "",
    "abstract": "Augmented Reality and Virtual Reality have emerged as the next frontier of intelligent image sensors and computer systems. In these systems, 3D die stacking stands out as a compelling solution, enabling in-situ processing capability of the sensory data for tasks such as image classification and object detection at low power, low latency, and a small form factor. These intelligent 3D CMOS Image Sensor (CIS) systems present a wide design space, encompassing multiple domains (e.g., computer vision algorithms, circuit design, system architecture, and semiconductor technology, including 3D stacking) that have not been explored in-depth so far. This paper aims to fill this gap. We first present an analytical evaluation framework, STAR-3DSim, dedicated to rapid pre-RTL evaluation of 3D-CIS systems capturing the entire stack from the pixel layer to the on-sensor processor layer. With STAR-3DSim, we then propose several knobs for PPA (power, performance, area) improvement of the Deep Neural Network (DNN) accelerator that can provide up to 53%, 41%, and 63% reduction in energy, latency, and area, respectively, across a broad set of relevant AR/VR workloads. Lastly, we present full-system evaluation results by taking image sensing, cross-tier data transfer, and off-sensor communication into consideration.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4399454483",
    "type": "article"
  },
  {
    "title": "A Single Bitline Highly Stable, Low Power With High Speed Half-Select Disturb Free 11T SRAM Cell",
    "doi": "https://doi.org/10.1145/3653675",
    "publication_date": "2024-07-09",
    "publication_year": 2024,
    "authors": "Lokesh Soni; Neeta Pandey",
    "corresponding_authors": "",
    "abstract": "A half-select disturb-free 11T (HF11T) static random access memory (SRAM) cell with low power, better stability and high speed is presented in this paper. The proposed SRAM cell works well with bit-interleaving design, which enhances soft-error immunity. A comparison of the proposed HF11T cell with other cutting-edge designs such as single-ended HS free 11T (SEHF11T), a shared-pass-gate 11T (SPG11T), data-dependent stack PMOS switching 10T (DSPS10T), a single-ended half-selected robust 12T (HSR12T), and 11T SRAM cells has been made. It exhibits 4.85×/9.19× less read delay ( T RA ) and write delay ( T WA ), respectively as compared to other considered SRAM cells. It achieves 1.07×/1.02× better read and write stability, respectively than the considered SRAM cells. It shows maximum reduction of 1.68×/4.58×/94.72×/9×/145× leakage power, read power, write power consumption, read power delay product (PDP) and write PDP respectively, than the considered SRAM cells. In addition, the proposed HF11T cell achieves 10.14× higher I on / I off ratio than the other compared cells. These improvements come with a trade-off, resulting in 1.13× more T RA compared to SPG11T. The simulation is performed with Cadence Virtuoso 45nm CMOS technology at supply voltage ( V DD ) of 0.6 V.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4399829483",
    "type": "article"
  },
  {
    "title": "Retargetable compiled simulation of embedded processors using a machine description language",
    "doi": "https://doi.org/10.1145/362652.362662",
    "publication_date": "2000-10-01",
    "publication_year": 2000,
    "authors": "Stefan Pees; Andreas Hoffmann; H. Meyr",
    "corresponding_authors": "",
    "abstract": "Fast processor simulators are needed for the software development of embedded processors, for HW/SW cosimulation systems, and for profiling and design of application-specific processors. Such fast simulators can be generated based on the machine description language LISA. Using this language to model processor architectures enables the generation of compiled simulators on various abstraction levels, assemblers, and compiler back ends. The article discusses the requirements of software development tools on processor models and presents the approach based on the LISA language. Furthermore, the implementation of a retargetable environment consisting of compiled simulator, debugger, and assembler is presented. Measurements for a verified, cycle-based LISA model of the TI TMS320C62× DSP show that that this approach achieves between 37× and 170× higher simulation speed compared to a commercial simulator using a standard technique and the same accuracy level.",
    "cited_by_count": 43,
    "openalex_id": "https://openalex.org/W1967441349",
    "type": "article"
  },
  {
    "title": "High-level design verification of microprocessors via error modeling",
    "doi": "https://doi.org/10.1145/296333.296347",
    "publication_date": "1998-10-01",
    "publication_year": 1998,
    "authors": "David Van Campenhout; Hussain Al-Asaad; John P. Hayes; Trevor Mudge; Richard B. Brown",
    "corresponding_authors": "",
    "abstract": "A design verification methodology for microprocessor hardware based on modeling design errors and generating simulation vectors for the modeled errors via physical fault testing techniques is presented. We have systematically collected design error data from a number of microprocessor design projects. The error data is used to derive error models suitable for design verification testing. A class of basic error models is identified and shown to yield tests that provide good coverage of common error types. To improve coverage for more complex errors, a new class of conditional error models is introduced. An experiment to evaluate the effectiveness of our methodology is presented. Single actual design errors are injected into a correct design, and it is determined if the methodology will generate a test that detects the actual errors. The experiment has been conducted for two microprocessor designs and the results indicate that very high coverage of actual design errors can be obtained with test sets that are complete for a small number of synthetic error models.",
    "cited_by_count": 43,
    "openalex_id": "https://openalex.org/W2122710652",
    "type": "article"
  },
  {
    "title": "A circuit level fault model for resistive bridges",
    "doi": "https://doi.org/10.1145/944027.944036",
    "publication_date": "2003-10-01",
    "publication_year": 2003,
    "authors": "Zhuo Li; Xiang Lü; Wangqi Qiu; Weiping Shi; D.M.H. Walker",
    "corresponding_authors": "",
    "abstract": "Delay faults are an increasingly important test challenge. Modeling bridge faults as delay faults helps delay tests to detect more bridge faults. Traditional bridge fault models are incomplete because these models only model the logic faults or these models are not efficient to use in delay tests for large circuits. In this article, we propose a physically realistic yet economical resistive bridge fault model to model delay faults as well as logic faults. An accurate yet simple delay calculation method is proposed. We also enumerate all possible fault behaviors and present the relationship between input patterns and output behaviors, which is useful in ATPG. Our fault simulation results show the benefit of at-speed tests.",
    "cited_by_count": 40,
    "openalex_id": "https://openalex.org/W2052534891",
    "type": "article"
  },
  {
    "title": "An exact solution to the minimum size test pattern problem",
    "doi": "https://doi.org/10.1145/502175.502186",
    "publication_date": "2001-10-01",
    "publication_year": 2001,
    "authors": "Paulo Flores; Horácio C. Neto; João Marques‐Silva",
    "corresponding_authors": "",
    "abstract": "This article addresses the problem of test pattern generation for single stuck-at faults in combinational circuits, under the additional constraint that the number of specified primary input assignments is minimized. This problem has different applications in testing, including the identification of \"don't care\" conditions to be used in the synthesis of Built-In Self-Test (BIST) logic. The proposed solution is based on an integer linear programming (ILP) formulation which builds on an existing Propositional Satisfiability (SAT) model for test pattern generation. The resulting ILP formulation is linear on the size of the original SAT model for test generation, which is linear on the size of the circuit. Nevertheless, the resulting ILP instances represent complex optimization problems, that require dedicated ILP algorithms. Preliminary results on benchmark circuits validate the practical applicability of the test pattern minimization model and associated ILP algorithm.",
    "cited_by_count": 39,
    "openalex_id": "https://openalex.org/W1975850963",
    "type": "article"
  },
  {
    "title": "Specification and verification of pipelining in the ARM2 RISC microprocessor",
    "doi": "https://doi.org/10.1145/296333.296345",
    "publication_date": "1998-10-01",
    "publication_year": 1998,
    "authors": "James K. Huggins; David Van Campenhout",
    "corresponding_authors": "",
    "abstract": "Gurevich Abstract State Machines (ASMs) provide a sound mathematical basis for the specification and verification of systems. An application of the ASM methodology to the verification of a pipelined microprocessor (an ARM2 implementation) is described. Both the sequential execution model and final pipelined model are formalized using ASMs. A series of intermediate models are introduced that gradually expose the complications of pipelining. The first intermediate model is proven equivalent to the sequential model in the absence of structural, control, and data hazards. In the following steps, these simplifying assumptions are lifted one by one, and the original proof is refined to establish the equivalence of each intermediate model with the sequential model, leading ultimately to a full proof of equivalence of the sequential and pipelined models.",
    "cited_by_count": 39,
    "openalex_id": "https://openalex.org/W2063162149",
    "type": "article"
  },
  {
    "title": "Satisfiability models and algorithms for circuit delay computation",
    "doi": "https://doi.org/10.1145/504914.504920",
    "publication_date": "2002-01-01",
    "publication_year": 2002,
    "authors": "Luís Guerra e Silva; João Marques‐Silva; L. Miguel Silveira; Karem A. Sakallah",
    "corresponding_authors": "",
    "abstract": "The existence of false paths represents a significant and computationally complex problem in the estimation of the true delay of combinational and sequential circuits. In this article we conduct a comprehensive study of modeling circuit delay computation, accounting for false paths, as a sequence of instances of Boolean satisfiability. Several path sensitization models and delay models are studied. In addition we evaluate some of the most competitive Boolean satisfiability algorithms seeking to identify which are best suited for solving circuit delay computation problems. Finally, realistic delay modeling (taking into account extracted interconnect delays and fanout data) is considered in order to experimentally evaluate the complexity of solving real-world instances.",
    "cited_by_count": 39,
    "openalex_id": "https://openalex.org/W2079771879",
    "type": "article"
  },
  {
    "title": "Power minimization algorithms for LUT-based FPGA technology mapping",
    "doi": "https://doi.org/10.1145/966137.966139",
    "publication_date": "2004-01-01",
    "publication_year": 2004,
    "authors": "Hao Li; Srinivas Katkoori; Wai-Kei Mak",
    "corresponding_authors": "",
    "abstract": "We study the technology mapping problem for LUT-based FPGAs targeting at power minimization. The problem has been proved to be NP-hard previously. Therefore, we present an efficient heuristic algorithm to generate low-power mapping solutions. The key idea is to compute and select low-power K -feasible cuts by an efficient incremental network flow computation method. Experimental results show that our algorithm reduces power consumption as well as area over the best algorithms reported in the literature. In addition, we present an extension to compute depth-optimal low-power mappings. Compared with Cutmap, a depth-optimal mapper with simultaneous area minimization, we achieve a 14% power savings on average without any depth penalty.",
    "cited_by_count": 38,
    "openalex_id": "https://openalex.org/W2030094243",
    "type": "article"
  },
  {
    "title": "Layout-driven RTL binding techniques for high-level synthesis using accurate estimators",
    "doi": "https://doi.org/10.1145/268424.268425",
    "publication_date": "1997-10-01",
    "publication_year": 1997,
    "authors": "Min Xu; Fadi Kurdahi",
    "corresponding_authors": "",
    "abstract": "The importance of effective and efficient accounting of layout effects is well established in High-Level Synthesis (HLS), since it allows more realistic exploration of the design space and the generation of solutions with predictable metrics. This feature is highly desirable in order to avoid unnecessary iterations through the design process. In this article, we address the problem of layout-driven register-transfer-level (RTL) binding as this step has a direct relevance to the final performance of the design. By producing not only an RTL design but also an approximate physical topology of the chip-level implementation, we ensure that the solution will perform at the predicted metric once implemented, thus avoiding unnecessary delays in the design process.",
    "cited_by_count": 38,
    "openalex_id": "https://openalex.org/W2074601596",
    "type": "article"
  },
  {
    "title": "Partitioning sequential programs for CAD using a three-step approach",
    "doi": "https://doi.org/10.1145/567270.567273",
    "publication_date": "2002-07-01",
    "publication_year": 2002,
    "authors": "Frank Vahid",
    "corresponding_authors": "Frank Vahid",
    "abstract": "Many computer-aided design problems involve solutions that require the partitioning of a large sequential program written in a language such as C or VHDL. Such partitioning can improve design metrics such as performance, power, energy, size, input/output lines, and even CAD tool run-time and memory requirements, by partitioning among hardware modules, hardware and software processors, or even among time-slices in reconfigurable computing devices. Previous partitioning approaches typically preselect the granularity at which the program is partitioned. In this article, we define three distinct partitioning steps: procedure determination, preclustering, and N -way partitioning, with the first two steps focusing on granularity selection. Using three steps instead of one can provide for a more thorough design space exploration and for faster partitioning. We emphasize the first two steps in this article since they represent the most novel aspects. We illustrate the approach on an example, provide results of several experiments, and point to the need for future research that more fully automates the three-step approach.",
    "cited_by_count": 37,
    "openalex_id": "https://openalex.org/W2060793708",
    "type": "article"
  },
  {
    "title": "Energy-aware variable partitioning and instruction scheduling for multibank memory architectures",
    "doi": "https://doi.org/10.1145/1059876.1059885",
    "publication_date": "2005-04-01",
    "publication_year": 2005,
    "authors": "Zhong Wang; Xiaobo Sharon Hu",
    "corresponding_authors": "",
    "abstract": "Many high-end DSP processors employ both multiple memory banks and heterogeneous register files to improve performance and power consumption. The complexity of such architectures presents a great challenge to compiler design. In this article, we present an approach for variable partitioning and instruction scheduling to maximally exploit the benefits provided by such architectures. Our approach is built on a novel graph model which strives to capture both performance and power demands. We propose an algorithm to iteratively find the variable partition such that the maximum energy saving is achieved while satisfying the given performance constraint. Experimental results demonstrate the effectiveness of our approach.",
    "cited_by_count": 37,
    "openalex_id": "https://openalex.org/W2158158601",
    "type": "article"
  },
  {
    "title": "Forming N-detection test sets without test generation",
    "doi": "https://doi.org/10.1145/1230800.1230810",
    "publication_date": "2007-04-01",
    "publication_year": 2007,
    "authors": "Irith Pomeranz; S.M. Reddy",
    "corresponding_authors": "",
    "abstract": "We describe a procedure for forming n -detection test sets for n &gt;1 without applying a test generation procedure to target faults. The proposed procedure accepts a one-detection test set. It extracts test cubes for target faults from the one-detection test set, and merges the test cubes to obtain new test vectors. By extracting and merging different test cubes in different iterations of this process, an n -detection test set is obtained. Merging of test cubes does not require test generation or fault simulation. Fault simulation is required for extracting test cubes for target faults. We demonstrate that the resulting test set is as effective in detecting untargeted faults as an n -detection test set generated by a deterministic test generation procedure. We also discuss the application of the proposed procedure starting from a random test set (instead of a one-detection test set).",
    "cited_by_count": 29,
    "openalex_id": "https://openalex.org/W1993241318",
    "type": "article"
  },
  {
    "title": "SoCDAL",
    "doi": "https://doi.org/10.1145/1297666.1297683",
    "publication_date": "2008-01-01",
    "publication_year": 2008,
    "authors": "Yongjin Ahn; Keesung Han; Ganghee Lee; Hyunjik Song; Junhee Yoo; Ki‐Young Choi; Xingguang Feng",
    "corresponding_authors": "",
    "abstract": "Time-to-market pressure and the ever-growing design complexity of multiprocessor system-on-chips have demanded an efficient design environment that enables fast exploration of large design space. In this article, we introduce a new design environment, called SoCDAL, for accelerating multiprocessor system-on-chip design through fast design-space exploration targeting real-time multimedia systems. SoCDAL is a set of mostly automated tools covering system specification, hardware/software estimation, application-to-architecture mapping, simulation model generation, and system verification through simulation. For system specification, the process network model has been widely used for system specification because of its modeling capability. However, it is hard to use for real-time systems design, since its behavior cannot be estimated statically. We introduce a new approach which enables analyzing a process network model statically with some restrictions. For the hardware/software estimation, we analyze codes statically. Application-to-architecture mapping process implements a novel algorithm to support an arbitrary number of processors, with performance evaluation by static scheduling considering communication behavior. Mapping results are used to generate simulation models automatically at several transaction levels to be pipelined to a commercial tool. We show the effectiveness of our approaches by some experimental results with multimedia applications such as JPEG, H.263, and H.264 encoders, as well as an H.264 decoder.",
    "cited_by_count": 27,
    "openalex_id": "https://openalex.org/W1989739148",
    "type": "article"
  },
  {
    "title": "Parameterized architecture-level dynamic thermal models for multicore microprocessors",
    "doi": "https://doi.org/10.1145/1698759.1698766",
    "publication_date": "2010-02-01",
    "publication_year": 2010,
    "authors": "Duo Li; Sheldon X.-D. Tan; Eduardo H. Pacheco; Murli Tirumala",
    "corresponding_authors": "",
    "abstract": "In this article, we propose a new architecture-level parameterized dynamic thermal behavioral modeling algorithm for emerging thermal-related design and optimization problems for high-performance multicore microprocessor design. We propose a new approach, called ParThermPOF , to build the parameterized thermal performance models from the given accurate architecture thermal and power information. The new method can include a number of variable parameters such as the locations of thermal sensors in a heat sink, different components (heat sink, heat spreader, core, cache, etc.), thermal conductivity of heat sink materials, etc. The method consists of two steps: first, a response surface method based on low-order polynomials is applied to build the parameterized models at each time point for all the given sampling nodes in the parameter space. Second, an improved Generalized Pencil-Of-Function (GPOF) method is employed to build the transfer-function-based behavioral models for each time-varying coefficient of the polynomials generated in the first step. Experimental results on a practical quad-core microprocessor show that the generated parameterized thermal model matches the given data very well. The compact models by ParThermPOF offer two order of magnitudes speedup over the commercial thermal analysis tool FloTHERM on the given examples. ParThermPOF is very suitable for design space exploration and optimization where both time and system parameters need to be considered.",
    "cited_by_count": 24,
    "openalex_id": "https://openalex.org/W2039060197",
    "type": "article"
  },
  {
    "title": "Gate-Level Simulation with GPU Computing",
    "doi": "https://doi.org/10.1145/1970353.1970363",
    "publication_date": "2011-06-01",
    "publication_year": 2011,
    "authors": "Debapriya Chatterjee; Andrew DeOrio; Valeria Bertacco",
    "corresponding_authors": "",
    "abstract": "Functional verification of modern digital designs is a crucial, time-consuming task impacting not only the correctness of the final product, but also its time to market. At the heart of most of today’s verification efforts is logic simulation, used heavily to verify the functional correctness of a design for a broad range of abstraction levels. In mainstream industry verification methodologies, typical setups coordinate the validation effort of a complex digital system by distributing logic simulation tasks among vast server farms for months at a time. Yet, the performance of logic simulation is not sufficient to satisfy the demand, leading to incomplete validation processes, escaped functional bugs, and continuous pressure on the EDA industry to develop faster simulation solutions. In this work we propose GCS, a solution to boost the performance of logic simulation, gate-level simulation in particular, by more than a factor of 10 using recent hardware advances in Graphic Processing Unit (GPU) technology. Noting the vast available parallelism in the hardware of modern GPUs and the inherently parallel structures of gate-level netlists, we propose novel algorithms for the efficient mapping of complex designs to parallel hardware. Our novel simulation architecture maximizes the utilization of concurrent hardware resources while minimizing expensive communication overhead. The experimental results show that our GPU-based simulator is capable of handling the validation of industrial-size designs while delivering more than an order-of-magnitude performance improvements on average, over the fastest multithreaded simulators commercially available.",
    "cited_by_count": 24,
    "openalex_id": "https://openalex.org/W2059896017",
    "type": "article"
  },
  {
    "title": "High-performance clock mesh optimization",
    "doi": "https://doi.org/10.1145/2209291.2209306",
    "publication_date": "2012-06-01",
    "publication_year": 2012,
    "authors": "Matthew R. Guthaus; Xuchu Hu; Gustavo Wilke; Guilherme Flach; Ricardo Reis",
    "corresponding_authors": "",
    "abstract": "Clock meshes are extremely effective at producing low-skew regional clock networks that are tolerant of environmental and process variations. For this reason, clock meshes are used in most high-performance designs, but this robustness consumes significant power. In this work, we present two techniques to optimize high-performance clock meshes. The first technique is a mesh perturbation methodology for nonuniform mesh routing. The second technique is a skew-aware buffer placement through iterative buffer deletion. We demonstrate how these optimizations can achieve significant power reductions and a near elimination of short-circuit power. In addition, the total wire length is decreased, the number of required buffers is decreased, and both skew and robustness are improved on average when variation is considered.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W1982469801",
    "type": "article"
  },
  {
    "title": "Scan Flip-Flop Grouping to Compress Test Data and Compact Test Responses for Launch-on-Capture Delay Testing",
    "doi": "https://doi.org/10.1145/2159542.2159550",
    "publication_date": "2012-04-01",
    "publication_year": 2012,
    "authors": "Dong Xiang; Zhen Chen; Laung‐Terng Wang",
    "corresponding_authors": "",
    "abstract": "Test data compression is a much more difficult problem for launch-on-capture (LOC) delay testing, because test data for LOC delay testing is much more than that of stuck-at fault testing, and LOC delay fault test generation in the two-frame circuit model can specify many more inputs. A new scan architecture is proposed to compress test stimulus data, compact test responses, and reduce test application time for LOC delay fault testing. The new scan architecture merges a number of scan flip-flops into the same group, where all scan flip-flops in the same group are assigned the same values for all test pairs. Sufficient conditions are presented for including any pair of scan flip-flops into the same group for LOC transition, non-robust path delay, and robust path delay fault testing. Test data for LOC delay testing based on the new scan architecture can be compressed significantly. Test application time can also be reduced greatly. Sufficient conditions are presented to construct a test response compactor for LOC transition, non-robust, and robust path delay fault testing. Folded scan forest and test response compactor are constructed for further test data compression. Sufficient experimental results are presented to show the effectiveness of the method.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W1995880343",
    "type": "article"
  },
  {
    "title": "Runtime verification for multicore SoC with high-quality trace data",
    "doi": "https://doi.org/10.1145/2442087.2442089",
    "publication_date": "2013-03-01",
    "publication_year": 2013,
    "authors": "Rico Backasch; Christian Hochberger; Alexander Weiß; Martin Leucker; Richard Lasslop",
    "corresponding_authors": "",
    "abstract": "Multicore System-on-Chip (SoC) implementations of embedded systems are becoming very popular. In these systems it is possible to spread out computations over many cores. On one hand this leads to better energy efficiency if clock frequencies and core voltages are reduced. On the other hand this delivers very high performance to the software developer and thus enables complex software systems to be implemented. Unfortunately, debugging and validation of these systems becomes extremely difficult. Various technological approaches try to solve this dilemma. In this contribution we will show a new approach to observe multi-core SoCs and make their internal operations visible to external analysis tools. Also, we show that runtime verification can be employed to analyze and validate these internal operations while the system operates in its normal environment. The combination of these two approaches delivers unprecedented options to the developer to understand and verify system behavior even in complex multicore SoCs.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W2166915430",
    "type": "article"
  },
  {
    "title": "Improving performance per watt of asymmetric multi-core processors via online program phase classification and adaptive core morphing",
    "doi": "https://doi.org/10.1145/2390191.2390196",
    "publication_date": "2013-01-01",
    "publication_year": 2013,
    "authors": "Rance Rodrigues; Arunachalam Annamalai; Israel Koren; Sandip Kundu",
    "corresponding_authors": "",
    "abstract": "Asymmetric multi-core processors (AMPs) have been shown to outperform symmetric ones in terms of performance and performance/watt. Improved performance and power efficiency are achieved when the program threads are matched to their most suitable cores. Since the computational needs of a program may change during its execution, the best thread to core assignment will likely change with time. We have, therefore, developed an online program phase classification scheme that allows the swapping of threads when the current needs of the threads justify a change in the assignment. The architectural differences among the cores in an AMP can never match the diversity that exists among different programs and even between different phases of the same program. Consider, for example, a program (or a program phase) that has a high instruction-level parallelism (ILP) and will exhibit high power efficiency if executed on a powerful core. We can not, however, include such powerful cores in the designed AMP, since they will remain underutilized most of the time, and they are not power efficient when the programs do not exhibit a high degree of ILP. Thus, we must expect to see program phases where the designed cores will be unable to support the ILP that the program can exhibit. We, therefore, propose in this article a dynamic morphing scheme. This scheme will allow a core to gain control of a functional unit that is ordinarily under the control of a neighboring core during periods of intense computation with high ILP. This way, we dynamically adjust the hardware resources to the current needs of the application. Our results show that combining online phase classification and dynamic core morphing can significantly improve the performance/watt of most multithreaded workloads.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W2004535862",
    "type": "article"
  },
  {
    "title": "Memory access optimization in compilation for coarse-grained reconfigurable architectures",
    "doi": "https://doi.org/10.1145/2003695.2003702",
    "publication_date": "2011-10-01",
    "publication_year": 2011,
    "authors": "Yong‐Joo Kim; Jongeun Lee; Aviral Shrivastava; Yunheung Paek",
    "corresponding_authors": "",
    "abstract": "Coarse-grained reconfigurable architectures (CGRAs) promise high performance at high power efficiency. They fulfil this promise by keeping the hardware extremely simple, and moving the complexity to application mapping. One major challenge comes in the form of data mapping. For reasons of power-efficiency and complexity, CGRAs use multibank local memory, and a row of PEs share memory access. In order for each row of the PEs to access any memory bank, there is a hardware arbiter between the memory requests generated by the PEs and the banks of the local memory. However, a fundamental restriction remains in that a bank cannot be accessed by two different PEs at the same time. We propose to meet this challenge by mapping application operations onto PEs and data into memory banks in a way that avoids such conflicts. To further improve performance on multibank memories, we propose a compiler optimization for CGRA mapping to reduce the number of memory operations by exploiting data reuse. Our experimental results on kernels from multimedia benchmarks demonstrate that our local memory-aware compilation approach can generate mappings that are up to 53% better in performance (26% on average) compared to a memory-unaware scheduler.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W2021552071",
    "type": "article"
  },
  {
    "title": "Hierarchical power management for adaptive tightly-coupled processor arrays",
    "doi": "https://doi.org/10.1145/2390191.2390193",
    "publication_date": "2013-01-01",
    "publication_year": 2013,
    "authors": "Vahid Lari; Shravan Muddasani; Srinivas Boppu; Frank Hannig; Moritz Schmid; Jürgen Teich",
    "corresponding_authors": "",
    "abstract": "We present a self-adaptive hierarchical power management technique for massively parallel processor architectures, supporting a new resource-aware parallel computing paradigm called invasive computing. Here, an application can dynamically claim, execute, and release the resources in three phases: resource acquisition (invade), program loading/configuration and execution (infect), and release (retreat). Resource invasion is governed by dedicated decentralized hardware controllers, called invasion controllers ( i ctrls), which are integrated into each processing element (PE). Several invasion strategies for claiming linearly connected or rectangular regions of processing resources are implemented. The key idea is to exploit the decentralized resource management inherent to invasive computing for power savings by enabling applications themselves to control the power for processing resources and invasion controllers using a hierarchical power-gating approach. We propose analytical models for estimating various components of energy consumption for faster design space exploration and compare them with the results obtained from a cycle-accurate C++ simulator of the processor array. In order to find optimal design trade-offs, various parameters like (a) energy consumption, (b) hardware cost, and (c) timing overheads are compared for different sizes of power domains. Experimental results show significant energy savings (up to 73%) for selected characteristical algorithms and different resource utilizations. In addition, we demonstrate the accuracy of our proposed analytical model. Here, estimation errors less than 3.6% can be reported.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W2053617725",
    "type": "article"
  },
  {
    "title": "Composable thermal modeling and simulation for architecture-level thermal designs of multicore microprocessors",
    "doi": "https://doi.org/10.1145/2442087.2442099",
    "publication_date": "2013-03-01",
    "publication_year": 2013,
    "authors": "Hai Wang; Sheldon X.-D. Tan; Duo Li; Ashish Gupta; Yuan Yuan",
    "corresponding_authors": "",
    "abstract": "Efficient temperature estimation is vital for designing thermally efficient, lower power and robust integrated circuits in nanometer regime. Thermal simulation based on the detailed thermal structures no longer meets the demanding tasks for efficient design space exploration. The compact and composable model-based simulation provides a viable solution to this difficult problem. However, building such thermal models from detailed thermal structures was not well addressed in the past. In this article, we propose a new compact thermal modeling technique, called ThermComp , standing for thermal modeling with composable modules. ThermComp can be used for fast thermal design space exploration for multicore microprocessors. The new approach builds the composable model from detailed structures for each basic module using the finite difference method and reduces the model complexity by the sampling-based model order reduction technique. These composable models are then used to assemble different multicore architecture thermal models and realized into SPICE-like netlists. The resulting thermal models can be simulated by the general circuit simulator SPICE. ThermComp tries to preserve the accuracy of fine-grained models with the speed of coarse-grained models. Experimental results on a number of multicore microprocessor architectures show the new approach can easily build accurate thermal systems from compact composable models for fast architecture thermal analysis and optimization and is much faster than the existing HotSpot method with similar accuracy.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W1973881538",
    "type": "article"
  },
  {
    "title": "Introduction to the special section on adaptive power management for energy and temperature-aware computing systems",
    "doi": "https://doi.org/10.1145/2390191.2390192",
    "publication_date": "2013-01-01",
    "publication_year": 2013,
    "authors": "Ayse K. Coskun; Yung-Hsiang Lu; Qinru Qiu",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W1986176750",
    "type": "article"
  },
  {
    "title": "A routing algorithm for graphene nanoribbon circuit",
    "doi": "https://doi.org/10.1145/2505056",
    "publication_date": "2013-10-01",
    "publication_year": 2013,
    "authors": "Tan Yan; Qiang Ma; Scott Chilstedt; Martin D. F. Wong; Deming Chen",
    "corresponding_authors": "",
    "abstract": "Conventional CMOS devices are facing an increasing number of challenges as their feature sizes scale down. Graphene nanoribbon (GNR) based devices are shown to be a promising replacement of traditional CMOS at future technology nodes. However, all previous works on GNRs focus at the device level. In order to integrate these devices into electronic systems, routing becomes a key issue. In this article, the GNR routing problem is studied for the first time. We formulate the GNR routing problem as a minimum hybrid-cost shortest path problem on triangular mesh (“hybrid” means that we need to consider both the length and the bending of the routing path). We show that by graph expansion, this minimum hybrid-cost shortest path problem can be solved by applying the conventional shortest path algorithm on the expanded graph. Experimental results show that our GNR routing algorithm effectively handles the hybrid cost.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W2169500615",
    "type": "article"
  },
  {
    "title": "Accelerated Soft-Error-Rate (SER) Estimation for Combinational and Sequential Circuits",
    "doi": "https://doi.org/10.1145/3035496",
    "publication_date": "2017-05-25",
    "publication_year": 2017,
    "authors": "Ji Li; Jeffrey Draper",
    "corresponding_authors": "",
    "abstract": "Radiation-induced soft errors have posed an increasing reliability challenge to combinational and sequential circuits in advanced CMOS technologies. Therefore, it is imperative to devise fast, accurate and scalable soft error rate (SER) estimation methods as part of cost-effective robust circuit design. This paper presents an efficient SER estimation framework for combinational and sequential circuits, which considers single-event transients (SETs) in combinational logic and multiple cell upsets (MCUs) in sequential elements. A novel top-down memoization algorithm is proposed to accelerate the propagation of SETs, and a general schematic and layout co-simulation approach is proposed to model the MCUs for redundant sequential storage structures. The feedback in sequential logic is analyzed with an efficient time frame expansion method. Experimental results on various ISCAS85 combinational benchmark circuits demonstrate that the proposed approach achieves up to 560.2X times speedup with less than 3% difference in terms of SER results compared with the baseline algorithm. The average runtime of the proposed framework on a variety of ISCAS89 benchmark circuits is 7.20s, and the runtime is 119.23s for the largest benchmark circuit with more than 3,000 flip-flops and 17,000 gates.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W2618494826",
    "type": "article"
  },
  {
    "title": "Statistical Peak Temperature Prediction and Thermal Yield Improvement for 3D Chip Multiprocessors",
    "doi": "https://doi.org/10.1145/2633606",
    "publication_date": "2014-08-01",
    "publication_year": 2014,
    "authors": "Da-Cheng Juan; Siddharth Garg; Diana Marculescu",
    "corresponding_authors": "",
    "abstract": "Thermal issues have become critical roadblocks for achieving highly reliable three-dimensional (3D) integrated circuits (ICs). The presence of process variations further exacerbates these problems. In this article, we propose techniques for the efficient evaluation and mitigation of the impact of leakage power variations on the temperature profile of 3D Chip Multiprocessors (CMPs). Experimental results demonstrate that, due to the impact of process variations, a 4-tier 3D implementation can be more than 40ˆC hotter and 23% leakier than its 2D counterpart. To determine the maximum temperature of each fabricated 3D IC, we propose an accurate learning-based model for peak temperature prediction. Based on the learning model, we then propose two post-fabrication techniques to increase the thermal yield of 3D CMPs: (1) tier restacking and (2) thermally-aware die matching. Experimental results show that: (1) the proposed prediction model achieves more than 98% accuracy, and (2) the proposed thermally-aware, post-fabrication optimization techniques significantly improve the thermal yield from only 51% to 99% for 3D CMPs.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W1981141412",
    "type": "article"
  },
  {
    "title": "Performance and power profiling for emulated Android systems",
    "doi": "https://doi.org/10.1145/2566660",
    "publication_date": "2014-03-01",
    "publication_year": 2014,
    "authors": "Chia-Heng Tu; Hui-Hsin Hsu; Jen-Hao Chen; Chun‐Han Chen; Shih‐Hao Hung",
    "corresponding_authors": "",
    "abstract": "Simulation is a common approach for assisting system design and optimization. For system-wide optimization, energy and computational resources are often the two most critical issues. Monitoring the energy state of each hardware component and measuring the time spent in each state is needed for accurate energy and performance prediction. For software optimization, it is important to profile the energy and the time consumed by each software construct in a realistic operating environment with a proper workload. However, the conventional approaches of simulation often fail to produce satisfying data. First, building a cycle-accurate simulation environment for a complex system, such as an Android smartphone, is difficult and can take a long time. Second, a slow simulation can significantly alter the behavior of multithreaded, I/O-intensive applications and can affect the accuracy of profiles. Third, existing software-based profilers generally do not work on simulators, which makes it difficult for performance analysis of complicated software, for example, Java applications executed by the Dalvik VM in an Android system. To address these aforementioned problems, we proposed and prototyped a framework, called virtual performance analyzer (VPA). VPA takes advantage of an existing emulator or virtual machine monitor to reduce the complexity of building a simulator. VPA allows the user to selectively and incrementally integrate timing models and power models into the emulator with our carefully designed performance/power monitors, tracing facility, and profiling tools to evaluate and analyze the emulated system. The emulated system can perform at different levels of speed to help verify if the profile data are impacted by the emulation speed. Finally, VPA supports existing software-based profiles and enables non-intrusive tracing/profiling by minimizing the probe effect. Our experimental results show that the VPA framework allows users to quickly establish a performance/power evaluation environment and gather useful information to support system design and software optimization for Android smartphones.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W2017296642",
    "type": "article"
  },
  {
    "title": "A Hybrid Technique for Discrete Gate Sizing Based on Lagrangian Relaxation",
    "doi": "https://doi.org/10.1145/2647956",
    "publication_date": "2014-08-01",
    "publication_year": 2014,
    "authors": "Vinicius Livramento; Chrystian Guth; José Luís Güntzel; Marcelo O. Johann",
    "corresponding_authors": "",
    "abstract": "Discrete gate sizing has attracted a lot of attention recently as the EDA industry faces the challenge of optimizing large standard cell-based circuits. The discrete nature of the problem, along with complex timing models, stringent design constraints, and ever-increasing circuit sizes, make the problem very difficult to tackle. Lagrangian Relaxation (LR) is an effective technique to handle complex constrained optimization problems and therefore has been successfully applied to solve the gate sizing problem. This article proposes an improved Lagrangian relaxation formulation for discrete gate sizing that relaxes timing, maximum gate input slew, and maximum gate output capacitance constraints. Based on such formulation, we propose a hybrid technique composed of three steps. First, a topological greedy heuristic solves the LR formulation. Such a heuristic is applied assuming a slightly increased target clock period (backoff factor) to better explore the solution space. Second, a delay recovery heuristic reestablishes the original target clock with small power overhead. Third, a power recovery heuristic explores the remaining slacks to further reduce power. Experiments on the ISPD 2012 Contest benchmarks show that our hybrid technique provides less leakage power than the state-of-the-art work for every circuit from the ISPD 2012 Contest infrastructure, achieving up to 24% less leakage. In addition, our technique achieves a much better compromise between leakage reduction and runtime, obtaining, on average, 9% less leakage power while running 8.8 times faster.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W2040498220",
    "type": "article"
  },
  {
    "title": "MAESTRO— Holistic Actor-Oriented Modeling of Nonfunctional Properties and Firmware Behavior for MPSoCs",
    "doi": "https://doi.org/10.1145/2594481",
    "publication_date": "2014-06-01",
    "publication_year": 2014,
    "authors": "Rafael Rosales; Michael Glaß; Jürgen Teich; Bo Wang; Yang Xu; Ralph Hasholzner",
    "corresponding_authors": "",
    "abstract": "Modeling and evaluating nonfunctional properties such as performance, power, and reliability of embedded systems are tasks of utmost importance. In this article, we introduce M AESTRO , a methodology for the modeling and evaluation of nonfunctional properties and embedded firmware of MPSoC architecture components at the Electronic System Level (ESL). In contrast to existing design flows that provide predefined performance models, M AESTRO defines a flexible approach that allows to define virtual prototypes that can be easily customized and extended to evaluate multiple nonfunctional properties of interest at different levels of abstraction. In M AESTRO , a design is composed purely from actor-oriented models. This enables typical ESL features such as automatic design space exploration and synthesizability of HW and SW components, typically missing in very general design flows. Unique to M AESTRO is the separation and coordination of the interaction between application functionality, firmware, and performance models for the evaluation of nonfunctional properties, and their complex interactions within a single Model-of-Computation (MoC). The main advantages of M AESTRO are: (I) Extensible modeling of interdependent nonfunctional properties of heterogeneous MPSoC components; (II) high flexibility to investigate the appropriate trade-off between modeling effort and accuracy of nonfunctional property evaluators; (III) a holistic approach for modeling application functionality as well as firmware affecting the evaluation of nonfunctional properties. Regarding (II), we present a mobile baseband processor platform use-case, executing a GSM paging application. To demonstrate (I) and (III), we present the modeling of a complex ESL processor virtual prototype, running a soft real-time application and equipped with both a power and reliability manager.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W2061227787",
    "type": "article"
  },
  {
    "title": "Scaling Input Stimulus Generation through Hybrid Static and Dynamic Analysis of RTL",
    "doi": "https://doi.org/10.1145/2676549",
    "publication_date": "2014-11-18",
    "publication_year": 2014,
    "authors": "Lingyi Liu; Shobha Vasudevan",
    "corresponding_authors": "",
    "abstract": "We enhance STAR, an automatic technique for functional input vector generation for design validation. STAR statically analyzes the source code of the Register-Transfer Level (RTL) design. The STAR approach is a hybrid between RTL symbolic execution and concrete simulation that offsets the disadvantages of both. The symbolic execution, which follows the concrete simulation path, extracts constraints for that path. The guard in the path constraints is then mutated and passed to an SMT solver. A satisfiable assignment generates a valid input vector. However, STAR suffers the problem of path explosion during symbolic execution. In this article, we present an explored symbolic state caching method to attack path explosion. Explored symbolic states are states starting from which all subpaths have been explored. Each explored symbolic state is stored in the form of bitmap encoding of branches to ease comparison. When the explored symbolic state is reached again in the following symbolic execution, all subpaths can be pruned. In addition, we use two types of optimizations: (a) dynamic UD chain slicing; and (b) local conflict resolution to improve the running efficiency of STAR. We demonstrate that the results of the enhanced STAR are promising in showing high coverage on benchmark RTL designs, and the runtime of the test generation process is reduced from several hours to less than 20 minutes.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W2074371713",
    "type": "article"
  },
  {
    "title": "UTPlaceF 2.0",
    "doi": "https://doi.org/10.1145/3174849",
    "publication_date": "2018-05-09",
    "publication_year": 2018,
    "authors": "Wuxi Li; Yibo Lin; Meng Li; Shounak Dhar; David Z. Pan",
    "corresponding_authors": "",
    "abstract": "Modern field-programmable gate array (FPGA) devices contain complex clock architectures on top of configurable logics. Unlike application specific integrated circuits (ASICs), the physical structure of clock networks in an FPGA is pre-manufactured and cannot be adjusted to different applications. Furthermore, clock routing resources are typically limited for high-utilization designs. Consequently, clock architectures impose extra clock constraints and further complicate physical implementation tasks such as placement. Traditional ASIC placement techniques only optimize conventional design metrics such as wirelength, routability, power, and timing without clock legality consideration. It is imperative to have new techniques to honor clock constraints during placement for FPGAs. In this article, we propose a high-performance FPGA placement engine, UTPlaceF 2.0, that optimizes wirelength and routability while honoring complex clock constraints. Our proposed approaches consist of an iterative minimum-cost-flow-based cell assignment as well as a clock-aware packing for producing clock-legal yet high-quality placement solutions. UTPlaceF 2.0 won first place in the ISPD’17 clock-aware FPGA placement contest organized by Xilinx, outperforming the second- and the third-place winners by 4.0% and 10.0%, respectively, in routed wirelength with competitive runtime, on a set of industry benchmarks.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W2801898382",
    "type": "article"
  },
  {
    "title": "Time-Multiplexed FPGA Overlay Architectures",
    "doi": "https://doi.org/10.1145/3339861",
    "publication_date": "2019-07-23",
    "publication_year": 2019,
    "authors": "Xiangwei Li; Douglas L. Maskell",
    "corresponding_authors": "",
    "abstract": "This article presents a comprehensive survey of time-multiplexed (TM) FPGA overlays from the research literature. These overlays are categorized based on their implementation into two groups: processor-based overlays, as their implementation follows that of conventional silicon-based microprocessors, and; CGRA-like overlays, with either an array of interconnected processor-based functional units or medium-grained arithmetic functional units. Time-multiplexing the overlay allows it to change its behavior with a cycle-by-cycle execution of the application kernel, thus allowing better sharing of the limited FPGA hardware resource. However, most TM overlays suffer from large resource overheads, due to either the underlying processor-like architecture (for processor-based overlays) or due to the routing array and instruction storage requirements (for CGRA-like overlays). Reducing the area overhead for CGRA-like overlays, specifically that required for the routing network, and better utilizing the hard macros in the target FPGA are active areas of research.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W2963420063",
    "type": "article"
  },
  {
    "title": "Impact of Cell Failure on Reliable Cross-Point Resistive Memory Design",
    "doi": "https://doi.org/10.1145/2753759",
    "publication_date": "2015-09-28",
    "publication_year": 2015,
    "authors": "Cong Xu; Dimin Niu; Zheng Yang; Shimeng Yu; Yuan Xie",
    "corresponding_authors": "",
    "abstract": "Resistive random access memory (ReRAM) technology is an emerging candidate for next-generation nonvolatile memory (NVM) architecture due to its simple structure, low programming voltage, fast switching speed, high on/off ratio, excellent scalability, good endurance, and great compatibility with silicon CMOS technology. The most attractive of the characteristics of ReRAM is its cross-point structure, which features a 4 F 2 cell size. In a cross-point structure, the existence of sneak current and resulting voltage loss due to the wire's resistance might cause read and write failures if not designed properly. In addition, a robust ReRAM design needs to deal with both soft and hard errors. In this article, we summarize mechanisms of both soft and hard errors of ReRAM cells and propose a unified model to characterize different failure behaviors. We quantitatively analyze the impact of cell failure types on the reliability of the cross-point array. We also propose an error-resilient architecture, which avoids unnecessary writes in the hard error detection unit. Assuming constant soft error rate, our approach can extend the lifetime of ReRAM up to 75% over a design without hard error detection and up to 12% over the design with a “write-verify” detection mechanism. Our approach yields greater significant lifetime improvement when considering postcycling retention degradation.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W1983382740",
    "type": "article"
  },
  {
    "title": "Cost-effective lifetime and yield optimization for NoC-based MPSoCs",
    "doi": "https://doi.org/10.1145/2535575",
    "publication_date": "2014-03-01",
    "publication_year": 2014,
    "authors": "Brett H. Meyer; Adam S. Hartman; Donald E. Thomas",
    "corresponding_authors": "",
    "abstract": "As manufacturing processes scale, designers are increasingly dependent on techniques to mitigate manufacturing defect and permanent failure. In embedded systems-on-chip, system lifetime and yield can be increased using slack —under-utilization in execution and storage resources—so that when components are defective, data and tasks can be remapped and rescheduled. For any given system, the design space of possible slack allocations is both large and complex, consisting of every possible way to replace each component in the initial system with another from the component library. Based on the observation that useful slack is often quantized, we have developed Critical Quantity Slack Allocation (CQSA), an approach that effectively and efficiently allocates execution and storage slack to jointly optimize system yield and cost. While exploring less than 1.4% of the slack allocation design space, our approach consistently outperforms alternative slack allocation techniques to find sets of designs within 1.4% of the lifetime-cost Pareto-optimal front. When applied to yield-cost optimization, our approach again outperforms alternative techniques, exploring less than 1.62% of the design space to find sets of designs within 4.27% of the yield-cost Pareto-optimal front. One advantage of managing failure at the system level is that the same techniques that improve lifetime often also improve yield. As a result, with little modification, CQSA is further able to perform effective joint optimization of lifetime and yield, finding designs within 1.6% of the Pareto-optimal front.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W2043270555",
    "type": "article"
  },
  {
    "title": "A New Unicast-Based Multicast Scheme for Network-on-Chip Router and Interconnect Testing",
    "doi": "https://doi.org/10.1145/2821506",
    "publication_date": "2016-01-28",
    "publication_year": 2016,
    "authors": "Dong Xiang; Kele Shen",
    "corresponding_authors": "",
    "abstract": "3D technology for networks-on-chip (NOCs) becomes attractive. It is important to present an effective scheme for 3D stacked NOC router and interconnect testing. A new approach to testing of NOC routers is proposed by classifying the routers. Routers with the same number of input/output ports fall into the same class. Routers of the same class are identical if their tests are the same. A test packet is delivered to all the identical routers by a simple unicast-based multicast scheme. It is found that the depth of the consumption buffer at each router has great impact on the test delivery time because test application and test delivery for router testing cannot be handled concurrently. Test delivery must set a router to operational mode. A mathematical model is presented to evaluate the impact of consumption buffer depth on the test delivery time. A new and simple test application scheme is proposed for interconnect testing. Some interesting extensions are presented for further test time reduction and thermal considerations. Sufficient experimental results are presented by comparison with one previous method. The proposed method works for single stuck-at, transition, even small delay faults at routers, and single bridging faults at physical, consumption and injection channels.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W2262726216",
    "type": "article"
  },
  {
    "title": "Reliability-Aware Resource Allocation and Binding in High-Level Synthesis",
    "doi": "https://doi.org/10.1145/2839300",
    "publication_date": "2016-01-28",
    "publication_year": 2016,
    "authors": "Liang Chen; Mojtaba Ebrahimi; Mehdi B. Tahoori",
    "corresponding_authors": "",
    "abstract": "Soft error is nowadays a major reliability issue for nanoscale VLSI, and addressing it during high-level synthesis is essential to improve the efficiency of error mitigation. Motivated by the observation that for behavioral designs, especially control-flow intensive ones, variables and operations have non-uniform soft error vulnerabilities, we propose a novel reliability-aware allocation and binding technique to explore more effective soft error mitigation during high level synthesis. We first perform a comprehensive vulnerability analysis at the behavioral level by considering error propagation and masking in both control and data flows. Then the optimizations based on integer linear programming, as well as heuristic algorithm, are employed to incorporate the behavioral vulnerabilities into the register and functional unit binding phases to achieve cost-efficient error mitigation. The experimental results reveal that compared with the previous techniques which ignored behavioral vulnerabilities, the proposed approach can achieve up to 85% reliability improvement with the same amount of area budget in the RTL design.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W2269743125",
    "type": "article"
  },
  {
    "title": "Efficient Security Monitoring with the Core Debug Interface in an Embedded Processor",
    "doi": "https://doi.org/10.1145/2907611",
    "publication_date": "2016-05-27",
    "publication_year": 2016,
    "authors": "Jin‐Yong Lee; Ingoo Heo; Yongje Lee; Yunheung Paek",
    "corresponding_authors": "",
    "abstract": "For decades, various concepts in security monitoring have been proposed. In principle, they all in common in regard to the monitoring of the execution behavior of a program (e.g., control-flow or dataflow) running on the machine to find symptoms of attacks. Among the proposed monitoring schemes, software-based ones are known for their adaptability on the commercial products, but there have been concerns that they may suffer from nonnegligible runtime overhead. On the other hand, hardware-based solutions are recognized for their high performance. However, most of them have an inherent problem in that they usually mandate drastic changes to the internal processor architecture. More recent ones have strived to minimize such modifications by employing external hardware security monitors in the system. However, these approaches intrinsically suffer from the overhead caused by communication between the host and the external monitor. Our solution also relies on external hardware for security monitoring, but unlike the others, ours tackles the communication overhead by using the core debug interface (CDI), which is readily available in most commercial processors for debugging. We build our system simply by plugging our monitoring hardware into the processor via CDI, precluding the need for altering the processor internals. To validate the effectiveness of our approach, we implement two well-known monitoring techniques on our proposed framework: dynamic information flow tracking and branch regulation. The experimental results on our FPGA prototype show that our external hardware monitors efficiently perform monitoring tasks with negligible performance overhead, mainly with thanks to the support of CDI, which helps us reduce communication costs substantially.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W2461431977",
    "type": "article"
  },
  {
    "title": "Efficient Cache Reconfiguration Using Machine Learning in NoC-Based Many-Core CMPs",
    "doi": "https://doi.org/10.1145/3350422",
    "publication_date": "2019-09-09",
    "publication_year": 2019,
    "authors": "Subodha Charles; Alif Ahmed; Ümit Y. Ogras; Prabhat Mishra",
    "corresponding_authors": "",
    "abstract": "Dynamic cache reconfiguration (DCR) is an effective technique to optimize energy consumption in many-core architectures. While early work on DCR has shown promising energy saving opportunities, prior techniques are not suitable for many-core architectures since they do not consider the interactions and tight coupling between memory, caches, and network-on-chip (NoC) traffic. In this article, we propose an efficient cache reconfiguration framework in NoC-based many-core architectures. The proposed work makes three major contributions. First, we model a distributed directory based many-core architecture similar to Intel Xeon Phi architecture. Next, we propose an efficient cache reconfiguration framework that considers all significant components, including NoC, caches, and main memory. Finally, we propose a machine learning--based framework that can reduce the exploration time by an order of magnitude with negligible loss in accuracy. Our experimental results demonstrate 18.5% energy savings on average compared to base cache configuration.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W2972747198",
    "type": "article"
  },
  {
    "title": "Smart-Hop Arbitration Request Propagation",
    "doi": "https://doi.org/10.1145/3356235",
    "publication_date": "2019-10-14",
    "publication_year": 2019,
    "authors": "Yashar Asgarieh; Bill Lin",
    "corresponding_authors": "",
    "abstract": "SMART-based NoC designs achieve ultra-low latencies by enabling flits to traverse multiple hops within a single clock cycle. Notwithstanding the clear performance benefits, SMART-based NoCs suffer from several shortcomings: each router must arbitrate among a quadratic number of requests, which leads to high costs; each router independently makes its own arbitration decisions, which leads to a problem called false negatives that causes throughput loss. In this article, we propose a new SMART-based NoC design called SHARP that overcomes these shortcomings. Our evaluation demonstrates that SHARP increases throughput by up to 19% and average link utilization by up to 24% by avoiding false negatives. By avoiding quadratic arbitration, our evaluation further demonstrates that SHARP reduces the wiring and area overhead significantly.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W2980924672",
    "type": "article"
  },
  {
    "title": "Directed Test Generation for Activation of Security Assertions in RTL Models",
    "doi": "https://doi.org/10.1145/3441297",
    "publication_date": "2021-01-15",
    "publication_year": 2021,
    "authors": "Hasini Witharana; Yangdi Lyu; Prabhat Mishra",
    "corresponding_authors": "",
    "abstract": "Assertions are widely used for functional validation as well as coverage analysis for both software and hardware designs. Assertions enable runtime error detection as well as faster localization of errors. While there is a vast literature on both software and hardware assertions for monitoring functional scenarios, there is limited effort in utilizing assertions to monitor System-on-Chip (SoC) security vulnerabilities. We have identified common SoC security vulnerabilities and defined several classes of assertions to enable runtime checking of security vulnerabilities. A major challenge in assertion-based validation is how to activate the security assertions to ensure that they are valid. While existing test generation using model checking is promising, it cannot generate directed tests for large designs due to state space explosion. We propose an automated and scalable mechanism to generate directed tests using a combination of symbolic execution and concrete simulation of RTL models. Experimental results on diverse benchmarks demonstrate that the directed tests are able to activate security assertions non-vacuously.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W3123479826",
    "type": "article"
  },
  {
    "title": "FTT-NAS: Discovering Fault-tolerant Convolutional Neural Architecture",
    "doi": "https://doi.org/10.1145/3460288",
    "publication_date": "2021-08-12",
    "publication_year": 2021,
    "authors": "Xuefei Ning; Guangjun Ge; Wenshuo Li; Zhenhua Zhu; Yin Zheng; Xiaohong Chen; Zhen Gao; Yu Wang; Huazhong Yang",
    "corresponding_authors": "",
    "abstract": "With the fast evolvement of embedded deep-learning computing systems, applications powered by deep learning are moving from the cloud to the edge. When deploying neural networks (NNs) onto the devices under complex environments, there are various types of possible faults: soft errors caused by cosmic radiation and radioactive impurities, voltage instability, aging, temperature variations, malicious attackers, and so on. Thus, the safety risk of deploying NNs is now drawing much attention. In this article, after the analysis of the possible faults in various types of NN accelerators, we formalize and implement various fault models from the algorithmic perspective. We propose Fault-Tolerant Neural Architecture Search (FT-NAS) to automatically discover convolutional neural network (CNN) architectures that are reliable to various faults in nowadays devices. Then, we incorporate fault-tolerant training (FTT) in the search process to achieve better results, which is referred to as FTT-NAS. Experiments on CIFAR-10 show that the discovered architectures outperform other manually designed baseline architectures significantly, with comparable or fewer floating-point operations (FLOPs) and parameters. Specifically, with the same fault settings, F-FTT-Net discovered under the feature fault model achieves an accuracy of 86.2% (VS. 68.1% achieved by MobileNet-V2), and W-FTT-Net discovered under the weight fault model achieves an accuracy of 69.6% (VS. 60.8% achieved by ResNet-18). By inspecting the discovered architectures, we find that the operation primitives, the weight quantization range, the capacity of the model, and the connection pattern have influences on the fault resilience capability of NN models.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W3195959245",
    "type": "article"
  },
  {
    "title": "Implementation, Characterization and Application of Path Changing Switch based Arbiter PUF on FPGA as a lightweight Security Primitive for IoT",
    "doi": "https://doi.org/10.1145/3491212",
    "publication_date": "2021-11-17",
    "publication_year": 2021,
    "authors": "Mahabub Hasan Mahalat; Suraj Mandal; Anindan Mondal; Bibhash Sen; Rajat Subhra Chakraborty",
    "corresponding_authors": "",
    "abstract": "Secure authentication of any Internet-of-Things (IoT) device becomes the utmost necessity due to the lack of specifically designed IoT standards and intrinsic vulnerabilities with limited resources and heterogeneous technologies. Despite the suitability of arbiter physically unclonable function (APUF) among other PUF variants for the IoT applications, implementing it on field-programmable gate arrays (FPGAs) is challenging. This work presents the complete characterization of the path changing switch (PCS) 1 based APUF on two different families of FPGA, like Spartan-3E (90 nm CMOS) and Artix-7 (28 nm CMOS). A comprehensive study of the existing tuning concept for programmable delay logic (PDL) based APUF implemented on FPGA is presented, leading to establishment of its practical infeasibility. We investigate the entropy, randomness properties of the PCS based APUF suitable for practical applications, and the effect of temperature variation signifying the adequate tolerance against environmental variation. The XOR composition of PCS based APUF is introduced to boost performance and security. The robustness of the PCS based APUF against machine learning based modeling attack is evaluated, showing similar characteristics as the conventional APUF. Experimental results validate the efficacy of PCS based APUF with a little hardware footprint removing the paucity of lightweight security primitive for IoT.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W3211884787",
    "type": "article"
  },
  {
    "title": "NoC Application Mapping Optimization Using Reinforcement Learning",
    "doi": "https://doi.org/10.1145/3510381",
    "publication_date": "2022-02-18",
    "publication_year": 2022,
    "authors": "Jagadheesh Samala; P. Veda Bhanu; J. Soumya",
    "corresponding_authors": "",
    "abstract": "Application mapping is one of the early stage design processes aimed to improve the performance of Network-on-Chip. Mapping is an NP-hard problem. A massive amount of high-quality supervised data is required to solve the application mapping problem using traditional neural networks. In this article, a reinforcement learning–based neural framework is proposed to learn the heuristics of the application mapping problem. The proposed reinforcement learning–based mapping algorithm (RL-MAP) has actor and critic networks. The actor is a policy network, which provides mapping sequences. The critic network estimates the communication cost of these mapping sequences. The actor network updates the policy distribution in the direction suggested by the critic. The proposed RL-MAP is trained with unsupervised data to predict the permutations of the cores to minimize the overall communication cost. Further, the solutions are improved using the 2-opt local search algorithm. The performance of RL-MAP is compared with a few well-known heuristic algorithms, the Neural Mapping Algorithm (NMA) and message-passing neural network-pointer network-based genetic algorithm (MPN-GA). Results show that the communication cost and runtime of the RL-MAP improved considerably in comparison with the heuristic algorithms. The communication cost of the solutions generated by RL-MAP is nearly equal to MPN-GA and improved by 4.2% over NMA, while consuming less runtime.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W4213170889",
    "type": "article"
  },
  {
    "title": "ESPSim: An Efficient Scalable Power Grid Simulator Based on Parallel Algebraic Multigrid",
    "doi": "https://doi.org/10.1145/3529533",
    "publication_date": "2022-05-19",
    "publication_year": 2022,
    "authors": "Chunqiao Li; Chengtao An; Fan Yang; Xuan Zeng",
    "corresponding_authors": "",
    "abstract": "Fast verification for the extremely large-scale power grid is demanding as CMOS technology advances consistently. In this work, we propose ESPSim, an efficient scalable power grid simulator based on a parallel smoothed aggregation-based algebraic multigrid technique. ESPSim has the ability to do fast DC and transient analysis through MPI and adaptive timestep control mechanism. Thanks to the smoother applied on the prolongation operator, ESPSim copes well with the convergence rate on extremely large-scale power grid transient analysis. Extensive experiments are conducted with a variety of serial/parallel solvers. The runtime of ESPSim is linear with case size. With 16 processors, 1,000 timesteps transient analysis of 63.4M nodes can be completed in 22.1 min. Over 22× speedup compared to the well-known direct solver Cholmod is observed.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W4280562550",
    "type": "article"
  },
  {
    "title": "Auto-tuning Fixed-point Precision with TVM on RISC-V Packed SIMD Extension",
    "doi": "https://doi.org/10.1145/3569939",
    "publication_date": "2022-11-02",
    "publication_year": 2022,
    "authors": "Chun‐Chieh Yang; Yi-Ru Chen; Hui-Hsin Liao; Yuan‐Ming Chang; Jenq‐Kuen Lee",
    "corresponding_authors": "",
    "abstract": "Today, as deep learning (DL) is applied more often in daily life, dedicated processors such as CPUs and GPUs have become very important for accelerating model executions. With the growth of technology, people are becoming accustomed to using edge devices, such as mobile phones, smart watches, and VR devices in their daily lives. A variety of technologies using DL are gradually being applied to these edge devices. However, there is a large number of computations in DL. It faces a challenging problem how to provide solutions in the edge devices. In this article, the proposed method enables a flow with the RISC-V Packed extension (P extension) in TVM. TVM, an open deep learning compiler for neural network models, is growing as a key infrastructure for DL computing. RISC-V is an open instruction set architecture (ISA) with customized and flexible features. The Packed-SIMD extension is a RISC-V extension that enables subword single-instruction multiple-data (SIMD) computations in RISC-V architectures to support fallback engines in AI computing. In the proposed flow, a fixed-point type that is supported by an integer of 16-bit type and saturation instructions is added to replace the original 32-bit float type. In addition, an auto-tuning method is proposed to use a uniform selector mechanism (USM) to find the binary point position for fixed-point type use. The tensorization feature of TVM can be used to optimize specific hardware such as subword SIMD instructions with RISC-V P extension. With our experiment on the Spike simulator, the proposed method with the USM can improve performance by approximately 2.54 to 6.15× in terms of instruction counts with little accuracy loss.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W4307922031",
    "type": "article"
  },
  {
    "title": "A Machine Learning Approach to Improving Timing Consistency between Global Route and Detailed Route",
    "doi": "https://doi.org/10.1145/3626959",
    "publication_date": "2023-10-10",
    "publication_year": 2023,
    "authors": "Vidya A. Chhabria; Wenjing Jiang; Andrew B. Kahng; Sachin S. Sapatnekar",
    "corresponding_authors": "",
    "abstract": "Due to the unavailability of routing information in design stages prior to detailed routing (DR), the tasks of timing prediction and optimization pose major challenges. Inaccurate timing prediction wastes design effort, hurts circuit performance, and may lead to design failure. This work focuses on timing prediction after clock tree synthesis and placement legalization, which is the earliest opportunity to time and optimize a “complete” netlist. The article first documents that having “oracle knowledge” of the final post-DR parasitics enables post-global routing (GR) optimization to produce improved final timing outcomes. To bridge the gap between GR-based parasitic and timing estimation and post-DR results during post-GR optimization , machine learning (ML)-based models are proposed, including the use of features for macro blockages for accurate predictions for designs with macros. Based on a set of experimental evaluations, it is demonstrated that these models show higher accuracy than GR-based timing estimation. When used during post-GR optimization, the ML-based models show demonstrable improvements in post-DR circuit performance. The methodology is applied to two different tool flows—OpenROAD and a commercial tool flow—and results on an open-source 45nm bulk and a commercial 12nm FinFET enablement show improvements in post-DR timing slack metrics without increasing congestion. The models are demonstrated to be generalizable to designs generated under different clock period constraints and are robust to training data with small levels of noise.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W4387502444",
    "type": "article"
  },
  {
    "title": "Dynamic state traversal for sequential circuit test generation",
    "doi": "https://doi.org/10.1145/348019.348288",
    "publication_date": "2000-07-01",
    "publication_year": 2000,
    "authors": "Michael S. Hsiao; E.M. Rudnick; J.H. Patel",
    "corresponding_authors": "",
    "abstract": "A new method for state justification is proposed for sequential circuit test generation. The linear list of states dynamically obtained during the derivation of test vectors is used to guide the search during state justification. State-transfer sequences that drive the circuit from the current state to the target state may already be known. Otherwise, genetic engineering of existing state-transfer sequences is required. In both cases, genetic-algorithm-based techniques are used to generate valid state justification sequences for the circuit in the presence of the target fault. This approach achieves extremely high fault coverages, and thus outperforms previous deterministic and simulation-based techniques.",
    "cited_by_count": 37,
    "openalex_id": "https://openalex.org/W1965514683",
    "type": "article"
  },
  {
    "title": "Graph-based code selection techniques for embedded processors",
    "doi": "https://doi.org/10.1145/362652.362661",
    "publication_date": "2000-10-01",
    "publication_year": 2000,
    "authors": "Rainer Leupers; Steven Bashford",
    "corresponding_authors": "",
    "abstract": "Code selection is an important task in code generation for programmable processors, where the goal is to find an efficient mapping of machine-independent intermediate code to processor-specific machine instructions. Traditional approaches to code selection are based on tree parsing which enables fast and optimal code selection for intermediate code given as a set of data-flow trees. While this approach is generally useful in compilers for general-purpose processors, it may lead to poor code quality in the case of embedded processors. The reason is that the special architectural features of embedded processors require performing code selection on data-flow graphs, which are a more general representation of intermediate code. In this paper, we present data-flow graph-based code selection techniques for two architectural families of embedded processors: media processors with support for SIMD instructions and fixed-point DSPs with irregular data paths. Both techniques exploit the fact that, in the area of embedded systems, high code quality is a much more important goal than high compilation speed. We demonstrate that certain architectural features can only be utilized by graph-based code selection, while in other cases this approach leads to a significant increase in code quality as compared to tree-based code selection.",
    "cited_by_count": 37,
    "openalex_id": "https://openalex.org/W2059056208",
    "type": "article"
  },
  {
    "title": "Design theory and implementation for low-power segmented bus systems",
    "doi": "https://doi.org/10.1145/606603.606606",
    "publication_date": "2003-01-01",
    "publication_year": 2003,
    "authors": "W.B. Jone; J. S. Wang; Hsueh-I Lu; I. P. Hsu; J.-Y. Chen",
    "corresponding_authors": "",
    "abstract": "The concept of bus segmentation has been proposed to minimize power consumption by reducing the switched capacitance on each bus [Chen et al. 1999]. This paper details the design theory and implementation issues of segmented bus systems. Based on a graph model and the Gomory-Hu cut-equivalent tree algorithm, a bus can be partitioned into several bus segments separated by pass transistors. Highly communicating devices are placed to adjacent bus segments, so most data communication can be achieved by switching a small portion of the bus segments. Thus, a significant amount of power consumption can be saved. It can be proved that the proposed bus partitioning method achieves an optimal solution. The concept of tree clustering is also proposed to merge bus segments for further power reduction. The design flow, which includes bus tree construction in the register-transfer level and bus segmentation cell placement and routing in the physical level, is discussed for design implementation. The technology has been applied to a μ-controller design, and simulation results by PowerMill show significant improvement in power consumption.",
    "cited_by_count": 35,
    "openalex_id": "https://openalex.org/W2078622522",
    "type": "article"
  },
  {
    "title": "A fast approach to computing exact solutions to the resource-constrained scheduling problem",
    "doi": "https://doi.org/10.1145/502175.502178",
    "publication_date": "2001-10-01",
    "publication_year": 2001,
    "authors": "Mukund Narasimhan; J. Ramanujam",
    "corresponding_authors": "",
    "abstract": "This article presents an algorithm that substantially reduces the computational effort required to obtain the exact solution to the Resource Constrained Scheduling (RCS) problem. The reduction is obtained by (a) using a branch-and-bound search technique, which computes both upper and lower bounds, and (b) using efficient techniques to accurately estimate the possible time-steps at which each operation can be scheduled and using this to prune the search space. Results on several benchmarks with varying resource constraints indicate the clear superiority of the algorithm presented here over traditional approaches using integer linear programming, with speed-ups of several orders of magnitude.",
    "cited_by_count": 34,
    "openalex_id": "https://openalex.org/W2154593868",
    "type": "article"
  },
  {
    "title": "Achieving high encoding efficiency with partial dynamic LFSR reseeding",
    "doi": "https://doi.org/10.1145/1027084.1027089",
    "publication_date": "2004-10-01",
    "publication_year": 2004,
    "authors": "C. Vamsi Krishna; Abhijit Jas; Nur A. Touba",
    "corresponding_authors": "",
    "abstract": "Previous forms of LFSR reseeding have been static (i.e., test application is stopped while each seed is loaded) and have required full reseeding (i.e., the length of the seed is equal to the length of the LFSR). A new form of LFSR reseeding is described here that is dynamic (i.e., the seed is incrementally modified while test application proceeds) and allows partial reseeding (i.e. length of the seed is less than that of the LFSR). In addition to providing better encoding efficiency, partial dynamic LFSR reseeding has a simpler hardware implementation than previous schemes based on multiple-polynomial LFSRs.",
    "cited_by_count": 33,
    "openalex_id": "https://openalex.org/W2005440997",
    "type": "article"
  },
  {
    "title": "Accurate modeling of substrate resistive coupling for floating substrates",
    "doi": "https://doi.org/10.1145/1124713.1124717",
    "publication_date": "2006-01-01",
    "publication_year": 2006,
    "authors": "Qing Su; Jamil Kawa; Charles Chiang; Yehia Massoud",
    "corresponding_authors": "",
    "abstract": "This article focuses on the formulation of the substrate resistive coupling using boundary element methods, specifically for substrates without grounded backplates (floating substrates). An accurate and numerically stable formulation is presented. Numerical results are shown to demonstrate the correctness and the numerical robustness of the formulation.",
    "cited_by_count": 30,
    "openalex_id": "https://openalex.org/W1965558067",
    "type": "article"
  },
  {
    "title": "A two-layer library-based approach to synthesis of analog systems from VHDL-AMS specifications",
    "doi": "https://doi.org/10.1145/989995.990000",
    "publication_date": "2004-04-01",
    "publication_year": 2004,
    "authors": "Alex Doboli; Nagu Dhanwada; A. Nunez-Aldana; Ranga Vemuri",
    "corresponding_authors": "",
    "abstract": "This paper presents a synthesis methodology for analog systems described using VHDL-AMS language. Synthesis produces net-lists of analog components that are selected from a library, and sized so that specified objectives (like AC response, signal to noise ratio, dynamic range, area) are optimized. The gap between abstract specifications and implementations is bridged using a two-layered methodology. The first layer is architecture generation. The second layer is component synthesis and constraint transformation. Architecture generation employs the branch-and-bound algorithm to create architectural alternatives for a system. Component synthesis and constraint transformation use a directed interval based genetic algorithm that operates on parameter ranges. The performance estimation engine embeds technology process parameters, SPICE models for basic circuits, and symbolic composition equations for basic structural configurations. The paper discusses the VHDL-AMS subset for synthesis. The subset offers the composition semantics. As a result, specifications offer sufficient insight into the system structure to allow automated architecture generation. To justify the flexibility of the methodology, the paper presents results for three case studies, a signal conditioning system, a filter, and an analog to digital converter. Experiments show that constraint-satisfying designs can be synthesized in a short time, at a low cost, and without requesting broad knowledge on analog circuits.",
    "cited_by_count": 30,
    "openalex_id": "https://openalex.org/W1998571609",
    "type": "article"
  },
  {
    "title": "Computation and communication refinement for multiprocessor SoC design",
    "doi": "https://doi.org/10.1145/1142980.1142983",
    "publication_date": "2004-06-07",
    "publication_year": 2004,
    "authors": "Radu Mărculescu; Ümit Y. Ogras; Nicholas H. Zamora",
    "corresponding_authors": "",
    "abstract": "Continuous advancements in semiconductor technology enable the design of complex systems-on-chips (SoCs) composed of tens or hundreds of IP cores. At the same time, the applications that need to run on such platforms have become increasingly complex and have tight power and performance requirements. Achieving a satisfactory design quality under these circumstances is only possible when both computation and communication refinement are performed efficiently, in an automated and synergistic manner. Consequently, formal and disciplined system-level design methodologies are in great demand for future multiprocessor design. This article provides a broad overview of some fundamental research issues and state-of-the-art solutions concerning both computation and communication aspects of system-level design. The methodology we advocate consists of developing abstract application and platform models, followed by application mapping onto the target platform, and then optimizing the overall system via performance analysis. In addition, a communication refinement step is critical for optimizing the communication infrastructure in this multiprocessor setup. Finally, simulation and prototyping can be used for accurate performance evaluation purposes.",
    "cited_by_count": 30,
    "openalex_id": "https://openalex.org/W2028417466",
    "type": "article"
  },
  {
    "title": "Architecture description language (ADL)-driven software toolkit generation for architectural exploration of programmable SOCs",
    "doi": "https://doi.org/10.1145/1142980.1142985",
    "publication_date": "2004-06-07",
    "publication_year": 2004,
    "authors": "Prabhat Mishra; Aviral Shrivastava; Nikil Dutt",
    "corresponding_authors": "",
    "abstract": "Advances in semiconductor technology permit increasingly complex applications to be realized using programmable systems-on-chips (SOCs). Furthermore, shrinking time-to-market demands, coupled with the need for product versioning through software modification of SOC platforms, have led to a significant increase in the software content of these SOCs. However, designer productivity is greatly hampered by the lack of automated software generation tools for the exploration and evaluation of different architectural configurations. Traditional hardware-software codesign flows do not support effective exploration and customization of the embedded processors used in programmable SOCs. The inherently application-specific nature of embedded processors and the stringent area, power, and performance constraints in embedded systems design critically require a fast and automated architecture exploration methodology. Architecture description language (ADL)-Driven design space exploration and software toolkit generation strategies present a viable solution to this problem, providing a systematic mechanism for a top-down design and validation of complex systems. The heart of this approach lies in the ability to automatically generate a software toolkit that includes an architecture-sensitive compiler, a cycle-accurate simulator, assembler, debugger, and verification/validation tools. This article illustrates a software toolkit generation methodology using the EXPRESSION ADL. Our exploration studies demonstrate the need for and usefulness of this approach, using as an example the problem of compiler-in-the-loop design space exploration of reduced instruction-set embedded processor architectures.",
    "cited_by_count": 29,
    "openalex_id": "https://openalex.org/W2022224635",
    "type": "article"
  },
  {
    "title": "Technology mapping and architecture evalution for <i>k/m</i> -macrocell-based FPGAs",
    "doi": "https://doi.org/10.1145/1044111.1044113",
    "publication_date": "2005-01-01",
    "publication_year": 2005,
    "authors": "Jason Cong; Hui Huang; Xin Yuan",
    "corresponding_authors": "",
    "abstract": "In this article, we study the technology mapping problem for a novel field-programmable gate array (FPGA) architecture that is based on k -input single-output programmable logic array- (PLA-) like cells, or, k/m -macrocells. Each cell in this architecture can implement a single output function of up to k inputs and up to m product terms. We develop a very efficient technology mapping algorithm, k_m_flow, for this new type of architecture. The experimental results show that our algorithm can achieve depth-optimality on almost all the testcases in a set of 16 Microelectronics Center of North Carolina (MCNC) benchmarks. Furthermore it is shown that on this set of benchmarks, with only a relatively small number of product terms ( m ≤ k + 3), the k/m -macrocell-based FPGAs can achieve the same or similar mapping depth compared with the traditional k -input single-output lookup table- ( k -LUT-) based FPGAs. We also investigate the total area and delay of k/m -macrocell-based FPGAs and compare them with those of the commonly used 4-LUT-based FPGAs. The experimental results show that k/m -macrocell-based FPGAs can outperform 4-LUT-based FPGAs in terms of both delay and area after placement and routing by VPR on this set of benchmarks.",
    "cited_by_count": 28,
    "openalex_id": "https://openalex.org/W2112037954",
    "type": "article"
  },
  {
    "title": "An interactive codesign environment for domain-specific coprocessors",
    "doi": "https://doi.org/10.1145/1124713.1124719",
    "publication_date": "2006-01-01",
    "publication_year": 2006,
    "authors": "Patrick Schaumont; Doris Ching; Ingrid Verbauwhede",
    "corresponding_authors": "",
    "abstract": "Energy-efficient embedded systems rely on domain-specific coprocessors for dedicated tasks such as baseband processing, video coding, or encryption. We present a language and design environment called GEZEL that can be used for the design, verification and implementation of such coprocessor-based systems.The GEZEL environment creates a platform simulator by combining a hardware simulation kernel with one or more instruction-set simulators. The hardware part of the platform is programmed in GEZEL, a deterministic, cycle-true and implementation-oriented hardware description language. GEZEL designs are scripted, allowing the hardware configuration of the platform simulator to be changed quickly without going through lengthy recompiles. For this reason, we call the environment interactive. We present the execution ladder as an optimization framework to balance interactivity against simulation speed.We demonstrate our approach using several designs including an AES encryption coprocessor and a Viterbi decoding coprocessor. We discuss the advantages of our approach as opposed to more conventional approaches using SystemC and Verilog/VHDL.",
    "cited_by_count": 28,
    "openalex_id": "https://openalex.org/W2157740678",
    "type": "article"
  },
  {
    "title": "Optimal simultaneous module and multivoltage assignment for low power",
    "doi": "https://doi.org/10.1145/1142155.1142161",
    "publication_date": "2006-04-01",
    "publication_year": 2006,
    "authors": "Deming Chen; Jason Cong; Junjuan Xu",
    "corresponding_authors": "",
    "abstract": "Reducing power consumption through high-level synthesis has attracted a growing interest from researchers due to its large potential for power reduction. In this work we study functional unit binding (or module assignment) given a scheduled data flow graph under a multi-Vdd framework. We assume that each functional unit can be driven by different Vdd levels dynamically during run time to save dynamic power. We develop a polynomial-time optimal algorithm for assigning low Vdds to as many operations as possible under the resource and latency constraints, and in the same time minimizing total switching activity through functional unit binding. Our algorithm shows consistent improvement over a design flow that separates voltage assignment from functional unit binding. We also change the initial scheduling to examine power/energy-latency tradeoff scenarios under different voltage level combinations. Experimental results show that we can achieve 28.1% and 33.4% power reductions when the latency bound is the tightest with two and three-Vdd levels respectively compared with the single-Vdd case. When latency is relaxed, multi-Vdd offers larger power reductions (up to 46.7%). We also show comparison data of energy consumption under the same experimental settings.",
    "cited_by_count": 27,
    "openalex_id": "https://openalex.org/W2151929849",
    "type": "article"
  },
  {
    "title": "Statistical timing analysis using levelized covariance propagation considering systematic and random variations of process parameters",
    "doi": "https://doi.org/10.1145/1179461.1179464",
    "publication_date": "2006-10-01",
    "publication_year": 2006,
    "authors": "Kunhyuk Kang; Bipul C. Paul; Kaushik Roy",
    "corresponding_authors": "",
    "abstract": "Variability in process parameters is making accurate timing analysis of nano-scale integrated circuits an extremely challenging task. In this article, we propose a new algorithm for statistical static timing analysis (SSTA) using levelized covariance propagation (LCP). The algorithm simultaneously considers the effect of die-to-die variations in process parameters as well as within-die variation, including systematic and random variations. In order to efficiently handle complicated process variation models while contending with the arbitrary correlation among timing signals, we employ a compact form of the levelized statistical data structure. Furthermore, we propose two enhancements to the LCP algorithms to the make it practical for the analysis of large sized circuits. Results on several ISCAS'85 benchmark circuits in predictive 70nm technology show an average of 0.19% and 0.57% errors in the mean and standard deviation, respectively, of timing analysis using the proposed technique, as compared to the Monte Carlo-based approach.",
    "cited_by_count": 27,
    "openalex_id": "https://openalex.org/W2172181553",
    "type": "article"
  },
  {
    "title": "Binary synthesis",
    "doi": "https://doi.org/10.1145/1255456.1255471",
    "publication_date": "2007-08-17",
    "publication_year": 2007,
    "authors": "Greg Stitt; Frank Vahid",
    "corresponding_authors": "",
    "abstract": "Recent high-level synthesis approaches and C-based hardware description languages attempt to improve the hardware design process by allowing developers to capture desired hardware functionality in a well-known high-level source language. However, these approaches have yet to achieve wide commercial success due in part to the difficulty of incorporating such approaches into software tool flows. The requirement of using a specific language, compiler, or development environment may cause many software developers to resist such approaches due to the difficulty and possible instability of changing well-established robust tool flows. Thus, in the past several years, synthesis from binaries has been introduced, both in research and in commercial tools, as a means of better integrating with tool flows by supporting all high-level languages and software compilers. Binary synthesis can be more easily integrated into a software development tool-flow by only requiring an additional backend tool, and it even enables completely transparent dynamic translation of executing binaries to configurable hardware circuits. In this article, we survey the key technologies underlying the important emerging field of binary synthesis. We compare binary synthesis to several related areas of research, and we then describe the key technologies required for effective binary synthesis: decompilation techniques necessary for binary synthesis to achieve results competitive with source-level synthesis, hardware/software partitioning methods necessary to find critical binary regions suitable for synthesis, synthesis methods for converting regions to custom circuits, and binary update methods that enable replacement of critical binary regions by circuits.",
    "cited_by_count": 27,
    "openalex_id": "https://openalex.org/W2293916051",
    "type": "article"
  },
  {
    "title": "A tool for automatic detection of deadlock in wormhole networks on chip",
    "doi": "https://doi.org/10.1145/1297666.1297672",
    "publication_date": "2008-01-01",
    "publication_year": 2008,
    "authors": "Sami Taktak; Jean-Lou Desbarbieux; Emmanuelle Encrenaz",
    "corresponding_authors": "",
    "abstract": "We present an extension of Duato's necessary and sufficient condition a routing function must satisfy in order to be deadlock-free, to support environment constraints inducing extra-dependencies between messages. We also present an original algorithm to automatically check the deadlock-freeness of a network with a given routing function. A prototype tool has been developed and automatic deadlock checking of large scale networks with various routing functions have been successfully achieved. We provide comparative results with standard approach, highlighting the benefits of our method.",
    "cited_by_count": 26,
    "openalex_id": "https://openalex.org/W2081911632",
    "type": "article"
  },
  {
    "title": "Temporal floorplanning using the three-dimensional transitive closure subGraph",
    "doi": "https://doi.org/10.1145/1278349.1278350",
    "publication_date": "2007-09-01",
    "publication_year": 2007,
    "authors": "Ping-Hung Yuh; Chia-Lin Yang; Yao‐Wen Chang",
    "corresponding_authors": "",
    "abstract": "Improving logic capacity by time-sharing, dynamically reconfigurable Field Gate Programmable Arrays (FPGAs) are employed to handle designs of high complexity and functionality. In this paper, we use a novel graph-based topological floorplan representation, named 3D-subTCG (3-Dimensional Transitive Closure subGraph), to deal with the 3-dimensional (temporal) floorplanning/placement problem, arising from dynamically reconfigurable FPGAs. The 3D-subTCG uses three transitive closure graphs to model the temporal and spatial relations between modules. We derive the feasibility conditions for the precedence constraints induced by the execution of the dynamically reconfigurable FPGAs. Because the geometric relationship is transparent to the 3D-subTCG and its induced operations (i.e., we can directly detect the relationship between any two tasks from the representation), we can easily detect any violation of the temporal precedence constraints on 3D-subTCG. We also derive important properties of the 3D-subTCG to reduce the solution space and shorten the running time for 3D (temporal) foorplanning/placement. Experimental results show that our 3D-subTCG-based algorithm is very effective and efficient.",
    "cited_by_count": 25,
    "openalex_id": "https://openalex.org/W2030767815",
    "type": "article"
  },
  {
    "title": "A compiler approach to managing storage and memory bandwidth in configurable architectures",
    "doi": "https://doi.org/10.1145/1391962.1391969",
    "publication_date": "2008-09-01",
    "publication_year": 2008,
    "authors": "Nastaran Baradaran; Pedro C. Diniz",
    "corresponding_authors": "",
    "abstract": "Configurable architectures offer the unique opportunity of realizing hardware designs tailored to the specific data and computational patterns of an application code. Customizing the storage structures is becoming increasingly important in mitigating the continuing gap between memory latencies and internal computing speeds. In this article we describe and evaluate a compiler algorithm that maps the arrays of a loop-based computation to internal storage structures, either RAM blocks or discrete registers. Our objective is to minimize the overall execution time while considering the capacity and bandwidth constraints of the storage resources. The novelty of our approach lies in creating a single framework that combines high-level compiler techniques with lower-level scheduling information for mapping the data. We illustrate the benefits of our approach for a set of image/signal processing kernels using a Xilinx Virtex™ Field-Programmable Gate Array (FPGA). Our algorithm leads to faster designs compared to the state-of-the-art custom data layout mapping technique, in some instances using less storage. When compared to hand-coded designs, our results are comparable in terms of execution time and resources, but are derived in a minute fraction of the design time.",
    "cited_by_count": 24,
    "openalex_id": "https://openalex.org/W2012687750",
    "type": "article"
  },
  {
    "title": "Efficiently scheduling runtime reconfigurations",
    "doi": "https://doi.org/10.1145/1391962.1391966",
    "publication_date": "2008-09-01",
    "publication_year": 2008,
    "authors": "Javier Resano; Juan Antonio Clemente; Carlos González; Daniel Mozos; Francky Catthoor",
    "corresponding_authors": "",
    "abstract": "Due to the emergence of portable devices that must run complex dynamic applications there is a need for flexible platforms for embedded systems. Runtime reconfigurable hardware can provide this flexibility but the reconfiguration latency can significantly decrease the performance. When dealing with task graphs, runtime support that schedules the reconfigurations in advance can drastically reduce this overhead. However, executing complex scheduling heuristics at runtime may generate an excessive penalty. Hence, we have developed a hybrid design-time/runtime reconfiguration scheduling heuristic that generates its final schedule at runtime but carries out most computations at design-time. We have tested our approach in a PowerPC 405 processor embedded on a FPGA demonstrating that it generates a very small runtime penalty while providing almost as good schedules as a full runtime approach.",
    "cited_by_count": 24,
    "openalex_id": "https://openalex.org/W2035415936",
    "type": "article"
  },
  {
    "title": "Schedulability analysis of preemptive and nonpreemptive EDF on partial runtime-reconfigurable FPGAs",
    "doi": "https://doi.org/10.1145/1391962.1391964",
    "publication_date": "2008-09-01",
    "publication_year": 2008,
    "authors": "Nan Guan; Qingxu Deng; Zonghua Gu; Wenyao Xu; Ge Yu",
    "corresponding_authors": "",
    "abstract": "Field Programmable Gate Arrays (FPGAs) are very popular in today's embedded systems design, and Partial Runtime-Reconfigurable (PRTR) FPGAs allow HW tasks to be placed and removed dynamically at runtime. Hardware task scheduling on PRTR FPGAs brings many challenging issues to traditional real-time scheduling theory, which have not been adequately addressed by the research community compared to software task scheduling on CPUs. In this article, we consider the schedulability analysis problem of HW task scheduling on PRPR FPGAs. We derive utilization bounds for several variants of global preemptive/nonpreemptive EDF scheduling, and compare the performance of different utilization bound tests.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W2004274762",
    "type": "article"
  },
  {
    "title": "Simultaneous resource binding and interconnection optimization based on a distributed register-file microarchitecture",
    "doi": "https://doi.org/10.1145/1529255.1529257",
    "publication_date": "2009-05-01",
    "publication_year": 2009,
    "authors": "Jason Cong; Yiping Fan; Junjuan Xu",
    "corresponding_authors": "",
    "abstract": "Behavior synthesis and optimization beyond the register-transfer level require an efficient utilization of the underlying platform features. This article presents a platform-based resource binding approach based on a Distributed Register-File Microarchitecture (DRFM) , which makes efficient use of distributed embedded memory blocks as register files in modern FPGAs. DRFM contains multiple islands, each having a local register file, a functional unit pool, and data-routing logic. Compared to the traditional discrete-register counterpart, a DRFM allows use of the platform-featured on-chip memory or register-file IP blocks to implement its local register files, and this results in a substantial saving of multiplexing logic and global interconnects. DRFM provides a useful architectural template and a direct optimization objective for minimizing interisland connections for synthesis algorithms. Given the scheduling solution and resource (functional units) constraints, two novel algorithms in the resource binding stage are developed based on DRFM: (i) a simultaneous DRFM clustering and binding algorithm, which decides the configuration of DRFM and the assignment of operations into islands with the focus on optimizing global connections; (ii) a data-forwarding scheduling algorithm, which takes advantage of the operation slacks to handle the read-port restriction of register files. On the Xilinx Virtex4 FPGA platform, experimental results with a set of real-life test cases show a 50% logic area reduction achieved by applying our approach, with a 14.6% performance improvement, compared to the traditional discrete-register-based approach. Also, experiments on small-size designs show that our algorithm produces the same number of total connections and at most one more maximum feeding-in connection compared to optimal solutions generated by ILP.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W2040253151",
    "type": "article"
  },
  {
    "title": "FPGA-based hardware acceleration for Boolean satisfiability",
    "doi": "https://doi.org/10.1145/1497561.1497576",
    "publication_date": "2009-03-01",
    "publication_year": 2009,
    "authors": "Kanupriya Gulati; Suganth Paul; Sunil P. Khatri; Srinivas Patil; Abhijit Jas",
    "corresponding_authors": "",
    "abstract": "We present an FPGA-based hardware solution to the Boolean satisfiability (SAT) problem, with the main goals of scalability and speedup. In our approach the traversal of the implication graph as well as conflict clause generation are performed in hardware, in parallel. The experimental results and their analysis, along with the performance models are discussed. We show that an order of magnitude improvement in runtime can be obtained over MiniSAT (the best-in-class software based approach) by using a Virtex-4 (XC4VFX140) FPGA device. The resulting system can handle instances with as many as 10K variables and 280K clauses.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W1979411114",
    "type": "article"
  },
  {
    "title": "Efficient error detection codes for multiple-bit upset correction in SRAMs with BICS",
    "doi": "https://doi.org/10.1145/1455229.1455247",
    "publication_date": "2009-01-01",
    "publication_year": 2009,
    "authors": "Pedro Reviriego; Juan Antonio Maestro",
    "corresponding_authors": "",
    "abstract": "Memories are one of the most widely used elements in electronic systems, and their reliability when exposed to Single Events Upsets (SEUs) has been studied extensively. As transistor sizes shrink, Multiple Bits Upsets (MBUs) are becoming an increasingly important factor in the reliability of memories exposed to radiation effects. To address this issue, Built-in Current Sensors (BICS) have recently been applied in conjunction with Single Error Correction/Double Error Detection (SEC-DED) codes to protect memories from MBUs. In this article, this approach is taken one step further, proposing specific codes optimized to be combined with BICS to provide protection against MBUs in memories. By exploiting the locality of errors within an MBU and the error detection and location capabilities of BICS, the proposed codes result in both a better protection level and a reduced cost compared with the existing SEC-DED approach.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W2050320264",
    "type": "article"
  },
  {
    "title": "Efficient partial scan cell gating for low-power scan-based testing",
    "doi": "https://doi.org/10.1145/1497561.1497571",
    "publication_date": "2009-03-01",
    "publication_year": 2009,
    "authors": "Xrysovalantis Kavousianos; D. Bakalis; Dimitris Nikolos",
    "corresponding_authors": "",
    "abstract": "Gating of the outputs of a portion of the scan cells (partial gating) has been recently proposed as a method for reducing the dynamic power dissipation during scan-based testing. We present a new systematic method for selecting, under area and performance design constraints, the most suitable for gating subset of scan cells as well as the proper gating value for each one of them, aiming at the reduction of the average switching activity during testing. We show that the proposed method outperforms the corresponding already known methods, with respect to average dynamic power dissipation reduction.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W1987649265",
    "type": "article"
  },
  {
    "title": "Huffman-based code compression techniques for embedded processors",
    "doi": "https://doi.org/10.1145/1835420.1835424",
    "publication_date": "2010-09-01",
    "publication_year": 2010,
    "authors": "Talal Bonny; Jörg Henkel",
    "corresponding_authors": "",
    "abstract": "The size of embedded software is increasing at a rapid pace. It is often challenging and time consuming to fit an amount of required software functionality within a given hardware resource budget. Code compression is a means to alleviate the problem by providing substantial savings in terms of code size. In this article we introduce a novel and efficient hardware-supported compression technique that is based on Huffman Coding. Our technique reduces the size of the generated decoding table, which takes a large portion of the memory. It combines our previous techniques, Instruction Splitting Technique and Instruction Re-encoding Technique into new one called Combined Compression Technique to improve the final compression ratio by taking advantage of both previous techniques. The instruction Splitting Technique is instruction set architecture (ISA)-independent. It splits the instructions into portions of varying size (called patterns) before Huffman coding is applied. This technique improves the final compression ratio by more than 20% compared to other known schemes based on Huffman Coding. The average compression ratios achieved using this technique are 48% and 50% for ARM and MIPS, respectively. The Instruction Re-encoding Technique is ISA-dependent. It investigates the benefits of reencoding unused bits (we call them reencodable bits) in the instruction format for a specific application to improve the compression ratio. Reencoding those bits can reduce the size of decoding tables by up to 40%. Using this technique, we improve the final compression ratios in comparison to the first technique to 46% and 45% for ARM and MIPS, respectively (including all overhead that incurs). The Combined Compression Technique improves the compression ratio to 45% and 42% for ARM and MIPS, respectively. In our compression technique, we have conducted evaluations using a representative set of applications and we have applied each technique to two major embedded processor architectures, namely ARM and MIPS.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W2082921940",
    "type": "article"
  },
  {
    "title": "Optimization Algorithms for the Multiplierless Realization of Linear Transforms",
    "doi": "https://doi.org/10.1145/2071356.2071359",
    "publication_date": "2012-01-01",
    "publication_year": 2012,
    "authors": "Levent Aksoy; Eduardo Costa; Paulo Flores; José Monteiro",
    "corresponding_authors": "",
    "abstract": "This article addresses the problem of finding the fewest numbers of addition and subtraction operations in the multiplication of a constant matrix with an input vector---a fundamental operation in many linear digital signal processing transforms. We first introduce an exact common subexpression elimination (CSE) algorithm that formalizes the minimization of the number of operations as a 0-1 integer linear programming problem. Since there are still instances that the proposed exact algorithm cannot handle due to the NP-completeness of the problem, we also introduce a CSE heuristic algorithm that iteratively finds the most common 2-term subexpressions with the minimum conflicts among the expressions. Furthermore, since the main drawback of CSE algorithms is their dependency on a particular number representation, we propose a hybrid algorithm that initially finds promising realizations of linear transforms using a numerical difference method, and then applies the proposed CSE algorithm to utilize the common subexpressions iteratively. The experimental results on a comprehensive set of instances indicate that the proposed approximate algorithms find competitive results with those of the exact CSE algorithm and obtain better solutions than the prominent, previously proposed, heuristics. It is also observed that our solutions yield significant area reductions in the design of linear transforms after circuit synthesis, compared to direct realizations of linear transforms.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W1971659206",
    "type": "article"
  },
  {
    "title": "Exploiting Chip Idleness for Minimizing Garbage Collection—Induced Chip Access Conflict on SSDs",
    "doi": "https://doi.org/10.1145/3131850",
    "publication_date": "2017-10-05",
    "publication_year": 2017,
    "authors": "Congming Gao; Liang Shi; Yejia Di; Qiao Li; Chun Jason Xue; Kaijie Wu; Edwin H.‐M. Sha",
    "corresponding_authors": "",
    "abstract": "Solid state drives (SSDs) are normally constructed with a number of parallel-accessible flash chips, where host I/O requests are processed in parallel. In addition, there are many internal activities in SSDs, such as garbage collection and wear leveling induced read, write, and erase operations, to solve the issues of inability of in-place updates and limited lifetime. When internal activities are triggered on a chip, the chip will be blocked. Our preliminary studies on several workloads show that when internal activities are frequently triggered, the host I/O performance will be significantly impacted because of the access conflict between them. In this work, in order to improve the access conflict induced performance degradation, a novel access conflict minimization scheme is proposed. The basic idea of the scheme is motivated by an interesting observation in SSDs: several chips are idle when other chips are busy with internal activities and host I/O requests. Based on this observation, we propose to schedule internal activities induced operations for minimized access conflict by exploiting the idleness of the multiple chips of SSDs. This approach is realized by two steps: First, read internal activities accessed data to the controller; second, by exploiting the idle chips during internal activities, write internal activities accessed data back to these idle chips. With this scheme, the internal activities can be processed with minimized access conflict to the host requests. Simulation results show that the proposed approach significantly reduces the access conflict, and in turn leads to a significant performance improvement of SSDs.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W2760885780",
    "type": "article"
  },
  {
    "title": "SEU fault evaluation and characteristics for SRAM-based FPGA architectures and synthesis algorithms",
    "doi": "https://doi.org/10.1145/2390191.2390204",
    "publication_date": "2013-01-01",
    "publication_year": 2013,
    "authors": "Naifeng Jing; Ju-Yueh Lee; Zhe Feng; Weifeng He; Zhigang Mao; Lei He",
    "corresponding_authors": "",
    "abstract": "Reliability has become an increasingly important concern for SRAM-based field programmable gate arrays (FPGAs). Targeting SEU (single event upset) in SRAM-based FPGAs, this article first develops an SEU evaluation framework that can quantify the failure sensitivity for each configuration bit during design time. This framework considers detailed fault behavior and logic masking on a post-layout FPGA application and performs logic simulation on various circuit elements for fault evaluation. Applying this framework on MCNC benchmark circuits, we first characterize SEUs with respect to different FPGA circuits and architectures, for example, bidirectional routing and unidirectional routing. We show that in both routing architectures, interconnects not only contribute to the lion's share of the SEU-induced functional failures, but also present higher failure rates per configuration bits than LUTs. Particularly, local interconnect multiplexers in logic blocks have the highest failure rate per configuration bit. Then, we evaluate three recently proposed SEU mitigation algorithms, IPD, IPF, and IPV, which are all logic resynthesis-based with little or no overhead on placement and routing. Different fault mitigating capabilities at the chip level are revealed, and it demonstrates that algorithms with explicit consideration for interconnect significantly mitigate the SEU at the chip level, for example, IPV achieves 61% failure rate reduction on average against IPF with about 15%. In addition, the combination of the three algorithms delivers over 70% failure rate reduction on average at the chip level. The experiments also reveal that in order to improve fault tolerance at the chip level, it is necessary for future fault mitigation algorithms to concern not only LUT or interconnect faults, but also their interactions. We envision that our framework can be used to cast more useful insights for more robust FPGA circuits, architectures, and better synthesis algorithms.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W1964218206",
    "type": "article"
  },
  {
    "title": "Exploiting workload dynamics to improve SSD read latency via differentiated error correction codes",
    "doi": "https://doi.org/10.1145/2489792",
    "publication_date": "2013-10-01",
    "publication_year": 2013,
    "authors": "Guanying Wu; Xubin He; Ningde Xie; Tong Zhang",
    "corresponding_authors": "",
    "abstract": "This article presents a cross-layer codesign approach to reduce SSD read response latency. The key is to cohesively exploit the NAND flash memory device write speed vs. raw storage reliability trade-off at the physical layer and runtime data access workload dynamics at the system level. Leveraging runtime data access workload variation, we can opportunistically slow down NAND flash memory write speed and hence improve NAND flash memory raw storage reliability. This naturally enables an opportunistic use of weaker error correction schemes that can directly reduce SSD read access latency. We develop a disk-level scheduling scheme to effectively smooth the write workload in order to maximize the occurrence of runtime opportunistic NAND flash memory write slowdown. Using 2 bits/cell NAND flash memory with BCH-based error correction correction as a test vehicle, we carry out extensive simulations over various workloads and demonstrate that this developed cross-layer co-design solution can reduce the average SSD read latency by up to 59.4% without sacrificing the write throughput performance.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W2010343672",
    "type": "article"
  },
  {
    "title": "CoMETC",
    "doi": "https://doi.org/10.1145/2534381",
    "publication_date": "2013-12-01",
    "publication_year": 2013,
    "authors": "Raid Ayoub; Rajib Nath; Tajana Rosing",
    "corresponding_authors": "",
    "abstract": "We introduce a Coordinated Management of Energy, Thermal, and Cooling (CoMETC) technique to minimize cooling and memory energy of server machines. State-of-the-art solutions decouple the optimization of cooling energy costs and energy consumption of CPU and memory subsystems. This results in suboptimal solutions due to thermal dependencies between CPU and memory and the nonlinearity in energy costs of cooling. In contrast, we develop a unified solution that integrates energy, thermal, and cooling management for CPU and memory subsystems to maximize energy savings. CoMETC reduces the operational energy of the memory by clustering active memory pages to a subset of memory modules while accounting for thermal and cooling aspects. At the same time, CoMETC removes hotspots between and within the CPU sockets and reduces the effects of thermal coupling with memory in order to minimize cooling energy costs. We design CoMETC using a control-theoretic approach to guarantee meeting these objectives. We introduce a formal thermal and cooling model to be used for online decisions inside CoMETC. Our experimental results show that CoMETC achieves average cooling and memory energy savings of 58% compared to state-of-the-art techniques at a performance overhead of less than 0.3%.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W2046813310",
    "type": "article"
  },
  {
    "title": "Concurrency-oriented verification and coverage of system-level designs",
    "doi": "https://doi.org/10.1145/2003695.2003697",
    "publication_date": "2011-10-01",
    "publication_year": 2011,
    "authors": "Alper Şen",
    "corresponding_authors": "Alper Şen",
    "abstract": "Correct concurrent System-on-Chips (SoCs) are very hard to design and reason about. In this work, we develop an automated framework complete with concurrency-oriented verification and coverage techniques for system-level designs. Our techniques are different from traditional simulation-based reliability techniques, since concurrency information is often lost in traditional techniques. We preserve concurrency information to obtain unique verification techniques that allow us to predict potential errors (formulated as transaction-level assertions) from error-free simulations. In order to do this, we exploit the inherent concurrency in the designs to generate and analyze novel partial-order simulation traces. Additionally, to evaluate the confidence on verification results and the gauge progress of verification, we develop novel mutation testing based on concurrent coverage metrics. Mutation testing is a fault insertion-based simulation technique that has been successfully applied in software testing. We present a comprehensive list of mutation operators for SystemC, similar to behavioral fault models, and show the effectiveness of these operators by relating them to actual bug patterns. We have successfully applied our verification and coverage techniques on industrial systems and demonstrated that current verification test suites need to be improved for concurrent designs, and we have found errors in systems that were tested previously.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W2082066754",
    "type": "article"
  },
  {
    "title": "A Fast Non-Monte-Carlo Yield Analysis and Optimization by Stochastic Orthogonal Polynomials",
    "doi": "https://doi.org/10.1145/2071356.2071366",
    "publication_date": "2012-01-01",
    "publication_year": 2012,
    "authors": "Fang Gong; Xuexin Liu; Hao Yu; Sheldon X.-D. Tan; Junyan Ren; Lei He",
    "corresponding_authors": "",
    "abstract": "Performance failure has become a significant threat to the reliability and robustness of analog circuits. In this article, we first develop an efficient non-Monte-Carlo (NMC) transient mismatch analysis, where transient response is represented by stochastic orthogonal polynomial (SOP) expansion under PVT variations and probabilistic distribution of transient response is solved. We further define performance yield and derive stochastic sensitivity for yield within the framework of SOP, and finally develop a gradient-based multiobjective optimization to improve yield while satisfying other performance constraints. Extensive experiments show that compared to Monte Carlo-based yield estimation, our NMC method achieves up to 700 X speedup and maintains 98% accuracy. Furthermore, multiobjective optimization not only improves yield by up to 95.3% with performance constraints, it also provides better efficiency than other existing methods.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W2093064288",
    "type": "article"
  },
  {
    "title": "Using CoreSight PTM to Integrate CRA Monitoring IPs in an ARM-Based SoC",
    "doi": "https://doi.org/10.1145/3035965",
    "publication_date": "2017-04-21",
    "publication_year": 2017,
    "authors": "Yongje Lee; Jin‐Yong Lee; Ingoo Heo; Dongil Hwang; Yunheung Paek",
    "corresponding_authors": "",
    "abstract": "The ARM CoreSight Program Trace Macrocell (PTM) has been widely deployed in recent ARM processors for real-time debugging and tracing of software. Using PTM, the external debugger can extract execution behaviors of applications running on an ARM processor. Recently, some researchers have been using this feature for other purposes, such as fault-tolerant computation and security monitoring. This motivated us to develop an external security monitor that can detect control hijacking attacks, of which the goal is to maliciously manipulate the control flow of victim applications at an attacker’s disposal. This article focuses on detecting a special type of attack called code reuse attacks (CRA), which use a recently introduced technique that allows attackers to perform arbitrary computation without injecting their code by reusing only existing code fragments. Our external monitor is attached to the outside of the host system via the system bus and ARM CoreSight PTM, and is fed with execution traces of a victim application running on the host. As a majority of CRAs violates the normal execution behaviors of a program, our monitor constantly watches and analyzes the execution traces of the victim application and detects a symptom of attacks when the execution behaviors violate certain rules that normal applications are known to adhere. We present two different implementations for this purpose: a hardware-based solution in which all CRA detection components are implemented in hardware, and a hardware/software mixed solution that can be employed in a more resource-constrained environment where the deployment of full hardware-level CRA detection is burdensome.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W2606014062",
    "type": "article"
  },
  {
    "title": "Optimization of 3D Digital Microfluidic Biochips for the Multiplexed Polymerase Chain Reaction",
    "doi": "https://doi.org/10.1145/2811259",
    "publication_date": "2016-01-28",
    "publication_year": 2016,
    "authors": "Zipeng Li; Tsung-Yi Ho; Krishnendu Chakrabarty",
    "corresponding_authors": "",
    "abstract": "A digital microfluidic biochip (DMFB) is an attractive technology platform for revolutionizing immunoassays, clinical diagnostics, drug discovery, DNA sequencing, and other laboratory procedures in biochemistry. In most of these applications, real-time polymerase chain reaction (PCR) is an indispensable step for amplifying specific DNA segments. To reduce the reaction time to meet the requirement of “real-time” applications, multiplexed PCR is widely utilized. In recent years, three-dimensional (3D) DMFBs that integrate photodetectors (i.e., cyberphysical DMFBs) have been developed, which offer the benefits of smaller size, higher sensitivity, and faster result generations. However, current DMFB design methods target optimization in only two dimensions, thus ignoring the 3D two-layer structure of a DMFB. Furthermore, these techniques ignore practical constraints related to the interference between on-chip device pairs, the performance-critical PCR thermal loop, and the physical size of devices. Moreover, some practical issues in real scenarios are not stressed (e.g., the avoidance of the cross-contamination for multiplexed PCR). In this article, we describe an optimization solution for a 3D DMFB and present a three-stage algorithm to realize a compact 3D PCR chip layout, which includes: (i) PCR thermal-loop optimization, (ii) 3D global placement based on Strong-Push-Weak-Pull (SPWP) model, and (iii) constraint-aware legalization. To avoid cross-contamination between different DNA samples, we also propose a Minimum-Cost-Maximum-Flow-based (MCMF-based) method for reservoir assignment. Simulation results for four laboratory protocols demonstrate that the proposed approach is effective for the design and optimization of a 3D chip for multiplexed real-time PCR.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W2268424974",
    "type": "article"
  },
  {
    "title": "A Hardware-Assisted Energy-Efficient Processing Model for Activity Recognition Using Wearables",
    "doi": "https://doi.org/10.1145/2886096",
    "publication_date": "2016-06-22",
    "publication_year": 2016,
    "authors": "Hassan Ghasemzadeh; Ramin Fallahzadeh; Roozbeh Jafari",
    "corresponding_authors": "",
    "abstract": "Wearables are being widely utilized in health and wellness applications, primarily due to the recent advances in sensor and wireless communication, which enhance the promise of wearable systems in providing continuous and real-time monitoring and interventions. Wearables are generally composed of hardware/software components for collection, processing, and communication of physiological data. Practical implementation of wearable monitoring in real-life applications is currently limited due to notable obstacles. The wearability and form factor are dominated by the amount of energy needed for sensing, processing, and communication. In this article, we propose an ultra-low-power granular decision-making architecture, also called screening classifier, which can be viewed as a tiered wake-up circuitry, consuming three orders of magnitude-less power than the state-of-the-art low-power microcontrollers. This processing model operates based on computationally simple template matching modules, based on coarse- to fine-grained analysis of the signals with on-demand and gradually increasing the processing power consumption. Initial template matching rejects signals that are clearly not of interest from the signal processing chain, keeping the rest of processing blocks idle. If the signal is likely of interest, the sensitivity and the power of the template matching modules are gradually increased, and ultimately, the main processing unit is activated. We pose optimization techniques to efficiently split a full template into smaller bins, called mini-templates, and activate only a subset of bins during each classification decision. Our experimental results on real data show that this signal screening model reduces power consumption of the processing architecture by a factor of 70% while the sensitivity of detection remains at least 80%.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W2468272042",
    "type": "article"
  },
  {
    "title": "Providing SLO Compliance on NVMe SSDs Through Parallelism Reservation",
    "doi": "https://doi.org/10.1145/3174867",
    "publication_date": "2018-02-01",
    "publication_year": 2018,
    "authors": "Sheng-Min Huang; Li-Pin Chang",
    "corresponding_authors": "",
    "abstract": "Non-Volatile Memory Express (NVMe) is a specification for next-generation solid-state disks (SSDs). Benefited from the massive internal parallelism and the high-speed PCIe bus, NVMe SSDs achieve extremely high data transfer rates, and they are an ideal solution of shared storage in virtualization environments. Providing virtual machines with Service Level Objective (SLO) compliance on NVMe SSDs is a challenging task, because garbage collection activities inside of NVMe SSDs globally affect the I/O performance of all virtual machines. In this study, we introduce a novel approach, called parallelism reservation, which is inspired by the rich internal parallelism of NVMe SSDs. The degree of parallelism stands for how many flash chips are concurrently active. Our basic idea is to reserve sufficient degrees of parallelism for read, write, and garbage collection operations, making sure that an NVMe SSD delivers stable read and write throughput and reclaims free space at a constant rate. The stable read and write throughput are proportionally distributed among virtual machines for SLO compliance. Our experimental results show that our parallelism reservation approach delivered satisfiable throughput and highly predictable response to virtual machines.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W2786131708",
    "type": "article"
  },
  {
    "title": "ReSC",
    "doi": "https://doi.org/10.1145/3174850",
    "publication_date": "2018-02-01",
    "publication_year": 2018,
    "authors": "Kun Yang; Domenic Forte; Mark Tehranipoor",
    "corresponding_authors": "",
    "abstract": "The Internet of Things (IoT), an emerging global network of uniquely identifiable embedded computing devices within the existing Internet infrastructure, is transforming how we live and work by increasing the connectedness of people and things on a scale that was once unimaginable. In addition to facilitated information and service exchange between connected objects, enhanced computing power and analytic capabilities of individual objects, and increased interaction between objects and their environments, the IoT also raises new security and privacy challenges. Hardware trust across the IoT supply chain is the foundation of IoT security and privacy. Two major supply chain issues—disappearance/theft of authentic IoT devices and appearance of inauthentic ones—have to be addressed to secure the IoT supply chain and lay the foundation for further security and privacy-defensive measures. Comprehensive solutions that enable IoT device authentication and traceability across the entire supply chain (i.e., during distribution and after being provisioned) need to be established. Existing hardware, software, and network protection methods, however, do not address IoT supply chain issues. To mitigate this shortcoming, we propose an RFID-enabled solution called ReSC that aims at defending the IoT supply chain. By incorporating three techniques—one-to-one mapping between RFID tag identity and control chip identity; unique tag trace, which records tag provenance and history information; and neighborhood attestation of IoT devices—ReSC is resistant to split attacks (i.e., separating tag from product, swapping tags), counterfeit injection, product theft throughout the entire supply chain, device recycling, and illegal network service access (e.g., Internet, cable TV, online games, remote firmware updates). Simulations, theoretical analysis, and experimental results based on a printed circuit board (PCB) prototype demonstrate the effectiveness of ReSC. Finally, we evaluate the security of our proposed scheme against various attacks.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W2786477842",
    "type": "article"
  },
  {
    "title": "A Comprehensive Side-Channel Information Leakage Analysis of an In-Order RISC CPU Microarchitecture",
    "doi": "https://doi.org/10.1145/3212719",
    "publication_date": "2018-08-20",
    "publication_year": 2018,
    "authors": "Davide Zoni; Alessandro Barenghi; Gerardo Pelosi; William Fornaciari",
    "corresponding_authors": "",
    "abstract": "Side-channel attacks are a prominent threat to the security of embedded systems. To perform them, an adversary evaluates the goodness of fit of a set of key-dependent power consumption models to a collection of side-channel measurements taken from an actual device, identifying the secret key value as the one yielding the best-fitting model. In this work, we analyze for the first time the microarchitectural components of a 32-bit in-order RISC CPU, showing which one of them is accountable for unexpected side-channel information leakage. We classify the leakage sources, identifying the data serialization points in the microarchitecture and providing a set of hints that can be fruitfully exploited to generate implementations resistant against side-channel attacks, either writing or generating proper assembly code.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W2888014022",
    "type": "article"
  },
  {
    "title": "Single-Event Multiple-Transient Characterization and Mitigation via Alternative Standard Cell Placement Methods",
    "doi": "https://doi.org/10.1145/2740962",
    "publication_date": "2015-09-28",
    "publication_year": 2015,
    "authors": "Bradley T. Kiddie; William H. Robinson; Daniel B. Limbrick",
    "corresponding_authors": "",
    "abstract": "As fabrication technology scales towards smaller transistor sizes and lower critical charge, single-event radiation effects are more likely to cause errant behavior in multiple, physically adjacent devices in modern integrated circuits (ICs), and with higher operating frequencies, this risk increasingly impacts design logic over memory as well. In order to increase future system reliability, circuit designers need greater awareness of multiple-transient charge-sharing effects during the early stages of their design flow with standard cell placement and routing. To measure the propagation and observability of multiple transients from single radiation events, this work uses several intra-pipeline combinational logic circuits at the 32nm technology node, investigates several different standard cell placements of each design, and analyzes those placements with a novel, physically realistic transient injection and simulation method. It is shown that (1) this simulation methodology, informed by experimental data, provides an increased realism over other works in traditional fault injection fields, (2) different placements of the same circuit where standard cells are grouped by logical hierarchy can result in different reliability behavior and benefits especially useful within the area of approximate computing, and (3) improved reliability through charge-sharing transient mitigation can be gained with no area penalty and minimal speed and power penalties by adjusting the placement of standard cells.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W2047468661",
    "type": "article"
  },
  {
    "title": "Core Placement Optimization for Multi-chip Many-core Neural Network Systems with Reinforcement Learning",
    "doi": "https://doi.org/10.1145/3418498",
    "publication_date": "2020-10-19",
    "publication_year": 2020,
    "authors": "Nan Wu; Lei Deng; Guoqi Li; Yuan Xie",
    "corresponding_authors": "",
    "abstract": "Multi-chip many-core neural network systems are capable of providing high parallelism benefited from decentralized execution, and they can be scaled to very large systems with reasonable fabrication costs. As multi-chip many-core systems scale up, communication latency related effects will take a more important portion in the system performance. While previous work mainly focuses on the core placement within a single chip, there are two principal issues still unresolved: the communication-related problems caused by the non-uniform, hierarchical on/off-chip communication capability in multi-chip systems, and the scalability of these heuristic-based approaches in a factorially growing search space. To this end, we propose a reinforcement-learning-based method to automatically optimize core placement through deep deterministic policy gradient, taking into account information of the environment by performing a series of trials (i.e., placements) and using convolutional neural networks to extract spatial features of different placements. Experimental results indicate that compared with a naive sequential placement, the proposed method achieves 1.99× increase in throughput and 50.5% reduction in latency; compared with the simulated annealing, an effective technique to approximate the global optima in an extremely large search space, our method improves the throughput by 1.22× and reduces the latency by 18.6%. We further demonstrate that our proposed method is capable to find optimal placements taking advantages of different communication properties caused by different system configurations, and work in a topology-agnostic manner.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W3094031577",
    "type": "article"
  },
  {
    "title": "Quantum Circuit Transformation: A Monte Carlo Tree Search Framework",
    "doi": "https://doi.org/10.1145/3514239",
    "publication_date": "2022-02-18",
    "publication_year": 2022,
    "authors": "Xiangzhen Zhou; Yuan Feng; Sanjiang Li",
    "corresponding_authors": "",
    "abstract": "In the noisy intermediate-scale quantum era, quantum processing units suffer from, among others, highly limited connectivity between physical qubits. To make a quantum circuit effectively executable, a circuit transformation process is necessary to transform it, with overhead cost the smaller the better, into a functionally equivalent one so that the connectivity constraints imposed by the quantum processing unit are satisfied. Although several algorithms have been proposed for this goal, the overhead costs are often very high, which degenerates the fidelity of the obtained circuits sharply. One major reason for this lies in that, due to the high branching factor and vast search space, almost all of these algorithms only search very shallowly, and thus, very often, only (at most) locally optimal solutions can be reached. In this article, we propose a Monte Carlo Tree Search (MCTS) framework to tackle the circuit transformation problem, which enables the search process to go much deeper. The general framework supports implementations aiming to reduce either the size or depth of the output circuit through introducing SWAP or remote CNOT gates. The algorithms, called MCTS-Size and MCTS-Depth , are polynomial in all relevant parameters. Empirical results on extensive realistic circuits and IBM Q Tokyo show that the MCTS-based algorithms can reduce the size (respectively, depth) overhead by, on average, 66% (respectively, 84%) when compared with t \\( \\left| {\\mathrm{ket}} \\right\\rangle \\) , an industrial-level compiler.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W4212971435",
    "type": "article"
  },
  {
    "title": "Towards LDPC Read Performance of 3D Flash Memories with Layer-induced Error Characteristics",
    "doi": "https://doi.org/10.1145/3585075",
    "publication_date": "2023-02-27",
    "publication_year": 2023,
    "authors": "Yajuan Du; Siyi Huang; Yao Zhou; Qiao Li",
    "corresponding_authors": "",
    "abstract": "3D flash memories have been widely developed to further increase the storage capacity of SSDs by vertically stacking multiple layers. However, this special physical structure brings new error characteristics. Existing studies have discovered that there exist significant Raw Bit Error Rate (RBER) variations among different layers and RBER similarity inside the same layer due to the manufacturing process. These error characteristics would introduce a new data reliability issue. Currently, Low-Density Parity-Check (LDPC) code has been widely used to ensure the data reliability of flash memories. It can provide stronger error correction capability for high RBERs by trading with longer read latency. Traditional LDPC codes designed for planar flash memories do not consider the layer RBER characteristics of 3D flash memories, which may induce sub-optimal read performance. This article first investigates the effect of RBER characteristics of 3D flash memories on read performance and then obtains two observations. On one hand, we observe that LDPC read latencies are largely diverse in different flash layers and increase in diverse speeds along with data retention. This phenomenon is caused by the inter-layer RBER variation. On the other hand, we also compare RBERs between different pages of the same flash layer and observe that read latencies with LDPC codes are quite similar, which is caused by the intra-layer RBER similarity. Then, by exploiting these two observation results, this article proposes a Multi-Granularity LDPC (MG-LDPC) read method to adapt read latency increase characteristics across 3D flash layers. In detail, we design five LDPC decoding engines with varied read level increase granularity (higher level induces higher latency) and assign these engines to each layer dynamically according to prior information, or in a fixed way. A series of experimental results demonstrate that the fixed and dynamic MG-LDPC methods can reduce SSD read response time by 21% and 51% on average, respectively.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W4322496126",
    "type": "article"
  },
  {
    "title": "A High Throughput STR-based TRNG by Jitter Precise Quantization Superposing",
    "doi": "https://doi.org/10.1145/3606373",
    "publication_date": "2023-06-29",
    "publication_year": 2023,
    "authors": "Yuan Zhang; Jiliang Zhang",
    "corresponding_authors": "",
    "abstract": "With the rapid development of integrated circuits and the continuous progress of computing capability, higher demands have been placed on the security and speed of data encryption in security systems. As a basic hardware security primitive, the true random number generator (TRNG) plays an important role in the encryption system, which requires higher throughput and randomness with lower hardware overhead. However, the throughput of TRNG is related to the entropy source’s quality and the randomness extraction methodology. To quantify the randomness of the entropy source with higher efficiency and quality, we utilize the independent jitter of the self-timed ring (STR) to generate original entropy and propose a high throughput jitter-based TRNG which can extract random information at the pulse of oscillation signal by jitter precise quantization superposing and random oscillation sampling. The proposed TRNG has been implemented on Artix-7 and Virtex-6 FPGAs. The generated true random number successfully passes the NIST SP800-22 and NIST SP800-90B tests while also exhibiting a minimum entropy greater than 0.9947. The most prominent superiority of our proposed TRNG is that it achieves a high throughput of 330 Mbps with an ultra-low hardware overhead of only 35 LUTs and 12 DFFs.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W4382540653",
    "type": "article"
  },
  {
    "title": "On-chip ESD Protection Design Methodologies by CAD Simulation",
    "doi": "https://doi.org/10.1145/3593808",
    "publication_date": "2023-11-15",
    "publication_year": 2023,
    "authors": "Zijin Pan; Xunyu Li; Weiquan Hao; Runyu Miao; Albert Wang",
    "corresponding_authors": "",
    "abstract": "Electrostatic discharge (ESD) can cause malfunction or failure of integrated circuits (ICs) . On-chip ESD protection design is a major IC design-for-reliability (DfR) challenge, particularly for complex chips made in advanced technology nodes. Traditional trial-and-error approaches become unacceptable to practical ESD protection designs for advanced ICs. Full-chip ESD protection circuit design optimization, prediction, and verification become essential to advanced chip designs, which highly depends on CAD algorithm and simulation that has been a constant research topic for decades. This paper reviews recent advances in CAD-enabled on-chip ESD protection circuit simulation design technologies and ESD-IC co-design methodologies. Key challenges of ESD CAD design practices are outlined. Practical ESD protection simulation design examples are discussed.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W4388716667",
    "type": "article"
  },
  {
    "title": "DeepFlow: A Cross-Stack Pathfinding Framework for Distributed AI Systems",
    "doi": "https://doi.org/10.1145/3635867",
    "publication_date": "2023-12-21",
    "publication_year": 2023,
    "authors": "Newsha Ardalani; Saptadeep Pal; Puneet Gupta",
    "corresponding_authors": "",
    "abstract": "Over the past decade, machine learning model complexity has grown at an extraordinary rate, as has the scale of the systems training such large models. However, there is an alarmingly low hardware utilization (5–20%) in large scale AI systems. The low system utilization is a cumulative effect of minor losses across different layers of the stack, exacerbated by the disconnect between engineers designing different layers spanning across different industries. To address this challenge, in this work we designed a cross-stack performance modelling and design space exploration framework. First, we introduce CrossFlow, a novel framework that enables cross-layer analysis all the way from the technology layer to the algorithmic layer. Next, we introduce DeepFlow (built on top of CrossFlow using machine learning techniques) to automate the design space exploration and co-optimization across different layers of the stack. We have validated CrossFlow’s accuracy with distributed training on real commercial hardware and showcase several DeepFlow case studies demonstrating pitfalls of not optimizing across the technology-hardware-software stack for what is likely the most important workload driving large development investments in all aspects of computing stack.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W4390051523",
    "type": "article"
  },
  {
    "title": "ZeroD-fender: A Resource-aware IoT Malware Detection Engine via Fine-grained Side-channel Analysis",
    "doi": "https://doi.org/10.1145/3687482",
    "publication_date": "2024-08-24",
    "publication_year": 2024,
    "authors": "Zhuoran Li; Danella Zhao",
    "corresponding_authors": "",
    "abstract": "In early 2023, cyberattacks experienced a significant rise due to unknown (zero-day) malware targeting Internet of Things (IoT) devices. To tackle the challenge of zero-day detection within a highly resource-constrained IoT environment, we propose a novel design that utilizes fine-grained power side-channel analysis with deep learning techniques. Our approach introduces an innovative concept called multiscale feature extraction to identify the most representative malware features across diverse architectures, thereby enhancing deep learning based detection performance against zero-day malware. Specifically, we employ a fine-grained power side-channel analysis of more than 120,000 honeypot-collected malware files across a hierarchy of commands , functions , and modules to identify the unique zero-day malware behaviors. With these identified features to train our model, ZeroD-fender’s performance in detecting zero-day malware has significantly improved. In pursuit of on-device detection, we present a resource-aware online inference customization framework. This framework features our lightweight network, ThingNetV2, which uses specialized 1-D depthwise separable convolution paired with h-swish activation, leading to significant resource savings. By applying the fine-grained power analysis, ZeroD-fender demonstrates a detection rate of 95.88% across various architecture zero-day malware, achieving detection speeds ranging between 16.083 ms and 23.961 ms , depending on the specific scenario.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4401846637",
    "type": "article"
  },
  {
    "title": "Functional multiple-output decomposition with application to technology mapping for lookup table-based FPGAs",
    "doi": "https://doi.org/10.1145/315773.315783",
    "publication_date": "1999-07-01",
    "publication_year": 1999,
    "authors": "Bernd Wurth; Ulf Schlichtmann; Klaus Eckl; K. Antreich",
    "corresponding_authors": "",
    "abstract": "Functional decomposition is an important technique for technology mapping to look up table-based FPGA architectures. We present the theory of and a novel approach to functional disjoint decomposition of multiple-output functions, in which common subfunctions are extracted during technology mapping. While a Boolean function usually has a very large number of subfunctions, we show that not all of them are useful for multiple-output decomposition. We use a partition of the set of bound set vertices as the basis to compute preferable decomposition functions, which are sufficient for an optimal multiple-output decomposition. We propose several new algorithms that deal with central issues of functional multiple-output decomposition. First, an efficient algorithm to solve the variable partitioning problem is described. Second, we show how to implicitly compute all preferable functions of a single-output function and how to identify all common preferable functions of a multiple-output function. Due to implicit computation in the crucial steps, the algorithm is very efficient. Experimental results show significant reductions in area.",
    "cited_by_count": 33,
    "openalex_id": "https://openalex.org/W2015415966",
    "type": "article"
  },
  {
    "title": "Object-oriented cosynthesis of distributed embedded systems",
    "doi": "https://doi.org/10.1145/234860.234861",
    "publication_date": "1996-07-01",
    "publication_year": 1996,
    "authors": "Wayne Wolf",
    "corresponding_authors": "Wayne Wolf",
    "abstract": "This article describes a new hardware-software cosynthesis algorithm that takes advantage of the structure inherent in an object-oriented specification. The algorithm creates a distributed system implementation with arbitrary topology, using the object-oriented structure to partition functionality in addition to scheduling and allocating processes. Process partitioning is an especially important optimization for such systems because the specification will not, in general, take into account the process structure required for efficient execution on the distributed engine. The object-oriented specification naturally provides both coarse-grained and fine-grained partitions of the system. Our algorithm uses that multilevel structure to guide synthesis. Experimental results show that our algorithm takes advantage of the object-oriented specification to quickly converge on high-quality implementations.",
    "cited_by_count": 32,
    "openalex_id": "https://openalex.org/W2049338756",
    "type": "article"
  },
  {
    "title": "A timing-driven design and validation methodology for embedded real-time systems",
    "doi": "https://doi.org/10.1145/296333.296338",
    "publication_date": "1998-10-01",
    "publication_year": 1998,
    "authors": "Ali Dasdan; Dinesh Ramanathan; Rajesh K. Gupta",
    "corresponding_authors": "",
    "abstract": "We address the problem of timing constraint derivation and validation for reactive and real-time embedded systems. We assume that such a system is structured into its tasks, and the structure is modeled using a task graph. Our solution uses the timing behavior committed by the environment to the system first to derive the timing constraints on the system's internal behavior and then use them to derive and validate the timing constraints on the system's external behavior. Our solution consists of the following contributions: a generalized task graph model, a comprehensive classification of timing constraints, algorithms for derivation and validation of timing constraints of the system modeled in the generalized task graph model, a codesign methodology that combines the model and the algorithms, and the implementation of this methodology in a tool called RADHA-RATAN. The main advantages of our solution are that it simplifies the problem of ensuring timing correctness of the system by reducing the complexity of the problem from system level to task level, and that it makes the codesign methodology timing-driven in that our solution makes it possible to maintain a handle on the system's timing correctness from very early stages in the system's design flow.",
    "cited_by_count": 30,
    "openalex_id": "https://openalex.org/W2000338814",
    "type": "article"
  },
  {
    "title": "Optimal register assignment to loops for embedded code generation",
    "doi": "https://doi.org/10.1145/233539.233542",
    "publication_date": "1996-04-01",
    "publication_year": 1996,
    "authors": "David J. Kolson; Alexandru Nicolau; Nikil Dutt; Ken Kennedy",
    "corresponding_authors": "",
    "abstract": "One of the challenging tasks in code generation for embedded systems is register assignment. When more live variables than registers exist, some variables will necessarily be accessed from data memory. Because loops are typically executed many times and are often time-critical, good register assignment in loops is exceedingly important as accessing data memory can degrade performance. The issue of finding an optimal register assignment to loops has been open for some time. In this article, we present a technique for optimal (i.e., spill minimizing) register assignment to loops. First we present a technique for register assignment to architecture styles that are characterized by a consolidated register file. Then we extend the technique to include architecture styles that are characterized by distributed memories and/or a combination of general- and special-purpose registers. Experimental results demonstrate that although the optimal algorithm may be computationally prohibitive, heuristic versions obtain results with performance better than that of an existing graph coloring approach.",
    "cited_by_count": 30,
    "openalex_id": "https://openalex.org/W2009749048",
    "type": "article"
  },
  {
    "title": "Power-delay optimizations in gate sizing",
    "doi": "https://doi.org/10.1145/329458.329473",
    "publication_date": "2000-01-01",
    "publication_year": 2000,
    "authors": "Sachin S. Sapatnekar; Weitong Chuang",
    "corresponding_authors": "",
    "abstract": "The problem of power-delay tradeoffs in transistor sizing is examined using a nonlinear optimization formulation. Both the dynamic and the short-circuit power are considered, and a new modeling technique is used to calculate the short-circuit power. The notion of transition density is used, with an enhancement that considers the effect of gate delays on the transition density. When the short-cuircuit power is neglected, the minimum power circuit is idential to the minimum area circuit. However, under our more realistic models, our experimental results on several circuits show that the minimum power circuit is not necessarily the same as the minimum area circuit.",
    "cited_by_count": 30,
    "openalex_id": "https://openalex.org/W2080686598",
    "type": "article"
  },
  {
    "title": "FILL and FUNI",
    "doi": "https://doi.org/10.1145/348019.348311",
    "publication_date": "2000-07-01",
    "publication_year": 2000,
    "authors": "David E. Long; Mahesh A. Iyer; M. Abramovici",
    "corresponding_authors": "",
    "abstract": "In this paper, we first present an algorithm (FILL) to efficiently identify a large subset of illegal states in synchronous sequential circuits, without assuming a global reset mechanism. A second algorithm, FUNI, finds sequentially untestable faults whose detection requires some of the illegal states computed by FILL. Although based on binary decision diagrams (BDDs), FILL is able to process large circuits by using a new functional partitioning procedure. The incremental building of the set of illegal states guarantees that FILL will always obtain at least a partial solution. FUNI is a direct method that identifies untestable faults without using the exhaustive search involved in automatic test generation (ATG). Experimental results show that FUNI finds a large number of untestable faults up to several orders of magnitude faster than an ATG algorithm that targeted the faults identified by FUNI. Also, many untestable faults identified by FUNI were aborted by the test generator.",
    "cited_by_count": 30,
    "openalex_id": "https://openalex.org/W2108572593",
    "type": "article"
  },
  {
    "title": "Synthesis of saturation arithmetic architectures",
    "doi": "https://doi.org/10.1145/785411.785415",
    "publication_date": "2003-07-01",
    "publication_year": 2003,
    "authors": "George A. Constantinides; Peter Y. K. Cheung; Wayne Luk",
    "corresponding_authors": "",
    "abstract": "This paper describes a synthesis technique for automating the design of linear Digital Signal Processing (DSP) systems such as digital filters. The proposed methodology makes optimized use of saturation arithmetic to produce a small design implemented directly in hardware. An analytical technique is proposed to estimate the saturation error resulting from a particular implementation, and an optimization procedure is introduced to aim for the smallest implementation satisfying user-specified bounds on saturation and roundoff error. Results are presented illustrating significant speedup and area reduction compared with standard DSP design techniques: up to 22% improvement in area and 28% improvement in speed have been obtained on Field Programmable Gate Array (FPGA) implementations.",
    "cited_by_count": 29,
    "openalex_id": "https://openalex.org/W2068452798",
    "type": "article"
  },
  {
    "title": "Gravity",
    "doi": "https://doi.org/10.1145/785411.785413",
    "publication_date": "2003-07-01",
    "publication_year": 2003,
    "authors": "Stefan Thomas Obenaus; Ted H. Szymanski",
    "corresponding_authors": "",
    "abstract": "Three dimensional integration is an increasingly feasible method of implementing complex circuitry. For large circuits, which most benefit from 3-D designs, efficient placement algorithms with low time complexity are required.We present an iterative 3-D placement algorithm that places circuit elements in three dimensions in linear time. Using an order of magnitude less time, our proposed algorithm produces placements with better than 11% less wire lengths than partitioning placement using the best and fastest partitioner. Due to the algorithms iterative nature, wire-length results can be further improved by increasing the number of iterations.Further, we provide empirical evidence that large circuits benefit most from 3-D technology and that even a small number of layers can provide significant wire-length improvements.",
    "cited_by_count": 29,
    "openalex_id": "https://openalex.org/W2079078065",
    "type": "article"
  },
  {
    "title": "Rectilinear block placement using B*-trees",
    "doi": "https://doi.org/10.1145/762488.762490",
    "publication_date": "2003-04-01",
    "publication_year": 2003,
    "authors": "Guangming Wu; Yun-Chih Chang; Yao‐Wen Chang",
    "corresponding_authors": "",
    "abstract": "Due to the layout complexity in modern VLSI designs, integrated circuit blocks may not be rectangular. However, literature on general rectilinear block placement is still quite limited. In this article, we present approaches for handling the placement for arbitrarily shaped rectilinear blocks using B*-trees [Chang et al. 2000]. We derive the feasibility conditions of B*-trees to guide the placement of rectilinear blocks. Experimental results show that our algorithm achieves optimal or near-optimal block placement for benchmarks with various shaped blocks.",
    "cited_by_count": 28,
    "openalex_id": "https://openalex.org/W1987148009",
    "type": "article"
  },
  {
    "title": "ATPG tools for delay faults at the functional level",
    "doi": "https://doi.org/10.1145/504914.504916",
    "publication_date": "2002-01-01",
    "publication_year": 2002,
    "authors": "M. Michael; Spyros Tragoudas",
    "corresponding_authors": "",
    "abstract": "We present an ATPG tool for functional delay faults which applies to the single-input transition (SIT) and the multi-input transition (MIT) fault models, and is based on Reduced Ordered Binary Decision Diagrams (ROBDDs). We are able, for the first time, to identify all faults that do not have any SIT tests, and generate all SIT tests for nonredundant faults in combinational circuits. We also provide methodologies for efficient generation of MIT tests. Our experimental results on the ISCAS'85 benchmarks is by far superior to existing methods as well as a Satisfiability-based tool that we have developed for comparative purposes. The presented tool, coupled with advancements in path delay fault coverage, shows that both the SIT and MIT functional models are very useful in ATPG for robust path delay faults for synthesized circuits.",
    "cited_by_count": 28,
    "openalex_id": "https://openalex.org/W2037118276",
    "type": "article"
  },
  {
    "title": "Simultaneous shield insertion and net ordering for capacitive and inductive coupling minimization",
    "doi": "https://doi.org/10.1145/1013948.1013950",
    "publication_date": "2004-07-01",
    "publication_year": 2004,
    "authors": "Kevin M. Lepak; Min Xu; Jun Chen; Lei He",
    "corresponding_authors": "",
    "abstract": "In this article, we first show that existing net ordering formulations to minimize noise are no longer sufficient with the presence of inductive noise, and shield insertion is needed to minimize inductive noise. Using a K eff model as the figure of merit for inductive coupling, we then formulate two simultaneous shield insertion and net ordering (SINO) problems: the optimal SINO/NF problem to find a minimal area SINO solution that is free of capacitive and inductive noise, and the optimal SINO/NB problem to find a minimal area SINO solution that is free of capacitive noise and is under the given inductive noise bound. We reveal that both optimal SINO problems are NP-hard, and propose effective approximate algorithms for the two problems. Experiments show that our SINO/NB algorithm uses from 51% to 82% fewer shields compared to uniform shield insertion and net ordering (US + NO), and uses from 4% to 47% fewer shields compared to separated net ordering and shield insertion (NO + SI). Furthermore, the SINO/NB solutions under practical noise bounds use from 38% to 61% fewer shields compared to SINO/NF solutions, and use up to 36% fewer shields compared to the theoretical lower bound for optimal SINO/NF solutions. Moreover, we show that the K eff model has a high fidelity versus the noise voltage computed using accurate RLC circuit models and SPICE simulations. To the best of our knowledge, it is the first work that presents an in-depth study on the automatic layout optimization of multiple nets to minimize both capacitive and inductive noise.",
    "cited_by_count": 27,
    "openalex_id": "https://openalex.org/W2098630265",
    "type": "article"
  },
  {
    "title": "Formal hardware specification languages for protocol compliance verification",
    "doi": "https://doi.org/10.1145/966137.966138",
    "publication_date": "2004-01-01",
    "publication_year": 2004,
    "authors": "A.S. Bunker; Ganesh Gopalakrishnan; Sally A. McKee",
    "corresponding_authors": "",
    "abstract": "The advent of the system-on-chip and intellectual property hardware design paradigms makes protocol compliance verification increasingly important to the success of a project. One of the central tools in any verification project is the modeling language, and we survey the field of candidate languages for protocol compliance verification, limiting our discussion to languages originally intended for hardware and software design and verification activities. We frame our comparison by first constructing a taxonomy of these languages, and then by discussing the applicability of each approach to the compliance verification problem. Each discussion includes a summary of the development of the language, an evaluation of the language's utility for our problem domain, and, where feasible, an example of how the language might be used to specify hardware protocols. Finally, we make some general observations regarding the languages considered.",
    "cited_by_count": 27,
    "openalex_id": "https://openalex.org/W2118514798",
    "type": "article"
  },
  {
    "title": "XFM",
    "doi": "https://doi.org/10.1145/1109118.1109120",
    "publication_date": "2005-10-01",
    "publication_year": 2005,
    "authors": "Syed Suhaib; Deepak A. Mathaikutty; Sandeep K. Shukla; David Berner",
    "corresponding_authors": "",
    "abstract": "We present an agile formal methodology named eXtreme Formal Modeling (XFM), based on Extreme Programming (XP) concepts to construct abstract models from natural language specifications of complex systems. In particular, we focus on Prescriptive Formal Models (PFMs) that capture the specification of the system under design in a mathematically precise manner. Such models can be used as golden reference models for formal verification, test generation, coverage monitor generation, etc. This methodology for incrementally building PFMs works by adding user stories expressed as LTL formulae gleaned from the natural language specifications, one by one, into the model. XFM builds the models, retaining correctness with respect to incrementally added properties by regressively model-checking all the LTL properties captured theretofore in the model. We illustrate XFM with a graded set of examples consisting of a traffic light controller and a DLX pipeline. To make the regressive model-checking steps feasible with current model-checking tools, we need to control the model size increments at each subsequent step in the process. We therefore analyze the effects of ordering the LTL properties in XFM on the statespace growth rate of the model. We compare three different property-ordering methodologies: ad hoc ordering, property-based ordering, and predicate-based ordering. We experiment on the models of the ISA bus monitor and the arbitration phase of the Pentium Pro bus. We experimentally show and mathematically reason that the predicate-based ordering is the best among these orderings. Finally, we present a GUI-based toolbox that we implemented to build PFMs using XFM.",
    "cited_by_count": 26,
    "openalex_id": "https://openalex.org/W1985484782",
    "type": "article"
  },
  {
    "title": "An adaptive cryptographic engine for internet protocol security architectures",
    "doi": "https://doi.org/10.1145/1013948.1013952",
    "publication_date": "2004-07-01",
    "publication_year": 2004,
    "authors": "Andreas Dandalis; Viktor K. Prasanna",
    "corresponding_authors": "",
    "abstract": "Architectures that implement the Internet Protocol Security (IPSec) standard have to meet the enormous computing demands of cryptographic algorithms. In addition, IPSec architectures have to be flexible enough to adapt to diverse security parameters. This article proposes an FPGA-based Adaptive Cryptographic Engine (ACE) for IPSec architectures. By taking advantage of FPGA technology, ACE can adapt to diverse security parameters on the fly while providing superior performance compared with software-based solutions. In this paper, we focus on performance issues. A diverse set of private-key cryptographic algorithms is utilized to demonstrate the applicability of the proposed cryptographic engine. The time performance metrics are throughput and key-setup latency. The latency metric is the most important measure for IPSec where a small amount of data is processed per key and key context switching occurs repeatedly. We are not aware of any published results that include extensive key-setup latency results.",
    "cited_by_count": 26,
    "openalex_id": "https://openalex.org/W2037251981",
    "type": "article"
  },
  {
    "title": "Loop scheduling with timing and switching-activity minimization for VLIW DSP",
    "doi": "https://doi.org/10.1145/1124713.1124724",
    "publication_date": "2006-01-01",
    "publication_year": 2006,
    "authors": "Zili Shao; Bin Xiao; Chun Jason Xue; Qingfeng Zhuge; Edwin H.‐M. Sha",
    "corresponding_authors": "",
    "abstract": "In embedded systems, high-performance DSP needs to be performed not only with high-data throughput but also with low-power consumption. This article develops an instruction-level loop-scheduling technique to reduce both execution time and bus-switching activities for applications with loops on VLIW architectures. We propose an algorithm, SAMLS (Switching-Activity Minimization Loop Scheduling), to minimize both schedule length and switching activities for applications with loops. In the algorithm, we obtain the best schedule from the ones that are generated from an initial schedule by repeatedly rescheduling the nodes with schedule length and switching activities minimization based on rotation scheduling and bipartite matching. The experimental results show that our algorithm can reduce both schedule length and bus-switching activities. Compared with the work of Lee et al. [2003], SAMLS shows an average 11.5% reduction in schedule length and an average 19.4% reduction in bus-switching activities.",
    "cited_by_count": 25,
    "openalex_id": "https://openalex.org/W1998152234",
    "type": "article"
  },
  {
    "title": "On the construction of zero-deficiency parallel prefix circuits with minimum depth",
    "doi": "https://doi.org/10.1145/1142155.1142162",
    "publication_date": "2006-04-01",
    "publication_year": 2006,
    "authors": "Haikun Zhu; Chung‐Kuan Cheng; Ronald Graham",
    "corresponding_authors": "",
    "abstract": "A parallel prefix circuit has n inputs x 1 , x 2 , …, x n , and computes the n outputs y i = x i • x i −1 •…• x 1 , 1 ≤ i ≤ n , in parallel, where • is an arbitrary binary associative operator. Snir proved that the depth t and size s of any parallel prefix circuit satisfy the inequality t + s ≥2 n −2. Hence, a parallel prefix circuit is said to be of zero-deficiency if equality holds. In this article, we provide a different proof for Snir's theorem by capturing the structural information of zero-deficiency prefix circuits. Following our proof, we propose a new kind of zero-deficiency prefix circuit Z ( d ) by constructing a prefix circuit as wide as possible for a given depth d . It is proved that the Z ( d ) circuit has the minimal depth among all possible zero-deficiency prefix circuits.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W2103316343",
    "type": "article"
  },
  {
    "title": "A verification system for transient response of analog circuits",
    "doi": "https://doi.org/10.1145/1255456.1255468",
    "publication_date": "2007-08-17",
    "publication_year": 2007,
    "authors": "Tathagato Rai Dastidar; P. P. Chakrabarti",
    "corresponding_authors": "",
    "abstract": "We present a method for application of formal techniques like model checking and equivalence checking for validation of the transient response of nonlinear analog circuits. We propose a temporal logic called Ana CTL (computational tree logic for analog circuit verification) which is suitable for specifying properties specific to analog circuits. The application of Ana CTL for validation of transient behavior of arbitrarily nonlinear analog circuits is presented. The transient response of a circuit under all possible input waveforms is represented as a finite state machine (FSM), by bounding and discretizing the continuous state space of an analog circuit. We have developed algorithms to run Ana CTL queries on this discretized model using search-based methods which reduce the runtime considerably by avoiding creation of the whole FSM. The application of these methods on several real-life analog circuits is presented and we show that this system is a useful aid for detecting and debugging early design errors. We also present methods for checking the equivalence of transient response of two analog circuits. The behavior of two different analog circuits can rarely be exactly similar. Hence, we introduce a notion of approximate equivalence. A query language for checking different notions of user-definable approximate equivalence is presented which extends the syntax of the Ana CTL model checking language. In its extended form, Ana CTL can be used combining model checking with equivalence checking.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W1964164497",
    "type": "article"
  },
  {
    "title": "System-level throughput analysis for process variation aware multiple voltage-frequency island designs",
    "doi": "https://doi.org/10.1145/1391962.1391967",
    "publication_date": "2008-09-01",
    "publication_year": 2008,
    "authors": "Siddharth Garg; Diana Marculescu",
    "corresponding_authors": "",
    "abstract": "The increasing variability in manufacturing process parameters is expected to lead to significant performance degradation in deep submicron technologies. Multiple Voltage-Frequency Island (VFI) design styles with fine-grained, process-variation aware clocking have recently been shown to possess increased immunity to manufacturing process variations. In this article, we propose a theoretical framework that allows designers to quantify the performance improvement that is to be expected if they were to migrate from a fully synchronous design to the proposed multiple VFI design style. Specifically, we provide techniques to efficiently and accurately estimate the probability distribution of the execution rate (or throughput) of both single and multiple VFI systems under the influence of manufacturing process variations. Finally, using an MPEG-2 encoder benchmark, we demonstrate how the proposed analysis framework can be used by designers to make architectural decisions such as the granularity of VFI domain partitioning based on the throughput constraints their systems are required to satisfy.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W2000284467",
    "type": "article"
  },
  {
    "title": "Timing-driven octilinear Steiner tree construction based on Steiner-point reassignment and path reconstruction",
    "doi": "https://doi.org/10.1145/1344418.1344422",
    "publication_date": "2008-04-02",
    "publication_year": 2008,
    "authors": "Jin-Tai Yan",
    "corresponding_authors": "Jin-Tai Yan",
    "abstract": "It is well known that the problem of constructing a timing-driven rectilinear Steiner tree for any signal net is important in performance-driven designs and has been extensively studied. Until now, many efficient approaches have been proposed for the construction of a timing-driven rectilinear Steiner tree. As technology process advances, +45° and −45° diagonal segments can be permitted in an octilinear routing model. To our knowledge, no approach is proposed to construct a timing-driven octilinear Steiner tree for any signal net. In this paper, given a rectilinear Steiner tree for any signal net, we propose an efficient transformation-based approach to construct a timing-driven octilinear Steiner tree based on the computation of the octilinear distance and the concept of Steiner-point reassignment and path reconstruction in an octilinear routing model. The experimental results show that our proposed transformation-based approach can use reasonable CPU time to construct a TOST, and a 10%--18% improvement in timing delay and a 5%--14% improvement in total wire length in the original RSTs are obtained in the construction of TOSTs for the tested signal nets.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W2013328386",
    "type": "article"
  },
  {
    "title": "A practical dynamic single assignment transformation",
    "doi": "https://doi.org/10.1145/1278349.1278353",
    "publication_date": "2007-09-01",
    "publication_year": 2007,
    "authors": "Karolien Vanbroekhoven; Gerda Janssens; Maurice Bruynooghe; Francky Catthoor",
    "corresponding_authors": "",
    "abstract": "This paper presents a novel method to construct a dynamic single assignment (DSA) form of array intensive, pointer free C programs. A program in DSA form does not perform any destructive update of scalars and array elements; that is, each element is written at most once. As DSA makes the dependencies between variable references explicit, it facilitates complex analyses and optimizations of programs. Existing transformations into DSA perform a complex data flow analysis with exponential analysis time, and they work only for a limited class of input programs. Our method removes irregularities from the data flow by adding copy assignments to the program, so that it can use simple data flow analyses. The presented DSA transformation scales very well with growing program sizes and overcomes a number of important limitations of existing methods. We have implemented the method and it is being used in the context of memory optimization and verification of those optimizations. Experiments show that in practice, the method scales well indeed, and that added copy operations can be removed in case they are unwanted.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W2040863504",
    "type": "article"
  },
  {
    "title": "A fuel-cell-battery hybrid for portable embedded systems",
    "doi": "https://doi.org/10.1145/1297666.1297685",
    "publication_date": "2008-01-01",
    "publication_year": 2008,
    "authors": "Kyungsoo Lee; Naehyuck Chang; Jianli Zhuo; Chaitali Chakrabarti; Sudheendra Kadri; Sarma Vrudhula",
    "corresponding_authors": "",
    "abstract": "This article presents our work on the development of a fuel cell (FC) and battery hybrid (FC-Bh) system for use in portable microelectronic systems. We describe the design and control of the hybrid system, as well as a dynamic power management (DPM)-based energy management policy that extends its operational lifetime. The FC is of the proton exchange membrane (PEM) type, operates at room temperature, and has an energy density which is 4--6 times that of a Li-ion battery. The FC cannot respond to sudden changes in the load, and so a system powered solely by the FC is not economical. An FC-Bh power source, on the other hand, can provide the high energy density of the FC and the high power density of a battery. In this work we first describe the prototype FC-Bh system that we have built. Such a prototype helps to characterize the performance of a hybrid power source, and also helps explore new energy management strategies for embedded systems powered by hybrid sources. Next we describe a Matlab/Simulink-based FC-Bh system simulator which serves as an alternate experimental platform and that enables quick evaluation of system-level control policies. Finally, we present an optimization framework that explicitly considers the characteristics of the FC-Bh system and is aimed at minimizing the fuel consumption. This optimization framework is applied on top of a prediction-based DPM policy and is used to derive a new fuel-efficient DPM scheme. The proposed scheme demonstrates up to 32% system lifetime extension compared to a competing scheme when run on a real trace-based MPEG encoding example.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W2113465473",
    "type": "article"
  },
  {
    "title": "Low-power gated and buffered clock network construction",
    "doi": "https://doi.org/10.1145/1297666.1297686",
    "publication_date": "2008-01-01",
    "publication_year": 2008,
    "authors": "Wei‐Chung Chao; Wai-Kei Mak",
    "corresponding_authors": "",
    "abstract": "We propose an efficient algorithm to construct a low-power zero-skew gated clock network, given the module locations and activity information. Unlike previous works, we consider masking logic insertion and buffer insertion simultaneously, and guarantee to yield a zero-skew clock tree. Both the logical and physical information of the modules are carefully taken into consideration when determining where masking logic should be inserted. We also account for the power overhead of the control signals so that the total average power consumption of the constructed zero-skew gated clock network can be minimized. To this end, we present a recursive approach to compute the effective switched capacitance of a general gated and buffered clock network, accounting for both the clock tree's and controller tree's switched capacitance. The power consumptions of the gated clock networks constructed by our algorithm are 20 to 36% lower than those reported in the best previous work in the literature.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W2123953188",
    "type": "article"
  },
  {
    "title": "Reconfigurable content-based router using hardware-accelerated language parser",
    "doi": "https://doi.org/10.1145/1344418.1344424",
    "publication_date": "2008-04-02",
    "publication_year": 2008,
    "authors": "James Moscola; John W. Lockwood; Young H. Cho",
    "corresponding_authors": "",
    "abstract": "This article presents a dense logic design for matching multiple regular expressions with a field programmable gate array (FPGA) at 10+ Gbps. It leverages on the design techniques that enforce the shortest critical path on most FPGA architectures while optimizing the circuit size. The architecture is capable of supporting a maximum throughput of 12.90 Gbps on a Xilinx Virtex 4 LX200 and its performance is linearly scalable with size. Additionally, this article presents techniques for parsing data streams to provide semantic information for patterns found within a data stream. We illustrate how a content-based router can be implemented with our parsing techniques using an XML parser as an example. The content-based router presented was designed, implemented, and tested in a Xilinx Virtex XCV2000E FPGA on the FPX platform. It is capable of processing 32-bits of data per clock cycle and runs at 100 MHz. This allows the system to process and route XML messages at 3.2 Gbps.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W2423007790",
    "type": "article"
  },
  {
    "title": "Congestion prediction in early stages of physical design",
    "doi": "https://doi.org/10.1145/1455229.1455241",
    "publication_date": "2009-01-01",
    "publication_year": 2009,
    "authors": "Chiu‐Wing Sham; Evangeline F. Y. Young; Jingwei Lu",
    "corresponding_authors": "",
    "abstract": "Routability optimization has become a major concern in physical design of VLSI circuits. Due to the recent advances in VLSI technology, interconnect has become a dominant factor of the overall performance of a circuit. In order to optimize interconnect cost, we need a good congestion estimation method to predict routability in the early designing stages. Many congestion models have been proposed but there's still a lot of room for improvement. Besides, routers will perform rip-up and reroute operations to prevent overflow, but most models do not consider this case. The outcome is that the existing models will usually underestimate the routability. In this paper, we have a comprehensive study on our proposed congestion models. Results show that the estimation results of our approaches are always more accurate than the previous congestion models.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W1967402431",
    "type": "article"
  },
  {
    "title": "ACM Journal on Emerging Technologies in Computing Systems",
    "doi": "https://doi.org/10.1145/1870109.1870120",
    "publication_date": "2010-11-01",
    "publication_year": 2010,
    "authors": "Montek Singh; Steven M. Nowick",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W4232121389",
    "type": "article"
  },
  {
    "title": "Guest Editorial",
    "doi": "https://doi.org/10.1145/1870109.1870110",
    "publication_date": "2010-11-01",
    "publication_year": 2010,
    "authors": "Naehyuck Chang; Jörg Henkel",
    "corresponding_authors": "",
    "abstract": "editorial Free AccessGuest Editorial: Current Trends in Low-Power Design Editors: Naehyuck Chang Seoul National University Seoul National UniversityView Profile , Jörg Henkel Karlsruhe Institute of Technology Karlsruhe Institute of TechnologyView Profile Authors Info & Claims ACM Transactions on Design Automation of Electronic SystemsVolume 16Issue 1November 2010 Article No.: 1pp 1–8https://doi.org/10.1145/1870109.1870110Published:01 November 2010Publication History 2citation489DownloadsMetricsTotal Citations2Total Downloads489Last 12 Months21Last 6 weeks0 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W2024951121",
    "type": "editorial"
  },
  {
    "title": "Methods for power optimization in SOC-based data flow systems",
    "doi": "https://doi.org/10.1145/1529255.1529260",
    "publication_date": "2009-05-01",
    "publication_year": 2009,
    "authors": "Philippe Grosse; Yves Durand; Paul Feautrier",
    "corresponding_authors": "",
    "abstract": "Whereas the computing power of DSP or general-purpose processors was sufficient for 3G baseband telecommunication algorithms, stringent timing constraints of 4G wireless telecommunication systems require computing-intensive data-driven architectures. Managing the complexity of these systems within the energy constraints of a mobile terminal is becoming a major challenge for designers. System-level low-power policies have been widely explored for generic software-based systems, but data-flow architectures used for high data-rate telecommunication systems feature heterogeneous components that require specific configurations for power management. In this study, we propose an innovative power optimization scheme tailored to self-synchronized data-flow systems. Our technique, based on the synchronous data-flow modeling approach, takes advantage of the latest low-power techniques available for digital architectures. We illustrate our optimization method on a complete 4G telecommunication baseband modem and show the energy savings expected by this technique considering present and future silicon technologies.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W2028459234",
    "type": "article"
  },
  {
    "title": "A cosimulation methodology for HW/SW validation and performance estimation",
    "doi": "https://doi.org/10.1145/1497561.1497566",
    "publication_date": "2009-03-01",
    "publication_year": 2009,
    "authors": "Franco Fummi; Mirko Loghi; Massimo Poncino; Graziano Pravadelli",
    "corresponding_authors": "",
    "abstract": "Cosimulation strategies allow us to simulate and verify HW/SW embedded systems before the real platform is available. In this field, there is a large variety of approaches that rely on different communication mechanisms to implement an efficient interface between the SW and the HW simulators. However, the literature lacks a comprehensive methodology which addresses the need for integrating and synchronizing heterogeneous simulators, like, for example, the SystemC simulation kernel for HW modules and an instruction set simulator for SW applications, without being intrusive for the HW and SW descriptions involved in the simulation. In this context, this article presents, compares, and integrates in a system-level framework two different co-simulation strategies for modeling, analyzing, and validating the performance of a HW/SW embedded system. Moreover, for both of them, a mechanism is proposed to provide an accurate time synchronization of the HW/SW communication. The first strategy is intended to provide an early cosimulation environment where HW/SW interaction can be validated without involving the operating system. The communication is implemented between a single SW task and a SystemC description of an HW module by exploiting the features of the remote debugging interface of a debugger (the GNU GDB), and by modifying the SystemC simulation kernel. On the other hand, the second strategy is intended to be used in further development steps, when the operating system is introduced to validate the cosimulation between HW modules and multitasking SW applications. In this approach, the communication is implemented via interrupts by using the features offered by the operating system. Experimental results are reported on two different case studies to analyze and compare the effectiveness of both the approaches.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W2032085587",
    "type": "article"
  },
  {
    "title": "Low-energy volatile STT-RAM cache design using cache-coherence-enabled adaptive refresh",
    "doi": "https://doi.org/10.1145/2534393",
    "publication_date": "2013-12-01",
    "publication_year": 2013,
    "authors": "Jianhua Li; Liang Shi; Qingan Li; Chun Jason Xue; Yiran Chen; Yinlong Xu; Wei Wang",
    "corresponding_authors": "",
    "abstract": "Spin-Torque Transfer RAM (STT-RAM) is a promising candidate for SRAM replacement because of its excellent features, such as fast read access, high density, low leakage power, and CMOS technology compatibility. However, wide adoption of STT-RAM as cache memories is impeded by its long write latency and high write power. Recent work proposed improving the write performance through relaxing the retention time of STT-RAM cells. The resultant volatile STT-RAM needs to be periodically refreshed to prevent data loss. When volatile STT-RAM is applied as the last-level cache (LLC) in chip multiprocessor (CMP) systems, frequent refresh operations could dissipate significant extra energy. In addition, refresh operations could severely conflict with normal read/write operations to degrade overall system performance. Therefore, minimizing the performance impact caused by refresh operations is crucial for the adoption of volatile STT-RAM. In this article, we propose Cache-Coherence-Enabled Adaptive Refresh (CCear) to minimize the number of refresh operations for volatile STT-RAM, adopted as the LLC for CMP systems. Specifically, CCear interacts with cache coherence protocol and cache management policy to minimize the number of refresh operations on volatile STT-RAM caches. Full-system simulation results show that CCear performs close to an ideal refresh policy with low overhead. Compared with state-of-the-art refresh policies, CCear simultaneously improves the system performance and reduces the energy consumption. Moreover, the performance of CCear could be further enhanced using small filter caches to accommodate the not-refreshed private STT-RAM blocks.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W2043957422",
    "type": "article"
  },
  {
    "title": "Employing circadian rhythms to enhance power and reliability",
    "doi": "https://doi.org/10.1145/2491477.2491482",
    "publication_date": "2013-07-01",
    "publication_year": 2013,
    "authors": "Saket Gupta; Sachin S. Sapatnekar",
    "corresponding_authors": "",
    "abstract": "This article presents a novel scheme for saving architectural power by mitigating delay degradations in digital circuits due to bias temperature instability (BTI), inspired by the notion of human circadian rhythms. The method works in two alternating phases. In the first, the compute phase, the circuit is awake and active, operating briskly at a greater-than-nominal supply voltage which causes tasks to complete more quickly. In the second, the idle phase, the circuit is power-gated and put to sleep, enabling BTI recovery. Since the wakeful stage works at an elevated supply voltage, it results in greater aging than operation at the nominal supply voltage, but the sleep state involves a recovery that more than compensates for this differential. We demonstrate, both at the circuit and the architectural levels, that at about the same performance, this approach can result in appreciable BTI mitigation, thus reducing the guardbands necessary to protect against aging, which results in power savings over the conventional design.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W1973169141",
    "type": "article"
  },
  {
    "title": "A parallel branch-and-cut approach for detailed placement",
    "doi": "https://doi.org/10.1145/1929943.1929950",
    "publication_date": "2011-03-01",
    "publication_year": 2011,
    "authors": "Stephen Cauley; V. Balakrishnan; Yuanming Hu; Cheng‐Kok Koh",
    "corresponding_authors": "",
    "abstract": "We introduce a technique that utilizes distributing computing resources for the efficient optimization of a traditional physical design problem. Specifically, we present a detailed placement strategy designed to exploit distributed computing environments, where the additional computing resources are employed in parallel to improve the optimization time. A Mixed Integer Programming (MIP) model and branch-and-cut optimization strategy are employed to solve the standard cell placement problem. By exploiting the problem structure, our algorithm improves upon the solutions afforded by existing optimization algorithms. First, an efficient batch-branching technique can eliminate several integer decision variables during each step of the optimization procedure. This batch-branching scheme can be performed serially or in parallel. In addition, custom cutting-planes are shown to significantly reduce the run time for optimizations as they efficiently refine the feasible region in order to quickly produce integer solutions. Our serial branch-and-cut strategies allow for significant reductions in wirelength, relative to the state-of-the-art commercial software package CPLEX, assuming a fixed allotment of time. Furthermore, we show that distributed computing resources can be used to significantly reduce the time required to achieve reductions in wirelength.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W1994553019",
    "type": "article"
  },
  {
    "title": "A comparative evaluation of multi-objective exploration algorithms for high-level design",
    "doi": "https://doi.org/10.1145/2566669",
    "publication_date": "2014-03-01",
    "publication_year": 2014,
    "authors": "Jacopo Panerati; Giovanni Beltrame",
    "corresponding_authors": "",
    "abstract": "This article presents a detailed overview and the experimental comparison of 15 multi-objective design-space exploration (DSE) algorithms for high-level design. These algorithms are collected from recent literature and include heuristic, evolutionary, and statistical methods. To provide a fair comparison, the algorithms are classified according to the approach used and examined against a large set of metrics. In particular, the effectiveness of each algorithm was evaluated for the optimization of a multiprocessor platform, considering initial setup effort, rate of convergence, scalability, and quality of the resulting optimization. Our experiments are performed with statistical rigor, using a set of very diverse benchmark applications (a video converter, a parallel compression algorithm, and a fast Fourier transformation algorithm) to take a large spectrum of realistic workloads into account. Our results provide insights on the effort required to apply each algorithm to a target design space, the number of simulations it requires, its accuracy, and its precision. These insights are used to draw guidelines for the choice of DSE algorithms according to the type and size of design space to be optimized.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W2061895663",
    "type": "article"
  },
  {
    "title": "Performance/Thermal-Aware Design of 3D-Stacked L2 Caches for CMPs",
    "doi": "https://doi.org/10.1145/2159542.2159545",
    "publication_date": "2012-04-01",
    "publication_year": 2012,
    "authors": "Guangyu Sun; Huazhong Yang; Yuan Xie",
    "corresponding_authors": "",
    "abstract": "Three-dimensional (3D) stacking technology enables integration of more memory on top of chip multiprocessors (CMPs). As the number of cores and the capacity of on-chip memory increase, the Non-Uniform Cache Architecture (NUCA) becomes more attractive. Compared to 2D cases, 3D stacking provides more options for the design of on-chip memory due to numerous advantages, such as the extra layout dimension, low latency across layers, etc. On the other hand, 3D stacking aggravates the thermal problem due to the increase of power density. In this work, we first study the design of 3D-stacked set-associative L2 caches through managing the placement of cache ways. The evaluation results show that the placement and corresponding management of 3D cache ways have an impact on the performance of CMPs. Then, we show that the efficiency of thermal control is also related to the placement of cache ways. For caches implemented with different memory technologies, the placement and management of cache ways have different effects on power consumption and power distribution. Consequently, we propose techniques to improve the efficiency of thermal control for different memory technologies. The evaluation results show the trade-off between performance and thermal control efficiency.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W2066068148",
    "type": "article"
  },
  {
    "title": "Online thermal control methods for multiprocessor systems",
    "doi": "https://doi.org/10.1145/2390191.2390197",
    "publication_date": "2013-01-01",
    "publication_year": 2013,
    "authors": "Francesco Zanini; David Atienza; Colin N. Jones; Luca Benini; Giovanni De Micheli",
    "corresponding_authors": "",
    "abstract": "With technological advances, the number of cores integrated on a chip is increasing. This in turn is leading to thermal constraints and thermal design challenges. Temperature gradients and hotspots not only affect the performance of the system but also lead to unreliable circuit operation and affect the lifetime of the chip. Meeting temperature constraints and reducing hotspots are critical for achieving reliable and efficient operation of complex multi-core systems. In this article, we analyze the use of four of the most promising families of online control techniques for thermal management of multiprocessors system-on-chip (MPSoC). In particular, in our exploration, we aim at achieving an online smooth thermal control action that minimizes the performance loss as well as the computational and hardware overhead of embedding a thermal management system inside the MPSoC. The definition of the optimization problem to tackle in this work considers the thermal profile of the system, its evolution over time, and current time-varying workload requirements. Thus, this problem is formulated as a finite-horizon optimal control problem, and we analyze the control features of different online thermal control approaches. In addition, we implemented the policies on an MPSoC hardware simulation platform and performed experiments on a cycle-accurate model of the eight-core Niagara multi-core architecture using benchmarks ranging from Web-accessing to playing multimedia. Results show different trade-offs among the analyzed techniques regarding the thermal profile, the frequency setting, the power consumption, and the implementation complexity.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W2159643889",
    "type": "article"
  },
  {
    "title": "A Model-Driven Engineering Methodology to Design Parallel and Distributed Embedded Systems",
    "doi": "https://doi.org/10.1145/2999537",
    "publication_date": "2017-01-04",
    "publication_year": 2017,
    "authors": "Andrea Enrici; Ludovic Apvrille; Renaud Pacalet",
    "corresponding_authors": "",
    "abstract": "In Model-Driven Engineering system-level approaches, the design of communication protocols and patterns is subject to the design of processing operations (computations) and to their mapping onto execution resources. However, this strategy allows us to capture simple communication schemes (e.g., processor-bus-memory) and prevents us from evaluating the performance of both computations and communications (e.g., impact of application traffic patterns onto the communication interconnect) in a single step. To solve these issues, we introduce a novel design approach—the Ψ-chart—where we design communication patterns and protocols independently of a system’s functionality and resources, via dedicated models. At the mapping step, both application and communication models are bound to the platform resources and transformed to explore design alternatives for both computations and communications. We present the Ψ-chart and its implementation (i.e., communication models and Design Space Exploration) in TTool/DIPLODOCUS, a Unified Modeling Language (UML)/SysML framework for the modeling, simulation, formal verification and automatic code generation of data-flow embedded systems. The effectiveness of our solution in terms of better design quality (e.g., portability, time) is demonstrated with the design of the physical layer of a ZigBee (IEEE 802.15.4) transmitter onto a multi-processor architecture.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W2569847765",
    "type": "article"
  },
  {
    "title": "Scrubbing Mechanism for Heterogeneous Applications in Reconfigurable Devices",
    "doi": "https://doi.org/10.1145/2997646",
    "publication_date": "2017-02-09",
    "publication_year": 2017,
    "authors": "Rui Santos; Shyamsundar Venkataraman; Akash Kumar",
    "corresponding_authors": "",
    "abstract": "Commercial off-the-shelf (COTS) reconfigurable devices have been recognized as one of the most suitable processing devices to be applied in nano-satellites, since they can satisfy and combine their most important requirements, namely processing performance, reconfigurability, and low cost. However, COTS reconfigurable devices, in particular Static-RAM Field Programmable Gate Arrays, can be affected by cosmic radiation, compromising the overall nano-satellite reliability. Scrubbing has been proposed as a mechanism to repair faults in configuration memory. However, the current scrubbing mechanisms are predominantly static, unable to adapt to heterogeneous applications and their runtime variations. In this article, a dynamically adaptive scrubbing mechanism is proposed. Through a window-based scrubbing scheduling, this mechanism adapts the scrubbing process to heterogeneous applications (composed of periodic/sporadic and streaming/DSP (Digital Signal Processing) tasks), as well as their reconfigurations and modifications at runtime. Conducted simulation experiments show the feasibility and the efficiency of the proposed solution in terms of system reliability metric and memory overhead.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W2586365929",
    "type": "article"
  },
  {
    "title": "Optimization and Quality Estimation of Circuit Design via Random Region Covering Method",
    "doi": "https://doi.org/10.1145/3084685",
    "publication_date": "2017-08-01",
    "publication_year": 2017,
    "authors": "Zhaori Bi; Dian Zhou; Sheng-Guo Wang; Xuan Zeng",
    "corresponding_authors": "",
    "abstract": "Random region covering is a global optimization technique that explores the landscape by introducing multiple random starting points to initiate the local optimization solvers. This study applies the random region covering technique to circuit design automation and proposes a theory to explain why this technique is efficient at searching for the global optimum. In addition to analyzing the efficiency of the random region covering algorithm, the theory gives a probability-based estimation of the goodness of the optimization result. To enhance the efficiency of the random region covering technique, this work evaluates the boundary of top performance regions and proposes a modified random region covering method that only performs the global optimization on the top design region. The results from a large number of mathematical experiments verify the proposed methodology. The optimized designs of a class-E power amplifier and a wide load range operational amplifier outperform both manual designs and other state-of-the-art optimization techniques.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W2742044854",
    "type": "article"
  },
  {
    "title": "Reducing Writebacks Through In-Cache Displacement",
    "doi": "https://doi.org/10.1145/3289187",
    "publication_date": "2019-01-10",
    "publication_year": 2019,
    "authors": "Mohammad Bakhshalipour; Aydin Faraji; Seyed Armin Vakil Ghahani; Farid Samandi; Pejman Lotfi-Kamran; Hamid Sarbazi‐Azad",
    "corresponding_authors": "",
    "abstract": "Non-Volatile Memory (NVM) technology is a promising solution to fulfill the ever-growing need for higher capacity in the main memory of modern systems. Despite having many great features, however, NVM’s poor write performance remains a severe obstacle, preventing it from being used as a DRAM alternative in the main memory. Most of the prior work targeted optimizing writes at the main memory side and neglected the decisive role of upper-level cache management policies on reducing the number of writes. In this article, we propose a novel cache management policy that attempts to maximize write-coalescing in the on-chip SRAM last-level cache (LLC) for the sake of reducing the number of costly writes to the off-chip NVM. We decouple a few physical ways of the LLC to have a dedicated and exclusive storage for the dirty blocks after being evicted from the cache and before being sent to the off-chip memory. By displacing dirty blocks in exclusive storage, they are kept in the cache based on their rewrite distance and are evicted when they are unlikely to be reused shortly. To maximize the effectiveness of exclusive storage, we manage it as a Cuckoo Cache to offer associativity based on the various applications’ demands. Through detailed evaluations targeting various single- and multi-threaded applications, we show that our proposal reduces the number of writebacks by 21%, on average, over the state-of-the-art method and enhances both performance and energy efficiency.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W2910601204",
    "type": "article"
  },
  {
    "title": "Compilation of Dataflow Applications for Multi-Cores using Adaptive Multi-Objective Optimization",
    "doi": "https://doi.org/10.1145/3310249",
    "publication_date": "2019-03-11",
    "publication_year": 2019,
    "authors": "Tobias Schwarzer; Joachim Falk; Simone Müller; Martín Letras; Christian Heidorn; Stefan Wildermann; Jürgen Teich",
    "corresponding_authors": "",
    "abstract": "State-of-the-art system synthesis techniques employ meta-heuristic optimization techniques for Design Space Exploration (DSE) to tailor application execution, e.g., defined by a dataflow graph, for a given target platform. Unfortunately, the performance evaluation of each implementation candidate is computationally very expensive, in particular on recent multi-core platforms, as this involves compilation to and extensive evaluation on the target hardware. Applying heuristics for performance evaluation on the one hand allows for a reduction of the exploration time but on the other hand may deteriorate the convergence of the optimization technique toward performance-optimal solutions with respect to the target platform. To address this problem, we propose DSE strategies that are able to dynamically trade off between (i) approximating heuristics to guide the exploration and (ii) accurate performance evaluation, i.e., compilation of the application and subsequent performance measurement on the target platform. Technically, this is achieved by introducing a set of additional, but easily computable guiding objective functions, and varying the set of objective functions that are evaluated during the DSE adaptively. One major advantage of these guiding objectives is that they are generically applicable for dataflow models without having to apply any configuration techniques to tailor their parameters to the specific use case. We show this for synthetic benchmarks as well as a real-world control application. Moreover, the experimental results demonstrate that our proposed adaptive DSE strategies clearly outperform a state-of-the-art DSE approach known from literature in terms of the quality of the gained implementations as well as exploration times. Amongst others, we show a case for a two-core implementation where after about 3 hours of exploration time one of our proposed adaptive DSE strategies already obtains a 60% higher performance value than obtained by the state-of-the-art approach. Even when the state-of-the-art approach is given a total exploration time of more than 2 weeks to optimize this value, the proposed adaptive DSE strategy features a 20% higher performance value after a total exploration time of about 4 days.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W2921571121",
    "type": "article"
  },
  {
    "title": "Instruction-Level Abstraction (ILA): A Uniform Specification for System-on-Chip (SoC) Verification",
    "doi": null,
    "publication_date": "2018-12-21",
    "publication_year": 2018,
    "authors": "Bo-Yuan Huang; Hongce Zhang; Pramod Subramanyan; Yakir Vizel; Aarti Gupta; Sharad Malik",
    "corresponding_authors": "",
    "abstract": "Modern Systems-on-Chip (SoC) designs are increasingly heterogeneous and contain specialized semi-programmable accelerators in addition to programmable processors. In contrast to the pre-accelerator era, when the ISA played an important role in verification by enabling a clean separation of concerns between software and hardware, verification of these “accelerator-rich” SoCs presents new challenges. From the perspective of hardware designers, there is a lack of a common framework for formal functional specification of accelerator behavior. From the perspective of software developers, there exists no unified framework for reasoning about software/hardware interactions of programs that interact with accelerators.This article addresses these challenges by providing a formal specification and high-level abstraction for accelerator functional behavior. It formalizes the concept of an Instruction Level Abstraction (ILA), developed informally in our previous work, and shows its application in modeling and verification of accelerators. This formal ILA extends the familiar notion of instructions to accelerators and provides a uniform, modular, and hierarchical abstraction for modeling software-visible behavior of both accelerators and programmable processors. We demonstrate the applicability of the ILA through several case studies of accelerators (for image processing, machine learning, and cryptography), and a general-purpose processor (RISC-V). We show how the ILA model facilitates equivalence checking between two ILAs, and between an ILA and its hardware finite-state machine (FSM) implementation. Further, this equivalence checking supports accelerator upgrades using the notion of ILA compatibility, similar to processor upgrades using ISA compatibility.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W3101944603",
    "type": "article"
  },
  {
    "title": "Accurate Modeling of Nonideal Low-Power PWM DC-DC Converters Operating in CCM and DCM using Enhanced Circuit-Averaging Techniques",
    "doi": "https://doi.org/10.1145/2890500",
    "publication_date": "2016-05-27",
    "publication_year": 2016,
    "authors": "Dani Tannir; Ya Wang; Peng Li",
    "corresponding_authors": "",
    "abstract": "The development of enhanced modeling techniques for the simulation of switched-mode Pulse Width Modulated (PWM) DC-DC power converters using circuit averaging is the main focus of this article. The circuit-averaging technique has traditionally been used to model the behavior of PWM DC-DC converters without considering important nonideal characteristics of the switching devices. As a result, most of these existing approaches present simplified models that are ideal or linearized, and do not accurately account for the performance characteristics of the converter. This is especially problematic for low-power applications. In this article, we present an enhanced nonideal behavioral circuit-averaged model that makes the simulation of DC-DC converters both computationally efficient and accurate, thereby presenting an important tool for circuit designers. Experimentally, we show that our Verilog-A-based new model allows for accurate simulation of both Buck- and Boost-type PWM converters operating in either CCM or DCM modes while providing more than one order of magnitude speedup over the transistor-level simulation.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2460053499",
    "type": "article"
  },
  {
    "title": "Data-driven Anomaly Detection with Timing Features for Embedded Systems",
    "doi": "https://doi.org/10.1145/3279949",
    "publication_date": "2019-04-02",
    "publication_year": 2019,
    "authors": "Sixing Lu; Roman Lysecky",
    "corresponding_authors": "",
    "abstract": "Malware is a serious threat to network-connected embedded systems, as evidenced by the continued and rapid growth of such devices, commonly referred to as the Internet of Things. Their ubiquitous use in critical applications require robust protection to ensure user safety and privacy. That protection must be applied to all system aspects, extending beyond protecting the network and external interfaces. Anomaly detection is one of the last lines of defence against malware, in which data-driven approaches that require the least domain knowledge are popular. However, embedded systems, particularly edge devices, face several challenges in applying data-driven anomaly detection, including unpredictability of malware, limited tolerance to long data collection windows, and limited computing/energy resources. In this article, we utilize subcomponent timing information of software execution, including intrinsic software execution, instruction cache misses, and data cache misses as features, to detect anomalies based on ranges, multi-dimensional Euclidean distance, and classification at runtime. Detection methods based on lumped timing range are also evaluated and compared. We design several hardware detectors implementing these data-driven detection methods, which non-intrusively measuring lumped/subcomponent timing of all system/function calls of the embedded application. We evaluate the area, power, and detection latency of the presented detector designs. Experimental results demonstrate that the subcomponent timing model provides sufficient features to achieve high detection accuracy with low false-positive rates using a one-class support vector machine, considering sophisticated mimicry malware.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2926997059",
    "type": "article"
  },
  {
    "title": "Lithography Hotspot Detection with FFT-based Feature Extraction and Imbalanced Learning Rate",
    "doi": "https://doi.org/10.1145/3372044",
    "publication_date": "2019-12-19",
    "publication_year": 2019,
    "authors": "Xu He; Yu Deng; Shizhe Zhou; Rui Li; Yao Wang; Yang Guo",
    "corresponding_authors": "",
    "abstract": "With the increasing gap between transistor feature size and lithography manufacturing capability, the detection of lithography hotspots becomes a key stage of physical verification flow to enhance manufacturing yield. Although machine learning approaches are distinguished for their high detection efficiency, they still suffer from problems such as large-scale layout and class imbalance. In this article, we develop a hotspot detection model based on machine learning with high performance. In the proposed model, we first apply an Fast Fourier Transform--based feature extraction method that can compress large-scale layout to a multi-dimensional representation with much smaller size while preserving the discriminative layout pattern information to improve the detection efficiency. Second, addressing the class imbalance problem, we propose a new technique called imbalanced learning rate and embed it into the convolutional neural network model to further reduce false alarms without accuracy decay. Compared with the results of current state-of-the-art approaches on ICCAD 2012 Contest benchmarks, our proposed model can achieve better solutions in many evaluation metrics, including the official metrics.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W3014404070",
    "type": "article"
  },
  {
    "title": "Architecting the Last-Level Cache for GPUs using STT-RAM Technology",
    "doi": "https://doi.org/10.1145/2764905",
    "publication_date": "2015-09-28",
    "publication_year": 2015,
    "authors": "Mohammad Hossein Samavatian; Mohammad Arjomand; Ramin Bashizade; Hamid Sarbazi‐Azad",
    "corresponding_authors": "",
    "abstract": "Future GPUs should have larger L2 caches based on the current trends in VLSI technology and GPU architectures toward increase of processing core count. Larger L2 caches inevitably have proportionally larger power consumption. In this article, having investigated the behavior of GPGPU applications, we present an efficient L2 cache architecture for GPUs based on STT-RAM technology. Due to its high-density and low-power characteristics, STT-RAM technology can be utilized in GPUs where numerous cores leave a limited area for on-chip memory banks. They have, however, two important issues, high energy and latency of write operations, that have to be addressed. Low retention time STT-RAMs can reduce the energy and delay of write operations. Nevertheless, employing STT-RAMs with low retention time in GPUs requires a thorough study on the behavior of GPGPU applications. Based on this investigation, we have architectured a two-part STT-RAM-based L2 cache with low-retention (LR) and high-retention (HR) parts. The proposed two-part L2 cache exploits a dynamic threshold regulator (DTR) to efficiently regulate the write threshold for migration of the data blocks from HR to LR, based on the behavior of the applications. Also, a Data and Access type Aware Cache Search mechanism (DAACS) is hired for handling the search of the requested data blocks in two parts of the cache. The STT-RAM L2 cache architecture proposed in this article can improve IPC by up to 171% (20% on average), and reduce the average consumed power by 28.9% compared to a conventional L2 cache architecture with equal on-chip area.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W2063731364",
    "type": "article"
  },
  {
    "title": "Scalable Power Management Using Multilevel Reinforcement Learning for Multiprocessors",
    "doi": "https://doi.org/10.1145/2629486",
    "publication_date": "2014-08-01",
    "publication_year": 2014,
    "authors": "Gung-Yu Pan; Jing-Yang Jou; Bo‐Cheng Lai",
    "corresponding_authors": "",
    "abstract": "Dynamic power management has become an imperative design factor to attain the energy efficiency in modern systems. Among various power management schemes, learning-based policies that are adaptive to different environments and applications have demonstrated superior performance to other approaches. However, they suffer the scalability problem for multiprocessors due to the increasing number of cores in a system. In this article, we propose a scalable and effective online policy called MultiLevel Reinforcement Learning (MLRL). By exploiting the hierarchical paradigm, the time complexity of MLRL is O ( n lg n ) for n cores and the convergence rate is greatly raised by compressing redundant searching space. Some advanced techniques, such as the function approximation and the action selection scheme, are included to enhance the generality and stability of the proposed policy. By simulating on the SPLASH-2 benchmarks, MLRL runs 53% faster and outperforms the state-of-the-art work with 13.6% energy saving and 2.7% latency penalty on average. The generality and the scalability of MLRL are also validated through extensive simulations.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W2140768449",
    "type": "article"
  },
  {
    "title": "Machine Learning Assisted PUF Calibration for Trustworthy Proof of Sensor Data in IoT",
    "doi": "https://doi.org/10.1145/3393628",
    "publication_date": "2020-06-08",
    "publication_year": 2020,
    "authors": "Urbi Chatterjee; Soumi Chatterjee; Debdeep Mukhopadhyay; Rajat Subhra Chakraborty",
    "corresponding_authors": "",
    "abstract": "Remote integrity verification plays a paramount role in resource-constraint devices owing to emerging applications such as Internet-of-Things (IoT), smart homes, e-health, and so on. The concept of Virtual Proof of Reality (VPoR) proposed by Rührmair et al. in 2015 has come up with a Sense-Prove-Validate framework for integrity checking of abundant data generated from billions of connected sensors. It leverages the unreliability factor of Physically Unclonable Functions (PUFs) with respect to ambient parameter variations such as temperature, supply voltages, and so on, and claims to prove the authenticity of the sensor data without using any explicit keys. The state-of-the-art authenticated sensing protocols majorly lack in limited authentications and huge storage overhead. These protocols also assume that the behaviour of the PUF instances varies unpredictably for different levels of ambient factors, which in turn makes them hard to go beyond the theoretical concept. We address these issues in this work 1 and propose a Machine Learning (ML) assisted PUF calibration scheme to predict the Challenge-Response Pair (CRP) behaviour of a PUF instance in a specific environment, given the CRP behaviour in a pivot environment. Here, we present a new class of authenticated sensing protocols where we leverage the beneficence of ML techniques to validate the authenticity and integrity of sensor data over ambient factor variations. The scheme also reduces the storage complexity of the verifier from O ( p * K * l * ( c + r )) to O ( p * l *( c + r )), where p is the number of PUF instances deployed in the framework, l is the number of challenge-response pairs used for authentication, c is the bit lengths of the challenge, r is the response bits of the PUF, and K is the number of levels of ambient factor variations. The scheme alleviates the issue of limited authentication as well, whereby every CRP is used only once for authentication and then deleted from the database. To validate the proposed protocol through actual experiments on FPGA, we propose 5-4 Double Arbiter PUF, which is an extension of Double Arbiter PUFs (DAPUFs) as this design is more suited for FPGA, and implement it on Xilinx Artix-7 FPGAs. We characterise the proposed PUF instance from −20° C to 80° C and use Random Forest --based ML technique to generate a soft model of the PUF instance. This model is further used by the verifier to authenticate the actual PUF circuit. According to the FPGA-based validation, the proposed protocol with DAPUF can be effectively used to authenticate sensor devices across wide variations of temperature values.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W3034680951",
    "type": "article"
  },
  {
    "title": "Strong Logic Obfuscation with Low Overhead against IC Reverse Engineering Attacks",
    "doi": "https://doi.org/10.1145/3398012",
    "publication_date": "2020-06-08",
    "publication_year": 2020,
    "authors": "Qutaiba Alasad; Jiann-Shuin Yuan; Pramod Subramanyan",
    "corresponding_authors": "",
    "abstract": "Untrusted foundries pose threats of integrated circuit (IC) piracy and counterfeiting, and this has motivated research into logic locking. Strong logic locking approaches potentially prevent piracy and counterfeiting by preventing unauthorized replication and use of ICs. Unfortunately, recent work has shown that most state-of-the-art logic locking techniques are vulnerable to attacks that utilize Boolean Satisfiability (SAT) solvers. In this article, we extend our prior work on using silicon nanowire (SiNW) field-effect transistors (FETs) to produce obfuscated ICs that are resistant to reverse engineering attacks, such as the sensitization attack, SAT and approximate SAT attacks, as well as tracked signal attacks. Our method is based on exchanging some logic gates in the original design with a set of polymorphic gates (PLGs), designed using SiNW FETs, and augmenting the circuit with a small block, whose output is untraceable, namely, URSAT. The URSAT may not offer very strong resilience against the combined AppSAT-removal attack. Strong URSAT is achieved using only CMOS-logic gates, namely, S-URSAT. The proposed technique, S-URSAT + PLG-based traditional encryption, designed using SiNW FETs, increases the security level of the design to robustly thwart all existing attacks, including combined AppSAT-removal attack, with small penalties. Then, we evaluate the effectiveness of our proposed methods and subject it to a thorough security analysis. We also evaluate the performance penalty of the technique and find that it results in very small overheads in comparison to other works. The average area, power, and delay overheads of implementing 64 baseline key-bits of S-URSAT for small benchmarks are 5.03%, 2.60%, and −2.26%, respectively, while for large benchmarks they are 2.37%, 1.18%, and −1.93%.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W3035438326",
    "type": "article"
  },
  {
    "title": "Machine Learning Approach for Fast Electromigration Aware Aging Prediction in Incremental Design of Large Scale On-chip Power Grid Network",
    "doi": "https://doi.org/10.1145/3399677",
    "publication_date": "2020-07-05",
    "publication_year": 2020,
    "authors": "Sukanta Dey; Sukumar Nandi; Gaurav Trivedi",
    "corresponding_authors": "",
    "abstract": "With the advancement of technology nodes, Electromigration (EM) signoff has become increasingly difficult, which requires a considerable amount of time for an incremental change in the power grid (PG) network design in a chip. The traditional Black’s empirical equation and Blech’s criterion are still used for EM assessment, which is a time-consuming process. In this article, for the first time, we propose a machine learning (ML) approach to obtain the EM-aware aging prediction of the PG network. We use neural network--based regression as our core ML technique to instantly predict the lifetime of a perturbed PG network. The performance and accuracy of the proposed model using neural network are compared with the well-known standard regression models. We also propose a new failure criterion based on which the EM-aging prediction is done. Potential EM-affected metal segments of the PG network is detected by using a logistic-regression--based classification ML technique. Experiments on different standard PG benchmarks show a significant speedup for our ML model compared to the state-of-the-art models. The predicted value of MTTF for different PG benchmarks using our approach is also better than some of the state-of-the-art MTTF prediction models and comparable to the other accurate models.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W3040013232",
    "type": "article"
  },
  {
    "title": "Mitigating Negative Impacts of Read Disturb in SSDs",
    "doi": "https://doi.org/10.1145/3410332",
    "publication_date": "2020-09-01",
    "publication_year": 2020,
    "authors": "Jun Li; Bowen Huang; Zhibing Sha; Zhigang Cai; Jianwei Liao; Balazs Gerofi; Yutaka Ishikawa",
    "corresponding_authors": "",
    "abstract": "Read disturb is a circuit-level noise in solid-state drives (SSDs), which may corrupt existing data in SSD blocks and then cause high read error rate and longer read latency. The approach of read refresh is commonly used to avoid read disturb errors by periodically migrating the hot read data to other free blocks, but it places considerable negative impacts on I/O (Input/Output) responsiveness. This article proposes scheduling approaches on write data and read refresh operations, to mitigate the negative effects caused by read disturb. To be specific, we first construct a model to classify SSD blocks into two categories according to the estimated read error rate by referring to the factors of block’s P/E (Program/Erase) cycle and the accumulated read count to the block. Then, the data being intensively read will be redirected to the block having a small read error rate, as it is not sensitive to read disturb even though the data will be heavily requested. Moreover, we take advantage of reinforcement learning to predict the idle interval between two I/O requests for purposely conducting (partial) read refresh operations. As a result, it is able to minimize negative impacts toward subsequent incoming I/O requests and to ensure I/O responsiveness. Through a series of emulation tests on several realistic disk traces, we demonstrate that the proposed mechanisms can noticeably yield performance improvements on the metrics of read error rate and I/O latency.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W3085404611",
    "type": "article"
  },
  {
    "title": "A Robust Modulus-Based Matrix Splitting Iteration Method for Mixed-Cell-Height Circuit Legalization",
    "doi": "https://doi.org/10.1145/3423326",
    "publication_date": "2020-12-10",
    "publication_year": 2020,
    "authors": "Jianli Chen; Ziran Zhu; Wenxing Zhu; Chang Yao-Wen",
    "corresponding_authors": "",
    "abstract": "Modern circuits often contain standard cells of different row heights to meet various design requirements. Taller cells give larger drive strengths and higher speed at the cost of larger areas and power. Multi-row height standard cells incur challenging issues for layout designs, especially the mixed-cell-height legalization problem with heterogeneous cell structures. Honoring the good cell positions from global placement, we present in this article a robust modulus-based matrix splitting iteration method (RMMSIM) to solve the mixed-cell-height legalization problem. Fixing the cell ordering from global placement and relaxing the right-boundary constraints, our proposed method first converts the problem into an equivalent linear complementarity problem (LCP), and then properly splits the matrices in the LCP so that the RMMSIM can solve the LCP optimally. The RMMSIM effectively explores the sparse characteristic of a circuit, and takes only linear time per iteration; as a result, it can solve the QP very efficiently. Finally, an allocation scheme for illegal cells is used to align such cells to placement sites on rows and fix the placement of out-of-right-boundary cells, if any. Experimental results show the effectiveness and efficiency of our proposed algorithm. In addition, the RMMSIM convergence and optimality are theoretically proved and empirically validated. In particular, this article provides a new RMMSIM formulation for various optimization problems that require solving large-scale convex quadratic programming problems efficiently.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W3111205547",
    "type": "article"
  },
  {
    "title": "FUBOCO: Structure Synthesis of Basic Op-Amps by FUnctional BlOck COmposition",
    "doi": "https://doi.org/10.1145/3522738",
    "publication_date": "2022-03-09",
    "publication_year": 2022,
    "authors": "Inga Abel; Helmut Graeb",
    "corresponding_authors": "",
    "abstract": "This article presents a method to automatically synthesize the structure and initial sizing of an operational amplifier. It is positioned between approaches with fixed design plans and a small search space of structures and approaches with generic structural production rules and a large search space with technically impractical structures. The presented approach develops a hierarchical composition graph based on functional blocks that spans a search space of thousands of technically meaningful structure variants for single-output, fully differential, and complementary operational amplifiers. The search algorithm is a combined heuristic and enumerative process. The evaluation is based on circuit sizing with a library of behavioral equations of functional blocks. Formalizing the knowledge of functional blocks in op-amps for structural synthesis and sizing inherently reduces the search space and lessens the number of created topologies not fulfilling the specifications. Experimental results for the three op-amp classes are presented. An outlook how this method can be extended to multi-stage op-amps is given.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W3204161648",
    "type": "article"
  },
  {
    "title": "GraphPlanner: Floorplanning with Graph Neural Network",
    "doi": "https://doi.org/10.1145/3555804",
    "publication_date": "2022-08-17",
    "publication_year": 2022,
    "authors": "Yiting Liu; Ziyi Ju; Zhengming Li; Mingzhi Dong; Hai Zhou; Jia Wang; Fan Yang; Xuan Zeng; Li Shang",
    "corresponding_authors": "",
    "abstract": "Chip floorplanning has long been a critical task with high computation complexity in the physical implementation of VLSI chips. Its key objective is to determine the initial locations of large chip modules with minimized wirelength while adhering to the density constraint, which in essence is a process of constructing an optimized mapping from circuit connectivity to physical locations. Proven to be an NP-hard problem, chip floorplanning is difficult to be solved efficiently using algorithmic approaches. This article presents GraphPlanner, a variational graph-convolutional-network-based deep learning technique for chip floorplanning. GraphPlanner is able to learn an optimized and generalized mapping between circuit connectivity and physical wirelength and produce a chip floorplan using efficient model inference. GraphPlanner is further equipped with an efficient clustering method, a unification of hyperedge coarsening with graph spectral clustering, to partition a large-scale netlist into high-quality clusters with minimized inter-cluster weighted connectivity. GraphPlanner has been integrated with two state-of-the-art mixed-size placers. Experimental studies using both academic benchmarks and industrial designs demonstrate that compared to state-of-the-art mixed-size placers alone, GraphPlanner improves placement runtime by 25% with 4% wirelength reduction on average.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W4292092927",
    "type": "article"
  },
  {
    "title": "CNN-Cap: Effective Convolutional Neural Network-based Capacitance Models for Interconnect Capacitance Extraction",
    "doi": "https://doi.org/10.1145/3564931",
    "publication_date": "2022-09-26",
    "publication_year": 2022,
    "authors": "Dingcheng Yang; Haoyuan Li; Wenjian Yu; Yuanbo Guo; Wenjie Liang",
    "corresponding_authors": "",
    "abstract": "Accurate capacitance extraction is becoming more important for designing integrated circuits under advanced process technology. The pattern matching-based full-chip extraction methodology delivers fast computational speed but suffers from large error and tedious efforts on building capacitance models of the increasing structure patterns. In this work, we propose an effective method for building convolutional neural network (CNN)-based capacitance models (called CNN-Cap) for two-dimensional (2-D) and three -dimensional (3-D) interconnect structures. With a novel grid-based data representation, the proposed method is able to model 2-D pattern structure and 3-D window structure with a variable number of conductors to largely reduce the number of patterns or increase the accuracy. Based on the ability of ResNet architecture on capturing spatial information and the proposed training skills, the obtained CNN-Cap exhibits much better performance over the multilayer perception neural network-based capacitance model while being more versatile. Extensive experiments on a 55 nm and a 15 nm process technologies have demonstrated that the error of total capacitance produced with 2-D CNN-Cap is always within 1.3%, and the error of produced coupling capacitance is less than 10% in over 99.5% probability. For 3-D structures, CNN-Cap predicts the total capacitance with less than 5% error in 99% probability and with a maximum error of 7.7%. For the tested 2-D and 3-D structures, the CNN-Cap run on a GPU server is more than 4,000× and 12,000×, respectively, faster than the conventional field solver Raphael, while consuming negligible memory.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W4297239078",
    "type": "article"
  },
  {
    "title": "Routability-driven Power/Ground Network Optimization Based on Machine Learning",
    "doi": "https://doi.org/10.1145/3587817",
    "publication_date": "2023-03-25",
    "publication_year": 2023,
    "authors": "Ping-Wei Huang; Yao‐Wen Chang",
    "corresponding_authors": "",
    "abstract": "The dynamic IR drop of a power/ground (PG) network is a critical problem in modern circuit designs. Excessive IR drop slows down circuit performance and causes potential functional failures. Most industrial practices tend to over-design the PG network for the dynamic IR drop constraints, reducing routing resources and incurring routing congestion. Existing machine learning-based approaches target only dynamic IR drop prediction without considering the routability affected by the P/G network. This article develops a machine learning-based method to solve the dynamic IR drop and routing resources tradeoffs. Our model can predict the two targets accurately by adopting a multi-task learning scheme, achieving a 0.99 high correlation coefficient. We show that our trained model is generalizable by testing different placement results. Our algorithm also achieves significant speedups of up to 29× compared to the time-consuming dynamic IR drop simulation by a leading commercial tool. Experimental results show that our algorithm can save about 13% routing resources without worsening the dynamic IR drop peak value.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4360948889",
    "type": "article"
  },
  {
    "title": "MEDUSA: A Multi-Resolution Machine Learning Congestion Estimation Method for 2D and 3D Global Routing",
    "doi": "https://doi.org/10.1145/3590768",
    "publication_date": "2023-04-01",
    "publication_year": 2023,
    "authors": "Zhonghua Zhou; Yuxuan Pan; Guy Lemieux; A. Ivanov",
    "corresponding_authors": "",
    "abstract": "Routing congestion is one of the many factors that need to be minimized during the physical design phase of large integrated circuits. In this article, we propose a novel congestion estimation method, called MEDUSA , that consists of three parts: (1) a feature extraction and “hyper-image” encoding; (2) a congestion estimation method using a fixed-resolution convolutional neural network model that takes a tile of this hyper-image as input and makes accurate congestion predictions for a small region of the circuit; and (3) a sliding-window method for repeatedly applying this convolutional neural network on a layout, thereby producing higher-resolution congestion maps for arbitrarily large circuits. The proposed congestion estimation approach works with both 2D (collapsed) and 3D global routing. Using both quantitative metrics and qualitative visual inspection, congestion maps produced with MEDUSA show better accuracy than prior estimation techniques. Global routers typically use estimation techniques during their first router iteration and then switch to using actual congestion information extracted from the intermediate router solutions. Experimental results within the same global router infrastructure show a significant impact on quality after the first routing iteration; other estimation techniques result in an average of 22% to 54% higher initial overflow counts. This initial quality improvement carries through to the final global routing solution, with other estimation techniques needing up to 5% more routing iterations and up to 3× more runtime, on average. Compared with other global routers, MEDUSA achieves comparable wire length results and lower total overflow counts (more legal global routing solutions) and is typically faster.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4362453037",
    "type": "article"
  },
  {
    "title": "Uncertainty-aware Energy Harvest Prediction and Management for IoT Devices",
    "doi": "https://doi.org/10.1145/3606372",
    "publication_date": "2023-06-29",
    "publication_year": 2023,
    "authors": "Nuzhat Yamin; Ganapati Bhat",
    "corresponding_authors": "",
    "abstract": "Internet of things (IoT) devices are popular in several high-impact applications such as mobile healthcare and digital agriculture. However, IoT devices have limited operating lifetime due to their small form factor. Harvesting energy from ambient sources is an effective method to supplement the battery. Energy harvesting necessitates development of energy management policies to manage the harvested energy. Designing optimal policies for energy management is challenging for two key reasons: (1) ambient energy sources are highly stochastic; therefore, energy management policies must consider the associated uncertainty; (2) energy management policies must consider future energy availability while making decisions to ensure that sufficient energy is available when there is no ambient energy. Prior approaches typically consider energy in the immediate future (e.g., 1 hour) and do not account for the uncertainty in future energy harvest. This article proposes novel machine learning and dynamic optimization-based approaches to handle the two challenges. Specifically, we first develop a novel set of features and use it in a low-power neural network architecture to predict future energy availability and uncertainty. The energy predictions and uncertainty are used in a dynamic optimization algorithm to optimally allocate the harvested energy. Experiments on solar energy data over 5 years from Golden, Colorado, show that the proposed energy prediction model achieves 3.4 J mean absolute error while having a coverage of 80%. Moreover, our energy management algorithm provides energy allocations that are within 2.5 J of an optimal Oracle with 2.65 mJ to 36.54 mJ of energy overhead.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4382540921",
    "type": "article"
  },
  {
    "title": "A Compact TRNG Design for FPGA Based on the Metastability of RO-driven Shift Registers",
    "doi": "https://doi.org/10.1145/3610295",
    "publication_date": "2023-07-21",
    "publication_year": 2023,
    "authors": "Qingsong Peng; Jingchang Bian; Zhengfeng Huang; Senling Wang; Aibin Yan",
    "corresponding_authors": "",
    "abstract": "True random number generators (TRNGs), as an important component of security systems, have received a lot of attention for their related research. The previous researches have provided a large number of TRNG solutions, however, they still failed to reach an excellent tradeoff in various performance metrics. This article presents a shift-registers metastability-based TRNG, which is implemented by compact reference units and comparison units. By forcing the D flip-flops in the shift-registers into the metastable state, it optimizes the problem that the conventional metastability entropy sources consume excessive hardware resources. And a new method of metastable randomness extraction is used to reduce the bias of metastable output. The proposed TRNG is implemented in Xilinx Spartan-6 and Virtex-6 FPGAs, which generate random sequences that pass the NIST SP800-22, NIST SP800-90B tests and show excellent robustness to voltage and temperature variations. This TRNG can consume only 3 slices of the FPGA, but it has a high throughput rate of 25 Mbit/s. In comparison with state-of-the-art FPGA-compatible TRNGs, the proposed TRNG achieves the highest figure of merit FOM, which means that the proposed TRNG significantly outperforms previous researches in terms of hardware resources, throughput rate, and operating frequency tradeoffs.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4385065678",
    "type": "article"
  },
  {
    "title": "TMDS: Temperature-aware Makespan Minimizing DAG Scheduler for Heterogeneous Distributed Systems",
    "doi": "https://doi.org/10.1145/3616869",
    "publication_date": "2023-08-19",
    "publication_year": 2023,
    "authors": "Debabrata Senapati; Kousik Rajesh; Chandan Karfa; Arnab Sarkar",
    "corresponding_authors": "",
    "abstract": "To meet application-specific performance demands, recent embedded platforms often involve the use of intricate micro-architectural designs and very small feature sizes leading to complex chips with multi-million gates. Such ultra-high gate densities often make these chips susceptible to inappropriate surges in core temperatures. Temperature surges above a specific threshold may throttle processor performance, enhance cooling costs, and reduce processor life expectancy. This work proposes a generic temperature management strategy that can be easily employed to adapt existing state-of-the-art task graph schedulers so that schedules generated by them never violate stipulated thermal bounds. The overall temperature-aware task graph scheduling problem has first been formally modeled as a constraint optimization formulation whose solution is shown to be prohibitively expensive in terms of computational overheads. Based on insights obtained through the formal model, a new fast and efficient heuristic algorithm called TMDS has been designed. Experimental evaluation over diverse test case scenarios shows that TMDS is able to deliver lower schedule lengths compared to the temperature-aware versions of four prominent makespan minimizing algorithms, namely, HEFT , PEFT , PPTS , and PSLS . Additionally, a case study with an adaptive cruise controller in automotive systems has been included to exhibit the applicability of TMDS in real-world settings.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4386001499",
    "type": "article"
  },
  {
    "title": "Heterogeneous Integration Supply Chain Integrity Through Blockchain and CHSM",
    "doi": "https://doi.org/10.1145/3625823",
    "publication_date": "2023-10-06",
    "publication_year": 2023,
    "authors": "Paul E. Calzada; Md Sami Ul Islam Sami; Kimia Zamiri Azar; Fahim Rahman; Farimah Farahmandi; Mark Tehranipoor",
    "corresponding_authors": "",
    "abstract": "Over the past few decades, electronics have become commonplace in government, commercial, and social domains. These devices have developed rapidly, as seen in the prevalent use of system-on-chips rather than separate integrated circuits on a single circuit board. As the semiconductor community begins conversations over the end of Moore’s law, an approach to further increase both functionality per area and yield using segregated functionality dies on a common interposer die, labeled a System in Package (SiP), is gaining attention. Thus, the chiplet and SiP space has grown to meet this demand, creating a new packaging paradigm, advanced packaging, and a new supply chain. This new distributed supply chain with multiple chiplet developers and foundries has augmented counterfeit vulnerabilities. Chiplets are currently available on an open market, and their origin and authenticity consequently are difficult to ascertain. With this lack of control over the stages of the supply chain, counterfeit threats manifest at the chiplet, interposer, and SiP levels. In this article, we identify counterfeit threats in the SiP domain, and we propose a mitigating framework utilizing blockchain for the effective traceability of SiPs to establish provenance. Our framework utilizes the Chiplet Hardware Security Module to authenticate a SiP throughout its life. To accomplish this, we leverage SiP information including electronic chip identification of chiplets, combating die and IC recycling sensor information, documentation, test patterns and/or electrical measurements, grade, and part number of the SiP. We detail the structure of the blockchain and establish protocols for both enrolling trusted information into the blockchain network and authenticating the SiP. Our framework mitigates SiP counterfeit threats including recycled, remarked, cloned, overproduced interposer, forged documentation, and substituted chiplet while detecting of out-of-spec and defective SiPs.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4387398461",
    "type": "article"
  },
  {
    "title": "WCPNet: Jointly Predicting Wirelength, Congestion and Power for FPGA Using Multi-task Learning",
    "doi": "https://doi.org/10.1145/3656170",
    "publication_date": "2024-04-08",
    "publication_year": 2024,
    "authors": "Juming Xian; Yan Xing; Shuting Cai; Weijun Li; Xiaoming Xiong; Zhengfa Hu",
    "corresponding_authors": "",
    "abstract": "To speed up the design closure and improve the QoR of FPGA, supervised single-task machine learning techniques have been used to predict individual design metric based on placement results. However, the design objective is to achieve optimal performance while considering multiple conflicting metrics. The single-task approaches predict each metric in isolation and neglect the potential correlations or dependencies among them. To address the limitations, this article proposes a multi-task learning approach to jointly predict wirelength, congestion and power. By sharing the common feature representations and adopting the joint optimization strategy, the novel WCPNet models (including WCPNet-HS and WCPNet-SS) cannot only predict the three metrics of different scales simultaneously, but also outperform the majority of single-task models in terms of both prediction performance and time cost, which are demonstrated by the results of the cross design experiment. By adopting the cross-stitch structure in the encoder, WCPNet-SS outperforms WCPNet-HS in prediction performance, but WCPNet-HS is faster because of the simpler parameters sharing structure. The significance of the feature image pinUtilization on predicting power and wirelength are demonstrated by the ablation experiment.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4394569836",
    "type": "article"
  },
  {
    "title": "Load Balanced PIM-Based Graph Processing",
    "doi": "https://doi.org/10.1145/3659951",
    "publication_date": "2024-04-18",
    "publication_year": 2024,
    "authors": "Xiang Zhao; Song Chen; Yi Kang",
    "corresponding_authors": "",
    "abstract": "Graph processing is widely used for many modern applications, such as social networks, recommendation systems, and knowledge graphs. However, processing large-scale graphs on traditional Von Neumann architectures is challenging due to the irregular graph data and memory-bound graph algorithms. Processing-in-memory (PIM) architecture has emerged as a promising approach for accelerating graph processing by enabling computation to be performed directly on memory. Despite having many processing units and high local memory bandwidth, PIM often suffers from insufficient global communication bandwidth and high synchronization overhead due to load imbalance. This article proposes GraphB, a novel PIM-based graph processing system, to address all these issues. From the algorithm perspective, we propose a degree-aware graph partitioning algorithm that can generate balanced partitioning at a low cost. From the architecture perspective, we introduce tile buffers incorporated with an on-chip 2D-Mesh, which provides high bandwidth for inter-node data transfer. Dataflow in GraphB is designed to enable computation–communication overlap and dynamic load balancing. In a PyMTL3-based cycle-accurate simulator with five real-world graphs and three common algorithms, GraphB achieves an average 2.2× and maximum 2.8× speedup compared to the SOTA PIM-based graph processing system GraphQ.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4394931151",
    "type": "article"
  },
  {
    "title": "Efficient Attacks on Strong PUFs via Covariance and Boolean Modeling",
    "doi": "https://doi.org/10.1145/3687469",
    "publication_date": "2024-08-08",
    "publication_year": 2024,
    "authors": "Hongfei Wang; Wei Liu; W. Cai; Yunxiao Lu; C. C. Wan",
    "corresponding_authors": "",
    "abstract": "The physical unclonable function (PUF) is a widely used hardware security primitive. Before hacking into a PUF-protected system, intruders typically initiate attacks on the PUF as the first step. Many strong PUF designs have been proposed to thwart non-invasive attacks that exploit acquired CRPs. In this work, we propose a general framework for efficient attacks on strong PUFs by investigating from two perspectives, namely, statistical covariances in the challenge space and the design dependency among PUF compositions. The framework consists of two novel attack methods against a wide range of PUF families, including XOR APUFs, interpose PUFs, and bistable ring (BR)-PUFs. It can also exploit the knowledge of reliability information to improve attack efficiency with gradient optimization. We evaluate our proposed attacks through extensive experiments, running both software-based simulation and hardware implementations on FPGAs to compare with corresponding SOTA works. Considerable effort has been made in ensuring identical software/hardware conditions for a fair comparison. The results demonstrate that our framework significantly outperforms SOTA results. Moreover, we show that our framework can efficiently attack diverse PUF families built from entirely different types, while almost all existing works solely focused on attacking one or very limited number of PUF designs.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4401427170",
    "type": "article"
  },
  {
    "title": "Simulation and sensitivity of linear analog circuits under parameter variations by Robust interval analysis",
    "doi": "https://doi.org/10.1145/315773.315780",
    "publication_date": "1999-07-01",
    "publication_year": 1999,
    "authors": "C.‐J. Richard Shi; Michael W. Tian",
    "corresponding_authors": "",
    "abstract": "An interval-mathematic approach is presented for frequency-domain simulation and sensitivity analysis of linear analog circuits under parameter variations. With uncertain parameters represented as intervals, bounding frequency-domain responses is formulated as the problem of solving systems of linear interval equations. The formulation is based on a variant of modified nodal analysis, and is particularly amenable to interval analysis. Some characterization of the solution sets of systems of linear interval equations are derived. With these characterizations, an elegant and efficient algorithm is proposed to solve systems of linear interval equations. While the widely used Monte Carlo approach requires many circuit simulations to achieve even moderate accuracy, the computational cost of the proposed approach is about twice that of one circuit simulation. The computed response bounds contain provably, or are usually very close to, the actual response bounds. Further, sensitivity under parameter variations can be computed from the response bounds at minor computational cost. The algorithms are implemented in SPICE3F5, using sparse-matrix techniques and tested on several practical analog circuits.",
    "cited_by_count": 28,
    "openalex_id": "https://openalex.org/W1995639759",
    "type": "article"
  },
  {
    "title": "Code size minimization and retargetable assembly for custom EPIC and VLIW instruction formats",
    "doi": "https://doi.org/10.1145/362652.362658",
    "publication_date": "2000-10-01",
    "publication_year": 2000,
    "authors": "Shail Aditya; Scott Mahlke; B. Ramakrishna Rau",
    "corresponding_authors": "",
    "abstract": "PICO is a fully automated system for designing the architecture and the microarchitecture of VLIW and EPIC processors. A serious concern with this class of processors, due to their very long instructions, is their code size. One focus of this paper is to describe a series of code size minimization techniques used within PICO, some of which are applied during the automatic design of the instruction format, while others are applied during program assembly. The design of a retargetable assembler to support these techniques also poses certain novel challenges, which constitute the second focus of this paper. Contrary to widely held perceptions, we demonstrate that it is entirely possible to design VLIW and EPIC processors that are capable of issuing large numbers of operational per cycle, but whose code size is only moderately larger than that for a sequential CISC processor.",
    "cited_by_count": 28,
    "openalex_id": "https://openalex.org/W2006901366",
    "type": "article"
  },
  {
    "title": "Optimal design of synchronous circuits using software pipelining techniques",
    "doi": "https://doi.org/10.1145/502175.502180",
    "publication_date": "2001-10-01",
    "publication_year": 2001,
    "authors": "François R. Boyer; E.M. Aboulhamid; Yvon Savaria; Michel Boyer",
    "corresponding_authors": "",
    "abstract": "We present a method to optimize clocked circuits by relocating and changing the time of activation of registers to maximize the throughput. Our method is based on a modulo scheduling algorithm for software pipelining, instead of retiming. It optimizes the circuit without the constraint on the clock phases that retiming has, which permits to always achieve the optimal clock period. The two methods have the same overall time complexity, but we avoid the computation of all pair-shortest paths, which is a heavy burden regarding both space and time. From the optimal schedule found, registers are placed in the circuit without looking at where the original registers were. The resulting circuit is a multi-phase clocked circuit, where all the clocks have the same period and the phases are automatically determined by the algorithm. Edge-triggered flip-flops are used where the combinational delays exactly match that period, whereas level-sensitive latches are used elsewhere, improving the area occupied by the circuit. Experiments on existing and newly developed benchmarks show a substantial performance improvement compared to previously published work.",
    "cited_by_count": 28,
    "openalex_id": "https://openalex.org/W2088808707",
    "type": "article"
  },
  {
    "title": "Constructing and exploiting linear schedules with prescribed parallelism",
    "doi": "https://doi.org/10.1145/504914.504921",
    "publication_date": "2002-01-01",
    "publication_year": 2002,
    "authors": "Alain Darte; Robert Schreiber; B. Ramakrishna Rau; Frédéric Vivien",
    "corresponding_authors": "",
    "abstract": "We present two new results of importance in code generation for and synthesis of synchronously scheduled parallel processor arrays and multicluster VLIWs. The first is a new practical method for constructing a linear schedule for the iterations of a loop nest that schedules precisely one iteration per cycle on each of a prescribed set of processors. While this problem goes back to the era in which systolic computation was in vogue, it has defied practical solution until now. We provide a closed form solution that enables the enumeration of all such schedules. The second result is a new technique that reduces the cost of code or hardware whose function is to control the flow of data and predicate operations, and to generate memory addresses. The key idea is that by using the mathematical structure of any of the conflict-free schedules we construct, a very shallow recurrence can be developed to inexpensively update these quantities.",
    "cited_by_count": 27,
    "openalex_id": "https://openalex.org/W2038495591",
    "type": "article"
  },
  {
    "title": "Introspection",
    "doi": "https://doi.org/10.1145/502175.502179",
    "publication_date": "2001-10-01",
    "publication_year": 2001,
    "authors": "Ramesh Karri; Balakrishnan Iyer",
    "corresponding_authors": "",
    "abstract": "We report a register transfer level technique for concurrent error detection and diagnosis in data dominated designs called Introspection . Introspection uses idle computation cyles in the data path and idle data transfer cycles in the interconnection network in a synergistic fashion for concurrent error detection and diagnosis (CEDD). The resulting on-chip fault latencies are one ten-thousandth (10 -4 ) of previously reported system level concurrent error detection and diagnosis latencies. The associated area overhead and performance penalty are negligible. We derive a cost function that considers introspection constraints such as (i) executing an operation on three disjoint function units for diagnosis and (ii) promoting function units to participate in at least one CEDD operation. We formulate integration of introspection constraints into the operation-to-operator binding phase of high-level synthesis as a weighted bipartite matching problem. The effectiveness of introspection and its implementation are illustrated on numerous industrial strength benchmarks.",
    "cited_by_count": 26,
    "openalex_id": "https://openalex.org/W2001006297",
    "type": "article"
  },
  {
    "title": "Equivalence checking between behavioral and RTL descriptions with virtual controllers and datapaths",
    "doi": "https://doi.org/10.1145/1109118.1109121",
    "publication_date": "2005-10-01",
    "publication_year": 2005,
    "authors": "Masahiro Fujita",
    "corresponding_authors": "Masahiro Fujita",
    "abstract": "In this article, we present techniques for comparison between behavioral level and register transfer level (RTL) design descriptions by mapping the designs into virtual controllers and virtual datapaths. We also discuss about how the equivalence between behavioral level and RTL designs can be defined precisely using the proposed “attribute statements” in an interactive fashion. Implementation issues as well as considerations on real life industrial design examples are also presented.",
    "cited_by_count": 24,
    "openalex_id": "https://openalex.org/W2006397252",
    "type": "article"
  },
  {
    "title": "Routing-aware scan chain ordering",
    "doi": "https://doi.org/10.1145/1080334.1080339",
    "publication_date": "2005-07-01",
    "publication_year": 2005,
    "authors": "Puneet Gupta; Andrew B. Kahng; Stefanus Mantik",
    "corresponding_authors": "",
    "abstract": "Scan chain insertion can have a large impact on routability, wirelength, and timing of the design. We present a routing-driven methodology for scan chain ordering with minimum wirelength objective. A routing-based approach to scan chain ordering, while potentially more accurate, can result in TSP (Traveling Salesman Problem) instances which are asymmetric and highly nonmetric; this may require a careful choice of solvers. We evaluate our new methodology on recent industry place-and-route blocks with 1200 to 5000 scan cells. We show substantial wirelength reductions for the routing-based flow versus the traditional placement-based flow. In a number of our test cases, over 86% of scan routing overhead is saved. Even though our experiments are, so far, timing oblivious, the routing-based flow also improves evaluated timing, and practical timing-driven extensions appear feasible.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W1967401717",
    "type": "article"
  },
  {
    "title": "Energy-efficient datapath scheduling using multiple voltages and dynamic clocking",
    "doi": "https://doi.org/10.1145/1059876.1059883",
    "publication_date": "2005-04-01",
    "publication_year": 2005,
    "authors": "Saraju P. Mohanty; N. Ranganathan",
    "corresponding_authors": "",
    "abstract": "Recently, dynamic frequency scaling has been explored at the CPU and system levels for power optimization. Low-power datapath scheduling using multiple supply voltages has been well researched. In this work, we develop new datapath scheduling algorithms that use multiple supply voltages and dynamic frequency clocking in a coordinated manner in order to reduce the energy consumption of datapath circuits. In dynamic frequency clocking, the functional units can be operated at different frequencies depending on the computations occurring within the datapath during a given clock cycle. The strategy is to schedule high-energy units, such as multipliers at lower frequencies, so that they can be operated at lower voltages to reduce energy consumption and the low-energy units, such as adders at higher frequencies, to compensate for speed. The proposed time- and resource-constrained algorithms have been applied to various high-level synthesis benchmark circuits under different time and resource constraints. The experimental results show significant reduction in energy for both the algorithms.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W2018289382",
    "type": "article"
  },
  {
    "title": "Segmented channel routability via satisfiability",
    "doi": "https://doi.org/10.1145/1027084.1027090",
    "publication_date": "2004-10-01",
    "publication_year": 2004,
    "authors": "William N. N. Hung; Xiaoyu Song; E.M. Aboulhamid; Andrew Kennings; A. Coppola",
    "corresponding_authors": "",
    "abstract": "Segmented channel routing is fundamental to the routing of row-based FPGAs. In this paper, we study segmented channel routability via satisfiability. Our method encodes the horizontal and vertical constraints of the routing problem as Boolean conditions. The routability constraint is satisfiable if and only if the net connections in the segmented channel are routable. Empirical results show that the method is time-efficient and applicable to large problem instances.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W1999343232",
    "type": "article"
  },
  {
    "title": "Efficient thermal-oriented 3D floorplanning and thermal via planning for two-stacked-die integration",
    "doi": "https://doi.org/10.1145/1142155.1142159",
    "publication_date": "2006-04-01",
    "publication_year": 2006,
    "authors": "Zuoyuan Li; Xianlong Hong; Qiang Zhou; Jinian Bian; Hannah Honghua Yang; V. Pitchumani",
    "corresponding_authors": "",
    "abstract": "New three-dimensional (3D) floorplanning and thermal via planning algorithms are proposed for thermal optimization in two-stacked die integration. Our contributions include (1) a two-stage design flow for 3D floorplanning, which scales down the enlarged solution space due to multidevice layer structure; (2) an efficient thermal-driven 3D floorplanning algorithm with power distribution constraints; (3) a thermal via planning algorithm considering congestion minimization. Experiments results show that our approach is nine times faster with better solution quality compared to a recent published result. In addition, the thermal via planning approach is proven to be very efficient to eliminate localized hot spots directly.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W1992904657",
    "type": "article"
  },
  {
    "title": "MPSoC memory optimization using program transformation",
    "doi": "https://doi.org/10.1145/1278349.1278356",
    "publication_date": "2007-09-01",
    "publication_year": 2007,
    "authors": "Youcef Bouchebaba; B. Girodias; Gabriela Nicolescu; E.M. Aboulhamid; Bruno Lavigueur; Pierre Paulin",
    "corresponding_authors": "",
    "abstract": "Multiprocessor system-on-a-chip (MPSoC) architectures have received a lot of attention in the past years, but few advances in compilation techniques target these architectures. This is particularly true for the exploitation of data locality. Most of the compilation techniques for parallel architectures discussed in the literature are based on a single loop nest. This article presents new techniques that consist in applying loop fusion and tiling to several loop nests and to parallelize the resulting code across different processors. These two techniques reduce the number of memory accesses. However, they increase dependencies and thereby reduce the exploitable parallelism in the code. This article tries to address this contradiction. To optimize the memory space used by temporary arrays, smaller buffers are used as a replacement. Different strategies are studied to optimize the processing time spent accessing these buffers. The experiments show that these techniques yield a significant reduction in the number of data cache misses (30%) and in processing time (50%).",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W1965979241",
    "type": "article"
  },
  {
    "title": "A critical-path-aware partial gating approach for test power reduction",
    "doi": "https://doi.org/10.1145/1230800.1230809",
    "publication_date": "2007-04-01",
    "publication_year": 2007,
    "authors": "Mohammed Elshoukry; Mohammad Tehranipoor; C.P. Ravikumar",
    "corresponding_authors": "",
    "abstract": "Power reduction during test application is important from the viewpoint of chip reliability and for obtaining correct test results. One of the ways to reduce scan test power is to block transitions propagating from the outputs of scan cells through combinational logic. In order to accomplish this, some researchers have proposed setting primary inputs to appropriate values or adding extra gates at the outputs of scan cells. In this article, we point out the limitations of such full gating techniques in terms of area overhead and performance degradation. We propose an alternate solution where a partial set of scan cells is gated. A subset of scan cells is selected to give maximum reduction in test power within a given area constraint. An alternate formulation of the problem is to treat maximum permitted test power as a constraint and achieve a test power that is within this limit using the fewest number of gated scan cells, thereby leading to the least impact in area overhead. Our problem formulation also comprehends performance constraints and prevents the inclusion of gating points on critical paths. The area overhead is predictable and closely corresponds to the average power reduction.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W2123380246",
    "type": "article"
  },
  {
    "title": "Compilation for compact power-gating controls",
    "doi": "https://doi.org/10.1145/1278349.1278364",
    "publication_date": "2007-09-01",
    "publication_year": 2007,
    "authors": "Yi‐Ping You; Chung-Wen Huang; Jenq Kuen Lee",
    "corresponding_authors": "",
    "abstract": "Power leakage constitutes an increasing fraction of the total power consumption in modern semiconductor technologies due to the continuing size reductions and increasing speeds of transistors. Recent studies have attempted to reduce leakage power using integrated architecture and compiler power-gating mechanisms. This approach involves compilers inserting instructions into programs to shut down and wake up components, as appropriate. While early studies showed this approach to be effective, there are concerns about the large amount of power-control instructions being added to programs due to the increasing amount of components equipped with power-gating controls in SoC design platforms. In this article we present a sink-n-hoist framework for a compiler to generate balanced scheduling of power-gating instructions. Our solution attempts to merge several power-gating instructions into a single compound instruction, thereby reducing the amount of power-gating instructions issued. We performed experiments by incorporating our compiler analysis and scheduling policies into SUIF compiler tools and by simulating the energy consumption using Wattch toolkits. The experimental results demonstrate that our mechanisms are effective in reducing the amount of power-gating instructions while further reducing leakage power compared to previous methods.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W2138843457",
    "type": "article"
  },
  {
    "title": "Layout-aware scan chain reorder for launch-off-shift transition test coverage",
    "doi": "https://doi.org/10.1145/1391962.1391972",
    "publication_date": "2008-09-01",
    "publication_year": 2008,
    "authors": "Sying-Jyan Wang; Kuo-lin Peng; Kuang-Cyun Hsiao; Katherine Shu-Min Li",
    "corresponding_authors": "",
    "abstract": "Launch-off-shift (LOS) is a popular delay test technique for scan-based designs. However, it is usually not possible to achieve good delay fault coverage in LOS test due to conflicts in test vectors. In this article, we propose a layout-based scan chain ordering method to improve fault coverage for LOS test with limited routing overhead. A fast and effective algorithm is used to eliminate conflicts in test vectors while at the same time restrict the extra scan chain routing. This approach provides many advantages. (1) The proposed method can improve delay fault coverage for LOS test. (2) With layout information taken into account, the routing penalty is limited, and thus the impact on circuit performance will not be significant. Experimental results show that the proposed LOS test method achieves about the same level of delay fault coverage as enhanced scan does, while the average scan chain wire length is about 2.2 times of the shortest scan chain.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W2024585893",
    "type": "article"
  },
  {
    "title": "System-level performance/power analysis for platform-based design of multimedia applications",
    "doi": "https://doi.org/10.1145/1188275.1188277",
    "publication_date": "2007-01-01",
    "publication_year": 2007,
    "authors": "Nicholas H. Zamora; Xiao Hu; Radu Mărculescu",
    "corresponding_authors": "",
    "abstract": "The objective of this article is to introduce the use of Stochastic Automata Networks (SANs) as an effective formalism for application-architecture modeling in system-level average-case analysis for platform-based design. By platform, we mean a family of heterogeneous architectures that satisfy a set of architectural constraints imposed to allow re-use of hardware and software components. More precisely, we show how SANs can be used early in the design cycle to identify the best performance/power trade-offs among several application-architecture combinations. Having this information available not only helps avoid lengthy simulations for predicting power and performance figures, but also enables efficient mapping of different applications onto a chosen platform. We illustrate the benefits of our methodology by using the “Picture-in-Picture” video decoder as a driver application.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W2072589363",
    "type": "article"
  },
  {
    "title": "Evolution of synthetic RTL benchmark circuits with predefined testability",
    "doi": "https://doi.org/10.1145/1367045.1367063",
    "publication_date": "2008-07-01",
    "publication_year": 2008,
    "authors": "Tomáš Pečenka; Lukáš Sekanina; Zdeněk Kotásek",
    "corresponding_authors": "",
    "abstract": "This article presents a new real-world application of evolutionary computing in the area of digital-circuits testing. A method is described which enables to evolve large synthetic RTL benchmark circuits with a predefined structure and testability. Using the proposed method, a new collection of synthetic benchmark circuits was developed. These benchmark circuits will be useful in a validation process of novel algorithms and tools in the area of digital-circuits testing. Evolved benchmark circuits currently represent the most complex benchmark circuits with a known level of testability. Furthermore, these circuits are the largest that have ever been designed by means of evolutionary algorithms. This work also investigates suitable parameters of the evolutionary algorithm for this problem and explores the limits in the complexity of evolved circuits.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W2087855246",
    "type": "article"
  },
  {
    "title": "Tailoring circuit-switched network-on-chip to application-specific system-on-chip by two optimization schemes",
    "doi": "https://doi.org/10.1145/1297666.1297678",
    "publication_date": "2008-01-01",
    "publication_year": 2008,
    "authors": "Kuei‐Chung Chang; Jih-Sheng Shen; Tien-Fu Chen",
    "corresponding_authors": "",
    "abstract": "As the number of cores on a chip increases, power consumed by the communication structures takes a significant portion of the overall power budget. In this article, we first propose a circuit-switched interconnection architecture which uses crossroad switches to construct dedicated channels dynamically between any pairs of cores for nonhuge application-specific SoCs. The structure of the crossroad switch is simple, which can be regarded as a NoC-lite router, and we can easily construct a low-power on-chip network with these switches by a system-level design methodology. We also present the design methodology to tailor the proposed interconnection architecture to low-power structures by two proposed optimization schemes with profiled communication characteristics. The first scheme is power-aware topology construction, which can build low-power application-specific interconnection topologies. To further reduce the power consumption, we propose the second optimization scheme to predetermine the operating mode of dual-mode switches in the NoC at runtime. We evaluate several interconnection techniques, and the results show that the proposed architecture is more low-power and high-performance than others under some constraints and scale boundaries. We take multimedia applications as case studies, and experimental results show the power savings of power-aware topology approximate to 49% of the interconnection architecture. The power consumption can be further reduced approximately 25% by applying partially dedicated path mechanism.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W2022762378",
    "type": "article"
  },
  {
    "title": "Trade-offs in loop transformations",
    "doi": "https://doi.org/10.1145/1497561.1497565",
    "publication_date": "2009-03-01",
    "publication_year": 2009,
    "authors": "Martin Palkovič; Francky Catthoor; Henk Corporaal",
    "corresponding_authors": "",
    "abstract": "Nowadays, multimedia systems deal with huge amounts of memory accesses and large memory footprints. To alleviate the impact of these accesses and reduce the memory footprint, high-level memory exploration and optimization techniques have been proposed. These techniques try to more efficiently utilize the memory hierarchy. An important step in these optimization techniques are loop transformations (LT). They have a crucial effect on later data memory footprint optimization steps and code generation. However, the state-of-the-art work has focused only on individual objectives. The main one in literature involves improving the locality of data accesses, and thus reducing the data memory footprint. It does not consider the trade-offs in the LT step in relation to successive optimization steps. Therefore, it is not globally efficient in mapping the application on the target platform. In this article we will discuss several trade-offs during the loop transformations. To our knowledge, we are the first ones considering these global trade-offs. Previous work always gave mostly one solution, having the best locality and thus the optimized memory footprint, even though some research in two-dimensional trade-offs in this area exists as well. We start from this state-of-the-art solution with minimal footprint. We show that by sacrificing the footprint, we can obtain gains in data reuse (crucial for energy reduction) and reduce the control-flow complexity. We demonstrate our approach on a real-life application, namely the QSDPCM video coder. At the end, we show that considering trade-offs for this application leads to 16% energy reduction in a two-layer memory subsystem and 10% cycle reduction on the ARM platform.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W2050199238",
    "type": "article"
  },
  {
    "title": "SystemJ compilation using the tandem virtual machine approach",
    "doi": "https://doi.org/10.1145/1529255.1529256",
    "publication_date": "2009-05-01",
    "publication_year": 2009,
    "authors": "Avinash Malik; Zoran Salčić; Partha S. Roop",
    "corresponding_authors": "",
    "abstract": "SystemJ is a language based on the Globally Asynchronous Locally Synchronous (GALS) paradigm. A SystemJ program is a collection of GALS nodes, also called clock domains, and each clock domain is a synchronous program that extends the Java language. Initial compilation of SystemJ has been to standard Java executing on a Java Virtual Machine (JVM), which is both inefficient and bulky for small embedded systems. This article proposes a new approach for compiling and executing SystemJ using a new type of virtual machine, called a Tandem Virtual Machine (TVM). The TVM approach provides an efficient implementation of SystemJ on both standard processors and resource-constrained embedded processors. The new approach is based on separating the control-driven and data-driven operations for execution on two virtual machines. While the JVM executes the data-driven operations, a Control Virtual Machine (CVM) is introduced to execute the control-driven parts of a SystemJ program. The TVM approach is capable of handling all data-driven and control-driven operations required by the GALS model. The benchmark results show that the TVM has code size improvements of over 60% on average and also a substantial improvement in execution speed over standard Java-based compilation.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W2073884684",
    "type": "article"
  },
  {
    "title": "Boosting interpolation with dynamic localized abstraction and redundancy removal",
    "doi": "https://doi.org/10.1145/1297666.1297669",
    "publication_date": "2008-01-01",
    "publication_year": 2008,
    "authors": "Gianpiero Cabodi; Marco Murciano; Sergio Nocco; Stefano Quer",
    "corresponding_authors": "",
    "abstract": "SAT--based Unbounded Model Checking based on Craig Interpolants is often able to overcome BDDs and other SAT--based techniques on large verification instances. Based on refutation proofs generated by SAT solvers, interpolants provide compact circuit representations of state sets, as they abstract away several nonrelevant details of the proofs. We propose three main contributions, aimed at controlling interpolant size and traversal depth. First of all, we introduce interpolant--based dynamic abstraction to reduce the support of computed interpolants. Subsequently, we propose new advances in interpolant compaction by redundancy removal. Finally, we introduce interpolant computation exploiting circuit quantification, instead of SAT refutation proofs. These techniques heavily rely on an effective application of the incremental SAT paradigm. The experimental results proposed in this paper are specifically oriented to prove properties, rather than disproving them, i.e., they target complete verification instead of simply hunting bugs. They show how this methodology is able to stretch the applicability of interpolant--based Model Checking to larger and deeper verification instances.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W2090103321",
    "type": "article"
  },
  {
    "title": "Timing-aware power-optimal ordering of signals",
    "doi": "https://doi.org/10.1145/1391962.1391973",
    "publication_date": "2008-09-01",
    "publication_year": 2008,
    "authors": "Konstantin Moiseev; Avinoam Kolodny; Shmuel Wimer",
    "corresponding_authors": "",
    "abstract": "A computationally efficient technique for reducing interconnect active power in VLSI systems is presented. Power reduction is accomplished by simultaneous wire spacing and net ordering, such that cross-capacitances between wires are optimally shared. The existence of a unique power-optimal wire order within a bundle is proven, and a method to construct this order is derived. The optimal order of wires depends only on the activity factors of the underlying signals; hence, it can be performed prior to spacing optimization. By using this order of wires, optimality of the combined solution is guaranteed (as compared with any other ordering and spacing of the wires). Timing-aware power optimization is enabled by simultaneously considering timing criticality weights and activity factors for the signals. The proposed algorithm has been applied to various interconnect layouts, including wire bundles from high-end microprocessor circuits in 65 nm technology. Interconnect power reduction of 17% on average has been observed in such bundles.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W2167427069",
    "type": "article"
  },
  {
    "title": "Autonomous hardware/software partitioning and voltage/frequency scaling for low-power embedded systems",
    "doi": "https://doi.org/10.1145/1640457.1640459",
    "publication_date": "2009-12-01",
    "publication_year": 2009,
    "authors": "Jingqing Mu; Roman Lysecky",
    "corresponding_authors": "",
    "abstract": "Warp processing is a recent computing technology capable of autonomously partitioning the critical kernels within an executing software application to hardware circuits implemented within an on-chip FPGA. While previous performance-driven warp processing has been shown to provide significant performance improvements over software only execution, the dynamic performance improvement of warp processors may be lost for certain application domains, such as real-time systems. Alternatively, as power consumption continue to become a dominant design constraint, we present and thoroughly analyze a low-power warp processing methodology that leverages voltage and/or frequency scaling to substantially reduce power consumption without any performance degradation—all without requiring designer effort beyond the initial software development.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W2040224440",
    "type": "article"
  },
  {
    "title": "Provably correct on-chip communication",
    "doi": "https://doi.org/10.1145/1497561.1497562",
    "publication_date": "2009-03-01",
    "publication_year": 2009,
    "authors": "Karin Avnit; Vijay D’Silva; Arcot Sowmya; S. Ramesh; Sri Parameswaran",
    "corresponding_authors": "",
    "abstract": "Hardware module reuse is a standard solution to the problems of increasing complexity of chip architectures and pressure to reduce time to market. In the absence of a single module interface standard, predesigned modules for “plug-and-play” usually require a converter between incompatible interface protocols. Current approaches to automatic synthesis of protocol converters mostly lack formal foundations and either employ abstractions far removed from the HDL implementation level or grossly simplify the structure of the protocols considered. This work presents a state-machine-based formalism for modeling bus-based communication protocols and a notion of protocol compatibility and of correct conversion between incompatible protocols. This formalism is used to derive algorithms for checking protocol compatibility and for provably correct, automatic converter synthesis. Experiments with automatic converter synthesis between different configurations of widely used commercial bus protocols, such as AMBA AHB, ASB APB, and the Open Core Protocol (OCP) are discussed. The work here is unique in its combination of a completely formal approach and the use of a low abstraction level that enables precise modeling of protocol characteristics that is also close to HDL.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W2132928765",
    "type": "article"
  },
  {
    "title": "Benchmarking and evaluating reconfigurable architectures targeting the mobile domain",
    "doi": "https://doi.org/10.1145/1698759.1698764",
    "publication_date": "2010-02-01",
    "publication_year": 2010,
    "authors": "Peter Jamieson; Tobias Becker; Peter Y. K. Cheung; Wayne Luk; Tero Rissa; Teemu Pitkänen",
    "corresponding_authors": "",
    "abstract": "We present the GroundHog 2009 benchmarking suite that evaluates the power consumption of reconfigurable technology for applications targeting the mobile computing domain. This benchmark suite includes seven designs; one design targets fine-grained FPGA fabrics allowing for quick state-of-the-art evaluation, and six designs are specified at a high level allowing them to target a range of existing and future reconfigurable technologies. Each of the six designs can be stimulated with the help of synthetically generated input stimuli created by an open-source tool included in the downloadable suite. Another tool is included to help verify the correctness of each implemented design. To demonstrate the potential of this benchmark suite, we evaluate the power consumption of two modern industrial FPGAs targeting the mobile domain. Also, we show how an academic FPGA framework, VPR 5.0, that has been updated for power estimates can be used to estimates the power consumption of different FPGA architectures and an open-source CAD flow mapping to these architectures.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W1973115070",
    "type": "article"
  },
  {
    "title": "Hardware/software partitioning and pipelined scheduling on runtime reconfigurable FPGAs",
    "doi": "https://doi.org/10.1145/1698759.1698763",
    "publication_date": "2010-02-01",
    "publication_year": 2010,
    "authors": "Mingxuan Yuan; Zonghua Gu; Xiuqiang He; Xue Liu; Lei Jiang",
    "corresponding_authors": "",
    "abstract": "FPGAs are widely used in today's embedded systems design due to their low cost, high performance, and reconfigurability. Partially RunTime-Reconfigurable (PRTR) FPGAs, such as Virtex-2 Pro and Virtex-4 from Xilinx, allow part of the FPGA area to be reconfigured while the remainder continues to operate without interruption, so that HW tasks can be placed and removed dynamically at runtime. We address two problems related to HW task scheduling on PRTR FPGAs: (1) HW/SW partitioning. Given an application in the form of a task graph with known execution times on the HW (FPGA) and SW (CPU), and known area sizes on the FPGA, find an valid allocation of tasks to either HW or SW and a static schedule with the optimization objective of minimizing the total schedule length (makespan). (2) Pipelined scheduling. Given an input task graph, construct a pipelined schedule on a PRTR FPGA with the goal of maximizing system throughput while meeting a given end-to-end deadline. Both problems are NP-hard. Satisfiability Modulo Theories (SMT) is an extension to SAT by adding the ability to handle arithmetic and other decidable theories. We use the SMT solver Yices with Linear Integer Arithmetic (LIA) theory as the optimization engine for solving the two scheduling problems. In addition, we present an efficient heuristic algorithm based on kernel recognition for the pipelined scheduling problem, a technique borrowed from SW pipelining, to overcome the scalability problem of the SMT-based optimal solution technique.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2056291785",
    "type": "article"
  },
  {
    "title": "Agglomerative-based flip-flop merging and relocation for signal wirelength and clock tree optimization",
    "doi": "https://doi.org/10.1145/2491477.2491484",
    "publication_date": "2013-07-01",
    "publication_year": 2013,
    "authors": "Sean Shih-Ying Liu; Wan-Ting Lo; Chieh-Jui Lee; Hung-Ming Chen",
    "corresponding_authors": "",
    "abstract": "In this article, we propose a flip-flop merging algorithm based on agglomerative clustering. Compared to previous state-of-the-art on flip-flop merging, our proposed algorithm outperforms that of Chang et al. [2010] and Wang et al. [2011] in all aspects, including number of flip-flop reductions, increase in signal wirelength, displacement of flip-flops, and execution time. Our proposed algorithm also has minimal disruption to original placement. In comparison with Jiang et al. [2011], Wang et al. [2011], and Chang et al. [2010], our proposed algorithm has the least displacement when relocating merged flip-flops. While previous works on flip-flop merging focus on the number of flip-flop reduction, we further evaluate the power consumption of clock tree after flip-flop merging. To further minimize clock tree wirelength, we propose a framework that determines a preferable location for relocated merged flip-flops for clock tree synthesis (CTS). Experimental results show that our CTS-driven flip-flop merging can reduce clock tree wirelength by an average of 7.82% with minimum clock network power consumption compared to all of the previous works.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W1980077563",
    "type": "article"
  },
  {
    "title": "<i>t/t</i> -Diagnosability of regular graphs under the PMC model",
    "doi": "https://doi.org/10.1145/2442087.2442091",
    "publication_date": "2013-03-01",
    "publication_year": 2013,
    "authors": "Chun-An Chen; Sun‐Yuan Hsieh",
    "corresponding_authors": "",
    "abstract": "A system is t/t -diagnosable if, given any collection of test results, the faulty nodes can be isolated to within a set of at most t nodes provided that the number of faulty nodes does not exceed t . Given an N -vertex graph G that is regular with the common degree d and has no cycle of three or four vertices, this study shows that G is (2d − 2)/(2d − 2) -diagnosable if N ≥ 4 d − 30 &gt; 0. Based on this result, the t/t -diagnosabilities of several classes of graphs can be computed efficiently.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W2033142520",
    "type": "article"
  },
  {
    "title": "System-Level Synthesis for Wireless Sensor Node Controllers",
    "doi": "https://doi.org/10.1145/2071356.2071358",
    "publication_date": "2012-01-01",
    "publication_year": 2012,
    "authors": "Muhammad Adeel Pasha; Steven Derrien; Olivier Sentieys",
    "corresponding_authors": "",
    "abstract": "Wireless sensor networks (WSN) is a new and very challenging research field for embedded system design automation. Engineering a WSN node hardware platform is known to be a tough challenge, as the design must enforce many severe constraints, among which energy dissipation is by far the most important one. WSN node devices have until now been designed using off-the-shelf low-power microcontroller units (MCUs), even if their power dissipation is still an issue and hinders the widespread use of this new technology. In this work, we propose a complete system-level flow for an alternative approach based on the concept of hardware microtasks, which relies on hardware specialization and power gating to drastically improve the energy efficiency of the computational/control part of the node. Our case study shows that power savings between one to two orders of magnitude are possible w.r.t. MCU-based implementations.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W2092727031",
    "type": "article"
  },
  {
    "title": "Electric Vehicle Optimized Charge and Drive Management",
    "doi": "https://doi.org/10.1145/3084686",
    "publication_date": "2017-08-01",
    "publication_year": 2017,
    "authors": "Korosh Vatanparvar; Mohammad Abdullah Al Faruque",
    "corresponding_authors": "",
    "abstract": "Electric vehicles (EVs) have been considered as a solution to the environmental issues caused by transportation, such as air pollution and greenhouse gas emission. However, limited energy capacity, scarce EV supercharging stations, and long recharging time have brought anxiety to drivers who use EVs as their main mean of transportation. Furthermore, EV owners need to deal with a huge battery replacement cost when the battery capacity degrades. Yet in-house EV chargers affect the pattern of the power grid load, which is not favorable to the utilities. The driving route, departure/arrival time of daily trips, and electricity price influence the EV energy consumption, battery lifetime, electricity cost, and EV charger load on the power grid. The EV driving range and battery lifetime issues have been addressed by battery management systems and route optimization methodologies. However, in this article, we are proposing an optimized charge and drive management (OCDM) methodology that selects the optimal driving route, schedules daily trips, and optimizes the EV charging process while considering the driver’s timing preference. Our methodology will improve the EV driving range, extend the battery lifetime, reduce the recharging cost, and diminish the influence of EV chargers on the power grid. The performance of our methodology compared to the state of the art have been analyzed by experimenting on three benchmark EVs and three drivers. Our methodology has decreased EV energy consumption by 27%, improved the battery lifetime by 24.8%, reduced the electricity cost by 35%, and diminished the power grid peak load by 17% while increasing less than 20 minutes of daily driving time. Moreover, the scalability of our OCDM methodology for different parameters (e.g., time resolution and multiday cycles) in terms of execution time and memory usage has been analyzed.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W2740832769",
    "type": "article"
  },
  {
    "title": "Architecture and Compiler Support for GPUs Using Energy-Efficient Affine Register Files",
    "doi": "https://doi.org/10.1145/3133218",
    "publication_date": "2017-11-07",
    "publication_year": 2017,
    "authors": "Shao-Chung Wang; Li-Chen Kan; Chao-Lin Lee; Yuan‐Shin Hwang; Jenq‐Kuen Lee",
    "corresponding_authors": "",
    "abstract": "A modern GPU can simultaneously process thousands of hardware threads. These threads are grouped into fixed-size SIMD batches executing the same instruction on vectors of data in a lockstep to achieve high throughput and performance. The register files are huge due to each SIMD group accessing a dedicated set of vector registers for fast context switching, and consequently the power consumption of register files has become an important issue. One proposed solution is to replace some of the vector registers by scalar registers, as different threads in a same SIMD group operate on scalar values and so the redundant computations and accesses of these scalar values can be eliminated. However, it has been observed that a significant number of registers containing affine vectors υ such that υ[ i ] = b + i × s can be represented by base b and stride s . Therefore, this article proposes an affine register file design for GPUs that is energy efficient due to it reducing the redundant executions of both the uniform and affine vectors. This design uses a pair of registers to store the base and stride of each affine vector and provides specific affine ALUs to execute affine instructions. A method of compiler analysis has been developed to detect scalars and affine vectors and annotate instructions for facilitating their corresponding scalar and affine computations. Furthermore, a priority-based register allocation scheme has been implemented to assign scalars and affine vectors to appropriate scalar and affine register files. Experimental results show that this design was able to dispatch 43.56% of the computations to scalar and affine ALUs when using eight scalar and four affine registers per warp. This resulted in the current design also reducing the energy consumption of the register files and ALUs to 21.86% and 26.54%, respectively, and it reduced the overall energy consumption of the GPU by an average of 5.18%.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W2767882261",
    "type": "article"
  },
  {
    "title": "Flexible and Tradeoff-Aware Constraint-Based Design Space Exploration for Streaming Applications on Heterogeneous Platforms",
    "doi": "https://doi.org/10.1145/3133210",
    "publication_date": "2017-11-27",
    "publication_year": 2017,
    "authors": "Kathrin Rosvall; Ingo Sander",
    "corresponding_authors": "",
    "abstract": "Due to its complexity, the problem of mapping and scheduling streaming applications on heterogeneous MPSoCs under real-time and performance constraints has traditionally been tackled by incomplete heuristic algorithms. In recent years, approaches based on Constraint Programming (CP) have shown promising results as complete methods for finding optimal mappings, in particular concerning throughput. However, so far none of the available CP approaches consider the tradeoff between throughput and buffer requirements or throughput and power consumption. This article integrates tradeoff awareness into the CP model and introduces a two-step solving approach that utilizes the advantages of heuristics, while still keeping the completeness property of CP. With a number of experiments considering several streaming applications and different platform models, the article illustrates not only the efficiency of the presented model but also its suitability for solving different problems with various combinations of performance constraints.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W2768650263",
    "type": "article"
  },
  {
    "title": "Compiler-Assisted and Profiling-Based Analysis for Fast and Efficient STT-MRAM On-Chip Cache Design",
    "doi": "https://doi.org/10.1145/3321693",
    "publication_date": "2019-05-29",
    "publication_year": 2019,
    "authors": "Nour Sayed; Longfei Mao; Rajendra Bishnoi; Mehdi B. Tahoori",
    "corresponding_authors": "",
    "abstract": "Spin Transfer Torque Magnetic Random Access Memory (STT-MRAM) is a promising candidate for large on-chip memories as a zero-leakage, high-density and non-volatile alternative to the present SRAM technology. Since memories are the dominating component of a System-on-Chip, the overall performance of the system is highly dependent on that memories. Nevertheless, the high write energy and latency of the emerging STT-MRAM are the most challenging design issues in a modern computing system. By relaxing the non-volatility of these devices, it is possible to reduce the write energy and latency costs, at the expense of reducing the retention time, which in turn may lead to loss of data. In this article, we propose a hybrid STT-MRAM design for caches with different retention capabilities. Then, based on the application requirements (i.e., execution time and memory access rate), program data layout is re-arranged at compilation time for achieving fast and energy-efficient hybrid STT-MRAM on-chip memory design with no reliability degradation. The application requirements have been defined at function granularity based on profiling and compiler-level analysis, which estimate the required retention time and memory access rate, respectively. Experimental results show that the proposed hybrid STT-MRAM cache combined with profiling-based and compiler-level analysis for the data re-arranging, on average, reduces the write energy per access by 49.7%. At system level, overall static and dynamic energy of the cache are reduced by 8.1% and 44%, respectively, whereas, the system performance has been improved up to 8.1%.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W2947376717",
    "type": "article"
  },
  {
    "title": "Impact of Electrostatic Coupling on Monolithic 3D-enabled Network on Chip",
    "doi": "https://doi.org/10.1145/3357158",
    "publication_date": "2019-09-17",
    "publication_year": 2019,
    "authors": "Dongjin Lee; Sourav Das; Janardhan Rao Doppa; Partha Pratim Pande; Krishnendu Chakrabarty",
    "corresponding_authors": "",
    "abstract": "Monolithic-3D-integration (M3D) improves the performance and energy efficiency of 3D ICs over conventional through-silicon-vias-based counterparts. The smaller dimensions of monolithic inter-tier vias offer high-density integration, the flexibility of partitioning logic blocks across multiple tiers, and significantly reduced total wire-length enable high-performance and energy-efficiency. However, the performance of M3D ICs degrades due to the presence of electrostatic coupling when the inter-layer-dielectric thickness between two adjacent tiers is less than 50nm. In this work, we evaluate the performance of an M3D-enabled Network-on-chip (NoC) architecture in the presence of electrostatic coupling. Electrostatic coupling induces significant delay and energy overheads for the multi-tier NoC routers. This in turn results in considerable performance degradation if the NoC design methodology does not incorporate the effects of electrostatic coupling. We demonstrate that electrostatic coupling degrades the energy-delay-product of an M3D NoC by 18.1% averaged over eight different applications from SPLASH-2 and PARSEC benchmark suites. As a countermeasure, we advocate the adoption of electrostatic coupling-aware M3D NoC design methodology. Experimental results show that the coupling-aware M3D NoC reduces performance penalty by lowering the number of multi-tier routers significantly.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W2974752139",
    "type": "article"
  },
  {
    "title": "Prolonging Lifetime of PCM-Based Main Memories through On-Demand Page Pairing",
    "doi": "https://doi.org/10.1145/2699867",
    "publication_date": "2015-03-02",
    "publication_year": 2015,
    "authors": "Marjan Asadinia; Mohammad Arjomand; Hamid Sarbazi Azad",
    "corresponding_authors": "",
    "abstract": "With current memory scalability challenges, Phase-Change Memory (PCM) is viewed as an attractive replacement to DRAM. The preliminary concern for PCM applicability is its limited write endurance that results in fast wear-out of memory cells. Worse, process variation in the deep-nanometer regime increases the variation in cell lifetime, resulting in an early and sudden reduction in main memory capacity due to the wear-out of a few cells. Recent studies have proposed redirection or correction schemes to alleviate this problem, but all suffer poor throughput or latency. In this article, we show that one of the inefficiency sources in current schemes, even when wear-leveling algorithms are used, is the nonuniform write endurance limit incurred by process variation, that is, when some memory pages have reached their endurance limit, other pages may be far from their limit. In this line, we present a technique that aims to displace a faulty page to a healthy page. This technique, called On-Demand Page Paired PCM (OD3P, for short), when applied at page level, can improve PCM time-to-failure by 20% on average for different multithreaded and multiprogrammed workloads while also improving IPC by 14% on average compared to previous page-level techniques. The comparison between line-level OD3P and previous line-level techniques reveals about 2× improvement of lifetime and performance.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W1977713234",
    "type": "article"
  },
  {
    "title": "Component-Based Synthesis of Embedded Systems Using Satisfiability Modulo Theories",
    "doi": "https://doi.org/10.1145/2746235",
    "publication_date": "2015-09-28",
    "publication_year": 2015,
    "authors": "Steffen Peter; Tony Givargis",
    "corresponding_authors": "",
    "abstract": "Constraint programming solvers, such as Satisfiability Modulo Theory (SMT) solvers, are capable tools in finding preferable configurations for embedded systems from large design spaces. However, constructing SMT constraint programs is not trivial, in particular for complex systems that exhibit multiple viewpoints and models. In thisarticle we propose CoDeL: a component-based description language that allows system designers to express components as reusable building blocks of the system with their parameterizable properties, models, and interconnectivity. Systems are synthesized by allocating, connecting, and parameterizing the components to satisfy the requirements of an application. We present an algorithm that transforms component-based design spaces, expressible in CoDeL, to an SMT program, which, solved by state-of-the-art SMT solvers, determines the satisfiability of the synthesis problem, and delivers a correct-by-construction system configuration. Evaluation results for use cases in the domain of scheduling and mapping of distributed real-time processes confirm, first, the performance gain of SMT compared to traditional design space exploration approaches, second, the usability gains by expressing design problems in CoDeL, and third, the capability of the CoDeL/SMT approach to support the design of embedded systems.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2009673834",
    "type": "article"
  },
  {
    "title": "Floorplanning and Topology Synthesis for Application-Specific Network-on-Chips with RF-Interconnect",
    "doi": "https://doi.org/10.1145/2890499",
    "publication_date": "2016-07-21",
    "publication_year": 2016,
    "authors": "Jinglei Huang; Song Chen; Wei Zhong; Wenchao Zhang; Shengxi Diao; Fujiang Lin",
    "corresponding_authors": "",
    "abstract": "Application-specific Network-on-Chip (ASNoC) has been proposed as a promising solution to address the global communication challenges in System-on-Chips. However, with the number of cores increasing, the on-chip communication becomes more and more complex and the power consumption imposes the major challenge for designing ASNoCs. In this article, we propose a four-stage floorplanning and topology synthesis approach for ASNoCs with Radio-Frequency Interconnect (RF-I). First, considering the advantage of RF-I in long-distance on-chip communication, we integrate the floorplanning and clustering to explore the proper clustering of cores, where the cores belonging to the same cluster will share the same switch for communications, form an island, and occupy a contiguous physical region. After the switches and network interfaces are inserted into the floorplan, the allocation of routing paths and the RF-I logical channels are integrated in an iterative procedure to generate fine-grained dynamically reconfigurable ASNoC topologies. Finally, considering the signal integrity of RF-I, we adjust the placement of the switches by a simulated annealing-based method to reduce the number of RF-I routing corners. To evaluate the placement of switches, we propose a dynamical programming-based method to route the transmission line with the minimized number of routing corners in linear time. The results show that, using the RF-I, we can reduce the power consumption of ASNoCs by 20% to 26%.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2492362241",
    "type": "article"
  },
  {
    "title": "Secure and Flexible Trace-Based Debugging of Systems-on-Chip",
    "doi": "https://doi.org/10.1145/2994601",
    "publication_date": "2016-12-28",
    "publication_year": 2016,
    "authors": "Jerry Backer; David Hély; Ramesh Karri",
    "corresponding_authors": "",
    "abstract": "This work tackles the conflict between enforcing security of a system-on-chip (SoC) and providing observability during trace-based debugging. On one hand, security objectives require that assets remain confidential at different stages of the SoC life cycle. On the other hand, the trace-based debug infrastructure exposes values of internal signals that can leak the assets to untrusted third parties. We propose a secure trace-based debug infrastructure to resolve this conflict. The secure infrastructure tags each asset to identify its owner (to whom it can be exposed during debug) and nonintrusively enforces the confidentiality of the assets during runtime debug. We implement a prototype of the enhanced infrastructure on an FPGA to validate its functional correctness. ASIC estimations show that our approach incurs practical area and power costs.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2565762120",
    "type": "article"
  },
  {
    "title": "An Adaptive Demand-Based Caching Mechanism for NAND Flash Memory Storage Systems",
    "doi": "https://doi.org/10.1145/2947658",
    "publication_date": "2016-12-13",
    "publication_year": 2016,
    "authors": "Yi Wang; Zhiwei Qin; Renhai Chen; Zili Shao; Laurence T. Yang",
    "corresponding_authors": "",
    "abstract": "During past decades, the capacity of NAND flash memory has been increasing dramatically, leading to the use of nonvolatile flash in the system’s memory hierarchy. The increasing capacity of NAND flash memory introduces a large RAM footprint to store the logical to physical address mapping. The demand-based approach can effectively reduce and well control the RAM footprint. However, extra address translation overhead is also introduced which may degrade the system performance. In this article, we present CDFTL, an adaptive Caching mechanism for Demand-based Flash Translation Layer, for NAND flash memory storage systems. CDFTL adopts both the fine-grained entry-based caching mechanism to exploit temporal locality and the coarse-grained translation-page-based caching mechanism to exploit spatial locality of workloads. By selectively caching the on-demand address mappings and adaptively changing the space configurations of two granularities, CDFTL can effectively utilize the RAM space and improve the cache hit ratio. We evaluate CDFTL under a real hardware embedded platform using a variety of I/O traces. Experimental results show that our technique can achieve an 11.13% reduction in average system response time and a 35.21% reduction in translation block erase counts compared with the previous work.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2567395862",
    "type": "article"
  },
  {
    "title": "A Hardware-Efficient Block Matching Algorithm and Its Hardware Design for Variable Block Size Motion Estimation in Ultra-High-Definition Video Encoding",
    "doi": "https://doi.org/10.1145/3290408",
    "publication_date": "2019-01-10",
    "publication_year": 2019,
    "authors": "Jianwei Zheng; Chao Lü; Jiefeng Guo; Deming Chen; Donghui Guo",
    "corresponding_authors": "",
    "abstract": "Variable block size motion estimation has contributed greatly to achieving an optimal interframe encoding, but involves high computational complexity and huge memory access, which is the most critical bottleneck in ultra-high-definition video encoding. This article presents a hardware-efficient block matching algorithm with an efficient hardware design that is able to reduce the computational complexity of motion estimation while providing a sustained and steady coding performance for high-quality video encoding. A three-level memory organization is proposed to reduce memory bandwidth requirement while supporting a predictive common search window. By applying multiple search strategies and early termination, the proposed design provides 1.8 to 3.7 times higher hardware efficiency than other works. Furthermore, on-chip memory has been reduced by 96.5% and off-chip bandwidth requirement has been reduced by 39.4% thanks to the proposed three-level memory organization. The corresponding power consumption is only 198mW at the highest working frequency of 500MHz. The proposed design is attractive for high-quality video encoding in real-time applications with low power consumption.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2910565488",
    "type": "article"
  },
  {
    "title": "A Hierarchical HVAC Control Scheme for Energy-aware Smart Building Automation",
    "doi": "https://doi.org/10.1145/3393666",
    "publication_date": "2020-05-23",
    "publication_year": 2020,
    "authors": "Rajib Lochan Jana; Soumyajit Dey; Pallab Dasgupta",
    "corresponding_authors": "",
    "abstract": "Heating ventilation and air conditioning (HVAC) systems usually account for the highest percentage of overall energy usage in large-sized smart building infrastructures. The performance of HVAC control systems for large buildings strongly depend on the outside environment, building architecture, and (thermal) zone usage pattern of the building. In large buildings, HVAC system with multiple air handling units (AHUs) is required to fulfill the cooling/heating requirements. In the present work, we propose an energy-aware building resource allocation and economic model predictive control (eMPC) framework for multi-AHU-based HVAC system. The energy consumption of a multi-AHU-based HVAC system significantly depends on how long the AHUs are running, which again is governed by the zone usage demands. Our approach comprises a two-step hierarchical technique where we first minimize the running time of AHUs by suitably allocating building resources (thermal zones) to usage demands for zones. Next, we formulate a finite receding horizon control problem for trading off energy consumption against thermal comfort during HVAC operations. Given a high-level building specification and usage demand, our computer-aided design framework generates building thermal models, allocates usage demands, formulates the control scheme, and simulates it to generate power consumption statistics for the given building with usage demands. We believe that the proposed framework will help in early analysis during the design phase of energy-aware building architecture and HVAC control. The framework can also be useful from a building operator point of view for energy-aware HVAC control as well as for satisfying smart grid demand-response events by HVAC system peak power reduction through automated control actions.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W3031841740",
    "type": "article"
  },
  {
    "title": "Machine Learning for Congestion Management and Routability Prediction within FPGA Placement",
    "doi": "https://doi.org/10.1145/3373269",
    "publication_date": "2020-07-07",
    "publication_year": 2020,
    "authors": "Hannah Szentimrey; Abeer Al-Hyari; Jeremy Foxcroft; Timothy J. Martin; David Noël; Gary Gréwal; Shawki Areibi",
    "corresponding_authors": "",
    "abstract": "Placement for Field Programmable Gate Arrays (FPGAs) is one of the most important but time-consuming steps for achieving design closure. This article proposes the integration of three unique machine learning models into the state-of-the-art analytic placement tool GPlace3.0 with the aim of significantly reducing placement runtimes. The first model, MLCong, is based on linear regression and replaces the computationally expensive global router currently used in GPlace3.0 to estimate switch-level congestion. The second model, DLManage, is a convolutional encoder-decoder that uses heat maps based on the switch-level congestion estimates produced by MLCong to dynamically determine the amount of inflation to apply to each switch to resolve congestion. The third model, DLRoute, is a convolutional neural network that uses the previous heat maps to predict whether or not a placement solution is routable. Once a placement solution is determined to be routable, further optimization may be avoided, leading to improved runtimes. Experimental results obtained using 372 benchmarks provided by Xilinx Inc. show that when all three models are integrated into GPlace3.0, placement runtimes decrease by an average of 48%.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W3041521987",
    "type": "article"
  },
  {
    "title": "Enhancing the Reliability of MLC NAND Flash Memory Systems by Read Channel Optimization",
    "doi": "https://doi.org/10.1145/2699866",
    "publication_date": "2015-09-28",
    "publication_year": 2015,
    "authors": "Nikolaos Papandreou; Thomas Parnell; Haralampos Pozidis; Thomas Mittelholzer; Evangelos Eleftheriou; Charles Camp; Thomas J. Griffin; Gary Tressler; Andrew Walls",
    "corresponding_authors": "",
    "abstract": "NAND flash memory is not only the ubiquitous storage medium in consumer applications but has also started to appear in enterprise storage systems as well. MLC and TLC flash technology made it possible to store multiple bits in the same silicon area as SLC, thus reducing the cost per amount of data stored. However, at current sub-20nm technology nodes, MLC flash devices fail to provide the levels of raw reliability, mainly cycling endurance, that are required by typical enterprise applications. Advanced signal processing and coding schemes are needed to improve the flash bit error rate and thus elevate the device reliability to the desired level. In this article, we report on the use of adaptive voltage thresholds and cell-to-cell interference cancellation in the read operation of NAND flash devices. We discuss how the optimal read voltage thresholds can be determined and assess the benefit of cancelling cell-to-cell interference in terms of cycling endurance, data retention, and resilience to read disturb.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W1994295486",
    "type": "article"
  },
  {
    "title": "Exact Logic and Fault Simulation in Presence of Unknowns",
    "doi": "https://doi.org/10.1145/2611760",
    "publication_date": "2014-06-01",
    "publication_year": 2014,
    "authors": "Dominik Erb; Michael A. Kochte; Matthias Sauer; Stefan Hillebrecht; Tobias Schubert; Hans-Joachim Wunderlich; Bernd Becker",
    "corresponding_authors": "",
    "abstract": "Logic and fault simulation are essential techniques in electronic design automation. The accuracy of standard simulation algorithms is compromised by unknown or X-values. This results in a pessimistic overestimation of X-valued signals in the circuit and a pessimistic underestimation of fault coverage. This work proposes efficient algorithms for combinational and sequential logic as well as for stuck-at and transition-delay fault simulation that are free of any simulation pessimism in presence of unknowns. The SAT-based algorithms exactly classifiy all signal states. During fault simulation, each fault is accurately classified as either undetected, definitely detected, or possibly detected. The pessimism with respect to unknowns present in classic algorithms is thoroughly investigated in the experimental results on benchmark circuits. The applicability of the proposed algorithms is demonstrated on larger industrial circuits. The results show that, by accurate analysis, the number of detected faults can be significantly increased without increasing the test-set size.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2065005875",
    "type": "article"
  },
  {
    "title": "Robust and Low-Power Digitally Programmable Delay Element Designs Employing Neuron-MOS Mechanism",
    "doi": "https://doi.org/10.1145/2740963",
    "publication_date": "2015-09-28",
    "publication_year": 2015,
    "authors": "Renyuan Zhang; Mineo Kaneko",
    "corresponding_authors": "",
    "abstract": "The feasibility of designing digitally programmable delay elements (PDEs) employing neuron-MOS mechanism is investigated in this work. By coupling the capacitors on the gate of the MOS transistor, the current flowing through the transistor can be digitally tuned without additional static power consumption. Various switching delays are generated by a clock buffer stage in this manner. Two types of neuron-MOS-based PDEs are suggested in this article. One of them is realized by directly applying capacitor-coupling technology on the transistors of an inverter as a clock buffer. The delay programmability is realized by tuning the charging/discharging current through the neuron-MOS inverter digitally. Since no additional transistor is introduced into the charging/discharging path, the performance fluctuation due to process variations on MOS transistors is reduced. The temperature effect is also partially compensated by the proposed neuron-MOS implementation. Another type of PDE circuit is proposed by employing a reliable reference-current-generator, where the neuron-MOS transistor acts as a linearly tunable resistance. A stable reference current is generated and used for charging/discharging the inverter as a clock buffer. As a result, the switching delay of the inverter is linearly programmed by digital input patterns. In general, both types of suggested PDE circuits achieve improved or fair performances over the robustness, power consumption, and linearity.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2093452503",
    "type": "article"
  },
  {
    "title": "Minimizing Stack Memory for Hard Real-Time Applications on Multicore Platforms with Partitioned Fixed-Priority or EDF Scheduling",
    "doi": "https://doi.org/10.1145/2846096",
    "publication_date": "2016-05-11",
    "publication_year": 2016,
    "authors": "Chao Wang; Chuansheng Dong; Haibo Zeng; Zonghua Gu",
    "corresponding_authors": "",
    "abstract": "Multicore processors are increasingly adopted in resource-constrained real-time embedded applications. In the development of such applications, efficient use of RAM memory is as important as the effective scheduling of software tasks. Preemption Threshold Scheduling (PTS) is a well-known technique for controlling the degree of preemption, possibly improving system schedulability, and to reduce system stack usage. In this paper, we consider partitioned multi-processor scheduling on a multicore processor with either Fixed-Priority or Earliest Deadline First scheduling algorithms with PTS and address the design optimization problem of mapping tasks to processor cores and assignment of task priorities and preemption thresholds with the optimization objective of minimizing system stack usage. We present both optimal solution techniques based on Mixed Integer Linear Programming and efficient heuristic algorithms that can achieve high-quality results. We perform extensive performance evaluations using both synthetic tasksets and industrial case studies.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2384806434",
    "type": "article"
  },
  {
    "title": "High-throughput Near-Memory Processing on CNNs with 3D HBM-like Memory",
    "doi": "https://doi.org/10.1145/3460971",
    "publication_date": "2021-06-28",
    "publication_year": 2021,
    "authors": "Naebeom Park; Sungju Ryu; Jaeha Kung; Jae‐Joon Kim",
    "corresponding_authors": "",
    "abstract": "This article discusses the high-performance near-memory neural network (NN) accelerator architecture utilizing the logic die in three-dimensional (3D) High Bandwidth Memory– (HBM) like memory. As most of the previously reported 3D memory-based near-memory NN accelerator designs used the Hybrid Memory Cube (HMC) memory, we first focus on identifying the key differences between HBM and HMC in terms of near-memory NN accelerator design. One of the major differences between the two 3D memories is that HBM has the centralized through- silicon-via (TSV) channels while HMC has distributed TSV channels for separate vaults. Based on the observation, we introduce the Round-Robin Data Fetching and Groupwise Broadcast schemes to exploit the centralized TSV channels for improvement of the data feeding rate for the processing elements. Using synthesized designs in a 28-nm CMOS technology, performance and energy consumption of the proposed architectures with various dataflow models are evaluated. Experimental results show that the proposed schemes reduce the runtime by 16.4–39.3% on average and the energy consumption by 2.1–5.1% on average compared to conventional data fetching schemes.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W3174762441",
    "type": "article"
  },
  {
    "title": "A Design Methodology for Energy-Aware Processing in Unmanned Aerial Vehicles",
    "doi": "https://doi.org/10.1145/3470451",
    "publication_date": "2021-09-13",
    "publication_year": 2021,
    "authors": "Jingyu He; Yao Xiao; Corina Bogdan; Shahin Nazarian; Paul Bogdan",
    "corresponding_authors": "",
    "abstract": "Unmanned Aerial Vehicles (UAVs) have rapidly become popular for monitoring, delivery, and actuation in many application domains such as environmental management, disaster mitigation, homeland security, energy, transportation, and manufacturing. However, the UAV perception and navigation intelligence (PNI) designs are still in their infancy and demand fundamental performance and energy optimizations to be eligible for mass adoption. In this article, we present a generalizable three-stage optimization framework for PNI systems that (i) abstracts the high-level programs representing the perception, mining, processing, and decision making of UAVs into complex weighted networks tracking the interdependencies between universal low-level intermediate representations; (ii) exploits a differential geometry approach to schedule and map the discovered PNI tasks onto an underlying manycore architecture. To mine the complexity of optimal parallelization of perception and decision modules in UAVs, this proposed design methodology relies on an Ollivier-Ricci curvature-based load-balancing strategy that detects the parallel communities of the PNI applications for maximum parallel execution, while minimizing the inter-core communication; and (iii) relies on an energy-aware mapping scheme to minimize the energy dissipation when assigning the communities onto tile-based networks-on-chip. We validate this approach based on various drone PNI designs including flight controller, path planning, and visual navigation. The experimental results confirm that the proposed framework achieves 23% flight time reduction and up to 34% energy savings for the flight controller application. In addition, the optimization on a 16-core platform improves the on-time visit rate of the path planning algorithm by 14% while reducing 81% of run time for ConvNet visual navigation.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W3200278798",
    "type": "article"
  },
  {
    "title": "MeF-RAM: A New Non-Volatile Cache Memory Based on Magneto-Electric FET",
    "doi": "https://doi.org/10.1145/3484222",
    "publication_date": "2021-11-02",
    "publication_year": 2021,
    "authors": "Shaahin Angizi; Navid Khoshavi; Andrew Marshall; P. A. Dowben; Deliang Fan",
    "corresponding_authors": "",
    "abstract": "Magneto-Electric FET ( MEFET ) is a recently developed post-CMOS FET, which offers intriguing characteristics for high-speed and low-power design in both logic and memory applications. In this article, we present MeF-RAM , a non-volatile cache memory design based on 2-Transistor-1-MEFET ( 2T1M ) memory bit-cell with separate read and write paths. We show that with proper co-design across MEFET device, memory cell circuit, and array architecture, MeF-RAM is a promising candidate for fast non-volatile memory ( NVM ). To evaluate its cache performance in the memory system, we, for the first time, build a device-to-architecture cross-layer evaluation framework to quantitatively analyze and benchmark the MeF-RAM design with other memory technologies, including both volatile memory (i.e., SRAM, eDRAM) and other popular non-volatile emerging memory (i.e., ReRAM, STT-MRAM, and SOT-MRAM). The experiment results for the PARSEC benchmark suite indicate that, as an L2 cache memory, MeF-RAM reduces Energy Area Latency ( EAT ) product on average by ~98% and ~70% compared with typical 6T-SRAM and 2T1R SOT-MRAM counterparts, respectively.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W3208883416",
    "type": "article"
  },
  {
    "title": "LOGIC: Logic Synthesis for Digital In-Memory Computing",
    "doi": "https://doi.org/10.1145/3711848",
    "publication_date": "2025-01-08",
    "publication_year": 2025,
    "authors": "Muhammad Rashedul Haq Rashed; Sven Thijssen; Sumit Kumar Jha; Rickard Ewetz",
    "corresponding_authors": "",
    "abstract": "In-memory processing offers a promising solution for enhancing the performance of data-intensive applications. While analog in-memory computing demonstrates remarkable efficiency, its limited precision is suitable only for approximate computing tasks. In contrast, digital in-memory computing delivers the deterministic precision necessary to accelerate high-assurance applications. Current digital in-memory computing methods typically involve manually breaking down arithmetic operations into in-memory compute kernels. In contrast, traditional digital circuits are synthesized through intricate and automated design workflows. In this article, we introduce a logic synthesis framework called LOGIC, which facilitates the translation of high-level applications into digital in-memory compute kernels that can be executed using non-volatile memory. We propose techniques for decomposing element-wise arithmetic operations into in-memory kernels while minimizing the number of in-memory operations. Additionally, we optimize the sequence of in-memory operations to reduce non-volatile memory utilization. To address the NP-hard execution sequencing optimization problem, we have developed two look-ahead algorithms that offer practical solutions. Additionally, we leverage data layout reorganization to efficiently accelerate applications that heavily rely on sparse matrix-vector multiplication operations. Our experimental evaluations demonstrate that our proposed synthesis approach improves the area and latency of fixed-point multiplication by 84% and 20% compared to the state-of-the-art, respectively. Moreover, when applied to scientific computing applications sourced from the SuiteSparse Matrix Collection, our design achieves remarkable improvements in area, latency, and energy efficiency by factors of 4.8×, 2.6×, and 11×, respectively.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4406181555",
    "type": "article"
  },
  {
    "title": "HEANA: A Hybrid Time-Amplitude Analog Optical Accelerator with Flexible Dataflows for Energy-Efficient CNN Inference",
    "doi": "https://doi.org/10.1145/3711845",
    "publication_date": "2025-01-09",
    "publication_year": 2025,
    "authors": "Sairam Sri Vatsavai; Venkata Sai Praneeth Karempudi; Ishan Thakkar",
    "corresponding_authors": "",
    "abstract": "Several photonic microring resonators (MRRs) based analog accelerators have been proposed to accelerate the inference of integer-quantized Convolutional Neural Networks (CNNs) with remarkably higher throughput and energy efficiency compared to their electronic counterparts. However, the existing analog photonic accelerators suffer from three shortcomings: (i) severe hampering of wavelength parallelism due to various crosstalk effects, (ii) inflexibility of supporting various dataflows with temporal accumulations, and (iii) failure in fully leveraging the ability of photodetectors to perform in-situ accumulations. These shortcomings collectively hamper the performance and energy efficiency of prior accelerators. To tackle these shortcomings, we present a novel H ybrid tim E - A mplitude a N alog optical A ccelerator, called HEANA. HEANA employs hybrid time-amplitude analog optical modulators (TAOMs) in a spectrally hitless arrangement which significantly reduces optical signal losses and crosstalk effects, thereby increasing the wavelength parallelism in HEANA. HEANA employs our invented balanced photo-charge accumulators (BPCAs) that enable buffer-less, in-situ, spatio-temporal accumulations to eliminate the need to use reduction networks in HEANA, relieving it from related latency and energy overheads. Moreover, TAOMs and BPCAs increase the flexibility of HEANA to efficiently support spatio-temporal accumulations for various dataflows. Our evaluation for the inference of four modern CNNs indicates that HEANA provides improvements of at least 25 × and 32 × in frames-per-second (FPS) and FPS/W (energy-efficiency), respectively, for equal-area comparisons, on gmean over two MRR-based analog CNN accelerators from prior work.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4406220331",
    "type": "article"
  },
  {
    "title": "Multi-Row Guiding Template Design for Lamellar Directed Self-Assembly with Self-Aligned Via Process",
    "doi": "https://doi.org/10.1145/3711851",
    "publication_date": "2025-01-09",
    "publication_year": 2025,
    "authors": "Yi‐Ting Lin; Kuang–Chao Fan; Iris Hui-Ru Jiang",
    "corresponding_authors": "",
    "abstract": "Directed self-assembly (DSA) of block copolymers can generate tiny and dense layout features, holding great potential for patterning vias and contacts at advanced nodes. Existing studies mainly focused on guiding template design for cylindrical DSA, but by leveraging self-aligned via process, lamellar DSA can form vias to be immune to placement errors and free of a uniform pitch between vias, which cylindrical DSA suffers from. The state-of-the-art guiding template design for lamellar DSA can handle only single-row templates, thus limiting the flexibility of via grouping. Therefore, in this article, we explore further and propose a novel and general multi-row guiding template design approach. Experimental results show that our approach outperforms the state-of-the-art work on both mask conflicts and short guiding templates, and requires much less computation time.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4406220537",
    "type": "article"
  },
  {
    "title": "Algorithm-Hardware Co-design for Accelerating Depthwise Separable CNNs",
    "doi": "https://doi.org/10.1145/3711846",
    "publication_date": "2025-01-09",
    "publication_year": 2025,
    "authors": "Guoqing Li; Rengang Li; Tuo Li; Tinghuan Chen; Meng Zhang; Henk Corporaal",
    "corresponding_authors": "",
    "abstract": "Depthwise separable convolution (DSC) is a popular method for constructing lightweight neural networks. However, the pointwise convolution (PWC) has a much larger number of parameters than the depthwise convolution (DWC), causing the imbalanced parameter ratio of PWC to DWC. In this paper, we propose an efficient and hardware-efficiency convolution (Shared Kernel sliding on channel Convolution, SKC) to replace the redundant PWC in DSC for a balanced parameter ratio, where SKC customizes the sharing kernel in the channel dimension to reduce the number of parameters, and the local connection in the channel dimension reduces the computation. Furthermore, the proposed SKC is suitable for Winograd acceleration, and the large kernel decomposition method is introduced to facilitate its use. We implement the first Winograd-based FPGA hardware accelerator for DSCNets. The shared 1D and 2D Winograd convolution computing engine is proposed to compute the proposed DSC consisting of DWC and SKC efficiently. An alternating loading and reusing storage approach is developed to efficiently load SKC input feature maps. Experimental results show our DSC-based accelerator can achieve 20 × higher power efficiency at the cost of a small loss of accuracy by algorithm-hardware co-design compared with traditional accelerators.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4406220615",
    "type": "article"
  },
  {
    "title": "RL-MUL 2.0: Multiplier Design Optimization with Parallel Deep Reinforcement Learning and Space Reduction",
    "doi": "https://doi.org/10.1145/3711850",
    "publication_date": "2025-01-14",
    "publication_year": 2025,
    "authors": "Dongsheng Zuo; Jiadong Zhu; Yikang Ouyang; Yuzhe Ma",
    "corresponding_authors": "",
    "abstract": "Multiplication is a fundamental operation in many applications, and multipliers are widely adopted in various circuits. However, optimizing multipliers is challenging due to the extensive design space. In this paper, we propose a multiplier design optimization framework based on reinforcement learning. We utilize matrix and tensor representations for the compressor tree of a multiplier, enabling seamless integration of convolutional neural networks as the agent network. The agent optimizes the multiplier structure using a Pareto-driven reward customized to balance area and delay. Furthermore, we enhance the original framework with parallel reinforcement learning and design space pruning techniques and extend its capability to optimize fused multiply-accumulate (MAC) designs. Experiments conducted on different bit widths of multipliers demonstrate that multipliers produced by our approach outperform all baseline designs in terms of area, power, and delay. The performance gain is further validated by comparing the area, power, and delay of processing element arrays using multipliers from our approach and baseline approaches.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4406371412",
    "type": "article"
  },
  {
    "title": "SPTA 2.0: Enhanced Scalable Parallel Track Assignment Algorithm with Two-Stage Partition Considering Timing Delay",
    "doi": "https://doi.org/10.1145/3712009",
    "publication_date": "2025-01-14",
    "publication_year": 2025,
    "authors": "Huayang Cai; Pengcheng Huang; Genggeng Liu; Xing Huang; Yidan Jing; Wen-Hao Liu; Ting-Chi Wang",
    "corresponding_authors": "",
    "abstract": "Routability has always been a significant challenge in Very Large Scale Integration (VLSI) design. To overcome the potential mismatch between the global routing results and the detailed routing requirements, track assignment is introduced to achieve an efficient routability estimation. Moreover, with the increasing scale of circuits, the intricate interconnections among the components on the chip lead to increased timing delay in signal transmission, thereby significantly impacting the performance and reliability of the circuit. Thus, to further improve the routability of the circuit, it is also critical to realize an accurate estimation of the timing delay within the track assignment stage. Existing heuristic track assignment algorithms, however, are prone to local optimality, and thus fail to provide accurate routability estimations. In this paper, we propose an enhanced scalable parallel track assignment algorithm called SPTA 2.0 for VLSI design, employing a two-stage partition strategy and considering timing delay. First, the proposed algorithm achieves efficient assignment of all wires by considering the routing information from both the global and local nets. Second, the overlap cost, the blockage cost, and the wirelength cost can be minimized to significantly improve the routability. Third, a critical wire controlling strategy is proposed to optimize signal timing delays inside nets. Finally, a two-stage partition strategy and a panel-subpanel-level parallelism are designed to further reduce the runtime, improving the scalability of the proposed methodology. Experimental results on multiple benchmarks demonstrate that the proposed method provides better routability estimations, and leads to superior track assignment solutions compared with existing algorithms.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4406371472",
    "type": "article"
  },
  {
    "title": "MESSI: Task Mapping and Scheduling Strategy for FPGA-based Heterogeneous Real-Time Systems",
    "doi": "https://doi.org/10.1145/3715323",
    "publication_date": "2025-01-25",
    "publication_year": 2025,
    "authors": "Sallar Ahmadi-Pour; Sangeet Saha; Klaus D. McDonald-Maier; Rolf Drechsler",
    "corresponding_authors": "",
    "abstract": "Continuous demands for improved performance within constrained resource budgets are driving a move from homogeneous to heterogeneous processing platforms for the implementation of today’s Real-Time (RT) embedded systems. The applications executing on such systems are typically represented as a Precedence Task Graph (PTG), where a node represents a task or algorithm for one functionality and edges represent the complex interactions between multiple functionalities. Due to RT constraints, the task graph needs to be executed within a specified deadline. Although some existing studies have looked into solving this challenge, comprehensive studies that combine the theoretical features of RT task-graph mapping and scheduling with practical runtime architectural characteristics have mostly been ignored to date. Hence, in this paper, we consider the challenge of scheduling a RT application modelled as a single PTG, with the objective of minimizing the overall execution time under Hardware (HW) resource and deadline constraints for heterogeneous Central Processing Unit (CPU) + Field Programmable Gate Array (FPGA) architectures. First, we introduce an optimal solution using Integer Linear Programming (ILP). However, this ILP-based optimal solution suffers from computational complexity and does not scale well even for moderately large problem sizes. Hence, we additionally propose heuristic algorithms for task mapping and scheduling. The efficiency of the proposed scheme, named MESSI, has been evaluated through experiments using PTGs on a practical CPU+FPGA system regarding current technology restrictions. Our experiments demonstrate that performance gains of 55.6 % and area usage reductions of 46.3 % are possible compared to full Software SW and HW execution, respectively.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4406825375",
    "type": "article"
  },
  {
    "title": "Unveiling Cross-checking Opportunities in Verilog Compilers",
    "doi": "https://doi.org/10.1145/3715325",
    "publication_date": "2025-01-28",
    "publication_year": 2025,
    "authors": "Yue Zhou; Yanyan Jiang; Jian Lu",
    "corresponding_authors": "",
    "abstract": "The landscape of Verilog toolchains for electronic design automation (EDA) is diverse, and their reliability is crucial, as errors can lead to significant debugging challenges and delays in development. Methodologies such as testing and formal verification have been applied to identify and eliminate defects in these toolchains. We propose a framework named VeriXmith to interconnect design tools involved in logical synthesis and simulation for cross-checking. These tools process circuit designs and produce outputs in different languages, such as Verilog netlists from synthesizers and C++ programs from simulators. Since these outputs represent the same circuit semantics, we can leverage this semantic consistency to verify the tools that translate one representation into another. Our approach involves creating semantics extractors to extend the range of circuit representations available for semantic equivalence checking by converting them into a canonical and comparable form. Additionally, we develop mutation operators for Verilog designs to introduce new data/control paths and language constructs, enhancing the diversity of circuit designs as test inputs. By validating semantic equivalence, our framework successfully identifies defects in existing Verilog toolchains. An exploratory experiment uncovers 31 previously unknown bugs in well-known open-source Verilog tools, including Verilator and Yosys.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4406915577",
    "type": "article"
  },
  {
    "title": "A New Dynamic Countermeasure to Strengthen Design Obfuscation in FPGAs",
    "doi": "https://doi.org/10.1145/3716502",
    "publication_date": "2025-02-05",
    "publication_year": 2025,
    "authors": "Sandeep Sunkavilli; Nishanth Chennagouni; Qiaoyan Yu",
    "corresponding_authors": "",
    "abstract": "FPGAs are being challenged by various security threats, including reverse engineering attacks, hardware tampering, and side-channel analysis attacks. Although the existing static obfuscation methods can protect FPGA systems from IP piracy and hardware tampering, limited work is available to improve the attack resilience of obfuscation modules. As hardware Trojans are one of the most significant hardware tampering attacks on FPGAs, this work aims for the specific hardware Trojan that attempts to nullify design obfuscation. To address this need, we leverage the advanced function of FPGA CAD tools to propose a Dynamic Partial Reconfiguration enabled Design Obfuscation (DPReDO) method. Our method partially modifies the FPGA bitstream at runtime to remove the sabotaged obfuscation variant, thus offering enhanced attack resilience against hardware Trojans. Experimental results based on ISCAS and ITC-99 benchmark circuits show that the DPReDO method reduces the Trojan hit rate by up to 80% over existing static obfuscation with less than 3% hardware overhead. To test the practical feasibility of the proposed countermeasure, we further apply DPReDO to an FPGA-accelerated computation engine for a financial application. Compared to static obfuscation, the proposed DPReDO only incurs 2.6% and 1.2% more FPGA LUTs and slices, respectively.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4407230583",
    "type": "article"
  },
  {
    "title": "Secure &amp; Reliable 10T SRAM Cell during Read, Write and Hold Operations against Power Analysis Attack",
    "doi": "https://doi.org/10.1145/3718086",
    "publication_date": "2025-02-18",
    "publication_year": 2025,
    "authors": "Aastha Gupta; Ravi Sindal; Vaibhav Neema",
    "corresponding_authors": "",
    "abstract": "Cryptography is essential to ensure data security in embedded devices that handle sensitive data. SRAM boosts overall performance by temporarily storing cryptographic keys. However, attackers can use side-channel, such as Power Analysis, to exploit power consumption patterns and extract secret keys. Once a key is compromised, encrypted data becomes vulnerable. There are many secure SRAM cell designs available in the literature, but they often degrade other performance parameters. This paper presents a novel 10-T SRAM cell design that provides protection against power analysis side-channel attacks (SCA) across all three cell operations, while also maintaining the performance of other key parameters. Monte Carlo simulations were conducted on 1000 samples each for case when BL=Q and BL≠Q during reading, writing, and holding data, using Cadence Virtuoso with a 45 nm technology node at 1V/270°C. Based on these simulations, the mean power difference was evaluated. The proposed P-10T SRAM cell exhibits a 0% mean power difference in all three modes of operation, demonstrating complete resilience to power analysis SCA. The design achieves 84.87% reliability with hold stability, read stability, and write ability values of 429 mV, 242 mV, and 250 mV, respectively. Furthermore, the write power dissipation of P-10T cell is 57.44 μW, which is 1.80 × lower than the power consumed by the conventional 6T cell.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4407709912",
    "type": "article"
  },
  {
    "title": "Dynamic Per-Flow Queues in Shared Buffer TSN Switches",
    "doi": "https://doi.org/10.1145/3718087",
    "publication_date": "2025-02-19",
    "publication_year": 2025,
    "authors": "Wenxue Wu; Tong Zhang; Zhen Li; Xiaoqin Feng; Liwei Zhang; Fengyuan Ren",
    "corresponding_authors": "",
    "abstract": "Time-Sensitive Networking (TSN), as an enhancement based on Ethernet, can ensure deterministic traffic transmission with low delays and minimal jitters. However, TSN switches have only eight priority queues inherited from Ethernet at each egress port, which limits the flexibility and efficiency of traffic scheduling, as well as the support for developing traffic management mechanisms. Although per-flow queues boost scheduling and Quality of Service (QoS), static per-flow hardware queues in switches are considered unpratical due to resource limits. In this paper, we leverage the limitation of buffer size on the number of concurrent flows in shared buffer TSN switches to design Dynamic Per-Flow Queues (DFQ). DFQ only maintains a fixed number of virtual queues determined by the buffer size and dynamically manages the mapping between virtual queues and active flows to provide the capability of per-flow queueing. By constructing Flow Mapping Table (FMT) with content-addressable memory (or hash bucket), DFQ can quickly match, create, and recycle queues to multiplex limited switch resource. We prototype DFQ on an FPGA switch and evaluate its performance in different scenarios. Experimental results show that DFQ can decrease the overhead of per-flow isolation with minimal impact on delay and throughput, indicating that DFQ is an effective per-flow queues solution.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4407749763",
    "type": "article"
  },
  {
    "title": "Layout Decomposition and Printing Time Optimization for Inkjet-Printed Electronics",
    "doi": "https://doi.org/10.1145/3721132",
    "publication_date": "2025-02-27",
    "publication_year": 2025,
    "authors": "Y. T. Lin; Meng Lian; Peng Hu; Bernhard Wolfrum; Tsun‐Ming Tseng; Iris Hui-Ru Jiang",
    "corresponding_authors": "",
    "abstract": "Inkjet-printed electronics is a low-cost option for large-scale production. To avoid manufacturing defects, recent research has considered design constraints, such as Laplace and proximity conflicts, decomposed the layouts into different layers, and printed them sequentially. The state-of-the-art work reduced the manufacturing time by optimizing the number of layers and drying time. In this work, we aim to enhance manufacturing efficiency from a new angle, concurrently optimizing the printing time and the layout decomposition of inkjet-printed electronics. We propose an integer linear programming formulation and a dynamic programming algorithm to determine layout decomposition and layer assignment and to estimate the total printing time by carefully considering printing characteristics and design constraints. Experimental results demonstrate significant reductions in overall printing time, leading to improved fabrication efficiency.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4408023918",
    "type": "article"
  },
  {
    "title": "LithoExp: Explainable Two-stage CNN-based Lithographic Hotspot Detection with Layout Defect Localization",
    "doi": "https://doi.org/10.1145/3721129",
    "publication_date": "2025-02-27",
    "publication_year": 2025,
    "authors": "Jiang Cong; HB Sun; Dan Feng; Zhiyao Xie; Benjamin Tan; Kang Liu",
    "corresponding_authors": "",
    "abstract": "Convolutional neural networks (CNNs) successfully detect lithographic hotspots by learning from hand-designed features of layout patterns or entire layouts, as images, in an end-to-end fashion. However, compared to lithography simulation, CNN-based solutions demonstrate inferior hotspot detection accuracy and a high false alarm rate. Moreover, the interpretability of the hotspot prediction process has yet to be considered due to the “black-box” nature of CNNs. In this work, inspired by conventional lithography simulation where defect regions are simulated as direct evidence for hotspot identification, we propose an explainable two-stage CNN-based hotspot detector that considers both the accuracy and interpretability of hotspot detection. Our architecture learns to locate the defect areas in the first stage as extracted hotspot features. In the second stage, we combine the strength of feature engineering and end-to-end learning, incorporating the original layout input, the learned defect location map from the first stage, and a fixed auxiliary region of interest (ROI) map for final hotspot detection. Experimental results for our technique exhibit the highest hotspot accuracy (98.1%) and the lowest false alarm rate (4.0%) thus far compared to all prior CNN solutions. We also demonstrate the best overall qualitative and quantitative interpretability results with the highest increase in confidence (IC) and the lowest average drop (AD) scores when CNN interpretation methods such as Grad-CAM-based approaches are applied. We further demonstrate use cases of our technique for successfully justifying and pinpointing hotspot mispredictions by examining the prediction evidence from our learned defect locations.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4408024913",
    "type": "article"
  },
  {
    "title": "An Efficient and Effective Optimization Algorithm for Buffer and Splitter Insertion in AQFP Circuits",
    "doi": "https://doi.org/10.1145/3721130",
    "publication_date": "2025-02-28",
    "publication_year": 2025,
    "authors": "Bing-Huan Wu; Wai-Kei Mak",
    "corresponding_authors": "",
    "abstract": "Adiabatic quantum-flux parametron (AQFP) is a superconducting technology with extremely low power consumption compared to traditional CMOS structures. Since AQFP logic gates are all clocked by AC current, extra buffer cells are required to balance the length of data paths. Furthermore, since the output current of an AQFP logic gate is too weak to drive more than one gate, splitter cells are needed to branch the output signals of multi-fanout gates. For an AQFP circuit, the total number of additional buffers and splitters may be much more than the number of logic gates, significantly impacting the circuit’s power, performance, and area. In this work, we propose several techniques to (i) reduce the total number of required buffers and splitters, and (ii) perturb the levels of logic gates to seek more opportunities for optimization. Experimental results show that, compared to state-of-the-art methods, our approach can obtain optimized results with less additional inserted buffers/splitters in shorter runtimes, especially in larger circuits.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4408067558",
    "type": "article"
  },
  {
    "title": "DeepVerifier: Learning to Update Test Sequences for Coverage-Guided Verification",
    "doi": "https://doi.org/10.1145/3721133",
    "publication_date": "2025-03-01",
    "publication_year": 2025,
    "authors": "Y. P. Lu; Chen Bai; Yuxuan Zhao; Ziyue Zheng; Yangdi Lyu; Mingyu Liu; Bei Yu",
    "corresponding_authors": "",
    "abstract": "Verification is critical in ensuring the reliable operation of modern, complex computing systems. However, as processor designs become increasingly sophisticated, conventional static verification techniques struggle to generate high-quality test sequences that achieve comprehensive coverage. Dynamic simulation-based approaches, which leverage coverage-driven objectives, can increase confidence in correct processor functionality but often suffer from low verification efficiency due to the generation of redundant test sequences and significant computational overhead. To address these challenges, this paper presents DeepVerifier, a novel coverage-guided test generation framework that leverages data-driven learning of existing test sequences and their associated coverage feedback. DeepVerifier uses a language model to learn the semantic representations of test sequences, ensure adherence to syntax constraints, and estimate the relationship between test sequences and coverage scores. By updating test sequences with higher coverage, DeepVerifier can significantly improve the efficiency and effectiveness of the verification process. Experimental results of verifying an out-of-order RISC-V microprocessor demonstrate that the framework accurately estimates the coverage scores of test sequences and updates high-quality sequences that contribute to higher coverage. This coverage-guided test generation technique holds promise for enhancing the reliability of modern processor designs.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4408070679",
    "type": "article"
  },
  {
    "title": "A Generalized Constraint Learning and Transfer Methodology with Net-First Graph Neural Network and Selective Topological Search for Hierarchical Analog / Mixed-Signal Circuit Layout Synthesis",
    "doi": "https://doi.org/10.1145/3722556",
    "publication_date": "2025-03-08",
    "publication_year": 2025,
    "authors": "Kaichang Chen; Georges Gielen",
    "corresponding_authors": "",
    "abstract": "Achieving efficient and effective automation in hierarchical analog/mixed-signal (AMS) integrated circuit layout synthesis remains a significant challenge in the electronic design automation domain, due to the vast design space and diverse layout requirements. The state-of-the-art AMS layout automation tools, like ALIGN and MAGICAL-EDA, utilize constraints extracted by designers to address this challenge. This constraint extraction is, however, a problem on its own when the number of constraints gets larger and the designs become more complicated. Recently, graph neural network (GNN)-based methods have been explored to extract inter-symmetry constraints in analog circuits, though with limited accuracy and applicability for other constraint types on hierarchical AMS circuits. In this paper, we propose a generalized constraint learning and transfer (CLT) framework that can address a generalized, wider range of constraints and offers a more accurate and robust CLT methodology for hierarchical AMS circuit layout synthesis. A generate-and-aggregate approach enhanced by net-first GNN (Nest-GNN) and selective topological search (SelecTS) algorithms is introduced to accurately and efficiently learn and transfer to a more generalized range of constraint, including symmetry, impedance matching and grouping for both placement and routing (P&amp;R). This framework is the first one, to the best of our knowledge, to transfer constraint types such as grouping and impedance matching, for P&amp;R on hierarchical AMS circuits. Tested on hierarchical AMS circuits with up to 25 hierarchies, over 1000 devices and more than 500 nets, our framework achieves an average CLT F1 score of over 0.98 for all constraint types in an efficient way, outperforming the state-of-the-art CLT methods.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4408256648",
    "type": "article"
  },
  {
    "title": "Adaptive Redistribution Layer Routing for Chiplet-Package Co-Design in 2.5D System",
    "doi": "https://doi.org/10.1145/3723043",
    "publication_date": "2025-03-11",
    "publication_year": 2025,
    "authors": "Zhen Zhuang; Weishiun Hung; MD Arafat Kabir; Yarui Peng; Tsung-Yi Ho",
    "corresponding_authors": "",
    "abstract": "2.5D packaging has become a popular alternative to integrate advanced logic and memory chiplets for high-performance computing and artificial intelligence systems. In the conventional design flow, chiplets and packages are independently designed and then integrated at the assembly stage. To bridge the gap between chiplet designs and package designs, existing chiplet-package co-design methods iteratively optimize chiplet layouts to improve the performance of the entire system. However, Redistribution Layer (RDL) routing, which finishes the interconnections between chiplets at the package level and significantly affects the system performance, is neglected in the existing co-design flows. Therefore, this paper proposes an effective chiplet-package co-design flow focusing on the RDL routing to optimize the package system performance dynamically. The proposed co-design flow can fill in the missing link, package-level co-optimization, of previous design flows. In the proposed co-design flow, we propose an efficient RDL routing algorithm to iteratively optimize the substrate layout based on the cross-boundary timing context extracted from both chiplets and the package. The proposed RDL routing algorithm has two critical techniques, including 1) a Maximal Independent Set-based (MIS-based) pin assignment method to dynamically optimize the pin positions of nets and 2) a network-flow-based router to generate routing layouts. Experimental results show that the proposed design flow can gradually improve the maximum frequency of a real design to the target performance, 400 MHz.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4408339805",
    "type": "article"
  },
  {
    "title": "Fault-Tolerant Cyclic Queuing and Forwarding with Fast ACK in Time-Sensitive Networking",
    "doi": "https://doi.org/10.1145/3723163",
    "publication_date": "2025-03-12",
    "publication_year": 2025,
    "authors": "Liwei Zhang; Tong Zhang; Xiaoqin Feng; Yuxia Ma; Hao Yang; Fengyuan Ren",
    "corresponding_authors": "",
    "abstract": "TSN is widely used in industrial automation networks because it can provide deterministic transmission services for critical data. Cyclic Queuing and Forwarding (CQF) is used to shape critical data. However, unexpected data errors may occur due to transient failures like electromagnetic interference. IEEE 802.1CB provides a solution to tolerate such failures by transmitting multiple replicas of data over disjoint paths. However, this solution introduces network resources wastage. Compared to redundant transmission, retransmission can reduce resource waste, but may violate the determinism in TSN. To address this issue, we propose a fault-tolerant mechanism for CQF that supports retransmission, called fault-tolerant CQF (FT-CQF). FT-CQF adopts the Go-Back-N concept to resist failure. Therefore, it does not violate the original transmission sequence of frames. On the basis of standard CQF, FT-CQF occupies an additional queue to cache replicas of Time-Trigger (TT) flows and reserves time slots to forward them. FT-CQF will forward or remove these replicas based on the ACK information. Non-TT flows can use this time slot to transmit when replicas are removed. We implemented FT-CQF on OMNeT++ and verified the performance of FT-CQF. Simulation experiments show that FT-CQF is effective in terms of reliability, bandwidth consumption, and delay.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4408343568",
    "type": "article"
  },
  {
    "title": "HNM-CIM: An Algorithm-Hardware Co-designed SRAM-based CIM for Transformer Acceleration Exploiting Hybrid N:M Sparsity",
    "doi": "https://doi.org/10.1145/3724394",
    "publication_date": "2025-03-17",
    "publication_year": 2025,
    "authors": "Yuang Ma; Yulong Meng; Zihao Xuan; Song Chen; Yi Kang",
    "corresponding_authors": "",
    "abstract": "SRAM-based computing-in-memory (CIM) is an efficient technology for computing neural networks where matrix operations are dominated. However, leveraging sparsity in CIM presents challenges due to the crossbar architecture, which complicates the avoidance of zero element calculations. Previous CIM designs have demonstrated that sparsity can improve energy efficiency, but these approaches often lead to non-negligible accuracy loss or substantial hardware overhead. To address this challenge, we propose a hybrid N:M CIM (HNM-CIM), an algorithm-architecture co-design framework for accelerating Transformers. At the algorithm level, we propose a hybrid N:M pruning (HNMP), a method that combines structured and unstructured sparsity. This approach maintains regularity while preserving the random distributions of sparsity, thereby enhancing model sparsity with negligible accuracy loss and ensuring CIM compatibility. At the hardware level, we introduce a hybrid N:M sparse digital CIM (HNM-CIM) to support HNMP, which can accelerate Transformers with hybrid N:M sparsity patterns. Experimental results show that HNMP can reduce Transformer models by about 3.1 × on model size with negligible accuracy loss. Compared with state-of-the-art references, HNM-CIM yields about 2.46 × speed up and 1.43 × area savings.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4408529805",
    "type": "article"
  },
  {
    "title": "Test Templates to Guide Test Generation for Single-Cycle Gate-Exhaustive Faults",
    "doi": "https://doi.org/10.1145/3724395",
    "publication_date": "2025-03-17",
    "publication_year": 2025,
    "authors": "Irith Pomeranz",
    "corresponding_authors": "Irith Pomeranz",
    "abstract": "Advanced fault models, such as the defect-aware, cell-aware and gate-exhaustive fault models, associate several faults with each standard cell or gate of a design. Test generation procedures, including ones that target advanced fault models, produce incompletely-specified tests, or test cubes, to support test compaction and test data compression. The key contribution of this article is to generalize the concept of a test cube into that of a test template for fault models where several faults are associated with the same standard cell or gate. Considering single-cycle gate-exhaustive faults as an example, a test template π i for a gate G i with a set of faults F i captures input values that are common to all the tests for the faults in F i , while allowing other input values to be different for different faults in F i . A new value, denoted by v , designates a value that is not common to all the inputs. A test template is useful since faults in F i share many of the same activation and propagation conditions, and learning the common input values of their tests can reduce the search space for test generation. The effectiveness of using test templates to guide test generation is demonstrated by considering single-cycle gate-exhaustive faults that are not detected by a given test set. Such faults are hard-to-detect. As part of the test generation procedure developed in this article, merging of test templates is carried out for increasing the fault coverage, and additional tests are generated by specifying the v values of test templates. The implementation of the test generation procedure was performed in an academic simulation environment using academic software tools, and the results are reported for benchmark circuits.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4408529860",
    "type": "article"
  },
  {
    "title": "EasyMRC: Efficient Mask Rule Checking via Representative Edge Sampling",
    "doi": "https://doi.org/10.1145/3723044",
    "publication_date": "2025-03-17",
    "publication_year": 2025,
    "authors": "Jiren Xu; Zhuolun He; Shuo Yin; Yuan Pu; Wenjian Yu; Bei Yu",
    "corresponding_authors": "",
    "abstract": "The photolithography process is getting more sophisticated with technology node scaling down and VLSI designs becoming complex. As photomask patterns get finer, mask rule checks (MRCs) are inevitable to avoid discrepancies in the layout and to ensure manufacturability. This paper introduces an efficient mask rule checking approach that utilizes a representative edge sampling scheme. The representative edge sampling scheme selects a subset of edges and points of each polygon that capture its contour, meanwhile greatly reducing the number of edges involved in actual checking. Experimental results demonstrate that the proposed approach achieves significant speedup compared with the state-of-the-art academic tool.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4408530722",
    "type": "article"
  },
  {
    "title": "TriHOT: Triangular and Hexagonal Norm Based Timing-Driven Optical Routing with Wavelength Division Multiplexing",
    "doi": "https://doi.org/10.1145/3725888",
    "publication_date": "2025-03-25",
    "publication_year": 2025,
    "authors": "Jun-Wei Liang; Iris Hui-Ru Jiang",
    "corresponding_authors": "",
    "abstract": "As semiconductor technology continues scaling, interconnect delay becomes a major bottleneck for circuit performance. On-chip optical interconnect with wavelength division multiplexing (WDM) is a promising alternative due to its high speed, broad bandwidth, and energy efficiency. Previous work estimates the timing of an optical interconnect in terms of L 1 or L 2 norm and simplifies its timing gain based on a distance threshold. This estimation and simplification cannot capture the essence of optical routing and the impact of WDM, and may cause timing degradation. In this work, we propose a novel timing model based on a unified triangular and hexagonal norm and establish a wirelength lower bound to measure the routing quality. Moreover, we reduce the WDM-aware optical routing to the Maximum Weighted Independent Set (MWIS) problem and approach it by weighted interval scheduling in linear time-space. Experimental results show that our method outperforms the state-of-the-art in terms of timing, wirelength, and transmission loss with comparable runtime.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4408833191",
    "type": "article"
  },
  {
    "title": "Context-aware Data Augmentation for Hardware Code Fault localization",
    "doi": "https://doi.org/10.1145/3725889",
    "publication_date": "2025-03-25",
    "publication_year": 2025,
    "authors": "Jian Hu; Zhenlei Liu",
    "corresponding_authors": "",
    "abstract": "The maintenance of quality and reliability in hardware products inherently relies on the verification of hardware code. Despite being a time-consuming process, the localization of faults in hardware code is essential for effective hardware verification. Dynamic fault localization (DFL) is considered as one of the most effective method for localizing faults. It utilizes coverage information, known as the coverage matrix, which is obtained from both passing and failing tests, to identify the program elements that are most likely responsible for observed failures in hardware programming languages such as VHDL or Verilog. However, the presence of error propagation, numerous fault-irrelevant statements, and a highly imbalanced coverage information pose significant challenges for DFL. In this paper, we propose Canal, a C ontext- a ware data augme n tation a pproach for dynamic fau l t localization in hardware code to address these challenges. Canal effectively overcomes these challenges by leveraging in-time detection to prevent error propagation and utilizing program slicing to construct a semantic context that filters out fault-irrelevant statements. Additionally, it employs over-sampling techniques to balance the coverage information of passing and failing tests. Finally, the balanced coverage matrix is fed into DFL to compute the suspiciousness value of each statement. To evaluate the effectiveness of Canal, we conduct large-scale experiments on 10 programs and compare our method with 10 dynamic fault localizations. The experimental results clearly demonstrate that Canal surpasses the performance of all the compared DFL methods, e.g., Canal achieves an average improvement of 148.2% in Top-1 accuracy compared to the evaluation formulas.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4408833264",
    "type": "article"
  },
  {
    "title": "CRM_BF:A Low-Overhead, High-Efficient and Reconfigurable Operation Unit Design Approach Using the Customized Reed-Muller Unit For Boolean Functions of Sequence Cipher Algorithms",
    "doi": "https://doi.org/10.1145/3725869",
    "publication_date": "2025-03-26",
    "publication_year": 2025,
    "authors": "Zhaoxu Zhou; Zhan-hua HUANG; Junwei Li; Yanjiang Liu; Zibin Dai",
    "corresponding_authors": "",
    "abstract": "Sequence ciphers algorithms encrypt or decrypt information at a low cost and high speed compared to other cryptographic algorithms, which are widely applied to critical applications and sensitive fields. As the core component of sequence ciphers, Boolean functions generate the random number or implement the update process of random numbers. The existing implementations of Boolean functions cause a great waste of area resources and generate several long critical paths that limit the hardware performance of sequence ciphers. To address this issue, a 64-bit Boolean Function Reconfigurable Operation Unit (BFROU) is proposed to reduce the area overhead, lower the delay latency, and enhance the operation efficacy of Boolean functions. Through statistical characterization analysis and cutting experiments of Boolean functions, a 64 bits BFROU based on CRM-3 units has been designed, which has the advantage of low-cost and high-efficient。The CRM unit is customized based on RM logic. A theoretical framework for Boolean functions is proposed by combining CRM units with mathematical expressions, which encompasses Boolean functions for any variable. On the platform of synthesis software, based the theoretical architecture, a CRM-OPT optimization algorithm is proposed, which can achieve the conversion of And Inverter Graph (AIG) to Customized Reed Muller Graph (CRMG).This Customized Reed-Muller (CRM) unit achieved at least 22.4% and 25.1% optimization in delay and area compared to Universal Reed-Muller (URM) units. The experimental results show that the Area Delay Product (ADP) is minimized when the CRM-3 unit is the optimal maximum cutting size. Ultimately, the BFROU design was realized utilizing CRM units, achieving an area of 195.4um² and a critical path delay of 0.35ns. This BFROU can achieve special Boolean functions involving 64 variables at maximum,with 91% of these functions being mapped within two iterations. Moreover, this BFROU has significant advantages over other known schemes regarding area, critical path delay, ADP, and number of iterations consumed.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4408845112",
    "type": "article"
  },
  {
    "title": "DeepPM: Predicting Performance and Energy Consumption of Program Binaries Using Transformers",
    "doi": "https://doi.org/10.1145/3725887",
    "publication_date": "2025-03-28",
    "publication_year": 2025,
    "authors": "Jun S. Shim; Hyung Jun Chang; Yeseong Kim; Jihong Kim",
    "corresponding_authors": "",
    "abstract": "Accurate estimation of performance and energy consumption is critical for optimizing application efficiency on diverse hardware platforms. Traditional methods often rely on profiling and measurements, requiring at least one execution, making them time-consuming and resource-intensive. This paper introduces the Deep Power Meter (DeepPM) framework, leveraging deep learning, specifically the Transformer architecture, to predict performance and energy consumption of basic blocks directly from compiled binaries, eliminating the need for explicit measurement processes. The DeepPM model effectively learns the performance and energy consumption of basic blocks, enabling accurate predictions for each. Furthermore, the framework enhances applicability across different ISAs and microarchitectures, addressing limitations of state-of-the-art ML-based techniques restricted to specific processor architectures. Experimental results using the SPEC CPU 2017 benchmark suite show that DeepPM achieves significantly lower prediction errors compared to state-of-the-art ML-based techniques, with a 24% improvement in performance and an 18% improvement in energy consumption for x86 basic blocks, and similar gains for ARM processors. Fine-tuning with minimal data from the Phoronix Test Suite further validates DeepPM’s robustness, achieving an error of approximately 13.7%, close to the fully trained model’s 13.3% error. These findings demonstrate DeepPM’s ability to enhance the accuracy and efficiency of performance and energy consumption predictions, making it a valuable tool for optimizing computing systems across diverse hardware environments.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4408944465",
    "type": "article"
  },
  {
    "title": "A data-centric chip design agent framework for Verilog code generation",
    "doi": "https://doi.org/10.1145/3727980",
    "publication_date": "2025-04-03",
    "publication_year": 2025,
    "authors": "Kaiyan Chang; Wenlong Zhu; Kun Wang; Xinyang He; Nan Yang; Zhirong Chen; Dantong Jin; Cangyuan Li; Yunhao Zhou; Hao Yan; Zhuoliang Zhao; Yuan Yuan Cheng; Mengdi Wang; Shengwen Liang; Yinhe Han; Xiaowei Li; Huawei Li; Ying Wang",
    "corresponding_authors": "",
    "abstract": "Recent advances in large language models (LLMs) have demonstrated significant potential for automated hardware description language (HDL) code generation from high-level specifications. However, two critical challenges limit further progress in this domain: the scarcity of quality Verilog training data and the inability of current approaches to generate RTL code optimized for power, performance, and area (PPA) metrics. This paper presents a comprehensive data-centric framework that addresses these limitations through innovations in both pre-fine-tuning data preparation and after-fine-tuning optimization strategies. In the pre-fine-tuning phase, we tackle the data scarcity problem with an automated design-data augmentation framework that generates high-volume, high-quality natural language specifications aligned with corresponding Verilog code and EDA scripts. Our approach creates a complete RTL-level feedback loop by augmenting EDA scripts, RTL code, and EDA tool feedback. In the after-fine-tuning phase, we focus on generating PPA-aware RTL code through a novel search and prompt framework. Our approach implements iterative filtering and selection of LLM-generated Verilog variants while providing high-quality predefined prompts, including composition and interface specifications. To evaluate the effectiveness of our data augmentation method, we fine-tune Llama 2-13B and Llama 2-7B models using the dataset generated by our augmentation framework. The results demonstrate a significant improvement in the Verilog generation tasks with LLMs. Moreover, the accuracy of Verilog generation surpasses that of the current state-of-the-art open-source Verilog generation model, increasing from 58.8% to 70.6% with the same benchmark. Our 13B model has a pass rate improvement compared with GPT-3.5 in Verilog generation and outperforms in EDA script ( i.e., SiliconCompiler) generation with only 200 EDA script data. Additionally, to evaluate the effectiveness of the our agent framework, we compare the PPA on the GPT-3.5, where the results show that the agent refined RTL code can have a better quality than the generated RTL code only with GPT-3.5.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4409118443",
    "type": "article"
  },
  {
    "title": "Optimizing FPGA Routing with Explainable Co-Learning of Congestion and Wirelength",
    "doi": "https://doi.org/10.1145/3728467",
    "publication_date": "2025-04-07",
    "publication_year": 2025,
    "authors": "Wenhao Liu; Yan Xing; Shuting Cai; Weijun Li; Xiaoming Xiong",
    "corresponding_authors": "",
    "abstract": "In FPGA routing, machine learning-based optimization methods have achieved improved routing solutions by integrating traditional heuristics with predictive capabilities. However, these approaches mostly relied on single-task learning models with black-box nature and often neglected the complex trade-offs and inter-dependencies between routing metrics. To address these limitations, this paper introduces a novel multi-task learning-based routing optimization method. In the congestion-wirelength co-learning stage, the simultaneous prediction of congestion and wirelength is formulated as a multi-task learning problem. A multi-task learning model, named CWNet, is proposed to tackle this challenge effectively. During the congestion-wirelength impact interpretation, the contribution of congestion to wirelength is quantified using an XAI technique known as DeepSHAP, producing a congestion-wirelength impact map. In the congestion-wirelength co-guided routing optimization (CWRO) stage, the VTR router’s lookahead map is enhanced based on the impact map, guiding the router to avoid locations where congestion significantly affect wirelength. Experimental results demonstrate that CWNet outperforms most baseline learning models in terms of both prediction performance and computational efficiency. Additionally, the impact map visually illustrates the complex and nonlinear relationship between congestion and wirelength. Ultimately, CWRO significantly reduces congestion, wirelength, and critical path delay, while maintaining a competitive runtime compared to baseline routers.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4409211728",
    "type": "article"
  },
  {
    "title": "Design Space Exploration for Scalable DNN Accelerators Using a Memory-Centric Analytical Model for HW/SW Co-Design",
    "doi": "https://doi.org/10.1145/3729227",
    "publication_date": "2025-04-18",
    "publication_year": 2025,
    "authors": "Wei-Chun Huang; Cheng-Hao Tang; Kuei‐Chung Chang; Tien-Fu Chen; Harry Hsieh; Ming‐Hsuan Tsai",
    "corresponding_authors": "",
    "abstract": "As Deep Neural Network (DNN) models became more complex, the escalating computational demands on hardware made DNN accelerators a critical research topic. The rapid growth of DNN models required DNN accelerators to keep pace with these computational demands. However, the cost of hardware design was significant, and hardware and software were tightly coupled in the design of DNN accelerators. Much research on HW/SW co-design was evident, highlighting the importance of having a comprehensive framework to help find the optimal hardware and software design during the design phase. The cost models used in most of the current research relied on data reuse and mathematical estimation to calculate costs, an approach that was fast but inaccurate. In this article, we propose a framework for HW/SW co-design and introduce a hybrid cost model based on Gem5 that provides fast and precise performance evaluation. The framework uses a memory-centric approach to accurately model off-chip memory behavior. In addition, we discuss how to find the best design in a large co-design space and integrate a design point through a traffic generator and a cost model. Finally, we demonstrate that our framework can accurately assist DNN accelerator developers in exploring the optimal hardware and software co-design quickly and efficiently.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4409585327",
    "type": "article"
  },
  {
    "title": "HSG-RAG: Hierarchical Knowledge Base Construction for Embedded System Development",
    "doi": "https://doi.org/10.1145/3731680",
    "publication_date": "2025-04-21",
    "publication_year": 2025,
    "authors": "Zhouyang Lu; Hailin Xu; A. Q. Chen; Siyuan Tang; Junyi Zhang; Yanping Feng; Wentao Pan; Jiangli Huang",
    "corresponding_authors": "",
    "abstract": "Customization is a fundamental aspect of embedded system development, requiring developers to acquire extensive domain-specific knowledge from technical documents. However, the sheer volume of these documents, coupled with the intricate relationships between their contents, makes it challenging to efficiently retrieve the necessary information. This challenge highlights the need for a structured approach to organize domain knowledge, with explicit representation of interrelationships. Moreover, while advanced large language models (LLMs) show promise in aiding embedded system development, they often lack the specialized knowledge needed to address domain-specific queries effectively. In this paper, we present HSG-RAG, a knowledge base construction and retrieval method tailored for embedded system development that leverages knowledge graphs to represent the hierarchical structure within technical documentation. Unlike prior retrieval-augmented generation (RAG) or GraphRAG-based approaches, which build the index either rely on semantic similarity or keyword co-occurrence, HSG-RAG captures the inherited dependency and hierarchical relationships in the documents, which benefits the retrieval in both performance and efficiency. We also introduce a benchmark for evaluating the effectiveness of RAG systems in solving real-world challenges in embedded systems, particularly for multi-hop question answering. Experimental results show that HSG-RAG outperforms both RAG and GraphRAG, generating more specific and concise responses.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4409623897",
    "type": "article"
  },
  {
    "title": "FixRTL: Auto-correction of Multiple RTL Bugs by a New Feature Burst Clustering Algorithm and Mutation",
    "doi": "https://doi.org/10.1145/3733238",
    "publication_date": "2025-04-30",
    "publication_year": 2025,
    "authors": "Mahsa Heidari; Bijan Alizadeh",
    "corresponding_authors": "",
    "abstract": "Existing debugging and correction approaches suffer from weaknesses such as scalability, reproducing new bugs, and lacking a strategy to deal with multiple bugs. Hence, this paper proposes FixRTL, a fully automated scalable methodology for localizing and correcting multiple bugs in Register-Transfer level (RTL) designs. FixRTL consists of three phases: 1) Constructing Samples , 2) Debugging , and 3) Correction . First, we simulate the design under verification (DUV), extract coverage data, and construct our samples. Since we are looking for buggy hit-statements, we use the proposed feature burst (FB) clustering algorithm in the Debugging Phase . The algorithm applies samples as train data, categorizes the encoded hit-statements into bursts, and uses them as test data to predict their cluster. Then we rank hit-statements based on their probability of containing bugs per cluster. In the Correction Phase , we apply a proposed mutation-based framework to correct high-ranked hit-statements. The results show that FixRTL reduces the percentage of hit-statements that must be examined to localize bugs on average by 44.3%. The results also demonstrate that FixRTL corrects 67% of injected bugs while recent existing works correct up to 25%. Moreover, unlike recent works, FixRTL offers corrections that match the grand truth.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4409963669",
    "type": "article"
  },
  {
    "title": "Sorting it out in Hardware: A State-of-the-Art Survey",
    "doi": "https://doi.org/10.1145/3734797",
    "publication_date": "2025-05-05",
    "publication_year": 2025,
    "authors": "Amir Hossein Jalilvand; Faeze S. Banitaba; Seyedeh Newsha Estiri; Sercan Aygün; M. Hassan Najafi",
    "corresponding_authors": "",
    "abstract": "Sorting is a fundamental operation in various applications and a traditional research topic in computer science. Improving the performance of sorting operations can have a significant impact on many application domains. Much attention has been paid to hardware-based solutions for high-performance sorting. These are often realized with application-specific integrated circuits (ASICs) or field-programmable gate arrays (FPGAs). Recently, in-memory sorting solutions have also been proposed to address the movement cost issue between memory and processing units, also known as the Von Neumann bottleneck. Due to the complexity of the sorting algorithms, achieving an efficient hardware implementation for sorting data is challenging. A large body of prior solutions is built on compare-and-swap (CAS) units. These are categorized as comparison-based sorting. Some recent solutions offer comparison-free sorting. In this survey, we review the latest works in the area of hardware-based sorting. We also discuss the recent hardware solutions for partial and stream sorting. Finally, we discuss some important concerns that need to be considered in the future designs of sorting systems.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4410095611",
    "type": "article"
  },
  {
    "title": "An Analytical Solution for Transient Electromigration Stress in Multisegment Straight-line Interconnects Based on a Stress-wave Model",
    "doi": "https://doi.org/10.1145/3734796",
    "publication_date": "2025-05-05",
    "publication_year": 2025,
    "authors": "Mohammad Abdullah Al Shohel; Vidya A. Chhabria; Nestor Evmorfopoulos; Sachin S. Sapatnekar",
    "corresponding_authors": "",
    "abstract": "This work presents an analytical approach for analyzing electromigration (EM) in modern technologies that use copper dual damascene (Cu DD) interconnects. In these technologies, due to design rule and methodology constraints, wires are typically laid out unidirectionally in each metal layer; since EM in Cu DD interconnects do not cross layer boundaries, the problem reduces to one of analyzing EM in multisegment interconnect lines. In contrast with traditional empirical methodologies, our approach is based on physics-based modeling, directly solving the differential equations that model EM-induced stress. This paper places a focus on interconnect lines, for reasons described above, and introduces the new concept of boundary reflections of stress flux that ascribes a physical (wave-like) analogy to the transient stress behavior in a finite multisegment line. This framework is used to derive analytical expressions of transient EM stress for lines with any number of segments, which can also be tailored to include the appropriate number of terms for any desired level of accuracy. The approach is applied to both the nucleation phase and the postvoiding phase on large power grid benchmarks. These experiments demonstrate excellent accuracy as compared to accurate numerical solution, as well as linear complexity with the number of segments for evaluating stress at a specified point and time.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4410125335",
    "type": "article"
  },
  {
    "title": "Early Stage DRC Hotspot Prediction for Mixed-Size Designs Through an Efficient Graph-Based Deep Learning",
    "doi": "https://doi.org/10.1145/3733236",
    "publication_date": "2025-05-05",
    "publication_year": 2025,
    "authors": "J.J. Lin; Shiyan Liang; Lin Wen-xiong; Peng Gao; Yan Xing; Tingting Wu; Xiaoming Xiong; Shuting Cai",
    "corresponding_authors": "",
    "abstract": "Predicting hotspot locations in the early stage of Design Rule Check (DRC) is crucial for designers to proactively prevent design rule violations. However, obtaining an accurate and efficient predictor faces significant challenges due to the influence of available information and severe data imbalance. In this study, we investigate the potential of utilizing Graph Neural networks (GNN) to address this challenge. Our focus is specifically on accurately predicting DRC hotspot locations without relying on global routing techniques. We consider the presence of macros in mixed-size designs. We propose an adaptive adjacency matrix that demonstrates superior application effectiveness compared to traditional adjacency matrices. Furthermore, experimental results on benchmark circuits show significant improvements in the true positive rate (22.38% for the RouteNet model and 26.90% for the GNN model) and accuracy (6.97% and 6.76%, respectively) compared to these models. Our proposed model also maintains a low false positive rate and outperforms other Convolutional Neural Network and GNN models. Additionally, its efficient learning capability and lower computational time contribute to its outstanding training performance, with training time being approximately 10% of that required by other models.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4410125827",
    "type": "article"
  },
  {
    "title": "LLM-assisted Bug Identification and Correction for Verilog HDL",
    "doi": "https://doi.org/10.1145/3733237",
    "publication_date": "2025-05-07",
    "publication_year": 2025,
    "authors": "Khushboo Qayyum; Chandan Kumar Jha; Sallar Ahmadi-Pour; Muhammad Hassan; Rolf Drechsler",
    "corresponding_authors": "",
    "abstract": "As technology continues to advance, it becomes increasingly integrated into daily life facilitating complex tasks across a range of environments. While some applications such as smartphones and smartwatches are less critical, others like healthcare devices and autonomous vehicles demand bug-free performance to prevent financial loss or harm. Traditionally, simulation-based testing and formal verification played a major role in ensuring a bug-free device. However, the simulation of bigger systems is limited to a definite number of scenarios on the Design under Verification (DUV). Hence, it is unable to explore all possible inputs that can occur. Formal verification, on the other hand, offers a higher level of assurance through mathematical proofs but is both time-consuming and suffers from scalability issues, especially as designs grow in complexity. Recently, Large Language Models (LLMs) have shown promise in tasks previously limited to human expertise. Their natural language processing capabilities can assist in handling extensive specifications and source code, particularly in debugging hardware descriptions and analyzing security and functionality. The utilization of Retrieval Augmented Generation (RAG) has further enhanced LLMs by incorporating large specification or source code bases, thereby improving their bug-identification and correction capabilities. While recent advancements in LLMs, particularly with RAG, have yielded promising results in bug identification and correction for a small class of hardware bugs, significant gaps remain in their full potential for systematically addressing a wide range of hardware bugs. For instance, existing LLM methodologies struggle to detect bugs involving incorrect constant values, i.e., the use of wrong constants in source code. This limitation underscores the need for further exploration in utilizing LLMs to fully optimize the verification process. To bridge this gap, we propose a 3-phased 4-stage LLM-assisted systematic bug closure methodology that focuses on functional bugs in Verilog HDL rather than structural or syntactic issues. Our approach extracts functional properties of the DUV and systematically breaks down complex expressions into smaller sub-expressions to facilitate bug detection and correction. By employing RAG, the LLM is guided using the functional specifications and source code to identify and correct bugs. If the initial guidance through RAG is insufficient, our methodology initiates an iterative bug closure process. This includes incorporating more extensive information from the specifications, fetching additional lines of code for bug localization, and breaking down complex Verilog HDL expressions. In our comprehensive evaluation, we assess the LLM’s capabilities using 9 different categories of bugs. As benchmarks, we use 5 OpenTitan Intellectual Property (IP) cores to demonstrate the scalability and effectiveness of our bug closure methodology where \\(\\approx 60\\% \\) of the bugs were corrected. Specifically, we evaluate OpenAI’s GPT-4 in its ability to identify and correct functional bugs in Verilog HDL code.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4410166048",
    "type": "article"
  },
  {
    "title": "LHS: LLM Assisted Efficient High-level Synthesis of Deep Learning Tasks",
    "doi": "https://doi.org/10.1145/3734523",
    "publication_date": "2025-05-08",
    "publication_year": 2025,
    "authors": "Eswar Reddy; Saugata Bhattacharyya; Ankur Jyoti Sarmah; Fedrick Nongpoh; Karthik Maddala; Chandan Karfa",
    "corresponding_authors": "",
    "abstract": "Deep learning tasks, especially those involving complex convolution neural networks (CNNs), are computationally intensive and pose significant challenges when implemented on hardware. Accelerating these tasks is critical for improving performance. High-level Synthesis (HLS) has the potential to automate the efficient hardware accelerator designs directly from high-level C/C++ specification of trained machine learning (ML) models. Traditional HLS tools cannot synthesize certain high-level constructs, which require manual intervention. Many source code optimizations and the selection of pragmas for HLS optimizations are crucial for generating efficient hardware accelerators with HLS. However, both of these tasks are mostly manual efforts. Recently, Large Language Models (LLMs) have shown remarkable capabilities in various generative tasks. In this work, we explore the application of LLMs to remove these manual efforts in adapting HLS for ML accelerator designs. Our framework called LLM-assisted HLS, i.e., LHS, uses LLMs to automate the resolution of synthesis issues, ensuring compatibility with HLS tools. Furthermore, our framework automates the source code modification and optimization selection through pragma insertion steps, which are crucial for optimizing the synthesized design. Our experimental results with LHS demonstrate a significant improvement in latency for deep learning tasks with underlying complex CNN models without much area overhead. Our LHS allows us to achieve up to 2690 × latency improvement. Promisingly, LHS performs better than the state-of-the-art ML accelerator design tool hls4ml in 4 out of 6 cases in the context of latency improvement at the expense of area overhead (i.e., performance to hardware gain). This work highlights the potential of LLMs to assist and accelerate the HLS process, thereby creating more efficient hardware implementation for deep learning models.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4410211293",
    "type": "article"
  },
  {
    "title": "GenPart 2.0: Enhanced Hypergraph Partitioning with Vertex Weight Handling using a Generative Model",
    "doi": "https://doi.org/10.1145/3735133",
    "publication_date": "2025-05-08",
    "publication_year": 2025,
    "authors": "Magi Chen; Ting-Chi Wang",
    "corresponding_authors": "",
    "abstract": "This paper introduces GenPart 2.0, an enhanced version of the hypergraph partitioner GenPart. While GenPart was limited to handling only unit vertex weights, GenPart 2.0 extends capabilities to include varying vertex weights. This extension is achieved through a variational graph neural network-based generative model and new feature preparation techniques. GenPart 2.0 addresses hypergraph partitioning challenges by establishing an embedding space that adheres to normalized cut and balance constraints. The generative model in GenPart 2.0 is designed to explore various partitioning configurations within this embedding space. Further, it enhances partitioning solutions using the V-cycle method. Testing on VLSI circuit benchmarks, including ISPD98, ISPD2005, and Titan23, under various balance constraints, has demonstrated improved performance by GenPart 2.0.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4410211402",
    "type": "article"
  },
  {
    "title": "DTGx2: Dual Target Diagnostic Test Generation",
    "doi": "https://doi.org/10.1145/3735131",
    "publication_date": "2025-05-08",
    "publication_year": 2025,
    "authors": "Irith Pomeranz",
    "corresponding_authors": "Irith Pomeranz",
    "abstract": "Logic diagnosis is important for deriving information about defects that are present in fabricated units when they are found to be faulty. This information can assist in yield learning and improvement. When needed, the accuracy of logic diagnosis can be improved by using diagnostic tests to complement fault detection tests. Diagnostic test generation for logic faults is the process that produces diagnostic tests. Diagnostic test generation procedures target fault pairs that are not distinguished by a fault detection test set. However, an improvement in diagnostic accuracy is not guaranteed as diagnostic tests are added to the test set, and some tests may cause the diagnostic accuracy to decrease. This article is the first to suggest a second target for diagnostic test generation based on the results of logic diagnosis for simulated faulty units. The second target attempts to predict when a diagnostic test will have a negative effect on the diagnostic accuracy, and helps exclude such a test from the test set. An attempt to generate an alternate test for the same fault pair is made in a later iteration of diagnostic test generation. The dual target diagnostic test generation procedure suggested in this article was implemented in an academic simulation environment and applied to benchmark circuits. Experimental results demonstrate the ability of the procedure to identify diagnostic tests that should be avoided. The tests typically have alternates that can be found in later iterations.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4410211458",
    "type": "article"
  },
  {
    "title": "AiTPO: KAN-UNet Heterogeneous Network for Timing Prediction and Optimization at Global Routing",
    "doi": "https://doi.org/10.1145/3735639",
    "publication_date": "2025-05-13",
    "publication_year": 2025,
    "authors": "Liu He; Zhisheng Zeng; Simin Tao; Zhipeng Huang; Yifan Li; Biwei Xie; Wei Gao; Xingquan Li",
    "corresponding_authors": "",
    "abstract": "Routing is a critical stage in achieving timing closure in integrated circuit design. Due to the time-consuming flow of detailed routing (DR), the lack of accurate routing information, and the impact of congestion during global routing (GR), rapidly obtaining precise timing information at the global routing stage to guide subsequent timing optimization is a significant challenge. These challenges lead to substantial discrepancies between the estimated timing at GR stage and the actual results after post-DR, resulting in inaccurate evaluations of chip performance. To address this issue, we propose an effective timing prediction and optimization framework, AiTPO. The innovative KAN-UNet heterogeneous timing prediction model effectively combines UNet and KAN networks. By fusing spatial features extracted by UNet with numerical data, the model gains the capability to learn complex relationships across multi-modal data, thereby enhancing robustness and accuracy. Additionally, with the accurate timing evaluation, we introduce two timing optimization strategies during global routing to enhance timing performance. The first strategy involves net ordering based on predicted significant delay nets, prioritizing the routing of more timing-critical nets to reduce detours caused by congestion. The second strategy employs timing estimation to select the most optimal topology from multiple candidates generated by the enhanced A* algorithm, where congestion is considered as a cost factor. Which contributes to optimizing Worst Negative Slack (WNS) and Total Negative Slack (TNS). Experimental results on the real circuits under 28nm process node show that the wire delay prediction accuracy with the proposed KAN-UNet model improves by 34.6% and 25.4% in terms of Mean Absolute Error (MAE) and Max Absolute Error (MaxAE), respectively, compared to GR-based estimations and demonstrate the effectiveness of our timing optimization strategies, which lead to a 2.0% and 4.2% improvement in TNS and WNS, respectively.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4410321359",
    "type": "article"
  },
  {
    "title": "ChatDSE: A Zero-Shot Microarchitecture Design Space Explorer Powered by GPT4.0",
    "doi": "https://doi.org/10.1145/3735640",
    "publication_date": "2025-05-16",
    "publication_year": 2025,
    "authors": "Mingxin Tang; Wei Chen; Lizhou Wu; Libo Huang; Kun Zeng",
    "corresponding_authors": "",
    "abstract": "Design Space Exploration (DSE) aims at identifying Pareto optimal synthesis configurations. Previous works require microarchitecture samples with key labels, including power and clock cycles, to train their models. However, as the chip design space expands rapidly, the cost of sampling the design space has significantly increased, due to the growing number of samples and time-consuming Very Large Scale Integration (VLSI) implementation flow. Recent advancements in Large Language Models (LLMs) have demonstrated their remarkable power in zero-shot learning tasks, presenting an innovative strategy for accomplishing DSE. Hence, this article presents ChatDSE, a zero-shot framework for DSE that is powered by the advanced capabilities of the LLM GPT4.0. Firstly, this framework analyzes the nature of the target microarchitecture and generates a corresponding system context to provide the prior knowledge of the microarchitecture. Secondly, a proposed sampling algorithm, PriorDC, identifies the most representative samples with pseudo labels. One of these samples is chosen as a baseline, whose power and clock cycles labels are set as 1, and the remaining sample labels are obtained by chatting with GPT4.0. Finally, ChatDSE engages in a dialogue with GPT4.0 to estimate the power and clock cycles of designs within the space, ultimately identifying the Pareto optimal design set. In the DSE for the RISC-V Berkeley Out-of-Order Machine (BOOM), experimental results show that ChatDSE is capable of identifying optimal designs and accelerates the exploration process by 574 times when compared to the state-of-the-art DSE methodologies.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4410443377",
    "type": "article"
  },
  {
    "title": "Large Language Models for EDA: Future or Mirage?",
    "doi": "https://doi.org/10.1145/3736167",
    "publication_date": "2025-05-16",
    "publication_year": 2025,
    "authors": "Zhuolun He; Yuan Pu; Haoyuan Wu; Tairu Qiu; Bei Yu",
    "corresponding_authors": "",
    "abstract": "In this paper, we explore the burgeoning intersection of large language models (LLMs) and electronic design automation (EDA). We critically assess whether LLMs represent a transformative future for EDA or merely a fleeting mirage. By organizing existing research into four critical domains of EDA — code generation, verification and debugging, knowledge representation and retreival, and optimization/modeling — we provide a comprehensive overview of the current state-of-the-art. The survey concludes with a 5-level roadmap to guide the progressive integration and advancement of LLMs in EDA. Ultimately, this paper aims to provide a comprehensive, evidence-based perspective on the role of LLMs in shaping the future of EDA.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4410443382",
    "type": "article"
  },
  {
    "title": "ModelGen: Automating Semiconductor Parameter Extraction with Large Language Model Agents",
    "doi": "https://doi.org/10.1145/3736165",
    "publication_date": "2025-05-20",
    "publication_year": 2025,
    "authors": "Yangbo Wei; Li Huang; Qi Feng; Zhanfei Chen; Jinlong Yan; Ting-Jung Lin; Zhen Huang; Kun Ren; Wei Xing; Lei He",
    "corresponding_authors": "",
    "abstract": "Device models require large numbers of parameters to characterize complex physical effects. Although the latest advancements in machine learning and automated tools have drastically improved efficiency over the classic methods, they still demand a considerable amount of human intervention in the loop to gain accuracy. This drastically limits further automation. Inspired by the success of Multimodal Large Language Models (MLLMs) in addressing tasks across diverse fields, we propose ModelGen, the first in-depth study to leverage MLLMs with RAG (Retrieval-Augmented Generation) to significantly reduce human effort in parameter extraction for compact model. Our contributions include (1) Automated Agentic Workflow Construction that learns to build and refine extraction workflows through iterative optimization, (2) MLLM Judge, a visual scoring mechanism that evaluates fitting quality using actual device characteristic plots rather than simple numerical metrics, and (3) Model-specific RAG for providing relevant domain knowledge during the extraction process. Experimental results demonstrate that ModelGen achieves a 26.8%-33.1% improvement in pass@1,3,5 compared to base LLM methods. The system completes complex model extractions for BSIMs and ASM-HEMT in hours (up to 168× faster) rather than days or weeks, making parameter extraction more accessible to non-experts while maintaining professional engineer-level accuracy.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4410519242",
    "type": "article"
  },
  {
    "title": "AutoSilicon: Scaling Up RTL Design Generation Capability of Large Language Models",
    "doi": "https://doi.org/10.1145/3737286",
    "publication_date": "2025-05-23",
    "publication_year": 2025,
    "authors": "Cangyuan Li; Chujie Chen; Yudong Pan; Wenjun Xu; Yahui Liu; Kaiyan Chang; Yujie Wang; Mengdi Wang; Ying Wang; Huawei Li; Yinhe Han",
    "corresponding_authors": "",
    "abstract": "Hardware description language (HDL) code designing is a critical component of the chip design process, requiring substantial engineering and time resources. Recent advancements in large language models (LLMs), such as GPT series, have shown promise in automating HDL code generation. However, current LLM-based approaches face significant challenges in meeting real-world hardware design requirements, particularly in handling complex designs and ensuring code correctness. Our evaluations reveal that the functional correctness rate of LLM-generated HDL code significantly decreases as design complexity increases. In this paper, we propose the AutoSilicon framework, which aims to scale up the hardware design capability of LLMs. AutoSilicon incorporates an agent system, which 1) allows for the decomposition of large-scale, complex code design tasks into smaller, simpler tasks; 2) provides a compilation and simulation environment that enables LLMs to compile and test each piece of code it generates; and 3) introduces a series of optimization strategies. Experimental results demonstrate that AutoSilicon can scale hardware designs to projects with code equivalent to over 10,000 tokens. In terms of design quality, it further improves the syntax correctness rate and functional correctness rate compared with approaches that do not employ any extensions. For example, compared to directly generating HDL code using GPT-4-turbo, AutoSilicon enhances the syntax correctness rate by an average of 35.8% and improves functional correctness by an average of 35.6%.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4410683300",
    "type": "article"
  },
  {
    "title": "Clustered-based Multi-pin Substrate Routing Optimization for Fine-Pitch Ball Grid Array",
    "doi": "https://doi.org/10.1145/3737285",
    "publication_date": "2025-05-23",
    "publication_year": 2025,
    "authors": "Ming-Yen Chuang; Yu-En Lin; Yi-Yu Liu",
    "corresponding_authors": "",
    "abstract": "As an important intermediate between integrated circuits (ICs) and the printed circuit board (PCB), the routing in the package substrate plays a crucial role in the efficiency and accuracy of signal and power transmission. While numerous research efforts have focused on substrate routing to avoid inefficient, time-consuming, and error-prone manual processes, few of them have addressed the challenge of routing multi-pin nets, particularly those with a large number of pins. This paper presents a three-stage framework of multi-pin net routing for packages with fine-pitch ball grid arrays, consisting of pin grouping, minimum spanning tree topology generation, and group topology connection. Our framework classifies net connections into different categories, prioritizes their routing ordering, and applies different routing approaches and strategies to boost overall routability. The results of the experiments conducted on six real industrial designs demonstrate that our framework can simultaneously and effectively handle two-pin nets and multi-pin nets with better routing performance compared to the state-of-the-art work.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4410685297",
    "type": "article"
  },
  {
    "title": "Machine Learning-Assisted VCD Processing for Accelerated Dynamic Voltage Drop Analysis",
    "doi": "https://doi.org/10.1145/3736579",
    "publication_date": "2025-05-27",
    "publication_year": 2025,
    "authors": "Jingchao Hu; Yufei Chen; Songyu Sun; Jianfei Song; Li Zhang; Xunzhao Yin; Zhou Jin; Cheng Zhuo",
    "corresponding_authors": "",
    "abstract": "With escalating power integrity challenges in advanced technologies, acquiring accurate dynamic power supply noise through Dynamic Voltage Drop (DVD) analysis becomes increasingly demanding. As noise margins shrink, the use of Value Change Dump (VCD) files for precise DVD analysis is indispensable but computationally expensive. Furthermore, the substantial storage requirements of VCD files, which record digital waveforms from logical simulations, pose significant challenges. In this paper, we propose a machine learning (ML)-assisted VCD processing framework to accelerate DVD analysis and improve data efficiency. Transitions recorded in VCD files are mapped to a Physical Design-Aware Circuit Hierarchy Tree (CHT) for efficient feature extraction. These features are leveraged by an XGBoost-based predictor to identify critical vector time windows within the VCD, significantly reducing simulation complexity. Additionally, Huffman encoding is applied to compress signal names, further optimizing storage utilization. Experimental results show that DVD analysis using our profiled VCD files achieves a speedup of approximately 3.53 × with an error margin of only 3.89%.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4410782091",
    "type": "article"
  },
  {
    "title": "Optimal Mixed-Cell-Height Detailed Placement with Discrete Spacing Costs",
    "doi": "https://doi.org/10.1145/3742429",
    "publication_date": "2025-05-30",
    "publication_year": 2025,
    "authors": "Dawei Huang; Ying-Jie Jiang; Shao‐Yun Fang",
    "corresponding_authors": "",
    "abstract": "Mixed-cell-height VLSI circuits are widely used to meet various design requirements. Due to design for manufacturability (DFM) considerations such as layout-dependent effects (LDEs), drain-to-drain abutment (DDA), and pattern coloring for multiple patterning, different spacings between adjacent cells affect performance, modeled as discrete spacing costs. A state-of-the-art dynamic programming (DP) approach can address this problem but can only handle a few cell rows simultaneously due to its high complexity. In this paper, we propose a novel DP algorithm that can solve the problem optimally and more efficiently. Additionally, several optimality-preserving reduction techniques are employed to derive full-chip optimal solutions for large-scale designs. Experimental results demonstrate that the proposed approach significantly outperforms existing methods in terms of total spacing cost and total displacement.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4410901945",
    "type": "article"
  },
  {
    "title": "HWREx: AI-enabled Hardware Weakness and Risk Exploration and Storytelling Framework with LLM-assisted Mitigation Suggestion",
    "doi": "https://doi.org/10.1145/3737459",
    "publication_date": "2025-05-31",
    "publication_year": 2025,
    "authors": "Sujan Ghimire; Yu-Zheng Lin; Muntasir Mamun; Muhtasim Alam Chowdhury; Farhad Alemi; Shuyu Cai; Jeng-Hung Guo; Mingyu Zhu; Haolong Li; Banafsheh Saber Latibari; Setareh Rafatirad; Pratik Satam; Soheil Salehi",
    "corresponding_authors": "",
    "abstract": "Abstract: The growing complexity of modern computing frameworks has led to an increase in cybersecurity vulnerabilities reported to the National Vulnerability Database (NVD). Extracting meaningful trends from this vast amount of unstructured data is challenging without proper tools and methodologies. Existing approaches lack a holistic strategy for vulnerability mitigation and prediction and effective knowledge extraction from the Common Weakness Enumeration (CWE), Common Vulnerability Exposure (CVE), and Common Attack Pattern Enumeration and Classification (CAPEC) databases. We introduce the AI-enabled Hardware Weakness and Risk Exploration and Storytelling Framework with LLM-assisted Mitigation Suggestion (HWREx), designed to address hardware vulnerabilities and IoT security. Our architecture features an Ontology-driven Storytelling capability that automates ontology updates to track vulnerability patterns and evolution over time, while offering mitigation strategies. It also clarifies the complex interrelations among CVEs, CWEs, and CAPECs through interactive visual knowledge graphs. Our framework achieved accuracy rates of 62% for CWE-CWE, 83% for CWE-CVE, and 77% for CWE-CAPEC linkage predictions. These graphs are instrumental for in-depth hardware weakness analysis and enable HWREx to deliver comprehensive assessments and actionable mitigation strategies. Additionally, HWREx utilizes Generative Pre-trained Transformers (GPT) to offer tailored mitigation suggestions.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4410919938",
    "type": "article"
  },
  {
    "title": "ARIANNA: An Automatic Design Flow for Fabric Customization and eFPGA Redaction",
    "doi": "https://doi.org/10.1145/3737287",
    "publication_date": "2025-06-02",
    "publication_year": 2025,
    "authors": "Luca Collini; Jitendra Bhandari; Chiara Muscari Tomajoli; Abdul Khader Thalakkattu Moosa; Benjamin Tan; Xifan Tang; Pierre‐Emmanuel Gaillardon; Ramesh Karri; Christian Pilato",
    "corresponding_authors": "",
    "abstract": "In the modern global Integrated Circuit (IC) supply chain, protecting intellectual property (IP) is a complex challenge, and balancing IP loss risk and added cost for theft countermeasures is hard to achieve. Using embedded configurable logic allows designers to completely hide the functionality of selected design portions from parties that do not have access to the configuration string (bitstream). However, the design space of redacted solutions is huge, with trade-offs between the portions selected for redaction and the configuration of the configurable embedded logic. We propose ARIANNA, a complete flow that aids the designer in all the stages, from selecting the logic to be hidden to tailoring the bespoke fabrics for the configurable logic used to hide it. We present a security evaluation of the considered fabrics and introduce two heuristics for the novel bespoke fabric flow. We evaluate the heuristics against an exhaustive approach. We also evaluate the complete flow using a selection of benchmarks. Results show that using ARIANNA to customize the redaction fabrics yields up to 3.3x lower overheads and 4x higher eFPGA fabric utilization than a one-fits-all fabric as proposed in prior works.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4410964457",
    "type": "article"
  },
  {
    "title": "Exploring Large Language Models for Hierarchical Hardware Circuit and Testbench Generation",
    "doi": "https://doi.org/10.1145/3742430",
    "publication_date": "2025-06-04",
    "publication_year": 2025,
    "authors": "Samuel Gomes Lopes; Shien Zhu; Gustavo Alonso",
    "corresponding_authors": "",
    "abstract": "Designing and verifying hardware circuits using a Hardware Description Language (HDL) is an essential but time-consuming part of hardware design. Generating the desired correct circuit and testbench code usually requires a significant engineering effort. Recently, Large Language Models (LLMs) have claimed to have strong code generation capabilities to reduce such engineering costs. Existing work has provided quantitative evaluations using LLMs for single-module, simple circuit generation. However, it is still unclear whether modern LLMs are useful in production workflows, e.g., generating correct hierarchical circuits with testbenches. And if they are capable, what are the best prompt engineering practices for hardware design? In this paper, we evaluate LLMs for HDL generation by exploring a 3-dimensional design space: commercial and open-source language models, single-module and hierarchical circuits, and prompting methods with varying complexity. We propose a 3-step design space exploration methodology to answer the two aforementioned questions. First, we explore the best prompt engineering practices across generating simple, middle, and hard single-module circuits with testbenches on CodeLLama-34B. We also define two fine-grained checklists to evaluate the circuit and testbench quality from a user’s perspective. Second, we benchmark 11 LLMs with prompt adaptation on 4 single-module circuits that CodeLLama-34B has trouble with to further find models that may be useful in a production workflow. Third, we apply the learned prompt practices on four top-level models to generate simple 2 to 4-module and more complex multi-module hierarchical circuits and testbenches. As a result, we find that some of the latest LLMs can generate correct simple hierarchical circuits and testbenches with given proper prompts, but still struggle with complex hierarchical circuits. We further provide useful guidelines from an end-user’s perspective on leveraging LLMs for hardware design.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4411032163",
    "type": "article"
  },
  {
    "title": "Lightweight Authenticated Integration and In-Field Secure Operation of System-in-Package",
    "doi": "https://doi.org/10.1145/3745780",
    "publication_date": "2025-06-25",
    "publication_year": 2025,
    "authors": "Christian Ewert; Andrija Nešković; Carsten Heinz; Felix Muuss; Alexander Treff; Marc Gourjon; Rainer Buchty; Thomas Eisenbarth; Andreas Koch; Mladen Bereković; Saleh Mulhem",
    "corresponding_authors": "",
    "abstract": "System in Package (SiP) relies on integrating different chiplets potentially involving many third-party devices and chiplet foundries. This type of advanced packaging technology opens up numerous threat scenarios, especially: (a) the inauthentic and untraceable integration of chiplets into a SiP, (b) the insecure integration of malicious chiplets, which leads to a severe impact on the SiP security in the field. The current solutions require many hardware cryptographic primitives, making them costly and power-hungry. Therefore, a new lightweight solution is needed to ensure secure chiplet integration and secure SiP operation. In this paper, we deal with these problems and introduce iTrustlet , as a combination of a physical unclonable function and an authenticated encryption scheme to ensure an authenticated and traceable chiplet integration. We propose a chiplet integration protocol based on iTrustlet and a classical root-of-trust (RoT) to ensure the integrated chiplets are unaltered and unreplaced. To guarantee SiP in-field security, iTrustlet with a hardware firewall (HWF) is proposed. Their interaction leads to two security features: (i) HWF provides a SiP protection mechanism, and (ii) iTrustlet secures the update of HWF rules. In particular, we provide a multilevel solution centralized around iTrustlet , focusing on lightweightness. The implementation results show that area and power overheads are 1.24% and 1.84% in the case of FPGA and 0.49% and 1.2% for ASIC implementation.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4411652473",
    "type": "article"
  },
  {
    "title": "Poor Man's Training on MCUs: A Memory-Efficient Quantized Back-Propagation-Free Approach",
    "doi": "https://doi.org/10.1145/3745772",
    "publication_date": "2025-07-01",
    "publication_year": 2025,
    "authors": "Yequan Zhao; Hai Li; Ian A. Young; Zheng Zhang",
    "corresponding_authors": "",
    "abstract": "Back propagation (BP) is the default solution for gradient computation in neural network training. However, implementing BP-based training on various edge devices such as FPGA, microcontrollers (MCUs), and analog computing platforms face multiple major challenges, such as the lack of hardware resources, long time-to-market, and dramatic errors in a low-precision setting. This paper presents a simple BP-free training scheme on an MCU, which makes edge training hardware design as easy as inference hardware design. We adopt a quantized zeroth-order method to estimate the gradients of quantized model parameters, which can overcome the error of a straight-through estimator in a low-precision BP scheme. We further employ a few dimension reduction methods (e.g., node perturbation, sparse training) to improve the convergence of zeroth-order training. Experiment results show that our BP-free training achieves comparable performance as BP-based training on adapting a pre-trained image classifier to various corrupted data on resource-constrained edge devices ( e.g., an MCU with 1024-KB SRAM for dense full-model training, or an MCU with 256-KB SRAM for sparse training). This method is most suitable for application scenarios where memory cost and time-to-market are the major concerns, but longer latency can be tolerated.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4411890856",
    "type": "article"
  },
  {
    "title": "Concurrent Prediction of Timing and wire Length Using A Multi-Task Graph Neural Network",
    "doi": "https://doi.org/10.1145/3747181",
    "publication_date": "2025-07-02",
    "publication_year": 2025,
    "authors": "Yan Xing; H. M. Hu; Weijun Li; Shuting Cai; Xiaoming Xiong",
    "corresponding_authors": "",
    "abstract": "Traditional supervised single-task learning models are used in timing-driven placement exploration to improve both effectiveness and efficiency by predicting wire length, wire delay, and cell delay separately. However, these metrics are interdependent, with the two delays being timing-based and wire length non-timing, which makes it difficult for single-task models to capture their complex relationships. Moreover, the limited existing multi-task learning methods can only predict either multiple timing or non-timing metrics. To address these limitations, this article introduces DLGNN, a novel multi-task graph learning model that simultaneously predicts these three metrics through an embedder-predictor architecture featuring two residual connections, a combination of both soft and hard parameter sharing, and a geometric loss strategy. Cross-design experimental results on the Nangate 45nm library demonstrate that DLGNN outperforms baseline models in terms of both predictive performance and time efficiency. Additionally, ablation studies emphasize the critical roles of the residual connections, the combination of soft and hard parameter sharing, and the geometric loss strategy in improving DLGNN’s predictive performance. The generalization experiment on the ASAP 7nm library further confirms DLGNN’s advantages for more advanced technology nodes.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4411927094",
    "type": "article"
  },
  {
    "title": "ZlibBoost: An Efficient and Flexible Open-Source Framework for Standard Cell Characterization",
    "doi": "https://doi.org/10.1145/3747182",
    "publication_date": "2025-07-02",
    "publication_year": 2025,
    "authors": "Zhengrui Chen; Chengjun Guo; Shizhang Wang; Guozhu Feng; Zixuan Song; Zhenhua Wu; Xunzhao Yin; Wei‐Bin Song; Li Zhang; Zheyu Yan; Cheng Zhuo",
    "corresponding_authors": "",
    "abstract": "As VLSI designs grow increasingly complex and transition to smaller process nodes, accurate and efficient library characterization has become essential for modern design workflows. Existing open-source tools are often constrained by limited functionality, efficiency, and accuracy, making them insufficient for today’s design challenges. This paper reviews the shortcomings of current open-source tools and introduces ZlibBoost, a novel open-source framework designed to provide both flexibility and high performance. Its modular, front-end and back-end separated architecture, along with user-friendly interfaces, enables seamless customization, integration of machine learning models, and expanded simulator compatibility. A variety of key features are introduced to significantly enhance both accuracy and efficiency of library characterization. Experimental results demonstrate ZlibBoost’s capability to meet the demands of both academic research and practical applications, establishing it as a robust solution for advancing semiconductor design.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4411927255",
    "type": "article"
  },
  {
    "title": "Rank-DSE: Neural Pareto Comparator of Microarchitecture Design Space Exploration",
    "doi": "https://doi.org/10.1145/3747294",
    "publication_date": "2025-07-03",
    "publication_year": 2025,
    "authors": "Peng Xu; Su Zheng; Mingzi Wang; Ziyang Yu; Shixin Chen; Tinghuan Chen; Keren Zhu; Tsung-Yi Ho; Bei Yu",
    "corresponding_authors": "",
    "abstract": "The complexity of microarchitecture design has surged due to the expanding design space and time-intensive verification processes. Existing regression-based machine learning methods struggle with inaccurate estimations because of limited training samples. To address these challenges, we propose Rank-DSE, a novel framework for microarchitecture design space exploration (DSE) that leverages a Neural Pareto Comparator (NPC) to directly model the comparative relationships between different architecture designs. Rank-DSE bypasses the inaccuracies of absolute PPA (performance, power, area) predictions by focusing on relative comparisons. The NPC computes the probability of one architecture dominating another and employs semi-supervised learning to reduce the reliance on labeled data. Additionally, a reinforcement-learning-based sampling scheme with an updating baseline Pareto set accelerates the exploration process. Experimental results on the ICCAD 2021 benchmark demonstrate that Rank-DSE achieves superior search quality and cost-efficiency compared to state-of-the-art methods. Specifically, Rank-DSE improves hypervolume by up to 7% while reducing exploration cost by 53.09% compared to cutting-edge approaches. These results highlight the advantages of Rank-DSE in terms of efficiency and effectiveness for microarchitecture DSE.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4411976826",
    "type": "article"
  },
  {
    "title": "iPO: Constant Liar Parameter Optimization for Placement with Representation and Transfer Learning",
    "doi": "https://doi.org/10.1145/3747292",
    "publication_date": "2025-07-04",
    "publication_year": 2025,
    "authors": "Xinhua Lai; Miao Liu; Xingquan Li; Yihang Qiu; Shi-Jian Chen; Xinhao Li; Jungang Xu",
    "corresponding_authors": "",
    "abstract": "Placement is a critical and time-consuming step in very-large-scale integration (VLSI) design flow. As placement methods continue to be researched, they introduce more parameters, making current methods for configuring parameters heavily reliant on human experience for each design. This paper proposes a novel cross-design parameter optimization method, iPO, to accelerate parameter tuning without human involvement in different placement engines (like iEDA-iPL and DREAMPlace). Specifically, we introduce a heuristic strategy called Constant Liar to accelerate parameter tuning, allowing us to optimize parameters concurrently on different machines. Our research indicates that optimizing parameters for every design is time-consuming. To address the inefficiency of parameter tuning, we propose a cross-design parameter transfer learning strategy. This strategy measures the cosine similarity between designs in collaboration with a graph embedding algorithm representing netlists and cells. Compared to DREAMPlace on ISPD2015 benchmarks, our method achieves average improvements of 9.8% in half-perimeter wirelength (HPWL) and 12.0% in route congestion. When compared to AutoDMP, iPO shows an average improvement of 11% in HPWL and 12.3% in congestion, along with a 3.49 × speed-up in the number of search iterations. Furthermore, we extended our experiments to the iEDA-28nm benchmarks, showing average improvements of 4.7%, 2.7% and 2.8% in HPWL, worst negative slack (WNS) and total negative slack (TNS), respectively, compared to iEDA-iPL. Finally, our ablation studies on parallelization demonstrate that using 10 parallel processes results in approximately an 18 × speed-up compared to using a single process.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4412035818",
    "type": "article"
  },
  {
    "title": "Resister: A Resilient Interposer Architecture for Chiplet to Mitigate Timing Side-Channel Attacks",
    "doi": "https://doi.org/10.1145/3748258",
    "publication_date": "2025-07-09",
    "publication_year": 2025,
    "authors": "Xinrui Wang; Lang Feng; Yujie Wang; Tianyao Xu; Yinhe Han; Zhongfeng Wang",
    "corresponding_authors": "",
    "abstract": "Chiplet technology has been a hot topic due to its potential for more efficient implementation of large-scale integrated circuits. In chiplet manufacturing, the general-purpose active interposer usually integrates chiplets from different vendors with a typical mesh network. This method of manufacturing is broadly recognized for its cost-efficiency. However, untrusted vendors make the chiplet system vulnerable to security threats such as timing side-channel attacks (TSA) based on network contention information. Even worse, the reliability of each chiplet is usually unknown beforehand to a general-purpose interposer’s manufacturer, so that TSAs can be on arbitrary chiplets at arbitrary time in the manufacturer’s view. To address this challenge, this work first quantitatively analyzes the attack patterns including reinforced styles, based on which, a resilient interposer architecture named Resister is proposed. A hardware defender is designed in every router to globally detect the malicious transaction patterns at runtime, and adaptively detour the transaction packets accordingly for security while maintaining the performance. According to the evaluation of GEM5 on SPEC 2017 and PARSEC benchmarks, Resister can effectively mitigate TSA with only a 1.7% performance overhead.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4412119462",
    "type": "article"
  },
  {
    "title": "PSCMark: Power Side Channel-Based Watermarking for SoC IPs Using Clock Gates",
    "doi": "https://doi.org/10.1145/3747293",
    "publication_date": "2025-07-10",
    "publication_year": 2025,
    "authors": "Upoma Das; M. Sazadur Rahman; Akshay Kulkarni; Mark Tehranipoor; Farimah Farahmandi",
    "corresponding_authors": "",
    "abstract": "Intellectual property (IP) core reuse serves as a key factor to the rapid development of modern system-on-chips (SoCs) by minimizing time-to-market and manufacturing cost. However, it is crucial to prevent security risks such as IP piracy and over-use while allowing IP reuse. IP watermarking is a viable solution to safeguard the copyright of IP cores through their unique identification. In this paper, we introduce PSCMark as an innovative technique for authenticating IPs through the power side-channel characteristic using clock gates. PSCMark seamlessly incorporates a power signature with minimal alterations to the IP core. This is accomplished by leveraging the existing clock gates to alter the dynamic power consumption within the IP (in an SoC) based on a specified challenge. This sharp variation in power attributes upon watermark activation facilitates IP authentication in SoC. Our experimental results show that PSCMark can be robustly/effectively verified, even with the interference emanating from the rest of the functional cores in complex SoCs. We evaluate our technique on several SoC benchmarks of varying size (i.e., MIPS, openMSP430, OR1200) and demonstrate its effectiveness in proving IP ownership with high detection resolution. We also provide silicon validation by implementing PSCMark across these benchmarks using the Artix-7 FPGA board. Furthermore, PSCMark ensures a subtle and obfuscated watermarking of IP cores, enhancing its resistance to detection, removal, or modification.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4412162310",
    "type": "article"
  },
  {
    "title": "MapTune: Versatile ASIC Technology Mapping via Reinforcement Learning Guided Library Tuning",
    "doi": "https://doi.org/10.1145/3748507",
    "publication_date": "2025-07-11",
    "publication_year": 2025,
    "authors": "M.T. Liu; Daniel D. Robinson; Yingjie Li; Johannes Kuehn; Rongjian Liang; Haoxing Ren; Cunxi Yu",
    "corresponding_authors": "",
    "abstract": "Technology mapping involves mapping logical circuits to a library of standard cells. Traditionally, a full technology library is used, leading to a large search space and potential runtime overhead. Motivated by randomly sampled technology mapping case studies, we propose MapTune to address this challenge by utilizing reinforcement learning to make design-specific cell selection choices. By learning from the environment and guided by the reward, MapTune refines the cell selection process, resulting in a reduced search space and potentially improved mapping quality. The effectiveness of MapTune is evaluated on a wide range of benchmarks, different technology libraries, and various technology mappers. The empirical results demonstrate that MapTune achieves higher mapping accuracy and reduces delay/area across various circuit designs, technology libraries, and mappers. The paper also discusses the Pareto-Optimal exploration and confirms the perpetual delay-area trade-off. Conducted on benchmark suites ISCAS 85/89, ITC/ISCAS 99, VTR8.0, and EPFL benchmarks, the post-technology mapping and post-sizing quality-of-results (QoR) have been significantly improved, with average Area-Delay Product (ADP) improvement of 16.56% among all different exploration settings in MapTune. The improvements consistently remained for four different technologies (7nm, 45nm, 130nm, and 180 nm) with various mappers including both state-of-the-art open-source and commercial synthesis tools.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4412196044",
    "type": "article"
  },
  {
    "title": "A Survey on Transistor-Level Electrical Rule Checking of Integrated Circuits",
    "doi": "https://doi.org/10.1145/3748327",
    "publication_date": "2025-07-12",
    "publication_year": 2025,
    "authors": "Bruno Ferres; Oussama Oulkaid; Matthieu Moy; Gabriel Radanne; Ludovic Henrio; Pascal Raymond; Mehdi Khosravian Ghadikolaei",
    "corresponding_authors": "",
    "abstract": "Hardware verification is crucial to ensure the quality of Integrated Circuits, and prevent costly bugs down the manufacturing flow. Electrical Rule Checking (ERC) is a verification step used to assert that a circuit complies with some electrical rules, from the absence of short-circuits to dedicated constructor rules. In this survey, we provide a global overview of existing ERC techniques at transistor-level, where voltage values are explicit. We propose a new classification method to compare the existing approaches based on their semantic modeling of circuits. This survey precisely describes transistor-level ERC research challenges and existing solutions. We believe it will help structure this research domain by positioning existing approaches with respect to each other. Obviously, a survey should also facilitate technological transfer and this one should help CAD vendors identify the most relevant approaches to integrate in their tools. Finally, we highlight several promising directions to improve the existing solutions.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4412363073",
    "type": "article"
  },
  {
    "title": "Rethinking Logic Rewriting: Technology-Aware Subgraph Matching with Exact Synthesis",
    "doi": "https://doi.org/10.1145/3749103",
    "publication_date": "2025-07-21",
    "publication_year": 2025,
    "authors": "Hongyang Pan; Keren Zhu; Fan Yang; Xuan Zeng; Sen Liu; Yong Xiao; Yun Shao; Zhufei Chu",
    "corresponding_authors": "",
    "abstract": "Logic synthesis is crucial in digital design automation, significantly enhancing performance, reducing area, and lowering power consumption through technology-independent optimization followed by technology mapping. Logic rewriting, a key strategy for optimization, iteratively replaces portions of logic circuits with more compact implementations. Despite historical advancements, challenges remain in subgraph selection, technology-dependent metrics, and performance-runtime trade-offs. This paper presents a novel Te chnology- a ware logic R e W riting ( TeaRW ) framework to address these challenges. TeaRW incorporates a technology-aware rewriting algorithm that evaluates post-mapping netlist metrics during the technology-independent optimization phase. It employs four distinct subgraph rewriting techniques to maximize the effectiveness of local optimization. For efficiency, TeaRW utilizes an optimized logic representation database derived from exact synthesis, enabling cost-effective replacements. Experimental results on real-world benchmarks show improvements over the ABC tool, including an average Area-Delay-Product (ADP) improvement of 8.18% in delay-oriented optimization and 0.28% in area-oriented optimization when compared to state-of-the-art optimization scripts.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4412519360",
    "type": "article"
  },
  {
    "title": "Analog and Mixed-Signal IC Modeling and Optimization: An Artificial Intelligence Perspective",
    "doi": "https://doi.org/10.1145/3754339",
    "publication_date": "2025-07-28",
    "publication_year": 2025,
    "authors": "Morteza Golzan; Telex M. N. Ngatched; Karteek Popuri; Lihong Zhang",
    "corresponding_authors": "",
    "abstract": "The design of circuits and systems has witnessed a growing interest in leveraging the potential of artificial intelligence in the realm of analog and mixed-signal (AMS) integrated circuits (ICs). This paper presents a comprehensive survey on the application of machine learning techniques to the modeling and optimization of AMS ICs and systems. We explore the state-of-the-art research subjects in this domain and identify the advancements made in automating AMS performance modeling and optimization pursuit from a machine learning perspective. We propose to categorize the existing endeavors in the literature from four points of view (i.e., modeling, optimization, structure, and application). By analyzing the existing methods and discussing their advantages as well as limitations, we aim to shed light on the challenges and opportunities in empowering machine learning for tackling more complex AMS IC and system designs.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4412695933",
    "type": "article"
  },
  {
    "title": "AiLO: A Predictive Framework for Logic Optimization Using Multi-Scale Cross-Attention Transformer",
    "doi": "https://doi.org/10.1145/3757319",
    "publication_date": "2025-07-30",
    "publication_year": 2025,
    "authors": "Ye Cai; Rui Wang; Liwei Ni; Miao Liu; Xingyu Meng; Xiaoze Lin; Junfeng Liu; Biwei Xie; Xingquan Li",
    "corresponding_authors": "",
    "abstract": "Logic Optimization (LO) is a critical stage in the chip design process, focused on improving the Quality of Results (QoR) by optimizing circuit designs to minimize area and delay. During logic optimization, evaluating the QoR after each iteration requires completing logic optimization and technology mapping. The evaluation process is highly time-consuming, restricting the number of optimization iterations possible within a given time. To address this, the AI-aided logic optimization framework (AiLO) is developed to explore more optimization operator sequences (recipes). AiLO framework consists of two core components: AI-based metric evaluation and optimization exploration. To achieve accurate evaluation, different prediction models can be integrated. A multi-scale cross-attention Transformer (CrossLO) is introduced to simulate the optimization structure of recipes across circuit at various scales to enhance the prediction accuracy. Moreover, the AI evaluation module can effectively maintain the recipe ranking, even when prediction accuracy is biased. The logic optimization exploration algorithm integrated with CrossLO (AI evaluation) shows an average improvement of 14.75% over the initial version. NSGA-II (optimization module) integrated with CrossLO achieves a significant lead over other algorithms in the same time. In addition, the AiLO framework continues to grow with the performance of the two components, demonstrating strong adaptability and flexibility.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4412756234",
    "type": "article"
  },
  {
    "title": "Test-Fleet Scheduling in Complex Validation and Production Environments",
    "doi": "https://doi.org/10.1145/3749985",
    "publication_date": "2025-07-25",
    "publication_year": 2025,
    "authors": "Aniruddha Datta; Bhanu Vikas Yaganti; Mate Palocska; A F Dove; Arik Peltz; Krishnendu Chakrabarty",
    "corresponding_authors": "",
    "abstract": "We present a solution to the complex design-automation problem of scheduling test operations in a validation laboratory or production facility. Our goal is to maximize the utilization of a fleet of test stations and minimize the overall test time for a set of products. We consider the realistic scenario where tests can have dependency graphs, implying that some tests must be completed and passed before others can proceed. We also consider a mix of product types that require different kinds of tests and a mix of testers, which implies that each product can only be tested only on a specific set of testers. To ensure scalability and flexibility, we have formulated this scheduling problem as a “partially observable stochastic game”, a multi-agent extension of a partially observable Markov decision process. We have implemented multi-agent reinforcement learning agents to maximize parallelization in a manner that speeds up both training and inferencing. We present scheduling results for synthetic test cases as well as real-life data from a production facility.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4412915838",
    "type": "article"
  },
  {
    "title": "HLSRewriter: Efficient Refactoring and Optimization of C/C++ Code with LLMs for High-Level Synthesis",
    "doi": "https://doi.org/10.1145/3749986",
    "publication_date": "2025-07-19",
    "publication_year": 2025,
    "authors": "Kangwei Xu; Grace Li Zhang; Xunzhao Yin; Cheng Zhuo; Ulf Schlichtmann; Bing Li",
    "corresponding_authors": "",
    "abstract": "In High-Level Synthesis (HLS), refactoring a standard C/C++ code into its HLS-compatible version (HLS-C) still requires significant human effort. While various program scripts have been introduced to automate this process, the resulting code still contains many HLS-incompatible issues that need to be manually refactored and optimized by developers. Since Large Language Models (LLMs) have the ability to automate code generation, they can also be used for automated code refactoring and optimization in HLS. However, due to the limited training of LLMs, considering hardware and software simultaneously, hallucinations may occur when using LLMs for HLS, leading to synthesis failures. To address these challenges, we introduce HLSRewriter , an LLM-aided code refactoring and optimization framework that takes regular C/C++ code as input and automatically generates its corresponding optimized HLS-C code for hardware synthesis with minimal human intervention. To mitigate LLM hallucinations, a step-wise reasoning process is employed to analyze and detect HLS-incompatible errors. Afterwards, a repair library containing reference templates is efficiently created by scanning the HLS tool manual, followed by cooperation with a Retrieval-Augmented Generation (RAG) paradigm to guide the LLMs toward correct refactoring. In addition, a pipeline-aware decomposition strategy is introduced to progressively break down complex loop structures into smaller tasks with a balanced trade-off between latency and area, thereby enabling efficient pipelining and parallel execution. To further improve hardware efficiency, a bit width adjuster module is incorporated into this framework to optimize the precision of floating-point variables. Moreover, LLM-aided HLS optimization strategies are introduced to add/tune hardware directives in HLS-C code, thereby enhancing the performance of the final synthesized hardware. Experimental results demonstrate that the proposed LLM-aided framework can achieve higher refactoring pass rates and superior hardware performance in 24 real-world tasks compared with traditional approaches and the direct application of LLMs for code refactoring and optimization. The codes are open-sourced at this link: https://github.com/code-source1/catapult.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4412960910",
    "type": "article"
  },
  {
    "title": "AGD: Analytic Gradient Descent for Discrete Optimization in EDA and its Use to Gate Sizing",
    "doi": "https://doi.org/10.1145/3748257",
    "publication_date": "2025-07-17",
    "publication_year": 2025,
    "authors": "Phuoc Pham; T.Y. Park; Sung-Hyuk Cho; Tayyeb Mahmood; Joon-Sung Yang; Jaeyong Chung",
    "corresponding_authors": "",
    "abstract": "In electronic design automation (EDA), simulation models are often non-differentiable, and many design choices are discrete. As a result, greedy optimization methods based on numerical gradients are widely used, although they often lead to suboptimal solutions. In contrast, analytical methods may provide better solutions but require significant research effort. Reinforcement learning (RL) has been employed to address this problem; however, RL also suffers from notorious sample inefficiency, which is exaggerated in EDA because data sampling in EDA is very expensive due to slow simulations. This paper proposes an alternative to RL for EDA, namely analytic gradient descent (AGD). Our method starts with a differentiable performance model, which can be either a learned surrogate or a static model. It then applies transformations similar to Shannon decomposition for each design variable in the performance model. Finally, one design option for each variable is selected using a one-hot variable, which is trained via a straight-through estimator (STE) through gradient descent. We demonstrate AGD on the well-known gate sizing problem using both a learned surrogate and a static model across 20 industrial benchmark circuits. Our experimental results show that the proposed method can outperform a several-decade-old commercial tool in the gate sizing task for 19 out of the 20 circuits.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413081852",
    "type": "article"
  },
  {
    "title": "High-level Synthesis Directives Design Optimization via Large Language Model",
    "doi": "https://doi.org/10.1145/3747291",
    "publication_date": "2025-07-17",
    "publication_year": 2025,
    "authors": "Xufeng Yao; Wenqian Zhao; Qi Sun; Cheng Zhuo; Bei Yu",
    "corresponding_authors": "",
    "abstract": "High-level synthesis is an effective methodology that accelerates early-stage circuit design. The optimization of HLS directives has been a critical yet challenging endeavor, with prevailing research primarily concentrating on custom feature engineering and dedicated model designs. However, these conventional approaches often fall short of fully harnessing the intricate latent information embedded within raw HLS directives, potentially limiting the scope and efficiency of optimization processes. In response to these challenges, this article pioneers the integration of large language model (LLM) into the HLS optimization workflow, leveraging their capabilities as both sophisticated feature extractors and autonomous agents. This application of LLM marks a significant departure from traditional methods, introducing a more nuanced and effective strategy for navigating the complex landscape of HLS directive optimization, enabling a more efficient exploration of the design space and prioritization of search strategies. Specifically, our approach makes a significant improvement to the Pareto frontier in directive design, enabling a more rapid and efficient design space exploration. This demonstrates not only an increase in optimization performance but also a decrease in computational overhead, thereby promising significant time savings in the circuit design process. This work not only enhances the current state of HLS directive optimization but also makes new avenues for the application of language models in the field of EDA. Our work makes the following key achievements: We propose an LLM-based framework for effective HLS directives design space exploration; We utilize the prior knowledge of LLM and fine-tune an LLM for HLS directives optimization; Empirical results demonstrate this LLM-based approach’s effectiveness. Specifically, we obtain 15% improvement on the normalized ADRS metric, demonstrating superior performance with limited sampling steps compared with current leading algorithms.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413082100",
    "type": "article"
  },
  {
    "title": "A Variation Tolerant Write Assist Read Decoupled 9T SRAM Cell for Low Voltage Application",
    "doi": "https://doi.org/10.1145/3754451",
    "publication_date": "2025-08-20",
    "publication_year": 2025,
    "authors": "Ayush Dahiya; Vansh Singhal; Poornima Mittal",
    "corresponding_authors": "",
    "abstract": "Driven by the swift expansion of energy-demanding Internet of Things devices, on-chip SRAM is undergoing a significant evolution to attain reduced power usage. This shift ushers in a new era of self-sufficient and energy-efficient technology. This paper proposes a novel 9-transistor Write Assist Read Decoupled (WARD) SRAM bitcell designed to achieve significant reductions in write latency. The design incorporates a low threshold (V TH ) write access transistor and leverages virtual ground (VGND) assist for low voltage operation at 32 nm CMOS technology node. It demonstrates notable improvements in write delay over conventional SRAM bitcells. At an operating voltage of 0.6 V, the WARD 9T cell offers reduced write ’1’ delay and write ’0’ delay by 3.18x/3.09x/2.42x/2.11x and 1.5x/1.475x/1.4x/1.37x/1.12x/1.118x compared to 9T half select free write assist (HFWA)/10T/9T single bitline (SB)/7T single-ended (SE) and 11T/9T HFWA/10T/9T transmission based read decoupled (TRD)/9T SB/7T SE cell SRAM bitcells respectively. Additionally, WARD 9T cell demonstrates a substantial reduction in read delay by 1.56x/1.56x/8.44x compared to 11T/8T positive feedback controlled (PFC)/9T SB SRAM bitcells, respectively. To validate its performance, the WARD 9T SRAM bitcell undergoes evaluation across various supply voltages, process corners at varied temperature ranges, considering the impact of voltage threshold variations on transistor mismatch through Monte Carlo simulations. Various parameters like write margin and write 1 delay are validated against 30 mV sigma variation in threshold voltage for 2k data points at 3 different temperatures. The latter undergoes further evaluation at different process corners. The comparative analysis includes various pre-existing SRAM cells, highlighting the superior performance of the WARD 9T cell.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413338238",
    "type": "article"
  },
  {
    "title": "RTMF: Routing based on TDM for Multi-FPGA System",
    "doi": "https://doi.org/10.1145/3760778",
    "publication_date": "2025-08-15",
    "publication_year": 2025,
    "authors": "Shiyan Liang; J.J. Lin; Dengxue Liu; Lin Wen-xiong; Peng Gao; Dongsheng Zuo; Tingting Wu; Xiaoming Xiong; Shuting Cai",
    "corresponding_authors": "",
    "abstract": "As modern VLSI design advances, the significance of multi-FPGA systems in prototyping and verification is steadily growing. Due to the physical I/O limitations, the Time-Division Multiplexing (TDM) and I/O assignment techniques are introduced to solve these problems. However, most multi-FPGA systems primarily focus on inter-FPGA routing while overlooking intra-FPGA routing. In this article, a comprehensive routing framework based on TDM for Multi-FPGA systems (RTMF) is hereby presented. To our knowledge, this is the first attempt to jointly optimize intra-level and inter-level routing in the work of multi-FPGA systems (MFS). The RTMF framework, tailored for system-level and intra-level routing under constrained wiring resources, integrates routing demands within and between FPGAs. Through the integration of TDM technology and adaptive optimization algorithms, RTMF effectively meets routing requirements and delivers efficient solutions. Furthermore, RTMF demonstrates remarkable adaptability, allowing for dynamic adjustments and optimizations to address diverse routing demands and constraints. In comparison to the state-of-the-art methodologies, in benchmark designs with a scale greater than 50,000, our approach on average reduces the maximum routing weight by 59.98% and 46.70%, respectively.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413446147",
    "type": "article"
  },
  {
    "title": "A Canonical Test Representation for Verification of Shared-Memory Behavior in Multiprocessor Systems",
    "doi": "https://doi.org/10.1145/3762184",
    "publication_date": "2025-08-28",
    "publication_year": 2025,
    "authors": "Bruno Dourado Miranda; Márcio Castro; Luiz C. V. dos Santos",
    "corresponding_authors": "",
    "abstract": "The scope of this article is the design verification of a multicore chip or multichip multiprocessor by running concurrent test programs until coverage goals are reached. Interactions between multiple processors through shared memory must obey a memory consistency model, which specifies valid behaviors. We propose a canonical test-program representation that encodes primal shared-memory behaviors to be induced at runtime. It is intended as one of the main keys to the design of new test generators. We prove that our representation does not limit the search space, because it induces equivalence classes that can be completely and uniquely encoded. In particular, we show experimental evidence that our representation is also suitable to learning-based test generators, because it enables the design of effective actions. We have built a generator directed by a Reinforcement Learning agent, designed its actions based on our encoding, and compared it with three generators when targeting 32-core designs. For a given time limit, our generator reached the largest coverage and led to the fastest error diagnosis in 3/4 of the verification scenarios, despite our choice of a minimalist agent. The theoretical guarantees and the experimental evidence indicate that our representation provides proper grounds for defining effective actions, and it prevents them from either inducing redundant tests or limiting the test suite.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413774686",
    "type": "article"
  },
  {
    "title": "Adaptive Control-Logic Routing with Length Matching and Fault Tolerance for FPVA Biochips Using Deep Reinforcement Learning",
    "doi": "https://doi.org/10.1145/3765631",
    "publication_date": "2025-09-01",
    "publication_year": 2025,
    "authors": "Huayang Cai; Genggeng Liu; Wenzhong Guo; Zipeng Li; Tsung-Yi Ho; Xing Huang",
    "corresponding_authors": "",
    "abstract": "With the increasing integration level of flow-based microfluidics, fully programmable valve arrays (FPVAs) have emerged as the next generation of flow-based microfluidic devices. Microvalves in an FPVA are typically managed by a control logic, where valves are connected to a core input via control channels to receive control signals that guide their state switchings. When executing bioassays using an FPVA, however, some valves need to be switched synchronously at different time points, so that both fluid transportation and biochemical operations can be executed correctly. Consequently, the channel lengths from the core input to these valves must be equal, which poses a big challenge to the channel routing of the control logic. To solve this problem, we propose a deep reinforcement learning-based adaptive routing flow for the control logic of FPVAs. With the proposed routing flow, an efficient control-channel network can be automatically constructed to realize accurate control signal propagation. Meanwhile, timing skews among synchronized valves and the total length of control channels are minimized simultaneously, thus generating an optimized control logic with excellent timing performance. Furthermore, by introducing backups of identified critical valves and flexible routing of backup paths without restrictions on control valve locations, a novel fault-tolerant design method considering length matching is implemented to efficiently improve the reliability of the control logic. Simulation results on multiple benchmarks demonstrate that the proposed routing flow leads to control logics with accurate valve synchronization, low cost, and high reliability.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413876885",
    "type": "article"
  },
  {
    "title": "MFIT : Multi-FIdelity Thermal Modeling for 2.5D and 3D Multi-Chiplet Architectures",
    "doi": "https://doi.org/10.1145/3765905",
    "publication_date": "2025-09-04",
    "publication_year": 2025,
    "authors": "Lukas Pfromm; Alish Kanani; Harsh Sharma; Parth Solanki; Eric J. Tervo; Jaehyun Park; Janardhan Rao Doppa; Partha Pratim Pande; Ümit Y. Ogras",
    "corresponding_authors": "",
    "abstract": "Rapidly evolving artificial intelligence and machine learning applications require ever-increasing computational capabilities, while monolithic 2D design technologies approach their limits. 2.5D/3D heterogeneous integration of smaller chiplets using advanced packaging has emerged as a promising paradigm for addressing this limit and meeting performance demands. These approaches offer a significant cost reduction and higher manufacturing yield than monolithic 2D integrated circuits. However, the compact arrangement and high compute density of these systems exacerbate thermal management challenges, potentially compromising performance. Addressing these thermal modeling challenges is critical, especially as system sizes grow and different design stages require varying levels of accuracy and speed. Since no single thermal modeling technique meets all these needs, this paper introduces MFIT, a range of multi-fidelity thermal models that effectively balance accuracy and speed. These multi-fidelity models can enable efficient design space exploration and runtime thermal management. Our extensive testing on systems with 16, 36, and 64 2.5D integrated chiplets and 16 × 3 3D integrated chiplets demonstrates that these models can reduce execution times from days to mere seconds and milliseconds with negligible loss in accuracy.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413989692",
    "type": "article"
  },
  {
    "title": "MoDAF: A Multi-objective Divide-and-Conquer Parameter Tuning Framework for CGRAs",
    "doi": "https://doi.org/10.1145/3766063",
    "publication_date": "2025-09-04",
    "publication_year": 2025,
    "authors": "Jingyuan Li; Yuan Dai; Wenbo Yin; Lingli Wang",
    "corresponding_authors": "",
    "abstract": "Coarse-grained reconfigurable architectures (CGRAs) are gaining increasing attention as domain-specific accelerators due to their high flexibility and energy efficiency. These architectures offer a compelling solution for applications that require custom hardware performance while retaining a degree of programmability. However, the design space of CGRAs is inherently vast and complex, presenting significant challenges for architects to explore design choices efficiently and systematically. Existing design space exploration (DSE) methodologies for CGRAs are often time-demanding and struggle to deliver optimal solutions when confronted with high-dimensional and multi-objective design space. Therefore, we consider constructing a CGRA parameter tuning framework called MoDAF. MoDAF initializes the design space using the most representative and diverse samples. It adopts a divide-and-conquer approach, utilizing Monte Carlo Tree Search (MCTS) and space partitioning techniques to dynamically break down the complex design space into more manageable subspaces. A hybrid model handles local fluctuations within each subspace, while a dual sampling algorithm is designed to increase sampling efficiency. MoDAF also incorporates a fast evaluation model to estimate CGRA throughput and area, significantly speeding up the exploration process. Compared with previous approaches, experiments show that our proposed framework reduces the average distance from the reference set by 53.0% and the hypervolume deviation by 64.2%, while also cutting wall time by 57.5%.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413990187",
    "type": "article"
  },
  {
    "title": "Enhanced Detection of Recycled FPGAs Using Gaussian Process Regression with LHS and Active Sampling",
    "doi": "https://doi.org/10.1145/3765907",
    "publication_date": "2025-09-05",
    "publication_year": 2025,
    "authors": "Yoshimi HAGIHARA; Foisal Ahmed; Yamane Shoma; Riaz-ul-haque Mian",
    "corresponding_authors": "",
    "abstract": "Modern Field-Programmable Gate Arrays (FPGAs) are widely utilized across various fields, including artificial intelligence accelerators and Internet of Things (IoT) devices, due to their flexibility and low-cost development potential. However, the problem of ”recycled FPGAs” being fraudulently sold as new has grown increasingly severe. This raises significant concerns about reliability degradation caused by performance deterioration, especially in critical applications such as medical and communication systems. Many studies have proposed methods for detecting recycled FPGAs based on delay degradation analysis using Ring Oscillators (ROs). However, the state-of-the-art approach requires a comprehensive evaluation of paths within all lookup tables, leading to increased testing costs and database management overhead. To address this issue, a method combining exhaustive fingerprinting (X-FP) methodology with an advanced RO design is proposed, where a statistical Virtual Probe (VP) model is used to predict the delay of the RO. This research aims to achieve high-accuracy predictions with fewer data points by employing Gaussian Process Regression (GPR) instead of the VP model. This demonstrates that, with actual silicon data, the proposed custom (GPR) improves prediction accuracy by 20% compared to state-of-the-art VP model methods with 50% less training data. The two proposed models demonstrated better performance than Naive GPR, achieving 9% and 7% higher prediction accuracy, respectively. The predictions were further verified using an optimized Autoencoder. The model successfully detected both 10-days and 14-days aged FPGAs among the new ones, achieving 100% overall accuracy using only 10% and 3% training data, respectively. While although the training data predicted by the VP can also detect aged FPGAs, it cannot properly classify all aged and non-aged FPGAs in both 3% and 10% training scenarios. Finally, for further verification in the case of both new and aged FPGA, after prediction, the logistic regression classifier was trained with both old and new FPGA data, achieving 100% correct classification.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4414019619",
    "type": "article"
  },
  {
    "title": "FACT: Fast and Accurate Multi-Corner Predictor for Timing Closure in Commercial EDA Flows",
    "doi": "https://doi.org/10.1145/3768166",
    "publication_date": "2025-09-15",
    "publication_year": 2025,
    "authors": "J. Xu; Ziyue Han; Shiyang Wu; Jiaqi Gao; Hao Yan; Longxing Shi",
    "corresponding_authors": "",
    "abstract": "With technology scaling progressing well into deep nanometer region, the number of technology corners surges from dozens to hundreds. This dramatic increase in corners significantly complicates timing closure during Engineering Change Orders (ECO) stages, as performing full-corner static timing analysis (STA) becomes increasingly time-consuming and challenging. Existing methodologies often leverage machine learning (ML) techniques to predict unknown corners based on a subset of known corners. However, as the total number of corners expands, these methods not only require a larger set of known corners but also become highly sensitive to known corner selection. Additionally, as designers push designs into near-threshold voltage regions to enhance energy efficiency, the number of corners increases and the nonlinearity between corners becomes more pronounced. This intensifies the difficulty for current ML-based methods to accurately predict full-corner timing metrics. In this work, we propose FACT, a fast and accurate multi-corner predictor for timing closure optimization. Our approach simplifies the process by necessitating timing analysis under only one known corner. By effectively capturing correlations across diverse technology files, FACT robustly infers full-corner timing metrics, even under challenging near-threshold conditions. Moreover, our framework seamlessly integrates with commercial EDA design flows, making it practical in industrial environments. Experimental results on open-source designs indicate superior stability of our method, coupled with a significant runtime speed-up over both traditional and prior ML-based timing ECO flows.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4414206594",
    "type": "article"
  },
  {
    "title": "AutoMarks: A GNN-based Automated Physical Design Watermarking Framework",
    "doi": "https://doi.org/10.1145/3768343",
    "publication_date": "2025-09-15",
    "publication_year": 2025,
    "authors": "Ruisi Zhang; Rachel Selina Rajarathnam; David Z. Pan; Farinaz Koushanfar",
    "corresponding_authors": "",
    "abstract": "Physical design refers to converting a logical circuit description into a physical chip layout for manufacturing. Although design companies invest huge efforts to fine-tune the cell positions and connections for better power, performance, and area metrics, chip layouts are vulnerable to security risks along the supply chain. Physical design watermarking injects signatures on the chip layout, allowing ownership authentication and avoiding potential security risks. A substantial effort is required to identify the best locations to insert the watermarks on the chip layout without affecting the overall layout quality. This paper presents AutoMarks , an automated and transferable watermarking framework that leverages graph neural networks to reduce watermark search overhead during the integrated circuit design’s placement stage. AutoMarks ’s novel automated watermark search is accomplished by (i) constructing novel graph and node features with physical, semantic, and design constraint-aware representation; (ii) designing a data-efficient sampling strategy for watermarking fidelity label collection; and (iii) leveraging a graph neural network to learn the connectivity between cells and predict the watermarking fidelity on unseen layouts. Extensive evaluations on ISPD’15, ISPD’19, and ICCAD’15 benchmarks demonstrate that our proposed automated methodology: (i) is capable of finding quality-preserving watermarks in a short time; (ii) is transferable across various designs, i.e., AutoMarks trained on one layout is generalizable to other benchmark circuits; (iii) is effective in watermarking designs optimized for wirelength and timing metrics. AutoMarks is also resilient against potential watermark removal and forging attacks. Our code is publicly available on GitHub.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4414206616",
    "type": "article"
  },
  {
    "title": "Towards Generalizable and Efficient Circuit Topology Design: A Graph-Transformer-based Surrogate Model with Curriculum Learning",
    "doi": "https://doi.org/10.1145/3768167",
    "publication_date": "2025-09-17",
    "publication_year": 2025,
    "authors": "Hongxia Lu; Shaoze Fan; Shun Zhang; Ningyuan Cao; Xin Zhang; Jing Li",
    "corresponding_authors": "",
    "abstract": "Unlike circuit parameter and sizing optimizations, the automated design of analog circuit topologies poses significant challenges for learning-based approaches. One challenge arises from the combinatorial growth of the topology space with circuit size, which limits the topology optimization efficiency. Moreover, traditional circuit evaluation methods are time-consuming, while the presence of data discontinuity in the topology space makes the accurate prediction of circuit performance exceptionally difficult for unseen topologies. To tackle these challenges, we design a novel Graph-Transformer-based Network (GTN) as the surrogate model for circuit evaluation, offering a substantial acceleration in the speed of circuit topology optimization without sacrificing performance. Our GTN model architecture is designed to embed voltage changes in circuit loops and current flows in connected devices, enabling accurate performance predictions for circuits with unseen topologies. To address the cold start problem when scaling GTN to large-scale circuits, we further introduce a curriculum learning strategy that progressively trains GTN from small-scale to large-scale circuits. This approach enables the model to first learn fundamental physical principles from simpler topologies and gradually adapt to complex configurations, effectively bridging the circuit complexity gap and improving prediction accuracy. Taking the power converter circuit design as an experimental task, our GTN model significantly outperforms an analytical approach and baseline methods directly utilizing graph neural networks. Furthermore, GTN achieves less than 5% relative error and 196 × speed-up compared with high-fidelity simulation. Notably, our GTN surrogate model empowers an automatic circuit design framework to discover circuits of comparable quality to those identified through high-fidelity simulation while reducing the time required by up to 98.2%. With curriculum learning, the enhanced GTN achieves a 51% improvement for performance prediction of large-scale circuits compared to the GTN model without this strategy. These advancements establish GTN as a scalable framework for automated analog circuit design across varying circuit complexity levels.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4414290365",
    "type": "article"
  },
  {
    "title": "RedPIM: An Efficient PIM Accelerator Design with Reduced Analog-to-Digital Conversions",
    "doi": "https://doi.org/10.1145/3769122",
    "publication_date": "2025-09-20",
    "publication_year": 2025,
    "authors": "Jiale Li; Yulin Fu; Longyu Ma; Chiu‐Wing Sham; Chong Fu",
    "corresponding_authors": "",
    "abstract": "ReRAM-based Processing-In-Memory (PIM) architectures are compelling contenders for deep learning due to their ability to perform matrix-vector multiplications (MVMs) directly within the memory, significantly reducing data movement and enhancing computational efficiency. However, since MVMs occur in the analog domain, analog-to-digital converters (ADCs) dominate power consumption and area overhead in current implementations. To this end, we propose RedPIM, an efficient ReRAM-based PIM accelerator design for deep neural networks (DNNs) that reduces the number of analog-to-digital conversions. RedPIM exploits the fact that in ReRAM-based PIM accelerators, the overall energy consumption generally increases with the number of activated analog-to-digital conversions. Specifically, we introduce a novel training algorithm that is aware of the ADC overhead during activation value quantization and optimizes accuracy concurrently. From a hardware design perspective, we develop a lookup table (LUT)-based quantization module to enable efficient and low-cost activation value quantization. In addition, we propose an efficient adaptive operation unit (OU) size assignment scheme that further minimizes analog-to-digital conversions by considering activation sparsity and weight distribution. Extensive experimental results show our RedPIM reduces latency to 27.72% and energy consumption to 10.15% of the baseline, with minimal accuracy loss, making it a promising solution for enhancing DNN acceleration. The code for this project is available at: https://github.com/JialeLiLab/ADC_aware_Learning.git.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4414371551",
    "type": "article"
  },
  {
    "title": "Holistic Optimization Framework for FPGA Accelerators",
    "doi": "https://doi.org/10.1145/3769307",
    "publication_date": "2025-09-24",
    "publication_year": 2025,
    "authors": "Stéphane Pouget; Michael Lo; Louis-Noël Pouchet; Jason Cong",
    "corresponding_authors": "",
    "abstract": "Customized accelerators have revolutionized modern computing by delivering substantial gains in energy efficiency and performance through hardware specialization. Field-Programmable Gate Arrays (FPGAs) play a crucial role in this paradigm, offering unparalleled flexibility and high-performance potential. High-Level Synthesis (HLS) and source-to-source compilers have simplified FPGA development by translating high-level programming languages into hardware descriptions enriched with directives. However, achieving high Quality of Results (QoR) remains a significant challenge, requiring intricate code transformations, strategic directive placement, and optimized data communication. This paper presents Prometheus , a holistic optimization framework that integrates key optimizations — including task fusion, tiling, loop permutation, computation-communication overlap, and concurrent task execution —into a unified design space. By leveraging Non-Linear Programming (NLP) methodologies , Prometheus explores the optimization space under strict resource constraints, enabling automatic bitstream generation. Unlike existing frameworks, Prometheus considers interdependent transformations and dynamically balances computation and memory access. We evaluate Prometheus across multiple benchmarks, demonstrating its ability to maximize parallelism, minimize execution stalls, and optimize data movement. The results showcase its superior performance compared to state-of-the-art FPGA optimization frameworks, highlighting its effectiveness in delivering high QoR while reducing manual tuning efforts.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4414476925",
    "type": "article"
  },
  {
    "title": "AiDRC: Accelerating Detailed Routing by AI-Driven Design Rule Violation Prediction and Checking",
    "doi": "https://doi.org/10.1145/3769306",
    "publication_date": "2025-09-25",
    "publication_year": 2025,
    "authors": "Yifan Li; R. G. Liu; Zhisheng Zeng; Z.H. Li H.W. Huang; Zhipeng Huang; Dongbo Bu; Xingquan Li",
    "corresponding_authors": "",
    "abstract": "Design rule violation (DRV) evaluation and optimization constitute a critical challenge in modern VLSI physical design. Fast and accurate assessments of routability and DRV have gained significant research attention due to their pivotal role in improving design closure efficiency. Traditional detailed routing and design rule checking (DRC) are computationally expensive. To address the above challenges, this work leverages AI models for the specific location prediction of DRVs in the pre-detailed routing stage and the checking of DRVs during detailed routing, which achieves fast and precise DRV evaluation. By integrating the crisscross attention mechanism and channel transformer within a ResNet backbone, our proposed DRV prediction and checking model gains the capability to learn non-local and cross-layer feature relationships and mitigates the negative impact of data imbalance. Experiments demonstrate the effectiveness of our prediction model and checking model, with area under curve (AUC) of 0.987 and F1-score of 0.934, respectively. Remarkably, when integrated into an open-source detailed routing tool, our DRV prediction model achieves 16 × acceleration, while our DRV checking model achieves a 293 × acceleration over the conventional DRC engine. By applying the predicted DRVs to the detailed routing tool, our framework eliminates an average of 44% DRVs of the initial detailed routing results, effectively bridging the gap between data-driven predictions and rule-based detailed routing workflows.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4414513768",
    "type": "article"
  },
  {
    "title": "Accurate Analytic Equation Generation for Compact Modeling with Physics-Assisted Kolmogorov-Arnold Networks",
    "doi": "https://doi.org/10.1145/3765904",
    "publication_date": "2025-09-25",
    "publication_year": 2025,
    "authors": "Guangxin Guo; Zhengguang Tang; Zhenhai Cui; Cong Li; Handing Wang; Hailong You",
    "corresponding_authors": "",
    "abstract": "This paper proposes a method to generate accurate and concise analytic equations for device compact modeling using Physics-Assisted Kolmogorov-Arnold Networks (PKAN). The equations are directly extracted from the trained neural network architecture. PKAN uses variable activation functions informed by prior physical knowledge to model device behaviors. Similarity constraints map these trained activation functions to mathematical symbols. Sparsification techniques simplify the network structure, producing concise and explicit equations. This paper also presents four approaches for physics-assisted device modeling using PKAN: 1) generating entire continuous equations without human intervention, 2) applying correlation factors to existing models without requiring knowledge of internal physical mechanisms, 3) revising specific parts of existing models, and 4) automatically extending existing models. Experimental results show that PKAN demonstrates significant accuracy improvements, achieving error reductions of 91.8%, 91.5%, 66.2%, and 83.7% for corresponding experiments, respectively. These findings demonstrate PKAN’s potential for various device modeling applications. By combining the precision of neural networks with the clarity of symbolic representation, PKAN offers a powerful tool for device modeling applications.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4414513777",
    "type": "article"
  },
  {
    "title": "DPTM: An Adaptive Scheduler Design Utilizing Timeslot Matching and Release Methods for Concurrent and Multi-task Interleaved Pipelining-oriented CGRA",
    "doi": "https://doi.org/10.1145/3769303",
    "publication_date": "2025-09-25",
    "publication_year": 2025,
    "authors": "Danping Jiang; Zibin Dai; Yanjiang Liu; Song XiaoYu; Zhaoxu Zhou",
    "corresponding_authors": "",
    "abstract": "Coarse-grained reconfigurable architectures (CGRAs) are increasingly employed as domain-specific accelerators due to their efficiency and flexibility. However, the existing CGRA architectures suffer from low hardware resource utilization and performance due to the limitations of the scheduling scheme. In this paper, an adaptive scheduler (denoted as DPTM) for concurrent and multi-task interleaved pipelining-oriented CGRA is introduced, which exploits timeslot matching and release methods to avoid the pipeline conflicts and improve the scheduling performance. The characteristics of task scheduling based on directed acyclic graph (DAG) are analyzed, and several performance-influencing factors are extracted to build a scheduling performance model for reducing the time cost of scheduling and guiding the design of scheduling schemes. Moreover, the scoreboard method of dynamic instruction schedulers is optimized to control the entry time of multiple tasks into the pipeline, and then a timeslot matching method is proposed to provide non-conflict pipelining for the multiple tasks. Further, a timeslot release method is presented to release the timeslots for unscheduled sub-tasks dynamically, which can adapt the parallel processing of multiple tasks and decrease the scheduling time. Then, an adaptive scheduling scheme combines the dynamic priority-based task assignment method, timeslot matching method, and timeslot release method to schedule massive tasks for CGRA. Finally, the overall architecture of DPTM is introduced and designed to validate the efficacy of the proposed scheduling scheme. Experimental results show that the proposed timeslot matching/release approach reduces 84% total scheduling time and decreases 40% average scheduling time at most compared to the non-timeslot-matching scheduling schemes, the proposed task assignment approach decreases 8% total scheduling time and lowers 3% average scheduling time compared to the existing approaches, and the proposed scheduler decreases 51% critical path delay, lowers 35% area overhead, and reduces 12% power consumption at most compared with the existing schedulers.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4414527515",
    "type": "article"
  },
  {
    "title": "Design Automation Techniques for Microfluidic Fully Programmable Valve Array Biochips: A Systematic Survey",
    "doi": "https://doi.org/10.1145/3768629",
    "publication_date": "2025-09-25",
    "publication_year": 2025,
    "authors": "Shu Hua Qi; Zhiwen Yu; Bin Guo; Sizhao Li; Zipeng Li; Hanbin Ma; Tsung-Yi Ho; Krishnendu Chakrabarty; Xing Huang",
    "corresponding_authors": "",
    "abstract": "Flow-based microfluidic biochips have attracted much attention over the past two decades. By integrating diverse micro-components, e.g., mixers and filters, on a miniaturized planar substrate, complicated bioassays such as protein crystallization and drug screening can be executed automatically without requiring human invention, thus becoming a promising alternative to traditional cumbersome laboratory equipment. As manufacturing technology advances, it has become possible to implement hundreds of thousands of microvalves within a single chip. This breakthrough has given rise to fully programmable valve array (FPVA) biochips, representing a next-generation platform in flow-based microfluidics that offers enhanced reconfigurability and operational flexibility. Nevertheless, the exponential increase in valve density has introduced significant design complexity when implementing sophisticated assay protocols. As a result, the design automation of FPVAs has emerged as a critical research frontier, attracting considerable attention from both academia and industry. This review paper systematically examines recent advances in FPVA design automation, involving computer-aided design methods for architectural synthesis, volume management, sample preparation, automated testing, fault localization, error recovery, and washing optimization. These techniques enable FPVA users to concentrate on assay protocol development while delegating implementation-specific design and optimization tasks to design automation tools. Furthermore, we analyze emerging security implications in FPVAs, particularly focusing on bioassay accuracy and reliability that ensure experimental reproducibility. Finally, potential trajectories for future research are discussed in detail to further promote the integration level and widespread application of FPVAs.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4414527597",
    "type": "article"
  },
  {
    "title": "Towards Floating Point-Based AI Acceleration: Hybrid PIM with Non-Uniform Data Format and Reduced Multiplications",
    "doi": "https://doi.org/10.1145/3769304",
    "publication_date": "2025-09-26",
    "publication_year": 2025,
    "authors": "Lidong Guo; Zhenhua Zhu; Xuefei Ning; Tengxuan Liu; Shiyao Li; Guohao Dai; Huazhong Yang; Wangyang Fu; Yu Wang",
    "corresponding_authors": "",
    "abstract": "Neural networks (NNs) have exhibited excellent performance in various fields of artificial intelligence. However, the primary operations in these mainstream models, including matrix-vector multiplication (MVM), element-wise multiplication (EWM), and depth-wise convolution (DWConv), require massive data movements during computation, which greatly impacts NNs’ inference performance. The emerging Processing-In-Memory (PIM) architectures have shown great potential to overcome the memory wall problem. However, constrained by the supported data format and operator type, directly adopting PIM architectures for neural network acceleration faces three challenges: (1) Floating-point (FP) format has been widely adopted for ensuring high algorithm accuracy. However, Resistive Random-Access Memory (RRAM)-based analog PIM architectures perform integer (INT) MVMs in the analog domain, limiting their application to the more accurate FP format; (2) Static Random-Access Memory (SRAM)-based digital PIM architectures require additional circuits to support the FP format, and the SRAM capacity cannot satisfy the storage requirement of latest large language models (LLMs); (3) When performing the operators with few accumulation steps, such as EWMs and DWConvs, only few memory units in PIM architecture are activated, resulting in severe device under-utilization. To tackle the above challenges, this paper proposes an RRAM and 3D-SRAM-based hybrid PIM architecture, achieving FP-based algorithm accuracy, high device utilization, and high energy efficiency. At the software level , we first analyze the impact of quantization errors on NN’s inference accuracy. For the quantization error-insensitive MVM operations, we propose the PIM-oriented exponent-free non-uniform (PN) data format. The proposed PN format can be flexibly adjusted to fit the non-uniform distribution and approach FP-based algorithm accuracy using bit-slicing-based full INT operations. For the quantization error-sensitive EWM/DWConv operations, we introduce the multiplication-free approximated FP multiplications to reduce the additional hardware overhead. At the hardware level , we propose a hybrid PIM architecture, including an RRAM analog PIM using shift-and-add for PN-based MVMs, and a 3D-SRAM digital PIM with high utilization for DWConv/EWM operations. Extensive experiments on CNNs and attention-free LLMs validate that the proposed PIM architecture achieves up to 99.4 × and 33.9 × speedup with 5697.7 × and 8.2 × energy efficiency improvement compared to GPU and PIM-baseline, respectively. With the proposed PN format and approximated FP multiplications, the algorithm accuracy of CNNs and attention-free LLMs can be improved by up to 3.01% and 10.18%, respectively.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4414532302",
    "type": "article"
  },
  {
    "title": "Supporting Timing-related Metrics for Autonomous Driving Frameworks in CyberRT",
    "doi": "https://doi.org/10.1145/3768344",
    "publication_date": "2025-09-30",
    "publication_year": 2025,
    "authors": "Miguel Alcon; Enrico Mezzetti; Jaume Abella; Francisco J. Cazorla",
    "corresponding_authors": "",
    "abstract": "The provision of increasingly advanced autonomous software functionalities builds on cutting-edge autonomous driving frameworks to enable modular interactions among multiple software components. This approach helps to support functional cause-effect chains from multiple sensors to actuators. The complexity of the (software) component interactions makes it more difficult to ascertain the correctness of the timing behavior of the system. This is so because traditional timing-related metrics like worst-case execution and worst-case response time do not capture the inter-dependency in cause-effect chains between the input sampling time and the time at which computation based on those inputs is performed. Complementary timing-related metrics, such as maximum reaction time and maximum data age have been considered to capture timing requirements, typically with an end-to-end scope, in cause-effect chains. These metrics have been formalized and demonstrated in ROS2-based automotive and autonomous driving setups [44, 46]. However, the formalization of those metrics, which is necessary for deriving analytical lower and upper bounds and monitoring them at run-time, largely depends on the execution model and semantics offered by the run-time. Any concrete application of those metrics need to be tailored and adapted to the system at hand. Apollo auto is a popular, industrial-quality, open-source autonomous driving framework that is seeing increasing adoption both for industrial and academic projects. Apollo builds on CyberRT , an ad-hoc run-time that is similar in mechanism and intent to ROS2 but differentiates from it with respect to execution model and supported semantics. In contrast to ROS2, CyberRT is highly specialized to support the Apollo AD framework, is neither extensively documented or thoroughly analysed in the literature, especially in relation to execution model and instantiation of timing-related metrics. In this work, for the first time, we provide an insightful analysis and discussion on CyberRT execution model and semantics, starting from its raw and non-extensively documented codebase. Based on the identified semantics, we elaborate a formalization of timing-related metrics on CyberRT , across different granularity scopes, namely end-to-end and node levels. In particular, we develop on the importance of node-level timing properties to intercept any latent timing misbehavior before it is too late, and it severely impacts end-to-end execution. We provide a concrete mapping of a comprehensive set of timing-related metrics to the CyberRT execution model, both at end-to-end and node level, and develop a monitoring library that allows to intercept them on the specific software stack. We exploit the proposed library on a set of Apollo autonomous driving scenarios to demonstrate its effectiveness in monitoring the considered timing metrics and to promptly intercept a subtle timing misbehavior beyond end-to-end execution scope in a representative autonomous driving stack.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4414663995",
    "type": "article"
  },
  {
    "title": "Runtime Fault Localization in Deep Neural Network Accelerators",
    "doi": "https://doi.org/10.1145/3770920",
    "publication_date": "2025-10-08",
    "publication_year": 2025,
    "authors": "Wei-Kai Liu; Jonti Talukdar; Benjamin Tan; Krishnendu Chakrabarty",
    "corresponding_authors": "",
    "abstract": "Systolic arrays are a popular choice for accelerating deep neural networks (DNNs) due to their inherent parallelism and efficient data reuse. However, ensuring the reliability of these DNN accelerators is crucial, as hardware faults can significantly degrade inferencing accuracy. Because systolic arrays utilize a large number of processing elements (PEs) for parallel processing, dataflow involving faulty PEs is especially of concern. Error propagation through PEs can reduce inferencing accuracy for DNN workloads. Although fault detection and repair techniques have been proposed to enhance the robustness of systolic arrays, fault localization remains an open problem. We propose a fault tolerance framework including run-time based fault detection and fault localization, both leveraging functional data to generate checksums on-the-fly. This approach enables error detection and localization during normal operation, avoiding the need for dedicated test patterns or additional downtime. Experimental evaluation shows that the proposed fault localization architecture incurs an area overhead less than 2% for a 256 × 256 systolic array. In simulations, the proposed method achieves 100% fault detection and localization in a 256 × 256 systolic array.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4414934603",
    "type": "article"
  },
  {
    "title": "C-CIM: A Multi-Mode Convolution-Capable SRAM-CIM",
    "doi": "https://doi.org/10.1145/3769859",
    "publication_date": "2025-10-10",
    "publication_year": 2025,
    "authors": "Ruoxian Yang; 新太郎 中居; Mei Wen; J. Deng; Yi Wen; Junzhong Shen; Bin Liang; Tianyu Wang; Zhaoyan Shen; Zili Shao",
    "corresponding_authors": "",
    "abstract": "SRAM is widely used in computing-in-memory (CIM) neural network accelerators because of its relatively mature technology and good compatibility with complementary metal oxide semiconductor logic process. Digital SRAM-CIM is favored by researchers because of its stability and accuracy. However, the current digital SRAM-CIM macro only supports the weight-stationary dataflows, which means the repeated movement of graph data. Some special deep neural network layers, such as depth-wise, make the utilization of computing resources inside CIM low. To overcome these problems, we propose C-CIM, which can switch between input-stationary and weight-stationary dataflows and support matrix multiplication as well as convolution operations with multiple mainstream convolution kernel sizes (1 × 1, 3 × 3, 5 × 5 and 7 × 7). The C-CIM achieves an average performance of 27.31TOPS/W@8b at a frequency of 1GHz. Experimental results show that our proposed SRAM-CIM successfully outperforms baseline in terms of performance optimization, achieving up to 7.6 × performance speedup and up to 86.84% reduction in activation relocation.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4415028150",
    "type": "article"
  },
  {
    "title": "Advanced And-Inverter Graph Decomposition Technique for Reducing Circuit Complexity",
    "doi": "https://doi.org/10.1145/3771280",
    "publication_date": "2025-10-10",
    "publication_year": 2025,
    "authors": "Mohamed Nadeem; L.O. Muller; Chandan Kumar Jha; Rolf Drechsler",
    "corresponding_authors": "",
    "abstract": "In the field of Electronic Design Automation (EDA), managing circuit complexity is a crucial task for efficient circuit verification, testing, and optimization. Increasing design complexity presents challenges for tasks such as formal verification, fault detection, and circuit optimization. Therefore, reducing circuit complexity becomes crucial in improving the efficiency and scalability of these tasks. These circuits are typically represented as graphs. In the field of parameterized complexity, CutWidth (CW) and TreeWidth (TW) are well-studied decomposition techniques that have been used in analyzing graph algorithms. In this paper, we introduce the TW decomposition technique to the field of EDA for the first time and demonstrate its impact on reducing the circuit complexity of circuits. Additionally, we present a new decomposition technique that combines both decompositions, resulting in a further reduction in circuit complexity. Furthermore, we present experimental results comparing complexity upper bounds from various decompositions to highlight the efficacy of our approach on the ISCAS’85 and EPFL benchmark circuits. Our results show that our decomposition technique outperforms the complexity upper bounds of CW by 90.16 × and the complexity upper bounds of TW by 9.34 × for the ISCAS’85 benchmarks. Additionally, it outperforms the complexity upper bounds of CW by 1986.37 × and the complexity upper bounds of TW by 94.13 × for the EPFL benchmarks. Finally, to demonstrate the applicability of the decomposition techniques in solving various EDA problems, we propose a new Formal Verification (FV) approach that leverages these techniques to provide an upper bound for the verification process. We also conduct an experimental evaluation on the ITC’99 , MCNC’91 , and VHDL Library of Arithmetic Units ( ELAU ) benchmark circuits, adder circuits of various sizes (up to 3072-bit width), and Genmul multipliers of different sizes (up to 10×10), to demonstrate the scalability of our approach.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4415028235",
    "type": "article"
  },
  {
    "title": "A High Efficient and Scalable Obstacle-Avoiding VLSI Global Routing Flow",
    "doi": "https://doi.org/10.1145/3769005",
    "publication_date": "2025-10-13",
    "publication_year": 2025,
    "authors": "Junhao Guo; Hongxin Kong; Lang Feng",
    "corresponding_authors": "",
    "abstract": "Routing is a crucial step in the VLSI design flow. With advancements in manufacturing technology, more constraints have emerged in design rules, particularly regarding obstacles during routing, leading to increased routing complexity. Unfortunately, many global routers struggle to generate efficient obstacle-free solutions due to the lack of scalable obstacle-avoiding tree generation methods and the capability to handle modern designs with complex obstacles and nets. In this work, we propose an efficient obstacle-aware global routing flow for VLSI designs with obstacles. The flow includes a rule-based obstacle-avoiding rectilinear Steiner minimal tree (OARSMT) algorithm during the tree generation phase. This algorithm is both scalable and fast, providing tree topologies avoiding obstacles in the early stage globally. With its guidance, in the later stages, the OARSMT-guided and obstacle-aware sparse maze routing are proposed to further minimize obstacle violations and reduce overflow costs. Compared to previously advanced methods on the benchmark with obstacles, our approach successfully eliminates obstacle violations and reduces wirelength and overflow cost, while sacrificing only a limited number of via counts and runtime overhead.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4415104276",
    "type": "article"
  },
  {
    "title": "You Only Need Non-hotspot: An Unsupervised Training-Free Method for Layout Hotspot Detection",
    "doi": "https://doi.org/10.1145/3771767",
    "publication_date": "2025-10-13",
    "publication_year": 2025,
    "authors": "Silin Chen; Kangjian Di; Yibo Huang; Binwu Zhu; Ningmu Zou",
    "corresponding_authors": "",
    "abstract": "Recent advances in deep learning-based layout hotspot detection have made remarkable progress in identifying potential defect patterns at early design stages. However, most existing methods rely on supervised learning, which requires manual identification of pre-defined hotspots and leads to considerable labeling effort. Moreover, design houses often struggle to obtain a sufficient number of labeled hotspot samples, limiting the applicability and scalability of such methods. In this article, we introduce a novel approach, termed you only need non-hotspot (YONN), which to the best of our knowledge, is the first unsupervised and training-free framework for layout hotspot detection. The proposed method mitigates the dependence on labeled hotspot data by leveraging memorized prototypes and a query-based inference mechanism. Specifically, YONN employs a CNN-based prototype generation network to extract multi-scale, fine-grained representations of layouts. During inference, a combination of shape-aware and topology-aware query mechanisms facilitates precise pixel-wise matching between test layout and memorized prototypes. To further enhance YONN’s efficiency and scalability, we propose a prototype sampling strategy that integrates density-based clustering techniques, significantly reducing the scale of the prototypes. Experimental results indicate that YONN achieves performance within 10% of leading state-of-the-art supervised learning methods, despite operating in a fully unsupervised setting without access to hotspot data. As an optional extension, YONN surpasses existing state-of-the-art approaches using only 30% hotspot labels. Notably, YONN is a training-free framework that enables on-the-fly adaptation by directly incorporating novel samples into the prototype bank, thereby supporting efficient and scalable learning within design for manufacturability workflows.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4415104302",
    "type": "article"
  },
  {
    "title": "InterAxNN: Reconfigurable and Approximate in-Memory Processing Accelerator for Ultra-Low-Power Binary Neural Network Inference in Intermittently Powered Systems",
    "doi": "https://doi.org/10.1145/3771845",
    "publication_date": "2025-10-13",
    "publication_year": 2025,
    "authors": "Arnab Raha; Sandeep Krishna Thirumala; Sumeet Kumar Gupta; Vijay Raghunathan",
    "corresponding_authors": "",
    "abstract": "In this work, we propose InterAxNN , an energy-aware approximate hardware architecture to perform vector-matrix multiplications in the binary precision regime for energy-constrained intermittently powered systems (IPS). In contrast to existing XNOR multiply-and-accumulate (MAC) operations implemented widely for binary neural networks (BNNs), we design a novel reconfigurable XNOR-MAC and AND-MAC memory macro to perform approximate binary precision operations, targeted for systems with extreme energy constraints. The proposed macro design is integrated with the ability to modify the MAC mode during run-time depending on instantaneous energy and power transients. We utilize the unique attributes of ferroelectric transistors (FeFETs) to implement the proposed ultra-low power BNN engine performing in-memory computing for artificial intelligence (AI) workloads. Subsequently, we leverage the quality configurable compute-in-memory-based hardware accelerator to implement InterAxNN based on a TI MSP430-based microcontroller. We evaluate the proposed InterAxNN concerning two baselines: (a) standard von Neumann computing architecture-based-microcontroller platform (MCU), and (b) MCU with a state-of-the-art low energy accelerator (MCU+LEA), and observe significant performance and energy benefits. Experimental results performed using a TI MSP430FR5379 IPS system show 448 × -581 × uplift in forward progress for 2%-8% accuracy loss for MNIST, 4%-5% accuracy loss for EMNIST, and 1%-4% reduction in accuracy for QMNIST, respectively, using MLP on a MCU+LEA platform with Unified NVM architecture. The AND-MAC mode in InterAxNN results in 91 × -127 × amount of additional forward progress over XNOR-MAC for 1%-2%, 4%-19%, and 1%-5% higher quality degradation for MNIST, EMNIST, and QMNIST, respectively.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4415104332",
    "type": "article"
  },
  {
    "title": "Structurally Secure Obfuscation: Assessing and Mitigating Structural Vulnerabilities in Circuits Obfuscation",
    "doi": "https://doi.org/10.1145/3772062",
    "publication_date": "2025-10-17",
    "publication_year": 2025,
    "authors": "Armin Darjani; Nima Kavand; Zhentao Han; Akash Kumar",
    "corresponding_authors": "",
    "abstract": "Because of the globalization of IC manufacturing and to protect IP integrity and confidentiality, circuit obfuscation techniques have been developed. These methods secure the circuit through obfuscation approaches. Recently, advanced machine learning (ML)-based structural attacks have been introduced that employ the structure of the circuit to reverse the obfuscation mechanism. These attacks use ML-based approaches to analyze and neutralize obfuscation schemes without requiring unlocked functional circuits, posing a significant challenge to IP security. To counter ML-based attacks, in this paper, we first analyze the sources of structural leakages of the interconnect obfuscation technique, one of the most robust IP protection mechanisms. We conduct a first-of-its-kind analysis of the circuit’s netlist graph, obfuscated using interconnect obfuscation, to evaluate its robustness against link prediction techniques. Based on our analysis, we introduce a security assessment tool that evaluates the strength of the obfuscation technique in omitting structural leakages that lead to the success of ML-based attacks. Our assessment tool reveals that previous obfuscation methods fall short of achieving their intended security levels. This leads to our second contribution, which is proposing ML-SafeConnect, an interconnect obfuscation technique that protects the obfuscated substructures by completely eliminating distance-based structural leakages. Using our assessment tool and state-of-the-art ML-based attack, we demonstrate that our obfuscation mechanism surpasses previous interconnect obfuscation techniques in preventing structural leakages. We show that ML-SafeConnect completely thwarts ML-based attacks for all benchmark circuits by decreasing the accuracy of state-of-the-art attacks to below 50%.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4415300753",
    "type": "article"
  },
  {
    "title": "Introduction to Special Issue on Large Language Models for Electronic System Design Automation",
    "doi": "https://doi.org/10.1145/3746636",
    "publication_date": "2025-10-18",
    "publication_year": 2025,
    "authors": "Robert P. Dick; Hammond Pearce; Li Shang; Fan Yang",
    "corresponding_authors": "",
    "abstract": "Large Language Models are having a substantial impact on electronic design automation in areas ranging from hardware architecture to verification and optimization. The special issue provides a snapshot of work on this topic. This introduction describes and provides context for the research area, describes the organization of the special issue, and provides terse summaries of each of its papers.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4415311931",
    "type": "article"
  },
  {
    "title": "EXFI",
    "doi": "https://doi.org/10.1145/296333.296351",
    "publication_date": "1998-10-01",
    "publication_year": 1998,
    "authors": "Alfredo Benso; P. Prinetto; Maurizio Rebaudengo; M. Sonza Reorda",
    "corresponding_authors": "",
    "abstract": "Evaluating the faulty behavior of low-cost embedded microprocessor-based boards is an increasingly important issue, due to their adoption in many safety critical systems. The architecture of a complete Fault Injection environment is proposed, integrating a module for generating a collapsed list of faults, and another for performing their injection and gathering the results. To address this issue, the paper describes a software-implemented Fault Injection approach based on the Trace Exception Mode available in most microprocessors. The authors describe EXFI, a prototypical system implementing the approach, and provide data about some sample benchmark applications. The main advantages of EXFI are the low cost, the good portability, and the high efficiency",
    "cited_by_count": 26,
    "openalex_id": "https://openalex.org/W2009194836",
    "type": "article"
  },
  {
    "title": "Modeling reactive systems in Java",
    "doi": "https://doi.org/10.1145/296333.296334",
    "publication_date": "1998-10-01",
    "publication_year": 1998,
    "authors": "Claudio Passerone; Claudio Sansoè; Luciano Lavagno; Rick McGeer; James Martin; Roberto Passerone; Alberto Sangiovanni‐Vincentelli",
    "corresponding_authors": "",
    "abstract": "We present an application of the Java TM programming language to specify and implement reactive real-time systems. We have developed and tested a collection of classes and methods to describe concurrent modules and their asynchronous communication by means of signals. The control structures are closely patterned after those of the synchronous language Esterel , succinctly describing concurrency, sequencing and preemption. We show the user-friendliness and efficiency of the proposed technique by using an example from the automotive domain.",
    "cited_by_count": 26,
    "openalex_id": "https://openalex.org/W2162357850",
    "type": "article"
  },
  {
    "title": "CMAPS",
    "doi": "https://doi.org/10.1145/329458.329465",
    "publication_date": "2000-01-01",
    "publication_year": 2000,
    "authors": "Pao‐Ann Hsiung",
    "corresponding_authors": "Pao‐Ann Hsiung",
    "abstract": "Currently, a lot of research is devoted to system design , and little work is done on requirements analysis . Besides going from specification to design, one of our main objectives is to show how an application problem can be transformed into specifications. Working from the hardware-software codesign perspective, a system is designed starting from an application problem itself, rather than the detailed behavioral specifications. Given an application problem specified as a directed acyclic graph of elementary problems, a hardware-software solution is derived such that the synthesized software, a parallel pseudoprogram, can be scheduled and executed on the synthesized software, a parallel pseudoprogram, can be scheduled and executed on the synthesized hardware, a set of system-level parallel computer specifications, with heuristically optimal performance. This is known as system-level cosynthesis of application-oriented general-purpose parallel systems for which a novel methodology called Cosynthesis Methodology for Applicaton-Oriented Parallel Systems (CMAPS), is presented. Since parallel programs and multiprocessor architectures are largely interdependent, CMAPS explores the relationship between hardware designs and software algorithms by interleaving the modeling phases and the synthesis phases of both hardware and software. High scalability in terms of problem complexity and easy upgradability to new technologies are achieved through modularization of the input problem specification, of the software algorithms, and of the hardware subsystem models. The work presented in this paper will be beneficial to designers of general-purpose parallel computer systems which must be oriented toward solving some user-specified problem such as the global controller of an industry automation process or a multiprocessor video server. Some application examples are given to illustrate various codesign phases of CMAPS and its feasibility.",
    "cited_by_count": 25,
    "openalex_id": "https://openalex.org/W2056533513",
    "type": "article"
  },
  {
    "title": "Processor modeling and code selection for retargetable compilation",
    "doi": "https://doi.org/10.1145/383251.383252",
    "publication_date": "2001-07-01",
    "publication_year": 2001,
    "authors": "Johan Van Praet; D. Lanneer; Werner Geurts; Gert Goossens",
    "corresponding_authors": "",
    "abstract": "Embedded processors in electronic systems typically are tuned to a few applications. Development of processor-specific compilers is prohibitively expensive and, as a result, such compilers, if existing, yield code of an unacceptable quality. To improve this code quality, we developed a processor model that captures the connectivity, the parallelism, and all architectural peculiarities of an embedded processor. We also implemented a retargetable and optimizing compiler working on this model. We present the graph-based processor model, and formally define the code generation task as binding the intermediate representation of an application to this model. We also present a new method for code selection, based on this processor model, that is capable of handling directed acyclic graphs instead of trees.",
    "cited_by_count": 24,
    "openalex_id": "https://openalex.org/W1995248109",
    "type": "article"
  },
  {
    "title": "Cluster-aware iterative improvement techniques for partitioning large VLSI circuits",
    "doi": "https://doi.org/10.1145/504914.504918",
    "publication_date": "2002-01-01",
    "publication_year": 2002,
    "authors": "Shantanu Dutt; Wenyong Deng",
    "corresponding_authors": "",
    "abstract": "Move-based iterative improvement partitioning (IIP) methods, such as the Fiduccia-Mattheyses (FM) algorithm [Fidducia and Mattheyses 1982] and Krishnamurthy's Look-Ahead (LA) algorithm [Krishnamurthy 1984], are widely used in VLSI CAD applications, largely due to their time efficiency and ease of implementation. This class of algorithms is of the \"local/greedy improvement\" type, and they generate relatively high-quality results for small and medium-size circuits. However, as VLSI circuits become larger, these algorithms suffer a rapid deterioration in solution quality. We propose new IIP methods CLIP and CDIP that select cells to move with a view to moving clusters that straddle the two subsets of a partition, into one of the subsets. The new algorithms significantly improve partition quality while preserving the advantage of time efficiency. Experimental results on 25 medium to large-size ACM/SIGDA benchmark circuits show up to 70% improvement over FM in mincut, and average mincut improvements of about 35% over all circuits and 47% over large circuits. They also outperform state-of-the-art non-IIP techniques, the quadratic-programming-based method Paraboli [Reiss et al. 1994] and the spectral partitioner MELO [Alpert and Yao 1995], by about 17% and 23%, respectively, with less CPU time. This demonstrates the potential of sophisticated IIP algorithms in dealing with the increasing complexity of emerging VLSI circuits. We also compare CLIP and CDIP to hMetis [Karypis et al. 1997], one of the best of the recent state-of-the-art partitioners that are based on the multilevel paradigm (others include ML c [Alpert et al. 1997] and LSR/MFFS [Cong et al. 1997]). The results show that one scheme of hMetis is 8% worse than CLIP/CDIP and the other two schemes are only 2--4% better. However, CLIP/CDIP have advantages over hMetis and other multilevel partitioners that outweigh these minimal mincut improvements. The first is much faster times-to-solution (for example, one of our best schemes CLIP-LA2 is 6.4 and 11.75 times faster than the two best hMetis schemes) and much better scalability with circuit size (e.g., for the largest circuit with about 162K nodes, CLIP-LA2 is 10.4 and and 21.5 times faster and obtains better solution qualities than the two best hMetis schemes). Second, CLIP/CDIP are \"flat\" partitioners, while multilevel techniques perform a sequence of node clustering/coarsening before partitioning the circuit. In complex placement applications such as timing-driven placement in the presence of multiple constraints, such circuit coarsening can hide crucial information needed for good-quality solutions, thus making the partitioning process oblivious to them. This, however, is not a problem with flat partitioners like CLIP/CDIP that can take all important parameters into account while partitioning. All these advantages make CLIP/CDIP suitable for use in complex physical design problems for large, deep-submicron VLSI circuits.",
    "cited_by_count": 24,
    "openalex_id": "https://openalex.org/W2042549343",
    "type": "article"
  },
  {
    "title": "High-level library mapping for memories",
    "doi": "https://doi.org/10.1145/348019.348297",
    "publication_date": "2000-07-01",
    "publication_year": 2000,
    "authors": "Pradip K. Jha; Nikil Dutt",
    "corresponding_authors": "",
    "abstract": "We present high-level library mapping, a technique that synthesizes a source memory module from a library of target memory modules. In this paper, we define the problem of high-level library mapping for memories, identify and solve the three subproblems associated with this task, and finally combine these solutions into a suite of two memory mapping algorithms. Experimental results on a number of memory-intensive designs demonstrate that our memory mapping approach generates a wide variety of cost-effective designs, often counter-intuitive ones, based on a user-given cost function, the target library, and the mapping algorithm used.",
    "cited_by_count": 24,
    "openalex_id": "https://openalex.org/W2080653501",
    "type": "article"
  },
  {
    "title": "Run-time performance optimization of an FPGA-based deduction engine for SAT solvers",
    "doi": "https://doi.org/10.1145/605440.605444",
    "publication_date": "2002-10-01",
    "publication_year": 2002,
    "authors": "Andreas Dandalis; Viktor K. Prasanna",
    "corresponding_authors": "",
    "abstract": "FPGAs are a promising technology for accelerating SAT solvers. Besides their high density, fine granularity, and massive parallelism, FPGAs provide the opportunity for run-time customization of the hardware based on the given SAT instance. In this article, a parallel deduction engine is proposed for backtrack search algorithms. The performance of the deduction engine is critical to the overall performance of the algorithm because, for any moderate SAT instance, millions of implications are derived. We propose a novel approach in which p , the amount of parallelization of the engine, is fine-tuned during problem solving in order to optimize performance. Not only the hardware is initially customized based on the input instance, but it is also dynamically modified in terms of p based on the knowledge gained during solving the SAT instance. Compared with conventional deduction engines that correspond to p = 1, we demonstrate speedups in the range of 2.87 to 5.44 for several SAT instances.",
    "cited_by_count": 24,
    "openalex_id": "https://openalex.org/W2091189496",
    "type": "article"
  },
  {
    "title": "BIST and production testing of ADCs using imprecise stimulus",
    "doi": "https://doi.org/10.1145/944027.944035",
    "publication_date": "2003-10-01",
    "publication_year": 2003,
    "authors": "K.L. Parthasarathy; T. Kuyel; D.L. Price; Le Jin; Degang Chen; R.L. Geiger",
    "corresponding_authors": "",
    "abstract": "A new approach for testing mixed-signal circuits based upon using imprecise stimuli is introduced. Unlike most existing Built-In Self-Test (BIST) and production test approaches that require excitation signals that are at least 3 bits or more linear than the Device-Under-Test (DUT), the proposed approach can work with stimuli that are several bits less linear than the DUT. This dramatically reduces the requirements on stimulus generation for BIST applications and offers potential for using inexpensive signal generators in production test, or for testing DUTs that have a linearity performance exceeding that of the available test equipment. As a proof of concept, a histogram-based algorithm for linearity testing for Analog-to-Digital Converters (ADCs) has been proposed. It can estimate the Integral Nonlinearity (INL) and Differential Nonlinearity (DNL) of an n -bit ADC by using a ramp signal of much less than n -bit linearity and a shifted version of the same nonlinear ramp as excitation. The performance of the algorithm is comparable to that of the traditional method which uses ( n + 3)-bits or a decade more linear input signals. Complete algorithm description, extensive simulation results and experimental results obtained from using a production tester on commercially available ICs are presented to validate the potential of this algorithm.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W1973094521",
    "type": "article"
  },
  {
    "title": "A scheduling algorithm for optimization and early planning in high-level synthesis",
    "doi": "https://doi.org/10.1145/1044111.1044115",
    "publication_date": "2005-01-01",
    "publication_year": 2005,
    "authors": "Seda Öǧrenci Memik; Ryan Kastner; Elaheh Bozorgzadeh; Majid Sarrafzadeh",
    "corresponding_authors": "",
    "abstract": "Complexities of applications implemented on embedded and programmable systems grow with the advances in capacities and capabilities of these systems. Mapping applications onto them manually is becoming a very tedious task. This draws attention to using high-level synthesis within design flows. Meanwhile, it is essential to provide a flexible formulation of optimization objectives as well as to perform efficient planning for various design objectives early on in the design flow. In this work, we address these issues in the context of data flow graph (DFG) scheduling, which is an essential element within the high-level synthesis flow. We present an algorithm that schedules a chain of operations with data dependencies among consecutive operations at a single step. This local problem is repeated to generate the schedule for the whole DFG. The local problem is formulated as a maximum weight noncrossing bipartite matching. We use a technique from the computational geometry domain to solve the matching problem. This technique provides a theoretical guarantee on the solution quality for scheduling a single chain of operations. Although still being local, this provides a relatively wider perspective on the global scheduling objectives. In our experiments we compared the latencies obtained using our algorithm with the optimal latencies given by the exact solution to the integer linear programming (ILP) formulation of the problem. In 9 out of 14 DFGs tested, our algorithm found the optimal solution, while generating latencies comparable to the optimal solution in the remaining five benchmarks. The formulation of the objective function in our algorithm provides flexibility to incorporate different optimization goals. We present examples of how to exploit the versatility of our algorithm with specific examples of objective functions and experimental results on the ability of our algorithm to capture these objectives efficiently in the final schedules.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W2132357315",
    "type": "article"
  },
  {
    "title": "Incremental hierarchical memory size estimation for steering of loop transformations",
    "doi": "https://doi.org/10.1145/1278349.1278363",
    "publication_date": "2007-09-01",
    "publication_year": 2007,
    "authors": "Qubo Hu; Per Gunnar Kjeldsberg; Arnout Vandecappelle; M. Palkovic; Francky Catthoor",
    "corresponding_authors": "",
    "abstract": "Modern embedded multimedia and telecommunications systems need to store and access huge amounts of data. This becomes a critical factor for the overall energy consumption, area, and performance of the systems. Loop transformations are essential to improve the data access locality and regularity in order to optimally design or utilize a memory hierarchy. However, due to abstract high-level cost functions, current loop transformation steering techniques do not take the memory platform sufficiently into account. They usually also result in only one final transformation solution. On the other hand, the loop transformation search space for real-life applications is huge, especially if the memory platform is still not fully fixed. Use of existing loop transformation techniques will therefore typically lead to suboptimal end-products. It is critical to find all interesting loop transformation instances. This can only be achieved by performing an evaluation of the effect of later design stages at the early loop transformation stage. This article presents a fast incremental hierarchical memory-size requirement estimation technique. It estimates the influence of any given sequence of loop transformation instances on the mapping of application data onto a hierarchical memory platform. As the exact memory platform instantiation is often not yet defined at this high-level design stage, a platform-independent estimation is introduced with a Pareto curve output for each loop transformation instance. Comparison among the Pareto curves helps the designer, or a steering tool, to find all interesting loop transformation instances that might later lead to low-power data mapping for any of the many possible memory hierarchy instances. Initially, the source code is used as input for estimation. However, performing the estimation repeatedly from the source code is too slow for large search space exploration. An incremental approach, based on local updating of the previous result, is therefore used to handle sequences of different loop transformations. Experiments show that the initial approach takes a few seconds, which is two orders of magnitude faster than state-of-the-art solutions but still too costly to be performed interactively many times. The incremental approach typically takes just a few milliseconds, which is another two orders of magnitude faster than the initial approach. This huge speedup allows us for the first time to handle real-life industrial-size applications and get realistic feedback during loop transformation exploration.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W2002918753",
    "type": "article"
  },
  {
    "title": "Efficient simulation of critical synchronous dataflow graphs",
    "doi": "https://doi.org/10.1145/1255456.1255458",
    "publication_date": "2007-08-17",
    "publication_year": 2007,
    "authors": "Chia‐Jui Hsu; Ming-Yung Ko; Shuvra S. Bhattacharyya; Suren Ramasubbu; José Luis Pino",
    "corresponding_authors": "",
    "abstract": "System-level modeling, simulation, and synthesis using electronic design automation (EDA) tools are key steps in the design process for communication and signal processing systems, and the synchronous dataflow (SDF) model of computation is widely used in EDA tools for these purposes. Behavioral representations of modern wireless communication systems typically result in critical SDF graphs : These consist of hundreds of components (or more) and involve complex intercomponent connections with highly multirate relationships (i.e., with large variations in average rates of data transfer or component execution across different subsystems). Simulating such systems using conventional SDF scheduling techniques generally leads to unacceptable simulation time and memory requirements on modern workstations and high-end PCs. In this article, we present a novel simulation-oriented scheduler (SOS) that strategically integrates several techniques for graph decomposition and SDF scheduling to provide effective, joint minimization of time and memory requirements for simulating critical SDF graphs. We have implemented SOS in the advanced design system (ADS) from Agilent Technologies. Our results from this implementation demonstrate large improvements in simulating real-world, large-scale, and highly multirate wireless communication systems (e.g., 3GPP, Bluetooth, 802.16e, CDMA 2000, XM radio, EDGE, and Digital TV).",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W2036943761",
    "type": "article"
  },
  {
    "title": "Efficient and scalable compiler-directed energy optimization for realtime applications",
    "doi": "https://doi.org/10.1145/1255456.1255464",
    "publication_date": "2007-08-17",
    "publication_year": 2007,
    "authors": "Po-Kuan Huang; Soheil Ghiasi",
    "corresponding_authors": "",
    "abstract": "With continuing shrinkage of technology feature sizes, the share of leakage in total energy consumption of digital systems continues to grow. Coordinated supply voltage and body bias throttling enables the compiler to better optimize the total energy consumption of the system in future technology nodes. We present a compilation technique that targets realtime applications running on embedded processors with combined dynamic voltage scaling (DVS) and adaptive body biasing (ABB) capabilities. Considering the delay and energy penalty of switching between operating modes of the processor, our compiler judiciously inserts mode-switch instructions in selected locations of the code and generates executable binary that is guaranteed to meet the deadline constraint. More importantly, our algorithm runs very fast and comes reasonably close to the theoretical limit of energy optimization using DVS+ABB. At 65nm technology, we improve the energy dissipation of the generated code by an average of 33.20% under deadline constraints. While our technique's improvement in energy dissipation over conventional DVS is marginal (6.91%) at 130nm, the average improvement continues to grow to 13.19%, 22.97%, and 33.21% for 90nm, 65nm, and 45nm technology nodes, respectively. Compared to a recent ILP-based competitor, we improve the runtime by more than three orders of magnitude, while producing improved results.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W2036067783",
    "type": "article"
  },
  {
    "title": "Exploring time/resource trade-offs by solving dual scheduling problems with the ant colony optimization",
    "doi": "https://doi.org/10.1145/1278349.1278359",
    "publication_date": "2007-09-01",
    "publication_year": 2007,
    "authors": "Gang Wang; Wenrui Gong; Brian DeRenzi; Ryan Kastner",
    "corresponding_authors": "",
    "abstract": "Design space exploration during high-level synthesis is often conducted through ad hoc probing of the solution space using some scheduling algorithm. This is not only time consuming but also very dependent on designer's experience. We propose a novel design exploration method that exploits the duality of time- and resource-constrained scheduling problems. Our exploration automatically constructs a time/area tradeoff curve in a fast, effective manner. It is a general approach and can be combined with any high-quality scheduling algorithm. In our work, we use the max-min ant colony optimization technique to solve both time- and resource-constrained scheduling problems. Our algorithm provides significant solution-quality savings (average 17.3% reduction of resource counts) with similar runtime compared to using force-directed scheduling exhaustively at every time step. It also scales well across a comprehensive benchmark suite constructed with classic and real-life samples.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W2130291762",
    "type": "article"
  },
  {
    "title": "Custom topology rotary clock router with tree subnetworks",
    "doi": "https://doi.org/10.1145/1529255.1529266",
    "publication_date": "2009-05-01",
    "publication_year": 2009,
    "authors": "Barış Taşkın; Joseph DeMaio; Owen Farell; Michael Hazeltine; Ryan Ketner",
    "corresponding_authors": "",
    "abstract": "Increasing demands on computing power have spurred the development of faster, higher-density Integrated Circuits (ICs), compounding power and complexity concerns in design budgets. The clock distribution network is a significant contributor to such power and complexity concerns. Resonant rotary clocking is a relatively new technology that realizes several benefits over current clocking methods, including power, frequency, and variation tolerance, yet lacks the automation tools to promote increased use. Towards this end, an automated rotary clock routing methodology is presented that generates custom topology rotary ring routes with tree subnetworks. In addition to the benefits of adiabatic clocking, the presented custom topology router permits 38.6% shorter wirelengths on average for register tapping, compared to traditional prescribed skew, binary tree routing.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W1986100061",
    "type": "article"
  },
  {
    "title": "Model checking sequential software programs via mixed symbolic analysis",
    "doi": "https://doi.org/10.1145/1455229.1455239",
    "publication_date": "2009-01-01",
    "publication_year": 2009,
    "authors": "Zijiang Yang; Chao Wang; Aarti Gupta; Franjo Ivančić",
    "corresponding_authors": "",
    "abstract": "We present an efficient symbolic search algorithm for software model checking. Our algorithms perform word-level reasoning by using a combination of decision procedures in Boolean and integer and real domains, and use novel symbolic search strategies optimized specifically for sequential programs to improve scalability. Experiments on real-world C programs show that the new symbolic search algorithms can achieve several orders-of-magnitude improvements over existing methods based on bit-level (Boolean) reasoning.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2056798016",
    "type": "article"
  },
  {
    "title": "Word-length selection for power minimization via nonlinear optimization",
    "doi": "https://doi.org/10.1145/1529255.1529261",
    "publication_date": "2009-05-01",
    "publication_year": 2009,
    "authors": "Jonathan Clarke; George A. Constantinides; Peter Y. K. Cheung",
    "corresponding_authors": "",
    "abstract": "This article describes the first method for minimizing the dynamic power consumption of a Digital Signal Processing (DSP) algorithm implemented on reconfigurable hardware via word-length optimization. Fast models for estimating the power consumption of the arithmetic components and the routing power of these algorithm implementations are used within a constrained nonlinear optimization formulation that solves a relaxed version of word-length optimization. Tight lower and upper bounds on the cost of the integer word-length problem can be obtained using the proposed solution, with typical upper bounds being 2.9% and 5.1% larger than the lower bounds for area and power consumption, respectively. Heuristics can then use the upper bound as a starting point from which to get even closer to the known lower bound. Results show that power consumption can be improved by up to 40% compared to that achieved when using simple word-length selection techniques, and further comparisons are made between the minimization of different cost functions that give insight into the advantages offered by multiple word-length optimization.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W1983783918",
    "type": "article"
  },
  {
    "title": "Logic synthesis and circuit customization using extensive external don't-cares",
    "doi": "https://doi.org/10.1145/1754405.1754411",
    "publication_date": "2010-05-01",
    "publication_year": 2010,
    "authors": "Kai-Hui Chang; Valeria Bertacco; Igor L. Markov; Alan Mishchenko",
    "corresponding_authors": "",
    "abstract": "Traditional digital circuit synthesis flows start from an HDL behavioral definition and assume that circuit functions are almost completely defined, making don't-care conditions rare. However, recent design methodologies do not always satisfy these assumptions. For instance, third-party IP blocks used in a system-on-chip are often overdesigned for the requirements at hand. By focusing only on the input combinations occurring in a specific application, one could resynthesize the system to greatly reduce its area and power consumption. Therefore we extend modern digital synthesis with a novel technique, called SWEDE, that makes use of extensive external don't-cares. In addition, we utilize such don't-cares present implicitly in existing simulation-based verification environments for circuit customization. Experiments indicate that SWEDE scales to large ICs with half-million input vectors and handles practical cases well.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2002518192",
    "type": "article"
  },
  {
    "title": "On-chip sensor-driven efficient thermal profile estimation algorithms",
    "doi": "https://doi.org/10.1145/1754405.1754410",
    "publication_date": "2010-05-01",
    "publication_year": 2010,
    "authors": "Yufu Zhang; Ankur Srivastava; Mohamed Zahran",
    "corresponding_authors": "",
    "abstract": "This article addresses the problem of chip-level thermal profile estimation using runtime temperature sensor readings. We address the challenges of: (a) availability of only a few thermal sensors with constrained locations (sensors cannot be placed just anywhere); (b) random chip power density characteristics due to unpredictable workloads and fabrication variability. Firstly we model the random power density as a probability density function. Given such statistical characteristics and the runtime thermal sensor readings, we exploit the correlation in power dissipation among different chip modules to estimate the expected value of temperature at each chip location. Our methods are optimal if the underlying power density has Gaussian nature. We give a heuristic method to estimate the chip-level thermal profile when the underlying randomness is non-Gaussian. An extension of our method has also been proposed to address the dynamic case. Several speedup strategies are carefully investigated to improve the efficiency of the estimation algorithm. Experimental results indicated that, given only a few thermal sensors, our method can generate highly accurate chip-level thermal profile estimates within a few milliseconds.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2032108441",
    "type": "article"
  },
  {
    "title": "Timing Analysis of System Initialization and Crash Recovery for a Segment-Based Flash Translation Layer",
    "doi": "https://doi.org/10.1145/2159542.2159546",
    "publication_date": "2012-04-01",
    "publication_year": 2012,
    "authors": "Chin-Hsien Wu; Hsing-Hung Lin",
    "corresponding_authors": "",
    "abstract": "Recently, the capacity of flash-memory storage systems has grown rapidly, and flash-memory technology has advanced along with the wave of consumer electronics and embedded systems. In order to properly manage product cost and initialization performance, vendors face serious challenges in system design and analysis. Thus, the timing analysis of system initialization and crash recovery for a segment-based flash translation layer has become an important research topic. This article focuses on system initialization, crash recovery, and timing analysis. The timing analysis of system initialization involves the relationship between the size of the main memory and the system initialization time. The timing analysis of crash recovery explains the worst case recovery time. The experiments in this study show that the timing analysis of system initialization and crash recovery can be applied to the segment-based flash translation layer.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2090591596",
    "type": "article"
  },
  {
    "title": "Register file partitioning and recompilation for register file power reduction",
    "doi": "https://doi.org/10.1145/1754405.1754409",
    "publication_date": "2010-05-01",
    "publication_year": 2010,
    "authors": "Xuan Guan; Yunsi Fei",
    "corresponding_authors": "",
    "abstract": "Register files in modern embedded processors contribute a substantial budget in the energy consumption due to their large switching capacitance and long working time. For some embedded processors, on average 25% of registers account for 83% of register file accessing time. This motivates us to partition the register file into hot and cold regions, with the most frequently used registers placed in the hot region, and the rarely accessed ones in the cold region. We employ the bit-line splitting and drowsy register cell techniques to reduce the overall register file accessing power. We propose a novel approach to partition the register in a way that can achieve the largest power saving. We formulate the register file partitioning process into a graph partitioning problem, and apply an effective algorithm to obtain the optimal result. We evaluate our algorithm for MiBench and SPEC2000 applications on the SimpleScalar PISA system, and an average saving of 58.3% and 54.4% over the nonpartitioned register file accessing power is achieved. The area overhead is negligible, and the execution time overhead is acceptable (5.5% for MiBench 2.4% for SPEC2000). Further evaluation for MiBench applications is performed on Alpha and X86 system.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2091559310",
    "type": "article"
  },
  {
    "title": "Learning-Based, Fine-Grain Power Modeling of System-Level Hardware IPs",
    "doi": "https://doi.org/10.1145/3177865",
    "publication_date": "2018-02-23",
    "publication_year": 2018,
    "authors": "Dong-Wook Lee; Andreas Gerstlauer",
    "corresponding_authors": "",
    "abstract": "Accurate power and performance models are needed to enable rapid, early system-level analysis and optimization. There is, however, a lack of fast yet fine-grain power models of hardware components at such high levels of abstraction. In this article, we present novel learning-based approaches for extending fast functional simulation models of accelerators and other hardware intellectual property components (IPs) with accurate cycle-, block-, and invocation-level power estimates. Our proposed power modeling approach is based on annotating functional hardware descriptions with capabilities that, depending on observability, allow capturing data-dependent resource, block, or input and output (I/O) activity without a significant loss in simulation speed. We further leverage advanced machine learning techniques to synthesize abstract power models using novel decomposition techniques that reduce model complexities and increase estimation accuracy. Results of applying our approach to various industrial-strength design examples show that our power models can predict cycle-, basic block-, and invocation-level power consumption to within 10%, 9%, and 3% of a commercial gate-level power estimation tool, respectively, all while running at several order of magnitude faster speeds of 1-10Mcycles/sec. Model training and synthesis takes less than 34 minutes in all cases, including up to 30 minutes for training data and trace generation using gate-level simulations.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2793449948",
    "type": "article"
  },
  {
    "title": "Toward Effective Reliability Requirement Assurance for Automotive Functional Safety",
    "doi": "https://doi.org/10.1145/3230620",
    "publication_date": "2018-08-22",
    "publication_year": 2018,
    "authors": "Guoqi Xie; Zhetao Li; Na Yuan; Renfa Li; Keqin Li",
    "corresponding_authors": "",
    "abstract": "Automotive functional safety requirement includes response time and reliability requirements learning from the functional safety standard ISO 26262. These two requirements must be simultaneously satisfied to assure automotive functional safety requirement. However, increasing reliability increases the response time intuitively. This study proposes a method to find the solution with the minimum response time while assuring reliability requirement. Pre-assigning reliability values to unassigned tasks by transferring the reliability requirement of the function to each task is a useful reliability requirement assurance approach proposed in recent years. However, the pre-assigned reliability values in state-of-the-art studies have unbalanced distribution of the reliability of all tasks, thereby resulting in a limited reduction in response time. This study presents the geometric mean-based non-fault-tolerant reliability pre-assignment (GMNRP) and geometric mean-based fault-tolerant reliability pre-assignment (GMFRP) approaches, in which geometric mean-based reliability values are pre-assigned to unassigned tasks. Geometric mean can make the pre-assigned reliability values of unassigned tasks to the central tendency, such that it can distribute the reliability requirements in a more balanced way. Experimental results show that GMNRP and GMFRP can effectively reduce the response time compared with their individual state-of-the-art counterparts.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2888324552",
    "type": "article"
  },
  {
    "title": "Fault-Tolerant Unicast-Based Multicast for Reliable Network-on-Chip Testing",
    "doi": "https://doi.org/10.1145/3243214",
    "publication_date": "2018-11-30",
    "publication_year": 2018,
    "authors": "Dong Xiang; Krishnendu Chakrabarty; Hideo Fujiwara",
    "corresponding_authors": "",
    "abstract": "We present a unified test technique that targets faults in links, routers, and cores of a network-on-chip design based on test sessions. We call an entire procedure, that delivers test packets to the subset of routers/cores, a test session. Test delivery for router/core testing is formulated as two fault-tolerant multicast algorithms. Test packet delivery for routers is implemented as a fault-tolerant unicast-based multicast scheme via the fault-free links and routers that were identified in the previous test sessions to avoid packet corruption. A new fault-tolerant routing algorithm is also proposed for the unicast-based multicast core test delivery in the whole network. Identical cores share the same test set, and they are tested within the same test session. Simulation results highlight the effectiveness of the proposed method in reducing test time.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2905163486",
    "type": "article"
  },
  {
    "title": "Dimension-reducible Boolean functions based on affine spaces",
    "doi": "https://doi.org/10.1145/1929943.1929945",
    "publication_date": "2011-03-01",
    "publication_year": 2011,
    "authors": "Anna Bernasconi; Valentina Ciriani",
    "corresponding_authors": "",
    "abstract": "We define and study a new class of regular Boolean functions called D-reducible. A D-reducible function, depending on all its n input variables, can be studied and synthesized in a space of dimension strictly smaller than n . We show that the D-reducibility property can be efficiently tested, in time polynomial in the representation of f , that is, an initial SOP form of f . A D-reducible function can be efficiently decomposed, giving rise to a new logic form, that we have called DredSOP. This form is shown here to be generally smaller than the corresponding minimum SOP form. Our experiments have also shown that a great number of functions of practical importance are indeed D-reducible, thus validating the overall interest of our approach.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W1975130924",
    "type": "article"
  },
  {
    "title": "Locality-Driven Parallel Static Analysis for Power Delivery Networks",
    "doi": "https://doi.org/10.1145/1970353.1970361",
    "publication_date": "2011-06-01",
    "publication_year": 2011,
    "authors": "Zhiyu Zeng; Zhuo Feng; Peng Li; Vivek Sarin",
    "corresponding_authors": "",
    "abstract": "Large VLSI on-chip Power Delivery Networks (PDNs) are challenging to analyze due to the sheer network complexity. In this article, a novel parallel partitioning-based PDN analysis approach is presented. We use the boundary circuit responses of each partition to divide the full grid simulation problem into a set of independent subgrid simulation problems. Instead of solving exact boundary circuit responses, a more efficient scheme is proposed to provide near-exact approximation to the boundary circuit responses by exploiting the spatial locality of the flip-chip-type power grids. This scheme is also used in a block-based iterative error reduction process to achieve fast convergence. Detailed computational cost analysis and performance modeling is carried out to determine the optimal (or near-optimal) number of partitions for parallel implementation. Through the analysis of several large power grids, the proposed approach is shown to have excellent parallel efficiency, fast convergence, and favorable scalability. Our approach can solve a 16-million-node power grid in 18 seconds on an IBM p5-575 processing node with 16 Power5+ processors, which is 18.8X faster than a state-of-the-art direct solver.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2060266578",
    "type": "article"
  },
  {
    "title": "Topological Approach to Automatic Symbolic Macromodel Generation for Analog Integrated Circuits",
    "doi": "https://doi.org/10.1145/3015782",
    "publication_date": "2017-03-10",
    "publication_year": 2017,
    "authors": "Guoyong Shi; Hanbin Hu; Shuwen Deng",
    "corresponding_authors": "",
    "abstract": "In the field of analog integrated circuit (IC) design, small-signal macromodels play indispensable roles for developing design insight and sizing reference. However, the subject of automatically generating symbolic low-order macromodels in human readable circuit form has not been well studied. Traditionally, work has been published on reducing full-scale symbolic transfer functions to simpler forms but without the guarantee of interpretability. On the other hand, methodologies developed for interconnect circuits (mainly resistor-capacitor-inductor (RCL) networks) are not suitable for analog ICs. In this work, a topological reduction method is introduced that is able to automatically generate interpretable macromodel circuits in symbolic form; that is, the circuit elements in the compact model maintain analytical relations of the parameters of the original full circuit. This type of symbolic macromodel has several benefits that other traditional modeling methods do not offer: First, reusability, namely that designer need not repeatedly generate macromodels for the same circuit even it is re-sized or re-biased; second, interpretability, namely a designer may directly identify circuit parameters (in the original circuit) that are closely related to the dominant frequency characteristics, such as dc gain, gain/phase margins, and dominant poles/zeros. The effectiveness and computational efficiency of the proposed method have been validated by several operational amplifier (opamp) circuit examples.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2595409684",
    "type": "article"
  },
  {
    "title": "Fast poisson solvers for thermal analysis",
    "doi": "https://doi.org/10.1145/2209291.2209305",
    "publication_date": "2012-06-01",
    "publication_year": 2012,
    "authors": "Haifeng Qian; Sachin S. Sapatnekar; Eren Kursun",
    "corresponding_authors": "",
    "abstract": "Accurate and efficient thermal analysis for a VLSI chip is crucial, both for sign-off reliability verification and for design-time circuit optimization. To determine an accurate temperature profile, it is important to simulate a die together with its thermal mounts: this requires solving Poisson's equation on a nonrectangular 3D domain. This article presents a class of eigendecomposition-based Fast Poisson Solvers (FPS) for chip-level thermal analysis. We start with a solver that solves a rectangular 3D domain with mixed boundary conditions in O( N ⋅ log N ) time, where N is the dimension of the finite difference matrix. Then we reveal, for the first time in the literature, a strong relation between fast Poisson solvers and Green-function-based methods. Finally, we propose an FPS method that leverages the preconditioned conjugate gradient method to solve nonrectangular 3D domains efficiently. We demonstrate this approach on thermal analysis of an industrial microprocessor, showing accurate results verified by a commercial tool, and that it solves a system of dimension 4.54e6 in only 13 conjugate gradient iterations, with a runtime of 65 seconds, a 15X speedup over the popular ICCG solver.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2620937262",
    "type": "article"
  },
  {
    "title": "Word- and Partition-Level Write Variation Reduction for Improving Non-Volatile Cache Lifetime",
    "doi": "https://doi.org/10.1145/3084690",
    "publication_date": "2017-08-01",
    "publication_year": 2017,
    "authors": "Shuai Wang; Guangshan Duan; Yupeng Li; Qianhao Dong",
    "corresponding_authors": "",
    "abstract": "Non-volatile memory technologies are among the most promising technologies for implementing the main memories and caches in future microprocessors and replacing the traditional DRAM and SRAM technologies. However, one of the most challenging design issues of the non-volatile memory technologies is the limited write. In this article, we first propose to exploit the narrow-width values to improve the lifetime of non-volatile last-level caches with word-level write variation reduction. Leading zeros masking scheme is proposed to reduce the write stress to the upper half of the narrow-width data. To balance the write variations between the upper half and the lower half of the narrow-width data, two swapping schemes, the swap on write (SW) and swap on replacement (SRepl), are proposed. Two existing optimization schemes, the multiple dirty bit (MDB) and read before write (RBW), are adopted with our word-level swapping design. To further reduce the write variation on the partition level, we propose to exploit the cache partitioning design to improve the lifetime. Based on the observation that different applications demonstrate different cache access (write) behaviors, we propose to partition the last-level cache for different applications and balance the write variations by partition swapping. Both software-based and hardware-based partitioning and swapping schemes are proposed and evaluated for different situations. Our experimental results show that both our word- and partition-level designs can improve the lifetime of the non-volatile caches effectively with low performance and energy overheads.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2741830349",
    "type": "article"
  },
  {
    "title": "On the Reliability and Tightness of GP and Exponential Models for Probabilistic WCET Estimation",
    "doi": "https://doi.org/10.1145/3185154",
    "publication_date": "2018-03-16",
    "publication_year": 2018,
    "authors": "Luís Fernando Arcaro; Karila Palma Silva; Rômulo Silva de Oliveira",
    "corresponding_authors": "",
    "abstract": "As computer architectures evolve, guaranteeing that Real-Time Systems’ (RTSs’) timing requirements are met through Worst Case Execution Time (WCET) upper bounds becomes increasingly difficult. Techniques such as Measurement-Based Probabilistic Timing Analysis (MBPTA) have emerged that estimate WCET bounds exceeded only with arbitrarily low probabilities (i.e., pWCETs) through Extreme Value Theory (EVT). The Peaks Over Threshold (POT) approach for applying EVT involves adjusting a tail-shaped distribution, e.g., Generalized Pareto (GP) or Exponential, to the values that exceed a carefully selected high threshold. Several works suggest that GP should be used within POT for best representing different tail shapes, while others consider the Exponential model more adequate for providing upper bounds with increased reliability. This work presents empirical reliability and tightness evaluations of the pWCET estimates yielded by the GP and Exponential models while applying MBPTA through the POT approach. It mainly provides counter-evidence to the GP model reliability and evidence of the Exponential model adequacy in this context.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2793331441",
    "type": "article"
  },
  {
    "title": "Real-Time Scheduling of DAG Tasks with Arbitrary Deadlines",
    "doi": "https://doi.org/10.1145/3358603",
    "publication_date": "2019-10-14",
    "publication_year": 2019,
    "authors": "Kankan Wang; Xu Jiang; Nan Guan; Di Liu; Weichen Liu; Qingxu Deng",
    "corresponding_authors": "",
    "abstract": "Real-time and embedded systems are shifting from single-core to multi-core processors, on which the software must be parallelized to fully utilize the computation capacity of the hardware. Recently, much work has been done on real-time scheduling of parallel tasks modeled as directed acyclic graphs (DAG). However, most of these studies assume tasks to have implicit or constrained deadlines. Much less work considered the general case of arbitrary deadlines (i.e., the relative deadline is allowed to be larger than the period), which is more difficult to analyze due to intra-task interference among jobs. In this article, we study the analysis of Global Earliest Deadline First (GEDF) scheduling for DAG parallel tasks with arbitrary deadlines. We develop new analysis techniques for GEDF scheduling of a single DAG task and this new analysis techniques can guarantee a better capacity augmentation bound 2.41 (the best known result is 2.5) in the case of a single task. Furthermore, the proposed analysis techniques are also extended to the case of multiple DAG tasks under GEDF and federated scheduling. Finally, through empirical evaluation, we justify the out-performance of our schedulability tests compared to the state-of-the-art in general.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2997221951",
    "type": "article"
  },
  {
    "title": "PREASC",
    "doi": "https://doi.org/10.1145/3388140",
    "publication_date": "2020-07-05",
    "publication_year": 2020,
    "authors": "Mehran Goli; Rolf Drechsler",
    "corresponding_authors": "",
    "abstract": "The increasing functionality of electronic systems due to the constant evolution of the market requirements makes the non-functional aspects of such systems (e.g., energy consumption, area overhead, or performance) a major concern in the design process. Approximate computing is a promising way to optimize these criteria by trading accuracy within acceptable limits. Since the cost of applying significant structural changes to a given design increases with the stage of development, the optimization solution needs to be incorporated into the design as early as possible. For the early design entry, modeling hardware at the Electronic System Level (ESL) using the SystemC language is nowadays widely used in the industry. To apply approximation techniques to optimize a given SystemC design, designers need to know which parts of the design can be approximated. However, identifying these parts is a crucial and non-trivial starting point of approximate computing, as the incorrect detection of even one critical part as resilient may result in an unacceptable output. This usually requires a significant programming effort by designers, especially when exploring the design space manually. In this article, we present PREASC, a fully automated framework to identify the resilience portions of a given SystemC design. PREASC is based on a combination of static and dynamic analysis methods along with regression analysis techniques (a fast machine learning method providing an accurate function estimation). Once the resilient portions are identified, an approximation degree analysis is performed to determine the maximum error rate that each resilient portion can tolerate. Subsequently, the maximum number of resilient portions that can be approximated at the same time are reported to designers at different granularity levels. The effectiveness of our approach is evaluated using several standard SystemC benchmarks from various domains.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W3039997617",
    "type": "article"
  },
  {
    "title": "Compiler-in-the-loop exploration during datapath synthesis for higher quality delay-area trade-offs",
    "doi": "https://doi.org/10.1145/2390191.2390202",
    "publication_date": "2013-01-01",
    "publication_year": 2013,
    "authors": "Sotirios Xydis; Kiamal Pekmestzi; Dimitrios Soudris; George Economakos",
    "corresponding_authors": "",
    "abstract": "Design space exploration during high-level synthesis targets the computation of those design solutions which form optimal trade-off points. This quest for optimal trade-offs has been focused on studying the impact of various architectural-level parameters during high-level synthesis algorithms, silently neglecting the trade-offs produced from the combined impact of behavioral-level together with architectural-level parameters. We propose a novel design space, exploration methodology that studies an extended instance of the solution space considering the effects of combining compiler- and architectural-level transformations. It is shown that exploring the design space in a global manner reveals new trade-off points, thus shifting towards higher quality design solutions. We use a combination of upper-bounding conditions together with gradient-based heuristic pruning to efficiently traverse the extended search space. Our exploration framework delivers significant quality improvements without compromising the optimality (Pareto accuracy) of the discovered solutions, together with significant runtime reductions compared to exploring exhaustively the solution space at every allocation scenario.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2045703421",
    "type": "article"
  },
  {
    "title": "Enabling energy efficient reliability in embedded systems through smart cache cleaning",
    "doi": "https://doi.org/10.1145/2505012",
    "publication_date": "2013-10-01",
    "publication_year": 2013,
    "authors": "Reiley Jeyapaul; Aviral Shrivastava",
    "corresponding_authors": "",
    "abstract": "Incessant and rapid technology scaling has brought us to a point where today's, and future transistors are susceptible to transient errors induced by energy carrying particles, called soft errors . Within a processor, the sheer size and nature of data in the caches render it most vulnerable to electrical interference on data stored in the cache. Data in the cache is vulnerable to corruption by soft errors, for the time it remains actively unused in the cache. Write-through and early-write-back [Li et al. 2004] cache configurations reduce the time for vulnerable data in the cache, at the cost of increased memory writes and thereby energy. We propose a smart cache cleaning methodology, that enables copying of only specific vulnerable cache blocks into the memory at chosen times, thereby ensuring data cache protection with minimal memory writes. In this work, we first propose a hybrid (software-hardware) methodology. We then propose an improved software solution that utilizes cache write-back functionality available in commodity processors; thereby reducing the hardware overhead required to implement smart cache cleaning for such systems. The parameters involved in the implementation of our Smart Cache Cleaning (SCC) technique enable a means to provide for customizable energy-efficient soft error reduction in the L1 data cache. Given the system requirements of reliability, power-budget and runtime priority of the application, appropriate parameters of the SCC can be customized to trade-off power consumption and L1 data cache reliability. Our experiments over LINPACK and Livermore benchmarks demonstrate 26% reduced energy-vulnerability product (energy-efficient vulnerability reduction) compared to that of hardware based cache reliability techniques. Our software-only solution achieves same levels of reliability with an additional 28% performance improvement.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2072882181",
    "type": "article"
  },
  {
    "title": "DFT Assisted Techniques for Peak Launch-to-Capture Power Reduction during Launch-On-Shift At-Speed Testing",
    "doi": "https://doi.org/10.1145/2790297",
    "publication_date": "2015-12-02",
    "publication_year": 2015,
    "authors": "Seetal Potluri; A. Satya Trinadh; Sobhan Babu; V. Kamakoti; Nitin Chandrachoodan",
    "corresponding_authors": "",
    "abstract": "Scan-based testing is crucial to ensuring correct functioning of chips. In this scheme, the scan and capture phases are interleaved. It is well known that for large designs, excessive switching activity during the launch-to-capture window leads to high voltage droop on the power grid, ultimately resulting in false delay failures during at-speed test. This article proposes a new design-for-testability (DFT) scheme for launch-on-shift (LOS) testing, which ensures that the combinational logic remains undisturbed between the interleaved capture phases, providing computer-aided-design (CAD) tools with extra search space for minimizing launch-to-capture switching activity through test pattern ordering (TPO). We further propose a new TPO algorithm that keeps track of the don't cares during the ordering process, so that the don't care filling step after the ordering process yields a better reduction in launch-to-capture switching activity compared to any other technique in the literature. The proposed DFT-assisted technique, when applied to circuits in ITC99 benchmark suite, produces an average reduction of 17.68% in peak launch-to-capture switching activity (CSA) compared to the best known lowpower TPO technique. Even for circuits whose test cubes are not rich in don't care bits, the proposed technique produces an average reduction of 15% in peak CSA, while for the circuits with test cubes rich in don't care bits (≥75%), the average reduction is 24%. The proposed technique also reduces the average power dissipation (considering both scan cells and combinational logic) during the scan phase by about 43.5% on an average, compared to the adjacent filling technique.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2196330920",
    "type": "article"
  },
  {
    "title": "Secure Assay Execution on MEDA Biochips to Thwart Attacks Using Real-Time Sensing",
    "doi": "https://doi.org/10.1145/3374213",
    "publication_date": "2020-01-17",
    "publication_year": 2020,
    "authors": "Tung-Che Liang; Mohammed Shayan; Krishnendu Chakrabarty; Ramesh Karri",
    "corresponding_authors": "",
    "abstract": "Digital microfluidic biochips (DMFBs) have emerged as a promising platform for DNA sequencing, clinical chemistry, and point-of-care diagnostics. Recent research has shown that DMFBs are susceptible to various types of malicious attacks. Defenses proposed thus far only offer probabilistic guarantees of security due to the limitation of on-chip sensor resources. A micro-electrode-dot-array (MEDA) biochip is a next-generation DMFB that enables the real-time sensing of on-chip droplet locations, which are captured in the form of a droplet-location map. We propose a security mechanism that validates assay execution by reconstructing the sequencing graph (i.e., the assay specification) from the droplet-location maps and comparing it against the golden sequencing graph. We prove that there is a unique (one-to-one) mapping from the set of droplet-location maps (over the duration of the assay) to the set of possible sequencing graphs. Any deviation in the droplet-location maps due to an attack is detected by this countermeasure because the resulting derived sequencing graph is not isomorphic to the original sequencing graph. We highlight the strength of the security mechanism by simulating attacks on real-life bioassays. We also address the concern that the proposed mechanism may raise false alarms when some fluidic operations are executed on MEDA biochips. To avoid such false alarms, we propose an enhanced sensing technique that provides fine-grained sensing for the security mechanism.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W3000715896",
    "type": "article"
  },
  {
    "title": "Tunable FPGA Bitstream Obfuscation with Boolean Satisfiability Attack Countermeasure",
    "doi": "https://doi.org/10.1145/3373638",
    "publication_date": "2020-02-03",
    "publication_year": 2020,
    "authors": "Brooks Olney; Robert Karam",
    "corresponding_authors": "",
    "abstract": "Field Programmable Gate Arrays (FPGAs) are seeing a surge in usage in many emerging application domains, where the in-field reconfigurability is an attractive characteristic for diverse applications with dynamic design requirements, such as cloud computing, automotive, IoT, and aerospace. The security of the FPGA configuration file, or bitstream , is critical, especially for devices with long in-field lifetimes, where attackers may attempt to extract valuable Intellectual Property (IP) from within. In this article, we propose a tunable obfuscation approach that protects IP from typical bitstream attacks while enabling designers to trade off security with acceptable overhead. We also consider two potential attacks on this protection mechanism: Boolean SAT Attacks on the obfuscation and removal attacks on the protection circuitry. The obfuscation and SAT countermeasure are integrated in a custom CAD framework within a commercial FPGA toolflow and together provide mathematically strong protection against common bitstream attacks. Further, we quantify the difficulty of a removal attack on the protection circuitry through pattern matching and direct bitstream manipulation. The average area, power, and delay overhead for obfuscation with 95% mismatch probability are 18%, 16%, and 8%, respectively, for small combinational circuits, and 1%, 2%, and 5% for larger arithmetic modules.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W3025090175",
    "type": "article"
  },
  {
    "title": "Algorithmic Fault Detection for RRAM-based Matrix Operations",
    "doi": "https://doi.org/10.1145/3386360",
    "publication_date": "2020-05-13",
    "publication_year": 2020,
    "authors": "Mengyun Liu; Lixue Xia; Yu Wang; Krishnendu Chakrabarty",
    "corresponding_authors": "",
    "abstract": "An RRAM-based computing system (RCS) provides an energy-efficient hardware implementation of vector-matrix multiplication for machine-learning hardware. However, it is vulnerable to faults due to the immature RRAM fabrication process. We propose an efficient fault tolerance method for RCS; the proposed method, referred to as extended-ABFT (X-ABFT), is inspired by algorithm-based fault tolerance (ABFT). We utilize row checksums and test-input vectors to extract signatures for fault detection and error correction. We present a solution to alleviate the overflow problem caused by the limited number of voltage levels for the test-input signals. Simulation results show that for a Hopfield classifier with faults in 5% of its RRAM cells, X-ABFT allows us to achieve nearly the same classification accuracy as in the fault-free case.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W3026878482",
    "type": "article"
  },
  {
    "title": "MNFTL",
    "doi": "https://doi.org/10.1145/3398037",
    "publication_date": "2020-07-07",
    "publication_year": 2020,
    "authors": "Chenlin Ma; Yi Wang; Zhaoyan Shen; Renhai Chen; Zhu Wang; Zili Shao",
    "corresponding_authors": "",
    "abstract": "The write constraints of Multi-Level Cell (MLC) NAND flash memory make most of the existing flash translation layer (FTL) schemes inefficient or inapplicable. In this article, we solve several fundamental problems in the design of MLC flash translation layer. The objective is to reduce the garbage collection overhead to reduce the average system response time. We make the key observation that the valid pages copy is the essential garbage collection overhead. Based on this observation, we propose two approaches, namely, concentrated mapping and postponed reclamation, to effectively reduce the valid pages copy. Besides, we propose a progressive garbage collection that can well utilize the system idle time to reclaim more spaces. We conduct a series of experiments on an embedded developing board with a set of benchmarks. The experimental results show that our scheme can achieve a significant reduction in the average system response time compared with the previous work.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W3040698329",
    "type": "article"
  },
  {
    "title": "TransNet",
    "doi": "https://doi.org/10.1145/3414062",
    "publication_date": "2020-09-10",
    "publication_year": 2020,
    "authors": "Seyed Ali Rokni; Marjan Nourollahi; Parastoo Alinia; Iman Mirzadeh; Mahdi Pedram; Hassan Ghasemzadeh",
    "corresponding_authors": "",
    "abstract": "Wearables are poised to transform health and wellness through automation of cost-effective, objective, and real-time health monitoring. However, machine learning models for these systems are designed based on labeled data collected, and feature representations engineered, in controlled environments. This approach has limited scalability of wearables because (i) collecting and labeling sufficiently large amounts of sensor data is a labor-intensive and expensive process; and (ii) wearables are deployed in highly dynamic environments of the end-users whose context undergoes consistent changes. We introduce TransNet , a deep learning framework that minimizes the costly process of data labeling, feature engineering, and algorithm retraining by constructing a scalable computational approach. TransNet learns general and reusable features in lower layers of the framework and quickly reconfigures the underlying models from a small number of labeled instances in a new domain, such as when the system is adopted by a new user or when a previously unseen event is to be added to event vocabulary of the system. Utilizing TransNet on four activity datasets, TransNet achieves an average accuracy of 88.1% in cross-subject learning scenarios using only one labeled instance for each activity class. This performance improves to an accuracy of 92.7% with five labeled instances.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W3086794567",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2742143",
    "publication_date": "2015-03-02",
    "publication_year": 2015,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "We develop a flat, analytic, and nonlinear placement algorithm, ePlace, which is more effective, generalized, simpler, and faster than previous works. Based on the analogy between placement instance and electrostatic system, we develop a novel placement ...",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W4249677948",
    "type": "paratext"
  },
  {
    "title": "ECDSA Passive Attacks, Leakage Sources, and Common Design Mistakes",
    "doi": "https://doi.org/10.1145/2820611",
    "publication_date": "2016-01-28",
    "publication_year": 2016,
    "authors": "Jeremy Dubeuf; David Hély; Vincent Beroulle",
    "corresponding_authors": "",
    "abstract": "Elliptic Curves Cryptography (ECC) tends to replace RSA for public key cryptographic services. ECC is involved in many secure schemes such as Elliptic Curve Diffie-Hellman (ECDH) key agreement, Elliptic Curve Integrated Encryption Scheme (ECIES), and Elliptic Curve Digital Signature Algorithm (ECDSA). As for every cryptosystem, implementation of such schemes may jeopardize the inherent security provided by the mathematical properties of the ECC. Unfortunate implementation or algorithm choices may create serious vulnerabilities. The elliptic curve scalar operation is particularly sensitive among these schemes. This article surveys passive attacks against well-spread elliptic curve scalar multiplication algorithms highlighting leakage sources and common mistakes that can be used to attack the ECDSA scheme. Experimental results are provided to illustrate and demonstrate the effectiveness of each vulnerability. Finally, the article describes the link between partial leakage and lattice attack in order to understand and demonstrate the impact of small leakages on the security of ECDSA. An example of side channel and lattice attack combination on NIST P-256 is provided in the case where the elliptic curve scalar multiplication is not protected against DPA/CPA and a controllable device is not accessible.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2260005205",
    "type": "article"
  },
  {
    "title": "Ripple 2.0",
    "doi": "https://doi.org/10.1145/2925989",
    "publication_date": "2016-09-02",
    "publication_year": 2016,
    "authors": "Xu He; Yao Wang; Yang Guo; Evangeline F. Y. Young",
    "corresponding_authors": "",
    "abstract": "Routability is one of the most important problems in high-performance circuit designs. From the viewpoint of placement design, two major factors cause routing congestion: (i) interconnections between cells and (ii) connections on macro blockages. In this article, we present a routability-driven placer, Ripple 2.0, which emphasizes both kinds of routing congestion. Several techniques will be presented, including (i) cell inflation with routing path consideration, (ii) congested cluster optimization, (iii) routability-driven cell spreading, and (iv) simultaneous routing and placement for routability refinement. With the official evaluation protocol, Ripple 2.0 outperforms other published academic routability-driven placers. Compared with top results in the ICCAD 2012 contest, Ripple 2.0 achieves a better detailed routing solution obtained by a commercial router.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2516707792",
    "type": "article"
  },
  {
    "title": "A Learning-based Methodology for Scenario-aware Mapping of Soft Real-time Applications onto Heterogeneous MPSoCs",
    "doi": "https://doi.org/10.1145/3529230",
    "publication_date": "2022-03-31",
    "publication_year": 2022,
    "authors": "Jan Spieck; Stefan Wildermann; Jürgen Teich",
    "corresponding_authors": "",
    "abstract": "Soft real-time streaming applications often process input data that evoke varying workloads for their tasks. This may lead to high energy consumption or deadline misses in case their mapping onto a heterogeneous MPSoC target architecture is not adapted, e.g., when tasks with high execution times for the current input are assigned to resources of low computational power. To handle the vast variety of different input data, we propose to cluster data with similar execution characteristics into so-called data scenarios for which we determine specialized mappings by performing a scenario-aware design space exploration (DSE). A runtime manager (RTM) uses these mappings to adapt the execution of the running applications to their upcoming input by first identifying their best-suited scenarios. Subsequently, the RTM selects mappings considering their identified scenarios, which minimize the total number of deadline misses and the consumed energy. We embed the RTM into hybrid application mapping (HAM); ergo, performing time-consuming optimizations offline. In this article, we propose a novel data-scenario-aware HAM methodology that can cope with multiple applications and comprises two novel scenario-based mapping selection algorithms: Inter-Application Resource Mediation Mapping introduces barely any runtime overhead. Adaptive multi-app mapping selection is highly adaptive to changes in the application workload but imposes a small runtime overhead. Our HAM approach is fully automated and uses machine-learning techniques to learn the selection of suitable mappings from training data sequences at design time. Experiments on three differently complex target architectures show that our proposed approach consistently outperforms existing state-of-the-art solutions regarding the number of deadline misses and consumed energy.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W4220914893",
    "type": "article"
  },
  {
    "title": "RASCv2: Enabling Remote Access to Side-Channels for Mission Critical and IoT Systems",
    "doi": "https://doi.org/10.1145/3524123",
    "publication_date": "2022-04-13",
    "publication_year": 2022,
    "authors": "Yunkai Bai; Andrew Stern; Jungmin Park; Mark Tehranipoor; Domenic Forte",
    "corresponding_authors": "",
    "abstract": "The Internet of Things (IoT) and smart devices are currently being deployed in systems such as autonomous vehicles and medical monitoring devices. The introduction of IoT devices into these systems enables network connectivity for data transfer, cloud support, and more, but can also lead to malware injection. Since many IoT devices operate in remote environments, it is also difficult to protect them from physical tampering. Conventional protection approaches rely on software. However, these can be circumvented by the moving target nature of malware or through hardware attacks. Alternatively, insertion of the internal monitoring circuits into IoT chips requires a design trade-off, balancing the requirements of the monitoring circuit and the main circuit. A very promising approach to detecting anomalous behavior in the IoT and other embedded systems is side-channel analysis. To date, however, this can be performed only before deployment due to the cost and size of side-channel setups (e.g., and oscilloscopes, probes) or by internal performance counters. Here, we introduce an external monitoring printed circuit board (PCB) named RASC to provide r emote a ccess to s ide- c hannels. RASC reduces the complete side-channel analysis system into two small PCBs (2 \\( \\times \\) 2 cm), providing the ability to monitor power and electromagnetic (EM) traces of the target device. Additionally, RASC can transmit data and/or alerts of anomalous activities detected to a remote host through Bluetooth. To demonstrate RASCs capabilities, we extract keys from encryption modules such as AES implemented on Arduino and FPGA boards. To illustrate RASC’s defensive capabilities, we also use it to perform malware detection. RASC’s success in power analysis is comparable to an oscilloscope/probe setup but is lightweight and two orders of magnitude cheaper.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W4224000643",
    "type": "article"
  },
  {
    "title": "Test Point Insertion for Multi-Cycle Power-On Self-Test",
    "doi": "https://doi.org/10.1145/3563552",
    "publication_date": "2022-09-13",
    "publication_year": 2022,
    "authors": "Senling Wang; Xihong Zhou; Yoshinobu Higami; Hiroshi Takahashi; Hiroyuki Iwata; Yoichi Maeda; Jun Matsushima",
    "corresponding_authors": "",
    "abstract": "Under the functional safety standard ISO26262, automotive systems require testing in the field, such as the power-on self-test (POST) . Unlike the production test, the POST requires reducing the test application time to meet the indispensable test quality (e.g., &gt;90% of latent fault metric) of ISO26262. This article proposes a test point insertion technique for multi-cycle power-on self-test to reduce the test application time under the indispensable test quality. The main difference to the existing test point insertion techniques is to solve the fault masking problem and the fault detection degradation problem under the multi-cycle test. We also present the method to identify a user-specified amount of test points that could achieve the most scan-in pattern reduction for attaining a target test coverage. The experimental results on ISCAS89 and ITC99 benchmarks show 24.4X pattern reduction on average to achieve 90% stuck-at fault coverage confirming the effectiveness of the proposed method.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W4296593725",
    "type": "article"
  },
  {
    "title": "DDAM: <u>D</u> ata <u>D</u> istribution- <u>A</u> ware <u>M</u> apping of CNNs on Processing-In-Memory Systems",
    "doi": "https://doi.org/10.1145/3576196",
    "publication_date": "2022-12-15",
    "publication_year": 2022,
    "authors": "Junpeng Wang; Haitao Du; Bo Ding; Qi Xu; Song Chen; Yi Kang",
    "corresponding_authors": "",
    "abstract": "Convolution neural networks (CNNs) are widely used algorithms in image processing, natural language processing and many other fields. The large amount of memory access of CNNs is one of the major concerns in CNN accelerator designs that influences the performance and energy-efficiency. With fast and low-cost memory access, Processing-In-Memory (PIM) system is a feasible solution to alleviate the memory concern of CNNs. However, the distributed manner of data storing in PIM systems is in conflict with the large amount of data reuse of CNN layers. Nodes of PIM systems may need to share their data with each other before processing a CNN layer, leading to extra communication overhead. In this article, we propose DDAM to map CNNs onto PIM systems with the communication overhead reduced. Firstly, A data transfer strategy is proposed to deal with the data sharing requirement among PIM nodes by formulating a Traveling-Salesman-Problem (TSP). To improve data locality, a dynamic programming algorithm is proposed to partition the CNN and allocate a number of nodes to each part. Finally, an integer linear programming (ILP)-based mapping algorithm is proposed to map the partitioned CNN onto the PIM system. Experimental results show that compared to the baselines, DDAM can get a higher throughput of 2.0× with the energy cost reduced by 37% on average.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W4311609527",
    "type": "article"
  },
  {
    "title": "SecureTVM: A TVM-based Compiler Framework for Selective Privacy-preserving Neural Inference",
    "doi": "https://doi.org/10.1145/3579049",
    "publication_date": "2023-01-03",
    "publication_year": 2023,
    "authors": "Po-Hsuan Huang; Chia-Heng Tu; Shen‐Ming Chung; Pei-Yuan Wu; Tung‐Lin Tsai; Yi-An Lin; Chun-Yi Dai; Tzu-Yi Liao",
    "corresponding_authors": "",
    "abstract": "Privacy-preserving neural inference helps protect both the user input data and the model weights from being leaked to others during the inference of a deep learning model. To achieve data protection, the inference is often performed within a secure domain, and the final result is revealed in plaintext. Nevertheless, performing the computations in the secure domain incurs about a thousandfold overhead compared with the insecure version, especially when the involved operations of the entire model are mapped to the secure domain, which is the computation scheme adopted by the existing works. This work is inspired by the transfer learning technique, where the weights of some parts of the model layers are transferred from a publicly available, pre-built deep learning model, and it opens a door to further boost the execution efficiency by allowing us to do the secure computations selectively on parts of the transferred model. We have built a compiler framework, SecureTVM, to automatically translate a trained model into the secure version, where the model layers to be protected can be selectively configured by its model provider. As a result, SecureTVM outperforms the state of the art, CrypTFlow2, by a factor of 55 for the transfer learning model. We believe that this work takes a step forward toward the practical uses of privacy-preserving neural inference for real-world applications.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4313437286",
    "type": "article"
  },
  {
    "title": "CRP2.0: A Fast and Robust Cooperation between Routing and Placement in Advanced Technology Nodes",
    "doi": "https://doi.org/10.1145/3590962",
    "publication_date": "2023-04-05",
    "publication_year": 2023,
    "authors": "Erfan Aghaeekiasaraee; Aysa Fakheri Tabrizi; Tiago Augusto Fontana; Renan Netto; Sheiny Fabre Almeida; Upma Gandhi; José Luís Güntzel; David T. Westwick; Laleh Behjat",
    "corresponding_authors": "",
    "abstract": "Traditionally, the placement and routing stages of a physical design are performed separately. Because of the additional complexities arising in advanced technology nodes, they have become more interdependent. Therefore, creating efficient cooperation between the routing and placement steps has become an important topic in Electronic Design Automation (EDA). In this article, a framework that allows cooperation between routing and placement is proposed. The main objective of the proposed framework is to improve the detailed routing solution by combining routing and placement. The core of this framework is the Cooperation between Routing and Placement (CRP2.0) 1 engine including techniques to combine routing and placement. The key contributions of CRP2.0 include an Integer Linear Programming (ILP)-based Detailed Placement (ILP-DP), net classification, and two Cost and Net Caching techniques. The efficacy of the proposed framework is evaluated on the official ACM/IEEE International Symposium on Physical Design (ISPD) 2018 and 2019 contest benchmarks. In this article, we show that by using the Cost Caching technique, the global routing runtime compared with state-of-the-art algorithms was reduced by 28.56%, on average. Moreover, numerical results show that when working with advanced technology nodes, the proposed framework can improve the detailed routing score by an average of 0.3% while only moving 0.7% of the cells, on average. The proposed engine can be employed as an add-on to the physical design flow between the global routing and detailed routing steps.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4362638787",
    "type": "article"
  },
  {
    "title": "Memristive-based Mixed-signal CGRA for Accelerating Deep Neural Network Inference",
    "doi": "https://doi.org/10.1145/3595638",
    "publication_date": "2023-05-03",
    "publication_year": 2023,
    "authors": "Reza Kazerooni-Zand; Mehdi Kamal; Ali Afzali‐Kusha; Massoud Pedram",
    "corresponding_authors": "",
    "abstract": "In this paper, a mixed-signal coarse-grained reconfigurable architecture (CGRA) for accelerating inference in deep neural networks (DNNs) is presented. It is based on performing dot-product computations using analog computing to achieve a considerable speed improvement. Other computations are performed digitally. In the proposed structure (called MX-CGRA), analog tiles consisting of memristor crossbars are employed. To reduce the overhead of converting the data between analog and digital domains, we utilize a proper interface between the analog and digital tiles. In addition, the structure benefits from an efficient memory hierarchy where the data is moved as close as possible to the computing fabric. Moreover, to fully utilize the tiles, we define a set of micro instructions to configure the analog and digital domains. Corresponding context words used in the CGRA are determined by these instructions (generated by a companion compiler tool). The efficacy of the MX-CGRA is assessed by modeling the execution of state-of-the-art DNN architectures on this structure. The architectures are used to classify images of the ImageNet dataset. Simulation results show that, compared to the previous mixed-signal DNN accelerators, on average, a higher throughput of 2.35 × is achieved.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4367847415",
    "type": "article"
  },
  {
    "title": "Modified Decoupled Sense Amplifier with Improved Sensing Speed for Low-Voltage Differential SRAM",
    "doi": "https://doi.org/10.1145/3611672",
    "publication_date": "2023-08-02",
    "publication_year": 2023,
    "authors": "Ayush Dahiya; Poornima Mittal; Rajesh Rohilla",
    "corresponding_authors": "",
    "abstract": "A modified decoupled sense amplifier (MDSA) and modified decoupled sense amplifier with NMOS foot-switch is proposed for improved sensing in differential SRAM for low-voltage operation at the 22-nm technology node. The MDSA and MDSANF both offer notable improvements to read delay over conventional voltage and current sense amplifiers. At an operating voltage of 0.8 V, the MDSA exhibited a reduced delay of 28.6%, 41.79%, 37.74%, and 30.94% compared to modified clamped sense amplifier (MCSA), double tail sense amplifier (DTSA), modified hybrid sense amplifier (MHSA), and conventional latch-type sense amplifier (LSA), respectively. Similarly, the MDSANF demonstrated a delay reduction of 26.13%, 39.78%, 35.58%, and 28.55% over MCSA, DTSA, MHSA, and LSA, respectively. To validate the performance, the MDSA and MDSANF are evaluated using the variation in delay and power consumption across various supply voltages, process corners, input differential bit line voltage (ΔV BL ), bit line capacitance (C BL ), and the sizing of decoupling transistors. Monte Carlo simulations were conducted to analyse the impact of voltage threshold variations on transistor mismatch which leads to an increased occurrence of read failures and a decline in SRAM yield. The performance analysis of various voltage and current sense amplifiers is presented along with MDSA and MDSANF. Area consideration for selection of sensing scheme is important and as such layout of MDSA and MDSANF was performed conforming to the design rules and estimated area for MDSA is 0.297 μm 2 whereas MDSANF occupies 0.5192 μm 2 .",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4385492672",
    "type": "article"
  },
  {
    "title": "Design of Enhanced Reversible 9T SRAM Design for the Reduction in Sub-threshold Leakage Current with14nm FinFET Technology",
    "doi": "https://doi.org/10.1145/3616538",
    "publication_date": "2023-08-24",
    "publication_year": 2023,
    "authors": "P. Praveen; Rakesh Kumar Singh",
    "corresponding_authors": "",
    "abstract": "Power dissipation is considered one of the important issues in low power Very-large-scale integration (VLSI) circuit design and is related to the threshold voltage. Generally, the sub-threshold leakage current and the leakage power dissipation are increased by reducing the threshold voltage. The overall performance of the circuit completely depends on this leakage power dissipation because this leakage and power consumption causes the components that are functioning by the battery for a long period to be washed-out rapidly. In this research, the reversible logic gate-based 9T static random access memory (SRAM) is designed in 14nm FinFET technology to reduce leakage power consumption in memory related applications. The Schmitt-trigger (ST)-based 9T SRAM cell is designed to attain high read-write stability and low power consumption using a single bit line structure. The reversible logic gates of Feynman (FG) and Fredkin gate (FRG) are combined to develop a row and column decoder in an SRAM design to diminish the leakage power. Moreover, the transistor stacking effect is applied to the proposed memory design to reduce the leakage power in active mode. The proposed reversible logic and transistor stacking based SRAM design is implemented in Tanner EDA Tool version 16.0. It also performs both read and write operations using the proposed circuit. The performance measures of read access time (RAT), write access time (WAT), read, write, and static power by varying supply voltage and temperature, delay and stability analysis (read/write static noise margin) are examined and compared with existing SRAM designs.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4386121315",
    "type": "article"
  },
  {
    "title": "Automatic Synthesis of FSMs for Enforcing Non-functional Requirements on MPSoCs Using Multi-objective Evolutionary Algorithms",
    "doi": "https://doi.org/10.1145/3617832",
    "publication_date": "2023-08-29",
    "publication_year": 2023,
    "authors": "Khalil Esper; Stefan Wildermann; Jürgen Teich",
    "corresponding_authors": "",
    "abstract": "Embedded system applications often require guarantees regarding non-functional properties when executed on a given MPSoC platform. Examples of such requirements include real-time, energy, or safety properties on corresponding programs. One option to implement the enforcement of such requirements is by a reactive control loop, where an enforcer decides based on a system response (feedback) how to control the system, e.g., by adapting the number of cores allocated to a program or by scaling the voltage/frequency mode of involved processors. Typically, a violation of a requirement must either never happen in case of strict enforcement, or only happen temporally (in case of so-called loose enforcement). However, it is a challenge to design enforcers for which it is possible to give formal guarantees with respect to requirements, especially in the presence of typically largely varying environmental input (workload) per execution. Technically, an enforcement strategy can be formally modeled by a finite state machine (FSM) and the uncertain environment determining the workload by a discrete-time Markov chain. It has been shown in previous work that this formalization allows the formal verification of temporal properties (verification goals) regarding the fulfillment of requirements for a given enforcement strategy. In this article, we consider the so-far-unsolved problem of design space exploration and automatic synthesis of enforcement automata that maximize a number of deterministic and probabilistic verification goals formulated on a given set of non-functional requirements. For the design space exploration (DSE), an approach based on multi-objective evolutionary algorithms is proposed in which enforcement automata are encoded as genes of states and state transition conditions. For each individual, the verification goals are evaluated using probabilistic model checking. At the end, the DSE returns a set of efficient FSMs in terms of probabilities of meeting given requirements. As experimental results, we present three use cases while considering requirements on latency and energy consumption.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4386251366",
    "type": "article"
  },
  {
    "title": "Dynamic Adaptation Using Deep Reinforcement Learning for Digital Microfluidic Biochips",
    "doi": "https://doi.org/10.1145/3633458",
    "publication_date": "2023-11-23",
    "publication_year": 2023,
    "authors": "Tung-Che Liang; Yi-Chen Chang; Zhanwei Zhong; Yaas Bigdeli; Tsung-Yi Ho; Krishnendu Chakrabarty; Richard B. Fair",
    "corresponding_authors": "",
    "abstract": "We describe an exciting new application domain for deep reinforcement learning (RL): droplet routing on digital microfluidic biochips (DMFBs). A DMFB consists of a two-dimensional electrode array, and it manipulates droplets of liquid to automatically execute biochemical protocols for clinical chemistry. However, a major problem with DMFBs is that electrodes can degrade over time. The transportation of droplet transportation over these degraded electrodes can fail, thereby adversely impacting the integrity of the bioassay outcome. We demonstrated that the formulation of droplet transportation as an RL problem enables the training of deep neural network policies that can adapt to the underlying health conditions of electrodes and ensure reliable fluidic operations. We describe an RL-based droplet routing solution that can be used for various sizes of DMFBs. We highlight the reliable execution of an epigenetic bioassay with the RL droplet router on a fabricated DMFB. We show that the use of the RL approach on a simple micro-computer (Raspberry Pi 4) leads to acceptable performance for time-critical bioassays. We present a simulation environment based on the OpenAI Gym Interface for RL-guided droplet routing problems on DMFBs. We present results on our study of electrode degradation using fabricated DMFBs. The study supports the degradation model used in the simulator.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4388941608",
    "type": "article"
  },
  {
    "title": "Thermal-Aware Chiplet Placement for 2.5D ICs with Sequence Pair Based Tree",
    "doi": "https://doi.org/10.1145/3716893",
    "publication_date": "2025-02-11",
    "publication_year": 2025,
    "authors": "Yu‐Min Lee; Hong‐Wen Chiou; J.W. Jiang",
    "corresponding_authors": "",
    "abstract": "This work develops an efficient thermal-aware chiplet placer with sequence-pair representation. It provides wirelength-driven placement and thermal-aware placement. Its wirelength-driven option combines the sequence-pair based tree, a parallel branch-and-bound method and advanced placement/pruning techniques to efficiently find the minimum-wirelength placement. The thermal-aware option incorporates the wirelength-driven option with a thermal-aware net weight decision method and a post chiplet placement procedure to effectively make a trade-off between wirelength and temperatures of chiplets. Compared with the state-of-the-art wirelength-driven chiplet placer, the developed wirelength-driven chiplet placer not only finds the same or less minimum wirelength placement but also speeds up at most two orders of magnitude. With considering thermal effect, Its thermal-aware option can reduce the maximum temperature up to 9.4 ℃ with an average 4.7% increase of wirelength, while ensuring that all cases meet thermal constraints. Compared to the state-of-the-art thermal-aware chiplet placer, the proposed thermal-aware placer not only takes shorter runtime but also provides less total wirelength placement.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4407373265",
    "type": "article"
  },
  {
    "title": "Hierarchical Integration of Reinforcement Learning and Optimization Algorithms for Time-Efficient Design Automation of Complex Analog Circuit",
    "doi": "https://doi.org/10.1145/3723162",
    "publication_date": "2025-03-17",
    "publication_year": 2025,
    "authors": "Xunbo Feng; Yifan Xu; Zhangcheng Huang; Wuyi Xu; Zhaori Bi; Fan Yang; Xuan Zeng; Ye Lü",
    "corresponding_authors": "",
    "abstract": "Design automation of complex analog circuits (CAC) with multiple sub-blocks is challenging mainly due to large design search space, uncertain intermediate subgoal creation and lengthy CAC simulation runtime. In this work, we propose a hierarchical and heterogeneous integration framework as a fully automated and time-efficient CAC design optimization solution. In Particularly, we (i) decompose CAC into two levels hierarchically, and for the first time introduce hierarchical RL (HRL) agents with hindsight and subgoal testing to automate the subgoal creation between these two levels. The subgoal converges to the optimal value through algorithm interactions. (ii) enable high-level design space dimensionality reduction; minimize CAC simulation runs through a buffer hold; and employ low-level sub-block execution parallelization to reduce overall run time. (iii) construct a heterogeneous integration of different RL algorithms and black-box optimization algorithms in hierarchy to further boost the speed, by benefiting both from the hierarchical structure and the advantages of each different algorithm. Experiments on four CAC topologies demonstrate that this framework achieves a maximum of 11.4X speed up compared to existing methods at the desired FoM. This work opens up a time efficient design automation route for complex analog circuits and systems.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4408529861",
    "type": "article"
  },
  {
    "title": "ILOSSS - Improved Logic Synthesis based on Several Stateful logic gates",
    "doi": "https://doi.org/10.1145/3731245",
    "publication_date": "2025-04-21",
    "publication_year": 2025,
    "authors": "Nuo Xu; Yihong Hu; Chaochao Feng; Wei Tong; Kang Liu; Liang Fang",
    "corresponding_authors": "",
    "abstract": "Memristor stateful logic is an effective way to achieve the real sense of in-memory computing in memristor-based crossbar array (MCBA). At present, the synthesis tools fall short in conducting a thorough exploration of the optimization potential pertaining to cascading stateful logic gates within MCBA, and the optimization objectives are relatively simple. In this paper, a suit of stateful logic synthesis kit, named ILOSSS, improved from the previous LOSSS tool is achieved. Such kit includes two kinds of stateful logic synthesis processes for latency (corresponding to the High Time-Efficiency Synthesis Process (HTESP)) and energy (corresponding to the Low-Energy Synthesis Process (LESP)) optimization respectively. Both of the synthesis processes are achieved by improving an existing synthesis process of MAGIC (SIMPLER-MAGIC) to support multiple stateful logic gates and inserting a post-processing stage with a well-developed automated optimization algorithm to reduce the number of the gates of the netlist with a corresponding purpose. Comparing to the standard SIMPLER-MAGIC tool, the HTESP achieves arithmetic mean improvements of over 23% in performance, and over 34% in effective lifetime under the EPFL benchmark suit which is also better than the results reported by the state-of-art MAGIC synthesis process (X-MAGIC). Meanwhile, the energy-delay product (EDP) of LESP has decreased by an average of over 10% and 42% compared to SIMPLER-MAGIC and HTESP respectively.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4409623798",
    "type": "article"
  },
  {
    "title": "HyperPlace: Harnessing a Large Language Model for Efficient Hyperparameter Optimization in GPU-Accelerated VLSI Placement",
    "doi": "https://doi.org/10.1145/3733601",
    "publication_date": "2025-05-03",
    "publication_year": 2025,
    "authors": "Magi Chen; Ting-Chi Wang",
    "corresponding_authors": "",
    "abstract": "While GPU-based placers have demonstrated significant speed advantages over their CPU-based counterparts, hyperparameter tuning remains a bottleneck, often requiring substantial human intervention and expert knowledge. This challenge is particularly critical given the urgent need for rapid time-to-market solutions. Recently, Large Language Models (LLMs) have exhibited remarkable capabilities in zero-shot learning, context understanding, logical reasoning, and answer generation. In this work, we introduce HyperPlace, an innovative paradigm that leverages an off-the-shelf LLM to automate hyperparameter optimization using in-context learning techniques. Our approach transcends single-output black-box optimization methods by incorporating a batch optimization mechanism that evaluates multiple hyperparameter configurations simultaneously across several GPU computing platforms. We validated the effectiveness of our approach in placement quality, measured by Half-Perimeter Wire Length (HPWL), using DREAMPlace 2.0. To further demonstrate the capability of integrating our framework with other placers, we conducted additional experiments using Xplace 2.0. By employing the ISPD2005 benchmarks for our evaluation, HyperPlace enhances the placement tools with up to a 1.66% reduction in HPWL compared to their published results. Additionally, we evaluated HyperPlace on the ISPD2015 benchmarks, which incorporate fence region constraints not present in ISPD2005 benchmarks. Under these more complex constraints, HyperPlace achieves up to a 22.24% reduction in HPWL compared to the default settings of the placement tools, further demonstrating its adaptability across diverse placement scenarios and benchmark suites.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4410058301",
    "type": "article"
  },
  {
    "title": "A Systematic Mapping Study on SystemC/TLM Modeling Capabilities in New Research Domains",
    "doi": "https://doi.org/10.1145/3735641",
    "publication_date": "2025-05-13",
    "publication_year": 2025,
    "authors": "Ahmed Mahmoudi; Andrija Nešković; Celine Thermann; Robin Sehm; Christoph Hübner; Tavia Plattenteich; Rolf Meyer; Rainer Buchty; Mladen Bereković; Saleh Mulhem",
    "corresponding_authors": "",
    "abstract": "With increasingly complex circuits and systems, the need for advanced design methodologies is growing. These methodologies shift the designers’ focus from technology-specific implementations to more abstract electronic system design (ESL). SystemC was developed to address this need. Being an open standard based on C++, SystemC facilitates hardware and software modeling across multiple levels of abstraction, with a particular emphasis on ESL. It is further enhanced by including the transaction-level modeling (TLM) layer, strengthening its capability to model communication between components, and even full-system simulators. Traditionally, SystemC/TLM has been deployed to provide hardware prototypes for software development early in the design process. However, surveys and literature reviews showing other capabilities of SystemC/TLM are scarce. Hence, it is essential to explore SystemC/TLM’s new capabilities in different domains such as in-circuit fault propagation, security assessment, and verification. In this paper, we conduct a systematic mapping study (SMS) of SystemC/TLM modeling capabilities in certain research domains. We elaborate on the state-of-the-art ESL with an emphasis on SystemC/TLM-based system modeling. Subsequently, we present how such technologies can be applied to the new research domains within the field of circuit and system modeling, namely: (D.1) architecture exploration, (D.2) power estimation, (D.3) fault-injection analysis, (D.4) functional and security verification, and (D.5) side-channel analysis. This SMS highlights the advantages and disadvantages of the investigated SystemC/TLM capabilities and addresses the open challenges in these domains, concluding that SystemC/TLM offers significant potential in performance evaluation, verification, and security assessment of circuits and systems at ESL.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4410321356",
    "type": "article"
  },
  {
    "title": "Interactive Visual Performance Space Exploration of Operational Amplifiers with Differentiable Neural Network Surrogate Models",
    "doi": "https://doi.org/10.1145/3744245",
    "publication_date": "2025-06-12",
    "publication_year": 2025,
    "authors": "Yannick Uhlmann; Till Moldenhauer; Jürgen Scheible",
    "corresponding_authors": "",
    "abstract": "To this day, the design of analog integrated circuits is a predominantly manual task, heavily reliant on the knowledge and intuition of human experts. Many current automation approaches aim to be holistic solutions, attempting to take the human out of the loop. This work, in turn, does not intend to replace human designers with algorithms, but support their qualities in the established flow. Here, the performance space of analog ICs is modeled by PVT-aware neural networks and visualized with parallel coordinate plots. Such a responsive visualization gives insights into the relations of parameters through interactive exploration where any parameter can be the cause while all others show the immediate effect. Thus, complex decision-making problems based on the experience of seasoned designers, such as circuit sizing or topology selection, are transformed into intuitive perceptual problems. Through the responsiveness and immediacy of the implementation, designers are encouraged to explore the entire performance space instead of basing all decisions on previous designs, never leaving the beaten path. A data generation and training procedure for surrogate models is outlined. Models for three operational amplifiers in three different technologies illustrate the applicability and feasibility of the presented approach. Additionally, a web-based demo, including all source code, is available for review.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4411242517",
    "type": "article"
  },
  {
    "title": "Securing Network-on-Chips Against Trojan-Induced Packet Duplication Attacks",
    "doi": "https://doi.org/10.1145/3744645",
    "publication_date": "2025-06-14",
    "publication_year": 2025,
    "authors": "Manju Rajan; Abhijit Das; John Jose",
    "corresponding_authors": "",
    "abstract": "The third-party Intellectual Property (IP) supply chain exposes System-on-Chip designs to malicious implants like Hardware Trojans (HTs). With extremely rare trigger conditions, some HTs can evade conventional and even machine learning-based validation methods. Current detection and mitigation approaches fall short, especially against HTs capable of creating detrimental effects on cache and Network-on-Chip (NoC) performance. In this article, we present a novel intermittent and robust HT called LOKI, which primarily operates within the Network Adapter (NA) but can simultaneously impact the performance of the NoC, the shared cache, and the cores. LOKI is implanted in a malicious IP’s NA and triggers packet duplication attacks, leading to increased latency and performance degradation across the system. This action has cascading effects on the system, including increased latency in the NoC, adversely impacting communication efficiency. The duplication also leads to increased cache misses and longer miss penalties, further degrading cache performance. Additionally, LOKI affects the Instruction-Per-Cycle (IPC) of the cores, thus influencing overall processing performance. Our evaluation demonstrates that LOKI causes a 3.53× increase in packet latency, a 15% increase in miss penalty, and a 10% decrease in overall IPC. To neutralize the effects of HT-induced packet duplication, we propose a ubiquitous mitigation framework called HULK. HULK is installed in the NA and monitors all messages going in and out of the NoC, allowing it to address anomalies occurring in the NA, routers, and links. Experimental evaluation shows that HULK can effectively mitigate LOKI’s impact, achieving baseline system-like performance with negligible hardware overhead. Unlike existing HT-specific mitigation proposals, HULK serves as a generic solution to neutralize all types of packet duplication attacks. To promote reproducibility and community adoption, we have open sourced the implementation at https://github.com/itsmanju/hulk .",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4411309347",
    "type": "article"
  },
  {
    "title": "Layout Synthesis for Quantum Circuits Considering Toffoli Gate Decomposition",
    "doi": "https://doi.org/10.1145/3744646",
    "publication_date": "2025-06-16",
    "publication_year": 2025,
    "authors": "Po-Wei Chen; Shan-You Huang; Shao‐Yun Fang",
    "corresponding_authors": "",
    "abstract": "State-of-the-art studies on quantum layout synthesis have proposed various approaches based on the assumption that the input circuit is only composed of single-qubit and two-qubit gates. This assumption greatly simplifies the layout synthesis problem, and thus they only require ensuring that all controlled-NOT (CNOT) gates satisfy the hardware constraints imposed by a given coupling graph. However, during the design of quantum circuits, multi-controlled Toffoli (MCT) gates are usually used to better characterize the function of the circuits. Directly decomposing them into single and two-qubit gates with a fixed routine ignores the flexibility and optimization opportunity provided by various decomposition (i.e., logic synthesis) possibilities and thus suffers from sub-optimal results. This article proposes a co-optimization approach for quantum logic and layout synthesis. The MCT gates are first decomposed into Toffoli gates, and an efficient qubit mapping checking process is proposed to optimally solve the SWAP-free layout synthesis problem by automatically determining the decomposition result of each Toffoli gate. If a SWAP-free result cannot be found, the proposed algorithm flow is then used to obtain a solution that minimizes the total cost that simultaneously counts the cost caused by the different decomposition methods for Toffoli gates and the cost induced by SWAP gates. Compared with a state-of-the-art method, the proposed approach reduces the number of additional CNOT gates by 16% with around 25X runtime speedup for the cases with SWAP-free solutions, which cannot be obtained without the co-optimization approach.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4411350551",
    "type": "article"
  },
  {
    "title": "A CPU+FPGA OpenCL Heterogeneous Computing Platform for Multi-Kernel Pipeline",
    "doi": "https://doi.org/10.1145/3744922",
    "publication_date": "2025-06-19",
    "publication_year": 2025,
    "authors": "Y. Wang; Wendong Mao; Lang Feng; Jin Sha; Zhongfeng Wang",
    "corresponding_authors": "",
    "abstract": "Over the past decades, Field-Programmable Gate Arrays (FPGAs) have become a choice for heterogeneous computing due to their flexibility, energy efficiency, and processing speed. OpenCL is used in FPGA heterogeneous computing for its high-level abstraction and cross-platform compatibility. Previous works have introduced optimization techniques in OpenCL for FPGAs to leverage FPGA-specific advantages. However, the multi-kernel pipeline technique, which can raise throughput and resource utilization, has not performed well. This article presents a CPU+FPGA heterogeneous platform with a novel execution model to optimize multi-kernel pipeline. Firstly, we extend OpenCL by introducing new APIs and additional functions to represent the execution model. Secondly, a hardware-software co-scheduling scheme is employed to manage execution. Thirdly, we design a holistic development flow and toolkit to facilitate the deployment of algorithms on the platform or the integration of RTL IP cores to the OpenCL environment. We validate the platform using a Range Doppler algorithm. The proposed development flow and integrated toolchain enhance the efficiency of integrating traditional RTL IP cores into the OpenCL environment. Experimental results demonstrate that, with a comparable processing speed (averaging 95%) to traditional RTL implementations, the platform successfully establishes the multi-kernel pipelines. Leveraging the multi-kernel pipeline, the platform achieves a significant improvement in multi-frame processing speed compared to traditional OpenCL.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4411456907",
    "type": "article"
  },
  {
    "title": "Enhanced TransUNet Framework for Predicting Static IR Drop and Chip Routability",
    "doi": "https://doi.org/10.1145/3750726",
    "publication_date": "2025-07-24",
    "publication_year": 2025,
    "authors": "Yunfan Zuo; Pinquan Li; Yuwei Sun; Hao Yan; Longxing Shi",
    "corresponding_authors": "",
    "abstract": "As semiconductor processes advance, the power delivery network (PDN) increasingly affects the power supply from the pads to the cells. Significant IR drops in standard cells can lead to timing violations, while suboptimal PDN topologies can lead to increased congestion. Together, these factors degrade overall chip performance and reliability. To accelerate design iteration, accurately and efficiently predicting unevenly distributed IR drop and congestion, especially in hotspot areas, has become a critical challenge. This paper introduces an enhanced TransUNet-based framework for distribution-aware static IR drop and congestion prediction, treating both problems as separate but related image prediction tasks. Such an abstraction preserves the IR drop and congestion distribution patterns on the original real physical layout and retains local hot spots. Our proposed framework leverages image classification techniques to model IR drop prediction as a spatial pattern recognition task, effectively addressing the long-tail distribution in different regions. To enhance hotspot prediction, we incorporate wavelet transform and transformer-based analysis to enable multiscale feature fusion. In the open-source CircuitNet dataset, our method predicts static IR drop with a mean absolute error( MAE ) of 0.374 mV and a maximum error rate( Err m ) of \\(18.7\\% \\) , reducing MAE and Err m by \\(77.4\\% \\) and \\(79.2\\% \\) , respectively, compared to the state-of-the-art method, all within 100 ms. The congestion prediction evaluations show \\(65.3\\% \\) lower NRMSE scores and \\(18. 4\\% \\) higher SSIM scores relative to the existing SOTA approach. Our approach accurately and reliably predicts long-tail distributions and localized hotspots in both IR drop and congestion tasks.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4412636671",
    "type": "article"
  },
  {
    "title": "An Improved MCTS Algorithm for Ordered Escape Routing of Differential Pair",
    "doi": "https://doi.org/10.1145/3760776",
    "publication_date": "2025-08-18",
    "publication_year": 2025,
    "authors": "Xinguo Deng; Wen Xu; Mingsheng Mei; Hu Hong; Yourun Lan; Jiarui Chen",
    "corresponding_authors": "",
    "abstract": "The ordered escape routing of the differential pair represents a critical component in the physical design of the printed circuit board. An improved Monte Carlo Tree Search (MCTS) algorithm and an innovative technique for estimating escape points are proposed to address the problem of satisfying the constraint of ordered escape routing. Compared with the existing method, the proposed method demonstrates a significant improvement in routing path length and CPU time, both for grid pin arrays and staggered pin arrays. Moreover, the proposed approach effectively addresses the blockage-avoided ordered escape routing problem for differential pairs.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413287017",
    "type": "article"
  },
  {
    "title": "Memory-Efficient and Adaptive Heterogeneous Framework for Gate-Level Fault Simulation",
    "doi": "https://doi.org/10.1145/3760777",
    "publication_date": "2025-08-15",
    "publication_year": 2025,
    "authors": "Zhiteng Chao; Feng Gu; Junying Huang; Wenjie Li; Jing Ye; Huawei Li; Xiaowei Li",
    "corresponding_authors": "",
    "abstract": "Gate-level fault simulation is essential for automatic test pattern generation (ATPG). The traditional event-driven simulation is time-consuming due to the large number of faults. While parallel fault simulation with GPGPUs shows promise, it faces reduced parallel efficiency on large circuits. This is mainly due to the increased space required to store fault values, limiting the number of faults that can be processed in parallel and preventing full utilization of the GPU’s capabilities. In this study, we propose a memory-efficient fault machine implementation FM gpu based on a circular vector, which is tailored for GPU fault simulation with some sacrifices of time efficiency and a variable length limit. We also propose a fully adaptive parallel fault simulation framework based on the CPU-GPU heterogeneous system, which includes two stages on the GPU and performs CPU simulation at the same time. All parameters related to GPU memory optimization and workload balancing in the framework can be adjusted adaptively. The experimental results demonstrate that our method achieves better memory efficiency and speedup compared to the previous GPU fault simulation methods, a maximum speedup of 137.48 × compared to the baseline open-source simulator with 32 threads, and a maximum speedup of 2.52 × compared to a 32-thread commercial tool.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413380437",
    "type": "article"
  },
  {
    "title": "Enhancing Large Language Models for Hardware Verification: A Novel SystemVerilog Assertion Dataset",
    "doi": "https://doi.org/10.1145/3764934",
    "publication_date": "2025-08-30",
    "publication_year": 2025,
    "authors": "Anand Menon; Samit Shahnawaz Miftah; Shamik Kundu; Souvik Kundu; Amisha Srivastava; Arnab Raha; Gaberiel Sonnenschien; Suvadeep Banerjee; Deepak A. Mathaikutty; Kanad Basu",
    "corresponding_authors": "",
    "abstract": "Hardware verification is crucial in modern SoC design, consuming around 70% of development time. SystemVerilog assertions ensure correct functionality. However, existing industrial practices rely on manual efforts for assertion generation, which becomes increasingly untenable as hardware systems become complex. Recent research shows that Large Language Models (LLMs) can automate this process. However, proprietary SOTA models like GPT-4o often generate inaccurate assertions and require expensive licenses, while smaller open-source LLMs need fine-tuning to manage HDL code complexities. To address these issues, we introduce VERT, an open-source dataset designed to enhance SystemVerilog assertion generation using LLMs. VERT enables researchers in academia and industry to fine-tune open-source models, outperforming larger proprietary ones in both accuracy and efficiency while ensuring data privacy through local fine-tuning and eliminating costly licenses. The dataset is curated by systematically augmenting variables from open-source HDL repositories to generate synthetic code snippets paired with corresponding assertions. Experimental results demonstrate that fine-tuned models like Deepseek Coder 6.7B and Llama 3.1 8B outperform GPT-4o, achieving up to 96.88% improvement over base models and 24.14% over GPT-4o on platforms including OpenTitan, CVA6, OpenPiton, and Pulpissimo. VERT is available at https://github.com/AnandMenon12/VERT.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413843787",
    "type": "article"
  },
  {
    "title": "Patchability-Driven Design Exploration for System-on-Chip Patching Architectures",
    "doi": "https://doi.org/10.1145/3762185",
    "publication_date": "2025-09-01",
    "publication_year": 2025,
    "authors": "Wei-Kai Liu; Benjamin Tan; Krishnendu Chakrabarty",
    "corresponding_authors": "",
    "abstract": "As System-on-Chip (SoC) designs become increasingly complex, ensuring comprehensive verification has become more challenging, leading to overlooked hardware bugs that can be found in the field. Addressing hardware bugs post-deployment is difficult, as they typically cannot be easily fixed like software bugs. To tackle this issue, hardware-based patching mechanisms have emerged as a potential solution for providing in-field fixes. However, the lack of a standardized method to evaluate the ”patchability” of different designs complicates the integration of patching infrastructure into SoCs. In this paper, we propose a fully parameterized Patch Support Block (PSB) architecture that can be tailored for various hardware designs, enabling post-deployment patching. We introduce a novel patchability score formulation that provides a quantifiable metric for evaluating the effectiveness of patching designs. Our approach considers both the observability and controllability of the patching hardware and provides a framework for system integrators to maximize patchability while managing resource constraints. Through experimentation with multiple design configurations, we demonstrate how our methodology can enhance patchability in hardware systems and provide security-related fixes for SoCs in real-world scenarios.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413876901",
    "type": "article"
  },
  {
    "title": "TCAD-Machine Learning Enabled TID Compact Model Development for Commercial SiC MOSFET",
    "doi": "https://doi.org/10.1145/3766551",
    "publication_date": "2025-09-11",
    "publication_year": 2025,
    "authors": "Xujiao Gao; Jaideep Ray; Brian Rummel; Caleb Glaser; Elaine Louise Rhoades; Joshua Young; Lawrence Musson; Thomas Buchheit",
    "corresponding_authors": "",
    "abstract": "We propose a TCAD-machine learning coupled approach that combines a TCAD tool (Charon), optimization/uncertainty quantification tool (Dakota), surrogate models, and Bayesian learning capabilities. The coupling approach is used for accurate modeling and calibration of total ionizing dose (TID) induced threshold voltage ( V th ) shifts in Commercial-Off-The-Shelf (COTS) semiconductor devices and to develop physics-informed TID compact models. This versatile approach is applied to model the TID effect in an exemplar COTS 3.3 kV SiC power MOSFET (Metal-Oxide-Semiconductor Field-Effect Transistor). With the Charon-Dakota coupling, we can determine key device geometry and doping values based on device physics, which are difficult to obtain or not available for COTS devices but important for TCAD simulation; additionally, we can efficiently generate thousands of simulation results in a large parameter space, which makes it possible to develop data-driven surrogate models and perform Bayesian calibration. Utilizing the full tool-coupling approach, we achieve calibrated TCAD simulation models that accurately capture the average TID-induced V th shifts behavior with total doses and V th shifts saturation at high doses as observed in experimental data. More importantly, the calibrated TCAD simulations are obtained with determined TID model parameters (e.g., hole trap density and capture cross section) values that contain well quantified uncertainties. Furthermore, we can isolate and quantify the noises that are not captured by the TCAD models but exist in the measured data due to measurements and devices variabilities. Lastly, the calibrated surrogate models are used to develop physics-informed TID compact models. The method is generalizable to other devices and/or radiation conditions with little modifications and can provide well-determined uncertainties.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4414127363",
    "type": "article"
  },
  {
    "title": "Scan Chain Watermarking : A Graph Neural Network based approach",
    "doi": "https://doi.org/10.1145/3769115",
    "publication_date": "2025-09-20",
    "publication_year": 2025,
    "authors": "Ashwin CS; Suchismita Roy",
    "corresponding_authors": "",
    "abstract": "Ensuring the integrity of scan chains in Very Large Scale Integration (VLSI) designs is crucial for hardware security and intellectual property (IP) protection. This work presents a Graph Neural Network (GNN)-based approach for optimising scan chains while simultaneously embedding a robust watermark to authenticate the design. The primary objective is to minimise transition density in scan chains, reducing power consumption while ensuring watermark resilience against adversarial attacks. Scan chain optimization is a crucial aspect of VLSI testing, aimed at minimizing power consumption while ensuring testability. Traditional approaches perform scan chain reordering and watermark embedding as separate steps, often leading to suboptimal solutions in terms of both security and power efficiency. In this work, a unified framework is proposed, where scan chain optimization and watermark embedding are integrated into a single-step process, leveraging Graph Neural Networks (GNNs). By formulating the scan chain as a weighted graph, the optimization is driven by transition density minimization while simultaneously embedding a cryptographic watermark within edge weights. This ensures that the scan chain remains resistant to adversarial modifications while achieving power-efficient reordering. The proposed methodology employs PyTorch Geometric-based GNN models to extract spatial, temporal, and structural features from scan chain graphs. The methodology is validated on the ISCAS-89 benchmark suite, and the results demonstrate a significant reduction in transition density across multiple circuits.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4414374656",
    "type": "article"
  },
  {
    "title": "Ultrafast Generative AI by Ultradense 3D Integration: A Case Study on LLM-based Edge Inference",
    "doi": "https://doi.org/10.1145/3768168",
    "publication_date": "2025-09-12",
    "publication_year": 2025,
    "authors": "Kerem Akarvardar; Xiaoyu Sun; Brian Crafton; Xiaochen Peng; H. Mori; Abhiroop Bhattacharjee; Hidehiro Fujiwara; H.‐S. Philip Wong",
    "corresponding_authors": "",
    "abstract": "Generative AI (GenAI) is one of the most critical applications today, continually challenging the limits of semiconductor technology. We introduce a very fine-grained 3D memory-on-logic architecture along with a novel data mapping strategy to support Large Language Model (LLM)-based GenAI, including both prefill and generation stages. Our conceptual analysis shows how ultradense 3D connectivity can enhance text generation speed and energy-efficiency well-beyond current limits. Preliminary findings from a basic analytical model indicate that the single batch autoregressive generation rate for Llama 3.2 1B could surpass 5K tokens/sec by maximizing weight locality and enhancing memory bandwidth through massively parallel 3D links between Multiply-Accumulate (MAC) units in the logic tier and their dedicated memory partitions in the 3D stack. We also explore the impact of advanced logic nodes and quantify their benefits in reducing prefill latency. Finally, we examine the challenges associated with memory access power and power density under extreme bandwidth conditions and present pipelined access strategies to address them.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4414594363",
    "type": "article"
  },
  {
    "title": "Scalable Yield Analysis of SRAM and Analog Circuits Using Multi-Kernel Sparse Representation",
    "doi": "https://doi.org/10.1145/3767165",
    "publication_date": "2025-09-12",
    "publication_year": 2025,
    "authors": "Ziqi Wang; L.-N. Wu; X. Li; Zhongxi Guo; Shi Xiao; Longxing Shi",
    "corresponding_authors": "",
    "abstract": "With the advancement of technology nodes and the increasingly stringent requirements for stability, general yield analysis of customized circuits in the early stages of design has become a key bottleneck in manufacturing. In this paper, we propose a multi-kernel sparse representation-based classification (MKSRC) method to enhance the efficiency and scalability of failure probability estimation by classifying tail samples. It employs class-balanced sampling to address data imbalance issues and utilizes multi-kernel features with adaptive kernel weights to enhance the accuracy and robustness of the classifier. Experimental results on 32-bit SRAM columns and analog circuits demonstrate that the proposed MKSRC method achieves higher classification accuracy and efficiency compared to other state-of-the-art methods, particularly in scenarios with limited training data. Compared to SOTA yield estimation methods, the MKSRC method achieves an average 2.57-3.29x improvement in both accuracy and efficiency, highlighting its ability to provide efficient and scalable yield analysis solutions for both SRAM and analog circuits.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4414594412",
    "type": "article"
  },
  {
    "title": "Energy-aware Scheduling of Workflow Applications Towards Schedule Length Optimization in Heterogeneous Distributed Embedded Systems",
    "doi": "https://doi.org/10.1145/3767164",
    "publication_date": "2025-09-12",
    "publication_year": 2025,
    "authors": "Jinchao Chen; Q. Zhang; Pengcheng Han; Ying Zhang; Yantao Lu; Pengyi Zheng",
    "corresponding_authors": "",
    "abstract": "Energy optimization constitutes a paramount design consideration in the realm of embedded systems development since these devices are inherently constrained by finite battery resources. Designing and developing an effective energy-aware scheduling approach is a desirable work to provide excellent processing capability while keeping the energy consumption under control. Although previous approaches can obtain reasonable scheduling solutions for tasks with energy consumption constraints, they are computationally expensive and have deficiencies in effectiveness or efficiency due to unfair or inefficient energy pre-assignment strategies. In this paper, we study the energy-aware workflow scheduling problem and present a three-stage list-based approach to minimize the schedule length of workflows in heterogeneous distributed embedded systems. First, the workflow applications and energy consumption of processors are modelled, and the energy-aware workflow scheduling problem is formulated as a non-linear mixed integer programming one with various dependency and energy constraints. Then, with an effective task prioritization strategy and a reasonable energy pre-assignment strategy, a three-stage list-based scheduling approach is proposed to schedule the tasks and minimize the schedule length of workflows. Experiments on randomly-generated and real-life workflows demonstrate that our proposed approach constantly outperforms the existing approaches and our algorithm can respectively reduce the normalized schedule length and the deviation ratio by 16.7% and 7.6% in average.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4414595688",
    "type": "article"
  },
  {
    "title": "Scheduling Task Graph Applications on Preloaded Shared-Bus based Heterogeneous Platforms",
    "doi": "https://doi.org/10.1145/3772003",
    "publication_date": "2025-10-21",
    "publication_year": 2025,
    "authors": "Chhavi Chaudhary; Rajesh Devaraj; Arnab Sarkar",
    "corresponding_authors": "",
    "abstract": "Modern embedded control applications in Cyber-Physical Systems (CPSs) often have complex inter-dependencies in their functionalities and are hence represented as Directed-Acyclic Task Graphs (DTGs). To meet complex performance as well as deployment-related logistic constraints, these applications may need to be implemented on a distributed and heterogeneous platform. Many-a-times, it becomes necessary to dynamically run a new application like say, an alarm service routine , on an already operational platform, where pre-existing workloads consisting of other application tasks along with their messages are running. However, although there is a significant body of literature dealing with the static scheduling of DTGs on different types of platforms, to the best of our knowledge, there does not exist any prominent work for the dynamic scheduling of dynamically arriving DTG applications on an already preoccupied platform. The primary reason for this dearth in strategies may be attributed to the inherent design as well as computational complexity associated with the dynamic inclusion of a new DTG application by effectively reclaiming the free slots within an already existing schedule. While delivering quick response times to the dynamically arrived application, the newly generated schedule must also ensure that it does not ever cause deadline violations for the already running applications . This work proposes a novel makespan-minimizing scheduling algorithm called DTG Scheduler for Preloaded Platforms ( DSPP ). DSPP is an efficient list-based heuristic strategy for co-scheduling the tasks as well as the inter-task messages of a DTG structured application on preloaded heterogeneous processing elements, interconnected via shared buses. The effectiveness of DSPP has been meticulously examined through simulation, employing benchmark DTGs for evaluation. The conducted experiments reveal the generic efficacy of DSPP across an extensive set of considered test case scenarios. Extensive simulation results show that DSPP can achieve up to ∼ 13% reduction in makespan in the best case and ∼ 10% on average, outperforming existing state-of-the-art methods.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4415382377",
    "type": "article"
  },
  {
    "title": "A codesign experiment in acoustic echo cancellation",
    "doi": "https://doi.org/10.1145/268424.268433",
    "publication_date": "1997-10-01",
    "publication_year": 1997,
    "authors": "Laurent Freund; M. Israël; Frédéric Rousseau; Jean-Michel Bergé; Michel Auguin; Cécile Belleudy; Guy Gogniat",
    "corresponding_authors": "",
    "abstract": "Continuous advances in processor and ASIC technologies enable the integration of more and more complex embedded systems. Embedded systems have become commonplace in recent years. Since their implementations generally require the use of heterogeneous resources (e.g., processor cores, ASICs) in one system with hard design constraints, the importance of hardware/software codesign methodologies increases steadily. HW/SW codesign approaches consist generally of HW/SW partitioning and scheduling, constrained code generation, and hardware and interface synthesis. This article presents the codesign of an industrial experiment in acoustic echo cancellation (GMDFα algorithm); and emphasizes the partitioning and communication synthesis steps. This experiment brings to light interesting problems such as data and program distribution between system memories and the modeling of communications in the partitioning process",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W2002568004",
    "type": "article"
  },
  {
    "title": "Code generation for fixed-point DSPs",
    "doi": "https://doi.org/10.1145/290833.290837",
    "publication_date": "1998-04-01",
    "publication_year": 1998,
    "authors": "Guido Araújo; Sharad Malik",
    "corresponding_authors": "",
    "abstract": "This paper examines the problem of code-generation for Digital Signal Processors (DSPs). We make two major contributions. First, for an important class of DSP architectures, we propose an optimal O(n) algorithm for the tasks of register allocation and instruction scheduling for expression trees. Optimality is guaranteed by sufficient conditions derived from a structural representation of the processor Instruction Set Architecture (ISA). Second, we develop heuristics for the case when basic blocks are Directed Acyclic Graphs (DAGs).",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W1999421209",
    "type": "article"
  },
  {
    "title": "Verifying sequential equivalence using ATPG techniques",
    "doi": "https://doi.org/10.1145/375977.376022",
    "publication_date": "2001-04-01",
    "publication_year": 2001,
    "authors": "Shi‐Yu Huang; Kwang‐Ting Cheng; Kuang-Chien Chen",
    "corresponding_authors": "",
    "abstract": "In this paper we address the problem of verifying the equivalence of two sequential circuits. State-of-the-art sequential optimization techniques such as retiming and sequential redundancy removal can handle designs with up to hundreds or even thousands of flip-flops. However, the BDD-based approaches for verifying sequential equivalence can easily run into memory explosion for such designs. In an attempt to handle larger circuits, we modify test pattern-generation techniques for verification. The suggested approach utilizes the popular efficient backward-justification technique used in most sequential ATPG programs. We present several techniques to enhance the efficiency of this approach by (1) identifying equivalent flip-flop pairs using an induction-based algorithm, and (2) generalizing the idea of exploring the structural similarity between circuits to perform verification in stages. This ATPG-based framework is suitable for verifying circuits either with or without a reset state. In order to extend this approach to verify retimed circuits, we introduce a delay-compensation-based algorithm for preprocessing the circuits. The experimental results of verifying the correctness of circuits after sequential redundancy removal and retiming with up to several hundred flip-flops are presented.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W2002125840",
    "type": "article"
  },
  {
    "title": "Hardware/software synthesis of formal specifications in codesign of embedded systems",
    "doi": "https://doi.org/10.1145/348019.348093",
    "publication_date": "2000-07-01",
    "publication_year": 2000,
    "authors": "Vincenza Carchiolo; Michele Malgeri; Guiseppe Mangioni",
    "corresponding_authors": "",
    "abstract": "CoDesign aims to integrate the design techniques of hardware and software. In this work, we present a CoDesign methodology based on a formal approach to embedded system specification. This methodology uses the Templated T-LOTOS language to specify the system during all design phases. Templated T-LOTOS is a formal language based on CCS and CSP models. Using Templated T-LOTOS, a system can be specified by observing the temporal ordering in which the events occur from the outside. In this paper we focus on the synthesis of system specified by Templated T-LOTOS. The proposed synthesis algorithm takes advantage of peculiarities of Templates T-LOTOS. Hardware modules are translated into a register transfer-level language that manages some signals in order to drive synchronization, while the software models are translated into C according to a finite state model whose operations are controlled by a scheduler. The synthesis of the Templated T-LOTOS specification is based on the direct translation of the language operators to ensure that the implemented system is the same as the specified one.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W2089029647",
    "type": "article"
  },
  {
    "title": "Data memory design and exploration for low-power embedded systems",
    "doi": "https://doi.org/10.1145/502175.502182",
    "publication_date": "2001-10-01",
    "publication_year": 2001,
    "authors": "Wen Tsong Shiue; Sathishkumar Udayanarayanan; Chaitali Chakrabarti",
    "corresponding_authors": "",
    "abstract": "In embedded system design, the designer has to choose an on-chip memory configuration that is suitable for a specific application. To aid in this design choice, we present a memory exploration procedure based on three performance metrics, namely, cache size, the memory access time and the energy consumption. We show the importance of including energy in the performance metrics, since an increase in the cache size and line size reduces the memory access time but does not necessarily reduce the energy consumption. The memory exploration procedures enable us to find the cache configuration (cache size, line size) that satisfies the area and time constraints while minimizing the energy consumption, and the cache configuration that satisfies the area and energy constraints while minimizing the memory access time. The exploration procedures for cache configuration is very efficient since it considers only a selected set of candidate points. Finally, we validate our exploration procedures by running simulation experiments on MediaBench applications.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W2022268722",
    "type": "article"
  },
  {
    "title": "Structural gate decomposition for depth-optimal technology mapping in LUT-based FPGA designs",
    "doi": "https://doi.org/10.1145/335043.335045",
    "publication_date": "2000-04-01",
    "publication_year": 2000,
    "authors": "Jason Cong; Yean-Yow Hwang",
    "corresponding_authors": "",
    "abstract": "In this paper we study structural gate decomposition in general, simple gate networks for depth-optimal technology mapping using K -input Lookup-Tables ( K -LUTs). We show that (1) structural gate decomposition in any K -bounded network results in an optimal mapping depth smaller than or equal to that of the original network, regardless of the decomposition method used; and (2) the problem of structural gate decomposition for depth-optimal technology mapping is NP-hard for K -unbounded networks when K ≥3 and remains NP-hard for K -boundeds networks when K ≥5. Based on these results, we propose two new structural gate decomposition algorithms, named DOGMA and DOGMA-m, which combine the level-driven node-packing technique (used in FlowMap) and the network flow-based labeling technique (used in Chortle-d) for depth-optimal technology mapping. Experimental results show that (1) among five structural gate decompostion algorithms, DOGMA-m results in the best mapping solutions; and (2) compared with speed_up(an algebraic algorithm) and TOS (a Boolean approach), DOGMA-m completes, decomposition of all tested benchmarks in a short time while speed_up and TOS fail in several cases. However, speed_up results in the smallest depth and area in the following technology mapping steps.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W2060499749",
    "type": "article"
  },
  {
    "title": "On the properties of the input pattern fault model",
    "doi": "https://doi.org/10.1145/606603.606609",
    "publication_date": "2003-01-01",
    "publication_year": 2003,
    "authors": "R.D. Blanton; John P. Hayes",
    "corresponding_authors": "",
    "abstract": "A review of traditional IC failure analysis techniques strongly indicates the need for fault models that directly analyze the function of circuit primitives. The input pattern (IP) fault model is a functional fault model that allows for both complete and partial functional verification of every circuit module, independent of the design level. We describe the IP fault model and provide a method for analyzing IP faults using standard single stuck-line- (SSL-) based fault simulators and test generation tools. The method is used to generate test sets that target the IP faults of the ISCAS85 benchmark circuits and a carry-lookahead adder. Improved IP fault coverage for the benchmarks and the adder is obtained by adding a small number of test patterns to tests that target only SSL faults. We also conducted fault simulation experiments that show IP test patterns are effective in detecting nontargeted faults such as bridging and transistor stuck-on faults. Finally, we discuss the notion of IP redundancy and show how large amounts of this redundancy exist in the benchmarks and in SSL-irredundant adder circuits.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W2050670618",
    "type": "article"
  },
  {
    "title": "Storage requirement estimation for optimized design of data intensive applications",
    "doi": "https://doi.org/10.1145/989995.989996",
    "publication_date": "2004-04-01",
    "publication_year": 2004,
    "authors": "Per Gunnar Kjeldsberg; Francky Catthoor; E. J.",
    "corresponding_authors": "",
    "abstract": "A novel storage requirement estimation methodology is presented for use in the early system design phases when the data transfer ordering is only partially fixed. At that stage, none of the existing estimation tools are adequate, as they either assume a fully specified execution order or ignore it completely. A prototype CAD tool has been developed that includes major parts of the storage requirement estimation and optimization methodology. Using representative application demonstrators, we show how our techniques and tool can effectively guide the designer to achieve a transformed specification with low storage requirement.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W2004094800",
    "type": "article"
  },
  {
    "title": "A 4-geometry maze router and its application on multiterminal nets",
    "doi": "https://doi.org/10.1145/1044111.1044118",
    "publication_date": "2005-01-01",
    "publication_year": 2005,
    "authors": "Gene Eu Jan; Ki-Yin Chang; Su Gao; Ian Parberry",
    "corresponding_authors": "",
    "abstract": "The maze routing problem is to find an optimal path between a given pair of cells on a grid plane. Lee's algorithm and its variants, probably the most widely used maze routing method, fails to work in the 4-geometry of the grid plane. Our algorithm solves this problem by using a suitable data structure for uniform wave propagation in the 4-geometry, 8-geometry, etc. The algorithm guarantees finding an optimal path if it exists and has linear time and space complexities. Next, to solve the obstacle-avoiding rectilinear and 4-geometry Steiner tree problems, a heuristic algorithm is presented. The algorithm utilizes a cost accumulation scheme based on the maze router to determine the Torricelli vertices (points) for improving the quality of multiterminal nets. Our experimental results show that the algorithm works well in practice. Furthermore, using the 4-geometry router, path lengths can be significantly reduced up to 12% compared to those in the rectilinear router.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W1972142782",
    "type": "article"
  },
  {
    "title": "A BNF-based automatic test program generator for compatible microprocessor verification",
    "doi": "https://doi.org/10.1145/966137.966142",
    "publication_date": "2004-01-01",
    "publication_year": 2004,
    "authors": "Lieh-Ming Wu; Kuochen Wang; Chuang-Yi Chiu",
    "corresponding_authors": "",
    "abstract": "A novel Backus-Naur-form- (BNF-) based method to automatically generate test programs from simple to complex ones for advanced microprocessors is presented in this paper. We use X86 architecture to illustrate our design method. Our method is equally applicable to other processor architectures by redefining BNF production rules. Design issues for an automatic program generator (APG) are first outlined. We have resolved the design issues and implemented the APG by a top-down recursive descent parsing method which was originated from compiler design. Our APG can produce not only random test programs but also a sequence of instructions for a specific module to be tested by specifying a user menu-driven file. In addition, test programs generated by our APG have the features of no infinite loop, not entering illegal states, controllable data dependency, flexible program size, and data cache testable. Our method has been shown to be efficient and feasible for the development of an APG compared with other approaches. We have also developed a coverage tool to integrate with the APG. Experimental evaluation of the generated test programs indicates that our APG, with the guidance of the coverage tool, only needs to generate a small number of test programs to sustain high coverage.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W2006892971",
    "type": "article"
  },
  {
    "title": "Compilation framework for code size reduction using reduced bit-width ISAs (rISAs)",
    "doi": "https://doi.org/10.1145/1124713.1124722",
    "publication_date": "2006-01-01",
    "publication_year": 2006,
    "authors": "Aviral Shrivastava; Partha Pratim Biswas; Ashok Halambi; Nikil Dutt; Alex Nicolau",
    "corresponding_authors": "",
    "abstract": "For many embedded applications, program code size is a critical design factor. One promising approach for reducing code size is to employ a “dual instruction set”, where processor architectures support a normal (usually 32-bit) Instruction Set, and a narrow, space-efficient (usually 16-bit) Instruction Set with a limited set of opcodes and access to a limited set of registers. This feature however, requires compilers that can reduce code size by compiling for both Instruction Sets. Existing compiler techniques operate at the routine-level granularity and are unable to make the trade-off between increased register pressure (resulting in more spills) and decreased code size. We present a compilation framework for such dual instruction sets, which uses a profitability based compiler heuristic that operates at the instruction-level granularity and is able to effectively take advantage of both Instruction Sets. We demonstrate consistent and improved code size reduction (on average 22%), for the MIPS 32/16 bit ISA. We also show that the code compression obtained by this “dual instruction set” technique is heavily dependent on the application characteristics and the narrow Instruction Set itself.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W2034618295",
    "type": "article"
  },
  {
    "title": "Workload-ahead-driven online energy minimization techniques for battery-powered embedded systems with time-constraints",
    "doi": "https://doi.org/10.1145/1188275.1188280",
    "publication_date": "2007-01-01",
    "publication_year": 2007,
    "authors": "Yuan Cai; Markus Schmitz; Bashir M. Al‐Hashimi; S.M. Reddy",
    "corresponding_authors": "",
    "abstract": "This article proposes a new online voltage scaling (VS) technique for battery-powered embedded systems with real-time constraints. The VS technique takes into account the execution times and discharge currents of tasks to further reduce the battery charge consumption when compared to the recently reported slack forwarding technique [Ahmed and Chakrabarti 2004], while maintaining low online complexity of O (1). Furthermore, we investigate the impact of online rescheduling and remapping on the battery charge consumption for tasks with data dependency which has not been explicitly addressed in the literature and propose a novel rescheduling/remapping technique. Finally, we take leakage power into consideration and extend the proposed online techniques to include adaptive body biasing (ABB) which is used to reduce the leakage power. We demonstrate and compare the efficiency of the presented techniques using seven real-life benchmarks and numerous automatically generated examples.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W1991260874",
    "type": "article"
  },
  {
    "title": "Postplacement rewiring by exhaustive search for functional symmetries",
    "doi": "https://doi.org/10.1145/1255456.1255469",
    "publication_date": "2007-08-17",
    "publication_year": 2007,
    "authors": "Kai-Hui Chang; Igor L. Markov; Valeria Bertacco",
    "corresponding_authors": "",
    "abstract": "We propose two new algorithms for rewiring: a postplacement optimization that reconnects pins of a given netlist without changing the logic function and gate locations. In the first algorithm, we extract small subcircuits consisting of several gates from the design and reconnect pins according to the symmetries of the subcircuits. To enhance the power of symmetry detection, we also propose a graph-based symmetry detector that can identify permutational and phase-shift symmetries on multiple input and output wires, as well as hybrid symmetries, creating abundant opportunities for rewiring. Our second algorithm, called long-range rewiring, is based on reconnecting equivalent pins and can augment the first approach for further optimization. We apply our techniques for wirelength optimization and observe that they provide wirelength reduction comparable to that achieved by detailed placement.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2088032122",
    "type": "article"
  },
  {
    "title": "Optimization of polynomial datapaths using finite ring algebra",
    "doi": "https://doi.org/10.1145/1278349.1278362",
    "publication_date": "2007-09-01",
    "publication_year": 2007,
    "authors": "Sivaram Gopalakrishnan; Priyank Kalla",
    "corresponding_authors": "",
    "abstract": "This article presents an approach to area optimization of arithmetic datapaths at register-transfer level (RTL). The focus is on those designs that perform polynomial computations (add, mult) over finite word-length operands (bit-vectors). We model such polynomial computations over m -bit vectors as algebra over finite integer rings of residue classes Z 2 m . Subsequently, we use the number-theoretic and algebraic properties of such rings to transform a given datapath computation into another, bit-true equivalent computation. We also derive a cost model to estimate, at RTL, the area cost of the computation. Using the transformation procedure along with the cost model, we devise algorithmic procedures to search for a lower-cost implementation. We show how these theoretical concepts can be applied to RTL optimization of arithmetic datapaths within practical CAD settings. Experiments conducted over a variety of benchmarks demonstrate substantial optimizations using our approach.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W1989423571",
    "type": "article"
  },
  {
    "title": "ILP-Based energy minimization techniques for banked memories",
    "doi": "https://doi.org/10.1145/1367045.1367059",
    "publication_date": "2008-07-01",
    "publication_year": 2008,
    "authors": "Özcan Öztürk; Mahmut Kandemir",
    "corresponding_authors": "",
    "abstract": "Main memories can consume a significant portion of overall energy in many data-intensive embedded applications. One way of reducing this energy consumption is banking, that is, dividing available memory space into multiple banks and placing unused (idle) memory banks into low-power operating modes. Prior work investigated code-restructuring- and data-layout-reorganization-based approaches for increasing the energy benefits that could be obtained from a banked memory architecture. This article explores different techniques that can potentially coexist within the same optimization framework for maximizing benefits of low-power operating modes. These techniques include employing nonuniform bank sizes, data migration, data compression, and data replication. By using these techniques, we try to increase the chances for utilizing low-power operating modes in a more effective manner, and achieve further energy savings over what could be achieved by exploiting low-power modes alone. Specifically, nonuniform banking tries to match bank sizes with application-data access patterns. The goal of data migration is to cluster data with similar access patterns in the same set of banks. Data compression reduces the size of the data used by an application, and thus helps reduce the number of memory banks occupied by data. Finally, data replication increases bank idleness by duplicating select read-only data blocks across banks. We formulate each of these techniques as an ILP (integer linear programming) problem, and solve them using a commercial solver. Our experimental analysis using several benchmarks indicates that all the techniques presented in this framework are successful in reducing memory energy consumption. Based on our experience with these techniques, we recommend to compiler writers for banked memories to consider data compression, replication, and migration.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W2016823211",
    "type": "article"
  },
  {
    "title": "Ultra-fast and efficient algorithm for energy optimization by gradient-based stochastic voltage and task scheduling",
    "doi": "https://doi.org/10.1145/1278349.1278352",
    "publication_date": "2007-09-01",
    "publication_year": 2007,
    "authors": "Bita Gorjiara; Nader Bagherzadeh; Pai H. Chou",
    "corresponding_authors": "",
    "abstract": "This paper presents a new technique, called Adaptive Stochastic Gradient Voltage-and-Task Scheduling (ASG-VTS), for power optimization of multicore hard realtime systems. ASG-VTS combines stochastic and energy-gradient techniques to simultaneously solve the slack distribution and task reordering problem. It produces very efficient results with few mode transitions. Our experiments show that ASG-VTS reduces number of mode transitions by 4.8 times compared to traditional energy-gradient-based approaches. Also, our heuristic algorithm can quickly find a solution that is as good as the optimal for a real-life GSM encoder/decoder benchmark. The runtime of ASG-VTS is 150 times and 1034 times faster than energy-gradient based and optimal ILP algorithms, respectively. Since the runtime of ASG-VTS is very low, it is ideal for design space exploration in system-level design tools. We have also developed a web-based interface for ASG-VTS algorithm.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W2027183973",
    "type": "article"
  },
  {
    "title": "Physical synthesis for FPGA interconnect power reduction by dual-Vdd budgeting and retiming",
    "doi": "https://doi.org/10.1145/1344418.1344426",
    "publication_date": "2008-04-02",
    "publication_year": 2008,
    "authors": "Yu Hen Hu; Yan Lin; Lei He; Tim Tuan",
    "corresponding_authors": "",
    "abstract": "Field programmable dual-Vdd interconnects are effective in reducing FPGA power. We formulate the dual-Vdd-aware slack budgeting problem as a linear program (LP) and a min-cost network flow problem, respectively. Both algorithms reduce interconnect power by 50% on average compared to single-Vdd interconnects, but the network-flow-based algorithm runs 11x faster on MCNC benchmarks. Furthermore, we develop simultaneous retiming and slack budgeting (SRSB) with flip-flop layout constraints in dual-Vdd FPGAs based on mixed integer linear programming, and speed-up the algorithm by LP relaxation and local legalization. Compared to retiming followed by slack budgeting, SRSB reduces interconnect power by up to 28.8%.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W1979667739",
    "type": "article"
  },
  {
    "title": "A multiprocessor system-on-chip for real-time biomedical monitoring and analysis",
    "doi": "https://doi.org/10.1145/1344418.1344427",
    "publication_date": "2008-04-02",
    "publication_year": 2008,
    "authors": "Iyad Al Khatib; Francesco Poletti; Davide Bertozzi; Luca Benini; Mohamed Bechara; Hasan Khalifeh; Axel Jantsch; Rustam Nabiev",
    "corresponding_authors": "",
    "abstract": "In this article we focus on multiprocessor system-on-chip (MPSoC) architectures for human heart electrocardiogram (ECG) real time analysis as a hardware/software (HW/SW) platform offering an advance relative to state-of-the-art solutions. This is a relevant biomedical application with good potential market, since heart diseases are responsible for the largest number of yearly deaths. Hence, it is a good target for an application-specific system-on-chip (SoC) and HW/SW codesign. We investigate a symmetric multiprocessor architecture based on STMicroelectronics VLIW DSPs that process in real time 12-lead ECG signals. This architecture improves upon state-of-the-art SoC designs for ECG analysis in its ability to analyze the full 12 leads in real time, even with high sampling frequencies, and its ability to detect heart malfunction for the whole ECG signal interval. We explore the design space by considering a number of hardware and software architectural options. Comparing our design with present-day solutions from an SoC and application point-of-view shows that our platform can be used in real time and without failures.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2012487446",
    "type": "article"
  },
  {
    "title": "Thermal sensor allocation and placement for reconfigurable systems",
    "doi": "https://doi.org/10.1145/1562514.1562518",
    "publication_date": "2009-08-01",
    "publication_year": 2009,
    "authors": "Byung-Hyun Lee; Ki‐Seok Chung; Bontae Koo; Nak-Woong Eum; Taewhan Kim",
    "corresponding_authors": "",
    "abstract": "A dynamic monitoring of thermal behavior of hardware resources using thermal sensors is very important to maintain the operation of systems safe and reliable. This article addresses the problem of thermal sensor allocation and placement for reconfigurable systems. For programmable logic arrays, the degree of the use of hardware resources in the systems highly depends on the target application to be implemented, making the allocation of thermal sensors at the manufacturing stage inadequate (or too costly if implemented) due to the unpredictable thermal profile. This means that the thermal sensor allocation could be processed at the time when the reconfigurable logic is implemented (i.e., at the post manufacturing stage). This work proposes an effective solution to the problem of thermal sensor allocation and placement at the post-manufacturing stage. Specifically, we define the Sensor Allocation and Placement Problem (SAPP), and propose a solution which formulates SAPP into the Unate-Covering Problem (UCP) and solves it optimally. Also we combine SAPP with temperature correlation to reduce required sensors more aggressively and propose a solution by applying UCP again. We then provide an extended solution to handle a practical design issue where the hardware resources for the sensor implementation on specific array locations have already been used up by the application logic. Experimental results using MCNC benchmarks show that our proposed technique uses 62.4% and 19.7% less number of sensors to monitor hotspots on the average than that used by the grid-based and the bisection-based approaches while the overhead of auxiliary circuitry is minimized, respectively.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2142803377",
    "type": "article"
  },
  {
    "title": "Interconnect customization for a hardware fabric",
    "doi": "https://doi.org/10.1145/1455229.1455240",
    "publication_date": "2009-01-01",
    "publication_year": 2009,
    "authors": "Gayatri Mehta; Justin Stander; Mustafa Baz; Brady Hunsaker; Alex K. Jones",
    "corresponding_authors": "",
    "abstract": "This article describes several multiplexer-based interconnection strategies designed to improve energy consumption of stripe-based coarse-grain reconfigurable fabrics. Application requirements for the architecture as well as two dense subgraphs are extracted from a suite of signal and image processing benchmarks. These statistics are used to drive the strategy of the composition of multiplexer-based interconnect. The article compares interconnects that are fully connected between stripes, those with a cardinality of 8:1 to 4:1, and extensions that provide a 5:1 cardinality, limited 6:1 cardinality, and hybrids between 5:1 and 3:1 cardinalities. Additionally, dedicated vertical routes are considered replacing some computational units with dedicated pass-gates. Using a fabric interconnect model (FIM) written in XML, we demonstrate that fabric instances and mappers can be automatically generated using a Web-based design flow. Upon testing these instances, we found that using an 8:1 cardinality interconnect with 33% of the computational units replaced with dedicated pass-gates provided the best energy versus mappability tradeoff, resulting in a 50% energy improvement over fully connected rows and 20% energy improvement over an 8:1 cardinality interconnect without dedicated vertical routes.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W1969025107",
    "type": "article"
  },
  {
    "title": "On the completeness of the polymorphic gate set",
    "doi": "https://doi.org/10.1145/1835420.1835425",
    "publication_date": "2010-09-01",
    "publication_year": 2010,
    "authors": "Zhifang Li; Wenjian Luo; Lihua Yue; Xufa Wang",
    "corresponding_authors": "",
    "abstract": "Polymorphic gates are special kinds of logic gates that can exhibit different functions under the control of environmental parameters, such as light, temperature, and VDD. These polymorphic gates can be used to build polymorphic circuits that perform different functions under different environments. Because polymorphic gates are different from traditional logic gates, the existent completeness theory for the traditional logic gate set is not suitable for the polymorphic gate set. So far, only the definition of the complete polymorphic gate set is given. There is no approach to judging whether a given polymorphic gate set is complete. The contributions of this article include three aspects. First, the impact of logic-1 and logic-0 on the completeness of the polymorphic gate set is discussed. Second, the theory and two related algorithms for judging the completeness of polymorphic gate sets with two modes are given. Finally, the theory and related algorithms for complete polymorphic gate sets with more than two modes are proposed.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2020322960",
    "type": "article"
  },
  {
    "title": "High-performance obstacle-avoiding rectilinear steiner tree construction",
    "doi": "https://doi.org/10.1145/1529255.1529267",
    "publication_date": "2009-05-01",
    "publication_year": 2009,
    "authors": "Chih-Hung Liu; Shih‐Yi Yuan; Sy‐Yen Kuo; Szu-Chi Wang",
    "corresponding_authors": "",
    "abstract": "Rectilinear Steiner trees are used to route signal nets by global and detail routers in VLSI design for a long time. However, in current IC industry, there are significantly increasing obstacles to be considered, such as large-scale power networks, pre-routed nets, IP blocks, and antenna jumpers. Accordingly, the obstacle-avoiding rectilinear Steiner minimal tree (OARSMT) problem has become more important. In this article, we propose a new routing graph, obstacle-avoiding routing graph (OARG), for the OARSMT problem. Due to the important properties of OARG, we construct a 3-step algorithm and a local refinement scheme, which both can take advantage of these properties, to find a suboptimal solution efficiently. Furthermore, each step of our 3-step algorithm as well as the local refinement scheme has theoretical or practical benefits. Therefore, each of them can be applicable to other existing works for general or specific considerations such as efficiency or effectiveness. Extensive experimental results show that our method outperforms all existing works in terms of wirelength and achieves the best speed performance.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2025854031",
    "type": "article"
  },
  {
    "title": "A gridless routing system with nonslicing floorplanning-based crosstalk reduction on gridless track assignment",
    "doi": "https://doi.org/10.1145/1929943.1929951",
    "publication_date": "2011-03-01",
    "publication_year": 2011,
    "authors": "Yih-Lang Li; Yu‐Ning Chang; Wen-Nai Cheng",
    "corresponding_authors": "",
    "abstract": "Track assignment, which is an intermediate stage between global routing and detailed routing, provides a good platform for promoting performance, and for imposing additional constraints during routing, such as crosstalk. Gridless track assignment (GTA) has not been addressed in public literature. This work develops a gridless routing system integrating a congestion-driven global router, crosstalk-driven GTA and an enhanced implicit connection-graph-based router. Initial assignment is produced rapidly with a left-edge like algorithm. Crosstalk reduction on the assignment is then transformed to a restricted nonslicing floorplanning problem, and a deterministic O-Tree based algorithm is employed to reassign each net segment. Finally, each panel is partitioned into several subpanels, and the subpanels are reordered using branch and bound algorithm to decrease the crosstalk further. Before detailed routing, routing tree construction is undertaken for placed IRoutes and other pins; many original point-to-point routings are set to connect to IRoutes, and can be accomplished simply with pattern routing. For detailed routing, this work proposes a rapid extraction method for pseudomaximum stripped tiles to boost path propagation. Experimental results demonstrate that the proposed gridless routing system has over 2.02 times the runtime speedup in average for fixed- and variable-rule routings of an implicit connection-graph-based router, NEMO. As compared with a commercial routing tool, this work yields an average reduction rate of 13.8% in coupling capacitance calculated using its built-in coupling capacitance estimator.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W1975619379",
    "type": "article"
  },
  {
    "title": "TEI-power",
    "doi": "https://doi.org/10.1145/3019941",
    "publication_date": "2017-04-21",
    "publication_year": 2017,
    "authors": "Woojoo Lee; Kyuseung Han; Yanzhi Wang; Tiansong Cui; Shahin Nazarian; Massoud Pedram",
    "corresponding_authors": "",
    "abstract": "FinFETs have emerged as a promising replacement for planar CMOS devices in sub-20nm technology nodes. However, based on the temperature effect inversion (TEI) phenomenon observed in FinFET devices, the delay characteristics of FinFET circuits in sub-, near-, and superthreshold voltage regimes may be fundamentally different from those of CMOS circuits with nominal voltage operation. For example, FinFET circuits may run faster in higher temperatures. Therefore, the existing CMOS-based and TEI-unaware dynamic power and thermal management techniques would not be applicable. In this article, we present TEI-power, a dynamic voltage and frequency scaling--based dynamic thermal management technique that considers the TEI phenomenon and also the superlinear dependencies of power consumption components on the temperature and outlines a real-time trade-off between delay and power consumption as a function of the chip temperature to provide significant energy savings, with no performance penalty—namely, up to 42% energy savings for small circuits where the logic cell delay is dominant and up to 36% energy savings for larger circuits where the interconnect delay is considerable.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2606628626",
    "type": "article"
  },
  {
    "title": "Optimal Scheduling and Allocation for IC Design Management and Cost Reduction",
    "doi": "https://doi.org/10.1145/3035483",
    "publication_date": "2017-06-09",
    "publication_year": 2017,
    "authors": "Prabhav Agrawal; Mike Broxterman; Biswadeep Chatterjee; Patrick Cuevas; Kathy H. Hayashi; Andrew B. Kahng; Pranay K. Myana; Siddhartha Nath",
    "corresponding_authors": "",
    "abstract": "A large semiconductor product company spends hundreds of millions of dollars each year on design infrastructure to meet tapeout schedules for multiple concurrent projects. Resources (servers, electronic design automation tool licenses, engineers, and so on) are limited and must be shared -- and the cost per day of schedule slip can be enormous. Co-constraints between resource types (e.g., one license per every two cores (threads)) and dedicated versus shareable resource pools make scheduling and allocation hard. In this article, we formulate two mixed integer-linear programs for optimal multi-project, multi-resource allocation with task precedence and resource co-constraints. Application to a real-world three-project scheduling problem extracted from a leading-edge design center of anonymized Company X shows substantial compute and license costs savings. Compared to the product company, our solution shows that the makespan of schedule of all projects can be reduced by seven days, which not only saves ∼ 2.7% of annual labor and infrastructure costs but also enhances market competitiveness. We also demonstrate the capability of scheduling over two dozen chip development projects at the design center level, subject to resource and datacenter capacity limits as well as per-project penalty functions for schedule slips. The design center ended up purchasing 600 additional servers, whereas our solution demonstrates that the schedule can be met without having to purchase any additional servers. Application to a four-project scheduling problem extracted from a leading-edge design center in a non-US location shows availability of up to ∼ 37% headcount reduction during a half-year schedule for just one type of chip design activity.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2623332009",
    "type": "article"
  },
  {
    "title": "Routable and Matched Layout Styles for Analog Module Generation",
    "doi": "https://doi.org/10.1145/3182169",
    "publication_date": "2018-06-28",
    "publication_year": 2018,
    "authors": "Bo Liu; Gong Chen; Bo Yang; Shigetoshi Nakatake",
    "corresponding_authors": "",
    "abstract": "Two 1 novel automatic generation methods for analog layout—a symmetrical twin-row method for MOS transistors and a twisted common-centroid method for capacitor arrays—are introduced. Based on the proposed layout styles and the corresponding algorithms, the symmetry and common-centroid placement patterns for analog devices are realized to guarantee matching properties. On this basis, as the most prominent contribution of this article, channel routing-based algorithms for the proposed layout styles are presented and could achieve 100% routability due to well-arranged devices and corresponding low routing complexity. The algorithms benefits include a small layout area that maximizes the diffusion-sharing of MOS transistors and less routing layer usage for common-centroid device arrays. Moreover, we successfully applied our algorithms to the layout designs of two typical analog modules including a two-stage operating amplifier and a Successive Approximation Register Analog-to-Digital Converter (SAR-ADC). The generated layouts and the circuit simulation results demonstrate the effectiveness of our algorithms in terms of their routability and matching properties. Our algorithms can also be extended to apply to a variety of essential MOS analog circuits.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2811209689",
    "type": "article"
  },
  {
    "title": "Reverse Engineering Digital ICs through Geometric Embedding of Circuit Graphs",
    "doi": "https://doi.org/10.1145/3193121",
    "publication_date": "2018-07-18",
    "publication_year": 2018,
    "authors": "Burçin Çakır; Sharad Malik",
    "corresponding_authors": "",
    "abstract": "Outsourcing of design and manufacturing processes makes integrated circuits (ICs) vulnerable to adversarial changes and raises concerns about their integrity. Reverse engineering the manufactured netlist helps identify malicious insertions. In this article, we present an automated approach that, given a reference design description with high-level blocks, infers these blocks in an untrusted gate-level (test) implementation. Using the graph connectivity of the netlists, we compute a geometric embedding for each wire in the circuits, which, then, is used to compute a bipartite matching between the nodes of the two designs and identify high-level blocks in the test circuit. Experiments to evaluate the efficacy of the proposed technique on various-sized designs, including the multi-core processor OpenSparc T1, show that it can correctly match over 90% of gates in the test circuit to their corresponding block in the reference model.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2884646805",
    "type": "article"
  },
  {
    "title": "Non-Intrusive In-Situ Requirements Monitoring of Embedded System",
    "doi": "https://doi.org/10.1145/3206213",
    "publication_date": "2018-08-20",
    "publication_year": 2018,
    "authors": "Minjun Seo; Roman Lysecky",
    "corresponding_authors": "",
    "abstract": "Accounting for all operating conditions of a system at the design stage is typically infeasible for complex systems. Monitoring and verifying system requirements at runtime enable a system to continuously and introspectively ensure the system is operating correctly in the presence of dynamic execution scenarios. In this article, we present a requirements-driven methodology enabling efficient runtime monitoring of embedded systems. The proposed approach extracts a runtime monitoring graph from system requirements specified using UML sequence diagrams. Non-intrusive, on-chip hardware dynamically monitors the system execution, verifies the execution adheres to the requirements model, and in the event of a failure provides detailed information that can be analyzed to determine the root cause. Using case studies of an autonomous vehicle and pacemaker prototypes, we analyze the relationship between event coverage, detection rate, and hardware requirements",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2888285544",
    "type": "article"
  },
  {
    "title": "PV-Aware Analog Sizing for Robust Analog Layout Retargeting with Optical Proximity Correction",
    "doi": "https://doi.org/10.1145/3236624",
    "publication_date": "2018-11-06",
    "publication_year": 2018,
    "authors": "Xuan Dong; Lihong Zhang",
    "corresponding_authors": "",
    "abstract": "For analog integrated circuits (ICs) in nanometer technology nodes, process variation (PV) induced by lithography may not only cause serious wafer pattern distortion, but also result in device mismatch, which can readily ruin circuit performance. Although the conventional optical proximity correction (OPC) operations can effectively improve the wafer image fidelity, an analog circuit without robust device sizes is still highly vulnerable to such a mismatch effect. In this article, a PV-aware sizing-inclusive analog layout retargeting framework, which encloses an efficient hybrid OPC scheme for yield enhancement, is proposed. The device sizes are tuned during the layout retargeting process by using a deterministic circuit-sizing algorithm considering PV conditions. Our hybrid OPC method combines global rule-based OPC with local model-based OPC functions to boost the wafer image quality improvement but without degrading the computational efficiency. The experimental results show that our proposed framework can achieve the best wafer image quality and circuit performance preservation compared to any other alternative approaches.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2899985657",
    "type": "article"
  },
  {
    "title": "Performance-Aware Test Scheduling for Diagnosing Coexistent Channel Faults in Topology-Agnostic Networks-on-Chip",
    "doi": "https://doi.org/10.1145/3291532",
    "publication_date": "2019-01-10",
    "publication_year": 2019,
    "authors": "Biswajit Bhowmik; Jatindra Kumar Deka; Santosh Biswas; Bhargab B. Bhattacharya",
    "corresponding_authors": "",
    "abstract": "High--performance multiprocessor SoCs used in practice require a complex network-on-chip (NoC) as communication architecture, and the channels therein often suffer from various manufacturing defects. Such physical defects cause a multitude of system-level failures and subsequent degradation of reliability, yield, and performance of the computing platform. Most of the existing test approaches consider mesh-based NoC channels only and do not perform well for other regular topologies such as octagons or spidergons, with regard to test time and overhead issues. This article proposes a topology-agnostic test mechanism that is capable of diagnosing on-line, coexistent channel-short, and stuck-at faults in these special NoCs as well as in traditional mesh architectures. We introduce a new test model called Damaru to decompose the network and present an efficient scheduling scheme to reduce test time without compromising resource utilization during testing. Additionally, the proposed scheduling scheme scales well with network size, channel width, and topological diversity. Simulation results show that the method achieves nearly 92% fault coverage and improves area overhead by almost 60% and test time by 98% compared to earlier approaches. As a sequel, packet latency and energy consumption are also improved by 67.05% and 54.69%, respectively, and they are further improved with increasing network size.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2909219026",
    "type": "article"
  },
  {
    "title": "Writeback-Aware LLC Management for PCM-Based Main Memory Systems",
    "doi": "https://doi.org/10.1145/3292009",
    "publication_date": "2019-01-10",
    "publication_year": 2019,
    "authors": "Bahareh Pourshirazi; Majed Valad Beigi; Zhichun Zhu; Gokhan Memik",
    "corresponding_authors": "",
    "abstract": "With the increase in the number of data-intensive applications on today's workloads, DRAM-based main memories are struggling to satisfy the growing data demand capacity. Phase Change Memory (PCM) is a type of non-volatile memory technology that has been explored as a promising alternative for DRAM-based main memories due to its better scalability and lower leakage energy. Despite its many advantages, PCM also has shortcomings such as long write latency, high write energy consumption, and limited write endurance, which are all related to the write operations. In this article, we propose a novel writeback-aware Last Level Cache (LLC) management scheme named WALL to reduce the number of LLC writebacks and consequently improve performance, energy efficiency, and lifetime of a PCM-based main memory system. First, we investigate the writeback behavior of LLC sets and show that writebacks are not uniformly distributed among sets; some sets observe much higher writeback rates than others. We then propose a writeback-aware set-balancing mechanism, which employs the underutilized LLC sets with few writebacks as an auxiliary storage for the evicted dirty lines from sets with frequent writebacks. We also propose a simple and effective writeback-aware replacement policy to avoid the eviction of the dirty blocks that are highly reused after being evicted from the cache. Our experimental results show that WALL achieves an average of 30.9% reduction in the total number of LLC writebacks, compared to the baseline scheme, which uses the LRU replacement policy. As a result, WALL can reduce the memory energy consumption by 23.1% and enhance PCM lifetime by 1.29×, on average, on an 8-core system with a 4GB PCM main memory, running memory-intensive applications.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2910314135",
    "type": "article"
  },
  {
    "title": "Bio-chemical Assay Locking to Thwart Bio-IP Theft",
    "doi": "https://doi.org/10.1145/3365579",
    "publication_date": "2019-11-22",
    "publication_year": 2019,
    "authors": "Sukanta Bhattacharjee; Jack Tang; Sudip Poddar; Mohamed Ibrahim; Ramesh Karri; Krishnendu Chakrabarty",
    "corresponding_authors": "",
    "abstract": "It is expected that as digital microfluidic biochips (DMFBs) mature, the hardware design flow will begin to resemble the current practice in the semiconductor industry: design teams send chip layouts to third-party foundries for fabrication. These foundries are untrusted and threaten to steal valuable intellectual property (IP). In a DMFB, the IP consists of not only hardware layouts but also of the biochemical assays (bioassays) that are intended to be executed on-chip. DMFB designers therefore must defend these protocols against theft. We propose to “lock” biochemical assays by inserting dummy mix-split operations. We experimentally evaluate the proposed locking mechanism, and show how a high level of protection can be achieved even on bioassays with low complexity. We also demonstrate a new class of attacks that exploit the side-channel information to launch sophisticated attacks on the locked bioassay.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2991276929",
    "type": "article"
  },
  {
    "title": "Ordered Escape Routing with Consideration of Differential Pair and Blockage",
    "doi": "https://doi.org/10.1145/3185783",
    "publication_date": "2018-05-09",
    "publication_year": 2018,
    "authors": "Fengxian Jiao; Sheqin Dong",
    "corresponding_authors": "",
    "abstract": "Ordered escape routing is a critical issue in high-speed PCB routing. Differential pair and thermal-blockage-avoided are useful in PCB design to obtain high noise immunity and low electromagnetic interference. In this article, a Min-cost Multi-commodity Flow (MMCF) approach is proposed to solve the ordered escape routing. First, the characteristic of grid pin array and staggered pin array is analyzed and then a basic network model is used to convert ordered escape routing to MMCF model. To satisfy the constraints of ordered escape routing, three novel transformations, such as non-crossing transformation, ordering transformation, and capacity transformation, are used to convert the basic network model to the final correct MMCF model. After that, the differential pair in ordered escape routing is discussed. Finally, a method to deal with the blockage issue is proposed. Experimental results show that our method achieves 100% routability for all the test cases. The method can get both a feasible solution and an optimal solution for ordered escape routing. Compared to published approaches, our method improves in both wire length and CPU time remarkably. At the same time, the proposed method can effectively avoid the blockage and deal with the differential pair.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2997962048",
    "type": "article"
  },
  {
    "title": "Least Upper Delay Bound for VBR Flows in Networks-on-Chip with Virtual Channels",
    "doi": "https://doi.org/10.1145/2733374",
    "publication_date": "2015-06-24",
    "publication_year": 2015,
    "authors": "Fahimeh Jafari; Zhonghai Lu; Axel Jantsch",
    "corresponding_authors": "",
    "abstract": "Real-time applications such as multimedia and gaming require stringent performance guarantees, usually enforced by a tight upper bound on the maximum end-to-end delay. For FIFO multiplexed on-chip packet switched networks we consider worst-case delay bounds for Variable Bit-Rate (VBR) flows with aggregate scheduling, which schedules multiple flows as an aggregate flow. VBR Flows are characterized by a maximum transfer size ( L ), peak rate ( p ), burstiness (σ), and average sustainable rate (ρ). Based on network calculus, we present and prove theorems to derive per-flow end-to-end Equivalent Service Curves (ESC), which are in turn used for computing Least Upper Delay Bounds (LUDBs) of individual flows. In a realistic case study we find that the end-to-end delay bound is up to 46.9% more accurate than the case without considering the traffic peak behavior. Likewise, results also show similar improvements for synthetic traffic patterns. The proposed methodology is implemented in C++ and has low run-time complexity, enabling quick evaluation for large and complex SoCs.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W1519206895",
    "type": "article"
  },
  {
    "title": "Accelerating FPGA debug",
    "doi": "https://doi.org/10.1145/2566668",
    "publication_date": "2014-03-01",
    "publication_year": 2014,
    "authors": "Eddie Hung; Steven J. E. Wilton",
    "corresponding_authors": "",
    "abstract": "FPGA technology is commonly used to prototype new digital designs before entering fabrication. Whilst these physical prototypes can operate many orders of magnitude faster than through a logic simulator, a fundamental limitation is their lack of on-chip visibility when debugging. To counter this, trace-buffer-based instrumentation can be installed into the prototype, allowing designers to capture a predetermined window of signal data during live operation for offline analysis. However, instead of requiring the designer to recompile their entire circuit every time the window is modified, this article proposes that an overlay network is constructed using only spare FPGA routing multiplexers to connect all circuit signals through to the trace instruments. Thus, during debugging, designers would only need to reconfigure this network instead of finding a new place-and-route solution. Furthermore, we describe how this network can deliver signals to both the trigger and trace units of these instruments, which are implemented simultaneously using dual-port RAMs. Our results show that new network configurations connecting any subset of signals to 80--90% of the available RAM capacity can be computed in less than 70 seconds, for a 100,000 LUT circuit, as many times as necessary. Our tool—QuickTrace—is available for download.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W1966105387",
    "type": "article"
  },
  {
    "title": "Synchronizing AMS Assertions with AMS Simulation",
    "doi": "https://doi.org/10.1145/2348839.2348842",
    "publication_date": "2012-10-01",
    "publication_year": 2012,
    "authors": "Subhankar Mukherjee; Pallab Dasgupta; Siddhartha Mukhopadhyay; Scott Little; John Havlicek; Srikanth Chandrasekaran",
    "corresponding_authors": "",
    "abstract": "The verification community anticipates the adoption of assertions in the Analog and Mixed-Signal (AMS) domain in the near future. Several questions need to be answered before AMS assertions are brought into practice, such as: (a) How will the languages for AMS assertions be different from the ones in the digital domain? (b) Does the analog simulator have to be assertion aware? (c) If so, then how and where on the time line will the AMS assertion checker synchronize with the analog simulator? and (d) What will be the performance penalty for monitoring AMS assertions accurately over analog simulation? This article attempts to answer these questions through theoretical analysis and empirical results obtained from industrial test cases. We study logics which extend Linear Temporal Logic (LTL) with predicates over real variables, and show that further extensions allowing the binding of real-valued variables across time makes the logic undecidable. We present a toolkit which can integrate with existing AMS simulators for checking AMS assertions on practical designs. We study the problem of synchronizing the AMS simulator with the AMS assertion checker and demonstrate the performance penalty of different synchronization options.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W1991079660",
    "type": "article"
  },
  {
    "title": "Implementing an Application-Specific Instruction-Set Processor for System-Level Dynamic Program Analysis Engines",
    "doi": "https://doi.org/10.1145/2746238",
    "publication_date": "2015-09-28",
    "publication_year": 2015,
    "authors": "Ingoo Heo; Minsu Kim; Yongje Lee; Changho Choi; Jin‐Yong Lee; Brent Byunghoon Kang; Yunheung Paek",
    "corresponding_authors": "",
    "abstract": "In recent years, dynamic program analysis (DPA) has been widely used in various fields such as profiling, finding bugs, and security. However, existing solutions have their own weaknesses. Software solutions provide flexibility in DPA but they suffer from tremendous performance overhead. In contrast, core-level hardware engines rely on specialized integrated logics and attain extremely fast computation, but they have a limited functional extensibility because the logics are tightly coupled with the host processor. To mend this, a prior system-level approach utilizes an existing channel to integrate their hardware without necessitating the host architecture modification and introduced great potential in performance. Nevertheless, the prior work does not address the detailed design and implementation of the engine, which is quite essential to leverage the deployment on real systems. To address this, in this article, we propose an implementation of programmable DPA hardware engine, called program analysis unit (PAU). PAU is an application-specific instruction-set processor (ASIP) whose instruction set is customized to reflect common features of various DPA methods. With the specialized architecture and programmability of software, our PAU aims at fast computation and sufficient flexibility. In our case studies on several DPA techniques, we show that our ASIP approach can be successfully applicable to complex DPA schemes while providing hardware-backed power in performance and software-based flexibility in analysis. Recent experiments on our FPGA prototype revealed that the performance of PAU is 4.7-13.6 times faster than pure software DPA, and the power/area consumption is also acceptably small compared to today's mobile processors.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2010435059",
    "type": "article"
  },
  {
    "title": "How to efficiently implement dynamic circuit specialization systems",
    "doi": "https://doi.org/10.1145/2491477.2491479",
    "publication_date": "2013-07-01",
    "publication_year": 2013,
    "authors": "Fatma Abouelella; Tom Davidson; Wim Meeus; Karel Bruneel; Dirk Stroobandt",
    "corresponding_authors": "",
    "abstract": "Dynamic circuit specialization (DCS) is a technique used to implement FPGA applications where some of the input data, called parameters, change slowly compared to other inputs. Each time the parameter values change, the FPGA is reconfigured by a configuration that is specialized for those new parameter values. This specialized configuration is much smaller and faster than a regular configuration. However, the overhead associated with the specialization process should be minimized to achieve the desired benefits of using the DCS technique. This overhead is represented by both the FPGA resources needed to specialize the FPGA at runtime and by the specialization time. The introduction of parameterized configurations [Bruneel and Stroobandt 2008] has improved the efficiency of DCS implementations. However, the specialization overhead still takes a considerable amount of resources and time. In this article, we explore how to efficiently build DCS systems by presenting a variety of possible solutions for the specialization process and the overhead associated with each of them. We split the specialization process into two main phases: the evaluation and the configuration phase. The PowerPC embedded processor, the MicroBlaze, and a customized processor (CP) are used as alternatives in the evaluation phase. In the configuration phase, the ICAP and a custom configuration interface (SRL configuration) are used as alternatives. Each solution is used to implement a DCS system for three applications: an adaptive finite impulse response (FIR) filter, a ternary content-addressable memory (TCAM), and a regular expression matcher (RegEx). The experiments show that the use of our CP along with the SRL configuration achieves minimum overhead in terms of resources and time. Our CP is 1.8 and 3.5 times smaller than the PowerPC and the area-optimized implementation of the MicroBlaze, respectively. Moreover, the use of the CP enables a more compact representation for the parameterized configuration in comparison to both the PowerPC and the MicroBlaze processors. For instance, in the FIR, the parameterized configuration compiled for our CP is 6--7 times smaller than that for the embedded processors.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2015780963",
    "type": "article"
  },
  {
    "title": "Fast Simulation of Networks-on-Chip with Priority-Preemptive Arbitration",
    "doi": "https://doi.org/10.1145/2755559",
    "publication_date": "2015-09-28",
    "publication_year": 2015,
    "authors": "Leandro Soares Indrusiak; James Harbin; Osmar Marchi dos Santos",
    "corresponding_authors": "",
    "abstract": "An increasingly time-consuming part of the design flow of on-chip multiprocessors is the simulation of the interconnect architecture. The accurate simulation of state-of-the art network-on-chip interconnects can take hours, and this process is repeated for each design iteration because it provides valuable insights on communication latencies that can greatly affect the overall performance of the system. In this article, we identify a time-predictable network-on-chip architecture and show that its timing behaviour can be predicted using models which are far less complex than the architecture itself. We then explore such a feature to produce simplified and lightweight simulation models that can produce latency figures with more than 90% accuracy and simulate more than 1,000 times faster when compared to a cycle-accurate model of the same interconnect.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2022110509",
    "type": "article"
  },
  {
    "title": "Automated Iterative Pipelining for ASIC Design",
    "doi": "https://doi.org/10.1145/2660768",
    "publication_date": "2015-03-02",
    "publication_year": 2015,
    "authors": "Lok-Won Kim; Dong-U Lee; John Villasenor",
    "corresponding_authors": "",
    "abstract": "We describe an automated pipelining approach for optimally balanced pipeline implementation that achieves low area cost as well as meeting timing requirements. Most previous automatic pipelining methods have focused on Instruction Set Architecture (ISA)-based designs and the main goal of such methods generally has been maximizing performance as measured in terms of instructions per clock (IPC). By contrast, we focus on datapath-oriented designs (e.g., DSP filters for image or communication processing applications) in ASIC design flows. The goal of the proposed pipelining approach is to find the optimally pipelined design that not only meets the user-specified target clock frequency, but also seeks to minimize area cost of a given design. Unlike most previous approaches, the proposed methods incorporate the use of accurate area and timing information (iteratively achieved by synthesizing every interim pipelined design) to achieve higher accuracy during design exploration. When compared with exhaustive design exploration that considers all possible pipeline patterns, the two heuristic pipelining methods presented here involve only a small area penalty (typically under 5%) while offering dramatically reduced computational complexity. Experimental validation is performed with commercial ASIC design tools and described for applications including polynomial function evaluation, FIR filters, matrix multiplication, and discrete wavelet transform filter designs with a 90nm standard cell library.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2054833962",
    "type": "article"
  },
  {
    "title": "Optimized 3D Network-on-Chip Design Using Simulated Allocation",
    "doi": "https://doi.org/10.1145/2159542.2159544",
    "publication_date": "2012-04-01",
    "publication_year": 2012,
    "authors": "Pingqiang Zhou; Ping-Hung Yuh; Sachin S. Sapatnekar",
    "corresponding_authors": "",
    "abstract": "Three-dimensional (3D) silicon integration technologies have provided new opportunities for Network-on-Chip (NoC) architecture design in Systems-on-Chip (SoCs). In this article, we consider the application-specific NoC architecture design problem in a 3D environment. We present an efficient floorplan-aware 3D NoC synthesis algorithm based on simulated allocation (SAL), a stochastic method for traffic flow routing, and accurate power and delay models for NoC components. We demonstrate that this method finds greatly improved solutions compared to a baseline algorithm reflecting prior work. To evaluate the SAL method, we compare its performance with the widely used simulated annealing (SA) method and show that SAL is much faster than SA for this application, while providing solutions of very similar quality. We then extend the approach from a single-path routing to a multipath routing scheme and explore the trade-off between power consumption and runtime for these two schemes. Finally, we study the impact of various factors on the network performance in 3D NoCs, including the TSV count and the number of 3D tiers. Our studies show that link power and delay can be significantly improved when moving from a 2D to a 3D implementation, but the improvement flattens out as the number of 3D tiers goes beyond a certain point.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2063347658",
    "type": "article"
  },
  {
    "title": "A Fault-Aware Toolchain Approach for FPGA Fault Tolerance",
    "doi": "https://doi.org/10.1145/2699838",
    "publication_date": "2015-03-02",
    "publication_year": 2015,
    "authors": "Adwait Gupte; Sudhanshu Vyas; Phillip H. Jones",
    "corresponding_authors": "",
    "abstract": "As the size and density of silicon chips continue to increase, maintaining acceptable manufacturing yields has become increasingly difficult. Recent works suggest that lithography techniques are reaching their limits with respect to enabling high yield fabrication of small-scale devices, thus there is an increasing need for techniques that can tolerate fabrication time defects. One candidate technology to help combat these defects is reconfigurable hardware. The flexible nature of reconfigurable devices, such as Field Programmable Gate Arrays (FPGAs), makes it possible for them to route around defective areas of a chip after the device has been packaged and deployed into the field. This work presents a technique that aims to increase the effective yield of FPGA manufacturing by re-claiming a portion of chips that would be ordinarily classified as unusable. In brief, we propose a modification to existing commercial toolchain flows to make them fault aware. A phase is added to identify faults within the chip. The locations of these faults are then used by the toolchain to avoid faults during the placement and routing phase. Specifically, we have applied our approach to the Xilinx commercial toolchain flow and evaluated its tolerance to both logic and routing resource faults. Our findings show that, at a cost of 5--10% in device frequency performance, the modified toolchain flow can tolerate up to 30% of logic resources being faulty and, depending on the nature of the target application, can tolerate 1--30% of the device's routing resources being faulty. These results provide strong evidence that commercial toolchains not designed for the purpose of tolerating faults can still be greatly leveraged in the presence of faults to place and route circuits in an efficient manner.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2084986771",
    "type": "article"
  },
  {
    "title": "Compact Modeling of Interconnect Circuits over Wide Frequency Band by Adaptive Complex-Valued Sampling Method",
    "doi": "https://doi.org/10.1145/2071356.2071361",
    "publication_date": "2012-01-01",
    "publication_year": 2012,
    "authors": "Hai Wang; Sheldon X.-D. Tan; Ryan Rakib",
    "corresponding_authors": "",
    "abstract": "In this article, we propose a new model order-reduction method for compact modeling of interconnect circuits over wide frequency band using a novel complex-valued adaptive sampling and error estimation scheme. We address the outstanding error control problems in the existing sampling-based reduction framework over a frequency band. Our new method, WBMOR , explicitly and efficiently computes the exact residual errors to guide the sampling process. We show by sampling along the imaginary axis and performing a new complex-valued reduction that the reduced model will match exactly with the original model at the sample points. Additionally, we show in theory that the proposed method can achieve the error bound over a given frequency range. In practice, the new algorithm can help designers choose the best order of the reduced model for the given frequency range and error bound via the adaptive sampling scheme. In addition, WBMOR can perform wideband accurate reductions of interconnect circuits for analog and RF applications where model accuracy needs to be maintained over a wide frequency range. We compare several sampling schemes such as Monte Carlo, logarithmic, recently proposed resampling, and ARMS methods. Experimental results on a number of RLC circuits show that WBMOR is much more efficient than all the other sampling methods, including the recently proposed resampling and ARMS schemes with the same reduction orders. Compared with the traditional real-valued sampling methods, the complex-valued sampling method is more accurate for the same computational cost.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2086508118",
    "type": "article"
  },
  {
    "title": "Garbage Collection for Multiversion Index in Flash-Based Embedded Databases",
    "doi": "https://doi.org/10.1145/2611757",
    "publication_date": "2014-06-01",
    "publication_year": 2014,
    "authors": "Po‐Chun Huang; Yuan-Hao Chang; Kam-Yiu Lam; Jiantao Wang; Chien-Chin Huang",
    "corresponding_authors": "",
    "abstract": "Recently, flash-based embedded databases have gained their momentum in various control and monitoring systems, such as cyber-physical systems (CPSes). To support the functionality to access the historical data, a multiversion index is adopted to simultaneously maintain multiple versions of data items, as well as their index information. However, maintaining a multiversion index on flash memory incurs considerable performance overheads on garbage collection, which is to reclaim the spaces occupied by the outdated/invalid data items and their index information on flash memory. In this work, we propose an efficient garbage collection strategy to solve the garbage collection issues of flash-based multiversion databases. In particular, a version-tracking method is proposed to accelerate the performance on the process on identifying/reclaiming the space of invalid data and their indexes, and a pre-summary method is also designed to solve the cascading update problem that is caused by the write-once nature of flash memory and is worsened when more versions refer to the same data item. The capability of the proposed strategy is then verified by analytical and experimental studies.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2156774110",
    "type": "article"
  },
  {
    "title": "Verification and coverage of message passing multicore applications",
    "doi": "https://doi.org/10.1145/2209291.2209296",
    "publication_date": "2012-06-01",
    "publication_year": 2012,
    "authors": "Etem Deniz; Alper Şen; Jim Holt",
    "corresponding_authors": "",
    "abstract": "We describe verification and coverage methods for multicore software that uses message passing libraries for communication. Specifically, we provide techniques to improve reliability of software using the new industry standard MCAPI by the Multicore Association. We develop dynamic predictive verification techniques that allow us to find actual and potential errors in a multicore software. Some of these error types are deadlocks, race conditions, and violation of temporal assertions. We complement our verification techniques with a mutation-testing-based coverage metric. Coverage metrics enable measuring the quality of verification tests. We implemented our techniques in tools and validated them on several multicore programs that use the MCAPI standard. We implement our techniques in tools and experimentally show the effectiveness of our approach. We find errors that are not found using traditional dynamic verification techniques and we can potentially explore execution schedules different than the original program with our coverage tool. This is the first time such predictive verification and coverage metrics have been developed for MCAPI.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2161458224",
    "type": "article"
  },
  {
    "title": "Low-Power Clock Tree Synthesis for 3D-ICs",
    "doi": "https://doi.org/10.1145/3019610",
    "publication_date": "2017-04-03",
    "publication_year": 2017,
    "authors": "Tiantao Lu; Ankur Srivastava",
    "corresponding_authors": "",
    "abstract": "We propose efficient algorithms to construct a low-power clock tree for through-silicon-via (TSV)-based 3D-ICs. We use shutdown gates to save clock trees’ dynamic power, which selectively turn off certain clock tree branches to avoid unnecessary clock activities when the modules in these tree branches are inactive. While this clock gating technique has been extensively studied in 2D circuits, its application in 3D-ICs is unclear. In 3D-ICs, a shutdown gate is connected to a control signal unit through control TSVs, which may cause placement conflicts with existing clock TSVs in the layout due to TSV’s large physical dimension. We develop a two-phase clock tree synthesis design flow for 3D-ICs: (1) 3D abstract clock tree generation based on K-means clustering and (2) clock tree embedding with simultaneous shutdown gates’ insertion based on simulated annealing (SA) and a force-directed TSV placer. Experimental results indicate that (1) the K-means clustering heuristic significantly reduces the clock power by clustering modules with similar switching behavior and close proximity, and (2) the SA algorithm effectively inserts the shutdown gates to a 3D clock tree, while considering control TSV’s placement. Compared with previous 3D clock tree synthesis techniques, our K-means clustering-based approach achieves larger reduction in clock tree power consumption while ensuring zero clock skew.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2605091737",
    "type": "article"
  },
  {
    "title": "Content-Aware Bit Shuffling for Maximizing PCM Endurance",
    "doi": "https://doi.org/10.1145/3017445",
    "publication_date": "2017-05-23",
    "publication_year": 2017,
    "authors": "Miseon Han; Youngsun Han; Seon Wook Kim; Hokyoon Lee; Il Memming Park",
    "corresponding_authors": "",
    "abstract": "Recently, phase change memory (PCM) has been emerging as a strong replacement for DRAM owing to its many advantages such as nonvolatility, high capacity, low leakage power, and so on. However, PCM is still restricted for use as main memory because of its limited write endurance. There have been many methods introduced to resolve the problem by either reducing or spreading out bit flips. Although many previous studies have significantly contributed to reducing bit flips, they still have the drawback that lower bits are flipped more often than higher bits because the lower bits frequently change their bit values. Also, interblock wear-leveling schemes are commonly employed for spreading out bit flips by shifting input data, but they increase the number of bit flips per write. In this article, we propose a noble content-aware bit shuffling (CABS) technique that minimizes bit flips and evenly distributes them to maximize the lifetime of PCM at the bit level. We also introduce two additional optimizations, namely, addition of an inversion bit and use of an XOR key, to further reduce bit flips. Moreover, CABS is capable of recovering from stuck-at faults by restricting the change in values of stuck-at cells. Experimental results showed that CABS outperformed the existing state-of-the-art methods in the aspect of PCM lifetime extension with minimal overhead. CABS achieved up to 48.5% enhanced lifetime compared to the data comparison write (DCW) method only with a few metadata bits. Moreover, CABS obtained approximately 9.7% of improved write throughput than DCW because it significantly reduced bit flips and evenly distributed them. Also, CABS reduced about 5.4% of write dynamic energy compared to DCW. Finally, we have also confirmed that CABS is fully applicable to BCH codes as it was able to reduce the maximum number of bit flips in metadata cells by 32.1%.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2617116991",
    "type": "article"
  },
  {
    "title": "An Effective Layout Decomposition Method for DSA with Multiple Patterning in Contact-Hole Generation",
    "doi": "https://doi.org/10.1145/3131847",
    "publication_date": "2017-09-21",
    "publication_year": 2017,
    "authors": "Yunfeng Yang; Wai-Shing Luk; Hai Zhou; David Z. Pan; Dian Zhou; Changhao Yan; Xuan Zeng",
    "corresponding_authors": "",
    "abstract": "Directed self-assembly (DSA) complemented with multiple patterning (MP) is an attractive next generation lithography (NGL) technique for contact-hole generation. Nevertheless, a high-quality DSA-aware layout decomposer is required to enable the technology. In this article, we introduce an efficient method which incorporates a set packing for generating DSA template candidates and a local search method. Besides, a multi-start strategy is integrated into the framework to prevent the local minima. Our framework encourages the reuse of existing coloring solvers. Hence, the development cost can significantly be reduced. In addition, for DSA multiple patterning where the number of masks is larger than two, we present an efficient iterative partition based method. Experimental results show that compared with the state-of-the-art work, our methods can achieve roughly 100× speedup for double patterning, and 78.8% conflict reduction with 5× speedup for triple patterning on the dense graphs.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2757526385",
    "type": "article"
  },
  {
    "title": "Static Mapping of Applications on Heterogeneous Multi-Core Platforms Combining Logic-Based Benders Decomposition with Integer Linear Programming",
    "doi": "https://doi.org/10.1145/3133219",
    "publication_date": "2017-12-21",
    "publication_year": 2017,
    "authors": "A. Emeretlis; George Theodoridis; Panayiotis Alefragis; Nikolaos Voros",
    "corresponding_authors": "",
    "abstract": "The proper mapping of an application on a multi-core platform and the scheduling of its tasks are key elements to achieve the maximum performance. In this article, a novel hybrid approach based on integrating the Logic-Based Benders Decomposition (LBBD) principle with a pure Integer Linear Programming (ILP) model is introduced for mapping applications described by Directed Acyclic Graphs (DAGs) on platforms consisting of heterogeneous cores. The LBBD approach combines two optimization techniques with complementary strengths, namely ILP and Constraint Programming (CP), and is employed as a cut generation scheme. The generated constraints are utilized by the ILP model to cut possible assignment combinations aiming at improving the solution or proving the optimality of the best-found one. The introduced approach was applied both on synthetic DAGs and on DAGs derived from real applications. Through the proposed approach, many problems were optimally solved that could not be solved by any of the above methods (ILP, LBBD) alone within a time limit of 2 hours, while the overall solution time was also significantly decreased. Specifically, the hybrid method exhibited speedups equal to 4.2× for the synthetic instances and 10× for the real-application DAGs over the LBBD approach and two orders of magnitude over the ILP model.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2778850657",
    "type": "article"
  },
  {
    "title": "Exploring the Role of Large Centralised Caches in Thermal Efficient Chip Design",
    "doi": "https://doi.org/10.1145/3339850",
    "publication_date": "2019-06-28",
    "publication_year": 2019,
    "authors": "Shounak Chakraborty; Hemangee K. Kapoor",
    "corresponding_authors": "",
    "abstract": "In the era of short channel length, Dynamic Thermal Management (DTM) has become a challenging task for the architects and designers engineering modern Chip Multi-Processors (CMPs). Ever-increasing demand of processing power along with the developed integration technology produces CMPs with high power density, which in turn increases effective chip temperature. This increased temperature leads to increase in the reliability issues for the chip-circuitry with significant increment in leakage power consumption. Recent DTM techniques apply DVFS or Task Migration to reduce temperature at the cores, the hottest on-chip components, but often ignore the on-chip hot caches. To commensurate the high data demand of these cores, most of the modern CMPs are equipped with large multi-level on-chip caches, out of which on-chip Last Level Caches (LLCs) occupy the largest on-chip area. These LLCs are accounted for their significantly high leakage power consumption that can also potentially generate on-chip hotspots at the LLCs similar to the cores. As power consumption constructs the backbone of heat dissipation, hence, this work dynamically shrinks cache size while maintaining performance constraint to reduce LLC leakage, primarily. These turned-off cache portions further work as on-chip thermal buffers for reducing average and peak temperature of the CMP without affecting the computation. Simulation results claim that, at a minimal penalty on the performance, proposed cache-based thermal management having 8MB centralised multi-banked shared LLC gives around 5°C reduction in peak and average chip temperature, which are comparable with a Greedy DVFS policy.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2954056768",
    "type": "article"
  },
  {
    "title": "Modeling and Simulation of Dynamic Applications Using Scenario-Aware Dataflow",
    "doi": "https://doi.org/10.1145/3342997",
    "publication_date": "2019-08-21",
    "publication_year": 2019,
    "authors": "Ricardo Bonna; Denis S. Loubach; George Ungureanu; Ingo Sander",
    "corresponding_authors": "",
    "abstract": "The tradeoff between analyzability and expressiveness is a key factor when choosing a suitable dataflow model of computation (MoC) for designing, modeling, and simulating applications considering a formal base. A large number of techniques and analysis tools exist for static dataflow models, such as synchronous dataflow. However, they cannot express the dynamic behavior required for more dynamic applications in signal streaming or to model runtime reconfigurable systems. On the other hand, dynamic dataflow models like Kahn process networks sacrifice analyzability for expressiveness. Scenario-aware dataflow (SADF) is an excellent tradeoff providing sufficient expressiveness for dynamic systems, while still giving access to powerful analysis methods. In spite of an increasing interest in SADF methods, there is a lack of formally-defined functional models for describing and simulating SADF systems. This article overcomes the current situation by introducing a functional model for the SADF MoC, as well as a set of abstract operations for simulating it. We present the first modeling and simulation tool for SADF so far, implemented as an open source library in the functional framework ForSyDe. We demonstrate the capabilities of the functional model through a comprehensive tutorial-style example of a RISC processor described as an SADF application, and a traditional streaming application where we model an MPEG-4 simple profile decoder. We also present a couple of alternative approaches for functionally modeling SADF on different languages and paradigms. One of such approaches is used in a performance comparison with our functional model using the MPEG-4 simple profile decoder as a test case. As a result, our proposed model presented a good tradeoff between execution time and implementation succinctness. Finally, we discuss the potential of our formal model as a frontend for formal system design flows regarding dynamic applications.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2969746574",
    "type": "article"
  },
  {
    "title": "JAMS-SG",
    "doi": "https://doi.org/10.1145/3355392",
    "publication_date": "2019-09-17",
    "publication_year": 2019,
    "authors": "Vipin Kumar Kukkala; Sudeep Pasricha; Thomas H. Bradley",
    "corresponding_authors": "",
    "abstract": "Time-triggered automotive networks use time-triggered protocols (FlexRay, TTEthernet, etc.) for periodic message transmissions that often originate from safety and time-critical applications. One of the major challenges with time-triggered transmissions is jitter, which is the unpredictable delay-induced deviation from the actual periodicity of a message. Failure to account for jitter can be catastrophic in time-sensitive systems, such as automotive platforms. In this article, we propose a novel scheduling framework (JAMS-SG) that satisfies timing constraints during message delivery for both jitter-affected time-triggered messages and high-priority event-triggered messages in automotive networks. At design time, JAMS-SG performs jitter-aware frame packing (packing of multiple signals from Electronic Control Units (ECUs) into messages) and schedules synthesis with a hybrid heuristic. At runtime, a Multi-Level Feedback Queue (MLFQ) handles jitter-affected time-triggered messages and high-priority event-triggered messages that are scheduled using a runtime scheduler. Our simulation results, based on messages and network traffic data from a real vehicle, indicate that JAMS-SG is highly scalable and outperforms the best-known prior work in the area in the presence of jitter.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2974882189",
    "type": "article"
  },
  {
    "title": "Energy-aware Scheduling of Task Graphs with Imprecise Computations and End-to-end Deadlines",
    "doi": "https://doi.org/10.1145/3365999",
    "publication_date": "2019-11-26",
    "publication_year": 2019,
    "authors": "Amirhossein Esmaili; Mahdi Nazemi; Massoud Pedram",
    "corresponding_authors": "",
    "abstract": "Imprecise computations allow scheduling algorithms developed for energy-constrained computing devices to trade off output quality with utilization of system resources. The goal of such scheduling algorithms is to utilize imprecise computations to find a feasible schedule for a given task graph while maximizing the quality of service (QoS) and satisfying a hard deadline and an energy bound. This work presents a heuristic for scheduling tasks with potentially imprecise computations, represented with directed acyclic graphs, on multiprocessor platforms. Furthermore, it presents a mixed integer linear program formulation of the same problem, which provides the optimal reference scheduling solutions, enabling evaluation of the efficacy of the proposed heuristic. Both the heuristic and mathematical program take account of potentially imprecise inputs of tasks on their output quality. Furthermore, the presented heuristic is capable of finding feasible schedules even under tight energy budgets. Through extensive experiments, it is shown that in some cases, the proposed heuristic is capable of finding the same QoS as the ones found by MILP. Furthermore, for those task graphs that MILP outperforms the proposed heuristic, QoS values obtained with the proposed heuristic are, on average, within 1.24% of the optimal solutions while improving the runtime by a factor of 100 or so. This clearly demonstrates the advantage of the proposed heuristic over the exact solution, especially for large task graphs where solving the mathematical problem is hampered by its lengthy runtime.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2990377386",
    "type": "article"
  },
  {
    "title": "NeuPow",
    "doi": "https://doi.org/10.1145/3388141",
    "publication_date": "2020-07-07",
    "publication_year": 2020,
    "authors": "Yehya Nasser; Carlo Sau; Jean-Christophe Prévotet; Tiziana Fanni; Francesca Palumbo; Maryline Hélard; Luigi Raffo",
    "corresponding_authors": "",
    "abstract": "In this article, we present a new, simple, accurate, and fast power estimation technique that can be used to explore the power consumption of digital system designs at an early design stage. We exploit the machine learning techniques to aid the designers in exploring the design space of possible architectural solutions, and more specifically, their dynamic power consumption, which is application-, technology-, frequency-, and data-stimuli dependent. To model the power and the behavior of digital components, we adopt the Artificial Neural Networks (ANNs), while the final target technology is Application Specific Integrated Circuit (ASIC). The main characteristic of the proposed method, called NeuPow, is that it relies on propagating the signals throughout connected ANN models to predict the power consumption of a composite system. Besides a baseline version of the NeuPow methodology that works for a given predefined operating frequency, we also derive an upgraded version that is frequency-aware, where the same operating frequency is taken as additional input by the ANN models. To prove the effectiveness of the proposed methodology, we perform different assessments at different levels. Moreover, technology and scalability studies have been conducted, proving the NeuPow robustness in terms of these design parameters. Results show a very good estimation accuracy with less than 9% of relative error independently from the technology and the size/layers of the design. NeuPow is also delivering a speed-up factor of about 84× with respect to the classical power estimation flow.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W3040943618",
    "type": "article"
  },
  {
    "title": "Security Threat Analyses and Attack Models for Approximate Computing Systems",
    "doi": "https://doi.org/10.1145/3442380",
    "publication_date": "2021-04-22",
    "publication_year": 2021,
    "authors": "Pruthvy Yellu; Landon Buell; Miguel Mark; Michel A. Kinsy; Dongpeng Xu; Qiaoyan Yu",
    "corresponding_authors": "",
    "abstract": "Approximate computing (AC) represents a paradigm shift from conventional precise processing to inexact computation but still satisfying the system requirement on accuracy. The rapid progress on the development of diverse AC techniques allows us to apply approximate computing to many computation-intensive applications. However, the utilization of AC techniques could bring in new unique security threats to computing systems. This work does a survey on existing circuit-, architecture-, and compiler-level approximate mechanisms/algorithms, with special emphasis on potential security vulnerabilities. Qualitative and quantitative analyses are performed to assess the impact of the new security threats on AC systems. Moreover, this work proposes four unique visionary attack models, which systematically cover the attacks that build covert channels, compensate approximation errors, terminate normal error resilience mechanisms, and propagate additional errors. To thwart those attacks, this work further offers the guideline of countermeasure designs. Several case studies are provided to illustrate the implementation of the suggested countermeasures.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W3160799743",
    "type": "article"
  },
  {
    "title": "A Module-Linking Graph Assisted Hybrid Optimization Framework for Custom Analog and Mixed-Signal Circuit Parameter Synthesis",
    "doi": "https://doi.org/10.1145/3456722",
    "publication_date": "2021-06-05",
    "publication_year": 2021,
    "authors": "Mohsen Hassanpourghadi; Rezwan A Rasul; Mike Shuo‐Wei Chen",
    "corresponding_authors": "",
    "abstract": "Analog and mixed-signal (AMS) computer-aided design tools are of increasing interest owing to demand for the wide range of AMS circuit specifications in the modern system on a chip and faster time to market requirement. Traditionally, to accelerate the design process, the AMS system is decomposed into smaller components (called modules ) such that the complexity and evaluation of each module are more manageable. However, this decomposition poses an interface problem, where the module’s input-output states deviate from when combined to construct the AMS system, and thus degrades the system expected performance. In this article, we develop a tool module-linking-graph assisted hybrid parameter search engine with neural networks (MOHSENN) to overcome these obstacles. We propose a module-linking-graph that enforces equality of the modules’ interfaces during the parameter search process and apply surrogate modeling of the AMS circuit via neural networks. Further, we propose a hybrid search consisting of a global optimization with fast neural network models and a local optimization with accurate SPICE models to expedite the parameter search process while maintaining the accuracy. To validate the effectiveness of the proposed approach, we apply MOHSENN to design a successive approximation register analog-to-digital converter in 65-nm CMOS technology. This demonstrated that the search time improves by a factor of 5 and 700 compared to conventional hierarchical and flat design approaches, respectively, with improved performance.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W3171010298",
    "type": "article"
  },
  {
    "title": "A Native SPICE Implementation of Memristor Models for Simulation of Neuromorphic Analog Signal Processing Circuits",
    "doi": "https://doi.org/10.1145/3474364",
    "publication_date": "2021-09-13",
    "publication_year": 2021,
    "authors": "Bo Li; Guoyong Shi",
    "corresponding_authors": "",
    "abstract": "Since the memristor emerged as a programmable analog storage device, it has stimulated research on the design of analog/mixed-signal circuits with the memristor as the enabler of in-memory computation. Due to the difficulty in evaluating the circuit-level nonidealities of both memristors and CMOS devices, SPICE-accuracy simulation tools are necessary for perfecting the art of neuromorphic analog/mixed-signal circuit design. This article is dedicated to a native SPICE implementation of the memristor device models published in the open literature and develops case studies of applying such a circuit simulation with MOSFET models to study how device-level imperfections can make adversarial effects on the analog circuits that implement neuromorphic analog signal processing. Methods on memristor stamping in the framework of modified nodal analysis formulation are presented, and implementation results are reported. Furthermore, functional simulations on neuromorphic signal processing circuits including memristors and CMOS devices are carried out to validate the effectiveness of the native SPICE implementation of memristor models from the perspectives of simulation accuracy, efficiency, and convergence for large-scale simulation tasks.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W3200591480",
    "type": "article"
  },
  {
    "title": "System-Level Observation Framework for Non-Intrusive Runtime Monitoring of Embedded Systems",
    "doi": "https://doi.org/10.1145/2717310",
    "publication_date": "2015-06-24",
    "publication_year": 2015,
    "authors": "Jong Chul Lee; Roman Lysecky",
    "corresponding_authors": "",
    "abstract": "As the complexity of embedded systems rapidly increases, the use of traditional analysis and debug methods encounters significant challenges in monitoring, analyzing, and debugging the complex interactions of various software and hardware components. This situation is further exacerbated for in-situ debugging and verification in which traditional debug and trace interfaces that require physical access are unavailable, infeasible, or cost prohibitive. In this article, we present a system-level observation framework that provides minimally intrusive methods for dynamically monitoring and analyzing deeply integrated hardware and software components within embedded systems. The system-level observation framework monitors hardware and software events by inserting additional logic for detecting designer-specified events within hardware cores to observe complex interaction across hardware and software boundaries at runtime, and provides visibility for monitoring complex execution behavior of software applications without affecting the system execution.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W175278625",
    "type": "article"
  },
  {
    "title": "Incremental Analysis of Power Grids Using Backward Random Walks",
    "doi": "https://doi.org/10.1145/2611763",
    "publication_date": "2014-06-01",
    "publication_year": 2014,
    "authors": "Baktash Boghrati; Sachin S. Sapatnekar",
    "corresponding_authors": "",
    "abstract": "Power grid design and analysis is a critical part of modern VLSI chip design and demands tools for accurate modeling and efficient analysis. The process of power grid design is inherently iterative, during which numerous small changes are made to an initial design, either to enhance the design or to fix design constraint violations. Due to the large sizes of power grids in modern chips, updating the solution for these perturbations can be a computationally intensive task. In this work, we first introduce an accurate modeling methodology for power grids that, contrary to conventional models, can result in asymmetrical equations. Next, we propose an efficient and accurate incremental solver that utilizes the backward random walks to identify the region of influence of the perturbation. The solution of the network is then updated for this significantly smaller region only. The proposed algorithm is capable of handling both symmetrical and asymmetrical power grid equations. Moreover, it can handle consecutive perturbations without any degradation in the quality of the solution. Experimental results show speedups of up to 13× for our incremental solver, as compared to a full resolve of the power grid.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W1965820479",
    "type": "article"
  },
  {
    "title": "Techniques for scalable and effective routability evaluation",
    "doi": "https://doi.org/10.1145/2566663",
    "publication_date": "2014-03-01",
    "publication_year": 2014,
    "authors": "Yaoguang Wei; Cliff Sze; V. Natarajan; Zhuo Li; Charles J. Alpert; Lakshmi Reddy; Andrew D. Huber; Gustavo Tèllez; Douglas Keller; Sachin S. Sapatnekar",
    "corresponding_authors": "",
    "abstract": "Routing congestion has become a critical layout challenge in nanoscale circuits since it is a critical factor in determining the routability of a design. An unroutable design is not useful even though it closes on all other design metrics. Fast design closure can only be achieved by accurately evaluating whether a design is routable or not early in the design cycle. Lately, it has become common to use a “light mode” version of a global router to quickly evaluate the routability of a given placement. This approach suffers from three weaknesses: (i) it does not adequately model local routing resources, which can cause incorrect routability predictions that are only detected late, during detailed routing; (ii) the congestion maps obtained by it tend to have isolated hotspots surrounded by noncongested spots, called “noisy hotspots”, which further affects the accuracy in routability evaluation; and (iii) the metrics used to represent congestion may yield numbers that do not provide sufficient intuition to the designer, and moreover, they may often fail to predict the routability accurately. This article presents solutions to these issues. First, we propose three approaches to model local routing resources. Second, we propose a smoothing technique to reduce the number of noisy hotspots and obtain a more accurate routability evaluation result. Finally, we develop a new metric which represents congestion maps with higher fidelity. We apply the proposed techniques to several industrial circuits and demonstrate that one can better predict and evaluate design routability and that congestion mitigation tools can perform much better to improve the design routability.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W1998461455",
    "type": "article"
  },
  {
    "title": "Performance-driven dynamic thermal management of MPSoC based on task rescheduling",
    "doi": "https://doi.org/10.1145/2566661",
    "publication_date": "2014-03-01",
    "publication_year": 2014,
    "authors": "Kunal Ganeshpure; Sandip Kundu",
    "corresponding_authors": "",
    "abstract": "High level of integration has led to the advent of Multiprocessor System-on-Chip (MPSoC) which consists of multiple processor cores and accelerators on the same die. A MPSoC programming model is based on a task graph where tasks are assigned to cores to maximize performance. To address thermal hotspots in MPSoCs, coarse-grain power management techniques based on Dynamic Frequency Scaling (DFS) are widely used. DFS is reactive in nature and has detrimental effects on performance. We propose an alternative solution based on dynamic task rescheduling where a temperature prediction scheme is built into the scheduler. The temperature look-ahead scheme is used for task reassignment or delay insertion in scheduling. Since temperature prediction and task assignment are done at runtime, both must be simple and extremely fast. To that end, we propose a heuristic solution based on a limited branch-and-bound search and compare results against an optimal Integer Linear Programming (ILP)-based solution. The proposed approach is shown to be superior to frequency scaling, and the resulting schedule length is within 5% to 10% of the optimal solution as obtained from ILP formulation.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2007452960",
    "type": "article"
  },
  {
    "title": "Robust Design Space Modeling",
    "doi": "https://doi.org/10.1145/2668118",
    "publication_date": "2015-03-02",
    "publication_year": 2015,
    "authors": "Qi Guo; Tianshi Chen; Zhi‐Hua Zhou; Olivier Temam; Ling Li; Depei Qian; Yunji Chen",
    "corresponding_authors": "",
    "abstract": "Architectural design spaces of microprocessors are often exponentially large with respect to the pending processor parameters. To avoid simulating all configurations in the design space, machine learning and statistical techniques have been utilized to build regression models for characterizing the relationship between architectural configurations and responses (e.g., performance or power consumption). However, this article shows that the accuracy variability of many learning techniques over different design spaces and benchmarks can be significant enough to mislead the decision-making. This clearly indicates a high risk of applying techniques that work well on previous modeling tasks (each involving a design space, benchmark, and design objective) to a new task, due to which the powerful tools might be impractical. Inspired by ensemble learning in the machine learning domain, we propose a robust framework called ELSE to reduce the accuracy variability of design space modeling. Rather than employing a single learning technique as in previous investigations, ELSE employs distinct learning techniques to build multiple base regression models for each modeling task. This is not a trivial combination of different techniques (e.g., always trusting the regression model with the smallest error). Instead, ELSE carefully maintains the diversity of base regression models and constructs a metamodel from the base models that can provide accurate predictions even when the base models are far from accurate. Consequently, we are able to reduce the number of cases in which the final prediction errors are unacceptably large. Experimental results validate the robustness of ELSE: compared with the widely used artificial neural network over 52 distinct modeling tasks, ELSE reduces the accuracy variability by about 62%. Moreover, ELSE reduces the average prediction error by 27% and 85% for the investigated MIPS and POWER design spaces, respectively.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2008784780",
    "type": "article"
  },
  {
    "title": "High-Level Test Synthesis",
    "doi": "https://doi.org/10.1145/2627754",
    "publication_date": "2014-08-01",
    "publication_year": 2014,
    "authors": "S. Ravi; M. Joseph",
    "corresponding_authors": "",
    "abstract": "High-level test synthesis is a special class of high-level synthesis having testability as one of the important components. This article presents a detailed survey on recent developments in high-level test synthesis from a synthesis process flow perspective. It also presents a survey on controller synthesis techniques for testability.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2038229614",
    "type": "article"
  },
  {
    "title": "Designing Hybrid DRAM/PCM Main Memory Systems Utilizing Dual-Phase Compression",
    "doi": "https://doi.org/10.1145/2658989",
    "publication_date": "2014-11-18",
    "publication_year": 2014,
    "authors": "Seung-Cheol Baek; Hyung Gyu Lee; Chrysostomos Nicopoulos; Jong‐Man Kim",
    "corresponding_authors": "",
    "abstract": "The last few years have witnessed the emergence of a promising new memory technology, namely Phase-Change Memory (PCM). Due to its inherent ability to scale deeply into the nanoscale regime and its low power consumption, PCM is increasingly viewed as an attractive alternative for the memory subsystem of future microprocessor architectures. However, PCM is marred by a duo of potentially show-stopping deficiencies, that is, poor write performance (especially when compared to the prevalent and ubiquitous DRAM technology) and limited durability. These weaknesses have urged designers to develop various supporting architectural techniques to aid and complement the operation of the PCM while mitigating its innate flaws. One promising such solution is the deployment of hybridized memory architectures that fuse DRAM and PCM, in order to combine the best attributes of each technology. In this article, we introduce a novel Dual-Phase Compression (DPC) scheme and its architectural design aimed at DRAM/PCM hybrids, which caters to the limitations of PCM technology while optimizing memory performance. The DPC technique is specifically optimized for PCM-based environments and is transparent to the operation of the remaining components of the memory subsystem. Furthermore, the proposed architecture is imbued with a multifaceted wear-leveling technique to enhance the durability and prolong the lifetime of the PCM. Extensive simulations with traces from real applications running on a full-system simulator demonstrate 20.4% performance improvement and 46.9% energy reduction, on average, as compared to a baseline DRAM/PCM hybrid implementation. Additionally, the multifaceted wear-leveling technique is shown to significantly prolong the lifetime of the PCM.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2105112345",
    "type": "article"
  },
  {
    "title": "Partitioning and Data Mapping in Reconfigurable Cache and Scratchpad Memory--Based Architectures",
    "doi": "https://doi.org/10.1145/2934680",
    "publication_date": "2016-09-02",
    "publication_year": 2016,
    "authors": "Prasenjit Chakraborty; Preeti Ranjan Panda; Sandeep Sen",
    "corresponding_authors": "",
    "abstract": "Scratchpad memory (SPM) is considered a useful component in the memory hierarchy, solely or along with caches, for meeting the power and energy constraints as performance ceases to be the sole criteria for processor design. Although the efficiency of SPM is well known, its use has been restricted owing to difficulties in programmability. Real applications usually have regions that are amenable to exploitation by either SPM or cache and hence can benefit if the two are used in conjunction. Dynamically adjusting the local memory resources to suit application demand can significantly improve the efficiency of the overall system. In this article, we propose a compiler technique to map application data objects to the SPM-cache and also partition the local memory between the SPM and cache depending on the dynamic requirement of the application. First, we introduce a novel graph-based structure to tackle data allocation in an application. Second, we use this to present a data allocation heuristic to map program objects for a fixed-size SPM-cache hybrid system that targets whole program optimization. We finally extend this formulation to adapt the SPM and cache sizes, as well as the data allocation as per the requirement of different application regions. We study the applicability of the technique on various workloads targeted at both SPM-only and hardware reconfigurable memory systems, observing an average of 18% energy-delay improvement over state-of-the-art techniques.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2513306639",
    "type": "article"
  },
  {
    "title": "RGMU: A High-flexibility and Low-cost Reconfigurable Galois Field Multiplication Unit Design Approach for CGRCA",
    "doi": "https://doi.org/10.1145/3639820",
    "publication_date": "2024-01-09",
    "publication_year": 2024,
    "authors": "Danping Jiang; Zibin Dai; Yanjiang Liu; Zongren Zhang",
    "corresponding_authors": "",
    "abstract": "Finite field multiplication is a non-linear transformation operator that appears in the majority of symmetric cryptographic algorithms. Numerous specified finite field multiplication units have been proposed as a fundamental module in the coarse-grained reconfigurable cipher logic array to support more cryptographic algorithms; however, it will introduce low flexibility and high overhead, resulting in reduced performance of the coarse-grained reconfigurable cipher logic array. In this article, a high-flexibility and low-cost reconfigurable Galois field multiplication unit (RGMU) is proposed to balance the tradeoffs between the function, delay, and area. All the finite field multiplication operations, including maximum distance separable matrix multiplication, parallel update of Fibonacci linear feedback shift register, parallel update of Galois linear feedback shift register, and composite field multiplication, are analyzed and two basic operation components are abstracted. Further, a reconfigurable finite field multiplication computational model is established to demonstrate the efficacy of reconfigurable units and guide the design of RGMU with high performance. Finally, the overall architecture of RGMU and two multiplication circuits are introduced. Experimental results show that the RGMU can not only reduce the hardware overhead and power consumption but also has the unique advantage of satisfying all the finite field multiplication operations in symmetric cryptography algorithms.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4390781217",
    "type": "article"
  },
  {
    "title": "EPHA: An Energy-efficient Parallel Hybrid Architecture for ANNs and SNNs",
    "doi": "https://doi.org/10.1145/3643134",
    "publication_date": "2024-01-25",
    "publication_year": 2024,
    "authors": "Yunping Zhao; Sheng Ma; Hengzhu Liu; Libo Huang",
    "corresponding_authors": "",
    "abstract": "Artificial neural networks (ANNs) and spiking neural networks (SNNs) are two general approaches to achieve artificial intelligence (AI). The former have been widely used in academia and industry fields; the latter, SNNs, are more similar to biological neural networks and can realize ultra-low power consumption, thus have received widespread research attention. However, due to their fundamental differences in computation formula and information coding, the two methods often require different and incompatible platforms. Alongside the development of AI, a general platform that can support both ANNs and SNNs is necessary. Moreover, there are some similarities between ANNs and SNNs, which leaves room to deploy different networks on the same architecture. However, there is little related research on this topic. Accordingly, this article presents an energy-efficient, scalable, and non-Von Neumann architecture (EPHA) for ANNs and SNNs. Our study combines device-, circuit-, architecture-, and algorithm-level innovations to achieve a parallel architecture with ultra-low power consumption. We use the compensated ferrimagnet to act as both synapses and neurons to store weights and perform dot-product operations, respectively. Moreover, we propose a novel computing flow to reduce the operations across multiple crossbar arrays, which enables our design to conduct large and complex tasks. On a suite of ANN and SNN workloads, the EPHA is 1.6× more power-efficient than a state-of-the-art design, NEBULA, in the ANN mode. In the SNN mode, our design is 4 orders of magnitude more than the Loihi in power efficiency.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4391222306",
    "type": "article"
  },
  {
    "title": "Root-Cause Analysis with Semi-Supervised Co-Training for Integrated Systems",
    "doi": "https://doi.org/10.1145/3649313",
    "publication_date": "2024-03-01",
    "publication_year": 2024,
    "authors": "Renjian Pan; Xin Li; Krishnendu Chakrabarty",
    "corresponding_authors": "",
    "abstract": "Root-cause analysis for integrated systems has become increasingly challenging due to their growing complexity. To tackle these challenges, machine learning (ML) has been applied to enhance root-cause analysis. Nonetheless, ML-based root-cause analysis usually requires abundant training data with root causes labeled by human experts, which are difficult or even impossible to obtain. To overcome this drawback, a semi-supervised co-training method is proposed for root-cause analysis in this article, which only requires a small portion of labeled data. First, a random forest is trained with labeled data. Next, we propose a co-training technique to learn from unlabeled data with semi-supervised learning, which pre-labels a subset of these data automatically and then retrains each decision tree in the random forest. In addition, a robust framework is proposed to avoid over-fitting. We further apply initialization by clustering and feature selection to improve the diagnostic performance. With two case studies from industry, the proposed approach shows superior performance against other state-of-the-art methods by saving up to 67% of labeling efforts.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4392356285",
    "type": "article"
  },
  {
    "title": "Security Evaluation of State Space Obfuscation of Hardware IP through a Red Team-Blue Team Practice",
    "doi": "https://doi.org/10.1145/3640461",
    "publication_date": "2024-03-05",
    "publication_year": 2024,
    "authors": "Md Moshiur Rahman; James Geist; Daniel Xing; Yuntao Liu; Ankur Srivastava; Travis Meade; Yier Jin; Swarup Bhunia",
    "corresponding_authors": "",
    "abstract": "Due to the inclination towards a fab-less model of integrated circuit (IC) manufacturing, several untrusted entities get white-box access to the proprietary intellectual property (IP) blocks from diverse vendors. To this end, the untrusted entities pose security-breach threats in the form of piracy, cloning, and reverse-engineering, sometimes threatening national security. Hardware obfuscation is a prominent countermeasure against such issues. Obfuscation allows for preventing the usage of the IP blocks without authorization from the IP owners. Due to finite state machine (FSM) transformation-based hardware obfuscation, the design’s FSM gets transformed to make it difficult for an attacker to reverse-engineer the design. A secret key needs to be applied to make the FSM functional, thus preventing the usage of the IP for unintended purposes. Although several hardware obfuscation techniques have been proposed, due to the inability to analyze the techniques from the attackers’ standpoint, numerous vulnerabilities inherent to the obfuscation methods go undetected unless a true adversary discovers them. In this article, we present a collaborative approach between two entities—one acting as an attacker or red team and another as a defender or blue team , the first systematic approach to replicate the real attacker-defender scenario in the hardware security domain, which in return strengthens the FSM transformation-based obfuscation technique. The blue team transforms the underlying FSM of a gate-level netlist using state space obfuscation. The red team plays the role of an adversary or evaluator and tries to unlock the design by extracting the unlocking key or recovering the obfuscation circuitries. As the key outcome of this red team–blue team effort, a robust state space obfuscation methodology is evolved showing security promises.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4392473188",
    "type": "article"
  },
  {
    "title": "POEM: Performance Optimization and Endurance Management for Non-volatile Caches",
    "doi": "https://doi.org/10.1145/3653452",
    "publication_date": "2024-03-27",
    "publication_year": 2024,
    "authors": "Aritra Bagchi; Dharamjeet; Ohm Rishabh; Manan Suri; Preeti Ranjan Panda",
    "corresponding_authors": "",
    "abstract": "Non-volatile memories (NVMs), with their high storage density and ultra-low leakage power, offer promising potential for redesigning the memory hierarchy in next-generation Multi-Processor Systems-on-Chip (MPSoCs). However, the adoption of NVMs in cache designs introduces challenges such as NVM write overheads and limited NVM endurance. The shared NVM cache in an MPSoC experiences requests from different processor cores and responses from the off-chip memory when the requested data is not present in the cache. Besides, upon evictions of dirty data from higher-level caches, the shared NVM cache experiences another source of write operations, known as writebacks . These sources of write operations—writebacks and responses—further exacerbate the contention for the shared bandwidth of the NVM cache and create significant performance bottlenecks. Uncontrolled write operations can also affect the endurance of the NVM cache, posing a threat to cache lifetime and system reliability. Existing strategies often address either performance or cache endurance individually, leaving a gap for a holistic solution. This study introduces the Performance Optimization and Endurance Management (POEM) methodology, a novel approach that aggressively bypasses cache writebacks and responses to alleviate the NVM cache contention. Contrary to the existing bypass policies that do not pay adequate attention to the shared NVM cache contention and focus too much on cache data reuse, POEM’s aggressive bypass significantly improves the overall system performance, even at the expense of data reuse. POEM also employs effective wear leveling to enhance the NVM cache endurance by careful redistribution of write operations across different cache lines. Across diverse workloads, POEM yields an average speedup of 34% over a naïve baseline and 28.8% over a state-of-the-art NVM cache bypass technique while enhancing the cache endurance by 15% over the baseline. POEM also explores diverse design choices by exploiting a key policy parameter that assigns varying priorities to the two system-level objectives.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4393224469",
    "type": "article"
  },
  {
    "title": "ARM-CO-UP: ARM COoperative Utilization of Processors",
    "doi": "https://doi.org/10.1145/3656472",
    "publication_date": "2024-04-08",
    "publication_year": 2024,
    "authors": "Ehsan Aghapour; Dolly Sapra; Andy D. Pimentel; Anuj Pathania",
    "corresponding_authors": "",
    "abstract": "HMPSoCs combine different processors on a single chip. They enable powerful embedded devices, which increasingly perform ML inference tasks at the edge. State-of-the-art HMPSoCs can perform on-chip embedded inference using different processors, such as CPUs, GPUs, and NPUs. HMPSoCs can potentially overcome the limitation of low single-processor CNN inference performance and efficiency by cooperative use of multiple processors. However, standard inference frameworks for edge devices typically utilize only a single processor. We present the ARM-CO-UP framework built on the ARM-CL library. The ARM-CO-UP framework supports two modes of operation – Pipeline and Switch. It optimizes inference throughput using pipelined execution of network partitions for consecutive input frames in the Pipeline mode. It improves inference latency through layer-switched inference for a single input frame in the Switch mode. Furthermore, it supports layer-wise CPU/GPU DVFS in both modes for improving power efficiency and energy consumption. ARM-CO-UP is a comprehensive framework for multi-processor CNN inference that automates CNN partitioning and mapping, pipeline synchronization, processor type switching, layer-wise DVFS , and closed-source NPU integration.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4394569872",
    "type": "article"
  },
  {
    "title": "Capacity-Aware Wash Optimization with Dynamic Fluid Scheduling and Channel Storage for Continuous-Flow Microfluidic Biochips",
    "doi": "https://doi.org/10.1145/3659952",
    "publication_date": "2024-04-17",
    "publication_year": 2024,
    "authors": "Zhisheng Chen; Xu Hu; Wenzhong Guo; Genggeng Liu; Jiaxuan Wang; Tsung-Yi Ho; Xing Huang",
    "corresponding_authors": "",
    "abstract": "Continuous-flow microfluidic biochips are gaining increasing attention with promising applications for automatically executing various laboratory procedures in biology and biochemistry. Biochips with distributed channel-storage architectures enable each channel to switch between the roles of transportation and storage. Consequently, fluid transportation, caching, and fetch can occur concurrently through different flow paths. When two dissimilar types of fluidic flows occur through the same channels in a time-interleaved manner, it may cause contamination to the latter as some residues of the former flow may be stuck at the channel wall during transportation. To remove the residues, wash operations are introduced as an essential step to avoid incorrect assay outcomes. However, existing work has been considered that the washing capacity of a buffer fluid is unlimited. In the actual scenario, a fixed-volume buffer fluid irrefutably possesses a limited washing capacity, which can be successively consumed while washing away residues from the channels. Hence, capacity-aware wash scheme is a basic requirement to fulfil the dynamic fluid scheduling and channel storage. In this paper, we formulate a practical wash optimization problem for microfluidic biochips, which considers the requirements of dynamic fluid scheduling, channel storage, as well as washing capacity constraints of buffer fluids simultaneously, and present an efficient design flow to solve this problem systematically. Given the high-level synthesis result of a biochemical application and the corresponding component placement solution, our goal is to complete a contamination-aware flow-path planning with short flow-channel length. Meanwhile, the biochemical application can be executed efficiently and correctly with an optimized capacity-aware wash scheme. Experimental results show that compared to a state-of-the-art washing method, the proposed method achieves an average reduction of 26.1%, 43.1%, and 34.1% across all the benchmarks with respect to the total channel length, total wash time, and execution time of bioassays, respectively.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4394891154",
    "type": "article"
  },
  {
    "title": "Enhanced Compiler Technology for Software-based Hardware Fault Detection",
    "doi": "https://doi.org/10.1145/3660524",
    "publication_date": "2024-04-22",
    "publication_year": 2024,
    "authors": "Davide Baroffio; Federico Reghenzani; William Fornaciari",
    "corresponding_authors": "",
    "abstract": "Software-Implemented Hardware Fault Tolerance (SIHFT) is a modern approach for tackling random hardware faults of dependable systems employing solely software solutions. This work extends an automatic compiler-based SIHFT hardening tool called ASPIS, enhancing it with novel protection mechanisms and overhead-reduction techniques, also providing an extensive analysis of its compliance with the non-trivial workload of the open-source Real-Time Operating System FreeRTOS. A thorough experimental fault-injection campaign on an STM32 board shows how the system achieves remarkably high tolerance to single-event upsets and a comparison between the SIHFT mechanisms implemented summarises the tradeoff between the overhead introduced and the detection capabilities of the various solutions.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4395001560",
    "type": "article"
  },
  {
    "title": "gem5-NVDLA: A Simulation Framework for Compiling, Scheduling, and Architecture Evaluation on AI System-on-Chips",
    "doi": "https://doi.org/10.1145/3661997",
    "publication_date": "2024-04-29",
    "publication_year": 2024,
    "authors": "Chengtao Lai; Wei Zhang",
    "corresponding_authors": "",
    "abstract": "Recent years have seen an increasing trend in designing AI accelerators together with the rest of the system, including CPUs and memory hierarchy. This trend calls for high-quality simulators or analytical models that enable such kind of co-exploration. Currently, the majority of such exploration is supported by AI accelerator analytical models. But such models usually overlook the non-trivial impact of congestion of shared resources, non-ideal hardware utilization and non-zero CPU scheduler overhead, which could only be modeled by cycle-level simulators. However, most simulators with full-stack toolchains are proprietary to corporations, and the few open-source simulators are suffering from either weak compilers or limited space of modeling. This framework resolves these issues by proposing a compilation and simulation flow to run arbitrary Caffe neural network models on the NVIDIA Deep Learning Accelerator (NVDLA) with gem5, a cycle-level simulator, and by adding more building blocks including scratchpad allocation, multi-accelerator scheduling, tensor-level prefetching mechanisms, and a DMA-aided embedded buffer to map workload to multiple NVDLAs. The proposed framework has been tested and verified on a set of convolution neural networks, showcasing the capability of modeling complex buffer management strategies, scheduling policies, and hardware architectures. As a case study of this framework, we demonstrate the importance of adopting different buffering strategies for activation and weight tensors in AI accelerators to acquire remarkable speedup.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4396220365",
    "type": "article"
  },
  {
    "title": "Data Pruning-enabled High Performance and Reliable Graph Neural Network Training on ReRAM-based Processing-in-Memory Accelerators",
    "doi": "https://doi.org/10.1145/3656171",
    "publication_date": "2024-08-13",
    "publication_year": 2024,
    "authors": "Chukwufumnanya Ogbogu; Biresh Kumar Joardar; Krishnendu Chakrabarty; Jana Doppa; Partha Pratim Pande",
    "corresponding_authors": "",
    "abstract": "Graph Neural Networks (GNNs) have achieved remarkable accuracy in cognitive tasks such as predictive analytics on graph-structured data. Hence, they have become very popular in diverse real-world applications. However, GNN training with large real-world graph datasets in edge-computing scenarios is both memory- and compute-intensive. Traditional computing platforms such as CPUs and GPUs do not provide the energy efficiency and low latency required in edge intelligence applications due to their limited memory bandwidth. Resistive random-access memory (ReRAM)-based processing-in-memory (PIM) architectures have been proposed as suitable candidates for accelerating AI applications at the edge, including GNN training. However, ReRAM-based PIM architectures suffer from low reliability due to their limited endurance, and low performance when they are used for GNN training in real-world scenarios with large graphs. In this work, we propose a learning-for-data-pruning framework, which leverages a trained Binary Graph Classifier (BGC) to reduce the size of the input data graph by pruning subgraphs early in the training process to accelerate the GNN training process on ReRAM-based architectures. The proposed light-weight BGC model reduces the amount of redundant information in input graph(s) to speed up the overall training process, improves the reliability of the ReRAM-based PIM accelerator, and reduces the overall training cost. This enables fast, energy-efficient, and reliable GNN training on ReRAM-based architectures. Our experimental results demonstrate that using this learning for data pruning framework, we can accelerate GNN training and improve the reliability of ReRAM-based PIM architectures by up to 1.6×, and reduce the overall training cost by 100× compared to state-of-the-art data pruning techniques.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4396613032",
    "type": "article"
  },
  {
    "title": "Advancing Hyperdimensional Computing Based on Trainable Encoding and Adaptive Training for Efficient and Accurate Learning",
    "doi": "https://doi.org/10.1145/3665891",
    "publication_date": "2024-06-04",
    "publication_year": 2024,
    "authors": "Jiseung Kim; Hyunsei Lee; Mohsen Imani; Yeseong Kim",
    "corresponding_authors": "",
    "abstract": "Hyperdimensional computing (HDC) is a computing paradigm inspired by the mechanisms of human memory, characterizing data through high-dimensional vector representations, known as hypervectors. Recent advancements in HDC have explored its potential as a learning model, leveraging its straightforward arithmetic and high efficiency. The traditional HDC frameworks are hampered by two primary static elements: randomly generated encoders and fixed learning rates. These static components significantly limit model adaptability and accuracy. The static, randomly generated encoders, while ensuring high-dimensional representation, fail to adapt to evolving data relationships, thereby constraining the model’s ability to accurately capture and learn from complex patterns. Similarly, the fixed nature of the learning rate does not account for the varying needs of the training process over time, hindering efficient convergence and optimal performance. This article introduces TrainableHD , a novel HDC framework that enables dynamic training of the randomly generated encoder depending on the feedback of the learning data, thereby addressing the static nature of conventional HDC encoders. TrainableHD also enhances the training performance by incorporating adaptive optimizer algorithms in learning the hypervectors. We further refine TrainableHD with effective quantization to enhance efficiency, allowing the execution of the inference phase in low-precision accelerators. Our evaluations demonstrate that TrainableHD significantly improves HDC accuracy by up to 27.99% (averaging 7.02%) without additional computational costs during inference, achieving a performance level comparable to state-of-the-art deep learning models. Furthermore, TrainableHD is optimized for execution speed and energy efficiency. Compared to deep learning on a low-power GPU platform like NVIDIA Jetson Xavier, TrainableHD is 56.4 times faster and 73 times more energy efficient. This efficiency is further augmented through the use of Encoder Interval Training (EIT) and adaptive optimizer algorithms, enhancing the training process without compromising the model’s accuracy.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4399321415",
    "type": "article"
  },
  {
    "title": "Gate-level test generation for sequential circuits",
    "doi": "https://doi.org/10.1145/238997.238999",
    "publication_date": "1996-10-01",
    "publication_year": 1996,
    "authors": "Kwang‐Ting Cheng",
    "corresponding_authors": "Kwang‐Ting Cheng",
    "abstract": "This paper discusses the gate-level automatic test pattern generation (ATPG) methods and techniques for sequential circuits. The basic concepts, examples, advantages, and limitations of representative methods are reviewed in detail. The relationship between gate-level sequential circuit ATPG and the partial scan design is also discussed.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W2022247345",
    "type": "article"
  },
  {
    "title": "A new viewpoint on code generation for directed acyclic graphs",
    "doi": "https://doi.org/10.1145/270580.270583",
    "publication_date": "1998-01-01",
    "publication_year": 1998,
    "authors": "S. Liao; Kurt Keutzer; Steve Tjiang; Srinivas Devadas",
    "corresponding_authors": "",
    "abstract": "We present a new viewpoint on code generation for directed acyclic graphs (DAGs). Our formulation is based on binate covering , the problem of satisfying, with minimum cost, a set of disjunctive clauses, and can take into account commutativity of operators and of the machine model. An important contribution of this work is a set of necessary and sufficient conditions for a valid schedule to be derived, based on the notion of worms and worm-partitions . This set of conditions can be compactly expressed with clauses that relate scheduling to code selection. For the case of one-register machines, we can derive clauses that lead to generation of optimal code for the DAG. Recent advances in exact binate covering algorithms allows us to use this strategy to generate optimal code for large basic blocks. The optimal code generated by our algorithm results in significant reductions in overall code size.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W2050956645",
    "type": "article"
  },
  {
    "title": "Efficient optimal design space characterization methodologies",
    "doi": "https://doi.org/10.1145/348019.348058",
    "publication_date": "2000-07-01",
    "publication_year": 2000,
    "authors": "Stephen A. Blythe; Robert A. Walker",
    "corresponding_authors": "",
    "abstract": "One of the primary advantages of a high-level synthesis system is its ability to explore the design space. This paper presents several methodologies for design space exploration that compute all optimal tradeoff points for the combined problem of scheduling, clock-length determination, and module selection. We discuss how each methodology takes advantage of the structure within the design space itself as well as the structure of, and interactions among, each of the three subproblems. (CAD)",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W1972329755",
    "type": "article"
  },
  {
    "title": "Optimal clock period FPGA technology mapping for sequential circuits",
    "doi": "https://doi.org/10.1145/293625.293632",
    "publication_date": "1998-07-01",
    "publication_year": 1998,
    "authors": "Peichen Pan; C. L. Liu",
    "corresponding_authors": "",
    "abstract": "We study the technology mapping problem for sequential circuits for look-up table (LUT) based field programmable gate arrays (FPGAs). Existing approaches to the problem simply remove the flip-flops (FFs), then map the remaining combinational logic, and finally put the FFs back. These approaches ignore the sequential nature of a circuit and assume the positions of the FFs are fixed. However, FFs in a sequential circuit can be reposistioned by a functionality-preserving transformation called retiming. As a result, existing approaches can only consider a very small portion of the available solution space. We propose in this paper a novel approach to the technology mapping problem. In our approach, retiming is integrated into the technology mapping process so as to consider the full solution space. We then present a polynomial technology mapping algorithm that, for a given circuit, produces a mapping solution with the minimum clock period among all possible ways of retiming. The effectiveness of the algorithm is also demonstrated experimentally.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W2013845995",
    "type": "article"
  },
  {
    "title": "Measurement and analysis of sequential design processes",
    "doi": "https://doi.org/10.1145/270580.270581",
    "publication_date": "1998-01-01",
    "publication_year": 1998,
    "authors": "Eric W. Johnson; Jay Brockman",
    "corresponding_authors": "",
    "abstract": "As design processes continue to increase in complexity it is important to base process-improvement decisions on quantitative analysis. We describe the development of an analytical approach for evaluating sequential design-process completion time and for determining the sensitivities of design time with respect to individual task durations and transition probabilities. Techniques are also detailed for collecting process metadata and calibrating a design proecess model. Example applications illustrate the use of the methodology in analyzing and improving software and hardware design processes.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W2026919142",
    "type": "article"
  },
  {
    "title": "Estimation of lower bounds in scheduling algorithms for high-level synthesis",
    "doi": "https://doi.org/10.1145/290833.290839",
    "publication_date": "1998-04-01",
    "publication_year": 1998,
    "authors": "Giri Tiruvuri; Moon Jung Chung",
    "corresponding_authors": "",
    "abstract": "To produce efficient design, a high-level synthesis system should be able to analyze a variety of cost-performance tradeoffs. The system can use lower-bound performance estimated methods to identify and puune inferior designs without producint complete designs. We present a lower-bound performance estimate method that is not only faster than existing methods, but also produces better lower bounds. In most cases, the lower bound produced by our algorithm is tight. Scheduling algorithms such as branch-and-bound need fast and effective lower-bound estimate methods, often for a large number of partially scheduled dataflow graphs, to reduce the search space. We extend our method to efficiently estimate completion time of partial schedules. This problem is not addressed by existing methods in the literature. Our lower-bound estimate is shown to by very effective in reducing the size of the search space when used in a branch-and-bound scheduling algorithm. Our methods can handle multicycle operations, pipelined functional units, and chaining of operations. We also present an extension to handle conditional branches. A salient feature of the extended method is its applicability to speculative execution as well as C-select implementation of conditional branches.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W2071192604",
    "type": "article"
  },
  {
    "title": "Semantics and verification of action diagrams with linear timing",
    "doi": "https://doi.org/10.1145/270580.270582",
    "publication_date": "1998-01-01",
    "publication_year": 1998,
    "authors": "K. Khordoc; E. Cerny",
    "corresponding_authors": "",
    "abstract": "Specifications containing linear timing constraints, such as found in action diagrams (timing diagrams) defining interface behaviors, are often used in practice. Although efficient O(n 3 ) shortest path algorithms exist for computing the minimum and maximum time distances between actions, subject to the timing constraints, there is so far no accurate method that can decide (a) whether a specification of this kind is realizable (i.e., can be simulated by a causal system), and (b) given the action diagrams of the interfaces of two or more communicating systems, whether the systems implementing such independent specifications will correctly interoperate (i.e., satisfy the respective protocols and timing assumptions). First we illustrate the weakness of existing action diagram verification techniques: the causality issue is not addressed, and the proposed methods to answer the compatibility (interoperability) question yield false negative answers in many practical situations. We then define the meaning of causality in an action diagram specification and state a set of sufficient conditions for causality to hold. This development then leads to an exact procedure for the verification of the interface compatibility of communicating action diagrams. the results are illustrated on a practical example.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W2076377800",
    "type": "article"
  },
  {
    "title": "Constraint analysis for code generation",
    "doi": "https://doi.org/10.1145/362652.362660",
    "publication_date": "2000-10-01",
    "publication_year": 2000,
    "authors": "K. van Eijk; Bart Mesman; C.A. Alba Pinto; Qin Zhao; Marco J.G. Bekooij; J. van Meerbergen; J.A.G. Jess",
    "corresponding_authors": "",
    "abstract": "Code generation methods for digital signal processors are increasingly hampered by the combination of tight timing constraints imposed by signal p processing applications and resource constraints implied by the processor architecture. In particular, limited resource availability (e.g.registers) poses a problem for traditional methods that perform code generation in separate stages (e.g., scheduling followed by register binding). This separation often results in suboptimality (or even infeasibility) of the generated solutions because it ignores the problem of phase coupling (e.g., since value lifetimes are a result of scheduling, scheduling affects the solution space for register binding). As a result, traditional methods need an increasing amount of help from the programmer (or designer) to arrive at a feasible solution. Because this requires an excessive amount of design time and extensive knowledge of the processor architecture, there is a need for automated techniques that can cope with the different kinds of contraints during scheduling. By exploiting these constraints to prune the schedule search space, the scheduler is often prevented from making a decision that inevitably violates one or more constraints. FACTS is a research tool developed for this purpose. In this paper we will elucidate the philosophy and concepts of FACTS and demonstrate them on a number of examples.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W2162365056",
    "type": "article"
  },
  {
    "title": "Optimizing computations for effective block-processing",
    "doi": "https://doi.org/10.1145/348019.348304",
    "publication_date": "2000-07-01",
    "publication_year": 2000,
    "authors": "Kumar N. Lalgudi; Marios C. Papaefthymiou; Miodrag Potkonjak",
    "corresponding_authors": "",
    "abstract": "Block-processing can decrease the time and power required to perform any given computation by simultaneously processing multiple samples of input data. The effectiveness of block-processing can be severely limited, however, if the delays in the dataflow graph of the computation are placed suboptimally. In this paper we investigate the application of retiming for improving the effectiveness of block-processing in computations. In particular, we consider the k-delay problem : Given a computation dataflow graph and a positive integer k , we wish to compute a retimed computation graph in which the original delays have been relocated so that k data samples can be processed simultaneously and fully regularly. We give an exact integer linear programming formulation for the k -delay problem. We also describe an algorithm that solves the k -delay problem fast in practice by relying on a set of necessary conditions to prune the search space. Experimental results with synthetic and random benchmarks demonstrate the performance improvements achievable by block-processing and the efficiency of our algorithm.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W1985186717",
    "type": "article"
  },
  {
    "title": "Multiway FPGA partitioning by fully exploiting design hierarchy",
    "doi": "https://doi.org/10.1145/329458.329463",
    "publication_date": "2000-01-01",
    "publication_year": 2000,
    "authors": "Wen-Jong Fang; Allen C.-H. Wu",
    "corresponding_authors": "",
    "abstract": "In this paper, we present a new integrated synthesis and partitioning method for multiple-FPGA applications. Our approach bridges the gap between HDL synthesis and physical partitioning by fully exploiting the design hierarchy. We propose a novel multiple-FPGA synthesis and partitioning method which is performed in three phases: (1) fine-grained synthesis, (2) functional-based clustering, and (3) hierarchical set-covering partitioning. This method first synthesizes a design specification in a fine-grained way so that functional clusters can be preserved based on the structural nature of the design specification. Then, it applies a hierarchical set-covering partitioning method to form the final FPGA partitions. Experimental results on a number of benchmarks and industrial designs demonstrate that I/O limits are the bottleneck for CLB utilization when applying a traditional multiple-FPGA synthesis method on flattened netlists. In contrast, by fully exploiting the design structural hierarchy during the multiple-FPGA partitioning, our proposed method produces fewer FPGA partitions with higher CLB and lower I/O-pin utilizations.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W2059817063",
    "type": "article"
  },
  {
    "title": "Prefetching for improved bus wrapper performance in cores",
    "doi": "https://doi.org/10.1145/504914.504917",
    "publication_date": "2002-01-01",
    "publication_year": 2002,
    "authors": "Roman Lysecky; Frank Vahid",
    "corresponding_authors": "",
    "abstract": "Reuse of cores can reduce design time for systems-on-a-chip. Such reuse is dependent on being able to easily interface a core to any bus. To enable such interfacing, many propose separating a core's interface from its internals by using a bus wrapper. However, this separation can lead to a performance penalty when reading a core's internal registers. In this paper, we introduce prefetching, which is analogous to caching, as a technique to reduce or eliminate this performance penalty, involving a tradeoff with power and size. We describe the prefetching technique, classify different types of registers, describe our initial prefetching architectures and heuristics for certain classes of registers, and highlight experiments demonstrating the performance improvements and size/power tradeoffs. We further introduce a technique for automatically designing a prefetch unit that satisfies user-imposed register-access constraints. The technique benefits from mapping the prefetching problem to the well-known real-time process scheduling problem. We then extend the technique to allow user-specified register interdependencies, using a Petri net model, resulting in even more efficient prefetch schedules.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W2146768042",
    "type": "article"
  },
  {
    "title": "Transistor placement for noncomplementary digital VLSI cell synthesis",
    "doi": "https://doi.org/10.1145/606603.606608",
    "publication_date": "2003-01-01",
    "publication_year": 2003,
    "authors": "Michael A. Riepe; Karem A. Sakallah",
    "corresponding_authors": "",
    "abstract": "There is an increasing need in modern VLSI designs for circuits implemented in high-performance logic families such as Cascode Voltage Switch Logic (CVSL), Pass Transistor Logic (PTL), and domino CMOS. Circuits designed in these noncomplementary ratioed logic families can be highly irregular, with complex diffusion sharing and nontrivial routing. Traditional digital cell layout synthesis tools derived from the highly stylized \"functional cell\" style break down when confronted with such circuit topologies. These cells require a full-custom, two-dimensional layout style which currently requires skilled manual design. In this work we propose a methodology for the synthesis of such complex noncomplementary digital cell layouts. We describe a new algorithm which permits the concurrent optimization of transistor chain placement and the ordering of the transistors within these diffusion-sharing chains. The primary mechanism for supporting this concurrent optimization is the placement of transistor subchains, diffusion-break-free components of the full transistor chains. When a chain is reordered, transistors may move from one subchain (and therefore one placement component) to another. We will demonstrate how this permits the chain ordering to be optimized for both intra-chain and inter-chain routing. We combine our placement algorithms with third-party routing and compaction tools, and present the results of a series of experiments which compare our technique with a commercial cell synthesis tool. These experiments make use of a new set of benchmark circuits which provide a rich sample of representative examples in several noncomplementary digital logic families.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W2014539192",
    "type": "article"
  },
  {
    "title": "Fast memory bank assignment for fixed-point digital signal processors",
    "doi": "https://doi.org/10.1145/966137.966140",
    "publication_date": "2004-01-01",
    "publication_year": 2004,
    "authors": "Jeonghun Cho; Yunheung Paek; David Whalley",
    "corresponding_authors": "",
    "abstract": "Most vendors of digital signal processors (DSPs) support a Harvard architecture, which has two or more memory buses, one for program and one or more for data and allow the processor to access multiple words of data from memory in a single instruction cycle. Also, many existing fixed-point DSPs are known to have an irregular architecture with heterogeneous registers, which contains multiple register files that are distributed and dedicated to different sets of instructions. Although there have been several studies conducted to efficiently assign data to multimemory banks, most of them assumed processors with relatively simple, homogeneous general-purpose registers. Thus, several vendor-provided compilers for DSPs that we examined were unable to efficiently assign data to multiple data memory banks, thereby often failing to generate highly optimized code for their machines. As a consequence, programmers for these DSPs often manually assign program variables to memories so as to fully utilize multimemory banks in their code. This paper reports on our recent attempt to address this problem by presenting an algorithm that helps the compiler to efficiently assign data to multimemory banks. Our algorithm differs from previous work in that it assigns variables to memory banks in separate, decoupled code generation phases, instead of a single, tightly coupled phase. The experimental results have revealed that our decoupled algorithm greatly simplifies our code generation process; thus our compiler runs extremely fast, yet generates target code that is comparable in quality to the code generated by a coupled approach.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W2054629523",
    "type": "article"
  },
  {
    "title": "Instruction-level test methodology for CPU core self-testing",
    "doi": "https://doi.org/10.1145/1109118.1109124",
    "publication_date": "2005-10-01",
    "publication_year": 2005,
    "authors": "S. Shamshiri; Hadi Esmaeilzadeh; Zainalabdein Navabi",
    "corresponding_authors": "",
    "abstract": "TIS is an instruction-level methodology for processor core self-testing that enhances instruction set of a CPU with test instructions. Since the functionality of test instructions is the same as the NOP instruction, NOP instructions can be replaced with test instructions. Online testing can be accomplished without any performance penalty. TIS tests different parts of the processor and detects stuck-at faults. This method can be employed in offline and online testing of single-cycle, multicycle and pipelined processors. But, TIS is more appropriate for online testing of pipelined architectures in which NOP instructions are frequently executed because of data, control and structural hazards. Running test instructions instead of these NOP instructions, TIS utilizes the time that is otherwise wasted by NOPs. In this article, two different implementations of TIS are presented. One implementation employs a dedicated hardware modules for test vector generation, while the other is a software-based approach that reads test vectors from memory. These two approaches are implemented on a pipelined processor core and their area overheads are compared. To demonstrate the appropriateness of the TIS test technique, several programs are executed and fault coverage results are presented.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W2079427175",
    "type": "article"
  },
  {
    "title": "Prototyping time- and space-efficient computations of algebraic operations over dynamically reconfigurable systems modeled by rewriting-logic",
    "doi": "https://doi.org/10.1145/1142155.1142156",
    "publication_date": "2006-04-01",
    "publication_year": 2006,
    "authors": "Maurício Ayala-Rincón; Carlos H. Llanos; Ricardo Pezzuol Jacobi; Reiner W. Hartenstein",
    "corresponding_authors": "",
    "abstract": "Many algebraic operations can be efficiently implemented as pipe networks in arrays of functional units such as systolic arrays that provide a large amount of parallelism. However, the applicability of classical systolic arrays is restricted to problems with strictly regular data dependencies yielding only arrays with uniform linear pipes. This limitation can be circumvented by using reconfigurable systolic arrays or reconfigurable data path arrays, where the node interconnections and operations can be redefined even at run time. In this context, several alternative reconfigurable systolic architectures can be explored and powerful tools are needed to model and evaluate them. Well-known rewriting-logic environments such as ELAN and Maude can be used to specify and simulate complex application-specific integrated systems. In this article we propose a methodology based on rewriting-logic which is adequate to quickly model and evaluate reconfigurable architectures (RA) in general and, in particular, reconfigurable systolic architectures. As an interesting case study we apply this rewriting-logic modeling methodology to the space-efficient treatment of the Fast-Fourier Transform (FFT). The FFT prototype conceived in this way, has been specified and validated in VHDL using the Quartus II system.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W1990033741",
    "type": "article"
  },
  {
    "title": "Simultaneous placement with clustering and duplication",
    "doi": "https://doi.org/10.1145/1142980.1142989",
    "publication_date": "2004-06-07",
    "publication_year": 2004,
    "authors": "Gang Chen; Jason Cong",
    "corresponding_authors": "",
    "abstract": "Clustering, duplication, and placement are critical steps in a cluster-based FPGA design flow. Clustering has a great impact on the wirelength, timing, and routability of a circuit. Logic duplication is an effective method for improving performance while maintaining the logic equivalence of a circuit. Based on several novel algorithmic contributions, we present an efficient and effective algorithm named SPCD (simultaneous placement with clustering and duplication) which performs clustering and duplication during placement for wirelength and timing minimization. First, we incorporate a path counting-based net weighting scheme for more effective timing optimization. Secondly, we introduce a novel method of moving a fragment of a cluster (called a fragment level move ) during placement to optimize the clustering structure. To reduce the critical path detour during legalization from a more global perspective, we also introduce the notions of a monotone region and a global monotone region in which improvement to the local/global path detour is guaranteed. Furthermore, we introduce a notion of a constrained gain graph to embed all complex FPGA clustering constraints, and implement an optimal incremental legalization algorithm under such constraints. Finally, in order to reduce the circuit area, we formulate a timing-constrained global redundancy removal problem and propose a heuristic solution. Our SPCD algorithm outperforms a widely used academic FPGA placement flow, T-VPack + VPR , with an average reduction of 31% in the longest path estimate delay and 18% in the routed delay. We also apply our SPCD algorithm to Altera's Stratix architecture in a commercial FPGA implementation flow ( Quartus II 4.0). The routed result achieved by our SPCD algorithm outperforms VPR by 20% and outperforms Quartus II 4.0 by 4%.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2079559808",
    "type": "article"
  },
  {
    "title": "An efficient algorithm for finding the minimal-area FPGA technology mapping",
    "doi": "https://doi.org/10.1145/1044111.1044121",
    "publication_date": "2005-01-01",
    "publication_year": 2005,
    "authors": "Chi‐Chou Kao; Yen‐Tai Lai",
    "corresponding_authors": "",
    "abstract": "Minimum area is one of the important objectives in technology mapping for lookup table-based field-progrmmable gate arrays (FPGAs). Although there is an algorithm that can find an optimal solution in polynomial time for the minimal-area FPGA technology mapping problem without gate duplication, its time complexity can grow exponentially with the number of inputs of the lookup-tables. This article proposes an algorithm with approximate to the area-optimal solution and lower time complexity. The time complexity of this algorithm is proven theoretically to be bounded by O ( n 3 ), where n is the total number of gates in the given circuit. It is shown that except for some cases the proposed algorithm can find an optimal solution of a given problem. We have combined the proposed algorithm with the existing postprocessing procedures which are used to find the gates that can be duplicated on a set of benchmark examples. The experimental results demonstrate the effectiveness of our algorithm.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W1994028288",
    "type": "article"
  },
  {
    "title": "A unified method for phase shifter computation",
    "doi": "https://doi.org/10.1145/1044111.1044120",
    "publication_date": "2005-01-01",
    "publication_year": 2005,
    "authors": "Dimitri Kagaris",
    "corresponding_authors": "Dimitri Kagaris",
    "abstract": "Phase shifters are used to shift the bit sequences produced by the successive stages of a built-in test pattern generator (TPG) based on a linear finite state machine (LFSM) by a specified amount ( phase shift ) relative to the characteristic sequence. An upper bound on the number of taps to be used for each phase shifter and a lower bound on the phase-shift value between successive stages of the TPG mechanism are the general parameters of the problem. Methods to design such phase shifters have been given in the past separately for Type-1 LFSRs, Type-2 LFSRs, and three-neighborhood cellular automata. In this article, we show how phase shifters can be synthesized uniformly and efficiently for any LFSM, including the aforementioned ones. We demonstrate the method by showing how to obtain phase shifters for two-dimensional cellular automata and for ring generators.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W2007572720",
    "type": "article"
  },
  {
    "title": "Event propagation for accurate circuit delay calculation using SAT",
    "doi": "https://doi.org/10.1145/1255456.1255473",
    "publication_date": "2007-08-17",
    "publication_year": 2007,
    "authors": "Suchismita Roy; P. P. Chakrabarti; Pallab Dasgupta",
    "corresponding_authors": "",
    "abstract": "A SAT-based modeling for event propagation in gate-level digital circuits, which is used for accurate calculation of critical delay in combinational and sequential circuits, is presented in this article. The accuracy of the critical delay estimation process depends on the accuracy with which the circuit in operation is modeled. A high level of precision in the modeling of the internal events in a circuit for the sake of greater accuracy causes a combinatorial blowup in the size of the problem, resulting in a scalability bottleneck for which most existing techniques effect a trade-off by restricting themselves to less precise models. SAT based techniques have a good track record in efficiency and scalability when the problem sizes become too large for most other methods. This article proposes a SAT-based technique for symbolic event propagation within a circuit which facilitates the estimation of the critical delay of circuits with a greater degree of accuracy, while at the same time scaling efficiently to large circuits. We report very encouraging results on the ISCAS85 and ISCAS89 benchmark circuits using the proposed technique.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2032642924",
    "type": "article"
  },
  {
    "title": "ILP and heuristic techniques for system-level design on network processor architectures",
    "doi": "https://doi.org/10.1145/1278349.1278361",
    "publication_date": "2007-09-01",
    "publication_year": 2007,
    "authors": "Chris Ostler; Karam S. Chatha; V. Ramamurthi; Krishnan Srinivasan",
    "corresponding_authors": "",
    "abstract": "Network processors incorporate several architectural features, including symmetric multiprocessing (SMP), block multithreading, and multiple memory elements, to support the high-performance requirements of current day applications. This article presents automated system-level design techniques for application development on such architectures. We propose integer linear programming formulations and heuristic techniques for process allocation and data mapping on SMP and block-multithreading-based network processors. The techniques incorporate process transformations and multithreading-aware data mapping to maximize the throughput of the application. The article presents experimental results that evaluate the techniques by implementing network processing applications on the Intel IXP 2400 architecture.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2076071620",
    "type": "article"
  },
  {
    "title": "Processor virtualization for secure mobile terminals",
    "doi": "https://doi.org/10.1145/1367045.1367057",
    "publication_date": "2008-07-01",
    "publication_year": 2008,
    "authors": "Hiroaki Inoue; Junji Sakai; Masato Edahiro",
    "corresponding_authors": "",
    "abstract": "We propose a processor virtualization architecture, VIRTUS, to provide a dedicated domain for preinstalled applications and virtualized domains for downloaded native applications. With it, security-oriented next-generation mobile terminals can provide any number of domains for native applications. VIRTUS features three new technologies, namely, VMM asymmetrization, dynamic interdomain communication (IDC), and virtualization-assist logic, and it is first in the world to virtualize an ARM-based multiprocessor. Evaluations have shown that VMM asymmetrization results in significantly less performance degradation and LOC increase than do other VMMs. Further, dynamic IDC overhead is low enough, and virtualization-assist logic can be implemented in a sufficiently small area.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W1967796680",
    "type": "article"
  },
  {
    "title": "SUPERB",
    "doi": "https://doi.org/10.1145/1562514.1596831",
    "publication_date": "2009-08-01",
    "publication_year": 2009,
    "authors": "Piet Engelke; Bernd Becker; M. Renovell; Juergen Schloeffel; Bettina Braitling; Ilia Polian",
    "corresponding_authors": "",
    "abstract": "A high-performance resistive bridging fault simulator SUPERB (Simulator Utilizing Parallel Evaluation of Resistive Bridges) is proposed. It is based on fault sectioning in combination with parallel-pattern or parallel-fault multiple-stuck-at simulation. It outperforms a conventional interval-based resistive bridging fault simulator by three orders of magnitude while delivering identical results. Further competing tools are outperformed by several orders of magnitude. Industrial-size circuits, including a multi-million-gates design, could be simulated with runtimes within an order of magnitude of the runtimes for pattern-parallel stuck-at fault simulation.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W1981134393",
    "type": "article"
  },
  {
    "title": "Generating realistic stimuli for accurate power grid analysis",
    "doi": "https://doi.org/10.1145/1529255.1529262",
    "publication_date": "2009-05-01",
    "publication_year": 2009,
    "authors": "Pedro Morgado; Paulo Flores; L. Miguel Silveira",
    "corresponding_authors": "",
    "abstract": "Power analysis tools are an integral component of any current power sign-off methodology. The performance of a design's power grid affects the timing and functionality of a circuit, directly impacting the overall performance. Ensuring power grid robustness implies taking into account, among others, static and dynamic effects of voltage drop, ground bounce, and electromigration. This type of verification is usually done by simulation, targeting a worst-case scenario where devices, switching almost simultaneously, could impose stern current demands on the power grid. While determination of the exact worst-case switching conditions from the grid perspective is usually not practical, the choice of simulation stimuli has a critical effect on the results of the analysis. Targetting safe but unrealistic settings could lead to pessimistic results and costly overdesigns in terms of die area. In this article we describe a software tool that generates a reasonable, realistic, set of stimuli for simulation. The approach proposed accounts for timing and spatial restrictions that arise from the circuit's netlist and placement and generates an approximation to the worst-case condition. The resulting stimuli indicate that only a fraction of the gates change in any given timing window, leading to a more robust verification methodology, especially in the dynamic case. Generating such stimuli is akin to performing a standard static timing analysis, so the tool fits well within conventional design frameworks. Furthermore, the tool can be used for hotspot detection in early design stages.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2035863366",
    "type": "article"
  },
  {
    "title": "A new efficient retiming algorithm derived by formal manipulation",
    "doi": "https://doi.org/10.1145/1297666.1297673",
    "publication_date": "2008-01-01",
    "publication_year": 2008,
    "authors": "Hai Zhou",
    "corresponding_authors": "Hai Zhou",
    "abstract": "A new efficient algorithm is derived for the minimal period retiming by formal manipulation. Contrary to all previous algorithms, which used fixed period feasibility checking to binary-search a candidate range, the derived algorithm checks the optimality of a feasible period directly. It is much simpler and more efficient than previous algorithms. Experimental results showed that it is even faster than ASTRA, an efficient heuristic algorithm. Since the derived algorithm is incremental by nature, it also opens the opportunity to be combined with other optimization techniques.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2152439301",
    "type": "article"
  },
  {
    "title": "Skew-aware polarity assignment in clock tree",
    "doi": "https://doi.org/10.1145/1497561.1497574",
    "publication_date": "2009-03-01",
    "publication_year": 2009,
    "authors": "Po‐Yuan Chen; Kuan-Hsien Ho; TingTing Hwang",
    "corresponding_authors": "",
    "abstract": "In modern sequential VLSI designs, clock tree plays an important role in synchronizing different components in a chip. To reduce peak current and power/ground noises caused by clock network, assigning different signal polarities to clock buffers is proposed in previous work. Although peak current and power/ground noises are minimized by signal polarities assignment, an assignment without timing information may increase the clock skew significantly. As a result, a timing-aware signal polarities assigning technique is necessary. In this article, we propose a novel signal polarities assigning technique which can not only reduce peak current and power/ground noises simultaneously but also render the clock skew in control. The experimental result shows that the clock skew produced by our algorithm is 94% of original clock skew in average while the clock skews produced by three algorithms (Partition, MST, Matching) in the absence of post clock tuning steps in the previous work are 235%, 272%, and 283%, respectively. Moreover, our algorithm is as efficient as the three algorithms of the previous work in reducing peak current and power/ground noises.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2620102549",
    "type": "article"
  },
  {
    "title": "Nanometer MOSFET Effects on the Minimum-Energy Point of Sub-45nm Subthreshold Logic---Mitigation at Technology and Circuit Levels",
    "doi": "https://doi.org/10.1145/1870109.1870111",
    "publication_date": "2010-11-01",
    "publication_year": 2010,
    "authors": "David Bol; Denis Flandre; Jean-Didier Legat",
    "corresponding_authors": "",
    "abstract": "Subthreshold operation of digital circuits enables minimum energy consumption. In this article, we observe that minimum energy E min of subthreshold logic dramatically increases when reaching 45nm CMOS node. We demonstrate by circuit simulation and analytical modeling that this increase comes from the combined effects of variability, gate leakage, and Drain-Induced Barrier Lowering (DIBL) effect. We then investigate the new impact of individual MOSFET parameters L g , V t , and T ox on E min in sub-45nm technologies. We further propose an optimum MOSFET selection, which favors low-V t mid-L g devices in 45nm CMOS technology. The use of such optimum MOSFETs yields 35% E min reduction for a benchmark multiplier with good speed performances and negligible area overhead. This optimum MOSFET selection can easily be integrated into a standard EDA tool flow by appropriate selection of the standard cell library. We finally demonstrate that undoped-channel fully-depleted Silicon-On-Insulator (SOI) technology brings 60% E min reduction with baseline MOSFETs thanks to strong mitigation of variability and short-channel effects. This study reveals a new (à priori counterintuitive) paradigm in device optimization for subthreshold logic: relaxing gate leakage constraints to improve robustness against short-channel effects and variability. Additionally, we propose pre-Silicon BSIM4 MOSFET model cards for realistic subthreshold circuit simulations including variability in bulk and fully depleted SOI technologies, which are made available online.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2003986325",
    "type": "article"
  },
  {
    "title": "Eh?Legalizer",
    "doi": "https://doi.org/10.1145/3158215",
    "publication_date": "2018-05-09",
    "publication_year": 2018,
    "authors": "Nima Karimpour Darav; Ismail Bustany; Andrew Kennings; David T. Westwick; Laleh Behjat",
    "corresponding_authors": "",
    "abstract": "The legalization step is performed after global placement where wire length and routability are optimized or during timing optimization where buffer insertion or gate sizing are applied to meet timing requirements. Therefore, an ideal legalization approach must preserve the quality of the input placement in terms of routability, wire length, and timing constraints. These requirements indirectly impose maximum and average cell movement constraints during legalization. In addition, the legalization step should effectively manage white space availability with a highly efficient runtime in order to be used in an iterative process such as timing optimization. In this article, a robust and fast legalization method called Eh?Legalizer for standard-cell placement is presented. Eh?Legalizer legalizes input placements while minimizing the maximum and average cell movements using a highly efficient novel network flow-based approach. In contrast to the traditional network flow-based legalizers, areas with high cell utilizations are effectively legalized by finding several candidate paths and there is no need for a post-process step. The experimental results conducted on several benchmarks show that Eh?Legalizer results in 2.5 times and 3.3 times less the maximum and average cell movement, respectively, while its runtime is significantly (18×) lower compared to traditional legalizers. In addition, the experimental results illustrate the scalability and robustness of Eh?Legalizer with respect to the floorplan complexity. Finally, the detailed-routing results show detailed-routing violations are reduced on average by 23% when Eh?Legalizer is used to generate legal solutions.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2800418272",
    "type": "article"
  },
  {
    "title": "A Maze Routing-Based Methodology With Bounded Exploration and Path-Assessed Retracing for Constrained Multilayer Obstacle-Avoiding Rectilinear Steiner Tree Construction",
    "doi": "https://doi.org/10.1145/3177878",
    "publication_date": "2018-05-09",
    "publication_year": 2018,
    "authors": "Kuen-Wey Lin; Yeh-Sheng Lin; Yih-Lang Li; Rung‐Bin Lin",
    "corresponding_authors": "",
    "abstract": "Owing to existing intellectual properties, prerouted nets, and power/ground wires, the routing of a system on chip design demands to detour around multilayer obstacles. Traditional approaches for the multilayer obstacle-avoiding rectilinear Steiner tree (ML-OARST) problem are thus nonmaze routing-based approaches for runtime issues, yet they cannot be directly applied to deal with additional constraints such as variant edge weights on a routing layer. In this article, we propose the maze routing-based methodology with bounded exploration and path-assessed retracing to reduce runtime and routing cost for the constrained ML-OARST construction problem. The exploration of maze routing is bounded to reduce the runtime; the costs of connecting pins are computed to select Steiner points in the retracing phase. To further reduce the routing cost, we develop a Steiner point-based ripping-up and rebuilding scheme for altering tree topology. Experimental results on industrial and randomly generated benchmarks demonstrate that the proposed methodology can provide a solution with good quality in terms of routing cost and has a significant speedup compared to traditional maze routing. A commercial tool is also used to show the effectiveness of the proposed methodology.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2802244581",
    "type": "article"
  },
  {
    "title": "Enhancements to SAT Attack",
    "doi": "https://doi.org/10.1145/3190853",
    "publication_date": "2018-05-09",
    "publication_year": 2018,
    "authors": "Yung‐Chih Chen",
    "corresponding_authors": "Yung‐Chih Chen",
    "abstract": "Logic encryption is an IC protection technique for preventing an IC design from overproduction and unauthorized use. It hides a design’s functionality by inserting key gates and key inputs, such that a secret key is required to activate the design and make it functioncorrectly. The security of a logic encryption algorithm is evaluated according to the difficulty of cracking the secret key. The state-of-the-art attack method identifies a secret key with a series of SAT-solving calls to prune all the incorrect keys. Although it can break most of the existing logic encryption algorithms within a few hours, we observe that there exist two enhancements for increasing its efficiency. First, we introduce a preprocess to identify and eliminate redundant key inputs and simplify SAT problems. Second, we present a key checking process for increasing the pruned incorrect keys in each SAT-solving iteration. We conducted the experiments on a set of benchmark circuits encrypted by six different logic encryption algorithms. The simulation results show that the enhanced method can successfully unlock 10 benchmark circuits which originally could not be cracked within 1 hour. For all the benchmark circuits, the average speedup is approximately 2.2x in terms of simulation time. Furthermore, a recent logic encryption method locks a design by creating cyclic paths, which can invalidate the SAT-based attack method. We analyze the impact of cyclic paths and propose an enhancement to break the cyclic logic encryption method.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2802290189",
    "type": "article"
  },
  {
    "title": "Trading Off Power Consumption and Prediction Performance in Wearable Motion Sensors",
    "doi": "https://doi.org/10.1145/3198457",
    "publication_date": "2018-09-30",
    "publication_year": 2018,
    "authors": "Ramin Fallahzadeh; Hassan Ghasemzadeh",
    "corresponding_authors": "",
    "abstract": "Power consumption is identified as one of the main complications in designing practical wearable systems, mainly due to their stringent resource limitations. When designing wearable technologies, several system-level design choices, which directly contribute to the energy consumption of these systems, must be considered. In this article, we propose a computationally lightweight system optimization framework that trades off power consumption and performance in connected wearable motion sensors. While existing approaches exclusively focus on one or a few hand-picked design variables, our framework holistically finds the optimal power-performance solution with respect to the specified application need. Our design tackles a multi-variant non-convex optimization problem that is theoretically hard to solve. To decrease the complexity, we propose a smoothing function that reduces this optimization to a convex problem. The reduced optimization is then solved in linear time using a devised derivative-free optimization approach, namely cyclic coordinate search. We evaluate our framework against several holistic optimization baselines using a real-world wearable activity recognition dataset. We minimize the energy consumption for various activity-recognition performance thresholds ranging from 40% to 80% and demonstrate up to 64% energy savings.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2896900236",
    "type": "article"
  },
  {
    "title": "UCR",
    "doi": "https://doi.org/10.1145/3264658",
    "publication_date": "2018-11-28",
    "publication_year": 2018,
    "authors": "Kun Yang; Ulbert J. Botero; Haoting Shen; Damon L. Woodard; Domenic Forte; Mark Tehranipoor",
    "corresponding_authors": "",
    "abstract": "Chipless Radio Frequency Identification (RFID) tags that do not include an integrated circuit (IC) in the transponder are more appropriate for supply-chain management of low-cost commodities and have been gaining extensive attention due to their relatively lower price. However, existing chipless RFID tags consume considerable tag area and manufacturing time/cost because of complex fabrication process (e.g., requiring removing or shorting some resonators on the tag substrate to encode data). Worse still, their identifiers (IDs) are deterministic, clonable, and small in terms of bitwidth. To address these shortcomings and help preserve the cold chain for commodities (e.g., vaccines, pharmaceuticals, etc.) sensitive to temperature, we develop a novel unclonable environmentally sensitive chipless RFID (UCR) tag that intrinsically generates a unique ID from both manufacturing variations and ambient temperature variation. A UCR tag consists of two parts: (i) a certain number of concentric ring slot resonators integrated on a certain laminate (e.g., TACONIC TLX-0), whose resonance frequencies rely on geometric parameters of slot resonators and dielectric constant of substrate material that are sensitive to manufacturing variations, and (ii) a stand-alone circular ring slot resonator integrated on a particular substrate (e.g., grease) that will be melted at a high temperature, whose resonance frequency relies on geometric parameters of slot resonator, dielectric constant of substrate material, and ambient temperature. UCR tags have the capability to track commodities and their temperatures in the supply chain. The area of UCR tag is comparable to regular quick response (QR) code. Experimental results based on UCR tag prototypes have verified their uniqueness and reliability.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2903029143",
    "type": "article"
  },
  {
    "title": "Optimization of Fault-Tolerant Mixed-Criticality Multi-Core Systems with Enhanced WCRT Analysis",
    "doi": "https://doi.org/10.1145/3275154",
    "publication_date": "2018-12-21",
    "publication_year": 2018,
    "authors": "Junchul Choi; Hoeseok Yang; Soonhoi Ha",
    "corresponding_authors": "",
    "abstract": "This article proposes a novel optimization technique of fault-tolerant mixed-criticality multi-core systems with worst-case response time (WCRT) guarantees. Typically, in fault-tolerant multi-core systems, tasks can be replicated or re-executed in order to enhance the reliability. In addition, based on the policy of mixed-criticality scheduling, low-criticality tasks can be dropped at runtime. Such uncertainties caused by hardening and mixed-criticality scheduling make WCRT analysis very difficult. We show that previous analysis techniques are pessimistic as they consider avoidably extreme cases that can be safely ignored within the given reliability constraint. We improve the analysis in order to tighten the pessimism of WCRT estimates by considering the maximum number of faults to be tolerated. Further, we improve the mixed-criticality scheduling by allowing partial dropping of low-criticality tasks. On top of those, we explore the design space of hardening, task-to-core mapping, and quality-of-service of the multi-core mixed-criticality systems. The effectiveness of the proposed technique is verified by extensive experiments with synthetic and real-life benchmarks.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2906594410",
    "type": "article"
  },
  {
    "title": "An efficient method for analyzing on-chip thermal reliability considering process variations",
    "doi": "https://doi.org/10.1145/2491477.2491485",
    "publication_date": "2013-07-01",
    "publication_year": 2013,
    "authors": "Yu‐Min Lee; Pei-Yu Huang",
    "corresponding_authors": "",
    "abstract": "This work provides an efficient statistical electrothermal simulator for analyzing on-chip thermal reliability under process variations. Using the collocation-based statistical modeling technique, first, the statistical interpolation polynomial for on-chip temperature distribution can be obtained by performing deterministic electrothermal simulation very few times and by utilizing polynomial interpolation. After that, the proposed simulator not only provides the mean and standard deviation profiles of on-chip temperature distribution, but also innovates the concept of thermal yield profile to statistically characterize the on-chip temperature distribution more precisely, and builds an efficient technique for estimating this figure of merit. Moreover, a mixed-mesh strategy is presented to further enhance the efficiency of the developed statistical electrothermal simulator. Experimental results demonstrate that (1) the developed statistical electrothermal simulator can obtain accurate approximations with orders of magnitude speedup over the Monte Carlo method; (2) comparing with a well-known cumulative distribution function estimation method, APEX [Li et al. 2004], the developed statistical electrothermal simulator can achieve 215× speedup with better accuracy; (3) the developed mixed-mesh strategy can achieve an order of magnitude faster over our baseline algorithm and still maintain an acceptable accuracy level.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2030474578",
    "type": "article"
  },
  {
    "title": "Dynamic programming-based runtime thermal management (DPRTM)",
    "doi": "https://doi.org/10.1145/2534382",
    "publication_date": "2013-12-01",
    "publication_year": 2013,
    "authors": "Ra’ed Al-Dujaily; Nizar Dahir; Terrence Mak; Fei Xia; Alex Yakovlev",
    "corresponding_authors": "",
    "abstract": "Complex thermal behavior inhibits the advancement of three-dimensional (3D) very-large-scale-integration (VLSI) system designs, as it could lead to ultra-high temperature hotspots and permanent silicon device damage. This article introduces a new runtime thermal management strategy to effectively diffuse and manage heat throughout 3D chip geometry for a better throughput performance in networks on chip (NoC). This strategy employs a dynamic programming-based runtime thermal management (DPRTM) policy to provide online thermal regulation. Reactive and proactive adaptive schemes are integrated to optimize the routing pathways depending on the critical temperature thresholds and traffic developments. Also, when the critical system thermal limit is violated, an urgent throttling will take place. The proposed DPRTM is rigorously evaluated through cycle-accurate simulations, and results show that the proposed approach outperforms conventional approaches in terms of computational efficiency and thermal stability. For example, the system throughput using the DPRTM approach can be improved by 33% when compared to other adaptive routing strategies for a given thermal constraint. Moreover, the DPRTM implementation presented in this article demonstrates that the hardware overhead is insignificant. This work opens a new avenue for exploring the on-chip adaptability and thermal regulation for future large-scale and 3D many-core integrations.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2054929864",
    "type": "article"
  },
  {
    "title": "GPU-Based Parallelization for Fast Circuit Optimization",
    "doi": "https://doi.org/10.1145/1970353.1970357",
    "publication_date": "2011-06-01",
    "publication_year": 2011,
    "authors": "Yifang Liu; Jiang Hu",
    "corresponding_authors": "",
    "abstract": "The progress of GPU (Graphics Processing Unit) technology opens a new avenue for boosting computing power. This work is an attempt to exploit the GPU for accelerating VLSI circuit optimization. We propose GPU-based parallel computing techniques and apply them on simultaneous gate sizing and threshold voltage assignment, which is a popular method for VLSI performance and power optimization. These techniques include efficient task scheduling and memory organization, all of which are aimed to fully utilize the advantages of GPUs. Compared to conventional sequential computation, our techniques can provide up to 56× (39× on average) speedup without any sacrifice on solution quality.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2089299404",
    "type": "article"
  },
  {
    "title": "A Survey of Parametric Dataflow Models of Computation",
    "doi": "https://doi.org/10.1145/2999539",
    "publication_date": "2017-01-20",
    "publication_year": 2017,
    "authors": "Adnan Bouakaz; Pascal Fradet; Alain Girault",
    "corresponding_authors": "",
    "abstract": "Dataflow models of computation (MoCs) are widely used to design embedded signal processing and streaming systems. Dozens of dataflow MoCs have been proposed in the past few decades. More recently, several parametric dataflow MoCs have been presented as an interesting tradeoff between analyzability and expressiveness. They offer a controlled form of dynamism under the form of parameters (e.g., parametric rates), along with runtime parameter configuration. This survey provides a comprehensive description of the existing parametric dataflow MoCs (constructs, constraints, properties, static analyses) and compares them using a common example. The main objectives are to help designers of streaming applications choose the most suitable model for their needs and pave the way for the design of new parametric MoCs.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2580097292",
    "type": "article"
  },
  {
    "title": "Approximate Energy-Efficient Encoding for Serial Interfaces",
    "doi": "https://doi.org/10.1145/3041220",
    "publication_date": "2017-05-20",
    "publication_year": 2017,
    "authors": "Daniele Jahier Pagliari; Enrico Macii; Massimo Poncino",
    "corresponding_authors": "",
    "abstract": "Serial buses are ubiquitous interconnections in embedded computing systems that are used to interface processing elements with peripherals, such as sensors, actuators, and I/O controllers. Despite their limited wiring, as off-chip connections they can account for a significant amount of the total power consumption of a system-on-chip device. Encoding the information sent on these buses is the most intuitive and affordable way to reduce their power contribution; moreover, the encoding can be made even more effective by exploiting the fact that many embedded applications can tolerate intermediate approximations without a significant impact on the final quality of results, thus trading off accuracy for power consumption. We propose a simple yet very effective approximate encoding for reducing dynamic energy in serial buses. Our approach uses differential encoding as a baseline scheme and extends it with bounded approximations to overcome the intrinsic limitations of differential encoding for data with low temporal correlation. We show that the proposed scheme, in addition to yielding extremely compact codecs, is superior to all state-of-the-art approximate serial encodings over a wide set of traces representing data received or sent from/to sensor or actuators.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2620517447",
    "type": "article"
  },
  {
    "title": "A self-tuning design methodology for power-efficient multi-core systems",
    "doi": "https://doi.org/10.1145/2390191.2390195",
    "publication_date": "2013-01-01",
    "publication_year": 2013,
    "authors": "Jin Sun; Rui Zheng; Jyothi Velamala; Yu Cao; Roman Lysecky; Karthik Shankar; Janet Roveda",
    "corresponding_authors": "",
    "abstract": "This article aims to achieve computational reliability and energy efficiency through codevelopment of algorithms, device, and circuit designs for application-specific, reconfigurable architectures. The new methodology characterizes aging-switching activity and aging-supply voltage relationships that are applicable for minimizing power consumption and task execution efficiency in order to achieve low bit energy ratio (BER). In addition, a new dynamic management algorithm (DMA) is proposed to alleviate device degradation and to extend system lifespan. In contrast to traditional workload balancing schemes in which cores are regarded as homogeneous, the new algorithm ranks cores as “highly competitive,” “less competitive,” and “not competitive” according to their various competitiveness. Core competitiveness is evaluated based upon their reliability, temperature, and timing requirements. Consequently, “competitive” cores will take charge of the majority of the tasks at relatively high voltage/frequency without violating power and timing budgets, while “not competitive” cores will have light workloads to ensure their reliability. The new approach combines intrinsic device characteristics (aging-switching activity and aging-supply voltage curves) into an integrated framework to achieve high reliability and low energy level with graceful degradation of system performance. Experimental results show that the proposed method has achieved up to 20% power reduction, with about 4% performance degradation (in terms of accomplished workload and system throughput), compared with traditional workload balancing methods. The new method also improves system mean-time-to-failure (MTTF) by up to 25%.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2621775645",
    "type": "article"
  },
  {
    "title": "Multi-Objective 3D Floorplanning with Integrated Voltage Assignment",
    "doi": "https://doi.org/10.1145/3149817",
    "publication_date": "2017-11-27",
    "publication_year": 2017,
    "authors": "Johann Knechtel; Jens Lienig; Ibrahim M. Elfadel",
    "corresponding_authors": "",
    "abstract": "Voltage assignment is a well-known technique for circuit design, which has been applied successfully to reduce power consumption in classical 2D integrated circuits (ICs). Its usage in the context of 3D ICs has not been fully explored yet although reducing power in 3D designs is of crucial importance, for example, to tackle the ever-present challenge of thermal management. In this article, we investigate the effective and efficient partitioning of 3D designs into multiple voltage domains during the floorplanning step of physical design. In particular, we introduce, implement, and evaluate novel algorithms for effective integration of voltage assignment into the inner floorplanning loops. Our algorithms are compatible not only with the traditional objectives of 2D floorplanning but also with the additional objectives and constraints of 3D designs, including the planning of through-silicon vias (TSVs) and the thermal management of stacked dies. We test our 3D floorplanner extensively on the GSRC benchmarks as well as on an augmented version of the IBM-HB+ benchmarks. The 3D floorplans are shown to achieve effective trade-offs for power and delays throughout different configurations—our results surpass naïve low-power and high-performance voltage assignment by 17% and 10%, on average. Finally, we release our 3D floorplanning framework as open-source code.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2768482204",
    "type": "article"
  },
  {
    "title": "Hardware-Enabled Pharmaceutical Supply Chain Security",
    "doi": "https://doi.org/10.1145/3144532",
    "publication_date": "2017-12-21",
    "publication_year": 2017,
    "authors": "Kun Yang; Haoting Shen; Domenic Forte; Swarup Bhunia; Mark Tehranipoor",
    "corresponding_authors": "",
    "abstract": "The pharmaceutical supply chain is the pathway through which prescription and over-the-counter (OTC) drugs are delivered from manufacturing sites to patients. Technological innovations, price fluctuations of raw materials, as well as tax, regulatory, and market demands are driving change and making the pharmaceutical supply chain more complex. Traditional supply chain management methods struggle to protect the pharmaceutical supply chain, maintain its integrity, enhance customer confidence, and aid regulators in tracking medicines. To develop effective measures that secure the pharmaceutical supply chain, it is important that the community is aware of the state-of-the-art capabilities available to the supply chain owners and participants. In this article, we will be presenting a survey of existing hardware-enabled pharmaceutical supply chain security schemes and their limitations. We also highlight the current challenges and point out future research directions. This survey should be of interest to government agencies, pharmaceutical companies, hospitals and pharmacies, and all others involved in the provenance and authenticity of medicines and the integrity of the pharmaceutical supply chain.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2776410873",
    "type": "article"
  },
  {
    "title": "Demand-Driven Single- and Multitarget Mixture Preparation Using Digital Microfluidic Biochips",
    "doi": "https://doi.org/10.1145/3200903",
    "publication_date": "2018-06-28",
    "publication_year": 2018,
    "authors": "Shalu; Srijan Kumar; Ananya Singla; Sudip Roy; Krishnendu Chakrabarty; P. P. Chakrabarti; Bhargab B. Bhattacharya",
    "corresponding_authors": "",
    "abstract": "Recent studies in algorithmic microfluidics have led to the development of several techniques for automated solution preparation using droplet-based digital microfluidic (DMF) biochips. A major challenge in this direction is to produce a mixture of several reactants with a desired ratio while optimizing reactant cost and preparation time. The sequence of mix-split operations that are to be performed on the droplets is usually represented as a mixing tree (or graph). In this article, we present an efficient mixing algorithm, namely, Mixing Tree with Common Subtrees ( MTCS ), for preparing single-target mixtures. MTCS attempts to best utilize intermediate droplets, which were otherwise wasted, and uses morphing based on permutation of leaf nodes to further reduce the graph size. The technique can be generalized to produce multitarget ratios, and we present another algorithm, namely, Multiple Target Ratios ( MTR ). Additionally, in order to enhance the output load, we also propose an algorithm for droplet streaming called Multitarget Multidemand ( MTMD ). Simulation results on a large set of target ratios show that MTCS can reduce the mean values of the total number of mix-split steps ( T ms ) and waste droplets ( W ) by 16% and 29% over Min-Mix (Thies et al. 2008) and by 22% and 34% over RMA (Roy et al. 2015), respectively. Experimental results also suggest that MTR can reduce the average values of T ms and W by 23% and 44% over the repeated version of Min-Mix , by 30% and 49% over the repeated version of RMA , and by 9% and 22% over the repeated-version of MTCS , respectively. It is observed that MTMD can reduce the mean values of T ms and W by 64% and 85%, respectively, over MTR . Thus, the proposed multitarget techniques MTR and MTMD provide efficient solutions to multidemand, multitarget mixture preparationon a DMF platform.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2811364359",
    "type": "article"
  },
  {
    "title": "Design Automation for Dilution of a Fluid Using Programmable Microfluidic Device--Based Biochips",
    "doi": "https://doi.org/10.1145/3306492",
    "publication_date": "2019-02-27",
    "publication_year": 2019,
    "authors": "Ankur Gupta; Juinn-Dar Huang; Shigeru Yamashita; Sudip Roy",
    "corresponding_authors": "",
    "abstract": "Microfluidic lab-on-a-chip has emerged as a new technology for implementing biochemical protocols on small-sized portable devices targeting low-cost medical diagnostics. Among various efforts of fabrication of such chips, a relatively new technology is a programmable microfluidic device (PMD) for implementation of flow-based lab-on-a-chip. A PMD chip is suitable for automation due to its symmetric nature. In order to implement a bioprotocol on such a reconfigurable device, it is crucial to automate a sample preparation on-chip as well. In this article, we propose a dilution PMD algorithm (namely DPMD ) and its architectural mapping scheme (namely generalized architectural mapping algorithm ( GAMA )) for addressing fluidic cells of such a device to perform dilution of a reagent fluid on-chip. We used an optimization function that first minimizes the number of mixing steps and then reduces the waste generation and further reagent requirement. Simulation results show that the proposed DPMD scheme is comparative to the existing state-of-the-art dilution algorithm. The proposed design automation using the architectural mapping scheme reduces the required chip area and, hence, minimizes the valve switching that, in turn, increases the life span of the PMD-chip.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2916644977",
    "type": "article"
  },
  {
    "title": "Hidden in Plaintext",
    "doi": "https://doi.org/10.1145/3361147",
    "publication_date": "2019-11-22",
    "publication_year": 2019,
    "authors": "Tamzidul Hoque; Kai Yang; Robert Karam; Shahin Tajik; Domenic Forte; Mark Tehranipoor; Swarup Bhunia",
    "corresponding_authors": "",
    "abstract": "Field Programmable Gate Arrays (FPGAs) have become an attractive choice for diverse applications due to their reconfigurability and unique security features. However, designs mapped to FPGAs are prone to malicious modifications or tampering of critical functions. Besides, targeted modifications have demonstrably compromised FPGA implementations of various cryptographic primitives. Existing security measures based on encryption and authentication can be bypassed using their side-channel vulnerabilities to execute bitstream tampering attacks. Furthermore, numerous resource-constrained applications are now equipped with low-end FPGAs, which may not support power-hungry cryptographic solutions. In this article, we propose a novel obfuscation-based approach to achieve strong resistance against both random and targeted pre-configuration tampering of critical functions in an FPGA design. Our solution first identifies the unique structural and functional features that separate the critical function from the rest of the design using a machine learning guided framework. The selected features are eliminated by applying appropriate obfuscation techniques, many of which take advantage of “FPGA dark silicon”—unused lookup table resources—to mask the critical functions. Furthermore, following the same obfuscation principle, a redundancy-based technique is proposed to thwart targeted, rule-based, and random tampering. We have developed a complete methodology and custom software toolflow that integrates with commercial tools. By applying the masking technique on a design containing AES, we show the effectiveness of the proposed framework in hiding the critical S-Box function. We implement the redundancy integrated solution in various cryptographic designs to analyze the overhead. To protect 16.2% critical component of a design, the proposed approach incurs an average area overhead of only 2.4% over similar redundancy-based approaches, while achieving strong security.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2990238172",
    "type": "article"
  },
  {
    "title": "Runtime Identification of Hardware Trojans by Feature Analysis on Gate-Level Unstructured Data and Anomaly Detection",
    "doi": "https://doi.org/10.1145/3391890",
    "publication_date": "2020-05-23",
    "publication_year": 2020,
    "authors": "Arunkumar Vijayan; Mehdi B. Tahoori; Krishnendu Chakrabarty",
    "corresponding_authors": "",
    "abstract": "As the globalization of chip design and manufacturing process becomes popular, malicious hardware inclusions such as hardware Trojans pose a serious threat to the security of digital systems. Advanced Trojans can mask many architectural-level Trojan signatures and adapt against several detection mechanisms. Runtime Trojan detection techniques are considered as a last line of defense against Trojan inclusion and activation. In this article, we propose an offline analysis to select a subset of flip-flops as surrogates and build an anomaly detection model based on the activity profile of flip-flops. These flip-flops are monitored online, and the anomaly detection model implemented online analyzes the flip-flop data to detect any anomalous Trojan activity. The effectiveness of our approach has been tested on several Trojan-inserted designs of the Leon3 processor. Trojan activation is detected with an accuracy score of above 0.9 (ratio of the number of true predictions to total number of predictions) with no false positives by monitoring less than 0.5% of the total number of flip-flops.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W3031089501",
    "type": "article"
  },
  {
    "title": "Leakage-Aware Dynamic Thermal Management of 3D Memories",
    "doi": "https://doi.org/10.1145/3419468",
    "publication_date": "2020-10-23",
    "publication_year": 2020,
    "authors": "Lokesh Siddhu; Rajesh Kedia; Preeti Ranjan Panda",
    "corresponding_authors": "",
    "abstract": "3D memory systems offer several advantages in terms of area, bandwidth, and energy efficiency. However, thermal issues arising out of higher power densities have limited their widespread use. While prior works have looked at reducing dynamic power through reduced memory accesses, in these memories, both leakage and dynamic power consumption are comparable. Furthermore, as the temperature rises, the leakage power increases, creating a thermal-leakage loop. We study the impact of leakage power on 3D memory temperature and propose turning OFF specific memory channels to meet thermal constraints. Data is migrated to a 2D memory before closing a 3D channel. We introduce an analytical model to assess the 2D memory delay and use the model to guide data migration decisions. The above strategy is referred to as FastCool and provides an improvement of 22%, 19%, and 32% on average (up to 57%, 72%, and 82%) in performance, memory energy, and energy-delay product (EDP), respectively, on different workloads consisting of SPEC CPU2006 benchmarks. We further propose a thermal management strategy named Energy-Efficient FastCool (EEFC) , which improves upon FastCool by selecting the channels to be closed by considering temperature, leakage, access rate, and position of various 3D memory channels at runtime. Our experiments demonstrate that EEFC leads to an additional improvement of up to 30%, 30%, and 51% in performance, memory energy, and EDP compared to FastCool. Finally, we analyze the effects of process variations on the efficiency of the proposed FC and EEFC strategies. Variation in the manufacturing process causes changes in the leakage power and temperature profile. Since EEFC considers both while selecting channels for closure, it is more resilient to process variations and achieves a lower application execution time and memory energy compared to FastCool.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W3093483245",
    "type": "article"
  },
  {
    "title": "A Deterministic-Path Routing Algorithm for Tolerating Many Faults on Very-Large-Scale Network-on-Chip",
    "doi": "https://doi.org/10.1145/3414060",
    "publication_date": "2020-10-27",
    "publication_year": 2020,
    "authors": "Ying Zhang; Xinpeng Hong; Zhongsheng Chen; Zebo Peng; Jianhui Jiang",
    "corresponding_authors": "",
    "abstract": "Very-large-scale network-on-chip (VLS-NoC) has become a promising fabric for supercomputers, but this fabric may encounter the many-fault problem. This article proposes a deterministic routing algorithm to tolerate the effects of many faults in VLS-NoCs. This approach generates routing tables offline using a breadth-first traversal algorithm and stores a routing table locally in each switch for online packet transmission. The approach applies the Tarjan algorithm to degrade the faulty NoC and maximizes the number of available nodes in the reconfigured NoC. In 2D NoCs, the approach updates routing tables of some nodes using the deprecated channel/node rules and avoids deadlocks in the NoC. In 3D NoCs, the approach uses a forbidden-turn selection algorithm and detour rules to prevent faceted rings and ensures the NoC is deadlock-free. Experimental results demonstrate that the proposed approach provides fault-free communications of 2D and 3D NoCs after injecting 40 faulty links. Meanwhile, it maximizes the number of available nodes in the reconfigured NoC. The approach also outperforms existing algorithms in terms of average latency, throughput, and energy consumption.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W3095398370",
    "type": "article"
  },
  {
    "title": "HeM3D",
    "doi": "https://doi.org/10.1145/3424239",
    "publication_date": "2021-02-17",
    "publication_year": 2021,
    "authors": "Aqeeb Iqbal Arka; Biresh Kumar Joardar; Ryan Kim; Dae Hyun Kim; Janardhan Rao Doppa; Partha Pratim Pande",
    "corresponding_authors": "",
    "abstract": "Heterogeneous manycore architectures are the key to efficiently execute compute- and data-intensive applications. Through-silicon-via (TSV)-based 3D manycore system is a promising solution in this direction as it enables the integration of disparate computing cores on a single system. Recent industry trends show the viability of 3D integration in real products (e.g., Intel Lakefield SoC Architecture, the AMD Radeon R9 Fury X graphics card, and Xilinx Virtex-7 2000T/H580T, etc.). However, the achievable performance of conventional TSV-based 3D systems is ultimately bottlenecked by the horizontal wires (wires in each planar die). Moreover, current TSV 3D architectures suffer from thermal limitations. Hence, TSV-based architectures do not realize the full potential of 3D integration. Monolithic 3D (M3D) integration, a breakthrough technology to achieve “More Moore and More Than Moore,” opens up the possibility of designing cores and associated network routers using multiple layers by utilizing monolithic inter-tier vias (MIVs) and hence, reducing the effective wire length. Compared to TSV-based 3D integrated circuits (ICs), M3D offers the “true” benefits of vertical dimension for system integration: the size of an MIV used in M3D is over 100 × smaller than a TSV. This dramatic reduction in via size and the resulting increase in density opens up numerous opportunities for design optimizations in 3D manycore systems: designers can use up to millions of MIVs for ultra-fine-grained 3D optimization, where individual cores and routers can be spread across multiple tiers for extreme power and performance optimization. In this work, we demonstrate how M3D-enabled vertical core and uncore elements offer significant performance and thermal improvements in manycore heterogeneous architectures compared to its TSV-based counterpart. To overcome the difficult optimization challenges due to the large design space and complex interactions among the heterogeneous components (CPU, GPU, Last Level Cache, etc.) in a M3D-based manycore chip, we leverage novel design-space exploration algorithms to trade off different objectives. The proposed M3D-enabled heterogeneous architecture, called HeM3D , outperforms its state-of-the-art TSV-equivalent counterpart by up to 18.3% in execution time while being up to 19°C cooler.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W3161671595",
    "type": "article"
  },
  {
    "title": "FastCFI: Real-time Control-Flow Integrity Using FPGA without Code Instrumentation",
    "doi": "https://doi.org/10.1145/3458471",
    "publication_date": "2021-06-05",
    "publication_year": 2021,
    "authors": "Lang Feng; Jeff Huang; Jiang Hu; Abhijith Reddy",
    "corresponding_authors": "",
    "abstract": "Control-Flow Integrity (CFI) is an effective defense technique against a variety of memory-based cyber attacks. CFI is usually enforced through software methods, which entail considerable performance overhead. Hardware-based CFI techniques can largely avoid performance overhead, but typically rely on code instrumentation, forming a non-trivial hurdle to the application of CFI. Taking advantage of the tradeoff between computing efficiency and flexibility of FPGA, we develop FastCFI, an FPGA-based CFI system that can perform fine-grained and stateful checking without code instrumentation. We also propose an automated Verilog generation technique that facilitates fast deployment of FastCFI, and a compression algorithm for reducing the hardware expense. Experiments on popular benchmarks confirm that FastCFI can detect fine-grained CFI violations over unmodified binaries. When using FastCFI on prevalent benchmarks, we demonstrate its capability to detect fine-grained CFI violations in unmodified binaries, while incurring an average of 0.36% overhead and a maximum of 2.93% overhead.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W3171616859",
    "type": "article"
  },
  {
    "title": "A Runtime Reconfigurable Design of Compute-in-Memory–Based Hardware Accelerator for Deep Learning Inference",
    "doi": "https://doi.org/10.1145/3460436",
    "publication_date": "2021-06-28",
    "publication_year": 2021,
    "authors": "Anni Lu; Xiaochen Peng; Yandong Luo; Shanshi Huang; Shimeng Yu",
    "corresponding_authors": "",
    "abstract": "Compute-in-memory (CIM) is an attractive solution to address the “memory wall” challenges for the extensive computation in deep learning hardware accelerators. For custom ASIC design, a specific chip instance is restricted to a specific network during runtime. However, the development cycle of the hardware is normally far behind the emergence of new algorithms. Although some of the reported CIM-based architectures can adapt to different deep neural network (DNN) models, few details about the dataflow or control were disclosed to enable such an assumption. Instruction set architecture (ISA) could support high flexibility, but its complexity would be an obstacle to efficiency. In this article, a runtime reconfigurable design methodology of CIM-based accelerators is proposed to support a class of convolutional neural networks running on one prefabricated chip instance with ASIC-like efficiency. First, several design aspects are investigated: (1) the reconfigurable weight mapping method; (2) the input side of data transmission, mainly about the weight reloading; and (3) the output side of data processing, mainly about the reconfigurable accumulation. Then, a system-level performance benchmark is performed for the inference of different DNN models, such as VGG-8 on a CIFAR-10 dataset and AlexNet GoogLeNet, ResNet-18, and DenseNet-121 on an ImageNet dataset to measure the trade-offs between runtime reconfigurability, chip area, memory utilization, throughput, and energy efficiency.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W3176833760",
    "type": "article"
  },
  {
    "title": "Quantifying Notions of Extensibility in FlexRay Schedule Synthesis",
    "doi": "https://doi.org/10.1145/2647954",
    "publication_date": "2014-08-01",
    "publication_year": 2014,
    "authors": "Reinhard Schneider; Dip Goswami; Samarjit Chakraborty; Unmesh D. Bordoloi; Petru Eles; Zebo Peng",
    "corresponding_authors": "",
    "abstract": "FlexRay has now become a well-established in-vehicle communication bus at most original equipment manufacturers (OEMs) such as BMW, Audi, and GM. Given the increasing cost of verification and the high degree of crosslinking between components in automotive architectures, an incremental design process is commonly followed. In order to incorporate FlexRay-based designs in such a process, the resulting schedules must be extensible , that is: (i) when messages are added in later iterations, they must preserve deadline guarantees of already scheduled messages, and (ii) they must accommodate as many new messages as possible without changes to existing schedules. Apart from extensible scheduling having not received much attention so far, traditional metrics used for quantifying them cannot be trivially adapted to FlexRay schedules. This is because they do not exploit specific properties of the FlexRay protocol. In this article we, for the first time, introduce new notions of extensibility for FlexRay that capture all the protocol-specific properties. In particular, we focus on the dynamic segment of FlexRay and we present a number of metrics to quantify extensible schedules. Based on the introduced metrics, we propose strategies to synthesize extensible schedules and compare the results of different scheduling algorithms. We demonstrate the applicability of the results with industrial-size case studies and also show that the proposed metrics may also be visually represented, thereby allowing for easy interpretation.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2043175197",
    "type": "article"
  },
  {
    "title": "Multiplierless Design of Folded DSP Blocks",
    "doi": "https://doi.org/10.1145/2663343",
    "publication_date": "2014-11-18",
    "publication_year": 2014,
    "authors": "Levent Aksoy; Paulo Flores; José Monteiro",
    "corresponding_authors": "",
    "abstract": "This article addresses the problem of minimizing the implementation cost of the time-multiplexed constant multiplication (TMCM) operation that realizes the multiplication of an input variable by a single constant selected from a set of multiple constants at a time. It presents an efficient algorithm, called orpheus , that finds a multiplierless TMCM design by sharing logic operators, namely adders, subtractors, adders/subtractors, and multiplexors (MUXes). Moreover, this article introduces folded design architectures for the digital signal processing (DSP) blocks, such as finite impulse response (FIR) filters and linear DSP transforms, and describes how these folded DSP blocks can be efficiently realized using TMCM operations optimized by orpheus . Experimental results indicate that orpheus can find better solutions than existing TMCM algorithms, yielding TMCM designs requiring less area. They also show that the folded architectures lead to alternative designs with significantly less area, but incurring an increase in latency and energy consumption, compared to the parallel architecture.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2069125731",
    "type": "article"
  },
  {
    "title": "Compiler Optimization for Reducing Leakage Power in Multithread BSP Programs",
    "doi": "https://doi.org/10.1145/2668119",
    "publication_date": "2014-11-18",
    "publication_year": 2014,
    "authors": "Wen-Li Shih; Yi‐Ping You; Chung-Wen Huang; Jenq Kuen Lee",
    "corresponding_authors": "",
    "abstract": "Multithread programming is widely adopted in novel embedded system applications due to its high performance and flexibility. This article addresses compiler optimization for reducing the power consumption of multithread programs. A traditional compiler employs energy management techniques that analyze component usage in control-flow graphs with a focus on single-thread programs. In this environment the leakage power can be controlled by inserting on and off instructions based on component usage information generated by flow equations. However, these methods cannot be directly extended to a multithread environment due to concurrent execution issues. This article presents a multithread power-gating framework composed of multithread power-gating analysis (MTPGA) and predicated power-gating (PPG) energy management mechanisms for reducing the leakage power when executing multithread programs on simultaneous multithreading (SMT) machines. Our multithread programming model is based on hierarchical bulk-synchronous parallel (BSP) models. Based on a multithread component analysis with dataflow equations, our MTPGA framework estimates the energy usage of multithread programs and inserts PPG operations as power controls for energy management. We performed experiments by incorporating our power optimization framework into SUIF compiler tools and by simulating the energy consumption with a post-estimated SMT simulator based on Wattch toolkits. The experimental results show that the total energy consumption of a system with PPG support and our power optimization method is reduced by an average of 10.09% for BSP programs relative to a system without a power-gating mechanism on leakage contribution set to 30%; and the total energy consumption is reduced by an average of 4.27% on leakage contribution set to 10%. The results demonstrate our mechanisms are effective in reducing the leakage energy of BSP multithread programs.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2077998140",
    "type": "article"
  },
  {
    "title": "Use It or Lose It",
    "doi": "https://doi.org/10.1145/2770873",
    "publication_date": "2015-09-28",
    "publication_year": 2015,
    "authors": "Hyungjun Kim; Siva Bhanu Krishna Boga; A. Vitkovskiy; Stavros Hadjitheophanous; Paul V. Gratz; Vassos Soteriou; Maria K. Michael",
    "corresponding_authors": "",
    "abstract": "Moore's Law scaling continues to yield higher transistor density with each succeeding process generation, leading to today's many-core chip multiprocessors (CMPs) with tens or even hundreds of interconnected cores or tiles. Unfortunately, deep submicron CMOS process technology is marred by increasing susceptibility to wear. Prolonged operational stress gives rise to accelerated wearout and failure due to several physical failure mechanisms, including hot-carrier injection (HCI) and negative-bias temperature instability (NBTI). Each failure mechanism correlates with different usage-based stresses, all of which can eventually generate permanent faults. While the wearout of an individual core in many-core CMPs may not necessarily be catastrophic, a single fault in the interprocessor network-on-chip (NoC) fabric could render the entire chip useless, as it could lead to protocol-level deadlocks, or even partition away vital components such as the memory controller or other critical I/O. In this article, we study HCI- and NBTI-induced wear due to actual stresses caused by real workloads, applied onto the interconnect microarchitecture and develop a critical path model for NBTI-induced wearout. A key finding of this modeling is that, counter to prevailing wisdom, wearout in the CMP's on-chip interconnect is correlated with lack of load observed in the NoC routers rather than high load. We then develop a novel wearout-decelerating scheme in which routers under low load have their wear-sensitive components exercised without significantly impacting cycle time, pipeline depth, area, or power consumption of the overall router. A novel deterministic approach is proposed for the generation of appropriate exercise-mode data, ensuring design parameter targets are met. We subsequently show that the proposed design yields an ∼2,300× decrease in the rate of wear.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2094339145",
    "type": "article"
  },
  {
    "title": "Exploiting Instruction Set Encoding for Aging-Aware Microprocessor Design",
    "doi": "https://doi.org/10.1145/2783435",
    "publication_date": "2015-12-02",
    "publication_year": 2015,
    "authors": "Fabian Oboril; Mehdi B. Tahoori",
    "corresponding_authors": "",
    "abstract": "Microprocessors fabricated at nanoscale nodes are exposed to accelerated transistor aging due to bias temperature instability and hot carrier injection. As a result, device delays increase over time, reducing the mean time to failure (MTTF) and hence lifetime of the processor. To address this challenge, many (micro)-architectural techniques target the execution stage of the instruction pipeline, as this one is typically most critical. However, also the decoding stages can become aging critical and limit the microprocessor lifetime, as we will show in this work. Therefore, we propose a novel aging-aware instruction set-encoding methodology (ArISE) that improves the instruction encoding iteratively using a heuristic algorithm. In addition, the switching activities of the affected memory elements are considered in order to co-optimize lifetime and energy efficiency. Our experimental results show that MTTF of the decoding stages can be improved by 2.3× with negligible implementation costs.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2185829336",
    "type": "article"
  },
  {
    "title": "Explaining Software Failures by Cascade Fault Localization",
    "doi": "https://doi.org/10.1145/2738038",
    "publication_date": "2015-06-24",
    "publication_year": 2015,
    "authors": "Qiuping Yi; Zijiang Yang; Jian Liu; Chen Zhao; Chao Wang",
    "corresponding_authors": "",
    "abstract": "During software debugging, a significant amount of effort is required for programmers to identify the root cause of a manifested failure. In this article, we propose a cascade fault localization method to help speed up this labor-intensive process via a combination of weakest precondition computation and constraint solving. Our approach produces a cause tree, where each node is a potential cause of the failure and each edge represents a casual relationship between two causes. There are two main contributions of this article that differentiate our approach from existing methods. First, our method systematically computes all potential causes of a failure and augments each cause with a proper context for ease of comprehension by the user. Second, our method organizes the potential causes in a tree structure to enable on-the-fly pruning based on domain knowledge and feedback from the user. We have implemented our new method in a software tool called CaFL, which builds upon the LLVM compiler and KLEE symbolic virtual machine. We have conducted experiments on a large set of public benchmarks, including real applications from GNU Coreutils and Busybox. Our results show that in most cases the user has to examine only a small fraction of the execution trace before identifying the root cause of the failure.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2251207443",
    "type": "article"
  },
  {
    "title": "Array Interleaving—An Energy-Efficient Data Layout Transformation",
    "doi": "https://doi.org/10.1145/2747875",
    "publication_date": "2015-06-24",
    "publication_year": 2015,
    "authors": "Namita Sharma; Preeti Ranjan Panda; Francky Catthoor; Praveen Raghavan; Tom Vander Aa",
    "corresponding_authors": "",
    "abstract": "Optimizations related to memory accesses and data storage make a significant difference to the performance and energy of a wide range of data-intensive applications. These techniques need to evolve with modern architectures supporting wide memory accesses. We investigate array interleaving , a data layout transformation technique that achieves energy efficiency by combining the storage of data elements from multiple arrays in contiguous locations, in an attempt to exploit spatial locality. The transformation reduces the number of memory accesses by loading the right set of data into vector registers, thereby minimizing redundant memory fetches. We perform a global analysis of array accesses, and account for possibly different array behavior in different loop nests that might ultimately lead to changes in data layout decisions for the same array across program regions. Our technique relies on detailed estimates of the savings due to interleaving, and also the cost of performing the actual data layout modifications. We also account for the vector register widths and the possibility of choosing the appropriate granularity for interleaving. Experiments on several benchmarks show a 6--34% reduction in memory energy due to the strategy.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2265966405",
    "type": "article"
  },
  {
    "title": "An Effective Chemical Mechanical Polishing Fill Insertion Approach",
    "doi": "https://doi.org/10.1145/2886097",
    "publication_date": "2016-05-11",
    "publication_year": 2016,
    "authors": "Chuangwen Liu; Peishan Tu; Pangbo Wu; Haomo Tang; Yande Jiang; Jian Kuang; Evangeline F. Y. Young",
    "corresponding_authors": "",
    "abstract": "To reduce chip-scale topography variation, dummy fill is commonly used to improve the layout density uniformity. Previous works either sought the most uniform density distribution or sought to minimize the inserted dummy fills while satisfying certain density uniformity constraint. However, due to more stringent manufacturing challenges, more criteria, like line deviation and outlier, emerge at newer technology nodes. This article presents a joint optimization scheme to consider variation, total fill, line deviation, outlier, overlap, and running time simultaneously. More specifically, first we decompose the rectilinear polygons and partition fillable regions into rectangles for easier processing. After decomposition, we insert dummy fills into the fillable rectangular regions optimizing the fill metrics simultaneously. We propose three approaches, Fast Median approach, LP approach, and Iterative approach, which are much faster with better quality, compared with the results of the top three contestants in the ICCAD Contest 2014.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2360470654",
    "type": "article"
  },
  {
    "title": "ERfair Scheduler with Processor Suspension for Real-Time Multiprocessor Embedded Systems",
    "doi": "https://doi.org/10.1145/2948979",
    "publication_date": "2016-12-13",
    "publication_year": 2016,
    "authors": "Piyoosh Purushothaman Nair; Arnab Sarkar; N. M. Harsha; Megha Gandhi; P. P. Chakrabarti; Sujoy Ghose",
    "corresponding_authors": "",
    "abstract": "Proportional fair schedulers with their ability to provide optimal schedulability along with hard timeliness and quality-of-service guarantees on multiprocessors form an attractive alternative in real-time embedded systems that concurrently run a mix of independent applications with varying timeliness constraints. This article presents ERfair Scheduler with Suspension on Multiprocessors (ESSM) , an efficient, optimal proportional fair scheduler that attempts to reduce system wide energy consumption by locally maximizing the processor suspension intervals while not sacrificing the ERfairness timing constraints of the system. The proposed technique takes advantage of higher execution rates of tasks in underloaded ERfair systems and uses a procrastination scheme to search for time points within the schedule where suspension intervals are locally maximal. Evaluation results reveal that ESSM achieves good sleep efficiency and provides up to 50% higher effective total sleep durations as compared to the Basic-ERfair scheduler on systems consisting of 2 to 20 processors.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2565124321",
    "type": "article"
  },
  {
    "title": "Dynamic Quantization Range Control for Analog-in-Memory Neural Networks Acceleration",
    "doi": "https://doi.org/10.1145/3498328",
    "publication_date": "2022-02-24",
    "publication_year": 2022,
    "authors": "Nathan Laubeuf; Jonas Doevenspeck; Ioannis A. Papistas; Michele Caselli; Stefan Cosemans; Peter Vrancx; Debjyoti Bhattacharjee; Arindam Mallik; Peter Debacker; Diederik Verkest; Francky Catthoor; Rudy Lauwereins",
    "corresponding_authors": "",
    "abstract": "Analog in Memory Computing (AiMC) based neural network acceleration is a promising solution to increase the energy efficiency of deep neural networks deployment. However, the quantization requirements of these analog systems are not compatible with state-of-the-art neural network quantization techniques. Indeed, while the quantization of the weights and activations is considered by modern deep neural network quantization techniques, AiMC accelerators also impose the quantization of each Matrix Vector Multiplication (MVM) result. In most demonstrated AiMC implementations, the quantization range of MVM results is considered a fixed parameter of the accelerator. This work demonstrates that dynamic control over this quantization range is possible but also desirable for analog neural networks acceleration. An AiMC compatible quantization flow coupled with a hardware aware quantization range driving technique is introduced to fully exploit these dynamic ranges. Using CIFAR-10 and ImageNet as benchmarks, the proposed solution results in networks that are both more accurate and more robust to the inherent vulnerability of analog circuits than fixed quantization range based approaches.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W4213435653",
    "type": "article"
  },
  {
    "title": "Application Mapping and Control-system Design for Microfluidic Biochips with Distributed Channel Storage",
    "doi": "https://doi.org/10.1145/3564288",
    "publication_date": "2022-09-26",
    "publication_year": 2022,
    "authors": "Zhisheng Chen; Wenzhong Guo; Genggeng Liu; Xing Huang",
    "corresponding_authors": "",
    "abstract": "Continuous-flow microfluidic biochips have emerged as a potential low-cost and fast-responsive lab-on-chip platform. They have attracted much attention due to their capability of performing various biochemical applications concurrently and automatically within a coin-sized chip area. To improve execution efficiency and reduce fabrication cost, a distributed channel-storage architecture can be implemented in which the same channels can be switched between the roles of transportation and storage. Accordingly, fluid transportation, caching, and fetch can be performed simultaneously through different flow paths. Such a flow-path planning needs to be considered carefully in the mapping procedure from a biochemical application to a given biochip architecture. Moreover, all the on-chip valves should be actuated correctly and promptly to temporally block the fluid transportation in unwanted directions and seal the fluids in caching channels. Such an exact control of the valves needs to be considered systematically in control-system design to support the mapping scheme for bioassay execution. In this article, we formulate the practical mapping-control co-design problem for microfluidic biochips with distributed channel storage, considering application mapping, valve synchronization, and control-system design simultaneously, and present an efficient synthesis flow to solve this problem systematically. Given the protocol of a biochemical application and the corresponding chip layout in the flow layer, our goal is to map the biochemical application onto the chip with short execution time. Meanwhile, a practical control system considering the real valve-switching requirements can be constructed efficiently with low fabrication cost. Experimental results on multiple real-life bioassays and synthetic benchmarks demonstrate the effectiveness of the proposed design flow.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W4297239162",
    "type": "article"
  },
  {
    "title": "<i>SwitchX</i> : Gmin-Gmax Switching for Energy-efficient and Robust Implementation of Binarized Neural Networks on ReRAM Xbars",
    "doi": "https://doi.org/10.1145/3576195",
    "publication_date": "2022-12-12",
    "publication_year": 2022,
    "authors": "Abhiroop Bhattacharjee; Priyadarshini Panda",
    "corresponding_authors": "",
    "abstract": "Memristive crossbars can efficiently implement Binarized Neural Networks (BNNs) wherein the weights are stored in high-resistance states (HRS) and low-resistance states (LRS) of the synapses. We propose SwitchX mapping of BNN weights onto ReRAM crossbars such that the impact of crossbar non-idealities, that lead to degradation in computational accuracy, are minimized. Essentially, SwitchX maps the binary weights in such manner that a crossbar instance comprises of more HRS than LRS synapses. We find BNNs mapped onto crossbars with SwitchX to exhibit better robustness against adversarial attacks than the standard crossbar-mapped BNNs, the baseline. Finally, we combine SwitchX with state-aware training (that further increases the feasibility of HRS states during weight mapping) to boost the robustness of a BNN on hardware. We find that this approach yields stronger defense against adversarial attacks than adversarial training, a state-of-the-art software defense. We perform experiments on a VGG16 BNN with benchmark datasets (CIFAR-10, CIFAR-100 & TinyImagenet) and use Fast Gradient Sign Method and Projected Gradient Descent adversarial attacks. We show that SwitchX combined with state-aware training can yield upto ~35% improvements in clean accuracy and ~6-16% in adversarial accuracies against conventional BNNs. Furthermore, an important by-product of SwitchX mapping is increased crossbar power savings, owing to an increased proportion of HRS synapses, that is furthered with state-aware training. We obtain upto ~21-22% savings in crossbar power consumption for state-aware trained BNN mapped via SwitchX on 16x16 & 32x32 crossbars using the CIFAR-10 & CIFAR-100 datasets.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W4311409824",
    "type": "article"
  },
  {
    "title": "ILP-based Substrate Routing with Mismatched Via Dimension Consideration for Wire-bonding FBGA Package Design",
    "doi": "https://doi.org/10.1145/3579843",
    "publication_date": "2023-01-10",
    "publication_year": 2023,
    "authors": "Jun-Sheng Wu; Chi-An Pan; Yi-Yu Liu",
    "corresponding_authors": "",
    "abstract": "With the rapidly growing demand for system-level integration, package substrates have become one of the most important carriers in semiconductor industry. Fine pitch ball grid array (FBGA) packaging is a widely used technology thanks to its relative cost-effectiveness compared to other advanced packaging technologies. In addition, it is also widely used in space-constrained applications, such as mobile and handheld devices. These packaging substrate interconnections are usually customized by layout engineers taking many complex and stringent design rules into consideration. However, fully net-by-net manual design for FBGA is time-consuming and error-prone. In this article, we propose an integer linear programming (ILP)-based router for wire-bonding FBGA packaging design. Our ILP formulation not only can handle design-dependent constraints but also take the problem of mismatched via dimension into account, which is caused by the mechanical processes and greatly increases design complexity. In addition to the ILP formulation for substrate routing, three optimization stages and several ILP constraint reduction techniques are also developed to boost the run time of ILP solver. Experimental results indicate that the proposed framework can achieve high routing completion rates, which could effectively reduce the cycle time of substrate layout design. In addition, in combination with the proposed optimization strategies, 278× speedup can be achieved compared to the ILP constraint optimized router.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4315491112",
    "type": "article"
  },
  {
    "title": "Component Fault Diagnosability of Hierarchical Cubic Networks",
    "doi": "https://doi.org/10.1145/3577018",
    "publication_date": "2023-01-18",
    "publication_year": 2023,
    "authors": "Yanze Huang; K. Wen; Limei Lin; Li Xu; Sun‐Yuan Hsieh",
    "corresponding_authors": "",
    "abstract": "The fault diagnosability of a network indicates the self-diagnosis ability of the network, thus it is an important measure of robustness of the network. As a neoteric feature for measuring fault diagnosability, the r -component diagnosability ct r (G) of a network G imposes the restriction that the number of components is at least r in the remaining network of G by deleting faulty set X , which enhances the diagnosability of G . In this article, we establish the r -component diagnosability for n -dimensional hierarchical cubic network HCN n , and we show that, under both PMC model and MM* model, the r -component diagnosability of HCN n is rn -½( r -1) r +1 for n ≥ 2 and 1≤ r≤ n-1 . Moreover, we introduce the concepts of 0-PMC subgraph and 0-MM* subgraph of HCN n . Then, we make use of 0-PMC subgraph and 0-MM* subgraph of HCN n to design two algorithms under PMC model and MM* model, respectively, which are practical and efficient for component fault diagnosis of HCN n . Besides, we compare the r -component diagnosability of HCN n with the extra conditional diagnosability, diagnosability, good-neighbor diagnosability, pessimistic diagnosability, and conditional diagnosability, and we verify that the r -component diagnosability of HCN n is higher than the other types of diagnosability.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4317209835",
    "type": "article"
  },
  {
    "title": "CBDC-PUF: A Novel Physical Unclonable Function Design Framework Utilizing Configurable Butterfly Delay Chain Against Modeling Attack",
    "doi": "https://doi.org/10.1145/3588435",
    "publication_date": "2023-03-21",
    "publication_year": 2023,
    "authors": "Yanjiang Liu; Junwei Li; Tongzhou Qu; Zibin Dai",
    "corresponding_authors": "",
    "abstract": "Physical unclonable function (PUF) is a promising security-based primitive, which provides an extremely large number of responses for key generation and authentication applications. Various PUFs have been developed as central building blocks in cryptographic protocols and security architectures, however, the existing PUFs and their improvements are still vulnerable to modeling attacks (MA) with refined machine learning algorithms. In this article, a configurable butterfly delay chain-based PUF design framework is proposed to meet the requirements of randomness, reliability, uniqueness, and MA-resistance metrics. A configurable butterfly delay chain is introduced to create multiple pairs of symmetric paths and a strong PUF relying on the intrinsic delay fluctuations of two identical paths is built. Furthermore, a secure hash function is used to insert non-linearities into the PUF, and a BCH-based error correction algorithm is utilized to recover the actual responses under noisy environments. The proposed PUF is implemented on Xilinx FPGAs and three machine learning algorithms are used to evaluate the resistance against MA. Experimental results show that the randomness, reliability, and uniqueness of the proposed PUF are close to the ideal value (49.6%, 99.9%, and 49.9%, respectively), and the prediction accuracy reaches 50% that indicating a desirable resilient to MA.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4328127680",
    "type": "article"
  },
  {
    "title": "GNN-based Multi-bit Flip-flop Clustering and Post-clustering Design Optimization for Energy-efficient 3D ICs",
    "doi": "https://doi.org/10.1145/3588570",
    "publication_date": "2023-04-06",
    "publication_year": 2023,
    "authors": "Pruek Vanna-Iampikul; Yi‐Chen Lu; Da Eun Shim; Sung Kyu Lim",
    "corresponding_authors": "",
    "abstract": "In high-performance three-dimensional Integrated Circuits (3D ICs), clock networks consume a large portion of the full-chip power. However, no previous 3D IC work has ever optimized 3D clock networks for both power and performance simultaneously, which results in sub-optimal 3D designs. To overcome this issue, in this article, we propose a GNN-based flip-flop clustering algorithm that merges single-bit flip-flops into multi-bit flip-flops in an unsupervised manner, which jointly optimizes the power and performance metrics of clock networks. Moreover, we integrate our algorithm into the state-of-the-art 3D physical design flow and verify the integration, which leads to a better 3D full-chip design. Experimental results on eight industrial benchmarks demonstrate that the algorithm achieves improvements up to 18% in total power and 8.2% in performance over the state-of-the-art 3D flow.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4362671008",
    "type": "article"
  },
  {
    "title": "A Reconfigurable 7T SRAM Bit Cell for High Speed, Power Saving and Low Voltage Application",
    "doi": "https://doi.org/10.1145/3616872",
    "publication_date": "2023-08-23",
    "publication_year": 2023,
    "authors": "Bhawna Rawat; Poornima Mittal",
    "corresponding_authors": "",
    "abstract": "The decreasing operational voltage and scaled technology node for memory designing has widened the gap between two crucial parameters for an SRAM – delay and power. As the demand for internet of things is increasing, the need for round the clock connectivity is increasing. This mandates designing a cell with a capability to switch between low power and high speed operation. Thus, this paper presents the design of dual mode operational 7T cell that can switch between single port and dual port configuration. The proposed reconfigurable cell can operate as single port or dual port cell single ended 7T cell. The reconfigurability in the cell is realized using control signals. The noise stability of the bit cell is obtained to be 333, 333, and 470 mV for read, hold, and write modes, respectively. The robustness of the cell against temperature variation, process variation and voltage variation is also analyzed. The performance variation in each parameter will not have a dramatic impact as it is within manageable limit. Its write time is 0.14 ns, while 5 ps are required for a successful read operation. The dual port configuration of the cell supports pipelining and thus operates faster than its single port configuration.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4386091489",
    "type": "article"
  },
  {
    "title": "Task Modules Partitioning, Scheduling and Floorplanning for Partially Dynamically Reconfigurable Systems with Heterogeneous Resources",
    "doi": "https://doi.org/10.1145/3625295",
    "publication_date": "2023-09-26",
    "publication_year": 2023,
    "authors": "Bo Ding; Jinglei Huang; Junpeng Wang; Qi Xu; Song Chen; Yi Kang",
    "corresponding_authors": "",
    "abstract": "Some field programmable gate arrays (FPGAs) can be partially dynamically reconfigurable with heterogeneous resources distributed on the chip. FPGA-based partially dynamically reconfigurable system (FPGA-PDRS) can be used to accelerate computing and improve computing flexibility. However, the traditional design of FPGA-PDRS is based on manual design. Implementing the automation of FPGA-PDRS needs to solve the problems of task modules partitioning, scheduling, and floorplanning on heterogeneous resources. Existing works only partly solve problems for the automation process of FPGA-PDRS or model homogeneous resources for FPGA-PDRS. To better solve the problems in the automation process of FPGA-PDRS and narrow the gap between algorithm and application, in this paper, we propose a complete workflow including three parts: pre-processing to generate the lists of task module candidate shapes according to the resource requirements, exploration process to search the solution of task modules partitioning, scheduling, and floorplanning, and post-optimization to improve the floorplan success rate. Experimental results show that, compared with state-of-the-art work, the pre-processing process can reduce the occupied area of task modules by 6% on average; the proposed complete workflow can improve performance by 9.6%, and reduce communication cost by 14.2% with improving the resources reuse rate of the heterogeneous resources on the chip. Based on the solution generated by the exploration process, the post-optimization process can improve the floorplan success rate by 11%.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4387055967",
    "type": "article"
  },
  {
    "title": "NPU-Accelerated Imitation Learning for Thermal Optimization of QoS-Constrained Heterogeneous Multi-Cores",
    "doi": "https://doi.org/10.1145/3626320",
    "publication_date": "2023-10-05",
    "publication_year": 2023,
    "authors": "Martin Rapp; Heba Khdr; Nikita Krohmer; Jörg Henkel",
    "corresponding_authors": "",
    "abstract": "Thermal optimization of a heterogeneous clustered multi-core processor under user-defined QoS targets requires application migration and DVFS. However, selecting the core to execute each application and the VF levels of each cluster is a complex problem because (1) the diverse characteristics and QoS targets of applications require different optimizations, and (2) per-cluster DVFS requires a global optimization considering all running applications. State-of-the-art resource management for power or temperature minimization either relies on measurements that are commonly not available (such as power) or fails to consider all the dimensions of the optimization (e.g., by using simplified analytical models). To solve this, ML methods can be employed. In particular, IL leverages the optimality of an oracle policy, yet at low run-time overhead, by training a model from oracle demonstrations. We are the first to employ IL for temperature minimization under QoS targets. We tackle the complexity by training NN at design time and accelerate the run-time NN inference using NPU. While such NN accelerators are becoming increasingly widespread, they are so far only used to accelerate user applications. In contrast, we use for the first time an existing accelerator on a real platform to accelerate NN-based resource management. To show the superiority of IL compared to RL in our targeted problem, we also develop multi-agent RL-based management. Our evaluation on a HiKey 970 board with an Arm big.LITTLE CPU and NPU shows that IL achieves significant temperature reductions at a negligible run-time overhead. We compare TOP-IL against several techniques. Compared to ondemand Linux governor, TOP-IL reduces the average temperature by up to 17 ˆC at minimal QoS violations for both techniques. Compared to the RL policy, our TOP-IL achieves 63 % to 89 % fewer QoS violations while resulting similar average temperatures. Moreover, TOP-IL outperforms the RL policy in terms of stability. We additionally show that our IL-based technique also generalizes to different software (unseen applications) and even hardware (different cooling) than used for training.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4387378083",
    "type": "article"
  },
  {
    "title": "Enhanced Real-time Scheduling of AVB Flows in Time-Sensitive Networking",
    "doi": "https://doi.org/10.1145/3637878",
    "publication_date": "2023-12-18",
    "publication_year": 2023,
    "authors": "Libing Deng; Gang Zeng; Ryo Kurachi; Hiroaki Takada; Xiongren Xiao; Renfa Li; Guoqi Xie",
    "corresponding_authors": "",
    "abstract": "Time-Sensitive Networking (TSN) realizes high bandwidth and time determinism for data transmission and thus becomes the crucial communication technology in time-critical systems. The Gate Control List (GCL) is used to control the transmission of different classes of traffic in TSN, including Time-Triggered (TT) flows, Audio-Video-Bridging (AVB) flows, and Best-Effort (BE) flows. Most studies focus on optimizing GCL synthesis by reserving the preceding time slots to serve TT flows with the strict delay requirement, but ignore the deadlines of non-TT flows and cause the large delay. Therefore, this paper proposes a comprehensive scheduling method to enhance the real-time scheduling of AVB flows while guaranteeing the time determinism of TT flows. This method first optimizes GCL synthesis to reserve the preceding time slots for AVB flows, and then introduces the Earliest Deadline First (EDF) method to further improve the transmission of AVB flows by considering their deadlines. Moreover, the worst-case delay (WCD) analysis method is proposed to verify the effectiveness of the proposed method. Experimental results show that the proposed method improves the transmission of AVB flows compared to the state-of-the-art methods.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4389884214",
    "type": "article"
  },
  {
    "title": "Functional partitioning improvements over structural partitioning for packaging constraints and synthesis",
    "doi": "https://doi.org/10.1145/290833.290841",
    "publication_date": "1998-04-01",
    "publication_year": 1998,
    "authors": "Frank Vahid; Thuy Dm Le; Yu-Chin Hsu",
    "corresponding_authors": "",
    "abstract": "Incorporating functional partitioning into a synthesis methodology leads to several important advantages. In functional partitioning, we first partition a functional specification into smaller subspecifications and then synthesize structure for each, in contrast to the current approach of first synthesizing structure for the entire specification and then partitioning that structure. One advantage is the improvement in I/O performance and package count, when partitioning among hardware blocks with size and I/O constraints, such as FPGAs or blocks within an ASIC. A second advantage is reduction in synthesis runtimes. We describe these important advantages, concluding that further research on functional partitioning can lead to inproved results from synthesis environments.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W2084719608",
    "type": "article"
  },
  {
    "title": "Transistor reordering for power minimization under delay constraint",
    "doi": "https://doi.org/10.1145/233539.233543",
    "publication_date": "1996-04-01",
    "publication_year": 1996,
    "authors": "Sharat C. Prasad; Kaushik Roy",
    "corresponding_authors": "",
    "abstract": "In this article we address the problem of optimization of VLSI circuits to minimize power consumption while meeting performance goals. We present a method of estimating power consumption of a basic or complex CMOS gate which takes the internal capacitances of the gate into account. This method is used to select an ordering of series-connected transistors found in CMOS gates to achieve lower power consumption. The method is very efficient when used by library-based design styles. We describe a multipass algorithm that makes use of transistor reordering to optimize performance and power consumption of circuits, has a linear time complexity per pass, and converges to a solution in a small number of passes. Transformations in addition to transistor reordering can be used by the algorithm. The algorithm has been benchmarked on several large examples and the results are presented.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W1968577415",
    "type": "article"
  },
  {
    "title": "The Unison algorithm",
    "doi": "https://doi.org/10.1145/238997.239009",
    "publication_date": "1996-10-01",
    "publication_year": 1996,
    "authors": "Rok Sosič; Jun Gu; Robert R. Johnson",
    "corresponding_authors": "",
    "abstract": "We present a Unison algorithm to evaluate arbitrarily complex Boolean expressions. This novel algorithm, based on the total differential of a Boolean function, enables fast evaluation of Boolean expressions in software. Any combination of Boolean operations can be packed into the bits of one computer word and evaluated in parallel by bitwise logical operations. Sample runs of the Unison algorithm show that many Boolean operations can evaluated in one clock cycle. The Unison algorithm is able to evaluate Boolean expressions at an execution speed that is comparable to compiled evaluation while retaining the flexibility of interpreted approaches. The algorithm lends itself well to many practical applications.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W1992171235",
    "type": "article"
  },
  {
    "title": "Event propagation conditions in circuit delay computation",
    "doi": "https://doi.org/10.1145/264995.264998",
    "publication_date": "1997-07-01",
    "publication_year": 1997,
    "authors": "Hakan Yalcin; John P. Hayes",
    "corresponding_authors": "",
    "abstract": "Accurate and efficient computation of delays is a central problem in computer-aided design of complex VLSI circuits. Delays are determined by events (signal transitions) propagated from the inputs of a circuit to its outputs, so precise characterization of event propagation is required for accurate delay computation. Although many different propagation conditions (PCs) have been proposed for delay computation, their properties and relationships have been far from clear. We present a systematic analysis of delay computation based on a series of waveform models that capture signal behavior rigorously at different levels of details. The most general model, called the exact of W0 model, specifies each event occurring in a circuit signal. A novel method is presented that generates approximate waveforms by progressively eliminating signal values from the exact model. For each waveform model, we drive the PCs that correctly capture the requirements under which an event propagates along a path. The waveform models and their PCs are shown to form a well-defined hierarchy, which provides a means to trade accuracy for computational effort. The relationships among the derived PCs and existing ones are analyzed in depth. It is proven that though many PCs, such as the popular floating mode condition, produce a correct upper bound on the circuit delay, they can fail to recognize event propagation in some instances. This analysis further enables us to derive new and useful PCs. We describe such a PC, called safe static. Experimental results demonstrate that safe static provides an excellent accuracy/efficiency tradeoff.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W2058767802",
    "type": "article"
  },
  {
    "title": "An optimal clock period selection method based on slack minimization criteria",
    "doi": "https://doi.org/10.1145/234860.234864",
    "publication_date": "1996-07-01",
    "publication_year": 1996,
    "authors": "En-Shou Chang; Daniel D. Gajski; Sanjiv M. Narayan",
    "corresponding_authors": "",
    "abstract": "An important decision in synthesizing a hardware implementation from a behavioral description is selecting the clock period to schedule the datapath operations into control steps. Prior to scheduling, most existing behavioral synthesis systems either require the designer to specify the clock period explicitly or require that the delays of the operators used in the design be specified in multiples of the clock period. An unfavorable choice of clock period could result in operations being idle for a large portion of the clock period and, consequently, affect the performance of the synthesized design. In this article, we demonstrate the effect of clock slack on the performance of designs and present an algorithm to find a slack-minimal clock period. We prove the optimality of our method and apply it to several examples to demonstrate its effectiveness in maximizing design performance.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W2067125172",
    "type": "article"
  },
  {
    "title": "Efficient decomposition of polygons into L-shapes with application to VLSI layouts",
    "doi": "https://doi.org/10.1145/234860.234865",
    "publication_date": "1996-07-01",
    "publication_year": 1996,
    "authors": "Mario A. López; Dinesh P. Mehta",
    "corresponding_authors": "",
    "abstract": "We present two practical algorithms for partitioning circuit components represented by rectilinear polygons so that they can be stored using the L-shaped corner stitching data structure; that is, our algorithms decompose a simple polygon into a set of nonoverlapping L-shapes and rectangles by using horizontal cuts only. The more general of our algorithms computes and optimal configuration for a wide variety of optimization functions, whereas the other computes a minimum configuration of rectangles and L-shapes. Both algorithms run in O ( n + h log h time, where n is the number of vertices in the polygon and h is the number of H-pairs. Because for VLSI data h is small, in practice these algorithms are linear in n . Experimental results on actual VLSI data compare our algorithms and demonstrate the gains in performance for corner stitching (as measured by different objective functions) obtained by using them instead of more traditional rectangular partitioning algorithms.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W2082541458",
    "type": "article"
  },
  {
    "title": "Reduction design for generic universal switch blocks",
    "doi": "https://doi.org/10.1145/605440.605443",
    "publication_date": "2002-10-01",
    "publication_year": 2002,
    "authors": "Hongbing Fan; Jiping Liu; Yu‐Liang Wu; C. K. Wong",
    "corresponding_authors": "",
    "abstract": "A k -side switch block with W terminals per side is said to be a universal switch block (( k , W )-USB) if every set of the nets satisfying the routing constraint (i.e., the number of nets on each side is at most W ) is simultaneously routable through the switch block. The (4, W )-USB was originated by designing better switch modules for 2-D FPGAs, such as Xilinx XC4000-type FPGAs, whereas the generic USBs can be applied in multidimensional or some nonconventional 2-D FPGA architectures. The problem we study in this article is to design ( k , W )-USBs with the minimum number of switches for any given pair of ( k , W ). We provide graph models for routing requirements and switch blocks and develop a series of decomposition theorems for routing requirements with the help of a new graph model. The powerful decomposition theory leads to the automatic generation of routing requirements and a detailed routing algorithm, as well as the reduction design method of building large USBs by smaller ones. As a result, we derive a class of well-structured and highly scalable optimum ( k , W )-USBs for k ≤ 6, or even W s, and near-optimum ( k , W )-USBs for k ≥ 7 and odd W s. We also give routing experiments to justify the routing improvement upon the entire chip using the USBs. The results demonstrate the usefulness of USBs.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W2056928920",
    "type": "article"
  },
  {
    "title": "Congestion reduction during placement with provably good approximation bound",
    "doi": "https://doi.org/10.1145/785411.785414",
    "publication_date": "2003-07-01",
    "publication_year": 2003,
    "authors": "Xiaoming Yang; M. Wang; Ryan Kastner; Soheil Ghiasi; Majid Sarrafzadeh",
    "corresponding_authors": "",
    "abstract": "This paper presents a novel method to reduce routing congestion during placement stage. The proposed approach is used as a post-processing step in placement. Congestion reduction is based on local improvement on the existing layout. However, the approach has a global view of the congestion over the entire design. It uses integer linear programming (ILP) to formulate the problem of conflicts between multiple congested regions, and performs local improvement according to the solution of the ILP problem. The approximation algorithm of the formulated ILP problem is studied and good approximation bounds are given and proved. Experiments show that the proposed approach can effectively alleviate the congestion of global routing results. The low computational complexity of the proposed approach indicates its scalability on large designs.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2076306182",
    "type": "article"
  },
  {
    "title": "Behavioral synthesis of field programmable analog array circuits",
    "doi": "https://doi.org/10.1145/605440.605445",
    "publication_date": "2002-10-01",
    "publication_year": 2002,
    "authors": "Haibo Wang; Sarma Vrudhula",
    "corresponding_authors": "",
    "abstract": "This article presents methods to translate a behavioral-level analog description into a Field Programmable Analog Array (FPAA) implementation. The methods consist of several steps that are referred to as function decomposition, macrocell synthesis, placement and routing, and postplacement simulation. The focus of this article is on the first three steps. The function decomposition step deals with decomposing a high-order system function into a set of lower-order functions. We present an efficient procedure for searching for an optimal solution. This procedure is based on first formally demonstrating the equivalence of two previously used optimization criteria. The objective of the macrocell synthesis step is to generate a hardware realization. A modified signal flow graph is introduced to represent FPAA circuits and graph transformations are used to identify the realizations that comply with the FPAA hardware constraints. The modified signal flow graph also allows scaling of capacitor values due to the limited set of allowable values in an FPAA. For the placement and routing step, an efficient method to estimate the circuit performance degradation due to parasitic effects is given. Using performance degradation as the cost function, an algorithm for finding an optimal FPAA placement and routing configuration is given. The efficacy of the methods developed is demonstrated by direct measurements on a set of filters.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2106267865",
    "type": "article"
  },
  {
    "title": "Annealing placement by thermodynamic combinatorial optimization",
    "doi": "https://doi.org/10.1145/1013948.1013951",
    "publication_date": "2004-07-01",
    "publication_year": 2004,
    "authors": "J. De Vicente; Juan Lanchares; R. Hermida",
    "corresponding_authors": "",
    "abstract": "Placement is key issue of integrated circuit physical design. There exist some techniques inspired in thermodynamics coping with this problem as Simulated Annealing. In this article, we present a combinatorial optimization method directly derived from both Thermodynamics and Information Theory. In TCO (Thermodynamic Combinatorial Optimization), two kinds of processes are considered: microstate and macrostate transformations. Applying the Shannon's definition of entropy to reversible microstate transformations, a probability of acceptance based on Fermi--Dirac statistics is derived. On the other hand, applying thermodynamic laws to macrostate transformations, an efficient annealing schedule is provided. TCO has been compared with a custom Simulated Annealing (SA) tool on a set of benchmark circuits for the FPGA (Field Programmable Gate Arrays) placement problem. TCO has provided the high-quality results of SA, while inheriting the adaptive properties of Natural Optimization (NO).",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W1972237171",
    "type": "article"
  },
  {
    "title": "Efficient techniques for transition testing",
    "doi": "https://doi.org/10.1145/1059876.1059880",
    "publication_date": "2005-04-01",
    "publication_year": 2005,
    "authors": "Xiao Liu; Michael S. Hsiao; Sreejit Chakravarty; Paul J. Thadikaran",
    "corresponding_authors": "",
    "abstract": "Scan-based transition tests are added to improve the detection of speed failures in sequential circuits. Empirical data suggests that both data volume and application time will increase dramatically for such transition testing. Techniques to address the above problem for a class of transition tests, called enhanced transition tests, are proposed in this article.The first technique, which combines the proposed transition test chains with the ATE repeat capability, reduces test data volume by 46.5% when compared with transition tests computed by a commercial transition test ATPG tool. However, the test application time may sometimes increase. To address the test time issue, a new DFT technique, Exchange Scan, is proposed. Exchange scan reduces both data volume and application time by 46.5%. These techniques rely on the use of hold-scan cells and highlight the effectiveness of hold-scan design to address test time and test data volume issues. In addition, we address the problem of yield loss due to incidental overtesting of functionally-untestable transition faults, and we formulate an efficient adjustment to the algorithm to keep the overtest ratio low. Our experimental results show that up to 14.5% reduction in overtest ratio can be achieved, with an average overtest reduction of 4.68%.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2062338825",
    "type": "article"
  },
  {
    "title": "ILP models for simultaneous energy and transient power minimization during behavioral synthesis",
    "doi": "https://doi.org/10.1145/1124713.1124725",
    "publication_date": "2006-01-01",
    "publication_year": 2006,
    "authors": "Saraju P. Mohanty; N. Ranganathan; Sunil K. Chappidi",
    "corresponding_authors": "",
    "abstract": "In low-power design for battery-driven portable applications, the reduction of peak power, peak power differential, cycle difference power, average power and energy are equally important. These are different forms of dynamic power dissipation of a CMOS circuit, which is predominant compared to static power dissipation for higher switching activity. The peak power, the cycle difference power, and the peak power differential drive the transient characteristic of a CMOS circuit. In this article, we propose an ILP-based framework for the reduction of energy and transient power through datapath scheduling during behavioral synthesis. A new metric called “modified cycle power function” (CPF*) is defined that captures the above power characteristics and facilitates integer linear programming formulations. The ILP-based datapath scheduling schemes with CPF* as objective function are developed assuming three modes of datapath operation, such as, single supply voltage and single frequency (SVSF), multiple supply voltages and dynamic frequency clocking (MVDFC), and multiple supply voltages and multicycling (MVMC). We conducted experiments on selected high-level synthesis benchmark circuits for various resource constraints and estimated power, energy and energy delay product for each of them. Experimental results show that significant reductions in power, energy and energy delay product can be obtained.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W1975621740",
    "type": "article"
  },
  {
    "title": "Reuse analysis of indirectly indexed arrays",
    "doi": "https://doi.org/10.1145/1142155.1142157",
    "publication_date": "2006-04-01",
    "publication_year": 2006,
    "authors": "Javed Absar; Francky Catthoor",
    "corresponding_authors": "",
    "abstract": "We propose techniques for identifying and exploiting spatial and temporal reuse for indirectly indexed arrays. Indirectly indexed arrays are those arrays which are, typically, accessed inside multilevel loop nests and whose index expression includes not only loop iterators and constants but arrays as well. Existing techniques for improving locality are quite sophisticated in the case of directly indexed arrays. But, unfortunately, they are inadequate for handling indirectly indexed arrays. In this article we therefore extend the existing framework and techniques of directly indexed to indirectly indexed arrays. The concepts of reuse subspace, dependence vector, self, and group reuse are extended and applied in this new context. Also, lately scratch-pad memory has become an attractive alternative to data-cache, specially in the embedded multimedia community. This is because embedded systems are very sensitive to area and energy and the scratch-pad is smaller in area and consumes less energy on a per access basis compared to the cache of the same capacity. Several techniques have been proposed in the past for the efficient exploitation of the scratch-pad for directly indexed arrays. We extend these techniques by presenting a method for scratch-pad mapping of indirectly indexed arrays. This enables the scratch-pad to be used in a larger context than was possible before.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2022728437",
    "type": "article"
  },
  {
    "title": "EWD",
    "doi": "https://doi.org/10.1145/1255456.1255470",
    "publication_date": "2007-08-17",
    "publication_year": 2007,
    "authors": "Deepak A. Mathaikutty; Hiren Patel; Sandeep K. Shukla; Axel Jantsch",
    "corresponding_authors": "",
    "abstract": "We present the EWD design environment and methodology, a modeling and simulation framework suited for complex and heterogeneous embedded systems with varying degrees of expressibility and modeling fidelity. This environment promotes the use of multiple models of computation (MoCs) to support heterogeneity and metamodeling for conformance tests of syntactic and static semantics during the process of modeling. Therefore, EWD is a multiple MoC modeling and simulation framework that ensures conformance of the MoC formalisms during model construction using a metamodeling approach. In addition, EWD provides a suite of translation tools that generate executable models for two simulation frameworks to demonstrate its language-independent modeling framework. The EWD methodology uses the Generic Modeling Environment for customization of the MoC-specific modeling syntax into a visual representation. To embed the execution semantics of the MoCs into the models, we have built parsing and translation tools that leverage an XML-based interoperability language. This interoperability language is then translated into executable Standard ML or Haskell models that can also be analyzed by existing simulation frameworks such as SML-Sys or ForSyDe. In summary, EWD is a metamodeling driven multitarget design environment with multi-MoC modeling capability.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2010547624",
    "type": "article"
  },
  {
    "title": "A model-based extensible framework for efficient application design using FPGA",
    "doi": "https://doi.org/10.1145/1230800.1230805",
    "publication_date": "2007-04-01",
    "publication_year": 2007,
    "authors": "Sumit Mohanty; Viktor K. Prasanna",
    "corresponding_authors": "",
    "abstract": "For an FPGA designer, several choices are available in terms of target FPGA devices, IP-cores, algorithms, synthesis options, runtime reconfiguration, degrees of parallelism, among others, while implementing a design. Evaluation of design alternatives in the early stages of the design cycle is important because the choices made can have a critical impact on the performance of the final design. However, a large number of alternatives not only results in a large number of designs, but also makes it a hard problem to efficiently manage, simulate, and evaluate them. In this article, we present a framework for FPGA-based application design that addresses the aforementioned issues. This framework supports a hierarchical modeling approach that integrates application and device modeling techniques and allows development of a library of models for design reuse. The framework integrates a high-level performance estimator for rapid estimation of the latency, area, and energy of the designs. In addition, a design space exploration tool allows efficient evaluation of candidate designs against the given performance requirements. The framework also supports extension through integration of widely used tools for FPGA-based design while presenting a unified environment for different target FPGAs. We demonstrate our framework through the modeling and performance estimation of a signal processing kernel and the design of end-to-end applications.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2151468157",
    "type": "article"
  },
  {
    "title": "Heterogeneously tagged caches for low-power embedded systems with virtual memory support",
    "doi": "https://doi.org/10.1145/1344418.1344428",
    "publication_date": "2008-04-02",
    "publication_year": 2008,
    "authors": "Xiangrong Zhou; П. П. Петров",
    "corresponding_authors": "",
    "abstract": "An energy-efficient data cache organization for embedded processors with virtual memory is proposed. Application knowledge regarding memory references is used to eliminate most tag translations. A novel tagging scheme is introduced, where both virtual and physical tags coexist. Physical tags and special handling of superset index bits are only used for references to shared regions in order to avoid cache inconsistency. By eliminating the need for most address translations on cache access, a significant power reduction is achieved. We outline an efficient hardware architecture, where the application information is captured in a reprogrammable way and the cache is minimally modified.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W1995350263",
    "type": "article"
  },
  {
    "title": "Partitioning parameterized 45-degree polygons with constraint programming",
    "doi": "https://doi.org/10.1145/1367045.1367061",
    "publication_date": "2008-07-01",
    "publication_year": 2008,
    "authors": "I-Lun Tseng; Adam Postuła",
    "corresponding_authors": "",
    "abstract": "An algorithm for partitioning parameterized 45-degree polygons into parameterized trapezoids is proposed in this article. The algorithm is based on the plane-sweep technique and can handle polygons with complicated constraints. The input to the algorithm consists of the contour of a parameterized polygon to be partitioned and a set of constraints for parameters of the contour. The algorithm uses horizontal cuts only and generates a number of nonoverlapping trapezoids whose union is the original parameterized polygon. Processing of constraints and coordinates that contain first-order multiple-variable polynomials has been made possible by incorporating the JaCoP constraint programming library. The proposed algorithm has been implemented in Java programming language and can be used as the basis to build the trapezoidal corner stitching data structure for parameterized VLSI layout masks.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2002679314",
    "type": "article"
  },
  {
    "title": "Constraint-driven floorplan repair",
    "doi": "https://doi.org/10.1145/1391962.1391975",
    "publication_date": "2008-09-01",
    "publication_year": 2008,
    "authors": "Michael D. Moffitt; Jarrod A. Roy; Igor L. Markov; Martha E. Pollack",
    "corresponding_authors": "",
    "abstract": "In this work, we propose a new and efficient approach to the floorplan repair problem, where violated design constraints are satisfied by applying small changes to an existing rough floorplan. Such a floorplan can be produced by a human designer, a scalable placement algorithm, or result from engineering adjustments to an existing floorplan. In such cases, overlapping modules must be separated, and others may need to be repositioned to satisfy additional requirements. Our algorithmic framework uses an expressive graph-based encoding of constraints which can reflect fixed-outline, region, proximity and alignment constraints. By tracking the implications of existing constraints, we resolve violations by imposing gradual modifications to the floorplan, in an attempt to preserve the characteristics of its initial design. Empirically, our approach is effective at removing overlaps and repairing violations that may occur when design constraints are acquired and imposed dynamically.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2045766544",
    "type": "article"
  },
  {
    "title": "Disjunctive image computation for software verification",
    "doi": "https://doi.org/10.1145/1230800.1230802",
    "publication_date": "2007-04-01",
    "publication_year": 2007,
    "authors": "Chao Wang; Zijiang Yang; Franjo Ivančić; Aarti Gupta",
    "corresponding_authors": "",
    "abstract": "Existing BDD-based symbolic algorithms designed for hardware designs do not perform well on software programs. We propose novel techniques based on unique characteristics of software programs. Our algorithm divides an image computation step into a disjunctive set of easier ones that can be performed in isolation. We use hypergraph partitioning to minimize the number of live variables in each disjunctive component, and variable scopes to simplify transition relations and reachable state subsets. Our experiments on nontrivial C programs show that BDD-based symbolic algorithms can directly handle software models with a much larger number of state variables than for hardware designs.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2046315901",
    "type": "article"
  },
  {
    "title": "Automatic verification of safety and liveness for pipelined machines using WEB refinement",
    "doi": "https://doi.org/10.1145/1367045.1367054",
    "publication_date": "2008-07-01",
    "publication_year": 2008,
    "authors": "Panagiotis Manolios; Sudarshan K. Srinivasan",
    "corresponding_authors": "",
    "abstract": "We show how to automatically verify that complex pipelined machine models satisfy the same safety and liveness properties as their instruction-set architecture (ISA) models by using well-founded equivalence bisimulation (WEB) refinement. We show how to reduce WEB-refinement proof obligations to formulas expressible in the decidable logic of counter arithmetic with lambda expressions and uninterpreted functions (CLU). This allows us to automate the verification of the pipelined machine models by using the UCLID decision procedure to transform CLU formulas to Boolean satisfiability problems. To relate pipelined machine states to ISA states, we use the commitment and flushing refinement maps. We evaluate our work using 17 pipelined machine models that contain various features, including deep pipelines, precise exceptions, branch prediction, interrupts, and instruction queues. Our experimental results show that the overhead of proving liveness, obtained by comparing the cost of proving both safety and liveness with the cost of only proving safety, is about 17%, but depends on the refinement map used; for example, the liveness overhead is 23% when flushing is used and is negligible when commitment is used.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2141772875",
    "type": "article"
  },
  {
    "title": "Power-delay optimization in VLSI microprocessors by wire spacing",
    "doi": "https://doi.org/10.1145/1562514.1562523",
    "publication_date": "2009-08-01",
    "publication_year": 2009,
    "authors": "Konstantin Moiseev; Avinoam Kolodny; Shmuel Wimer",
    "corresponding_authors": "",
    "abstract": "The problem of optimal space allocation among interconnect wires in a VLSI layout, in order to minimize the switching power consumption and the average signal delay, is addressed in this article. We define a Weighted Power-Delay Sum (WPDS) objective function and derive necessary and sufficient conditions for the existence of optimal interwire space allocation, based on the notion of capacitance density. At the optimum, every wire must be in equilibrium of its line-to-line weighted capacitance density on its two opposite sides, and the WPDS of the whole circuit is minimal if and only if capacitance density is uniformly distributed across the entire layout. This condition is shown to be equivalent to all paths of the layout cross-capacitance graph having the same length and all cuts having the same flow. An implementation which has been used in the design of a recent commercial high-end microprocessor and yielded 17% power reduction and 9% delay reduction in top-level interconnects is presented.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W1982206121",
    "type": "article"
  },
  {
    "title": "Circuit optimization techniques to mitigate the effects of soft errors in combinational logic",
    "doi": "https://doi.org/10.1145/1640457.1640462",
    "publication_date": "2009-12-01",
    "publication_year": 2009,
    "authors": "Rajeev R. Rao; Vivek Joshi; David Blaauw; Dennis Sylvester",
    "corresponding_authors": "",
    "abstract": "Soft errors in combinational logic circuits are emerging as a significant reliability problem for VLSI designs. Technology scaling trends indicate that the soft error rates (SER) of logic circuits will be dominant factor for future technology generations. SER mitigation in logic can be accomplished by optimizing either the gates inside a logic block or the flipflops present on the block boundaries. We present novel circuit optimization techniques that target these elements separately as well as in unison to reduce the SER of combinational logic circuits. First, we describe the construction of a new class of flip-flop variants that leverage the effect of temporal masking by selectively increasing the length of the latching window thereby preventing faulty transients from being registered. In contrast to previous flip-flop designs that rely on logic duplication and complicated circuit design styles, the new variants are redesigned from the library flip-flop using efficient transistor sizing. We then propose a flip-flop selection method that uses slack information at each primary output node to determine the flip-flop configuration that produces maximum SER savings. Next, we propose a gate sizing algorithm that trades off SER reduction and area overhead. This approach first computes bounds on the maximum achievable SER reduction by resizing a gate. This bound is then used to prune the circuit graph, arriving at a smaller set of candidate gates on which we perform incremental sensitivity computations to determine the gates that are the largest contributors to circuit SER. Third, we propose a unified, co-optimization approach combining flip-flop selection with the gate sizing algorithm. The joint optimization algorithm produces larger SER reductions while incurring smaller circuit overhead than either technique taken in isolation. Experimental results on a variety of benchmarks show average SER reductions of 10.7X with gate sizing, 5.7X with flip-flop assignment, and 30.1X for the combined optimization approach, with no delay penalties and area overheads within 5-6%. The runtimes for the optimization algorithms are on the order of 1-3 minutes.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W1999018339",
    "type": "article"
  },
  {
    "title": "Speeding-up heuristic allocation, scheduling and binding with SAT-based abstraction/refinement techniques",
    "doi": "https://doi.org/10.1145/1698759.1698762",
    "publication_date": "2010-02-01",
    "publication_year": 2010,
    "authors": "Gianpiero Cabodi; Luciano Lavagno; Marco Murciano; A. Kondratyev; Yosinori Watanabe",
    "corresponding_authors": "",
    "abstract": "Hardware synthesis is the process by which system-level, Register Transfer (RT)-level, or behavioral descriptions can be turned into real implementations, in terms of logic gates. Scheduling is one of the most time-consuming steps in the overall design flow, and may become much more complex when performing hardware synthesis from high-level specifications. Exploiting a single scheduling strategy on very large designs is often reductive and potentially inadequate. Furthermore, finding the “best” single candidate among all possible scheduling algorithms is practically infeasible. In this article we introduce a hybrid scheduling approach that is a preliminary step towards a comprehensive solution not yet provided by industrial or by academic solutions. Our method relies on an abstract symbolic representation of data flow nodes (operations) bound to control flow paths: it produces a more realistic lower bound during the prescheduling resource estimation step and speeds up slower but accurate heuristic scheduling techniques, thus achieving a globally improved result.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2051172096",
    "type": "article"
  },
  {
    "title": "Behavior-Level Observability Analysis for Operation Gating in Low-Power Behavioral Synthesis",
    "doi": "https://doi.org/10.1145/1870109.1870113",
    "publication_date": "2010-11-01",
    "publication_year": 2010,
    "authors": "Jason Cong; Bin Liu; Rupak Majumdar; Zhiru Zhang",
    "corresponding_authors": "",
    "abstract": "Many techniques for power reduction in advanced RTL synthesis tools rely explicitly or implicitly on observability don’t-care conditions. In this article we propose a systematic approach to maximize the effectiveness of these techniques by generating power-friendly RTL descriptions in behavioral synthesis. This is done using operation gating , that is, explicitly adding a predicate to an operation based on its observability condition, so that the operation, once identified as unobservable at runtime, can be avoided using RTL power optimization techniques such as clock gating. We first introduce the concept of behavior-level observability and its approximations in the context of behavioral synthesis. We then propose an efficient procedure to compute an approximated behavior-level observability of every operation in a dataflow graph. Unlike previous techniques which work at the bit level in Boolean networks, our method is able to perform analysis at the word level, and thus avoids most computation effort with a reasonable approximation. Our algorithm exploits the observability-masking nature of some Boolean operations, as well as the select operation, and allows certain forms of other knowledge to be considered for stronger observability conditions. The approximation is proved exact for (acyclic) dataflow graphs when non-Boolean operations other than select are treated as black boxes. The behavior-level observability condition obtained by our analysis can be used to guide the operation scheduler to optimize the efficiency of operation gating. In a set of experiments on real-world designs, our method achieves an average of 33.9% reduction in total power; it outperforms a previous method by 17.1% on average and gives close-to-optimal solutions on several designs. To the best of our knowledge, this is the first time behavior-level observability analysis and optimization are performed during behavioral synthesis in a systematic manner. We believe that our idea can be applied to compiler transformations in general.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2054368274",
    "type": "article"
  },
  {
    "title": "Complexity of 3-D floorplans by analysis of graph cuboidal dual hardness",
    "doi": "https://doi.org/10.1145/1835420.1835426",
    "publication_date": "2010-09-01",
    "publication_year": 2010,
    "authors": "Renshen Wang; Evangeline F. Y. Young; Chung‐Kuan Cheng",
    "corresponding_authors": "",
    "abstract": "Interconnect dominated electronic design stimulates a demand for developing circuits on the third dimension, leading to 3-D integration. Recent advances in chip fabrication technology enable 3-D circuit manufacturing. However, there is still a possible barrier of design complexity in exploiting 3-D technologies. This article discusses the impact of migrating from 2-D to 3-D on the difficulty of floorplanning and placement. By looking at a basic formulation of the graph cuboidal dual problem, we show that the 3-D cases and the 3-layer 2.5-D cases are fundamentally more difficult than the 2-D cases in terms of computational complexity. By comparison among these cases, the intrinsic complexity in 3-D floorplan structures is revealed in the hard-to-decide relations between topological connections and geometrical contacts. The results show possible challenges in the future for physical design and CAD of 3-D integrated circuits.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2066278595",
    "type": "article"
  },
  {
    "title": "Hardware-Software Codesign of an Embedded Multiple-Supply Power Management Unit for Multicore SoCs Using an Adaptive Global/Local Power Allocation and Processing Scheme",
    "doi": "https://doi.org/10.1145/1970353.1970364",
    "publication_date": "2011-06-01",
    "publication_year": 2011,
    "authors": "Rajdeep Bondade; Dongsheng Ma",
    "corresponding_authors": "",
    "abstract": "Power dissipation has become a critical design constraint for the growth of modern multicore systems due to increasing clock frequencies, leakage currents, and system parasitics. To overcome this urgent crisis, this article presents an embedded platform for on-chip power management of a multicore System-on-Chip (SoC). The design involves the development of two key components, from the hardware to the software level. From the hardware perspective, a multiple-supply power management unit is proposed and is implemented using a Single-Inductor Multiple-Output (SIMO) DC-DC converter. To dynamically respond to the sensed instantaneous power demands and to accurately control the power delivery to the processor cores, the power management unit employs a software-defined adaptive global/local power allocation feedback controller. The proposed controller is designed using the hardware-software codesign methodology to uniquely control the SIMO converter during various operation scenarios. This is achieved using several embedded software control algorithms that operate synergetically to ensure efficient and reliable system operation. The hardware-software codesign technique also allows the SIMO controller to be integrated with future microprocessor cores. Therefore, by employing the vast amount of on-chip resources, the converter can perform effective power processing to provide the most power-optimal voltages at the hardware level. Such an embedded power management module leads to an integrated, power-aware, and autonomous SoC design that is independent of additional external hardware control, thereby reducing on-chip area and system complexity. In this design, each power output from the SIMO converter provides a step-up/down voltage conversion, thereby enabling a wide range of variable supply voltage. An adaptive global/local power allocation control algorithm is employed to significantly improve Dynamic Voltage and Frequency Scaling (DVFS) tracking speed and line/load regulation, while still retaining low cross-regulation. Designed with a 180nm CMOS process, the converter precisely provides three independently variable power outputs from 0.9 V to 3.0 V, with a total power range from 33 mW to 900 mW. A very fast load transient response of 3.25 μ s is achieved, in response to a 67.5-mA full-step load current change. The design thus provides a cost-effective power management solution to achieve a robust, fast-transient, DVFS-compatible multicore SoC.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2050695540",
    "type": "article"
  },
  {
    "title": "Chassis",
    "doi": "https://doi.org/10.1145/1970353.1970367",
    "publication_date": "2011-06-01",
    "publication_year": 2011,
    "authors": "Antara Ain; Debjit Pal; Pallab Dasgupta; Siddhartha Mukhopadhyay; Rajdeep Mukhopadhyay; John Gough",
    "corresponding_authors": "",
    "abstract": "Power Management Units (PMUs) are large integrated circuits consisting of many predesigned mixed-signal components. PMU integration poses a serious verification problem considering the size of the integrated circuit and the complexity of analog simulation. In this article we present an approach for automatic generation of behavioral models for PMU components from top-down skeleton models, fitted with parameter values estimated by bottom-up parameter extraction algorithms. It is shown that replacing PMU components with these autogenerated hybrid automata-based abstract behavioral models enables significant simulation speedup (&gt; 20X on our industrial test cases) and helps in early detection of integration errors. The article also justifies the level of accuracy in our models with respect to the goal of verifying integrated PMUs. The approach presented in this work is implemented in the form of a tool suite called Chassis.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2070939580",
    "type": "article"
  },
  {
    "title": "Load-balanced clock tree synthesis with adjustable delay buffer insertion for clock skew reduction in multiple dynamic supply voltage designs",
    "doi": "https://doi.org/10.1145/2209291.2209307",
    "publication_date": "2012-06-01",
    "publication_year": 2012,
    "authors": "Kuan‐Yu Lin; Hong-Ting Lin; Tsung-Yi Ho; Chia‐Chun Tsai",
    "corresponding_authors": "",
    "abstract": "Power consumption is known to be a crucial issue in current IC designs. To tackle this problem, Multiple Dynamic Supply Voltage (MDSV) designs are proposed as an efficient solution for power savings. However, the increasing variability of clock skew during the switching of power modes leads to an increase in the complication of clock skew reduction in MDSV designs. In this article, we propose a load-balanced clock tree synthesizer with Adjustable Delay Buffer (ADB) insertion for clock skew reduction in MDSV designs. The clock tree synthesizer adopts the Minimum Spanning Tree (MST) metric to estimate the interconnect capacitance and execute the graph-theoretic clustering. The power-mode-guided optimization is also embedded into the clock tree synthesizer for improving additional area overhead in the step of ADB insertion. After constructing the initial buffered clock tree, we insert the ADBs with delay value assignments to reduce clock skew in MDSV designs. The ADBs can be used to produce additional delays, hence the clock latencies and skew become tunable in a clock tree. An efficient algorithm of ADB insertion for the minimization of clock skew, area, and runtime in MDSV designs has been presented. Comparing with the state-of-the-art algorithm of ADB insertion, experimental results show maximum 42.40% area overhead improvement. With the power-mode-guided optimization, the maximum improvement of area overhead can increase to 47.87%.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2094278783",
    "type": "article"
  },
  {
    "title": "Performance bound analysis of analog circuits in frequency- and time-domain considering process variations",
    "doi": "https://doi.org/10.1145/2534395",
    "publication_date": "2013-12-01",
    "publication_year": 2013,
    "authors": "Xuexin Liu; Sheldon X.-D. Tan; A. A. Palma-Rodriguez; Esteban Tlelo‐Cuautle; Guoyong Shi",
    "corresponding_authors": "",
    "abstract": "In this article, we propose a new performance bound analysis of analog circuits considering process variations. We model the variations of component values as intervals measured from tested chips and manufacture processes. The new method first applies a graph-based analysis approach to generate the symbolic transfer function of a linear(ized) analog circuit. Then the frequency response bounds (maximum and minimum) are obtained by performing nonlinear constrained optimization in which magnitude or phase of the transfer function is the objective function to be optimized subject to the ranges of process variational parameters. The response bounds given by the optimization-based method are very accurate and do not have the over-conservativeness issues of existing methods. Based on the frequency-domain bounds, we further develop a method to calculate the time-domain response bounds for any arbitrary input stimulus. Experimental results from several analog benchmark circuits show that the proposed method gives the correct bounds verified by Monte Carlo analysis while it delivers one order of magnitude speedup over Monte Carlo for both frequency-domain and time-domain bound analyses. We also show analog circuit yield analysis as an application of the frequency-domain variational bound analysis.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2096728620",
    "type": "article"
  },
  {
    "title": "Discrete sizing for leakage power optimization in physical design",
    "doi": "https://doi.org/10.1145/2390191.2390206",
    "publication_date": "2013-01-01",
    "publication_year": 2013,
    "authors": "Santiago Mok; J. Jack Lee; Puneet Gupta",
    "corresponding_authors": "",
    "abstract": "While sizing has been studied for over three decades, the absence of a common framework with which to compare methods has made progress difficult to measure. In this article, we compare popular sizing techniques in which gates are chosen from a discrete standard cell library and slew and interconnect effects are accounted for. The difference between sizing methods reduces from roughly 53% to 8% between best and worst case after slew propagation is taken into account. In our benchmarks, no one sizing technique consistently outperforms the others.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2098409615",
    "type": "article"
  },
  {
    "title": "Multiharmonic Small-Signal Modeling of Low-Power PWM DC-DC Converters",
    "doi": "https://doi.org/10.1145/3057274",
    "publication_date": "2017-06-09",
    "publication_year": 2017,
    "authors": "Ya Wang; Di Gao; Dani Tannir; Ning Dong; Fang Guang-hui; Wei Dong; Peng Li",
    "corresponding_authors": "",
    "abstract": "Small-signal models of pulse-width modulation (PWM) converters are widely used for analyzing stability and play an important role in converter design and control. However, existing small-signal models either are based on averaged DC behaviors, and hence are unable to capture frequency responses that are faster than the switching frequency, or greatly approximate these high-frequency responses. We address the severe limitations of the existing models by proposing a multiharmonic model that provides a complete small-signal characterization of both DC averages and high-order harmonic responses. The proposed model captures important high-frequency overshoots and undershoots of the converter response, which are otherwise unaccounted for by the existing techniques. In two converter examples, the proposed model corrects the misleading results of the existing models by providing truthful characterization of the overall converter AC response and offers important guidance for converter design and closed-loop control.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2623731417",
    "type": "article"
  },
  {
    "title": "DYNASCORE",
    "doi": "https://doi.org/10.1145/3110222",
    "publication_date": "2017-10-05",
    "publication_year": 2017,
    "authors": "Angeliki Kritikakou; Thibaut Marty; Matthieu Roy",
    "corresponding_authors": "",
    "abstract": "In real-time mixed-critical systems, Worst-Case Execution Time (WCET) analysis is required to guarantee that timing constraints are respected—at least for high-criticality tasks. However, the WCET is pessimistic compared to the real execution time, especially for multicore platforms. As WCET computation considers the worst-case scenario, it means that whenever a high-criticality task accesses a shared resource in multicore platforms, it is considered that all cores use the same resource concurrently. This pessimism in WCET computation leads to a dramatic underutilization of the platform resources, or even failing to meet the timing constraints. In order to increase resource utilization while guaranteeing real-time guarantees for high-criticality tasks, previous works proposed a runtime control system to monitor and decide when the interferences from low-criticality tasks cannot be further tolerated. However, in the initial approaches, the points where the controller is executed were statically predefined. In this work, we propose a dynamic runtime control which adapts its observations to online temporal properties, further increasing the dynamism of the approach, and mitigating the unnecessary overhead implied by existing static approaches. Our dynamic adaptive approach allows one to control the ongoing execution of tasks based on runtime information, and further increases the gains in terms of resource utilization compared with static approaches.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2761068414",
    "type": "article"
  },
  {
    "title": "Revisiting Routability-Driven Placement for Analog and Mixed-Signal Circuits",
    "doi": "https://doi.org/10.1145/3131849",
    "publication_date": "2017-10-05",
    "publication_year": 2017,
    "authors": "Hongxia Zhou; Chiu‐Wing Sham; Hailong Yao",
    "corresponding_authors": "",
    "abstract": "The exponential increase in scale and complexity of very large-scale integrated circuits (VLSIs) poses a great challenge to current electronic design automation (EDA) techniques. As an essential step in the whole EDA layout synthesis, placement is attracting more and more attention, especially for analog and mixed-signal integrated circuits. Recently, experts in this field have observed a variety of analog-specific layout constraints to obtain high-performance placement solutions. These constraints include symmetry, alignment, boundary, preplace, abutment, range and maximum separation, and routability of the placement solutions. In this article, the effectiveness of slicing and nonslicing representation is investigated. Additionally, the technique of congestion-based virtual sizing is proposed. Experimental results show that the routability can be improved significantly by applying congestion-based virtual sizing. Results also show that the slicing representation can improve the regularity of the placement solutions and hence improve the routability with higher efficiency compared to the nonslicing representation.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2763688168",
    "type": "article"
  },
  {
    "title": "SHAIP",
    "doi": "https://doi.org/10.1145/3274669",
    "publication_date": "2018-11-30",
    "publication_year": 2018,
    "authors": "Siam U. Hussain; M. Sadegh Riazi; Farinaz Koushanfar",
    "corresponding_authors": "",
    "abstract": "In this article, we present SHAIP, a secure Hamming distance–based mutual authentication protocol. It allows an unlimited number of authentications by employing an intrinsic Physical Unclonable Function (PUF). PUFs are being increasingly employed for remote authentication of devices. Most of these devices have limited resources. Therefore, the intrinsic PUFs are most suitable for this task as they can be built with little or no modification to the underlying hardware platform. One major drawback of the current authentication schemes is that they expose the PUF response. This makes the intrinsic PUFs, which have a limited number of challenge-response pairs, unusable after a certain number of authentication sessions. Moreover, these schemes are one way in the sense that they only allow one party, the prover, to authenticate herself to the verifier. We propose a symmetric mutual authentication scheme based on secure (privacy-preserving) computation of the Hamming distance between the PUF response from the remote device and reference response stored at the verifier end. This allows both parties to authenticate each other without revealing their respective sets of inputs. We show that our scheme is effective with all state-of-the-art intrinsic PUFs. The proposed scheme is lightweight and does not require any modification to the underlying hardware.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2904804748",
    "type": "article"
  },
  {
    "title": "Guiding Formal Verification Orchestration Using Machine Learning Methods",
    "doi": "https://doi.org/10.1145/3224206",
    "publication_date": "2018-08-22",
    "publication_year": 2018,
    "authors": "Eman M. Elmandouh; Amr G. Wassal",
    "corresponding_authors": "",
    "abstract": "Typical modern HW designs include many blocks associated with thousands of design properties. Having today's commercial formal verifiers utilize a complementary set of state-of-art formal algorithms is a key in enabling the formal verification tools to successfully cope with verification problems of different sizes, types, and complexities. Formal engines orchestration is the methodology used to pick the most appropriate formal engine for a specific verification problem. It assures proper scheduling of the formal engines to minimize the time consumed to solve individual design verification problems, hence highly impacts the time required to verify the overall design properties. This work proposes the utilization of supervised machine learning classification techniques to guide the orchestration step by predicting the formal engines that should be assigned to a design property. Up to 16,500 formal verification runs on RTL designs and their properties are used to train the classifier to create a prediction model. The classifier assigns any new verification problem to an appropriate list of formal engines associated with a probability distribution over the set of engines classes. Our results indicate how the proposed model is able to improve the formal suite total run-time by up to 59% of its maximum allowable time improvement using multi-classification-based orchestration and to nominate with 88% accuracy the appropriate formal engines for new-to-verify HW designs.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2997434955",
    "type": "article"
  },
  {
    "title": "How Secure Is Split Manufacturing in Preventing Hardware Trojan?",
    "doi": "https://doi.org/10.1145/3378163",
    "publication_date": "2020-03-02",
    "publication_year": 2020,
    "authors": "Yajun Yang; Zhang Chen; Yuan Liu; Tsung-Yi Ho; Yier Jin; Pingqiang Zhou",
    "corresponding_authors": "",
    "abstract": "With the trend of outsourcing fabrication, split manufacturing is regarded as a promising way to both acquire the high-end nodes in untrusted external foundries and protect the design from potential attackers. However, in this article, we show that split manufacturing is not inherently secure, that a hardware Trojan attacker can still recover necessary information with a proximity-based or a simulated-annealing-based mapping approach together with a probability-based or net-based pruning method at the placement level. We further propose a defense approach by moving the insecure gates away from their easily attacked candidate locations. Results on benchmark circuits show the effectiveness of our proposed methods.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W3010910933",
    "type": "article"
  },
  {
    "title": "Multi-Fidelity Surrogate-Based Optimization for Electromagnetic Simulation Acceleration",
    "doi": "https://doi.org/10.1145/3398268",
    "publication_date": "2020-07-07",
    "publication_year": 2020,
    "authors": "Yi Wang; Paul D. Franzon; David Smart; Brian Swahn",
    "corresponding_authors": "",
    "abstract": "As circuits’ speed and frequency increase, fast and accurate capture of the details of the parasitics in metal structures, such as inductors and clock trees, becomes more critical. However, conducting high-fidelity 3D electromagnetic (EM) simulations within the design loop is very time consuming and computationally expensive. To address this issue, we propose a surrogate-based optimization methodology flow, namely multi-fidelity surrogate-based optimization with candidate search (MFSBO-CS), which integrates the concept of multi-fidelity to reduce the full-wave EM simulation cost in analog/RF simulation-based optimization problems. To do so, a statistical co-kriging model is adapted as the surrogate to model the response surface, and a parallelizable perturbation-based adaptive sampling method is used to find the optima. Within the proposed method, low-fidelity fast RC parasitic extraction tools and high-fidelity full-wave EM solvers are used together to model the target design and then guide the proposed adaptive sample method to achieve the final optimal design parameters. The sampling method in this work not only delivers additional coverage of design space but also helps increase the accuracy of the surrogate model efficiently by updating multiple samples within one iteration. Moreover, a novel modeling technique is developed to further improve the multi-fidelity surrogate model at an acceptable additional computation cost. The effectiveness of the proposed technique is validated by mathematical proofs and numerical test function demonstration. In this article, MFSBO-CS has been applied to two design cases, and the result shows that the proposed methodology offers a cost-efficient solution for analog/RF design problems involving EM simulation. For the two design cases, MFSBO-CS either reaches comparably or outperforms the optimization result from various Bayesian optimization methods with only approximately one- to two-thirds of the computation cost.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W3040947815",
    "type": "article"
  },
  {
    "title": "Towards Smarter Diagnosis",
    "doi": "https://doi.org/10.1145/3398267",
    "publication_date": "2020-07-07",
    "publication_year": 2020,
    "authors": "Qicheng Huang; Chenlei Fang; Soumya Mittal; R.D. Blanton",
    "corresponding_authors": "",
    "abstract": "Given the inherent perturbations during the fabrication process of integrated circuits that lead to yield loss, diagnosis of failing chips is a mitigating method employed during both yield ramping and high-volume manufacturing for yield learning. However, various uncertainties in the fabrication process bring a number of challenges, resulting in diagnosis with undesirable outcomes or low efficiency, including, for example, diagnosis failure, bad resolution, and extremely long runtime. It would therefore be very beneficial to have a comprehensive preview of diagnostic outcomes beforehand, which allows fail logs to be prioritized in a more reasonable way for smarter allocation of diagnosis resources. In this work, we propose a learning-based previewer, which is able to predict five aspects of diagnostic outcomes for a failing IC, including diagnosis success, defect count, failure type, resolution, and runtime magnitude. The previewer consists of three classification models and one regression model, where Random Forest classification and regression are used. Experiments on a 28 nm test chip and a high-volume 90 nm part demonstrate that the predictors can provide accurate prediction results, and in a virtual application scenario the overall previewer can bring up to 9× speed-up for the test chip and 6× for the high-volume part.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W3042191246",
    "type": "article"
  },
  {
    "title": "Machine Learning Approaches for Efficient Design Space Exploration of Application-Specific NoCs",
    "doi": "https://doi.org/10.1145/3403584",
    "publication_date": "2020-08-28",
    "publication_year": 2020,
    "authors": "Yong Hu; Marcel Mettler; Daniel Mueller-Gritschneder; Thomas Wild; Andreas Herkersdorf; Ulf Schlichtmann",
    "corresponding_authors": "",
    "abstract": "In many Multi-Processor Systems-on-Chip (MPSoCs), traffic between cores is unbalanced. This motivates the use of an application-specific Network-on-Chip (NoC) that is customized and can provide a high performance at low cost in terms of power and area. However, finding an optimized application-specific NoC architecture is a challenging task due to the huge design space. This article proposes to apply machine learning approaches for this task. Using graph rewriting, the NoC Design Space Exploration (DSE) is modelled as a Markov Decision Process (MDP). Monte Carlo Tree Search (MCTS), a technique from reinforcement learning, is used as search heuristic. Our experimental results show that—with the same cost function and exploration budget—MCTS finds superior NoC architectures compared to Simulated Annealing (SA) and a Genetic Algorithm (GA). However, the NoC DSE process suffers from the high computation time due to expensive cycle-accurate SystemC simulations for latency estimation. This article therefore additionally proposes to replace latency simulation by fast latency estimation using a Recurrent Neural Network (RNN). The designed RNN is sufficiently general for latency estimation on arbitrary NoC architectures. Our experiments show that compared to SystemC simulation, the RNN-based latency estimation offers a similar speed-up as the widely used Queuing Theory (QT). Yet, in terms of estimation accuracy and fidelity, the RNN is superior to QT, especially for high-traffic scenarios. When replacing SystemC simulations with the RNN estimation, the obtained solution quality decreases only slightly, whereas it suffers significantly when QT is used.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W3081587429",
    "type": "article"
  },
  {
    "title": "Ising-FPGA",
    "doi": "https://doi.org/10.1145/3411511",
    "publication_date": "2020-09-01",
    "publication_year": 2020,
    "authors": "Ankit Mondal; Ankur Srivastava",
    "corresponding_authors": "",
    "abstract": "The Ising model has been explored as a framework for modeling NP-hard problems, with several diverse systems proposed to solve it. The Magnetic Tunnel Junction– (MTJ) based Magnetic RAM is capable of replacing CMOS in memory chips. In this article, we propose the use of MTJs for representing the units of an Ising model and leveraging its intrinsic physics for finding the ground state of the system through annealing. We design the structure of a basic MTJ-based Ising cell capable of performing the functions essential to an Ising solver. The hardware overhead of the Ising model is analyzed, and a technique to use the basic Ising cell for scaling to large problems is described. We then go on to propose Ising-FPGA, a parallel and reconfigurable architecture that can be used to map a large class of NP-hard problems, and show how a standard Place and Route tool can be utilized to program the Ising-FPGA. The effects of this hardware platform on our proposed design are characterized and methods to overcome these effects are prescribed. We discuss how three representative NP-hard problems can be mapped to the Ising model. Further, we suggest ways to simplify these problems to reduce the use of hardware and analyze the impact of these simplifications on the quality of solutions. Simulation results show the effectiveness of MTJs as Ising units by producing solutions close/comparable to the optimum and demonstrate that our design methodology holds the capability to account for the effects of the hardware.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W3082584932",
    "type": "article"
  },
  {
    "title": "Dataflow Model–based Software Synthesis Framework for Parallel and Distributed Embedded Systems",
    "doi": "https://doi.org/10.1145/3447680",
    "publication_date": "2021-06-05",
    "publication_year": 2021,
    "authors": "Eunjin Jeong; Dowhan Jeong; Soonhoi Ha",
    "corresponding_authors": "",
    "abstract": "Existing software development methodologies mostly assume that an application runs on a single device without concern about the non-functional requirements of an embedded system such as latency and resource consumption. Besides, embedded software is usually developed after the hardware platform is determined, since a non-negligible portion of the code depends on the hardware platform. In this article, we present a novel model-based software synthesis framework for parallel and distributed embedded systems. An application is specified as a set of tasks with the given rules for execution and communication. Having such rules enables us to perform static analysis to check some software errors at compile-time to reduce the verification difficulty. Platform-specific programs are synthesized automatically after the mapping of tasks onto processing elements is determined. The proposed framework is expandable to support new hardware platforms easily. The proposed communication code synthesis method is extensible and flexible to support various communication methods between devices. In addition, the fault-tolerant feature can be added by modifying the task graph automatically according to the selected fault-tolerance configurations by the user. The viability of the proposed software development methodology is evaluated with a real-life surveillance application that runs on six processing elements.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W3168472436",
    "type": "article"
  },
  {
    "title": "Pseudo-3D Physical Design Flow for Monolithic 3D ICs: Comparisons and Enhancements",
    "doi": "https://doi.org/10.1145/3453480",
    "publication_date": "2021-06-05",
    "publication_year": 2021,
    "authors": "Heechun Park; Bon Woong Ku; Kyungwook Chang; Da Eun Shim; Sung Kyu Lim",
    "corresponding_authors": "",
    "abstract": "Studies have shown that monolithic 3D ( M3D ) ICs outperform the existing through-silicon-via ( TSV ) -based 3D ICs in terms of power, performance, and area ( PPA ) metrics, primarily due to the orders of magnitude denser vertical interconnections offered by the nano-scale monolithic inter-tier vias. In order to facilitate faster industry adoption of the M3D technologies, physical design tools and methodologies are essential. Recent academic efforts in developing an EDA algorithm for 3D ICs, mainly targeting placement using TSVs, are inadequate to provide commercial-quality GDS layouts. Lately, pseudo-3D approaches have been devised, which utilize commercial 2D IC EDA engines with tricks that help them operate as an efficient 3D IC CAD tool. In this article, we provide thorough discussions and fair comparisons (both qualitative and quantitative) of the state-of-the-art pseudo-3D design flows, with analysis of limitations in each design flow and solutions to improve their PPA metrics. Moreover, we suggest a hybrid pseudo-3D design flow that achieves both benefits. Our enhancements and the inter-mixed design flow, provide up to an additional 26% wirelength, 10% power consumption, and 23% of power-delay-product improvements.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W3172718840",
    "type": "article"
  },
  {
    "title": "Design Flow and Methodology for Dynamic and Static Energy-constrained Scheduling Framework in Heterogeneous Multicore Embedded Devices",
    "doi": "https://doi.org/10.1145/3450448",
    "publication_date": "2021-06-05",
    "publication_year": 2021,
    "authors": "Guoqi Xie; Peng Hao; Xiongren Xiao; Yao Liu; Renfa Li",
    "corresponding_authors": "",
    "abstract": "With Internet of things technologies, billions of embedded devices, including smart gateways, smart phones, and mobile robots, are connected and deeply integrated. Almost all these embedded devices are battery-constrained and energy-limited systems. In recent years, several works used energy pre-assignment techniques to study the dynamic energy-constrained scheduling of a parallel application in heterogeneous multicore embedded systems. However, the existing energy pre-assignment techniques cannot satisfy the actual energy constraint, because it is the joint constraint on dynamic energy and static energy. Further, the modeling and verification of these works are based on the simulations, which have not been verified in real embedded devices. This study aims to propose a dynamic and static energy-constrained scheduling framework in heterogeneous multicore embedded devices. Solving this problem can utilize existing energy pre-assignment techniques, but it requires a deeply integrated design flow and methodology. The design flow consists of four processes: (1) power and energy modeling; (2) power parameter measurement; (3) basic framework design including energy pre-assignment; and (4) framework optimization. Each design flow has corresponding design methodology. Both our theoretical analysis and practical verification using the low-power ODROID-XU4 device confirm the effectiveness of the proposed framework.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W3173055684",
    "type": "article"
  },
  {
    "title": "An Improved Methodology for Resilient Design Implementation",
    "doi": "https://doi.org/10.1145/2749462",
    "publication_date": "2015-09-28",
    "publication_year": 2015,
    "authors": "Andrew B. Kahng; Seokhyeong Kang; Jiajia Li; José Pineda de Gyvez",
    "corresponding_authors": "",
    "abstract": "Resilient design techniques are used to (i) ensure correct operation under dynamic variations and to (ii) improve design performance (e.g., timing speculation). However, significant overheads (e.g., 16% and 14% energy penalties due to throughput degradation and additional circuits) are incurred by existing resilient design techniques. For instance, resilient designs require additional circuits to detect and correct timing errors. Further, when there is an error, the additional cycles needed to restore a previous correct state degrade throughput, which diminishes the performance benefit of using resilient designs. In this work, we describe an improved methodology for resilient design implementation to minimize the costs of resilience in terms of power, area, and throughput degradation. Our methodology uses two levers: selective-endpoint optimization (i.e., sensitivity-based margin insertion) and clock skew optimization. We integrate the two optimization techniques in an iterative optimization flow which comprehends toggle rate information and the trade-off between cost of resilience and margin on combinational paths. Since the error-detection network can result in up to 9% additional wirelength cost, we also propose a matching-based algorithm for construction of the error-detection network to minimize this resilience overhead. Further, our implementations comprehend the impacts of signoff corners (in particular, hold constraints, and use of typical vs. slow libraries) and process variation, which are typically omitted in previous studies of resilience trade-offs. Our proposed flow achieves energy reductions of up to 21% and 10% compared to a conventional (with only margin used to attain robustness) design and a brute-force implementation (i.e., a typical resilient design, where resilient endpoints are (greedily) instantiated at timing-critical endpoints), respectively. We show that these benefits increase in the context of an adaptive voltage scaling strategy.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W1971700309",
    "type": "article"
  },
  {
    "title": "Diagnosability of Component-Composition Graphs in the MM* Model",
    "doi": "https://doi.org/10.1145/2611759",
    "publication_date": "2014-06-01",
    "publication_year": 2014,
    "authors": "Chia‐Wei Lee; Sun‐Yuan Hsieh",
    "corresponding_authors": "",
    "abstract": "Diagnosability is an important metric for measuring the reliability of multiprocessor systems. This article adopts the MM* model and outlines the common properties of a wide class of interconnection networks, called component-composition graphs (CCGs), to determine their diagnosability by using their obtained properties. By applying the results to multiprocessor systems, the diagnosability of hypercube-like networks (including hypercubes, crossed cubes, Möbius cubes, twisted cubes, locally twisted cubes, generalized twisted cubes, and recursive circulants), star graphs, pancake graphs, bubble-sort graphs, and burnt pancake graphs, all of which belong to the class of CCGs, can also be computed.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W1974204164",
    "type": "article"
  },
  {
    "title": "In-Scratchpad Memory Replication",
    "doi": "https://doi.org/10.1145/2770874",
    "publication_date": "2015-09-28",
    "publication_year": 2015,
    "authors": "Leila Delshadtehrani; Hamed Farbeh; Seyed Ghassem Miremadi",
    "corresponding_authors": "",
    "abstract": "Scratchpad memories (SPMs) are widely employed in multicore embedded processors. Reliability is one of the major constraints in the embedded processor design, which is threatened with the increasing susceptibility of memory cells to multiple-bit upsets (MBUs) due to continuous technology down-scaling. This article proposes a low-cost and efficient data replication mechanism, called In-Scratchpad Memory Replication (ISMR), to correct MBUs in SPMs of multicore embedded processors. The main feature of ISMR is a smart controller, called Replication Management Unit (RMU), which is responsible for dynamically analyzing the activity of the SPM blocks at runtime and efficiently replicating the vulnerable SPM blocks into currently inactive SPM blocks. RMU exploits a 2-bit tag for each SPM block, where the value of each tag is determined by RMU according to the SPM access pattern. Accordingly, the proposed mechanism guarantees the replication of all vulnerable SPM blocks to provide error correction without decreasing the SPM utilization. To detect errors in SPM blocks, ISMR uses a 2-bit interleaved-parity code. As compared with the previous E-RAID 1 mechanism, the simulation results illustrate that for an 8-core embedded processor, the ISMR mechanism experiences 81% less energy consumption overhead and 48% less performance overhead.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2046313076",
    "type": "article"
  },
  {
    "title": "An Effective Floorplan-Guided Placement Algorithm for Large-Scale Mixed-Size Designs",
    "doi": "https://doi.org/10.1145/2611761",
    "publication_date": "2014-06-01",
    "publication_year": 2014,
    "authors": "Jackey Z. Yan; V. Natarajan; Chris Chu",
    "corresponding_authors": "",
    "abstract": "In this article we propose an effective algorithm flow to handle modern large-scale mixed-size placement, both with and without geometry constraints. The basic idea is to use floorplanning to guide the placement of objects at the global level. The flow consists of four steps: (1) The objects in the original netlist are clustered into blocks; (2) floorplanning is performed on the blocks; (3) the blocks are shifted within the chip region to further optimize the wirelength; (4) with large macro-locations fixed, incremental placement is applied to place the remaining objects. There are several advantages to handling placement at the global level with a floorplanning technique. First, the problem size can be significantly reduced. Second, exact Half-Perimeter WireLength (HPWL) can be minimized. Third, better object distribution can be achieved so that legalization only needs to handle minor overlaps among small objects in a block. Fourth, macro-rotation and various geometry constraints can be handled. To demonstrate the effectiveness of this new flow, we implement a high-quality and efficient floorplan-guided placer called FLOP . We also construct the Modern Mixed-Size (MMS) placement benchmarks that can effectively represent the complexities of modern mixed-size designs and the challenges faced by modern mixed-size placers. Compared with most state-of-the-art mixed-size placers and leading macroplacers, experimental results show that FLOP achieves the best HPWL and easily obtains legal solutions on all circuits with all geometry constraints satisfied.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2064910292",
    "type": "article"
  },
  {
    "title": "Applying Pay-Burst-Only-Once Principle for Periodic Power Management in Hard Real-Time Pipelined Multiprocessor Systems",
    "doi": "https://doi.org/10.1145/2699865",
    "publication_date": "2015-03-02",
    "publication_year": 2015,
    "authors": "Gang Chen; Kai Huang; Christian Buckl; Alois Knoll",
    "corresponding_authors": "",
    "abstract": "Pipelined computing is a promising paradigm for embedded system design. Designing a power management policy to reduce the power consumption of a pipelined system with nondeterministic workload is, however, nontrivial. In this article, we study the problem of energy minimization for coarse-grained pipelined systems under hard real-time constraints and propose new approaches based on an inverse use of the pay-burst-only-once principle. We formulate the problem by means of the resource demands of individual pipeline stages and propose two new approaches, a quadratic programming-based approach and fast heuristic, to solve the problem. In the quadratic programming approach, the problem is transformed into a standard quadratic programming with box constraint and then solved by a standard quadratic programming solver. Observing the problem is NP-hard, the fast heuristic is designed to solve the problem more efficiently. Our approach is scalable with respect to the numbers of pipeline stages. Simulation results using real-life applications are presented to demonstrate the effectiveness of our methods.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2083831202",
    "type": "article"
  },
  {
    "title": "An MDE Approach for Rapid Prototyping and Implementation of Dynamic Reconfigurable Systems",
    "doi": "https://doi.org/10.1145/2800784",
    "publication_date": "2015-12-02",
    "publication_year": 2015,
    "authors": "Gilberto Ochoa‐Ruiz; Sébastien Guillet; Florent de Lamotte; Éric Rutten; El‐Bay Bourennane; Jean-Philippe Diguet; Guy Gogniat",
    "corresponding_authors": "",
    "abstract": "This article presents a co-design methodology based on RecoMARTE, an extension to the well-known UML MARTE profile, which is used for the specification and automatic generation of Dynamic and Partially Reconfigurable Systems-on-Chip (DRSoC). This endeavor is part of a larger framework in which Model-Driven Engineering (MDE) techniques are extensively used for modeling and via model transformations, generating executable models, which are exploited by implementation tools to create reconfigurable systems. More specifically, the methodological aspects presented in this article are concerned with expediting the conception and implementation of the hardware platform and the integration of correct by construction reconfiguration controller. This article builds upon previous research by integrating previously separated endeavors to obtain a complete PR system generation chain, which aims at shielding the designer of many of the burdensome technological and tool-specific requirements. The methodology permits for the verification of the platform description at different stages in the development process (i.e., HDL for simulation, static FPGA implementation, controller simulation and verification). Furthermore, automation capabilities embedded in the flow enable the generation of the platform description and the integration of the reconfiguration controller executive seamlessly. In order to demonstrate the benefits of the proposed approach, we present a case study in which we target the creation of an image-processing application to be deployed onto an FPGA board. We present the required modeling strategies and we discuss how the generation chains are integrated with the back-end Xilinx tools (the most mature version of PR technology) to produce the necessary executable artifacts: VHDL for the platform description and a C description of the reconfiguration controller to be executed by an embedded processor.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2183330436",
    "type": "article"
  },
  {
    "title": "A Finite-Point Method for Efficient Gate Characterization Under Multiple Input Switching",
    "doi": "https://doi.org/10.1145/2778970",
    "publication_date": "2015-12-02",
    "publication_year": 2015,
    "authors": "Anupama R. Subramaniam; Janet Roveda; Yu Cao",
    "corresponding_authors": "",
    "abstract": "Timing characterization of standard cells is one of the essential steps in VLSI design. The traditional static timing analysis (STA) tool assumes single input switching models for the characterization of multiple input gates. However, due to technology scaling, increasing operating frequency, and process variation, the probability of the occurrence of multiple input switching (MIS) is increasing. On the other hand, considering all possible MIS scenarios for the characterization of multiple input logic gates, is computationally intensive. To improve the efficiency, this work proposes a finite-point-based characterization methodology for multiple input gates with the effects of MIS. Furthermore, delay variation due to MIS is integrated into the STA flow through propagation of switching windows. The proposed modeling methodology is validated using benchmark circuits at the 45nm technology node for various operating conditions. Experimental results demonstrate significant reduction in computation cost and data volume with less than ∼10% error compared to that of traditional SPICE simulation.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2188437737",
    "type": "article"
  },
  {
    "title": "Exploring Soft-Error Robust and Energy-Efficient Register File in GPGPUs using Resistive Memory",
    "doi": "https://doi.org/10.1145/2827697",
    "publication_date": "2016-01-28",
    "publication_year": 2016,
    "authors": "Jingweijia Tan; Zhi Li; Mingsong Chen; Xin Fu",
    "corresponding_authors": "",
    "abstract": "The increasing adoption of graphics processing units (GPUs) for high-performance computing raises the reliability challenge, which is generally ignored in traditional GPUs. GPUs usually support thousands of parallel threads and require a sizable register file. Such large register file is highly susceptible to soft errors and power-hungry. Although ECC has been adopted to register file in modern GPUs, it causes considerable power overhead, which further increases the power stress. Thus, an energy-efficient soft-error protection mechanism is more desirable. Besides its extremely low leakage power consumption, resistive memory (e.g., spin-transfer torque RAM) is also immune to the radiation induced soft errors due to its magnetic field based storage. In this article, we propose to LEverage reSistive memory to enhance the Soft-error robustness and reduce the power consumption (LESS) of registers in the General-Purpose computing on GPUs (GPGPUs). Since resistive memory experiences longer write latency compared to SRAM, we explore the unique characteristics of GPGPU applications to obtain the win-win gains: achieving the near-full soft-error protection for the register file, and meanwhile substantially reducing the energy consumption with negligible performance degradation. Our experimental results show that LESS is able to mitigate the registers soft-error vulnerability by 86% and achieve 61% energy savings with negligible (e.g., 1%) performance degradation.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2260256017",
    "type": "article"
  },
  {
    "title": "A Cost-Effective Energy Optimization Framework of Multicore SoCs Based on Dynamically Reconfigurable Voltage-Frequency Islands",
    "doi": "https://doi.org/10.1145/2817207",
    "publication_date": "2016-01-28",
    "publication_year": 2016,
    "authors": "Song Jin; Songwei Pei; Yinhe Han; Huawei Li",
    "corresponding_authors": "",
    "abstract": "Voltage-frequency island (VFI)-based design has been widely exploited for optimizing system energy of embedded multicore chip in recent years. The existing work either constructed a single static VFI partition for all kinds of applications or required per-core voltage domain configuration. However, the former solution is hard to find one optimal VFI partition for diverse applications while the latter one suffers from high hardware cost. In this article, we propose a cost effective energy optimization framework based on dynamically reconfigurable VFI (D-VFI). Our framework treats a small number of cores as dynamic cores (D-cores) and configures each of them with an independent voltage domain. At runtime, the D-cores can be pieced together with neighboring static VFIs by scaling their operating voltages. This can dynamically construct the optimal VFI partitions for different kinds of applications, thus achieving more aggressive energy optimization under low cost. To identify the D-cores, we propose a rules constrained task scheduling and VFI partitioning algorithm. Moreover, we analyze the task schedules to determine the optimal scaling intervals which can accommodate voltage scaling induced latency. Experimental results demonstrate that the effectiveness of the proposed scheme.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2263942918",
    "type": "article"
  },
  {
    "title": "DC Characteristics and Variability on 90nm CMOS Transistor Array-Style Analog Layout",
    "doi": "https://doi.org/10.1145/2888395",
    "publication_date": "2016-05-11",
    "publication_year": 2016,
    "authors": "Chen Gong; Toru Fujimura; Qing Dong; Shigetoshi Nakatake; Bo Yang",
    "corresponding_authors": "",
    "abstract": "In the MOS analog layout, variability suppression is becoming a major issue, as is layout efficiency. Introducing a transistor array (TA) style to analog layout, this article addresses the layout-dependent variability based on the measurement results of test chips on 90nm CMOS process. In TA style, a large transistor is decomposed into a set of unified subtransistors, which are connected in series or parallel. Focusing on one row layout of diffusion sharing for the multiple gates, we analyze the current direction-dependent variability and the leakage current via off-gates for the electrical isolation. Furthermore, we present several analog design cases on TA including analysis of the impact on the DC characteristics caused by the transistor channel decomposition.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2357304008",
    "type": "article"
  },
  {
    "title": "A Hybrid DRAM/PCM Buffer Cache Architecture for Smartphones with QoS Consideration",
    "doi": "https://doi.org/10.1145/2979143",
    "publication_date": "2016-12-28",
    "publication_year": 2016,
    "authors": "Ye-Jyun Lin; Chia-Lin Yang; Hsiang-Pang Li; Cheng-Yuan Michael Wang",
    "corresponding_authors": "",
    "abstract": "Flash memory is widely used in mobile phones to store contact information, application files, and other types of data. In an operating system, the buffer cache keeps the I/O blocks in dynamic random access memory (DRAM) to reduce the slow flash accesses. However, in smartphones, we observed two issues which reduce the benefits of the buffer cache. First, a large number of synchronous writes force writing the data from the buffer cache to flash frequently. Second, the large amount of I/O accesses from background applications diminishes the buffer cache efficiency of the foreground application, which degrades the quality-of-service (QoS). In this article, we propose a buffer cache architecture with hybrid DRAM and phase change memory (PCM) memory, which improves the I/O performance and QoS for smartphones. We use a DRAM first-level buffer cache to provide high buffer cache performance and a PCM last-level buffer cache to reduce the impact of frequent synchronous writes. Based on the proposed hierarchical buffer cache architecture, we propose a sub-block management and background flush to reduce the impact of the PCM write limitation and the dirty block write-back overhead, respectively. To improve the QoS, we propose a least-recently-activated first replacement policy (LRA) to keep the data from the applications that are most likely to become the foreground one. The experimental results show that with the proposed mechanisms, our hierarchical buffer cache can improve the I/O response time by 20% compared to the conventional buffer cache. The proposed LRA can improve the foreground application performance by 1.74x compared to the conventional CLOCK policy.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2563326589",
    "type": "article"
  },
  {
    "title": "Automatic Mapping of the Best-Suited DNN Pruning Schemes for Real-Time Mobile Acceleration",
    "doi": "https://doi.org/10.1145/3495532",
    "publication_date": "2022-02-24",
    "publication_year": 2022,
    "authors": "Yifan Gong; Geng Yuan; Zheng Zhan; Wei Niu; Zhengang Li; Pu Zhao; Yuxuan Cai; Sijia Liu; Bin Ren; Xue Lin; Xulong Tang; Yanzhi Wang",
    "corresponding_authors": "",
    "abstract": "Weight pruning is an effective model compression technique to tackle the challenges of achieving real-time deep neural network (DNN) inference on mobile devices. However, prior pruning schemes have limited application scenarios due to accuracy degradation, difficulty in leveraging hardware acceleration, and/or restriction on certain types of DNN layers. In this article, we propose a general, fine-grained structured pruning scheme and corresponding compiler optimizations that are applicable to any type of DNN layer while achieving high accuracy and hardware inference performance. With the flexibility of applying different pruning schemes to different layers enabled by our compiler optimizations, we further probe into the new problem of determining the best-suited pruning scheme considering the different acceleration and accuracy performance of various pruning schemes. Two pruning scheme mapping methods—one -search based and the other is rule based—are proposed to automatically derive the best-suited pruning regularity and block size for each layer of any given DNN. Experimental results demonstrate that our pruning scheme mapping methods, together with the general fine-grained structured pruning scheme, outperform the state-of-the-art DNN optimization framework with up to 2.48 \\( \\times \\) and 1.73 \\( \\times \\) DNN inference acceleration on CIFAR-10 and ImageNet datasets without accuracy loss.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W3217772193",
    "type": "article"
  },
  {
    "title": "Breaking the Design and Security Trade-off of Look-up-table–based Obfuscation",
    "doi": "https://doi.org/10.1145/3510421",
    "publication_date": "2022-02-18",
    "publication_year": 2022,
    "authors": "Gaurav Kolhe; Tyler Sheaves; Sai Manoj Pudukotai Dinakarrao; Hamid Mahmoodi; Setareh Rafatirad; Avesta Sasan; Houman Homayoun",
    "corresponding_authors": "",
    "abstract": "Logic locking and Integrated Circuit (IC) camouflaging are the most prevalent protection schemes that can thwart most hardware security threats. However, the state-of-the-art attacks, including Boolean Satisfiability (SAT) and approximation-based attacks, question the efficacy of the existing defense schemes. Recent obfuscation schemes have employed reconfigurable logic to secure designs against various hardware security threats. However, they have focused on specific design elements such as SAT hardness. Despite meeting the focused criterion such as security, obfuscation incurs additional overheads, which are not evaluated in the present works. This work provides an extensive analysis of Look-up-table (LUT)–based obfuscation by exploring several factors such as LUT technology, size, number of LUTs, and replacement strategy as they have a substantial influence on Power-Performance-Area (PPA) and Security (PPA/S) of the design. We show that using large LUT makes LUT-based obfuscation resilient to hardware security threats. However, it also results in enormous design overheads beyond practical limits. To make the reconfigurable logic obfuscation efficient in terms of design overheads, this work proposes a novel LUT architecture where the security provided by the proposed primitive is superior to that of the traditional LUT-based obfuscation. Moreover, we leverage the security-driven design flow, which uses off-the-shelf industrial EDA tools to mitigate the design overheads further while being non-disruptive to the current industrial physical design flow. We empirically evaluate the security of the LUTs against state-of-the-art obfuscation techniques in terms of design overheads and SAT-attack resiliency. Our findings show that the proposed primitive significantly reduces both area and power by a factor of 8 \\( \\times \\) and 2 \\( \\times \\) , respectively, without compromising security.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4212893557",
    "type": "article"
  },
  {
    "title": "Efficient Layout Hotspot Detection via Neural Architecture Search",
    "doi": "https://doi.org/10.1145/3517130",
    "publication_date": "2022-02-18",
    "publication_year": 2022,
    "authors": "Yiyang Jiang; Fan Yang; Bei Yu; Dian Zhou; Xuan Zeng",
    "corresponding_authors": "",
    "abstract": "Layout hotspot detection is of great importance in the physical verification flow. Deep neural network models have been applied to hotspot detection and achieved great success. Despite their success, high-performance neural networks are still quite difficult to design. In this article, we propose a bayesian optimization-based neural architecture search scheme to automatically do this time-consuming and fiddly job. Experimental results on ICCAD 2012 and ICCAD 2019 Contest benchmarks show that the architectures designed by our proposed scheme achieve higher performance on hotspot detection task compared with state-of-the-art manually designed neural networks.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4213282001",
    "type": "article"
  },
  {
    "title": "Software/Hardware Co-design of 3D NoC-based GPU Architectures for Accelerated Graph Computations",
    "doi": "https://doi.org/10.1145/3514354",
    "publication_date": "2022-04-04",
    "publication_year": 2022,
    "authors": "Dwaipayan Choudhury; Reet Barik; Aravind Sukumaran-Rajam; Ananth Kalyanaraman; Partha Pratim Pande",
    "corresponding_authors": "",
    "abstract": "Manycore GPU architectures have become the mainstay for accelerating graph computations. One of the primary bottlenecks to performance of graph computations on manycore architectures is the data movement. Since most of the accesses in graph processing are due to vertex neighborhood lookups, locality in graph data structures plays a key role in dictating the degree of data movement. Vertex reordering is a widely used technique to improve data locality within graph data structures. However, these reordering schemes alone are not sufficient as they need to be complemented with efficient task allocation on manycore GPU architectures to reduce latency due to local cache misses. Consequently, in this article, we introduce a software/hardware co-design framework for accelerating graph computations. Our approach couples an architecture-aware vertex reordering with a priority-based task allocation technique. As the task allocation aims to reduce on-chip latency and associated energy, the choice of Network-on-Chip (NoC) as the communication backbone in the manycore platform is an important parameter. By leveraging emerging three-dimensional (3D) integration technology, we propose design of a small-world NoC (SWNoC)-enabled manycore GPU architecture, where the placement of the links connecting the streaming multiprocessors (SMs) and the memory controllers (MCs) follow a power-law distribution. The proposed 3D SWNoC-enabled software/hardware co-design framework achieves 11.1% to 22.9% performance improvement and 16.4% to 32.6% less energy consumption depending on the dataset and the graph application, when compared to the default order of dataset running on a conventional planar mesh architecture.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4226425543",
    "type": "article"
  },
  {
    "title": "Rescuing ReRAM-based Neural Computing Systems from Device Variation",
    "doi": "https://doi.org/10.1145/3533706",
    "publication_date": "2022-04-28",
    "publication_year": 2022,
    "authors": "Chenglong Huang; Nuo Xu; Junwei Zeng; Wenqing Wang; Yihong Hu; Liang Fang; Desheng Ma; Yan-Ting Chen",
    "corresponding_authors": "",
    "abstract": "Resistive random-access memory (ReRAM)-based crossbar array (RCA) is a promising platform to accelerate vector-matrix multiplication in deep neural networks (DNNs). There are, however, some practical issues, especially device variation, that hinder the versatile development of ReRAM in neural computing systems. The device variations include device-to-device variation (DDV) and cycle-to-cycle variation (CCV) that deviate the devise resistance in the RCA from their target state. Such resistance deviation seriously degrades the inference accuracy of DNNs. To address this issue, we propose a software-hardware compensation solution that includes compensation training based on scale factors (CTSF) and variation-aware compensation training based on scale factors (VACTSF) to protect the ReRAM-based DNN accelerator against device variation. The scale factors in CTSF can be flexibly set for reducing accuracy loss due to device variation when the weights programmed into RCA are determined. For effectively handling CCV, the scale factors are introduced into the training process for obtaining variation-tolerant weights by leveraging the inherent self-healing ability of DNNs. Simulation results based on our method confirm that the accuracy losses due to device variation on LeNet-5, ResNet, and VGG16 with different datasets are less than 5% under a large device variation by CTSF. More robust weights for conquering CCV are also obtained by VACTSF. The simulation results present that our method is competitive in comparison to other variation-tolerant methods.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4293236956",
    "type": "article"
  },
  {
    "title": "Board-level multiterminal net routing for FPGA-based logic emulation",
    "doi": "https://doi.org/10.1145/253052.253136",
    "publication_date": "1997-04-01",
    "publication_year": 1997,
    "authors": "Wai-Kei Mak; Martin D. F. Wong",
    "corresponding_authors": "",
    "abstract": "We consider a board-level routing problem applicable to FPGA-based logic emulation systems such as the Realizer System [Varghese et al. 1993] and the Enterprise Emulation System [Maliniak 1992] manufactured by Quickturn Design Systems. Optimal algorithms have been proposed for the case where all nets are two-terminal nets [Chan and Schlag 1993; Mak and Wong 1995]. We show how multiterminal nets can be handled by decomposition into two-terminal nets. We show that the multiterminal net decomposition problem can be modeled as a bounded-degree hypergraph-to-graph transformation problem where hyperedges are transformed to spanning trees. A network flow-based algorithm that solves both problems is proposed. It determines if there is a feasible decomposition and gives one whenever such a decomposition exists.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W1968334894",
    "type": "article"
  },
  {
    "title": "Slicible rectangular graphs and their optimal floorplans",
    "doi": "https://doi.org/10.1145/502175.502176",
    "publication_date": "2001-10-01",
    "publication_year": 2001,
    "authors": "Parthasarathi Dasgupta; Susmita Sur‐Kolay",
    "corresponding_authors": "",
    "abstract": "Rectangular dualization method of floorplanning usually involves topology generation followed by sizing. Slicible topologies are often preferred for their simplicity and efficiency. While slicible topologies can be obtained efficiently, existing linear-time algorithms for topology generation from a given rectangular graph does not guarantee slicible topologies even if one exists. Moreover, the class of rectangular graphs, known as inherently nonslicible graphs, do not have any slicible topologies. In this article, new tighter sufficiency conditions for slicibility of rectangular graphs are postulated and utilized in the generation of area-optimal floorplans. These graph-theoretic conditions not only capture a larger class of slicible rectangular graphs but also help in reducing the total effort for topology generation, and in solving problems of larger size.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2043511988",
    "type": "article"
  },
  {
    "title": "On the use of flexible, rectilinear blocks to obtain minimum-area floorplans in mixed block and cell designs",
    "doi": "https://doi.org/10.1145/329458.329470",
    "publication_date": "2000-01-01",
    "publication_year": 2000,
    "authors": "Dinesh P. Mehta; Naveed A. Sherwani",
    "corresponding_authors": "",
    "abstract": "This paper presents three minimum-area floorplanning algorithms that use flexible arbitrary rectilinear shapes for the standard cell regions in MBC design. The first algorithm (pure HCST) introduces a grid traversal technique which guarantees a minimum-area floorplan. The second algorithm (Hybrid-BF) uses a combination of HCST and Breadth First (BF) traversals to give a practical solution that approximately places flexible blocks at specified locations called seeds . The third algorithm (Hybrid-MBF) improves on the shapes of the flexible blocks generated by Hybrid-BF by using a combination of HCST and a Modified Breadth First (MBF) traversal. All three algorithms are polynomial in the number of grid squares. Optimized implementations of Hybrid-BF and Hybrid-MBF required less than two seconds on a SUN SPARCstation 10.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2043590481",
    "type": "article"
  },
  {
    "title": "On the fundamental limitations of transformational design",
    "doi": "https://doi.org/10.1145/502175.502181",
    "publication_date": "2001-10-01",
    "publication_year": 2001,
    "authors": "Jeroen Voeten",
    "corresponding_authors": "Jeroen Voeten",
    "abstract": "The completeness of a collection of design transformations is an important aspect in transformational design. Completeness guarantees that any correct design can in principle be explored using the transformation system. In the field of transformational design the problem of incompleteness is not well understood and it is often believed that complete transformation systems can be constructed. In this article, we show, using a formal framework based on the theory of computation, that this is not the case if the transformation system is based on an expressive general-purpose design language such as VHDL. Only when restrictions are imposed on the design language and correctness relation, a transformation system can be made complete in theory, but this is expected to result in serious practical problems. It is shown that the incompleteness problem in transformational design is closely related to the syntactic variance problem in high-level synthesis and that this latter problem is not solvable in general either.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2056693265",
    "type": "article"
  },
  {
    "title": "CLIP",
    "doi": "https://doi.org/10.1145/348019.348234",
    "publication_date": "2000-07-01",
    "publication_year": 2000,
    "authors": "Avaneendra Gupta; John P. Hayes",
    "corresponding_authors": "",
    "abstract": "A novel technique, CLIP , is presented for the automatic generation of optimal layouts of CMOS cells in the two-dimensional (2D) style. CLIP is based on integer-linear programming ( ILP ) and solves both the width and height minimization problems for 2D cells. Width minimization is formulated in a precise form that combines all factors influencing the 2D cell width—transistor placement, diffusion sharing, and vertical interrow connections—in a common problem space; this space is then searched in a systematic manner by the branch-and-bound algorithms used by ILP solvers. For height minimization, cell height is modeled accurately in terms of the horizontal wire routing density, and a minimum-height layout is found from among all layouts of minimum width. For exact width minimization alone, CLIP 's run times are in seconds for large circuits with 30 or more transistors. For both height and width optimization, CLIP is practical for circuits with up to 20 transistors. To extend CLIP to larger circuits, hierarchical methods are necessary. Since CLIP is optimum under the modeling assumptions, its layouts are significantly better than those generated by other, heuristic, layout tools.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W2010927173",
    "type": "article"
  },
  {
    "title": "Forced simulation",
    "doi": "https://doi.org/10.1145/502175.502185",
    "publication_date": "2001-10-01",
    "publication_year": 2001,
    "authors": "Partha S. Roop; Arcot Sowmya; S. Ramesh",
    "corresponding_authors": "",
    "abstract": "Component reuse techniques have been a recent focus of research because they are seen as the next-generation techniques to handle increasing system complexities. However, there are several unresolved issues to be addressed and prominent among them is the issue of component matching . As the number of reusable components in a component database grows, the task of manually matching a component to the user requirements becomes infeasible. Automating this matching can help in rapid system prototyping, improving quality and reducing cost. In addition, if the matching algorithm is sound, this approach can also reduce precious validation effort.In this article, we propose an algorithm for automatic matching of a design function to a device from a component database. The distinguishing feature of the algorithm is that when successful, it generates an interface that can automatically adapt the device to behave as the function. The algorithm is based on a new simulation relation called forced simulation that is shown to be a necessary and sufficient condition for component matching to be possible for a given pair of function and device. We demonstrate the application of the algorithm by reusing on some programmable components of the Intel family.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W2027167791",
    "type": "article"
  },
  {
    "title": "Optimized wafer-probe and assembled package test design for analog circuits",
    "doi": "https://doi.org/10.1145/1059876.1059882",
    "publication_date": "2005-04-01",
    "publication_year": 2005,
    "authors": "Soumendu Bhattacharya; Abhijit Chatterjee",
    "corresponding_authors": "",
    "abstract": "It is well known that wafer-probe test costs of analog ICs are an order of magnitude less than the corresponding test costs of assembled packages. It is therefore natural to push as much of the testing process into wafer-probe testing as possible to reduce the scope of assembled package testing. However, the signal drive and response observation capabilities during wafer probe testing are limited in comparison to assembled packages. In this article, it is shown that by using band-limited transient test signals, which can be supported by wafer-probe test instrumentation, significant numbers of bad ICs can be detected early during the wafer-probe test. The optimal test stimuli are determined by cooptimizing the wafer-probe and assembled package test waveforms. Overall test costs, including the cost of packaging bad ICs, are minimized and are reduced up to four times. The proposed method has been validated using hardware test data, which were obtained through measurements made on a prototype.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W1979840878",
    "type": "article"
  },
  {
    "title": "Optimizing instruction TLB energy using software and hardware techniques",
    "doi": "https://doi.org/10.1145/1059876.1059879",
    "publication_date": "2005-04-01",
    "publication_year": 2005,
    "authors": "I. Kadayif; Anand Sivasubramaniam; Mahmut Kandemir; Gokul B. Kandiraju; Gong Chen",
    "corresponding_authors": "",
    "abstract": "Power consumption and power density for the Translation Look-aside Buffer (TLB) are important considerations not only in its design, but can have a consequence on cache design as well. After pointing out the importance of instruction TLB (iTLB) power optimization, this article embarks on a new philosophy for reducing the number of accesses to this structure. The overall idea is to keep a translation currently being used in a register and avoid going to the iTLB as far as possible---until there is a page change. We propose four different approaches for achieving this, and experimentally demonstrate that one of these schemes that uses a combination of compiler and hardware enhancements can reduce iTLB dynamic power by over 85% in most cases.The proposed approaches can work with different instruction-cache (iL1) lookup mechanisms and achieve significant iTLB power savings without compromising on performance. Their importance grows with higher iL1 miss rates and larger page sizes. They can work very well with large iTLB structures that can possibly consume more power and take longer to lookup, without the iTLB getting into the common case. Further, we also experimentally demonstrate that they can provide performance savings for virtually indexed, virtually tagged iL1 caches, and can even make physically indexed, physically tagged iL1 caches a possible choice for implementation.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W1979194338",
    "type": "article"
  },
  {
    "title": "Effective techniques for the generalized low-power binding problem",
    "doi": "https://doi.org/10.1145/1124713.1124718",
    "publication_date": "2006-01-01",
    "publication_year": 2006,
    "authors": "Azadeh Davoodi; Ankur Srivastava",
    "corresponding_authors": "",
    "abstract": "This article proposes two very fast graph theoretic heuristics for the low power binding problem given fixed number of resources and multiple architectures for the resources. First, the generalized low power binding problem is formulated as an Integer Linear Programming (ILP) problem that happens to be an NP-complete task to solve. Then two polynomial-time heuristics are proposed that provide a speedup of up to 13.7 with an extremely low penalty for power when compared to the optimal ILP solution for our selected benchmarks.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2054715287",
    "type": "article"
  },
  {
    "title": "Simplifying the design and automating the verification of pipelines with structural hazards",
    "doi": "https://doi.org/10.1145/1109118.1109123",
    "publication_date": "2005-10-01",
    "publication_year": 2005,
    "authors": "Jason T. Higgins; Mark D. Aagaard",
    "corresponding_authors": "",
    "abstract": "This article describes a technique that simplifies the design of pipelined circuits automates the specification and verification of structural-hazard and datapath correctness properties for pipelined circuits. The technique is based upon a template for pipeline stages, a control-circuit cell library, a decomposition of structural hazard and datapath correctness into a collection of simple properties, and a prototype design tool that generates verification scripts for use by external tools. Our case studies include scalar and superscalar implementations of a 32-bit OpenRISC integer microprocessor.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2065518690",
    "type": "article"
  },
  {
    "title": "Reducing energy consumption of multiprocessor SoC architectures by exploiting memory bank locality",
    "doi": "https://doi.org/10.1145/1142155.1142163",
    "publication_date": "2006-04-01",
    "publication_year": 2006,
    "authors": "Mahmut Kandemir",
    "corresponding_authors": "Mahmut Kandemir",
    "abstract": "The next generation embedded architectures are expected to accommodate multiple processors on the same chip. While this makes interprocessor communication less costly as compared to traditional high-end parallel machines, it also makes off-chip requests very costly. In particular, frequent off-chip memory accesses do not only increase execution cycles but also increase overall power consumption. One way of alleviating this power problem is to divide the off-chip memory into multiple banks, each of which can be power-controlled independently using low-power operating modes.In this article, we focus on a multiprocessor-system-on-a-chip (MPSoC) architecture with a banked memory system, and show how code and data optimizations can help us reduce memory energy consumption for embedded applications with regular data access patterns, for example, those from the embedded image and video processing domain. This is achieved by ensuring bank locality, which means that each processor localizes its accesses into a small set of banks in a given time period. We present a mathematical formulation of the bank locality problem. Our formulation is based on constructing a set of matrix equations that capture the mappings between the data, computation, processor, and memory bank spaces. Based on this formulation, we propose a heuristic solution to the bank locality problem under different scenarios. Our solution involves an iterative process through which we try to satisfy as many matrix constraints as possible; the unsatisfied constraints represent the degree of degradation in bank locality. Finally, we report extensive experimental results showing the effectiveness of our strategy in practice. Our results show that the proposed solution improves bank locality significantly, and reduces the overall memory system energy consumption by up to 34% over an approach that makes use of the low-power modes but does not employ our strategy.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2051744224",
    "type": "article"
  },
  {
    "title": "Radio frequency identification prototyping",
    "doi": "https://doi.org/10.1145/1344418.1344425",
    "publication_date": "2008-04-02",
    "publication_year": 2008,
    "authors": "Alex K. Jones; Swapna Dontharaju; Shenchih Tung; Leo Mats; Peter J. Hawrylak; Raymond R. Hoare; J.T. Cain; Marlin H. Mickle",
    "corresponding_authors": "",
    "abstract": "While RFID is starting to become a ubiquitious technology, the variation between different RFID systems still remains high. This paper presents several prototyping environments for different components of radio frequency identification (RFID) tags to demonstrate how many of these components can be standardized for many different purposes. We include two active tag prototypes, one based on a microprocessor and the second based on custom hardware. To program these devices we present a design automation flow that allows RFID transactions to be described in terms of primitives with behavior written in ANSI C code. To save power with active RFID devices we describe a passive transceiver switch called the “burst switch” and demonstrate how this can be used in a system with a microprocessor or custom hardware controller. Finally, we present a full RFID system prototyping environment based on real-time spectrum analysis technology currently deployed at the University of Pittsburgh RFID Center of Excellence. Using our prototyping techniques we show how transactions from multiple standards can be combined and targeted to several microprocessors include the Microchip PIC, Intel StrongARM and XScale, and AD Chips EISC as well as several hardware targets including the Altera Apex, Actel Fusion, Xilinx Coolrunner II, Spartan 3 and Virtex 2, and cell-based ASICs.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W1976966845",
    "type": "article"
  },
  {
    "title": "Functional verification of task partitioning for multiprocessor embedded systems",
    "doi": "https://doi.org/10.1145/1278349.1278357",
    "publication_date": "2007-09-01",
    "publication_year": 2007,
    "authors": "Dipankar Das; P. P. Chakrabarti; Rajeev Kumar",
    "corresponding_authors": "",
    "abstract": "With the advent of multiprocessor embedded platforms, application partitioning and mapping have gained primacy as a design step. The output of this design step is a multithreaded partitioned application where each thread is mapped to a processing element (processor or ASIC) in the multiprocessor platform. This partitioned application must be verified to be consistent with the native unpartitioned application. This verification task is called application (or task) partitioning verification. This work proposes a code-block-level containment-checking -based methodology for application partitioning verification. We use a UML-based code-block-level modeling language which is rich enough to model most designs. We formulate the application partitioning verification problem as a special case of the containment checking problem, which we call the complete containment checking problem . We propose a state space reduction technique specific to the containment checking, reachability analysis, and deadlock detection problems. We propose novel data structures and token propagation methodologies which enhance the efficiency of containment checking. We present an efficient containment checking algorithm for the application partitioning verification problem. We develop a containment checking tool called TraceMatch and present experimental results. We present a comparison of the state space reduction achieved by TraceMatch with that achieved by formal analysis and verification tools like Spin, PEP, PROD, and LoLA.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W1984778404",
    "type": "article"
  },
  {
    "title": "Hierarchical partitioning of VLSI floorplans by staircases",
    "doi": "https://doi.org/10.1145/1188275.1188282",
    "publication_date": "2007-01-01",
    "publication_year": 2007,
    "authors": "Subhashis Majumder; Susmita Sur‐Kolay; Bhargab B. Bhattacharya; Swarup Kumar Das",
    "corresponding_authors": "",
    "abstract": "This article addresses the problem of recursively bipartitioning a given floorplan F using monotone staircases. At each level of the hierarchy, a monotone staircase from one corner of F to its opposite corner is identified, such that (i) the two parts of the bipartition are nearly equal in area (or in the number of blocks), and (ii) the number of nets crossing the staircase is minimal. The problem of area-balanced bipartitioning is shown to be NP-hard, and a maxflow-based heuristic is proposed. Such a hierarchy may be useful to repeater placement in deep-submicron physical design, and also to global routing.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2013173842",
    "type": "article"
  },
  {
    "title": "The optimization of kEP-SOPs",
    "doi": "https://doi.org/10.1145/1344418.1344431",
    "publication_date": "2008-04-02",
    "publication_year": 2008,
    "authors": "Anna Bernasconi; Valentina Ciriani; Roberto Cordone",
    "corresponding_authors": "",
    "abstract": "We propose a new algebraic four-level expression called k-EXOR-projected sum of products (kEP-SOP). The optimization of a kEP-SOP is NP NP -hard, but can be approximated within a fixed performance guarantee in polynomial time. Moreover, fully testable circuits under the stuck-at-fault model can be derived from kEP-SOPs by adding at most a constant number of multiplexer gates. The experiments show that the computational time is very short and the results are most of the time optimal with respect to the number of products involved. kEP-SOPs also prove experimentally a good starting point for general multilevel logic synthesis.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2015589329",
    "type": "article"
  },
  {
    "title": "A fast simultaneous input vector generation and gate replacement algorithm for leakage power reduction",
    "doi": "https://doi.org/10.1145/1344418.1344430",
    "publication_date": "2008-04-02",
    "publication_year": 2008,
    "authors": "Lei Cheng; Deming Chen; Martin D. F. Wong",
    "corresponding_authors": "",
    "abstract": "The Input vector control (IVC) technique is based on the observation that the leakage current in a CMOS logic gate depends on gate input state, and a good input vector is able to minimize leakage when the circuit is in sleep mode. The gate replacement technique is a very effective method to further reduce the leakage current. In this article, we propose a fast heuristic algorithm to find a low-leakage input vector with simultaneous gate replacement. Results on MCNC91 benchmark circuits show that our algorithm produces 14% better leakage current reduction with several orders of magnitude speedup in runtime for large circuits compared to the previous state-of-the-art algorithm. In particular, the average runtime for the ten largest combinational circuits has been dramatically reduced from 1879 seconds to 0.34 seconds.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2106420699",
    "type": "article"
  },
  {
    "title": "Workload-ahead-driven online energy minimization techniques for battery-powered embedded systems with time-constraints",
    "doi": "https://doi.org/10.1145/1217088.1217093",
    "publication_date": "2007-01-01",
    "publication_year": 2007,
    "authors": "Yuan Cai; Markus Schmitz; Bashir M. Al‐Hashimi; S.M. Reddy",
    "corresponding_authors": "",
    "abstract": "This article proposes a new online voltage scaling (VS) technique for battery-powered embedded systems with real-time constraints. The VS technique takes into account the execution times and discharge currents of tasks to further reduce the battery charge consumption when compared to the recently reported slack forwarding technique [Ahmed and Chakrabarti 2004], while maintaining low online complexity of O(1). Furthermore, we investigate the impact of online rescheduling and remapping on the battery charge consumption for tasks with data dependency which has not been explicitly addressed in the literature and propose a novel rescheduling/remapping technique. Finally, we take leakage power into consideration and extend the proposed online techniques to include adaptive body biasing (ABB) which is used to reduce the leakage power. We demonstrate and compare the efficiency of the presented techniques using seven real-life benchmarks and numerous automatically generated examples.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W4255636589",
    "type": "article"
  },
  {
    "title": "An open-source binary utility generator",
    "doi": "https://doi.org/10.1145/1344418.1344423",
    "publication_date": "2008-04-02",
    "publication_year": 2008,
    "authors": "Alexandro Baldassin; Paulo Centoducatte; Sandro José Rigo; D. Casarotto; Luiz C. V. dos Santos; Max Schultz; Olinto José Varela Furtado",
    "corresponding_authors": "",
    "abstract": "Electronic system level (ESL) modeling allows early hardware-dependent software (HDS) development. Due to broad CPU diversity and shrinking time-to-market, HDS development can neither rely on hand-retargeting binary tools, nor can it rely on pre-existent tools within standard packages. As a consequence, binary utilities which can be easily adapted to new CPU targets are of increasing interest. We present in this article a framework for automatic generation of binary utilities. It relies on two innovative ideas: platform-aware modeling and more inclusive relocation handling. Generated assemblers, linkers, disassemblers and debuggers were validated for MIPS, SPARC, PowerPC, i8051 and PIC16F84. An open-source prototype generator is available for download.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W1964709037",
    "type": "article"
  },
  {
    "title": "Low-power TinyOS tuned processor platform for wireless sensor network motes",
    "doi": "https://doi.org/10.1145/1754405.1754408",
    "publication_date": "2010-05-01",
    "publication_year": 2010,
    "authors": "Rajkumar Raval; Carlos Fernández; Chris J. Bleakley",
    "corresponding_authors": "",
    "abstract": "In this article we describe a low-power processor platform for use in Wireless Sensor Network (WSN) nodes (motes). WSN motes are small, battery-powered devices comprised of a processor, sensors, and a radio frequency transceiver. It is expected that WSNs consisting of large numbers of motes will offer long-term, distributed monitoring, and control of real-world equipment and phenomena. A key requirement for these applications is long battery life. We investigate a processor platform architecture based on an application-specific programmable processor core, System-On-Chip bus, and a hardware accelerator. The architecture improves on the energy consumption of a conventional microprocessor design by tuning the architecture for a suite of TinyOS-based WSN applications. The tuning method used minimizes changes to the instruction set architecture facilitating rapid software migration to the new platform. The processor platform was implemented and validated in an FPGA-based WSN mote. The benefits of the approach in terms of energy consumption are estimated to be a reduction of 48% for ASIC implementation relative to a conventional programmable processor for a typical TinyOS application suite without use of voltage scaling.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W1968138598",
    "type": "article"
  },
  {
    "title": "Leakage-aware task scheduling for partially dynamically reconfigurable FPGAs",
    "doi": "https://doi.org/10.1145/1562514.1562520",
    "publication_date": "2009-08-01",
    "publication_year": 2009,
    "authors": "Ping-Hung Yuh; Chia-Lin Yang; Chi-Feng Li; Chung-Hsiang Lin",
    "corresponding_authors": "",
    "abstract": "As technology continues to shrink, reducing leakage power of Field-Programmable Gate Arrays (FPGAs) becomes a critical issue for the practical use of FPGAs. In this article, we address the leakage issue of partially dynamically reconfigurable FPGA architectures with sleep transistors embedded into FPGA fabrics. In particular, we focus on eliminating leakage waste due to the delay between reconfiguration and execution time of a task. For partially dynamically reconfigurable FPGAs, the configuration prefetching technique is commonly used to hide runtime reconfiguration overhead. With prefetching, the configuration of a task is loaded into FPGAs as early as possible. Therefore, there is often a delay between reconfiguration and execution time of a task. In this period of time, the SRAM cells allocated to a task cannot be turned off even though they are not utilized. In this article, we propose a two-stage task scheduling methodology to reduce leakage waste due to the delay between reconfiguration and execution time of a task without sacrificing performance. In the first stage, a performance-driven task scheduler that targets at minimizing the schedule length is invoked to generate an initial placement. In the second stage, a postplacement leakage-aware task scheduling is applied to refine the initial placement such that leakage waste is minimized provided that the schedule length is not increased. To solve the postplacement leakage optimization problem, we propose two algorithms. The first one is an optimal algorithm based on Integer Linear Programming (ILP). The second algorithm is a heuristic approach that iteratively refines the placement to reduce leakage waste. Experimental results on real and synthetic designs show that the efficiency and effectiveness of the proposed postplacement leakage reduction techniques.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W1969303161",
    "type": "article"
  },
  {
    "title": "Design intent coverage revisited",
    "doi": "https://doi.org/10.1145/1455229.1455238",
    "publication_date": "2009-01-01",
    "publication_year": 2009,
    "authors": "Arnab Sinha; Pallab Dasgupta; Bhaskar Pal; Sayantan Das; Prasenjit Basu; P. P. Chakrabarti",
    "corresponding_authors": "",
    "abstract": "Design intent coverage is a formal methodology for analyzing the gap between a formal architectural specification of a design and the formal functional specifications of the component RTL blocks of the design. In this article we extend the design intent coverage methodology to hybrid specifications containing both state-machines and formal properties. We demonstrate the benefits of this extension in two domains of considerable recent interest, namely (a) the use of auxiliary state-machines in formal specifications, and (b) the use of modest sized RTL blocks in the design intent coverage analysis.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W1973637973",
    "type": "article"
  },
  {
    "title": "Implementing the scale vector-thread processor",
    "doi": "https://doi.org/10.1145/1367045.1367050",
    "publication_date": "2008-07-01",
    "publication_year": 2008,
    "authors": "Ronny Krashinsky; Christopher Batten; Krste Asanović",
    "corresponding_authors": "",
    "abstract": "The Scale vector-thread processor is a complexity-effective solution for embedded computing which flexibly supports both vector and highly multithreaded processing. The 7.1-million transistor chip has 16 decoupled execution clusters, vector load and store units, and a nonblocking 32KB cache. An automated and iterative design and verification flow enabled a performance-, power-, and area-efficient implementation with two person-years of development effort. Scale has a core area of 16.6 mm 2 in 180 nm technology, and it consumes 400 mW--1.1 W while running at 260 MHz.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2004902140",
    "type": "article"
  },
  {
    "title": "C-testable bit parallel multipliers over <i>GF</i> (2 <sup> <i>m</i> </sup> )",
    "doi": "https://doi.org/10.1145/1297666.1297671",
    "publication_date": "2008-01-01",
    "publication_year": 2008,
    "authors": "Hafizur Rahaman; Jimson Mathew; Dhiraj K. Pradhan; Abusaleh Jabir",
    "corresponding_authors": "",
    "abstract": "We present a C-testable design of polynomial basis (PB) bit-parallel (BP) multipliers over GF(2 m ) for 100% coverage of stuck-at faults. Our design method also includes the method for test vector generation, which is simple and efficient. C-testability is achieved with three control inputs and approximately 6% additional hardware. Only 8 constant vectors are required irrespective of the sizes of the fields and primitive polynomial. We also present a Built-In Self-Test (BIST) architecture for generating the test vectors efficiently, which eliminates the need for the extra control inputs. Since these circuits have critical applications as parts of cryptography (e.g., Elliptic Curve Crypto (ECC) systems) hardware, the BIST architecture may provide with added level of security, as the tests would be done internally and without the requirement of probing by external testing equipment. Finally we present experimental results comprising the area, delay and power of the testable multipliers of various sizes with the help of the Synopsys® tools using UMC 0.18 micron CMOS technology library.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2018972938",
    "type": "article"
  },
  {
    "title": "Interrupt modeling for efficient high-level scheduler design space exploration",
    "doi": "https://doi.org/10.1145/1297666.1297676",
    "publication_date": "2008-01-01",
    "publication_year": 2008,
    "authors": "Franklin Johnson; JoAnn M. Paul",
    "corresponding_authors": "",
    "abstract": "Single Chip Heterogeneous Multiprocessors executing a wide variety of software are increasingly common in consumer electronics. Because of the mix of real-time and best effort software across the entire chip, a key design element of these systems is the choice of scheduling strategy. Without task migration, the benefits of single chip processing cannot be fully realized. Previously, high-level modeling environments have not been capable of modeling asynchronous events such as interrupts and preemptive scheduling while preserving the performance benefits of high level simulation. This paper shows how extensions to Modeling Environment for Software and Hardware (MESH) enable precise modeling of these asynchronous events while running more than 1000 faster than cycle-accurate simulation. We discuss how we achieved this and illustrate its use in modeling preemptive scheduling. We evaluate the potential of migrating running tasks between processors to improve performance in a multimedia cell phone example. We show that by allowing schedulers to rebalance processor loads as new tasks arrive significant performance gains can be achieved over statically partitioned and dynamic scheduling approaches. In our example, we show that system response time can be improved by as much as 1.96 times when a preemptive migratory scheduler is used, despite the overhead incurred by scheduling tasks across multiple processors and transferring state during the migration of running tasks. The contribution of this work is to provide a framework for evaluating preemptive scheduling policies and task migration in a high level simulator, by combining the new ability to model interrupts with dramatically increased efficiency in the high-level modeling of scheduling and commuincation MESH already provides.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2028084302",
    "type": "article"
  },
  {
    "title": "An energy characterization platform for memory devices and energy-aware data compression for multilevel-cell flash memory",
    "doi": "https://doi.org/10.1145/1367045.1367052",
    "publication_date": "2008-07-01",
    "publication_year": 2008,
    "authors": "Yongsoo Joo; Youngjin Cho; Donghwa Shin; Jaehyun Park; Naehyuck Chang",
    "corresponding_authors": "",
    "abstract": "Memory devices often consume more energy than microprocessors in current portable embedded systems, but their energy consumption changes significantly with the type of transaction, data values, and access timing, as well as depending on the total number of transactions. These variabilities mean that an innovative tool and framework are required to characterize modern memory devices running in embedded system architectures. We introduce an energy measurement and characterization platform for memory devices, and demonstrate an application to multilevel-cell (MLC) flash memories, in which we discover significant value-dependent programming energy variations. We introduce an energy-aware data compression method that minimizes the flash programming energy, rather than the size of the compressed data, which is formulated as an entropy coding with unequal bit-pattern costs. Deploying a probabilistic approach, we derive energy-optimal bit-pattern probabilities and expected values of the bit-pattern costs which are applicable to the large amounts of compressed data typically found in multimedia applications. Then we develop an energy-optimal prefix coding that uses integer linear programming, and construct a prefix-code table. From a consideration of Pareto-optimal energy consumption, we can make tradeoffs between data size and programming energy, such as a 41% energy savings for a 52% area overhead.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2030629640",
    "type": "article"
  },
  {
    "title": "SOC test-architecture optimization for the testing of embedded cores and signal-integrity faults on core-external interconnects",
    "doi": "https://doi.org/10.1145/1455229.1455233",
    "publication_date": "2009-01-01",
    "publication_year": 2009,
    "authors": "Qiang Xu; Yubin Zhang; Krishnendu Chakrabarty",
    "corresponding_authors": "",
    "abstract": "The test time for core-external interconnect shorts and opens is typically much less than that for core-internal logic. Therefore, prior work on test-infrastructure design for core-based system-on-a-chip (SOC) has mainly focused on minimizing the test time for core-internal logic. However, as feature sizes shrink for newer process technologies, the test time for signal integrity (SI) faults on interconnects cannot be neglected. The test time for SI faults can be comparable to, or even larger than, the test time for the embedded cores. We investigate the impact of interconnect SI tests on SOC test-architecture design and optimization. A compaction method for SI faults and algorithms for test-architecture optimization are also presented. Experimental results for the ITC'02 benchmarks show that the proposed approach can significantly reduce the overall testing time for core-internal logic and core-external interconnects.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2158004857",
    "type": "article"
  },
  {
    "title": "Formal Verification and Debugging of Precise Interrupts on High Performance Microprocessors",
    "doi": "https://doi.org/10.1145/2348839.2348841",
    "publication_date": "2012-10-01",
    "publication_year": 2012,
    "authors": "Bijan Alizadeh",
    "corresponding_authors": "Bijan Alizadeh",
    "abstract": "The increased parallelism provided by Out-Of-Order (OOO) and superscalar mechanisms have made the control portion of advanced processors more complicated so that the state-of-the-art formal verification techniques for Register-Transfer-Level (RTL) and gate-level designs cannot scale to the complexity of such complicated processors. Moreover, verification and debugging of exceptions and external interrupts on such processors are nontrivial tasks. Because the exceptions arrival time, the external interrupt arrival time, as well as the microprocessor response time must be precise, verification and debugging require sophisticated hardware and software capabilities. This article proposes techniques for effective verification and debugging of cycle-accurate OOO processors in the event of exceptions and external interrupts. The results show that our techniques reduce the complexity of the verification and debugging processes by reducing the number of simulation cycles (3.3 × average reduction) and the number of state variables (8.7 × average reduction) to be traced for localizing bugs.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W1968935964",
    "type": "article"
  },
  {
    "title": "Test compaction techniques for assertion-based test generation",
    "doi": "https://doi.org/10.1145/2534397",
    "publication_date": "2013-12-01",
    "publication_year": 2013,
    "authors": "Jason G. Tong; Marc Boulé; Željko Žilić",
    "corresponding_authors": "",
    "abstract": "Assertions are now widely used in verification as a means to help convey designer intent and also to simplify the detection of erroneous conditions by the firing of assertions. With this expressive modeling power, assertions could also be used for tasks such as helping to assess test coverage and even as a source for test generation. Our work deals with this last aspect, namely, assertion-based test generation. In this article, we present our compacted test generation scheme based on assertions. Novel compaction techniques are presented based on assertion clustering, test-path overlap detection and parallel-path removal. Our compaction approach is experimentally evaluated using nearly 300 assertions to show the amount of reduction that can be obtained in the size of the test sets. This ultimately has a positive impact on verification time in the quest for bugfree designs.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W1971159340",
    "type": "article"
  },
  {
    "title": "Low-power anti-aging zero skew clock gating",
    "doi": "https://doi.org/10.1145/2442087.2442098",
    "publication_date": "2013-03-01",
    "publication_year": 2013,
    "authors": "Shih-Hsu Huang; Wen-Pin Tu; Chia-Ming Chang; Song-Bin Pan",
    "corresponding_authors": "",
    "abstract": "In advanced CMOS technology, the NBTI (negative bias temperature instability) effect results in delay degradations of PMOS transistors. Further, because of clock gating, PMOS transistors in a clock tree often have different active probabilities, leading to different delay degradations. If the degradation difference is not properly controlled, this clock skew may cause the circuit fails to function at some point later in time. Intuitively, the degradation difference can be eliminated, if we increase the active probability of the low-probability clock gates to ensure the clock gates at the same level always having the same active probability. However, this intuitive method may suffer from large power consumption overhead. In this article, we point out, by carefully planning the transistor-level clock signal propagation path, we can have many clock gates whose active probabilities do not affect the degradation difference. Based on that observation, we propose a critical-PMOS-aware clock tree design methodology to eliminate the degradation difference with minimum power consumption overhead. Benchmark data consistently show our approach achieves very good results in terms of both the NBTI-induced clock skew (i.e., the degradation difference) and the power consumption overhead.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W1985539057",
    "type": "article"
  },
  {
    "title": "Concept-based partitioning for large multidomain multifunctional embedded systems",
    "doi": "https://doi.org/10.1145/1754405.1754407",
    "publication_date": "2010-05-01",
    "publication_year": 2010,
    "authors": "Waseem Ahmed; Douglas Myers",
    "corresponding_authors": "",
    "abstract": "Hardware-software partitioning is an important phase in embedded systems. Decisions made during this phase impact the quality, cost, performance, and the delivery date of the final product. Over the past decade or more, various partitioning approaches have been proposed. A majority operate at a relatively fine granularity and use a low-level executable specification as the starting point. This presents problems if the context is families of industrial products with frequent release of upgraded or new members. Managing complexity using a low-level specification is extremely challenging and impacts developer productivity. Designing using a high-level specification and component-based development, although a better option, imposes component integration and replacement problems during system evolution and new product release. A new approach termed Concept-Based Partitioning is presented that focuses on system evolution, product lines, and large-scale reuse when partitioning. Beginning with information from UML 2.0 sequence diagrams and a concept repository concepts are identified and used as the unit of partitioning within a specification. A methodology for the refinement of interpart communication in the system specification using sequence diagrams is also presented. Change localization during system evolution, composability during large-scale reuse, and provision for configurable feature variations for a product line are facilitated by a Generic Adaptive Layer (GAL) around selected concepts. The methodology was applied on a subsystem of an Unmanned Aerial Vehicle (UAV) using various concepts which improved the composability of concepts while keeping performance and size overhead within the 2% range.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W1990415661",
    "type": "article"
  },
  {
    "title": "Energy-Efficient Progressive Remote Update for Flash-Based Firmware of Networked Embedded Systems",
    "doi": "https://doi.org/10.1145/1870109.1870116",
    "publication_date": "2010-11-01",
    "publication_year": 2010,
    "authors": "Jin-Sik Kim; Pai H. Chou",
    "corresponding_authors": "",
    "abstract": "Firmware update over a network connection is an essential but expensive feature for many embedded systems due to not only the relatively high power consumption and limited bandwidth, but also page-granular erasure before rewriting to flash memory. This work proposes a page-level, link-time technique that minimizes not only the size of patching scripts but also perturbation to the firmware memory, over the entire sequence of updates in the system’s lifetime. We propose a tool that first clusters functions to minimize caller-callee dependency across pages, and then orders the functions within each page to minimize intrapage perturbation. Experimental results show our technique to reduce the energy consumption of firmware update by 30--42% over the state-of-the-art. Most importantly, this is the first work that has ever shown to evolve well over 41 revisions of a real-world open-source real-time operating system.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2035939328",
    "type": "article"
  },
  {
    "title": "Statistical Soft Error Rate (SSER) Analysis for Scaled CMOS Designs",
    "doi": "https://doi.org/10.1145/2071356.2071365",
    "publication_date": "2012-01-01",
    "publication_year": 2012,
    "authors": "Huan-Kai Peng; Hsuan-Ming Huang; Yu‐Hsin Kuo; Charles H.‐P. Wen",
    "corresponding_authors": "",
    "abstract": "This article re-examines the soft error effect caused by radiation-induced particles beyond the deep submicron regime. Considering the impact of process variations, voltage pulse widths of transient faults are found no longer monotonically diminishing after propagation, as they were formerly. As a result, the soft error rates in scaled electronic designs escape traditional static analysis and are seriously underestimated. In this article we formulate the statistical soft error rate (SSER) problem and present two frameworks to cope with the aforementioned sophisticated issues. The table-lookup framework captures the change of transient-fault distributions implicitly by using a Monte-Carlo approach, whereas the SVR-learning framework does the task explicitly by using statistical learning theory. Experimental results show that both frameworks can more accurately estimate SERs than static approaches do. Meanwhile, the SVR-learning framework outperforms the table-lookup framework in both SER accuracy and runtime.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2037022090",
    "type": "article"
  },
  {
    "title": "Fast Statistical Full-Chip Leakage Analysis for Nanometer VLSI Systems",
    "doi": "https://doi.org/10.1145/2348839.2348855",
    "publication_date": "2012-10-01",
    "publication_year": 2012,
    "authors": "Ruijing Shen; Sheldon X.-D. Tan; Hai Wang; Jinjun Xiong",
    "corresponding_authors": "",
    "abstract": "In this article, we present a new full-chip statistical leakage estimation considering the spatial correlation condition (strong or weak). The new algorithm can deliver linear time, O ( N ), time complexity, where N is the number of grids on chip. The proposed algorithm adopts a set of uncorrelated virtual variables over grid cells to represent the original physical random variables and the cell size is determined by the spatial correlation length. In this way, each physical variable is always represented by virtual variables locally. We prove the number of neighbor cells for each grid cell is not related to the condition of spatial correlation (from no correlation to 100% correlated), which leads to linear time complexity in terms of number of gates. We compute the gate leakage by the orthogonal polynomials-based collocation method. The total leakage of a whole chip can be computed by simply summing up the coefficients of corresponding orthogonal polynomials in each grid cell. Furthermore, we develop a look-up table to cache statistical information for each type of gate instead of calculating leakage for every single instance of gate on a chip. As a result, a new statistical leakage characterization in Standard Cell Library (SCL) is put forward. Furthermore, an incremental analysis algorithm is proposed to update the chip-level statistical leakage information efficiently after a few changes are made. The proposed method has no restrictions on static leakage models, or types of leakage distributions. The large circuit examples in 45nm CMOS process demonstrate the proposed algorithm is 1000X faster than a recently proposed grid-based method with similar accuracy and many orders of magnitude times speedup over the Monte Carlo method. Experimental results also show the incremental analysis provides about 10X further speedup. We expect the incremental analysis could achieve more speedup over the full leakage analysis for larger problem sizes.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2083347118",
    "type": "article"
  },
  {
    "title": "Scan-Cell Reordering for Minimizing Scan-Shift Power Based on Nonspecified Test Cubes",
    "doi": "https://doi.org/10.1145/1870109.1870119",
    "publication_date": "2010-11-01",
    "publication_year": 2010,
    "authors": "Yu-Ze Wu; Mango C.-T. Chao",
    "corresponding_authors": "",
    "abstract": "This article presents several scan-cell reordering techniques to reduce the signal transitions during the test mode while preserving the don’t-care bits in the test patterns for a later optimization. Combined with a pattern-filling technique, the proposed scan-cell reordering techniques can utilize both high response correlations and pattern correlations to simultaneously minimize scan-out and scan-in transitions. Those scan-shift transitions can be further reduced by selectively using the inverse connections between scan cells. In addition, the trade-off between routing overhead and power consumption can also be controlled by the proposed scan-cell reordering techniques. A series of experiments are conducted to demonstrate the effectiveness of each of the proposed techniques individually.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2105182247",
    "type": "article"
  },
  {
    "title": "Postplacement Voltage Island Generation",
    "doi": "https://doi.org/10.1145/2071356.2071360",
    "publication_date": "2012-01-01",
    "publication_year": 2012,
    "authors": "Mario K. Y. Leung; Eric K. I. Chio; Evangeline F. Y. Young",
    "corresponding_authors": "",
    "abstract": "High power consumption will not only shorten the battery life of handheld devices, but also cause thermal and reliability problems. To lower power consumption, one way is to reduce the supply voltage as in multisupply voltage (MSV) designs. In region-based MSV, a circuit will be partitioned into “voltage islands” where each island occupies a contiguous physical space and operates at one supply voltage. In the work of Wu et al. [2005], this voltage supply problem is addressed, and the input placement is partitioned into a set of rectangular voltage islands by a slicing structure. However, the constraint of using a slicing structure prohibits better solutions in their approach. In the work of Ching et al. [2006], the constraint of obtaining rectangular shapes is relaxed; their method forms islands of very irregular shapes. In this article, we propose a method that focuses on forming rectangular voltage islands to minimize the power consumption, while at the same time favoring the power routing step. It is found that, even with this reduced flexibility on island shapes, we can still perform as well as, or in some cases, even better than the previous work of Ching et al. [2006] that does not control the shapes of the islands, in terms of power saving and island number.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2115256077",
    "type": "article"
  },
  {
    "title": "Common-source-line array",
    "doi": "https://doi.org/10.1145/2500459",
    "publication_date": "2013-10-01",
    "publication_year": 2013,
    "authors": "Bo Zhao; Jun Yang; Youtao Zhang; Yiran Chen; Hai Li",
    "corresponding_authors": "",
    "abstract": "Traditional array organization of bipolar nonvolatile memories such as STT-MRAM and memristor utilizes two bitlines for cell manipulations. With technology scaling, such bitline pair will soon become the bottleneck for further density improvement. In this article we propose a novel common-source-line array architecture, which uses a shared source-line along the row, leaving only one bitline per column. We elaborate the array design to ensure reliability, and demonstrate its effectiveness on STT-MRAM and memristor memory arrays. Our study results show that with comparable latency and energy, the proposed common-source-line array can save 34% and 33% area for Memristor-RAM and STT-MRAM respectively, compared with corresponding dual-bitline arrays.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2140017980",
    "type": "article"
  },
  {
    "title": "Training Fixed-Point Classifiers for On-Chip Low-Power Implementation",
    "doi": "https://doi.org/10.1145/3057275",
    "publication_date": "2017-06-09",
    "publication_year": 2017,
    "authors": "Hassan Albalawi; Yuanning Li; Xin Li",
    "corresponding_authors": "",
    "abstract": "In this article, we develop several novel algorithms to train classifiers that can be implemented on chip with low-power fixed-point arithmetic with extremely small word length. These algorithms are based on Linear Discriminant Analysis (LDA), Support Vector Machine (SVM), and Logistic Regression (LR), and are referred to as LDA-FP, SVM-FP, and LR-FP, respectively. They incorporate the nonidealities (i.e., rounding and overflow) associated with fixed-point arithmetic into the offline training process so that the resulting classifiers are robust to these nonidealities. Mathematically, LDA-FP, SVM-FP, and LR-FP are formulated as mixed integer programming problems that can be robustly solved by the branch-and-bound methods described in this article. Our numerical experiments demonstrate that LDA-FP, SVM-FP, and LR-FP substantially outperform the conventional approaches for the emerging biomedical applications of brain decoding.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2624507639",
    "type": "article"
  },
  {
    "title": "Time-Triggered Scheduling of Mixed-Criticality Systems",
    "doi": "https://doi.org/10.1145/3073415",
    "publication_date": "2017-06-15",
    "publication_year": 2017,
    "authors": "Lalatendu Behera; Purandar Bhaduri",
    "corresponding_authors": "",
    "abstract": "Real-time and embedded systems are moving from the traditional design paradigm to integration of multiple functionalities onto a single computing platform. Some of the functionalities are safety critical and subject to certification. The rest of the functionalities are nonsafety critical and do not need to be certified. Designing efficient scheduling algorithms which can be used to meet the certification requirement is challenging. Our research considers the time-triggered approach to scheduling of mixed-criticality jobs with two criticality levels. The first proposed algorithm for the time-triggered approach is based on the OCBP scheduling algorithm which finds a fixed-priority order of jobs. Based on this priority order, the existing algorithm constructs two scheduling tables S LO oc and S HI oc . The scheduler uses these tables to find a scheduling strategy. Another time-triggered algorithm called MCEDF was proposed as an improvement over the OCBP-based algorithm. Here we propose an algorithm which directly constructs two scheduling tables without using a priority order. Furthermore, we show that our algorithm schedules a strict superset of instances which can be scheduled by the OCBP-based algorithm as well as by MCEDF. We show that our algorithm outperforms both the OCBP-based algorithm and MCEDF in terms of the number of instances scheduled in a randomly generated set of instances. We generalize our algorithm for jobs with m criticality levels. Subsequently, we extend our algorithm to find scheduling tables for periodic and dependent jobs. Finally, we show that our algorithm is also applicable to mixed-criticality synchronous programs upon uniprocessor platforms and schedules a bigger set of instances than the existing algorithm.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2624842433",
    "type": "article"
  },
  {
    "title": "Test Modification for Reduced Volumes of Fail Data",
    "doi": "https://doi.org/10.1145/3065925",
    "publication_date": "2017-06-13",
    "publication_year": 2017,
    "authors": "Irith Pomeranz; M. Enamul Amyeen; Srikanth Venkataraman",
    "corresponding_authors": "",
    "abstract": "As part of a yield improvement process, fail data is collected from faulty units. Several approaches exist for reducing the tester time and the volume of fail data that needs to be collected based on the observation that a subset of the fail data is sufficient for accurate defect diagnosis. This article addresses the volume of fail data by considering the test set that is used for collecting fail data. It observes that certain faults from a set of target faults produce significantly larger numbers of faulty output values (and therefore significantly larger volumes of fail data) than other faults under a given test set. Based on this observation, it describes a procedure for modifying the test set to reduce the maximum number of faulty output values that a target fault produces. When defects are considered in a simulation experiment, and a defect diagnosis procedure is applied to the fail data that they produce, two effects are observed: the maximum and average numbers of faulty output values per defect are reduced significantly with the modified test set, and the quality of diagnosis is similar or even improved with the modified test set.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2626938262",
    "type": "article"
  },
  {
    "title": "Two-Stage Layout Decomposition for Hybrid E-Beam and Triple Patterning Lithography",
    "doi": "https://doi.org/10.1145/3084683",
    "publication_date": "2017-08-01",
    "publication_year": 2017,
    "authors": "Xingquan Li; Wenxing Zhu",
    "corresponding_authors": "",
    "abstract": "Hybrid e-beam lithography (EBL) and triple patterning lithography (TPL) are advanced technologies for the manufacture of integrated circuits. We propose a technology that combines the advantages of EBL and TPL, which is more promising for the pattern product industry. Layout decomposition is a crucial step in this technology. In this article, we propose a two-stage decomposition flow for the hybrid e-beam and triple patterning lithography of the general layout decomposition (HETLD) problem. At the first stage, we formulate two optimization problems: the e-beam and stitch-aware TPL mask assignment (ESTMA) problem and the extended minimum weight dominating set for R 4 mask assignment (MDS R 4 MA) problem. Binary linear program formulations of the two problems are solved by the cutting plane approach. At the second stage, solutions of the first stage problems are legalized to feasible solutions of the HETLD problem by stitch insertion and e-beam shot. To speed up decomposition, we reduce the problem size by removing some vertices and some minor conflict edges before decomposition. Experimental results show the effectiveness of our decomposition methods based on ESTMA and MDS R 4 MA.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2740204001",
    "type": "article"
  },
  {
    "title": "Selection of Critical Paths for Reliable Frequency Scaling under BTI-Aging Considering Workload Uncertainty and Process Variations Effects",
    "doi": "https://doi.org/10.1145/3177864",
    "publication_date": "2018-02-23",
    "publication_year": 2018,
    "authors": "Andres Gomez; Victor Champac",
    "corresponding_authors": "",
    "abstract": "Conventional clock guardbanding to assure a circuit’s reliable operation under device aging due to NBTI/PBTI and process variations introduce significant performance loss in modern nanometer circuits. Dynamic Frequency Scaling (DFS) is a more efficient technique that allows us to adjust the system clock frequency according to the process condition and aging deterioration of the circuit. At the design phase, the DFS technique requires the identification of the logic paths to be monitored to introduce the required circuitry to monitor their delay. However, critical path identification is a complex problem due to three major challenges: (1) The critical paths of the circuit depend on the stress duty cycle of the devices, which are unknown in advance at design phase; (2) the critical paths of the circuit depend on the process parameters variations, whose impact on delay depend on the spatial correlation due to proximity at the circuit layout; and (3) the critical paths reordering probability may change over time due to aging. This article presents a methodology for efficient selection of the critical paths to be monitored under a DFS framework, addressing the aforementioned challenges. Experimental results on ISCAS 85/89 benchmark circuits show the feasibility of the proposed approach to select a restricted path set while providing reliable aging monitoring.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2794328362",
    "type": "article"
  },
  {
    "title": "Graph-Grammar-Based IP-Integration (GRIP)—An EDA Tool for Software-Defined SoCs",
    "doi": "https://doi.org/10.1145/3139381",
    "publication_date": "2018-04-11",
    "publication_year": 2018,
    "authors": "Munish Jassi; Yong Hu; Daniel Mueller-Gritschneder; Ulf Schlichtmann",
    "corresponding_authors": "",
    "abstract": "In modern system-on-chip (SoC) designs, IP-reuse is considered a driving force to increase productivity. To support various designs, a huge amount of Intellectual Property (IP) hardware blocks have been developed. The integration of those IPs into an SoC may require significant effort—up to days or weeks depending on experience and complexity. This article presents a novel approach to significantly reduce the design effort to bring-up a working SoC design by automatic IP integration as part of a library-based Software-defined SoC flow. In detail, the IP-supplier prepares a HW-accelerated software library (HASL) for the SoC architect, who wants to use the IP in an SoC design. As a key point of our approach, integration knowledge is encoded in the library as a set of integration rules. These rules are defined in the machine-readable standardized IP-XACT format by the IP supplier, who has a good knowledge of the IP’s hardware details. The library preparation step on the IP supplier’s side is also partly automated in the proposed flow, including a partial generation of configurable HW drivers, schedulers, and the software library functions. For the SoC architect, we have developed the graph-grammar-based IP-integration (GRIP) tool. The software application is developed using the functions supplied in the HASL. According to the calls to the HASL functions, the GRIP tool automatically integrates IP-blocks using the rule information supplied with the library and runs a full Design Space Exploration. For this, the SoC architecture and rules are transformed into the graph domain to apply graph rewriting methods. The GRIP tool is model-driven and based on the Eclipse Modeling Framework. With code generation techniques, SoC candidate architectures can be transformed to hardware descriptions for the target platform. The HW/SW interfaces between SW library functions and IP blocks can be automatically generated for bare-metal or Linux-based applications. The approach is demonstrated with two case-studies on the Xilinx Zynq-based ZedBoard evaluation board using a HASL for computer vision. It can yield 10×-150× performance improvement for the bare-metal application versions and 4×--7× performance improvement for the Linux-based application versions, when executed on an optimized HW-accelerated SoC architecture compared to a non HW-accelerated SoC. The effort for IP integration is comparable to using a software library, hence, providing a significant advantage over a manual IP integration.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2798176432",
    "type": "article"
  },
  {
    "title": "Detection Mechanisms for Unauthorized Wireless Transmissions",
    "doi": "https://doi.org/10.1145/3241046",
    "publication_date": "2018-11-06",
    "publication_year": 2018,
    "authors": "Doohwang Chang; Ganapati Bhat; Ümit Y. Ogras; Bertan Bakkaloğlu; Sule Ozev",
    "corresponding_authors": "",
    "abstract": "With increasing diversity of supply chains from design to delivery, there is an increasing risk that unauthorized changes can be made within an IC. One of the motivations for this type of change is to learn important information (such as encryption keys, spreading codes) from the hardware, and transmit this information to a malicious party. To evade detection, such unauthorized communication can be hidden within legitimate bursts of transmit signal. In this article, we present several signal processing techniques to detect unauthorized transmissions which can be hidden within the legitimate signal. We employ a scheme where the legitimate transmission is configured to emit a single sinusoidal waveform. We use time and spectral domain analysis techniques to explore the transmit spectrum. Since every transmission, no matter how low the signal power is, must have a spectral signature, we identify unauthorized transmission by eliminating the desired signal from the spectrum after capture. Experiment results show that when spread spectrum techniques are used, the presence of an unauthorized signal can be determined without the need for decoding the malicious signal. The proposed detection techniques need to be used as enhancements to the regular testing and verification procedures if hardware security is a concern.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2900352848",
    "type": "article"
  },
  {
    "title": "Remote Detection of Unauthorized Activity via Spectral Analysis",
    "doi": "https://doi.org/10.1145/3276770",
    "publication_date": "2018-11-28",
    "publication_year": 2018,
    "authors": "Fatih Karabacak; Ümit Y. Ogras; Sule Ozev",
    "corresponding_authors": "",
    "abstract": "Unauthorized hardware or firmware modifications, known as trojans, can steal information, drain the battery, or damage IoT devices. Since trojans may be triggered in the field at an unknown instance, it is important to detect their presence at runtime. However, it is difficult to run sophisticated detection algorithms on these devices due to limited computational power and energy and, in some cases, lack of accessibility. This article presents a stand-off self-referencing technique for detecting unauthorized activity. The proposed technique processes involuntary electromagnetic emissions on a separate hardware, which is physically decoupled from the device under test. When the device enters the test mode , a predefined test application is run on the device repetitively for a known period. The periodicity ensures that the spectral electromagnetic power of the test application concentrates at known frequencies, leaving the remaining frequencies within the operating bandwidth at the noise level. Any deviations from the noise level for these unoccupied frequency locations indicate the presence of unknown (unauthorized) activity. Hence, we are able to differentiate trojan activity without using a golden reference , or any knowledge of the attributes of the trojan activity. Experiments based on hardware measurements show that the proposed technique achieves close to 100% detection accuracy at up to 120cm distance.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2902622436",
    "type": "article"
  },
  {
    "title": "Knowledge- and Simulation-Based Synthesis of Area-Efficient Passive Loop Filter Incremental Zoom-ADC for Built-In Self-Test Applications",
    "doi": "https://doi.org/10.1145/3266227",
    "publication_date": "2018-12-21",
    "publication_year": 2018,
    "authors": "Osman Emir Erol; Sule Ozev",
    "corresponding_authors": "",
    "abstract": "We propose a fully differential, synthesizable zoom-ADC architecture with a passive loop filter for low-frequency Built-In Self-Test (BIST) applications, along with a synthesis tool that can target various design specifications. We present the detailed ADC architecture and a step-by-step process for designing the zoom-ADC. The design flow does not rely on the extensive knowledge of an experienced ADC designer. Two ADCs have been synthesized with different performance requirements in the 65nm CMOS process. The first ADC achieves a 90.4dB Signal-to-Noise Ratio (SNR) in 512μs measurement time and consumes 17μW power. The second design achieves a 78.2dB SNR in 31.25μs measurement time and consumes 63μW power.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2905668108",
    "type": "article"
  },
  {
    "title": "Automatic Optimization of the VLAN Partitioning in Automotive Communication Networks",
    "doi": "https://doi.org/10.1145/3278120",
    "publication_date": "2018-12-21",
    "publication_year": 2018,
    "authors": "Fedor Smirnov; Felix Reimann; Jürgen Teich; Michael Glaß",
    "corresponding_authors": "",
    "abstract": "Dividing the communication network into so-called Virtual Local Area Networks (VLANs), i.e., subnetworks that are isolated at the data link layer (OSI layer 2), is a promising approach to address the increasing security challenges in automotive networks. The automation of the VLAN partitioning is a well-researched problem in the domain of local or metropolitan area networks. However, the approaches used there are hardly applicable for the design of automotive networks as they mainly focus on reducing the amount of broadcast traffic and cannot capture the many design objectives of automotive networks like the message timing or the link load, which are affected by the VLAN partitioning. As a remedy, this article proposes an approach based on a set of Pseudo-Boolean constraints to generate a message routing which is feasible with respect to the VLAN-related routing restrictions in automotive networks. This approach can be used for a design space exploration to optimize not only the VLAN partitioning but also other routing-related objectives. We demonstrate both the efficiency of our message routing approach and the now accessible optimization potential for the complete Electric/Electronic architecture with a mixed-criticality system from the automotive domain. There we thoroughly investigate the impact of the VLAN partitioning on the message timing and the link loads by optimizing these design objectives concurrently. During the exploration of the huge design space, where each resource can be assigned to one of four VLANs, our approach requires less than 40ms for the creation of a valid solution and ensures that all messages satisfy their deadlines and link load bounds.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2905833125",
    "type": "article"
  },
  {
    "title": "Share-n-Learn",
    "doi": "https://doi.org/10.1145/3318044",
    "publication_date": "2019-04-22",
    "publication_year": 2019,
    "authors": "Seyed Ali Rokni; Hassan Ghasemzadeh",
    "corresponding_authors": "",
    "abstract": "Wearable sensors utilize machine learning algorithms to infer important events such as the behavioral routine and health status of their end users from time-series sensor data. A major obstacle in large-scale utilization of these systems is that the machine learning algorithms cannot be shared among users or reused in contexts different from the setting in which the training data are collected. As a result, the algorithms need to be retrained from scratch in new sensor contexts, such as when the on-body location of the wearable sensor changes or when the system is utilized by a new user. The retraining process places significant burden on end users and system designers to collect and label large amounts of training sensor data. In this article, we challenge the current algorithm training paradigm and introduce Share-n-Learn to automatically detect and learn physical sensor contexts from a repository of shared expert models without collecting any new labeled training data. Share-n-Learn enables system designers and end users to seamlessly share and reuse machine learning algorithms that are trained under different contexts and data collection settings. We develop algorithms to autonomously identify sensor contexts and propose a gating function to automatically activate the most accurate machine learning model among the set of shared expert models. We assess the performance of Share-n-Learn for activity recognition when a dynamic sensor constantly migrates from one body location to another. Our analysis based on real data collected with human subjects on three datasets demonstrates that Share-n-Learn achieves, on average, 68.4% accuracy in detecting physical activities with context-varying wearables. This accuracy performance is about 19% more than ‘majority voting,’ 10% more than the state-of-the-art transfer learning, and only 8% less than the experimental upper bound.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2941525771",
    "type": "article"
  },
  {
    "title": "Energy Efficient Chip-to-Chip Wireless Interconnection for Heterogeneous Architectures",
    "doi": "https://doi.org/10.1145/3340109",
    "publication_date": "2019-07-26",
    "publication_year": 2019,
    "authors": "Sri Harsha Gade; M Meraj Ahmed; Sujay Deb; Amlan Ganguly",
    "corresponding_authors": "",
    "abstract": "Heterogeneous multichip architectures have gained significant interest in high-performance computing clusters to cater to a wide range of applications. In particular, heterogeneous systems with multiple multicore CPUs, GPUs, and memory have become common to meet application requirements. The shared resources like interconnection network in such systems pose significant challenges due to the diverse traffic requirements of CPUs and GPUs. Especially, the performance and energy consumption of inter-chip communication have remained a major bottleneck due to limitations imposed by off-chip wired links. To overcome these challenges, we propose a wireless interconnection network to provide energy-efficient, high-performance communication in heterogeneous multi-chip systems. Interference-free communication between GPUs and memory modules is achieved through directional wireless links, while omnidirectional wireless interfaces connect cores in the CPUs with other components in the system. Besides providing low-energy, high-bandwidth inter-chip communication, the wireless interconnection scales efficiently with system size to provide high performance across multiple chips. The proposed inter-chip wireless interconnection is evaluated on two system sizes with multiple CPU and multiple GPU chips, along with main memory modules. On a system with 4 CPU and 4 GPU chips, application runtime is sped up by 3.94×, packet energy is reduced by 94.4%, and packet latency is reduced by 58.34% as compared to baseline system with wired inter-chip interconnection.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2965267251",
    "type": "article"
  },
  {
    "title": "Automatic Stage-form Circuit Reduction for Multistage Opamp Design Equation Generation",
    "doi": "https://doi.org/10.1145/3363499",
    "publication_date": "2019-10-31",
    "publication_year": 2019,
    "authors": "Guoyong Shi",
    "corresponding_authors": "Guoyong Shi",
    "abstract": "An automatic stage-form circuit reduction method for multistage operational amplifiers (opamps) is proposed. A tool based on this method can reduce a multistage opamp into a condensed stage-form macromodel, from which design equations can be generated automatically by another existing symbolic program. The proposed model generation method is fully symbolic; namely, it does not make reference to any numerical device values with a circuit, hence it does not require circuit biasing and sizing at an early design stage. The parameters coming with the generated models are dominant-effect approximation of the stage-related characteristics of the original circuits and thus are visually readable for design reasoning. Compensations in the original circuits are extracted automatically and reserved in the macromodel circuits. The user of this tool is only required to input the circuit stage information by identifying several key devices in the original circuits. As design equations can also be automatically generated from stage-form macromodels by a purely symbolic method, the proposed model generation method completes the path from a transistor-level opamp circuit to its characteristic design equations in a completely formal way. Examples are provided to demonstrate the effectiveness of the proposed model generation method, and numerical validation is further carried out to verify that the reduced symbolic models can successfully capture the key circuit behavior in the frequency domain for multistage opamps.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2986016996",
    "type": "article"
  },
  {
    "title": "Search-space Decomposition for System-level Design Space Exploration of Embedded Systems",
    "doi": "https://doi.org/10.1145/3369388",
    "publication_date": "2020-01-10",
    "publication_year": 2020,
    "authors": "Valentina Richthammer; Fabian Ewald Fassnacht; Michael Glaß",
    "corresponding_authors": "",
    "abstract": "The development of large-scale multi- and many-core platforms and the rising complexity of embedded applications have led to a significant increase in the number of implementation possibilities for a single application. Furthermore, rising demands on safe, energy-efficient, or real-time capable application execution make the problem of determining feasible implementations that are optimal with respect to such design objectives even more of a challenge. State-of-the-art Design Space Exploration (DSE) techniques for this problem demonstrably suffer from the vast and sparse search spaces posed by modern embedded systems, emphasizing the need for novel design methodologies in this field. Based on the idea of reducing problem complexity by a suitable decomposition of the system specification—in particular, by a reduction of target architecture or task mapping options—the work at hand proposes a portfolio of dynamic decomposition mechanisms that automatically decompose any system specification based on a short pre-exploration of the complete system. We present a two-phase approach consisting of (a) a set of novel data extraction and representation techniques combined with (b) a selection of filtering operations that automatically extract a decomposed system specification based on information gathered during pre-exploration. In particular, we employ heat map data structures and threshold as well as graph-partitioning filters to reduce problem complexity. The proposed decomposition procedure can seamlessly be integrated in any DSE flow, constituting a flexible extension for existing DSE approaches. Furthermore, it improves existing static decomposition techniques and other heuristics relying on information about the problem instance, since systems with irregular architectural topology or distribution of resource types can now be decomposed based on an automatic, problem-independent pre-exploration phase. We illustrate the efficiency of the proposed decomposition portfolio applied to state-of-the-art DSEs for many-core systems as well as networked embedded systems from the automotive domain. Experimental results show significant increases in optimization quality of up to 87% within constant DSE time compared to existing approaches.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2998789021",
    "type": "article"
  },
  {
    "title": "Hardware Trojan Mitigation in Pipelined MPSoCs",
    "doi": "https://doi.org/10.1145/3365578",
    "publication_date": "2020-01-15",
    "publication_year": 2020,
    "authors": "Amin Malekpour; Roshan Ragel; Tuo Li; Haris Javaid; Aleksandar Ignjatović; Sri Parameswaran",
    "corresponding_authors": "",
    "abstract": "Multiprocessor System-on-Chip (MPSoC) has become necessary due to the the billions of transistors available to the designer, the need for fast design turnaround times, and the power wall. Thus, present embedded systems are designed with MPSoCs, and one possible way MPSoCs can be realized is through Pipelined MPSoC (PMPSoC) architectures, which are used in applications from video surveillance to cryptosystems. Hardware Trojans (HTs) on PMPSoCs are a significant concern due to the damage caused by their stealth. An adversary could use HTs to extract secret information (data leakage) to modify functionality/data (functional modification) or make PMPSoCs deny service. In this article, we present PMPGuard, a mechanism that (1) detects the presence of hardware Trojans in Third Party Intellectual Property (3PIP) cores of PMPSoCs by continuous monitoring and testing and (2) recovers the system by switching the infected processor core with another one. We designed, implemented, and tested the system on a commercial cycle accurate multiprocessor simulation environment. Compared to the state-of-the-art system-level techniques that use Triple Modular Redundancy (TMR) and therefore incur at least 3× area and power overheads, our proposed system incurs about 2× area and 1.5× power overheads without any adverse impact on throughput.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2999348527",
    "type": "article"
  },
  {
    "title": "LBNoC",
    "doi": "https://doi.org/10.1145/3365994",
    "publication_date": "2020-01-15",
    "publication_year": 2020,
    "authors": "Khyamling Parane; Prabhu Prasad B M; Basavaraj Talawar",
    "corresponding_authors": "",
    "abstract": "An FPGA-based Network-on-Chip (NoC) using a low-latency router with a look-ahead bypass (LBNoC) is discussed in this article. The proposed design targets the optimized area with improved network performance. The techniques such as single-cycle router bypass, adaptive routing module, parallel Virtual Channel (VC), and Switch allocation, combined virtual cut through and wormhole switching, have been employed in the design of the LBNoC router. The LBNoC router is parameterizable with the network topology, traffic patterns, routing algorithms, buffer depth, buffer width, number of VCs, and I/O ports being configurable. A table-based routing algorithm has been employed to support the design of custom topologies. The input buffer modules of NoC router have been mapped on the FPGA Block RAM hard blocks to utilize resources efficiently. The LBNoC architecture consumes 4.5% and 27.1% fewer hardware resources than the ProNoC and CONNECT NoC architectures. The average packet latency of the LBNoC NoC architecture is 30% and 15% lower than the CONNECT and ProNoC architectures. The LBNoC architecture is 1.15× and 1.18× faster than the ProNoC and CONNECT NoC frameworks.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2999896544",
    "type": "article"
  },
  {
    "title": "Security of Microfluidic Biochip",
    "doi": "https://doi.org/10.1145/3382127",
    "publication_date": "2020-04-21",
    "publication_year": 2020,
    "authors": "Huili Chen; Seetal Potluri; Farinaz Koushanfar",
    "corresponding_authors": "",
    "abstract": "With the advancement of system miniaturization and automation, Lab-on-a-Chip (LoC) technology has revolutionized traditional experimental procedures. Microfluidic Biochip (MFB) is an emerging branch of LoC with wide medical applications such as DNA sequencing, drug delivery, and point of care diagnostics. Due to the critical usage of MFBs, their security is of great importance. In this article, we exploit the vulnerabilities of two types of MFBs: Flow-based Microfluidic Biochip (FMFB) and Digital Microfluidic Biochip (DMFB). We propose a systematic framework for applying Reverse Engineering (RE) attacks and Hardware Trojan (HT) attacks on MFBs as well as for practical countermeasures against the proposed attacks. We evaluate the attacks and defense on various benchmarks where experimental results prove the effectiveness of our methods. Security metrics are defined to quantify the vulnerability of MFBs. The overhead and performance of the proposed attacks as well as countermeasures are also discussed.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W3022748741",
    "type": "article"
  },
  {
    "title": "Lagrangian Relaxation-Based Time-Division Multiplexing Optimization for Multi-FPGA Systems",
    "doi": "https://doi.org/10.1145/3377551",
    "publication_date": "2020-02-03",
    "publication_year": 2020,
    "authors": "Chak-Wa Pui; Evangeline F. Y. Young",
    "corresponding_authors": "",
    "abstract": "&lt;?tight?&gt;To increase the resource utilization in multi-FPGA (field-programmable gate array) systems, time-division multiplexing (TDM) is a widely used technique to accommodate a large number of inter-FPGA signals. However, with this technique, the delay imposed by the inter-FPGA connections becomes significant. Previous research has shown that the TDM ratios of signals can greatly affect the performance of a system. In this article, to minimize the system clock period and support more practical constraints in modern multi-FPGA systems, we propose an analytical framework to optimize the TDM ratios of inter-FPGA nets. A Lagrangian relaxation-based method first gives a continuous result under relaxed constraints. A binary search--based discretization algorithm is then used to assign the TDM ratio of each net such that the resulting maximum displacement is optimal and all the constraints are satisfied. Finally, a swapping-based post refinement is performed to further optimize the TDM ratios. For comparison, we also solve the problem using linear programming (LP)--based methods, which have guaranteed error bounds to the optimal solutions. Experimental results show that our framework can achieve similar quality with much shorter runtime compared to the LP-based methods. Moreover, our framework scales for designs with over 45,000 inter-FPGA nets while the runtime and memory usage of the LP-based methods will increase dramatically as the design scale becomes larger.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W3034300466",
    "type": "article"
  },
  {
    "title": "Fine-grained Adaptive Testing Based on Quality Prediction",
    "doi": "https://doi.org/10.1145/3385261",
    "publication_date": "2020-07-07",
    "publication_year": 2020,
    "authors": "Mengyun Liu; Renjian Pan; Fangming Ye; Xin Li; Krishnendu Chakrabarty; Xinli Gu",
    "corresponding_authors": "",
    "abstract": "The ever-increasing complexity of integrated circuits inevitably leads to high test cost. Adaptive testing provides an effective solution for test-cost reduction; this testing framework selects the important test items for each set of chips. However, adaptive testing methods designed for digital circuits are coarse-grained, and they are targeted only at systematic defects. To incorporate fabrication variations and random defects in the testing framework, we propose a fine-grained adaptive testing method based on machine learning. We use the parametric test results from the previous stages of test to train a quality-prediction model for use in subsequent test stages. Next, we partition a given lot of chips into two groups based on their predicted quality. A test-selection method based on statistical learning is applied to the chips with high predicted quality. An ad hoc test-selection method is proposed and applied to the chips with low predicted quality. Experimental results using a large number of fabricated chips and the associated test data show that to achieve the same defect level as in prior work on adaptive testing, the fine-grained adaptive testing method reduces test cost by 90% for low-quality chips and up to 7% for all the chips in a lot.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W3041786383",
    "type": "article"
  },
  {
    "title": "Robust Multi-Target Sample Preparation on MEDA Biochips Obviating Waste Production",
    "doi": "https://doi.org/10.1145/3414061",
    "publication_date": "2020-10-22",
    "publication_year": 2020,
    "authors": "Sudip Poddar; Tapalina Banerjee; Robert Wille; Bhargab B. Bhattacharya",
    "corresponding_authors": "",
    "abstract": "Digital microfluidic biochips have fueled a paradigm shift in implementing bench-top laboratory experiments on a single tiny chip, thus replacing costly and bulky equipment. However, because of imprecise fluidic functions, several volumetric split errors may occur during the execution of bioassays. Earlier approaches to error-correcting sample preparation addressed this problem by using a cyberphysical system yielding several drawbacks such as increased sample preparation cost and time, and uncertainty in assay completion time. In addition, error correction for only a single-target sample has been considered so far, although many assays require the production of multi-target samples. In this work, we present an error-free dilution technique that guarantees the correctness of the resulting concentration factor of a sample without performing any additional roll-back or roll-forward action. To the best of our knowledge, we are the first to present a solution strategy for tackling dispensing errors during sample preparation. We use micro-electrode-dot-array biochips that offer the advantages of manipulating fractional volumes of droplets (aliquots) for navigation, as well as mix-split operations. Instead of performing traditional mix-and-split steps with integral-volume droplets, we execute only an aliquoting-and-mix sequence using differential-size aliquots. Thus, all split operations, which are the main source of errors in conventional digital microfluidic biochips, are completely eliminated, and hence neither sensing nor any correcting action is needed, and further, no management of intermediate waste droplets is needed. Additionally, the procedure can be fully parallelized for accurately producing multiple dilutions of a sample. Experimental results corroborate the superiority of the proposed method in terms of error management, as well as sample preparation cost and time.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W3096845005",
    "type": "article"
  },
  {
    "title": "Multiprocessor Scheduling of a Multi-Mode Dataflow Graph Considering Mode Transition Delay",
    "doi": "https://doi.org/10.1145/2997645",
    "publication_date": "2017-01-20",
    "publication_year": 2017,
    "authors": "Hanwoong Jung; Hyunok Oh; Soonhoi Ha",
    "corresponding_authors": "",
    "abstract": "Synchronous Data Flow (SDF) model is widely used for specifying signal processing or streaming applications. Since modern embedded applications become more complex with dynamic behavior changes at run-time, several extensions of the SDF model have been proposed to specify the dynamic behavior changes while preserving static analyzability of the SDF model. They assume that an application has a finite number of behaviors (or modes) and each behavior (mode) is represented by an SDF graph. They are classified as multi-mode dataflow models in this paper. While there exist several scheduling techniques for multi-mode dataflow models, no one allows task migration between modes. By observing that the resource requirement can be additionally reduced if task migration is allowed, we propose a multiprocessor scheduling technique of a multi-mode dataflow graph considering task migration between modes. Based on a genetic algorithm, the proposed technique schedules all SDF graphs in all modes simultaneously to minimize the resource requirement. To satisfy the throughput constraint, the proposed technique calculates the actual throughput requirement of each mode and the output buffer size for tolerating throughput jitter. We compare the proposed technique with a method which analyzes SDF graphs in each execution mode separately and a method that does not allow task migration for synthetic examples and three real applications: H.264 decoder, vocoder, and LTE receiver algorithms.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W3124393990",
    "type": "article"
  },
  {
    "title": "Reducing test cost of integrated, heterogeneous systems using pass-fail test data analysis",
    "doi": "https://doi.org/10.1145/2566666",
    "publication_date": "2014-03-01",
    "publication_year": 2014,
    "authors": "Sounil Biswas; Hongfei Wang; R.D. Blanton",
    "corresponding_authors": "",
    "abstract": "Stringent quality requirements for integrated, heterogeneous systems have led designers and test engineers to mandate large sets of tests to be applied to these systems, which, in turn, have resulted in increased test cost. However, many of these tests are unnecessary (i.e., redundant), since their outcomes can be reliably predicted using results from other applied tests. A methodology for identifying the redundant tests of an integrated, heterogeneous system that has only binary pass-fail test data is described. This methodology uses decision trees, Boolean minimization, and satisfiability as core components. Feasibility is empirically demonstrated using test data from two commercially fabricated systems, namely, a high-speed serializer/deserializer (HSS) and a phase-locked loop (PLL). Our analysis of test data from &gt; 38,000 HSS and &gt; 22,000 PLL circuits show that 14 out of 40 HSS tests and 11 out of 36 PLL tests are redundant.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W1985760828",
    "type": "article"
  },
  {
    "title": "Reducing Contention in Shared Last-Level Cache for Throughput Processors",
    "doi": "https://doi.org/10.1145/2676550",
    "publication_date": "2014-11-18",
    "publication_year": 2014,
    "authors": "Hsien-Kai Kuo; Bo‐Cheng Lai; Jing-Yang Jou",
    "corresponding_authors": "",
    "abstract": "Deploying the Shared Last-Level Cache (SLLC) is an effective way to alleviate the memory bottleneck in modern throughput processors, such as GPGPUs. A commonly used scheduling policy of throughput processors is to render the maximum possible thread-level parallelism. However, this greedy policy usually causes serious cache contention on the SLLC and significantly degrades the system performance. It is therefore a critical performance factor that the thread scheduling of a throughput processor performs a careful trade-off between the thread-level parallelism and cache contention. This article characterizes and analyzes the performance impact of cache contention in the SLLC of throughput processors. Based on the analyses and findings of cache contention and its performance pitfalls, this article formally formulates the aggregate working-set-size-constrained thread scheduling problem that constrains the aggregate working-set size on concurrent threads. With a proof to be NP-hard, this article has integrated a series of algorithms to minimize the cache contention and enhance the overall system performance on GPGPUs. The simulation results on NVIDIA's Fermi architecture have shown that the proposed thread scheduling scheme achieves up to 61.6% execution time enhancement over a widely used thread clustering scheme. When compared to the state-of-the-art technique that exploits the data reuse of applications, the improvement on execution time can reach 47.4%. Notably, the execution time improvement of the proposed thread scheduling scheme is only 2.6% from an exhaustive searching scheme.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2017239686",
    "type": "article"
  },
  {
    "title": "Dataflow Graph Partitioning for Area-Efficient High-Level Synthesis with Systems Perspective",
    "doi": "https://doi.org/10.1145/2660769",
    "publication_date": "2014-11-18",
    "publication_year": 2014,
    "authors": "Sharad Sinha; Thambipillai Srikanthan",
    "corresponding_authors": "",
    "abstract": "Area efficiency in datapath synthesis is a widely accepted goal of high-level synthesis. Applications represented by their dataflow graphs are synthesized using resource sharing principles to reduce the area. However, existing resource sharing algorithms focus on absolute area reduction and maximal resource sharing. This kind of a design approach leads to constraints on how often, in terms of number of clock cycles, a new set of input data can be fed to an application. It also leads to very large multiplexers in case of very big dataflow graphs with hundreds of nodes. An adaptive dataflow graph partitioning algorithm is proposed that partitions a graph taking into account a user-defined constraint on how often a new set of input data (generally referred to as data initiation interval) is available. At the same time, a resource sharing algorithm is applied to such partitions in order to reduce area. Multiple design points are generated for a given dataflow graph with different area and time measures to enable a designer to make decisions. We demonstrate our graph partitioning algorithm using synthetically generated large dataflow graphs and on some benchmark applications.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2041398073",
    "type": "article"
  },
  {
    "title": "Yield Improvement for 3D Wafer-to-Wafer Stacked ICs Using Wafer Matching",
    "doi": "https://doi.org/10.1145/2699832",
    "publication_date": "2015-03-02",
    "publication_year": 2015,
    "authors": "Mottaqiallah Taouil; Said Hamdioui; Erik Jan Marinissen",
    "corresponding_authors": "",
    "abstract": "Three-Dimensional Stacked IC (3D-SIC) using Through-Silicion Vias (TSVs) is an emerging technology that provides heterogeneous integration, higher performance, and lower power consumption compared to traditional ICs. Stacking 3D-SICs using Wafer-to-Wafer (W2W) has several advantages such as high stacking throughput, high TSV density, and the ability to handle thin wafers and small dies. However, it suffers from low-compound yield as the stacking of good dies on bad dies and vice versa cannot be prevented. This article investigates wafer matching as a means for yield improvement. It first defines a complete wafer matching framework consisting of different scenarios, each a combination of a matching process (defines the order of wafer selection), a matching criterion (defines whether good or bad dies are matched), wafer rotation (defines either wafers are rotated or not), and a repository type. The repository type specifies whether either the repository is filled immediately after each wafer selection (i.e., running repository) or after all wafers are matched (i.e., static repository). A mapping of prior work on the framework shows that existing research has mainly explored scenarios based on static repositories. Therefore, the article analyzes scenarios based on running repositories. Simulation results show that scenarios based on running repositories improve the compound yield with up to 13.4% relative to random W2W stacking; the improvement strongly depends on the number of stacked dies, die yield, repository size, as well as on the used matching process. Moreover, the results reveal that scenarios based on running repositories outperform those of static repositories in terms of yield improvement at significant runtime reduction (three orders of magnitude) and lower memory complexity (from exponential to linear in terms of stack size).",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2065534833",
    "type": "article"
  },
  {
    "title": "A Tool for Analog/RF BIST Evaluation Using Statistical Models of Circuit Parameters",
    "doi": "https://doi.org/10.1145/2699837",
    "publication_date": "2015-03-02",
    "publication_year": 2015,
    "authors": "Kamel Beznia; Ahcène Bounceur; Reinhardt Euler; Salvador Mir",
    "corresponding_authors": "",
    "abstract": "Testing analog integrated circuits is expensive in terms of both test equipment and time. To reduce the cost, Design-For-Test techniques (DFT) such as Built-In Self-Test (BIST) have been developed. For a given Circuit Under Test (CUT), the choice of a suitable technique should be made at the design stage as a result of the analysis of test metrics such as test escapes and yield loss. However, it is very hard to carry out this estimation for analog/RF circuits by using fault simulation techniques. Instead, the estimation of parametric test metrics is made possible by Monte Carlo circuit-level simulations and the construction of statistical models. These models represent the output parameter space of the CUT in which the test metrics are defined. In addition, models of the input parameter space may be required to accelerate the simulations and obtain higher confidence in the DFT choices. In this work, we describe a methodological flow for the selection of most adequate statistical models and several techniques that can be used for obtaining these models. Some of these techniques have been integrated into a Computer-Aided Test (CAT) tool for the automation of the process of test metrics estimation. This estimation is illustrated for the case of a BIST solution for CMOS imager pixels that requires the use of advanced statistical modeling techniques.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2067161261",
    "type": "article"
  },
  {
    "title": "BLAS",
    "doi": "https://doi.org/10.1145/2555616",
    "publication_date": "2014-03-01",
    "publication_year": 2014,
    "authors": "Da‐Wei Chang; Hsin-Hung Chen; Dau-Jieu Yang; Hsung‐Pin Chang",
    "corresponding_authors": "",
    "abstract": "Increasing the degree of parallelism and reducing the overhead of garbage collection (GC overhead) are the two keys to enhancing the performance of solid-state drives (SSDs). SSDs employ multichannel architectures, and a data placement scheme in an SSD determines how the data are striped to the channels. Without considering the data access pattern, existing fixed and device-level data placement schemes may have either high GC overhead or poor I/O parallelism, resulting in degraded performance. In this article, an adaptive block-level data placement scheme called BLAS is proposed to maximize the I/O parallelism while simultaneously minimizing the GC overhead. In contrast to existing device-level schemes, BLAS allows different data placement policies for blocks with different access patterns. Pages in read-intensive blocks are scattered over various channels to maximize the degree of read parallelism, while pages in each of the remaining blocks are attempted to be gathered in the same physical block to minimize the GC overhead. Moreover, BLAS allows the placement policy for a logical block to be changed dynamically according to the access pattern changes of that block. Finally, a parallelism-aware write buffer management approach is adopted in BLAS to maximize the degree of write parallelism. Performance results show that BLAS yields a significant improvement in the SSD response time when compared to existing device-level schemes. In particular, BLAS outperforms device-level page striping and device-level block striping by factors of up to 8.75 and 7.41, respectively. Moreover, BLAS achieves low GC overhead and is effective in adapting to workload changes.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2099185950",
    "type": "article"
  },
  {
    "title": "Clock Tree Synthesis Considering Slew Effect on Supply Voltage Variation",
    "doi": "https://doi.org/10.1145/2651401",
    "publication_date": "2014-11-18",
    "publication_year": 2014,
    "authors": "Chun-Kai Wang; Yeh-Chi Chang; Hung-Ming Chen; Ching-Yu Chin",
    "corresponding_authors": "",
    "abstract": "This work tackles a problem of clock power minimization within a skew constraint under supply voltage variation. This problem is defined in the ISPD 2010 benchmark. Unlike mesh and cross link that reduce clock skew uncertainty by multiple driving paths, our focus is on controlling skew uncertainty in the structure of the tree. We observe that slow slew amplifies supply voltage variation, which induces larger path delay variation and skew uncertainty. To obtain the optimality, we formulate a symmetric clock tree synthesis as a mathematical programming problem in which the slew effect is considered by an NLDM-like cell delay variation model. A symmetry-to-asymmetry tree transformation is proposed to further reduce wire loading. Experimental results show that the proposed four methods save up to 20% of clock tree capacitance loading. Beyond controlling slew to suppress supply-voltage-variation-induced skew, we also discuss the strategies of clock tree synthesis under variant variation scenarios and the limitations of the ISPD 2010 benchmark.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2139580002",
    "type": "article"
  },
  {
    "title": "A Methodology to Recover RTL IP Functionality for Automatic Generation of SW Applications",
    "doi": "https://doi.org/10.1145/2720019",
    "publication_date": "2015-06-24",
    "publication_year": 2015,
    "authors": "Nicola Bombieri; Franco Fummi; Sara Vinco",
    "corresponding_authors": "",
    "abstract": "With the advent of heterogeneous multiprocessor system-on-chips (MPSoCs), hardware/software partitioning is again on the rise both in research and in product development. In this new scenario, implementing intellectual-property (IP) blocks as SW applications rather than dedicated HW is an increasing trend to fully exploit the computation power provided by the MPSoC CPUs. On the other hand, whole libraries of IP blocks are available as RTL descriptions, most of them without a corresponding high-level SW implementation. In this context, this article presents a methodology to automatically generate SW applications in C++, by starting from existing RTL IPs implemented in hardware description language (HDL). The methodology exploits an abstraction algorithm to eliminate implementation details typical of HW descriptions (such as cycle-accurate functionality and data types) to guarantee relevant performance of the generated code. The experimental results show that, in many cases, the C++ code automatically generated in a few seconds with the proposed methodology is as efficient as the corresponding code manually implemented from scratch.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2144849043",
    "type": "article"
  },
  {
    "title": "TCONMAP",
    "doi": "https://doi.org/10.1145/2751558",
    "publication_date": "2015-09-28",
    "publication_year": 2015,
    "authors": "Karel Heyse; Brahim Al Farisi; Karel Bruneel; Dirk Stroobandt",
    "corresponding_authors": "",
    "abstract": "Parameterised configurations are FPGA configuration bitstreams in which the bits are defined as functions of user-defined parameters. From a parameterised configuration, it is possible to quickly and efficiently derive specialised, regular configuration bitstreams by evaluating these functions. The specialised bitstreams have different properties and functionality depending on the chosen values of the parameters. The most important application of parameterised configurations is the generation of specialised configuration bitstreams for Dynamic Circuit Specialisation, a technique for optimising circuits at runtime using partial reconfiguration of the FPGA. Generating and using parameterised configurations requires a new FPGA tool flow. In this article, we present a new technology mapping algorithm for parameterised designs, called TCONMAP, that can be used to produce parameterised configurations in which both the configuration of the logic blocks and routing is a function of the parameters. In our experiments, we demonstrate that in using TCONMAP, the depth and area of the mapped circuit is close to the minimal depth and area attainable. Both Dynamic Circuit Specialisation and fine-grained modular reconfiguration are extracted by TCONMAP from the HDL description of the design requiring only simple parameter annotations.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2155417261",
    "type": "article"
  },
  {
    "title": "Parasitic-Aware Common-Centroid FinFET Placement and Routing for Current-Ratio Matching",
    "doi": "https://doi.org/10.1145/2856031",
    "publication_date": "2016-04-19",
    "publication_year": 2016,
    "authors": "Po-Hsun Wu; Mark Po-Hung Lin; Xin Li; Tsung-Yi Ho",
    "corresponding_authors": "",
    "abstract": "The FinFET technology is regarded as a better alternative for modern high-performance and low-power integrated-circuit design due to more effective channel control and lower power consumption. However, the gate-misalignment problem resulting from process variation and the parasitic resistance resulting from interconnecting wires based on the FinFET technology becomes even more severe compared with the conventional planar CMOS technology. Such gate misalignment and unwanted parasitic resistance may increase the threshold voltage and decrease the drain current of transistors. When applying the FinFET technology to analog circuit design, the variation of drain currents can destroy current-ratio matching among transistors and degrade circuit performance. In this article, we present the first FinFET placement and routing algorithms for layout generation of a common-centroid FinFET array to precisely match the current ratios among transistors. Experimental results show that the proposed matching-driven FinFET placement and routing algorithms can obtain the best current-ratio matching compared with the state-of-the-art common-centroid placer.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2335894895",
    "type": "article"
  },
  {
    "title": "A Framework for Block Placement, Migration, and Fast Searching in Tiled-DNUCA Architecture",
    "doi": "https://doi.org/10.1145/2907946",
    "publication_date": "2016-05-27",
    "publication_year": 2016,
    "authors": "Shirshendu Das; Hemangee K. Kapoor",
    "corresponding_authors": "",
    "abstract": "Multicore processors have proliferated several domains ranging from small-scale embedded systems to large data centers, making tiled CMPs (TCMPs) the essential next-generation scalable architecture. NUCA architectures help in managing the capacity and access time for such larger cache designs. It divides the last-level cache (LLC) into multiple banks connected through an on-chip network. Static NUCA (SNUCA) has a fixed address mapping policy, whereas dynamic NUCA (DNUCA) allows blocks to relocate nearer to the processing cores at runtime. To allow this, DNUCA divides the banks into multiple banksets and a block can be placed in any bank within a particular bankset. The entire bankset may need to be searched to access a block. Optimal bankset searching mechanisms are essential for getting the benefits from DNUCA. This article proposes a DNUCA-based TCMP architecture called TLD-NUCA. It reduces the LLC access time of TCMP and also allows a heavily loaded bank to distribute its load among the underused banks. Instead of other DNUCA designs, TLD-NUCA considers larger banksets. Such relaxations result in more uniform load distribution than existing DNUCA-based TCMP (T-DNUCA). Considering larger banksets improves the utilization factor, but T-DNUCA cannot implement it because of its expensive searching mechanism. TLD-NUCA uses a centralized directory, called TLD, to search a block from all the banks. Also, the proposed block placement policy reduces the instances when the central TLD needs to be contacted. It does not require the expensive simultaneous search as needed by T-DNUCA. Better cache utilization and a reduction in LLC access time improve the miss rate as well as the average memory access time (AMAT). Improving the miss rate and AMAT results in improvements in cycles per instructions (CPI). Experimental analysis found that TLD-NUCA improves performance by 6.5% as compared to T-DNUCA. The improvement is 13% as compared to the SNUCA-based TCMP design.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2404726111",
    "type": "article"
  },
  {
    "title": "A Compact Implementation of Salsa20 and Its Power Analysis Vulnerabilities",
    "doi": "https://doi.org/10.1145/2934677",
    "publication_date": "2016-11-11",
    "publication_year": 2016,
    "authors": "Bodhisatwa Mazumdar; Sk Subidh Ali; Ozgur Sinanoglu",
    "corresponding_authors": "",
    "abstract": "In this article, we present a compact implementation of the Salsa20 stream cipher that is targeted towards lightweight cryptographic devices such as radio-frequency identification (RFID) tags. The Salsa20 stream cipher, ann addition-rotation-XOR (ARX) cipher, is used for high-security cryptography in NEON instruction sets embedded in ARM Cortex A8 CPU core-based tablets and smartphones. The existing literature shows that although classical cryptanalysis has been effective on reduced rounds of Salsa20, the stream cipher is immune to software side-channel attacks such as branch timing and cache timing attacks. To the best of our knowledge, this work is the first to perform hardware power analysis attacks, where we evaluate the resistance of all eight keywords in the proposed compact implementation of Salsa20. Our technique targets the three subrounds of the first round of the implemented Salsa20. The correlation power analysis (CPA) attack has an attack complexity of 2 19 . Based on extensive experiments on a compact implementation of Salsa20, we demonstrate that all these keywords can be recovered within 20,000 queries on Salsa20. The attacks show a varying resilience of the key words against CPA that has not yet been observed in any stream or block cipher in the present literature. This makes the architecture of this stream cipher interesting from the side-channel analysis perspective. Also, we propose a lightweight countermeasure that mitigates the leakage in the power traces as shown in the results of Welch’s t -test statistics. The hardware area overhead of the proposed countermeasure is only 14% and is designed with compact implementation in mind.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2549819053",
    "type": "article"
  },
  {
    "title": "NeuroCool: Dynamic Thermal Management of 3D DRAM for Deep Neural Networks through Customized Prefetching",
    "doi": "https://doi.org/10.1145/3630012",
    "publication_date": "2023-10-23",
    "publication_year": 2023,
    "authors": "Shailja Pandey; Lokesh Siddhu; Preeti Ranjan Panda",
    "corresponding_authors": "",
    "abstract": "Deep neural network (DNN) implementations are typically characterized by huge datasets and concurrent computation, resulting in a demand for high memory bandwidth due to intensive data movement between processors and off-chip memory. Performing DNN inference on general-purpose cores/edge is gaining attraction to enhance user experience and reduce latency. The mismatch in the CPU and conventional DRAM speed leads to under-utilization of the compute capabilities, causing increased inference time. 3D DRAM is a promising solution to effectively fulfill the bandwidth requirement of high-throughput DNNs. However, due to high power density in stacked architectures, 3D DRAMs need dynamic thermal management (DTM), resulting in performance overhead due to memory-induced CPU throttling. We study the thermal impact of DNN applications running on a 3D DRAM system, and make a case for a memory temperature-aware customized prefetch mechanism to reduce DTM overheads and significantly improve performance. In our proposed NeuroCool DTM policy, we intelligently place either DRAM ranks or tiers in low power state, using the DNN layer characteristics and access rate. We establish the generalization of our approach through training and test datasets comprising diverse data points from widely used DNN applications. Experimental results on popular DNNs show that NeuroCool results in a average performance gain of 44% (as high as 52%) and memory energy improvement of 43% (as high as 69%) over general-purpose DTM policies.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4387869276",
    "type": "article"
  },
  {
    "title": "RSPP: Restricted Static Pseudo-Partitioning for Mitigation of Cross-Core Covert Channel Attacks",
    "doi": "https://doi.org/10.1145/3637222",
    "publication_date": "2023-12-13",
    "publication_year": 2023,
    "authors": "Jaspinder Kaur; Shirshendu Das",
    "corresponding_authors": "",
    "abstract": "Cache timing channel attacks exploit the inherent properties of cache memories: hit and miss time along with the shared nature of the cache to leak secret information. The side channel and covert channel are the two well-known cache timing channel attacks. In this article, we propose Restricted Static Pseudo-Partitioning (RSPP), an effective partition-based mitigation mechanism that restricts the cache access of only the adversaries involved in the attack. It has an insignificant impact of only 1% in performance, as the benign processes have access to the full cache and restrictions are limited only to the suspicious processes and cache sets. It can be implemented with a maximum storage overhead of 1.45% of the total Last-Level Cache (LLC) size. This article presents three variations of the proposed attack mitigation mechanism: RSPP, simplified-RSPP (S-RSPP) and corewise-RSPP (C-RSPP) with different hardware overheads. A full system simulator is used for evaluating the performance impact of RSPP. A detailed experimental analysis with different LLC and attack parameters is also discussed. RSPP is also compared with the existing defense mechanisms effective against cross-core covert channel attacks.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4389675391",
    "type": "article"
  },
  {
    "title": "Model refinement for hardware-software codesign",
    "doi": "https://doi.org/10.1145/250243.250247",
    "publication_date": "1997-01-01",
    "publication_year": 1997,
    "authors": "Jie Gong; Daniel D. Gajski; Smita Bakshi",
    "corresponding_authors": "",
    "abstract": "Hardware-software codesign, which implements a given specification with a set of system components such as ASICs and processors, includes several key tasks such as system component allocation, functional partitioning, quality metrics estimation, and model refinement. In this work, we focus on the model refinement task which transforms a specification from an original functional model to a refined implementation model. First, we categorize several commonly used implementation models and describe a set of refinement procedures to transform a specification to each of these implementation models. We also present a set of experimental results to compare the implementation models and to demonstrate how the proposed approach can be used to explore different implementation styles.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2014722192",
    "type": "article"
  },
  {
    "title": "Procedure cloning",
    "doi": "https://doi.org/10.1145/298865.298871",
    "publication_date": "1999-01-01",
    "publication_year": 1999,
    "authors": "Frank Vahid",
    "corresponding_authors": "Frank Vahid",
    "abstract": "Functional partitioning assigns the functions of a system's program-like specification among system components, such as standard-software and custom-hardware processors. We introduce a new transformation, called procedure cloning, that significantly improves functional partitioning results. The transformation creates a clone of a procedure for sole use by a particular procedure caller, so the clone can be assigned to the caller's processor, which in turn improves performance through reduced communication. Heuristics are used to prevent the exponential size increase that could occur if cloning were done indiscriminately. We introduce a variety of cloning heuristics, highlight experiments demonstrating the improvements obtained using cloning, and compare the various cloning heuristics.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2087104644",
    "type": "article"
  },
  {
    "title": "Initializability analysis of synchronous sequential circuits",
    "doi": "https://doi.org/10.1145/544536.544538",
    "publication_date": "2002-04-01",
    "publication_year": 2002,
    "authors": "Fulvio Corno; P. Prinetto; Maurizio Rebaudengo; M. Sonza Reorda; Giovanni Squillero",
    "corresponding_authors": "",
    "abstract": "This article addresses the problem of initializing synchronous sequential circuits, that is, of generating the shortest sequence able to drive the circuit to a known state, regardless of the initial state. Logic initialization is considered, being the only one compatible with current commercial tools. A hybrid Genetic Algorithm is proposed, which combines general ideas from evolutionary computation with specific techniques, well suited to the addressed problem. For the first time, experimental results provide data about the complete set of ISCAS'89 circuits, and show that, despite the inherent algorithm incompleteness, the method is capable of finding the optimum result for the considered circuits. A prototypical tool implementing the algorithm found better results than previous methods.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W1976017876",
    "type": "article"
  },
  {
    "title": "Estimation of state line statistics in sequential circuits",
    "doi": "https://doi.org/10.1145/567270.567275",
    "publication_date": "2002-07-01",
    "publication_year": 2002,
    "authors": "Vikram Saxena; Farid N. Najm; I.N. Hajj",
    "corresponding_authors": "",
    "abstract": "In this article, we present a simulation-based technique for estimation of signal statistics (switching activity and signal probability) at the flip-flop output nodes (state signals) of a general sequential circuit. Apart from providing an estimate of the power consumed by the flip-flops, this information is needed for calculating power in the combinational portion of the circuit. The statistics are computed by collecting samples obtained from fast RTL simulation of the circuit under input sequences that are either randomly generated or independently selected from user-specified pattern sets. An important advantage of this approach is that the desired accuracy can be specified up front by the user; with some approximation, the algorithm iterates until the specified accuracy is achieved. This approach has been implemented and tested on a number of sequential circuits and has been shown to handle very large sequential circuits that can not be handled by other existing methods, while using a reasonable amount of CPU time and memory (the circuit s38584.1, with 1426 flip-flops, can be analyzed in about 10 minutes).",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W1979219751",
    "type": "article"
  },
  {
    "title": "Retiming-based factorization for sequential logic optimization",
    "doi": "https://doi.org/10.1145/348019.348068",
    "publication_date": "2000-07-01",
    "publication_year": 2000,
    "authors": "Surendra K. Bommu; Niall O'Neill; Maciej Ciesielski",
    "corresponding_authors": "",
    "abstract": "Current sequential optimization techniques apply a variety of logic transformations that mainly target the combinational logic component of the circuit. Retiming is typically applied as a postprocessing step to the gate-level implementation obtained after technology mapping. This paper introduces a new sequential logic transformation which integrates retiming with logic transformations at the technology-independent level. This transformation is based on implicit retiming across logic blocks and fanout stems during logic optimization. Its application to sequential network synthesis results in the optimization of logic across register boundaries. It can be used in conjunction with any measure of circuit quality for which a fast and reliable gain estimation method can be obtained. We immplemented our new technique within the SIS framework and demonstrated its effectiveness in terms of cycle-time minimization on a set sequential benchmark circuits.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W1984491986",
    "type": "article"
  },
  {
    "title": "False-noise analysis using logic implications",
    "doi": "https://doi.org/10.1145/567270.567276",
    "publication_date": "2002-07-01",
    "publication_year": 2002,
    "authors": "A. Glebov; S. V. Gavrilov; David Blaauw; Vladimir Zolotov",
    "corresponding_authors": "",
    "abstract": "Cross-coupled noise analysis has become a critical concern in today's VLSI designs. Typically, noise analysis makes the assumption that all aggressing nets can simultaneously switch in the same direction. This creates a worst- case noise pulse on the victim net that often leads to false noise violations. In this article we present a new approach that uses logic implications to identify the maximum set of aggressor nets that can inject noise simultaneously under the logic constraints of the circuit. We propose an approach to efficiently generate logic implications from a transistor-level description and propagate them in the circuit using ROBDD representations. We propose a new method for lateral propagation of implications and also show how tristate gates and high-impedance signal states can be handled using tristate implications. We then show that the problem of finding the worst-case logically feasible noise can be represented as a maximum weighted independent set problem and show how to efficiently solve it. Initially, we restrict our discussion to zero-delay implications, which are valid for glitch-free circuits, and then extend our approach to timed implications. The proposed approaches were implemented in an industrial noise analysis tool and results are shown for a number of industrial test cases. We demonstrate that a significant reduction in the number of noise failures can be obtained from considering the logic implications as proposed in this article, underscoring the need for false-noise analysis.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2140572351",
    "type": "article"
  },
  {
    "title": "On test data volume reduction for multiple scan chain designs",
    "doi": "https://doi.org/10.1145/944027.944031",
    "publication_date": "2003-10-01",
    "publication_year": 2003,
    "authors": "S.M. Reddy; Kohei Miyase; Seiji Kajihara; Irith Pomeranz",
    "corresponding_authors": "",
    "abstract": "We consider issues related to the reduction of scan test data in designs with multiple scan chains. We propose a metric that can be used to evaluate the effectiveness of procedures for reducing the scan data volume. The metric compares the achieved compression to the compression which is intrinsic to the use of multiple scan chains. We also propose a procedure for modifying a given test set so as to achieve reductions in test data volume assuming a combinational decompressor circuit.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W1994418768",
    "type": "article"
  },
  {
    "title": "Chip placement in a reticle for multiple-project wafer fabrication",
    "doi": "https://doi.org/10.1145/1297666.1297688",
    "publication_date": "2008-01-01",
    "publication_year": 2008,
    "authors": "Meng-Chiou Wu; Rung‐Bin Lin; Shih-Cheng Tsai",
    "corresponding_authors": "",
    "abstract": "Chip placement in a reticle is crucial to the cost of a multiproject wafer run. In this article we develop several chip placement methods based on the volume-driven compatibility optimization (VOCO) concept, which maximizes dicing compatibility among chips with large-volume requirements while minimizing reticle dimensions. Our mixed-integer linear programming models with VOCO are too complex to render good solutions for large test cases. Our B*-tree with VOCO and HQ with VOCO use 16%∼ 29% fewer wafers and 8%∼ 19% less reticle area than the hierarchical quadrisection (HQ) method proposed by Kahng et al. [2005]",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2019764621",
    "type": "article"
  },
  {
    "title": "Playing the trade-off game",
    "doi": "https://doi.org/10.1145/1529255.1529258",
    "publication_date": "2009-05-01",
    "publication_year": 2009,
    "authors": "Praveen Raghavan; Murali Jayapala; Andy Lambrechts; Javed Absar; Francky Catthoor",
    "corresponding_authors": "",
    "abstract": "Modern mobile devices need to be extremely energy efficient. Due to the growing complexity of these devices, energy-aware design exploration has become increasingly important. Current exploration tools often do not support energy estimation, or require the design to be very detailed before estimation is possible. It is important to get early feedback on both performance and energy consumption during all phases of the design and at higher abstraction levels. This article presents a unified optimization and exploration framework to explore source-level transformation to processor architecture design space. The proposed retargetable compiler and simulator framework can map applications to a range of processors and memory configurations, simulate, and report detailed performance and energy estimates. An accurate and consistent energy modeling approach is introduced which can estimate the energy consumption of processor and memories at a component level, which can help to guide the design process. Fast energy-aware architecture exploration is illustrated by modeling both state-of-the-art processors as well as other architectures. Various design trade-offs are also illustrated on different academic as well as industrial benchmarks from both the wireless communication and multimedia domain. We also illustrate a design space exploration on different applications and show that there is large trade-off space between application performance, energy consumption, and area. We show that the proposed framework is consistent, accurate, and covers a large design space including various novel low-power extensions in a unified framework.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2020403045",
    "type": "article"
  },
  {
    "title": "Power-aware SoC test planning for effective utilization of port-scalable testers",
    "doi": "https://doi.org/10.1145/1367045.1367062",
    "publication_date": "2008-07-01",
    "publication_year": 2008,
    "authors": "Anuja Sehgal; Sudarshan Bahukudumbi; Krishnendu Chakrabarty",
    "corresponding_authors": "",
    "abstract": "Many system-on-chip (SoC) integrated circuits contain embedded cores with different scan frequencies. To better meet the test requirements for such heterogeneous SoCs, leading tester companies have recently introduced port-scalable testers, which can simultaneously drive groups of channels at different data rates. However, the number of tester channels available for scan testing is limited; therefore, a higher shift frequency can increase the test time for a core if the resulting test access architecture reduces the bit-width used to access it. We present a scalable test planning technique that exploits port scalability of testers to reduce SoC test time. We compare the proposed heuristic optimization method to two baseline methods based on prior works that use a single scan data rate for all embedded cores. We also propose a power-aware test planning technique to effectively utilize port-scalable testers under constraints of test power consumption. Experimental results are presented for power-aware test scheduling to illustrate the impact of power constraints on overall test time.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2034549010",
    "type": "article"
  },
  {
    "title": "Straightforward construction of depth-size optimal, parallel prefix circuits with fan-out 2",
    "doi": "https://doi.org/10.1145/1455229.1455244",
    "publication_date": "2009-01-01",
    "publication_year": 2009,
    "authors": "Yen‐Chun Lin; Li‐Ling Hung",
    "corresponding_authors": "",
    "abstract": "Prefix computation is used in various areas and is considered as a primitive operation. Parallel prefix circuits are parallel prefix algorithms on the combinational circuit model. The depth of a prefix circuit is a measure of its processing time; smaller depth implies faster computation. The size of a prefix circuit is the number of operation nodes in it. Smaller size implies less power consumption, less VLSI area, and less cost. A prefix circuit with n inputs is depth-size optimal if its depth plus size equals 2 n − 2. A circuit with a smaller fan-out is in general faster and occupies less VLSI area. To be of practical use, the depth and fan-out of a prefix circuit should be small. In this paper, a family of depth-size optimal, parallel prefix circuits with fan-out 2 is presented. This family of prefix circuits is easier to construct and more amenable to automatic synthesis than two other families of the same type, although the three families have the same minimum depth among all depth-size optimal prefix circuits with fan-out 2. The balanced structure of the new family is also a merit.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2043169655",
    "type": "article"
  },
  {
    "title": "Temperature-aware register reallocation for register file power-density minimization",
    "doi": "https://doi.org/10.1145/1497561.1497569",
    "publication_date": "2009-03-01",
    "publication_year": 2009,
    "authors": "Xiangrong Zhou; Chenjie Yu; П. П. Петров",
    "corresponding_authors": "",
    "abstract": "Increased chip temperature has been known to cause severe reliability problems and to significantly increase leakage power. The register file has been previously shown to exhibit the highest temperature compared to all other hardware components in a modern high-end embedded processor, which makes it particularly susceptible to faults and elevated leakage power. We show that this is mostly due to the highly clustered register file accesses where a set of few registers physically placed close to each other are accessed with very high frequency. We propose compile-time temperature-aware register reallocation methodologies for breaking such groups of registers and to uniformly distribute the accesses to the register file. This is achieved with no performance and no hardware overheads . We show that the underlying problem is NP-hard, and subsequently introduce and evaluate two efficient algorithmic heuristics. Our extensive experimental study demonstrates the efficiency of the proposed methodology.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2044774393",
    "type": "article"
  },
  {
    "title": "Design Space Optimization of Shared Memory Architecture in Accelerator-rich Systems",
    "doi": "https://doi.org/10.1145/3446001",
    "publication_date": "2021-03-13",
    "publication_year": 2021,
    "authors": "Mitali Sinha; Gade Sri Harsha; Pramit Bhattacharyya; Sujay Deb",
    "corresponding_authors": "",
    "abstract": "Shared memory architectures, as opposed to private-only memories, provide a viable alternative to meet the ever-increasing memory requirements of multi-accelerator systems to achieve high performance under stringent area and energy constraints. However, an impulsive memory sharing degrades performance due to network contention and latency to access shared memory. We propose the Accelerator Shared Memory (ASM) framework to provide an optimal private/shared memory configuration and shared data allocation under a system’s resource and network constraints. Evaluations show ASM provides up to 34.35% and 31.34% improvement in performance and energy, respectively, over baseline systems.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W3137117590",
    "type": "article"
  },
  {
    "title": "Distance-aware Approximate Nanophotonic Interconnect",
    "doi": "https://doi.org/10.1145/3484309",
    "publication_date": "2021-11-02",
    "publication_year": 2021,
    "authors": "Jae‐Chul Lee; Cédric Killian; Sébastien Le Beux; Daniel Chillet",
    "corresponding_authors": "",
    "abstract": "The energy consumption of manycore architectures is dominated by data movement, which calls for energy-efficient and high-bandwidth interconnects. To overcome the bandwidth limitation of electrical interconnects, integrated optics appear as a promising technology. However, it suffers from high power overhead related to low laser efficiency, which calls for the use of techniques and methods to improve its energy costs. Besides, approximate computing is emerging as an efficient method to reduce energy consumption and improve execution speed of embedded computing systems. It relies on allowing accuracy reduction on data at the cost of tolerable application output error. In this context, the work presented in this article exploits both features by defining approximate communications for error-tolerant applications. We propose a method to design realistic and scalable nanophotonic interconnect supporting approximate data transmission and power adaption according to the communication distance to improve the energy efficiency. For this purpose, the data can be sent by mixing low optical power signal and truncation for the Least Significant Bits (LSB) of the floating-point numbers, while the overall power is adapted according to the communication distance. We define two ranges of communications, short and long, which require only four power levels. This reduces area and power overhead to control the laser output power. A transmission model allows estimating the laser power according to the targeted BER and the number of truncated bits, while the optical network interface allows configuring, at runtime, the number of approximated and truncated bits and the laser output powers. We explore the energy efficiency provided by each communication scheme, and we investigate the error resilience of the benchmarks over several approximation and truncation schemes. The simulation results of ApproxBench applications show that, compared to an interconnect involving only robust communications, approximations in the optical transmission led to up to 53% laser power reduction with a limited degradation at the application level with less than 9% of output error. Finally, we show that our solution is scalable and leads to 10% reduction in the total energy consumption, 35× reduction in the laser driver size, and 10× reduction in the laser controller compared to state-of-the-art solution.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W3210723043",
    "type": "article"
  },
  {
    "title": "Partitioning techniques for partially protected caches in resource-constrained embedded systems",
    "doi": "https://doi.org/10.1145/1835420.1835423",
    "publication_date": "2010-09-01",
    "publication_year": 2010,
    "authors": "Kyoungwoo Lee; Aviral Shrivastava; Nikil Dutt; Nalini Venkatasubramanian",
    "corresponding_authors": "",
    "abstract": "Increasing exponentially with technology scaling, the soft error rate even in earth-bound embedded systems manufactured in deep subnanometer technology is projected to become a serious design consideration. Partially protected cache (PPC) is a promising microarchitectural feature to mitigate failures due to soft errors in power, performance, and cost sensitive embedded processors. A processor with PPC maintains two caches, one protected and the other unprotected, both at the same level of memory hierarchy. The intuition behind PPCs is that not all data in the application is equally prone to soft errors. By finding and mapping the data that is more prone to soft errors to the protected cache, and error-resilient data to the unprotected cache, failures induced by soft errors can be significantly reduced at a minimal power and performance penalty. Consequently, the effectiveness of PPCs critically hinges on the compiler's ability to partition application data into error-prone and error-resilient data. The effectiveness of PPCs has previously been demonstrated on multimedia applications—where an obvious partitioning of data exists, the multimedia data is inherently resilient to soft errors, and the rest of the data and the entire code is assumed to be error-prone. Since the amount of multimedia data is a quite significant component of the entire application data, this obvious partitioning is quite effective. However, no such obvious data and code partitioning exists for general applications. This severely restricts the applicability of PPCs to data caches and instruction caches in general. This article investigates vulnerability-based partitioning schemes that are applicable to applications in general and effectively reduce failures due to soft errors at minimal power and performance overheads. Our experimental results on an HP iPAQ-like processor enhanced with PPC architecture, running benchmarks from the MiBench suite demonstrate that our partitioning heuristic efficiently finds page partitions for data PPCs that can reduce the failure rate by 48% at only 2% performance and 7% energy overhead, and finds page partitions for instruction PPCs that reduce the failure rate by 50% at only 2% performance and 8% energy overhead, on average.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W1990477916",
    "type": "article"
  },
  {
    "title": "Reliability analysis of memories protected with BICS and a per-word parity bit",
    "doi": "https://doi.org/10.1145/1698759.1698768",
    "publication_date": "2010-02-01",
    "publication_year": 2010,
    "authors": "Pedro Reviriego; Juan Antonio Maestro; Chris J. Bleakley",
    "corresponding_authors": "",
    "abstract": "This article presents an analysis of the reliability of memories protected with Built-in Current Sensors (BICS) and a per-word parity bit when exposed to Single Event Upsets (SEUs). Reliability is characterized by Mean Time to Failure (MTTF) for which two analytic models are proposed. A simple model, similar to the one traditionally used for memories protected with scrubbing, is proposed for the low error rate case. A more complex Markov model is proposed for the high error rate case. The accuracy of the models is checked using a wide set of simulations. The results presented in this article allow fast estimation of MTTF enabling design of optimal memory configurations to meet specified MTTF goals at minimum cost. Additionally the power consumption of memories protected with BICS is compared to that of memories using scrubbing in terms of the number of read cycles needed in both configurations.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W1996642491",
    "type": "article"
  },
  {
    "title": "40nm CMOS 0.35V-Optimized Standard Cell Libraries for Ultra-Low Power Applications",
    "doi": "https://doi.org/10.1145/1970353.1970369",
    "publication_date": "2011-06-01",
    "publication_year": 2011,
    "authors": "Fady Abouzeid; Sylvain Clerc; Fabian Firmin; Marc Renaudin; Tiempo Sas; Gilles Sicard",
    "corresponding_authors": "",
    "abstract": "Ultra-low voltage is now a well-known solution for energy constrained applications designed using nanometric process technologies. This work is focused on setting up an automated methodology to enable the design of ultra-low voltage digital circuits exclusively using standard EDA tools. To achieve this goal, a 0.35V energy-delay optimized library was developed. This library, fully compliant with standard library design flow and characterization, was verified through the design and fabrication of a BCH decoder circuit, following a standard front-end to back-end flow. At 0.33V, it performs at 600 kHz with a dynamic energy consumption reduced by a factor 14x from nominal 1.1V. Based on this design, experiments, and preliminary silicon results, two additional libraries were developed in order to enhance future ultra-low voltage circuit performance.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2012616521",
    "type": "article"
  },
  {
    "title": "Optimal common-centroid-based unit capacitor placements for yield enhancement of switched-capacitor circuits",
    "doi": "https://doi.org/10.1145/2534394",
    "publication_date": "2013-12-01",
    "publication_year": 2013,
    "authors": "Chien‐Chih Huang; Chin‐Long Wey; Jwu-E Chen; Pei-Wen Luo",
    "corresponding_authors": "",
    "abstract": "Yield is defined as the probability that the circuit under consideration meets with the design specification within the tolerance. Placement with higher correlation coefficients has fewer mismatches and lower variation of capacitor ratio, thus achieving higher yield performance. This study presents a new optimization criterion that quickly determines if the placement is optimal. The optimization criterion leads to the development of the concepts of C-entries and partitioned subarrays which can significantly reduce the searching space for finding the optimal/near-optimal placements on a sufficiently large array size.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2016340200",
    "type": "article"
  },
  {
    "title": "An index-based management scheme with adaptive caching for huge-scale low-cost embedded flash storages",
    "doi": "https://doi.org/10.1145/2505013",
    "publication_date": "2013-10-01",
    "publication_year": 2013,
    "authors": "Po‐Chun Huang; Yuan-Hao Chang; Tei‐Wei Kuo",
    "corresponding_authors": "",
    "abstract": "Due to its remarkable access performance, shock resistance, and costs, NAND flash memory is now widely adopted in a variety of computing environments, especially in mobile devices such as smart phones, media players and electronic book readers. For the consideration of costs, low-cost embedded flash storages such as flash memory cards are often employed on such devices. Different from solid-state disks, the RAM buffer equipped on low-cost embedded flash storages are very small, for example, limited under several dozens of kilobytes, despite of the rapidly growing capacity of the storages. The significance of effectively utilizing the very limited on-device RAM buffers of embedded flash storages is therefore highlighted, and a novel design of scalable flash management schemes is needed to tackle the new access constraints of MLC NAND flash memory. In this work, a highly scalable design of the flash translation layer is presented with the considerations of the on-device RAM size, user access patterns, address-mapping-information caching and MLC access constraints. Through a series of experiments, it is verified that, with appropriate settings of cache sizes, the proposed management scheme provides comparable performance results to prior arts with much lower requirements on the on-device RAM. In other words, the proposed scheme suggests a strategy to make better use of the on-device RAM, and is suitable for embedded flash storages.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2020841880",
    "type": "article"
  },
  {
    "title": "A probabilistic analysis of coverage methods",
    "doi": "https://doi.org/10.1145/2003695.2003698",
    "publication_date": "2011-10-01",
    "publication_year": 2011,
    "authors": "Laurent Sébastien Fournier; Avi Ziv; Ekaterina Kutsy; Ofer Strichman",
    "corresponding_authors": "",
    "abstract": "Coverage is an important measure for the quality and completeness of the functional verification of hardware logic designs. Verification teams spend a significant amount of time looking for bugs in the design and in providing high-quality coverage. This process is performed through the use of various sampling strategies for selecting test inputs. The selection of sampling strategies to achieve the verification goals is typically carried out in an intuitive manner. We studied several commonly used sampling strategies and provide a probabilistic framework for assessing and comparing their relative values. For this analysis, we derived results for two measures of interest: first, the probability of finding a bug within a given number of samplings; and second, the expected number of samplings until a bug is detected. These results are given for both recurring sampling schemes, in which the same inputs might be selected repeatedly, and for nonrecurring sampling schemes, in which already sampled inputs are never selected again. By considering results from the theory of search, and more specifically, from the well-known multiarmed bandit problem, we demonstrate the optimality of a greedy sampling strategy within our defined framework.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2025340003",
    "type": "article"
  },
  {
    "title": "Reliability-Driven Power/Ground Routing for Analog ICs",
    "doi": "https://doi.org/10.1145/2071356.2071362",
    "publication_date": "2012-01-01",
    "publication_year": 2012,
    "authors": "Jingwei Lin; Tsung-Yi Ho; Iris Hui-Ru Jiang",
    "corresponding_authors": "",
    "abstract": "Electromigration and voltage drop (IR-drop) are two major reliability issues in modern IC design. Electromigration gradually creates permanently open or short circuits due to excessive current densities; IR-drop causes insufficient power supply, thus degrading performance or even inducing functional errors because of nonzero wire resistance. Both types of failure can be triggered by insufficient wire widths. Although expanding the wire width alleviates electromigration and IR-drop, unlimited expansion not only increases the routing cost, but may also be infeasible due to the limited routing resource. In addition, electromigration and IR-drop manifest mainly in the power/ground (P/G) network. Therefore, taking wire widths into consideration is desirable to prevent electromigration and IR-drop at P/G routing. Unlike mature digital IC designs, P/G routing in analog ICs has not yet been well studied. In a conventional design, analog designers manually route P/G networks by implementing greedy strategies. However, the growing scale of analog ICs renders manual routing inefficient, and the greedy strategies may be ineffective when electromigration and IR-drop are considered. This study distances itself from conventional manual design and proposes an automatic analog P/G router that considers electromigration and IR-drops. First, employing transportation formulation, this article constructs an electromigration-aware rectilinear Steiner tree with the minimum routing cost. Second, without changing the solution quality, wires are bundled to release routing space for enhancing routability and relaxing congestion. A wire width extension method is subsequently adopted to reduce wire resistance for IR-drop safety. Compared with high-tech designs, the proposed approach achieves equally optimal solutions for electromigration avoidance, with superior efficiencies. Furthermore, via industrial design, experimental results also show the effectiveness and efficiency of the proposed algorithm for electromigration prevention and IR-drop reduction.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2034833782",
    "type": "article"
  },
  {
    "title": "A Simultaneous Input Vector Control and Circuit Modification Technique to Reduce Leakage with Zero Delay Penalty",
    "doi": "https://doi.org/10.1145/1870109.1870118",
    "publication_date": "2010-11-01",
    "publication_year": 2010,
    "authors": "Nikhil Jayakumar; Sunil P. Khatri",
    "corresponding_authors": "",
    "abstract": "Leakage power currently comprises a large fraction of the total power consumption of an IC. Techniques to minimize leakage have been researched widely. However, most approaches to reducing leakage have an associated performance penalty. In this article, we present an approach which minimizes leakage by simultaneously modifying the circuit while deriving the input vector that minimizes leakage. In our approach, we selectively modify a gate so that its output (in sleep mode) is in a state which helps minimize the leakage of other gates in its transitive fanout. Gate replacement is performed in a slack-aware manner, to minimize the resulting delay penalty. One of the major advantages of our technique is that we achieve a significant reduction in leakage without increasing the delay of the circuit.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2053083000",
    "type": "article"
  },
  {
    "title": "Deflection routing in 3D network-on-chip with limited vertical bandwidth",
    "doi": "https://doi.org/10.1145/2505011",
    "publication_date": "2013-10-01",
    "publication_year": 2013,
    "authors": "Jinho Lee; Dongwoo Lee; Sunwook Kim; Ki‐Young Choi",
    "corresponding_authors": "",
    "abstract": "This article proposes a deflection routing for 3D NoC with serialized TSVs for vertical links. Compared to buffered routing, deflection routing provides area- and power-efficient communication and little loss of performance under low to medium traffic load. Under 3D environments, the deflection routing can yield even better performance than buffered routing when key aspects are properly taken into account. However, the existing deflection routing technique cannot be directly applied because the serialized TSV links will take longer time to send data than ordinary planar links and cause many problems. A naive deflection through a TSV link can cause significantly longer latency and more energy consumption even for communications through planar links. This article proposes a method to mitigate the effect and also solve arising deadlock and livelock problems. Evaluation of the proposed scheme shows its effectiveness in throughput, latency, and energy consumption.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2053756914",
    "type": "article"
  },
  {
    "title": "Clock buffer polarity assignment with skew tuning",
    "doi": "https://doi.org/10.1145/2003695.2003709",
    "publication_date": "2011-10-01",
    "publication_year": 2011,
    "authors": "Jianchao Lu; Barış Taşkın",
    "corresponding_authors": "",
    "abstract": "A clock polarity assignment method is proposed that reduces the peak current on the vdd/gnd rails of an integrated circuit. The impacts of (i) the output capacitive load on the peak current drawn by the sink-level clock buffers, and (ii) the buffer/inverter replacement scheme of polarity assignment on timing accuracy are considered in the formulation. The proposed sink-level-only polarity assignment is performed by a lexi-search algorithm in order to balance the peak current on the clock tree. Most of the previous polarity assignment methods that do not include clock tree resynthesis lead to an undesirable increase in the worst corner clock skew. Hence, a skew-tuning scheme is proposed that reduces the clock skew through polarity refinement and not through clock tree resynthesis. The proposed polarity assignment method with the skew-tuning scheme is implemented within an industrial design flow for practicality. Experimental results show that the worst-case peak current drawn by the clock tree can be reduced by an average of 36.5%. The worst corner clock skew is increased from 60.7ps to 76.2ps by applying the proposed polarity assignment method. The proposed skew-tuning scheme reduces the worst-case clock skew from 76.2ps to 61.5ps, on average, with a limited degradation in the peak current improvement (36.5% to 31.2%, on average).",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2056390536",
    "type": "article"
  },
  {
    "title": "An in-place search algorithm for the resource constrained scheduling problem during high-level synthesis",
    "doi": "https://doi.org/10.1145/1835420.1835422",
    "publication_date": "2010-09-01",
    "publication_year": 2010,
    "authors": "Cheng-Juei Yu; Yi-Hsin Wu; Sheng‐De Wang",
    "corresponding_authors": "",
    "abstract": "We propose an in-place search algorithm for computing the exact solutions to the resource constrained scheduling problem. This algorithm supports operation chaining, pipelining and multicycling in the underlying scheduling problem. Based on two lower-bound estimation mechanisms that are capable of predicting the criterion values of search nodes represented by partially scheduled data flow graphs, the proposed algorithm can effectively prune the nonpromising search space and finds the optimum usually several times faster than existing techniques. As opposed to existing search-based scheduling techniques whose space complexity is squared or exponential in the search depth, our approach requires only a constant storage space during the traversal of the search tree. The low space complexity is accomplished by using a combination-generating algorithm, which leads our approach to visit search nodes in such a way that each one is obtained by making only a small change to its sibling without keeping any parent nodes in memory. Experimental results on several well known benchmarks with varying resource constraints show the effectiveness of the proposed algorithm.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2057913622",
    "type": "article"
  },
  {
    "title": "Timing variation-aware scheduling and resource binding in high-level synthesis",
    "doi": "https://doi.org/10.1145/2003695.2003700",
    "publication_date": "2011-10-01",
    "publication_year": 2011,
    "authors": "Kartikey Mittal; Arpit Joshi; Madhu Mutyam",
    "corresponding_authors": "",
    "abstract": "Due to technological scaling, process variations have increased significantly, resulting in large variations in the delay of the functional units. Hence, the worst-case approach is becoming increasingly pessimistic in meeting a certain performance yield. The problem therefore is to increase the performance as much as possible while maintaining the desired yield. In this work, we introduce an integer linear programming (ILP) formulation for scheduling and resource binding in high-level synthesis (HLS) which tries to mitigate the effect of timing variations. In the presence of delay variations of resources, as chained resources can give a better latency and performance yield trade-off, instead of considering them independently, we consider external chaining of resources, that is, two or more resources are connected by external wiring, and exploit operation chaining. Without violating the yield constraints, the proposed ILP formulation chains two consecutive operations and binds these chained operations to chained resources for minimizing the overall latency of the schedule. Our ILP formulation also makes sure that two consecutive operations can be chained over multiple clock cycles so that it becomes possible to access the data in the middle of the chained operations at the start of the clock steps over which the operations are chained. By solving our ILP formulation using ILOG CPLEX, we show that our mechanism achieves lesser latency in most cases, compared to the no-chaining case. Significant performance improvement is achieved even for the 100% yield case, which has never been demonstrated in any published work, to the best of our knowledge.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2063400142",
    "type": "article"
  },
  {
    "title": "Design of energy-efficient, adaptable throughput systems at near/sub-threshold voltage",
    "doi": "https://doi.org/10.1145/2390191.2390194",
    "publication_date": "2013-01-01",
    "publication_year": 2013,
    "authors": "Meeta Srivastav; M. Henry; Leyla Nazhandali",
    "corresponding_authors": "",
    "abstract": "Voltage scaling has been a prevalent method of saving energy for energy-constrained applications. However, current technology trends which shrink transistors sizes exacerbate process variation effects in voltage-scaled systems. Large variations in transistor parameters result in high variation in performance and power across the chip. These effects, if ignored at the design, stage, will result in unpredictable behavior when deployed in the field. In this article, we leverage the benefits of voltage scaling methodology for obtaining energy efficiency and compensate for the loss in throughput by exploiting parallelism present in the various DSP designs. We show that such a hybrid method consumes 8%--77% less power, compared to simple dynamic voltage scaling over different throughputs. We study this system architecture in two different workload environments: static and dynamic. We show that to achieve the highest level of energy efficiency, the number of cores and the operating voltages vary widely between a BASE design versus a process variation-aware (PVA) design. We further demonstrate that the PVA design enjoys an average of 26.9% and 51.1% reduction in energy consumption for the static and dynamic designs, respectively. Since different cores will have a wide range of speeds at operating voltages close to near/sub-thresholds due to process variation, we gather characteristic behavior of each core. With knowledge of the core speeds, we can further increase the energy efficiency. Furthermore, in this article, we show that of this methodology will be 49.3% more energy efficient, compared to that building the system with no knowledge about the characteristics of each core.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2079439147",
    "type": "article"
  },
  {
    "title": "Thermal analysis of multiprocessor SoC applications by simulation and verification",
    "doi": "https://doi.org/10.1145/1698759.1698765",
    "publication_date": "2010-02-01",
    "publication_year": 2010,
    "authors": "Dipankar Das; P. P. Chakrabarti; Rajeev Kumar",
    "corresponding_authors": "",
    "abstract": "Overheating of computer chips leads to degradation of performance and reliability. Therefore, preventing chips from overheating in spite of increased performance requirements has emerged as a major challenge. Since the cost of cooling has been rising steadily, various architecture and application design techniques are used to prevent chip overheating. Temperature-aware task scheduling has emerged as an important application design methodology for addressing this problem in multiprocessor SoC systems. In this work we present the formulation and implementation of a method for analyzing the thermal (chip heating) behavior of a MPSoC task schedule, during the early stages of the design. We highlight the challenges in developing such a framework and propose solutions for tackling them. Due to nondeterminism in task execution times and decision branches, multiprocessor applications cannot be evaluated accurately by the current state-of-the-art thermal simulation and steady-state analysis methods. Hence an analysis covering nondeterministic execution behaviors is required for thermal analysis of MPSoC task schedules. To address this issue we propose a model checking-based approach for solving the thermal analysis problem and formulate it as a hybrid automata reachability verification problem. We present an algorithm for constructing this hybrid automata given the task schedule, a set of power profiles of tasks, and the Compact Thermal Model (CTM) of the chip. Information about task power consumption is inferred from Markov chains which are learned from power profiles of tasks, obtained from simulation or emulation runs. A numerical analysis-based algorithm which uses CounterExample-Guided Abstraction Refinement (CEGAR) is developed for reachability analysis of this hybrid automata. We propose a directed simulation methodology which uses results of a time-bounded analysis of the hybrid automata modeling thermal behavior of the application, to simulate the expected worst-case execution runs of the same. The algorithms presented in this work have been implemented in a prototype tool called HeatCheck . We present experimental results and analysis of thermal behavior of a set of task schedules executing on a MPSoC system.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2085914595",
    "type": "article"
  },
  {
    "title": "The Synthesis of Cyclic Dependencies with Boolean Satisfiability",
    "doi": "https://doi.org/10.1145/2348839.2348848",
    "publication_date": "2012-10-01",
    "publication_year": 2012,
    "authors": "John Backes; Marc D. Riedel",
    "corresponding_authors": "",
    "abstract": "The accepted wisdom is that combinational circuits must have acyclic (i.e., feed-forward) topologies. Yet simple examples suggest that this is incorrect. In fact, introducing cycles (i.e., feedback) into combinational designs can lead to significant savings in area and in delay. Prior work described methodologies for synthesizing cyclic circuits with Sum-Of-Product (SOP) and Binary-Decision Diagram (BDD)-based formulations. Recently, techniques for analyzing and mapping cyclic circuits based on Boolean satisfiability (SAT) were proposed. This article presents a SAT-based methodology for synthesizing cyclic dependencies. The strategy is to generate cyclic functional dependencies through a technique called Craig interpolation. Given a choice of different functional dependencies, a branch-and-bound search is performed to pick the best one. Experiments on benchmark circuits demonstrate the effectiveness of the approach.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2092333098",
    "type": "article"
  },
  {
    "title": "ECO cost measurement and incremental gate sizing for late process changes",
    "doi": "https://doi.org/10.1145/2390191.2390207",
    "publication_date": "2013-01-01",
    "publication_year": 2013,
    "authors": "J. Jack Lee; Puneet Gupta",
    "corresponding_authors": "",
    "abstract": "Changes in the manufacturing process parameters may create timing violations in a design, making it necessary to perform an engineering change order (ECO) to correct these problems. We present a framework for performing incremental gate sizing for process changes late in the design cycle, and a method for creating initial designs that are robust to late process changes. This includes a method for measuring and estimating ECO cost and for transforming these costs into linear programming optimization problems. In the case of ECOs, the method reduces ECO costs on average, by 89% in changed area compared to a leading commercial tool. Furthermore, the robust initial designs are, on average, 55% less likely to need redesign in the future.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2104069607",
    "type": "article"
  },
  {
    "title": "Resource Sharing of Pipelined Custom Hardware Extension for Energy-Efficient Application-Specific Instruction Set Processor Design",
    "doi": "https://doi.org/10.1145/2348839.2348843",
    "publication_date": "2012-10-01",
    "publication_year": 2012,
    "authors": "Hai Lin; Yunsi Fei",
    "corresponding_authors": "",
    "abstract": "Application-Specific Instruction set Processor (ASIP) has become an increasingly popular platform for embedded systems because of its high performance, flexibility, and short turn-around time. The hardware extension in ASIPs can speed-up program execution. However, it also incurs area overhead and extra static energy consumption. Traditional datapath merging techniques reduce the circuit overhead by reusing hardware modules for executing multiple operations. However, they introduce structural hazard for multiple custom instructions in sequence, and hence reduce the performance improvement. In this article, we introduce a pipelined configurable structure for the hardware extension in ASIPs, so that structural hazards can be remedied. With multiple subgraphs of operations selected, we design a novel operation-to-hardware mapping algorithm based on Integer Linear Programming (ILP) to automatically construct a resource-efficient pipelined configurable functional unit. Different resource sharing schemes would affect both the hardware overhead and the overall performance improvement. We analyze the design trade-offs between resource efficiency and performance improvement. At the end, we present our design space exploration results by setting the optimization objective to area, area and delay, and delay respectively.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2117205775",
    "type": "article"
  },
  {
    "title": "Phase-adjustable error detection flip-flops with 2-stage hold-driven optimization, slack-based grouping scheme and slack distribution control for dynamic voltage scaling",
    "doi": "https://doi.org/10.1145/1698759.1698767",
    "publication_date": "2010-02-01",
    "publication_year": 2010,
    "authors": "Masanori Kurimoto; Hiroaki Suzuki; Rei Akiyama; T. Yamanaka; Haruyuki Ohkuma; Hidehiro Takata; Hirofumi Shinohara",
    "corresponding_authors": "",
    "abstract": "For Dynamic Voltage Scaling (DVS), we propose a novel design methodology. This methodology is composed of an error detection circuit and three technologies to reduce the area and power penalties which are the large issues for the conventional DVS with error detection. The proposed circuit, Phase-Adjustable Error Detection Flip-Flip (PEDFF), adjusts the clock phase of an additional FF for the timing error detection, based on the timing slack. 2-Stage Hold-Driven Optimization (2-SHDO) technology splits the hold-driven optimization in two stages. Slack-Based Grouping Scheme (SBGS) technology divides each timing path into appropriate groups based on the timing slack. Slack Distribution Control (SDC) technology improves the sharp distribution of the path delay at which the logic synthesis tool has relaxed the delay. We evaluate the methodology by simulating a 32-bit microprocessor in 90 nm CMOS technology. The proposed methodology reduces the energy consumption by 19.8% compared to non-DVS. The OR-tree's latency is shortened to 16.3% compared to the conventional DVS. The area and power penalties for delay buffers on short paths are reduced to 35.0% and 40.6% compared to the conventional DVS, respectively. The proposed methodology with SDC reduces the energy consumption by 17.0% on another example with the sharp slack distribution by the logic synthesis compared to non-DVS.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2135033600",
    "type": "article"
  },
  {
    "title": "Obfuscation-Based Protection Framework against Printed Circuit Boards Unauthorized Operation and Reverse Engineering",
    "doi": "https://doi.org/10.1145/3035482",
    "publication_date": "2017-04-27",
    "publication_year": 2017,
    "authors": "Zimu Guo; Jia Di; Mark Tehranipoor; Domenic Forte",
    "corresponding_authors": "",
    "abstract": "Printed circuit boards (PCBs) are a basic necessity for all modern electronic systems but are becoming increasingly vulnerable to cloning, overproduction, tampering, and unauthorized operation. Most efforts to prevent such attacks have only focused on the chip level, leaving a void for PCBs and higher levels of abstraction. In this article, we propose the first ever obfuscation-based framework for the protection of PCBs. Central to our approach is a permutation block that hides the inter-chip connections between chips on the PCB and is controlled by a key. If the correct key is applied, then the correct connections between chips are made. Otherwise, the connections are incorrectly permuted, and the PCB/system fails to operate. We propose a permutation network added to the PCB based on a Benes network that can easily be implemented in a complex programmable logic device or field-programmable gate arrays. Based on this implementation, we analyze the security of our approach with respect to (i) brute-force attempts to reverse engineer the PCB, (ii) brute-force attempts at guessing the correct key, and (iii) physical and logistic attacks by a range of adversaries. Performance evaluation results on 12 reference designs show that brute force generally requires prohibitive time to break the obfuscation. We also provide detailed requirements for countermeasures that prevent reverse engineering, unauthorized operation, and so on, for different classes of attackers.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2608112030",
    "type": "article"
  },
  {
    "title": "A Disturbance-Free Built-In Self-Test and Diagnosis Technique for DC-DC Converters",
    "doi": "https://doi.org/10.1145/3152157",
    "publication_date": "2017-12-21",
    "publication_year": 2017,
    "authors": "Maryam Shafiee; Navankur Beohar; Priyanka Bakliwal; S. Sanoj Kumar Roy; Debashis Mandal; Bertan Bakkaloğlu; Sule Ozev",
    "corresponding_authors": "",
    "abstract": "Complex electronic systems include multiple power domains and drastically varying dynamic power consumption patterns, requiring the use of multiple power conversion and regulation units. High-frequency switching converters have been gaining prominence in the DC-DC converter market due to their high efficiency and smaller form factor. Unfortunately, they are also subject to higher process variations, and faster in-field degradation, jeopardizing stable operation of the power supply. This article presents a technique to track changes in the dynamic loop characteristics of DC-DC converters without disturbing the normal mode of operation using a white noise–based excitation and correlation. Using multiple points for injection and analysis, we show that the degraded part can be diagnosed to take remedial action. White noise excitation is generated via a pseudo-random disturbance at reference, load current, and pulse-width modulation (PWM) nodes of the converter with the test signal energy being spread over a wide bandwidth, without significantly affecting the converter noise and ripple floor. The impulse response is extracted by correlating the random input sequence with the disturbed output generated. Test signal analysis is achieved by correlating the pseudo-random input sequence with the output response and thereby accumulating the desired behavior over time and pulling it above the noise floor of the measurement set-up. An off-the-shelf power converter, LM27402, is used as the device-under-test (DUT) for experimental verification. Experimental results show that the proposed technique can estimate converter natural frequency and quality factor ( Q -factor) within ±2.5% and ±0.7% error margin respectively, over changes in load inductance and capacitance. For the diagnosis purpose, a measure of inductor's DC resistance (DCR) value, which is the inductor's series resistance and indicative of the degradation in inductor's Q -factor, is estimated within less than ±1.6% error margin.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2780934147",
    "type": "article"
  },
  {
    "title": "Design-for-testability for multi-cycle broadside tests by holding of state variables",
    "doi": "https://doi.org/10.1145/2566665",
    "publication_date": "2014-03-01",
    "publication_year": 2014,
    "authors": "Irith Pomeranz",
    "corresponding_authors": "Irith Pomeranz",
    "abstract": "This article describes a design-for-testability approach for increasing the transition fault coverage of multi-cycle broadside tests. Earlier methods addressed two-cycle tests. The importance of multi-cycle tests results from the ability to produce more compact test sets than possible with two-cycle tests, from the fact that when multi-cycle tests are applied at-speed, they can detect defects that are not detected by two-cycle tests and from their ability to avoid overtesting of delay faults. The approach described in this article is based on holding the values of selected state variables constant during the functional clock cycles of a multi-cycle broadside test. This allows new tests to be produced, which are different from broadside tests, without relying on nonfunctional toggling of state variables as in earlier methods for two-cycle tests. Experimental results show significant improvements in transition fault coverage using a fixed set of hold configurations for two types of multi-cycle broadside test sets: (1) test sets that are stored and applied from an external tester, and (2) functional broadside test sets that are generated using on-chip hardware.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2031532240",
    "type": "article"
  },
  {
    "title": "Efficient Coverage-Driven Stimulus Generation Using Simultaneous SAT Solving, with Application to SystemVerilog",
    "doi": "https://doi.org/10.1145/2651400",
    "publication_date": "2014-11-18",
    "publication_year": 2014,
    "authors": "An-Che Cheng; Chia-Chih Yen; Celina G. Val; Sam Bayless; Alan J. Hu; Iris Hui-Ru Jiang; Jing-Yang Jou",
    "corresponding_authors": "",
    "abstract": "SystemVerilog provides powerful language constructs for verification, and one of them is the covergroup functional coverage model. This model is designed as a complement to assertion verification, that is, it has the advantage of defining cross-coverage over multiple coverage points. In this article, a coverage-driven verification (CDV) approach is formulated as a simultaneous Boolean satisfiability (SAT) problem that is based on covergroups. The coverage bins defined by the functional model are converted into Conjunction Normal Form (CNF) and then solved together by our proposed simultaneous SAT algorithm PLNSAT to generate stimuli for improving coverage. The basic PLNSAT algorithm is then extended in our second proposed algorithm GPLNSAT, which exploits additional information gleaned from the structure of SystemVerilog covergroups. Compared to generating stimuli separately, the simultaneous SAT approaches can share learned knowledge across each coverage target, thus reducing the overall solving time drastically. Experimental results on a UART circuit and the largest ITC benchmark circuits show that the proposed algorithms can achieve 10.8x speedup on average and outperform state-of-the-art techniques in most of the benchmarks.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2063008354",
    "type": "article"
  },
  {
    "title": "Power and Area Efficiency NoC Router Design for Application-Specific SoC by Using Buffer Merging and Resource Sharing",
    "doi": "https://doi.org/10.1145/2633604",
    "publication_date": "2014-08-01",
    "publication_year": 2014,
    "authors": "Kun-Lin Tsai; Hao-Tse Chen; Yo-An Lin",
    "corresponding_authors": "",
    "abstract": "Network-on-Chip (NoC) is an efficient on-chip communication architecture specifically for System-on-a-Chip (SoC) design. However, the input buffers of a NoC router often take a significant portion of the silicon area and power consumption. Besides, the performance of a NoC is also greatly affected by the buffer size. In this article, a static buffer merging and resource sharing method is proposed for the application-specific SoC minimizing the NoC buffer. When given an application-specific task graph and the dataflow distribution, the proposed method statically merges rarely used buffers and generates the suitable number of input buffers for each router at design timely. The merged buffer is shared by several input directions. The experimental result shows that the buffer can be utilized more effectively after the resource sharing. Based on the synthesized design with TSMC 90nm technology, the proposed method reduces an average of 42.23% area and 35.13% power while providing similar performance.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2090424385",
    "type": "article"
  },
  {
    "title": "Performance-Driven Unit-Capacitor Placement of Successive-Approximation-Register ADCs",
    "doi": "https://doi.org/10.1145/2770872",
    "publication_date": "2015-12-02",
    "publication_year": 2015,
    "authors": "Chien‐Chih Huang; Chin‐Long Wey; Jwu-E Chen; Pei-Wen Luo",
    "corresponding_authors": "",
    "abstract": "The performance of many switched-capacitor analog integrated circuits, such as analog-to-digital converters (ADCs) and sample and hold circuits, is directly related to their accurate capacitance ratios. In general, capacitor mismatch can result from two sources of errors: random mismatch and systematic mismatch. Paralleling unit capacitance (UC) with a common-centroid structure can alleviate the random mismatch errors. The complexity of generating an optimal solution to the UC placement problem is extremely high, let alone if both placement and routing problems are to be optimized simultaneously. This article evaluates the performance of the UC placement generated in an existing work and proposes an alternative UC placement to achieve optimal ratio mismatch M and better linearity performance of SAR ADC design. Results show that the proposed UC placement achieves a ratio mismatch of M = 0.695, the effective number of bits ENOB = 8.314 bits, and the integral nonlinearity INL = 0.816 LSB (least significant bits) for a 9-bit SAR ADC design.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2194574225",
    "type": "article"
  },
  {
    "title": "Synthesis of Dual-Mode Circuits Through Library Design, Gate Sizing, and Clock-Tree Optimization",
    "doi": "https://doi.org/10.1145/2856032",
    "publication_date": "2016-05-11",
    "publication_year": 2016,
    "authors": "Sangmin Kim; Seokhyeong Kang; Youngsoo Shin",
    "corresponding_authors": "",
    "abstract": "A dual-mode circuit is a circuit that has two operating modes: a default high-performance mode at nominal voltage and a secondary low-performance near-threshold voltage (NTV) mode. A key problem that we address is to maximize NTV mode clock frequency. Some cells that are particularly slow in NTV mode are optimized through transistor sizing and stack removal; static noise margin of each gate is extracted and appended in a library so that function failures can be checked and removed during synthesis. A new gate-sizing algorithm is proposed that takes account of timing slacks at both modes. A new sensitivity measure is introduced for this purpose; binary search is then applied to find the maximum NTV mode frequency. Clock-tree synthesis is reformulated to minimize clock skew at both modes. This is motivated by the fact that the proportion of load-dependent delay along clock paths, as well as clock-path delays themselves, should be made equal. Experiments on some test circuits indicate that NTV mode clock period is reduced by 24%, on average; clock skew at NTV decreases by 13%, on average; and NTV mode energy-delay product is reduced by 20%, on average.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2388355420",
    "type": "article"
  },
  {
    "title": "Library-Based Placement and Routing in FPGAs with Support of Partial Reconfiguration",
    "doi": "https://doi.org/10.1145/2901295",
    "publication_date": "2016-05-18",
    "publication_year": 2016,
    "authors": "Fubing Mao; Yi‐Chung Chen; Wei Zhang; Hai Li; Bingsheng He",
    "corresponding_authors": "",
    "abstract": "While traditional Field-Programmable Gate Array design flow usually employs fine-grained tile-based placement, modular placement is increasingly required to speed up the large-scale placement and save the synthesis time. Moreover, the commonly used modules can be pre-synthesized and stored in the library for design reuse to significantly save the design, verification time, and development cost. Previous work mainly focuses on modular floorplanning without module placement information. In this article, we propose a library-based placement and routing flow that best utilizes the pre-placed and routed modules from the library to significantly save the execution time while achieving the minimal area-delay product. The flow supports the static and reconfigurable modules at the same time. The modular information is represented in the B*-Tree structure, and the B*-Tree operations are amended together with Simulated Annealing to enable a fast search of the placement space. Different width-height ratios of the modules are exploited to achieve area-delay product optimization. Partial reconfiguration-aware routing using pin-to-wire abutment is proposed to connect the modules after placement. Our placer can reduce the compilation time by 65% on average with 17% area and 8.2% delay overhead compared with the fine-grained results of Versatile Place and Route through the reuse of module information in the library for the base architecture. For other architectures, the area increase ranges from 8.32% to 25.79%, the delay varies from − 13.66% to 19.79%, and the runtime improves by 43.31% to 77.2%.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2399946272",
    "type": "article"
  },
  {
    "title": "Probabilistic Model Checking for Uncertain Scenario-Aware Data Flow",
    "doi": "https://doi.org/10.1145/2914788",
    "publication_date": "2016-09-02",
    "publication_year": 2016,
    "authors": "Joost-Pieter Katoen; Hao Wu",
    "corresponding_authors": "",
    "abstract": "The Scenario-Aware Dataflow (SADF) model is based on concurrent actors that interact via channels. It combines streaming data and control to capture scenarios while incorporating hard and soft real-time aspects. To model data-flow computations that are subject to uncertainty, SADF models are equipped with random primitives. We propose to use probabilistic model checking to analyze uncertain SADF models. We show how measures such as expected time, long-run objectives like throughput, as well as timed reachability—can a given system configuration be reached within a deadline with high probability?—can be automatically determined. The crux of our method is a compositional semantics of SADF with exponential agent execution times combined with automated abstraction techniques akin to partial-order reduction. We present the semantics in detail and show how it accommodates the incorporation of execution platforms, enabling the analysis of energy consumption. The feasibility of our approach is illustrated by analyzing several quantitative measures of an MPEG-4 decoder and an industrial face recognition application.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2514391951",
    "type": "article"
  },
  {
    "title": "Toward a Human-Readable State Machine Extraction",
    "doi": "https://doi.org/10.1145/3513086",
    "publication_date": "2022-02-18",
    "publication_year": 2022,
    "authors": "Michaela Brunner; Alexander Hepp; Johanna Baehr; Georg Sigl",
    "corresponding_authors": "",
    "abstract": "The target of sequential reverse engineering is to extract the state machine of a design. Sequential reverse engineering of a gate-level netlist consists of the identification of so-called state flip-flops (sFFs), as well as the extraction of the state machine. The second step can be solved with an exact approach if the correct sFFs and the correct reset state are provided. For the first step, several more or less heuristic approaches exist. This work investigates sequential reverse engineering with the objective of a human-readable state machine extraction. A human-readable state machine reflects the original state machine and is not overloaded by additional design information. For this purpose, the work derives a systematic categorization of sFF sets, based on properties of single sFFs and their sets. These properties are determined by analyzing the degrees of freedom in describing state machines as the well-known Moore and Mealy machines. Based on the systematic categorization, this work presents an sFF set definition for a human-readable state machine, categorizes existing sFF identification strategies, and develops four post-processing methods. The results show that post-processing predominantly improves the outcome of several existing sFF identification algorithms.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4213304450",
    "type": "article"
  },
  {
    "title": "Energy Efficient Boosting of GEMM Accelerators for DNN via Reuse",
    "doi": "https://doi.org/10.1145/3503469",
    "publication_date": "2022-02-24",
    "publication_year": 2022,
    "authors": "Nihat Mert Cicek; Xipeng Shen; Özcan Öztürk",
    "corresponding_authors": "",
    "abstract": "Reuse-centric convolutional neural networks (CNN) acceleration speeds up CNN inference by reusing computations for similar neuron vectors in CNN’s input layer or activation maps. This new paradigm of optimizations is, however, largely limited by the overheads in neuron vector similarity detection, an important step in reuse-centric CNN. This article presents an in-depth exploration of architectural support for reuse-centric CNN. It addresses some major limitations of the state-of-the-art design and proposes a novel hardware accelerator that improves neuron vector similarity detection and reduces the energy consumption of reuse-centric CNN inference. The accelerator is implemented to support a wide variety of neural network settings with a banked memory subsystem. Design exploration is performed through RTL simulation and synthesis on an FPGA platform. When integrated into Eyeriss, the accelerator can potentially provide improvements up to 7.75 \\( \\times \\) in performance. Furthermore, it can reduce the energy used for similarity detection up to 95.46%, and it can accelerate the convolutional layer up to 3.63 \\( \\times \\) compared to the software-based implementation running on the CPU.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4213431941",
    "type": "article"
  },
  {
    "title": "Structured Dynamic Precision for Deep Neural Networks Quantization",
    "doi": "https://doi.org/10.1145/3549535",
    "publication_date": "2022-07-19",
    "publication_year": 2022,
    "authors": "Kai Huang; Bowen Li; Dongliang Xiong; Haitian Jiang; Xiaowen Jiang; Xiaolang Yan; Luc Claesen; Dehong Liu; Junjian Chen; Zhili Liu",
    "corresponding_authors": "",
    "abstract": "Deep Neural Networks (DNNs) have achieved remarkable success in various Artificial Intelligence applications. Quantization is a critical step in DNNs compression and acceleration for deployment. To further boost DNN execution efficiency, many works explore to leverage the input-dependent redundancy with dynamic quantization for different regions. However, the sensitive regions in the feature map are irregularly distributed, which restricts the real speed up for existing accelerators. To this end, we propose an algorithm-architecture co-design, named Structured Dynamic Precision (SDP). Specifically, we propose a quantization scheme in which the high-order bit part and the low-order bit part of data can be masked independently. And a fixed number of term parts are dynamically selected for computation based on the importance of each term in the group. We also present a hardware design to enable the algorithm efficiently with small overheads, whose inference time mainly scales with the precision proportionally. Evaluation experiments on extensive networks demonstrate that compared to the state-of-the-art dynamic quantization accelerator DRQ, our SDP can achieve 29% performance gain and 51% energy reduction for the same level of model accuracy.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4285798357",
    "type": "article"
  },
  {
    "title": "Machine Learning Based Framework for Fast Resource Estimation of RTL Designs Targeting FPGAs",
    "doi": "https://doi.org/10.1145/3555047",
    "publication_date": "2022-09-29",
    "publication_year": 2022,
    "authors": "Benzheng Li; Xi Zhang; Hailong You; Zhongdong Qi; Yuming Zhang",
    "corresponding_authors": "",
    "abstract": "Field-programmable gate arrays (FPGAs) have grown to be an important platform for integrated circuit design and hardware emulation. However, with the dramatic increase in design scale, it has become a key challenge to partition very large scale integration into multi-FPGA systems. Fast estimation of FPGA on-chip resource usage for individual sub-circuit blocks early in the circuit design flow will provide an essential basis for reasonable circuit partition. It will also help FPGA designers to tune the circuits in hardware description language. In this article, we propose a framework for fast estimation of the on-chip resources consumed by register transfer level (RTL) designs with machine learning methods. We extensively collect RTL designs as a dataset, extract features from the result of a parser tool and analyze their roles, and train a targeted three-stage ensemble learning model. A 5,513× speedup is achieved while having 27% relative absolute error. Although the effect is sufficient to support RTL circuit partition, we discuss how the estimation quality continues to be improved.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4297999712",
    "type": "article"
  },
  {
    "title": "Multiterminal Pathfinding in Practical VLSI Systems with Deep Neural Networks",
    "doi": "https://doi.org/10.1145/3564930",
    "publication_date": "2022-10-13",
    "publication_year": 2022,
    "authors": "Dmitry Utyamishev; Inna Partin-Vaisband",
    "corresponding_authors": "",
    "abstract": "A multiterminal obstacle-avoiding pathfinding approach is proposed. The approach is inspired by deep image learning. The key idea is based on training a conditional generative adversarial network (cGAN) to interpret a pathfinding task as a graphical bitmap and consequently map a pathfinding task onto a pathfinding solution represented by another bitmap. To enable the proposed cGAN pathfinding, a methodology for generating synthetic dataset is also proposed. The cGAN model is implemented in Python/Keras, trained on synthetically generated data, evaluated on practical VLSI benchmarks, and compared with state-of-the-art. Due to effective parallelization on GPU hardware, the proposed approach yields a state-of-the-art-like wirelength and a better runtime and throughput for moderately complex pathfinding tasks. However, the runtime and throughput with the proposed approach remain constant with an increasing task complexity, promising orders of magnitude improvement over state-of-the-art in complex pathfinding tasks. The cGAN pathfinder can be exploited in numerous high throughput applications, such as, navigation, tracking, and routing in complex VLSI systems. The last is of particular interest to this work.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4304891868",
    "type": "article"
  },
  {
    "title": "ECO-GNN: Signoff Power Prediction Using Graph Neural Networks with Subgraph Approximation",
    "doi": "https://doi.org/10.1145/3569942",
    "publication_date": "2022-10-27",
    "publication_year": 2022,
    "authors": "Yi‐Chen Lu; Siddhartha Nath; Sai Pentapati; Sung Kyu Lim",
    "corresponding_authors": "",
    "abstract": "Modern electronic design automation flows depend on both implementation and signoff tools to perform timing-constrained power optimization through Engineering Change Orders (ECOs), which involve gate sizing and threshold-voltage ( V th )-assignment of standard cells. However, the signoff ECO optimization is highly time-consuming, and the power improvement is hard to predict in advance. Ever since the industrial benchmarks released by the ISPD-2012 gate-sizing contest, active research has been conducted extensively to improve the optimization process. Nonetheless, previous works were mostly based on heuristics or analytical methods whose timing models were oversimplified and lacked of formal validations from commercial signoff tools. In this article, we propose ECO-graph neural networks (GNN), a transferable graph-learning-based framework, which harnesses GNNs to perform commercial-quality signoff power optimization through discrete ( V th -assignment. One of the highlights of our framework is that it generates tool-accurate optimization results instantly on unseen netlists that are not utilized in the training process. Furthermore, we propose a subgraph approximation technique to improve training and inferencing time of the proposed GNN model. We show that design instances with non-overlapping subgraphs can be optimized in parallel so as to improve the inference time of the learning-based model. Finally, we implement a GNN-based explanation method to interpret the optimization results achieved by our framework. Experimental results on 14 industrial designs, including a RISC-V-based multi-core system and the renowned ISPD-2012 benchmarks, demonstrate that our framework achieves up to 14× runtime improvement with similar signoff power optimization quality compared with Synopsys PrimeTime , an industry-leading signoff tool.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4307641039",
    "type": "article"
  },
  {
    "title": "A Switching NMOS Based Single Ended Sense Amplifier for High Density SRAM Applications",
    "doi": "https://doi.org/10.1145/3576198",
    "publication_date": "2022-12-12",
    "publication_year": 2022,
    "authors": "Bhawna Rawat; Poornima Mittal",
    "corresponding_authors": "",
    "abstract": "The demand for single ended static random access memory is growing, driven by the decreasing technology node and increasing processing load. This mandates the need for a single ended sense amplifier to be used along with the memory. Consequently, a single ended latch based sense amplifier is proposed in this article for high-speed, low power application. The sense amplifier is designed at a 32 nm technology node and its functioning is analyzed at 1 V supply voltage, while the environment temperature is maintained at 27 °C. It is analyzed for its delay, temperature tolerance, variability tolerance, and area occupancy. The delay requirement of 0.2 ns for the proposed scheme is significantly lower in comparison to its other counter parts. While, its false read time is 0.3μs. In terms of power consumption, the proposed sensing topology is marginally higher than SPSS, but its leakage power is 1.4 times less than SPSS. The major advantage of the proposed SA is its reduced area footprint of 7.65 μm 2 , which is 1.78 times better than the best pre-existing topology in terms of area.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4311410228",
    "type": "article"
  },
  {
    "title": "DAGSizer: A Directed Graph Convolutional Network Approach to Discrete Gate Sizing of VLSI Graphs",
    "doi": "https://doi.org/10.1145/3577019",
    "publication_date": "2022-12-16",
    "publication_year": 2022,
    "authors": "Chung‐Kuan Cheng; Chester Holtz; Andrew B. Kahng; Bill Lin; Uday Mallappa",
    "corresponding_authors": "",
    "abstract": "The objective of a leakage recovery step is to make use of positive slack and reduce power by performing appropriate standard-cell swaps such as threshold-voltage ( V th ) or channel-length reassignments. The resulting engineering change order netlist needs to be timing clean. Because this recovery step is performed several times in a physical design flow and involves long runtimes and high tool-license usage, previous works have proposed graph neural network–based frameworks that restrict feature aggregation to three-hop neighborhoods and do not fully consider the directed nature of netlist graphs. As a result, the intermediate node embeddings do not capture the complete structure of the timing graph. In this article, we propose DAGSizer , a framework that exploits the directed acyclic nature of timing graphs to predict cell reassignments in the discrete gate sizing task. Our DAGSizer (Sizer for DAGs) framework is based on a node ordering-aware recurrent message-passing scheme for generating the latent node embeddings. The generated node embeddings absorb the complete information from the fanin cone (predecessors) of the node. To capture the fanout information into the node embeddings, we enable a bidirectional message-passing mechanism. The concatenated latent node embeddings from the forward and reverse graphs are then translated to nodewise delta-delay predictions using a teacher sampling mechanism. With eight possible cell-assignments, the experimental results demonstrate that our model can accurately estimate design-level leakage recovery with an absolute relative error ε model under 5.4%. As compared to our previous work, GRA-LPO, we also demonstrate a significant improvement in the model mean squared error.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4313476040",
    "type": "article"
  },
  {
    "title": "Multi-Objective Optimization for Safety-Related Available E/E Architectures Scoping Highly Automated Driving Vehicles",
    "doi": "https://doi.org/10.1145/3582004",
    "publication_date": "2023-01-25",
    "publication_year": 2023,
    "authors": "Ricardo Gonzalez de Oliveira; Nicolas Navet; Achim Henkel",
    "corresponding_authors": "",
    "abstract": "Megatrends such as Highly Automated Driving (HAD) (SAE ≥ Level 3), electrification, and connectivity are reshaping the automotive industry. Together with the new technologies, the business models will also evolve, opening up new possibilities and new fields of competition. To cope with the ongoing advances, new Electric/Electronic (E/E) architecture patterns are emerging in the sector, distributing the vehicle functions across several processing devices and enhancing the connectivity between them via Ethernet-based networks. Upcoming systems will demand Safety-Related Availability (SaRA) requirements in mixed-critical E/E architectures that challenge the concept of freedom from interference defined in ISO 26262. This work explores the concepts of SaRA system development according to ISO 26262, building a framework based on model-based systems engineering to evaluate feasible next-generation automotive E/E architecture designs with a multi-objective analysis. Additionally, we propose a pattern template for SaRA systems to automate the architecture synthesis. To illustrate the framework created, we evaluate a set of automotive E/E architectures synthesized to support mixed-critical vehicle features, including SaRA SAE Level-3 functions, considering the communication networks’ performance as well as hardware and safety-related development costs. This work presents a methodology for original equipment manufacturers and Tier-1 suppliers that enables them to make the trade-offs arising in the design of E/E architectures based on quantified information.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4318041430",
    "type": "article"
  },
  {
    "title": "Low-energy Pipelined Hardware Design for Approximate Medium Filter",
    "doi": "https://doi.org/10.1145/3582005",
    "publication_date": "2023-01-25",
    "publication_year": 2023,
    "authors": "Mervat M. A. Mahmoud; Nahla Elashkar; H. H. Draz",
    "corresponding_authors": "",
    "abstract": "Image and video processing algorithms are currently crucial for many applications. Hardware implementation of these algorithms provides higher speed for large computation applications. Removing noise is often a typical pre-processing step to enhance the results of later analysis and processing. Median filter is a typical nonlinear filter that is very commonly used for impulse noise elimination in digital image processing. This article suggests a low-energy median filter hardware design for battery-based hardware applications. An approximate solution with high accuracy is investigated to speed up the filtering operation, reduce the area, and consume less power/energy. Pipelining and parallelism are used to optimize the speed and power of this technique. Non-pipelined, two different pipelined structures, and two parallel architectures versions are designed. The design versions are implemented first with a Virtex-5 LX110T FPGA and then using the UMC 130nm standard cell ASIC technology. The selection and the even-odd sorting-based median filters are also implemented for an equitable comparison with the standard median filtering techniques. The suggested non-pipelined median filter design enhances the throughput 35% more than the highest investigated state of the art. The pipelining enhances the throughput to more than twice its value. Additionally, the parallel architecture decreases the area and the consumed power by around 40%. The simulation results reveal that one of the suggested designs significantly decreases the area, with the same speed as the fastest design in the literature, without noticeably degrading the accuracy, and a significant decrease in energy consumption by about 60%.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4318041434",
    "type": "article"
  },
  {
    "title": "Fast Area Optimization Approach for XNOR/OR-based Fixed Polarity Reed-Muller Logic Circuits based on Multi-strategy Wolf Pack Algorithm",
    "doi": "https://doi.org/10.1145/3587818",
    "publication_date": "2023-03-14",
    "publication_year": 2023,
    "authors": "Yuhao Zhou; Zhenxue He; Jianhui Jiang; Jia Liu; Juncai He; Tao Wang; Limin Xiao; Xiang Wang",
    "corresponding_authors": "",
    "abstract": "Area optimization is one of the most important contents of circuits logic synthesis. The smaller area has stronger testability and lower cost. However, searching for a circuit with the smallest area in a large-scale space of polarity is a combinatorial optimization problem. The existing optimization approaches are inefficient and do not consider the time cost. In this paper, we propose a multi-strategy wolf pack algorithm (MWPA) to solve high-dimension combinatorial optimization problems. MWPA performs global search based on the proposed global exploration strategy, extends the search area based on the Levy flight strategy, and performs local search based on the proposed deep exploitation strategy. In addition, we propose a fast area optimization approach (FAOA) for fixed polarity Reed-Muller (FPRM) logic circuits based on MWPA, which searches the best polarity corresponding to a FPRM circuit. The experimental results confirm that FAOA is highly effective and can be used as a promising EDA tool.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4324142445",
    "type": "article"
  },
  {
    "title": "Accelerating Deformable Convolution Networks with Dynamic and Irregular Memory Accesses",
    "doi": "https://doi.org/10.1145/3597431",
    "publication_date": "2023-05-15",
    "publication_year": 2023,
    "authors": "Cheng Chu; Cheng Liu; Dawen Xu; Ying Wang; Tao Luo; Huawei Li; Xiaowei Li",
    "corresponding_authors": "",
    "abstract": "Deformable convolution networks (DCNs) proposed to address image recognition with geometric or photometric variations typically involve deformable convolution that convolves on arbitrary locations of input features. The locations change with different inputs and induce considerable dynamic and irregular memory accesses that cannot be handled by classic neural network accelerators (NNAs). Moreover, bilinear interpolation (BLI) operation, which is required to obtain deformed features in DCNs, also cannot be deployed on existing NNAs directly. Although a general purposed processor (GPP) seated along with classic NNAs can process the deformable convolution, the processing on GPP can be extremely slow due to the limited parallel computing capability and massive additional data movement. To address the problem, we develop a DCN accelerator on existing NNAs to support both the standard convolution and deformable convolution. Specifically, for the dynamic and irregular accesses in DCNs, we have both the input and output features divided into tiles and build a tile dependency table (TDT) to track the irregular tile dependency at runtime. With the TDT, we further develop an on-chip tile scheduler to handle the dynamic and irregular accesses efficiently. In addition, we propose a novel mapping strategy to enable parallel BLI processing on NNAs and apply layer fusion techniques for more energy-efficient DCN processing. According to our experiments, the proposed accelerator achieves orders of magnitude higher performance and energy efficiency compared to the typical computing architectures including ARM, ARM+TPU, and GPU with 6.6% chip area penalty to a classic NNA.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4376616779",
    "type": "article"
  },
  {
    "title": "Boosting VLSI Design Flow Parameter Tuning with Random Embedding and Multi-objective Trust-region Bayesian Optimization",
    "doi": "https://doi.org/10.1145/3597931",
    "publication_date": "2023-05-25",
    "publication_year": 2023,
    "authors": "Su Zheng; Hao Geng; Chen Bai; Bei Yu; Martin D. F. Wong",
    "corresponding_authors": "",
    "abstract": "Modern very large-scale integration (VLSI) design requires the implementation of integrated circuits using electronic design automation (EDA) tools. Due to the complexity of EDA algorithms, there are numerous tool parameters that have imperative impacts on the chip design quality. Manual selection of parameter values is excessively laborious and constrained by experts’ experience. Due to the high complexity and lack of parallelization, most existing parameter tuning methods cannot make sufficient exploration in a large search space. In this article, we boost the efficiency and performance of parameter tuning with random embedding and multi-objective trust-region Bayesian optimization. Random embedding can effectively cut down the number of variables in the search process and thus reduce the runtime of Bayesian optimization. Multi-objective trust-region Bayesian optimization allows the algorithm to explore diverse solutions with excellent parallelism. Due to the ability to do more exploration in limited runtime, the proposed framework can achieve better performance than existing methods in our experiments.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4378218479",
    "type": "article"
  },
  {
    "title": "A General Layout Pattern Clustering Using Geometric Matching-based Clip Relocation and Lower-bound Aided Optimization",
    "doi": "https://doi.org/10.1145/3610293",
    "publication_date": "2023-07-24",
    "publication_year": 2023,
    "authors": "Xu He; Yao Wang; Zhiyong Fu; Yipei Wang; Yang Guo",
    "corresponding_authors": "",
    "abstract": "With the continuous shrinking of feature size, detection of lithography hotspots has been raised as one of the major concerns in Design-for-Manufacturability (DFM) of semiconductor processing. Hotspot detection, along with other DFM measures, trades off turnaround time for the yield of IC manufacturing, and thus a simplified but wide-ranging pattern definition is a key to the problem. Layout pattern clustering methods, which group geometrically similar layout clips into clusters, have been vastly proposed to identify layout patterns efficiently. To minimize the clustering number for subsequent DFM processing, in this article, we propose a geometric-matching-based clip relocation technique to increase the opportunity of pattern clustering. Particularly, we formulate the lower bound of the clustering number as a maximum-clique problem, and we have also proved that the clustering problem can be solved by the result of the maximum-clique very efficiently. Compared with the experimental results of the state-of-the-art approaches on ICCAD 2016 Contest benchmarks, the proposed method can achieve the optimal solutions for all benchmarks with very competitive runtime. To evaluate the scalability, the ICCAD 2016 Contest benchmarks are extended and evaluated. Moreover, experimental results on the extended benchmarks demonstrate that our method can reduce the cluster number by 16.59% on average, while the runtime is 74.11% faster on large-scale benchmarks compared with previous works.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4385222311",
    "type": "article"
  },
  {
    "title": "Lightning: Leveraging DVFS-induced Transient Fault Injection to Attack Deep Learning Accelerator of GPUs",
    "doi": "https://doi.org/10.1145/3617893",
    "publication_date": "2023-09-20",
    "publication_year": 2023,
    "authors": "Rihui Sun; Pengfei Qiu; Yongqiang Lyu; Jian Dong; Haixia Wang; Dongsheng Wang; Gang Qu",
    "corresponding_authors": "",
    "abstract": "Graphics Processing Units (GPU) are widely used as deep learning accelerators because of its high performance and low power consumption. Additionally, it remains secure against hardware-induced transient fault injection attacks, a classic type of attacks that have been developed on other computing platforms. In this work, we demonstrate that well-trained machine learning models are robust against hardware fault injection attacks when the faults are generated randomly. However, we discover that these models have components, which we refer to as sensitive targets, that are vulnerable to faults. By exploiting this vulnerability, we propose the Lightning attack, which precisely strikes the model’s sensitive targets with hardware-induced transient faults based on the Dynamic Voltage and Frequency Scaling (DVFS). We design a sensitive targets search algorithm to find the most critical processing units of Deep Neural Network (DNN) models determining the inference results, and develop a genetic algorithm to automatically optimize the attack parameters for DVFS to induce faults. Experiments on three commodity Nvidia GPUs for four widely-used DNN models show that the proposed Lightning attack can reduce the inference accuracy by 69.1% on average for non-targeted attacks, and, more interestingly, achieve a success rate of 67.9% for targeted attacks.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4386888948",
    "type": "article"
  },
  {
    "title": "Construction of All Multilayer Monolithic RSMTs and Its Application to Monolithic 3D IC Routing",
    "doi": "https://doi.org/10.1145/3626958",
    "publication_date": "2023-10-11",
    "publication_year": 2023,
    "authors": "Monzurul Islam Dewan; Sheng-En David Lin; Dae Hyun Kim",
    "corresponding_authors": "",
    "abstract": "Monolithic three-dimensional (M3D) integration allows ultra-thin silicon tier stacking in a single package. The high-density stacking is acquiring interest and is becoming more popular for smaller footprint areas, shorter wirelength, higher performance, and lower power consumption than the conventional planar fabrication technologies. The physical design of M3D integrated circuits requires several design steps, such as three-dimensional (3D) placement, 3D clock-tree synthesis, 3D routing, and 3D optimization. Among these, 3D routing is significantly time consuming due to countless routing blockages. Therefore, 3D routers proposed in the literature insert monolithic interlayer vias (MIVs) and perform tier-by-tier routing in two substeps. In this article, we propose an algorithm to build a routing topology database (DB) used to construct all multilayer monolithic rectilinear Steiner minimum trees on the 3D Hanan grid. To demonstrate the effectiveness of the DB in various applications, we use the DB to construct timing-driven 3D routing topologies and perform congestion-aware global routing on 3D designs. We anticipate that the algorithm and the DB will help 3D routers reduce the runtime of the MIV insertion step and improve the quality of the 3D routing.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4387540953",
    "type": "article"
  },
  {
    "title": "BOOM-Explorer: RISC-V BOOM Microarchitecture Design Space Exploration",
    "doi": "https://doi.org/10.1145/3630013",
    "publication_date": "2023-10-26",
    "publication_year": 2023,
    "authors": "Chen Bai; Qi Sun; Jianwang Zhai; Yuzhe Ma; Bei Yu; Martin D. F. Wong",
    "corresponding_authors": "",
    "abstract": "Microarchitecture parameters tuning is critical in the microprocessor design cycle. It is a non-trivial design space exploration (DSE) problem due to the large solution space, cycle-accurate simulators’ modeling inaccuracy, and high simulation runtime for performance evaluations. Previous methods require massive expert efforts to construct interpretable equations or high computing resource demands to train black-box prediction models. This article follows the black-box methods due to better solution qualities than analytical methods in general. We summarize two learned lessons and propose BOOM-Explorer accordingly. First, embedding microarchitecture domain knowledge in the DSE improves the solution quality. Second, BOOM-Explorer makes the microarchitecture DSE for register-transfer-level designs within the limited time budget feasible. We enhance BOOM-Explorer with the diversity-guidance, further improving the algorithm performance. Experimental results with RISC-V Berkeley-Out-of-Order Machine under 7-nm technology show that our proposed methodology achieves an average of 18.75% higher Pareto hypervolume, 35.47% less average distance to reference set, and 65.38% less overall running time compared to previous approaches.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4388195174",
    "type": "article"
  },
  {
    "title": "Energy-Constrained Scheduling for Weakly Hard Real-Time Systems Using Standby-Sparing",
    "doi": "https://doi.org/10.1145/3631587",
    "publication_date": "2023-11-14",
    "publication_year": 2023,
    "authors": "Linwei Niu; Danda B. Rawat; Jonathan Musselwhite; Zonghua Gu; Qingxu Deng",
    "corresponding_authors": "",
    "abstract": "For real-time embedded systems, QoS (Quality of Service), fault tolerance, and energy budget constraint are among the primary design concerns. In this research, we investigate the problem of energy constrained standby-sparing for both periodic and aperiodic tasks in a weakly hard real-time environment. The standby-sparing systems adopt a primary processor and a spare processor to provide fault tolerance for both permanent and transient faults. For such kind of systems, we firstly propose several novel standby-sparing schemes for the periodic tasks which can ensure the system feasibility under tighter energy budget constraint than the traditional ones. Then based on them integrated approachs for both periodic and aperiodic tasks are proposed to minimize the aperiodic response time whilst achieving better energy and QoS performance under the given energy budget constraint. The evaluation results demonstrated that the proposed techniques significantly outperformed the existing state-of-the-art approaches in terms of feasibility and system performance while ensuring QoS and fault tolerance under the given energy budget constraint.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4388671810",
    "type": "article"
  },
  {
    "title": "SparGD: A Sparse GEMM Accelerator with Dynamic Dataflow",
    "doi": "https://doi.org/10.1145/3634703",
    "publication_date": "2023-11-27",
    "publication_year": 2023,
    "authors": "Bo Wang; Sheng Ma; Shengbai Luo; Lizhou Wu; Jianmin Zhang; Chunyuan Zhang; Tiejun Li",
    "corresponding_authors": "",
    "abstract": "Deep learning has become a highly popular research field, and previously deep learning algorithms ran primarily on CPUs and GPUs. However, with the rapid development of deep learning, it was discovered that existing processors could not meet the specific large-scale computing requirements of deep learning, and custom deep learning accelerators have become popular. The majority of the primary workloads in deep learning are general matrix-matrix multiplications (GEMMs), and emerging GEMMs are highly sparse and irregular. The TPU and SIGMA are typical GEMM accelerators in recent years, but the TPU does not support sparsity, and both the TPU and SIGMA have insufficient utilization rates of the Processing Element (PE). We design and implement SparGD, a sparse GEMM accelerator with dynamic dataflow. SparGD has specific PE structures, flexible distribution networks and reduction networks, and a simple dataflow switching module. When running sparse and irregular GEMMs, SparGD can maintain high PE utilization while utilizing sparsity, and can switch to the optimal dataflow according to the computing environment. For sparse, irregular GEMMs, our experimental results show that SparGD outperforms systolic arrays by 30 times and SIGMA by 3.6 times.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4389046642",
    "type": "article"
  },
  {
    "title": "On the crossing distribution problem",
    "doi": "https://doi.org/10.1145/298865.298868",
    "publication_date": "1999-01-01",
    "publication_year": 1999,
    "authors": "Xiaoyu Song; Yuke Wang",
    "corresponding_authors": "",
    "abstract": "VLSI layout design is typically decomposed into four steps: placement, global routing, routing region definition, and detailed routing. The crossing distribution problem occurs prior to detailed routing [Groenveld 1989; Mared-Sadowska and Sarrafzadeh 1995; Wang and Shung 1992]. A crossing is defined as the intersection of two nets. The problem of net crossing distribution is important in layout design, such as design of dense chips, multichip modules (MCM), critical net routing, and analog circuits [Groenveld 1989; Sarrafzadah 1995; Wang and Shung 1992]. It is observed that nets crossing each other are more difficult to route than those that do not cross. The layout of crossing nets has to be realized in more than two layers and requires a larger number of vias In this paper we study the crossing distribution problem of two-terminal nets between two regions. We present an optimal O(n2) time algorithm for two-sided nets, where n is the number of nets. Our results are superior to previous ones [Markek-Sadowska and Sarrafzadeh 1995; Wang and Shung 1992]. We give an optimal O(n 2 ) time algorithm for the crossing distribution problem with one-sided nets. We solve optimally the complete version of the crossing distribution problem for two-terminal nets in two regions that has not been studied before.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W1970008483",
    "type": "article"
  },
  {
    "title": "ICOS",
    "doi": "https://doi.org/10.1145/290833.290834",
    "publication_date": "1998-04-01",
    "publication_year": 1998,
    "authors": "Pao‐Ann Hsiung; Chung-Hwang Chen; Trong‐Yen Lee; Sao‐Jie Chen",
    "corresponding_authors": "",
    "abstract": "The design of multiprocessor architectures differs from uniprocessor systems in that the number of processors and their interconnection must be considered. This leads to an enormous increase in the design-space exploration time, which is exponential in the total number of system components. The methodology proposed here, called Intelligent Concurrent Object-Oriented Synthesis (ICOS) methodology, makes feasible the synthesis of complex multiprocessor systems through the application of several techiques that speed up the design process. ICOS is based on Performance Synthesis Methodology (PSM), a recently proposed object-oriented system-level design methodology. Four major techniques: object-oriented design, fuzzy design-space exploration, concurrent design, and intelligent reuse of complete subsystems are integrated in ICOS. First, object-oriented modeling and design, through the use of object-oriented relationships and operators, make the whole design process manageable and maintainable in ICOS. Second, fuzzy comparison applied to the specializations or instances of components reduces the exponential growth of design-space exploration in ICOS. Third, independent components from different design alternatives are synthesized in parallel; this design concurrency shortens the overall design time. Lastly, the resynthesis of complete subsystems can be avoided through the application of learning, thus making the methodology intelligent enough to reuse previous design configurations. Experiments show that all these applied techniques contribute to the synthesis efficiency and the degree of automation in ICOS.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W1970739668",
    "type": "article"
  },
  {
    "title": "Performance-constrained hierarchical pipelining for behaviors, loops, and operations",
    "doi": "https://doi.org/10.1145/371254.371256",
    "publication_date": "2001-01-01",
    "publication_year": 2001,
    "authors": "Smita Bakshi; Daniel D. Gajski",
    "corresponding_authors": "",
    "abstract": "Behavioral specifications of DSP systems generally contain a number of nested loops. In order to obtain high date rates for such systems, it is necessary to pipeline the system within the behavior, within the loop bodies, and also within the operations. In order to hierarchically pipeline a performance-constrained system, an important step consists of distributing the performance constraint among the loops in such a manner that the constraint is satisfied and design cost is minimized. This paper presents an algorithm for propagating constraints and hierarchically pipelining a given throughput-constrained system. Along with pipelining, the algorithm schedules the operations within the loop bodies and selects components for them, with the aim of minimizing cost while satisfying the constraint propagated to the loop body. Results demonstrate the necessity of pipelining across the three granularity levels in order to obtain high performance designs. They also demonstrate the feasibility and quality of our approach, the indicate that it may be efficiently used for synthesizing or estimating within system-level design.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2009586031",
    "type": "article"
  },
  {
    "title": "Search space definition and exploration for nonuniform data reuse opportunities in data-dominant applications",
    "doi": "https://doi.org/10.1145/606603.606610",
    "publication_date": "2003-01-01",
    "publication_year": 2003,
    "authors": "Tanja Van Achteren; Francky Catthoor; Rudy Lauwereins; Geert Deconinck",
    "corresponding_authors": "",
    "abstract": "Efficient exploitation of temporal locality in the memory accesses on array signals can have a very large impact on the power consumption in embedded data dominated applications. The effective use of an optimized custom memory hierarchy or a customized software controlled mapping on a predefined hierarchy is crucial for this. Only recently have effective systematic techniques to deal with this specific design step begun to appear. They are still limited in their exploration scope. In this paper we construct the design space by introducing three parameters which determine how and when copies are made between different levels in a hierarchy, and determine their impact on the total memory size, storage-related power consumption, and code complexity. Strategies are then established for an efficient exploration, such that cost-effective solutions for the memory size/power trade-off can be achieved. The effectiveness of the techniques is demonstrated for several real-life image processing algorithms.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2051334857",
    "type": "article"
  },
  {
    "title": "Two-layer bus routing for high-speed printed circuit boards",
    "doi": "https://doi.org/10.1145/1124713.1124726",
    "publication_date": "2006-01-01",
    "publication_year": 2006,
    "authors": "Muhammet Mustafa Özdal; Martin D. F. Wong",
    "corresponding_authors": "",
    "abstract": "The increasing clock frequencies in high-end industrial circuits bring new routing challenges that cannot be handled by traditional algorithms. An important design automation problem for high-speed boards today is routing nets within tight minimum and maximum length bounds. In this article, we propose an algorithm for routing bus structures between components on two layers such that all length constraints are satisfied. This algorithm handles length extension simultaneously during the actual routing process so that maximum resource utilization is achieved during length extension. Our approach here is to process one track at a time, and choose the best subset of nets to be routed on each track. The algorithm we propose for single-track routing is guaranteed to find the optimal subset of nets together with the optimal solution with length extension on one track. The experimental comparison with a recently proposed technique shows the effectiveness of this algorithm both in terms of solution quality and run-time.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W1997134428",
    "type": "article"
  },
  {
    "title": "An <i>o</i> ( <i>min</i> ( <i>m</i> , <i>n</i> )) parallel deadlock detection algorithm",
    "doi": "https://doi.org/10.1145/1080334.1080341",
    "publication_date": "2005-07-01",
    "publication_year": 2005,
    "authors": "John J. Lee; Vincent J. Mooney",
    "corresponding_authors": "",
    "abstract": "This article presents a novel Parallel Deadlock Detection Algorithm (PDDA) and its hardware implementation, Deadlock Detection Unit (DDU). PDDA uses simple Boolean representations of request, grant, and no activity so that the hardware implementation of PDDA becomes easier and operates faster. We prove the correctness of PDDA and that the DDU has a runtime complexity of O ( min ( m , n )), where m is the number of resources and n is the number of processes. The DDU reduces deadlock detection time by 99%, (i.e., 100X) or more compared to software implementations of deadlock detection algorithms. An experiment involving a practical situation with an early deadlock condition showed that the time measured from application initialization to deadlock detection was reduced by 46% by employing the DDU as compared to detecting deadlock in software.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2114494927",
    "type": "article"
  },
  {
    "title": "Application-aware snoop filtering for low-power cache coherence in embedded multiprocessors",
    "doi": "https://doi.org/10.1145/1297666.1297682",
    "publication_date": "2008-01-01",
    "publication_year": 2008,
    "authors": "Xiangrong Zhou; Chenjie Yu; Alokika Dash; П. П. Петров",
    "corresponding_authors": "",
    "abstract": "Maintaining local caches coherently in shared-memory multiprocessors results in significant power consumption. The customization methodology we propose exploits the fact that in embedded systems, important knowledge is available to the system designers regarding memory sharing between tasks. We demonstrate how the snoop-induced cache probings can be significantly reduced by identifying and exploiting in a deterministic way the shared memory regions between the processors. Snoop activity is enabled only for the accesses referring to known shared regions. The hardware support is not only cost efficient, but also software programmable, which allows for reprogrammability and customization across different tasks and applications.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W1965904410",
    "type": "article"
  },
  {
    "title": "T-trees",
    "doi": "https://doi.org/10.1145/1562514.1562519",
    "publication_date": "2009-08-01",
    "publication_year": 2009,
    "authors": "Ping-Hung Yuh; Chia-Lin Yang; Yao‐Wen Chang",
    "corresponding_authors": "",
    "abstract": "Improving logic capacity by time-sharing, dynamically reconfigurable FPGAs are employed to handle designs of high complexity and functionality. In this article, we model each task as a 3D-box and deal with the temporal floorplanning/placement problem for dynamically reconfigurable FPGA architectures. We present a tree-based data structure, called T-trees , to represent the spatial and temporal relations among tasks. Each node in a T-tree has at most three children which represent the dimensional relationship among tasks. For the T-tree, we develop an efficient packing method and derive the condition to ensure the satisfaction of precedence constraints which model the temporal ordering among tasks induced by the execution of dynamically reconfigurable FPGAs. Experimental results show that our tree-based formulation can obtain significantly better solution quality with less execution time than the most recent state-of-the-art work.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2019789464",
    "type": "article"
  },
  {
    "title": "Lens aberration aware placement for timing yield",
    "doi": "https://doi.org/10.1145/1455229.1455245",
    "publication_date": "2009-01-01",
    "publication_year": 2009,
    "authors": "Andrew B. Kahng; Chul‐Hong Park; Puneet Sharma; Qinke Wang",
    "corresponding_authors": "",
    "abstract": "Process variations due to lens aberrations are to a large extent systematic, and can be modeled for purposes of analyses and optimizations in the design phase. Traditionally, variations induced by lens aberrations have been considered random due to their small extent. However, as process margins reduce, and as improvements in reticle enhancement techniques control variations due to other sources with increased efficacy, lens aberration-induced variations gain importance. For example, our experiments indicate that delays of most cells in the Artisan TSMC 90nm library are affected by 2--8% due to lens aberration. Aberration-induced variations are systematic and depend on the location in the lens field. In this article, we first propose an aberration-aware timing analysis flow that accounts for aberration-induced cell delay variations. We then propose an aberration-aware timing-driven analytical placement approach that utilizes the predictable slow and fast regions created on the chip due to aberration to improve cycle time. We study the dependence of our improvement on chip size, as well as use of the technique along with field blading which allows partial reticle exposure. We evaluate our technique on two testcases, AES and JPEG implemented in 90 nm technology. The proposed technique reduces cycle time by 4.322% (80ps) at the cost of 1.587% increase in trial-routed wirelength for AES. On JPEG, we observe a cycle time reduction of 5.182% (132ps) at the cost of 1.095% increase in trial-routed wirelength.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2064201511",
    "type": "article"
  },
  {
    "title": "Theories and algorithms on single-detour routing for untangling twisted bus",
    "doi": "https://doi.org/10.1145/1529255.1529268",
    "publication_date": "2009-05-01",
    "publication_year": 2009,
    "authors": "Tan Yan; Martin D. F. Wong",
    "corresponding_authors": "",
    "abstract": "Previous works on PCB bus routing assume matched pin ordering on both sides. But in practice, the pin ordering might be mismatched and the nets become twisted. In this article, we propose a preprocessing step to untangle such twisted nets. We also introduce a practical routing style, which we call single-detour routing , to simplify the untangling problem. We then present a necessary and sufficient condition for the existence of single-detour routing solutions. Furthermore, we present a dynamic-programming-based algorithm to solve the single-detour untangling problem with consideration of wire capacity between adjacent pins. Our algorithm produces an optimal single-detour routing solution that rematches the pin ordering. By integrating our algorithm into the bus router in a previous length-matching router, we show that many routing problems that cannot be solved previously can now be solved with insignificant increase in runtime.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2076069777",
    "type": "article"
  },
  {
    "title": "A 252Kgates/4.9Kbytes SRAM/71mW multistandard video decoder for high definition video applications",
    "doi": "https://doi.org/10.1145/1455229.1455246",
    "publication_date": "2009-01-01",
    "publication_year": 2009,
    "authors": "Chih-Da Chien; Cheng-An Chien; Jui-Chin Chu; Jiun-In Guo; Ching-Hwa Cheng",
    "corresponding_authors": "",
    "abstract": "This article proposes a low-cost, low-power multistandard video decoder for high definition (HD) video applications. The proposed design supports multiple-standard (JPEG baseline, MPEG-1/2/4 Simple Profile (SP), and H.264 Baseline Profile (BP)) video decoding through interactive parsing control and common parameter bus interface. In order to reduce hardware cost, the shared adder-based structure and reusable data management are proposed to achieve hardware sharing and reduce internal memory size, respectively. In addition, the proposed design is optimized through reducing memory bandwidth by increasing both data reuse amount and burst length of memory access as well as eliminating cycle overhead in data access for supporting HD video decoding with single AHB-based SDR memory. The proposed 252Kgates/4.9kB/71mW/0.13μm multi-standard video decoder reduces 72% in gate count and 87% in power consumption as compared to the state-of-the-art design, when operating at 120MHz for real-time HD1080 video decoding with single AHB-based SDR memory.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2081076472",
    "type": "article"
  },
  {
    "title": "Direction-Constrained Rectangle Escape Routing",
    "doi": "https://doi.org/10.1145/3178047",
    "publication_date": "2018-02-23",
    "publication_year": 2018,
    "authors": "Jin-Tai Yan",
    "corresponding_authors": "Jin-Tai Yan",
    "abstract": "Given a set of buses with available escape directions inside a chip, a two-phase algorithm is proposed to assign one feasible escape direction onto any bus such that the number of used layers is minimized and to allocate the pin rectangle and the projection rectangle of any escape bus onto the minimized layers in direction-constrained rectangle escape routing. In our proposed algorithm, based on the concept of two-dimensional maximum density inside a chip, the escape directions of the buses can be first assigned to minimize the number of the used layers by iteratively eliminating unnecessary escape directions for any bus inside a chip. Furthermore, based on the construction of the represented intervals and the assignment constraints for the escape buses, a modified left-edge algorithm can be used to allocate all the escape buses onto the minimized layers. Compared with Ma’s integer linear program (ILP)-based algorithm [10] using lp_solve and Gurobi in rectangle escape routing, the experimental results show that our proposed algorithm obtains the same results but reduces CPU time by 94.2% and 35.7% when using lp_solve and Gurobi for 16 tested examples with no direction constraint on average, respectively. Compared with the modified algorithm from Ma's ILP-based algorithm [10] using lp_solve and Gurobi in direction-constrained rectangle escape routing, the experimental results show that our proposed algorithm obtains the same results but reduces CPU time by 94.3% and 37.7% when using lp_solve and Gurobi for 16 tested examples with direction constraints on average, respectively. Besides that, compared with Yan’s iterative algorithm, the experimental results show that our proposed algorithm increases CPU time by 1.0% to reduce the number of used layers 11.1% for 16 tested examples on average.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2794175138",
    "type": "article"
  },
  {
    "title": "Switching Predictive Control Using Reconfigurable State-Based Model",
    "doi": "https://doi.org/10.1145/3267126",
    "publication_date": "2018-11-19",
    "publication_year": 2018,
    "authors": "Maral Amir; Frank Vahid; Tony Givargis",
    "corresponding_authors": "",
    "abstract": "Advanced control methodologies have helped the development of modern vehicles that are capable of path planning and path following. For instance, Model Predictive Control (MPC) employs a predictive model to predict the behavior of the physical system for a specific time horizon in the future. An optimization problem is solved to compute optimal control actions while handling model uncertainties and nonlinearities. However, these prediction routines are computationally intensive and the computational overhead grows with the complexity of the model. Switching MPC addresses this issue by combining multiple predictive models, each with a different precision granularity. In this artcle, we proposed a novel switching predictive control method based on a model reduction scheme to achieve various model granularities for path following in autonomous vehicles. A state-based model with tunable parameters is proposed to operate as a reconfigurable predictive model of the vehicle. A runtime switching algorithm is presented that selects the best model using machine learning. We employed a metric that formulates the tradeoff between the error and computational savings due to model reduction. Our simulation results show that the use of the predictive model in the switching scheme as opposed to single granularity scheme, yields a 45% decrease in execution time in tradeoff for a small 12% loss in accuracy in prediction of future outputs and no loss of accuracy in tracking the reference trajectory.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2901969984",
    "type": "article"
  },
  {
    "title": "SystemC-AMS Thermal Modeling for the Co-simulation of Functional and Extra-Functional Properties",
    "doi": "https://doi.org/10.1145/3267125",
    "publication_date": "2018-12-21",
    "publication_year": 2018,
    "authors": "Yukai Chen; Sara Vinco; Enrico Macii; Massimo Poncino",
    "corresponding_authors": "",
    "abstract": "Temperature is a critical property of smart systems, due to its impact on reliability and to its inter-dependence with power consumption. Unfortunately, the current design flows evaluate thermal evolution ex-post on offline power traces. This does not allow to consider temperature as a dimension in the design loop, and it misses all the complex inter-dependencies with design choices and power evolution. In this article, by adopting the functional language SystemC-AMS (Analog Mixed Signal), we propose a method to enable thermal/power/functional co-simulation. The system thermal model is built by using state-of-the-art circuit equivalent models, by exploiting the support for electrical linear networks intrinsic of SystemC-AMS. The experimental results will show that the choice of SystemC-AMS is a winning strategy for building a simultaneous simulation of multiple functional and extra-functional properties of a system. The generated code exposes an accuracy comparable to that of the reference thermal simulator HotSpot. Additionally, the initial overhead due to the general purpose nature of SystemC-AMS is compensated by the surprisingly high performance of transient simulation, with speedups as high as two orders of magnitude.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2905861723",
    "type": "article"
  },
  {
    "title": "Thermal-aware 3D Symmetrical Buffered Clock Tree Synthesis",
    "doi": "https://doi.org/10.1145/3313798",
    "publication_date": "2019-04-05",
    "publication_year": 2019,
    "authors": "Deok Keun Oh; Mu Jun Choi; Ju-Ho Kim",
    "corresponding_authors": "",
    "abstract": "The semiconductor industry has accepted three-dimensional integrated circuits (3D ICs) as a possible solution to address speed and power management problems. In addition, 3D ICs have recently demonstrated a huge potential in reducing wire length and increasing the density of a chip. However, the growing density in chips such as TSV-based 3D ICs has brought the increased temperature on chip and temperature gradients depending on location. Thus, through silicon via (TSV)-based 3D clock tree synthesis (CTS) causes thermal problems leading to large clock skew. We propose a novel 3D symmetrical buffered clock tree synthesis considering thermal variation. First, &lt;u&gt;3D&lt;/u&gt; abstract tree topology based on &lt;u&gt;n&lt;/u&gt;earest-&lt;u&gt;n&lt;/u&gt;eighbor selection with &lt;u&gt;m&lt;/u&gt;edian cost (3D-NNM) is constructed by pairing sinks that have similar power consumption. Second, the layer assignment of internal nodes is determined for uniform TSV distribution. Third, in thermal-aware 3D deferred merging embedding (DME), the exact location of TSV is determined and wire routing/buffer insertion are performed after the thermal profile based on grid is obtained. The proposed method is verified using a 45nm process technology and utilized a predictive technology model (PTM) with HSPICE. It is also evaluated for the IBM benchmarks and ISPD’09 benchmarks with no blockages. In experimental result, we achieve on average 19% of clock skew reduction compared to existing thermal-aware 3D CTS. Therefore, thermal-aware 3D symmetrical buffered clock tree synthesis presented in this work is very efficient for circuit reliability.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2939642612",
    "type": "article"
  },
  {
    "title": "Memristive Crossbar Mapping for Neuromorphic Computing Systems on 3D IC",
    "doi": "https://doi.org/10.1145/3365576",
    "publication_date": "2019-11-25",
    "publication_year": 2019,
    "authors": "Qi Xu; Hao Geng; Song Chen; Bei Yu; Feng Wu",
    "corresponding_authors": "",
    "abstract": "In recent years, neuromorphic computing systems based on memristive crossbar have provided a promising solution to enable acceleration of neural networks. However, most of the neural networks used in realistic applications are often sparse. If such sparse neural network is directly implemented on a single memristive crossbar, then it would result in inefficient hardware realizations. In this work, we propose E3D-FNC, an enhanced three-dimesnional (3D) floorplanning framework for neuromorphic computing systems, in which the neuron clustering and the layer assignment are considered interactively. First, in each iteration, hierarchical clustering partitions neurons into a set of clusters under the guidance of the proposed distance metric. The optimal number of clusters is determined by L-method. Then matrix re-ordering is proposed to re-arrange the columns of the weight matrix in each cluster. As a result, the reordered connection matrix can be easily mapped into a set of crossbars with high utilizations. Next, since the clustering results will in turn affect the floorplan, we perform the floorplanning of neurons and crossbars again. All the proposed methodologies are embedded in an iterative framework to improve the quality of NCS design. Finally, a 3D floorplan of neuromorphic computing systems is generated. Experimental results show that E3D-FNC can achieve highly hardware-efficient designs compared to the state of the art.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2989960237",
    "type": "article"
  },
  {
    "title": "Harnessing the Granularity of Micro-Electrode-Dot-Array Architectures for Optimizing Droplet Routing in Biochips",
    "doi": "https://doi.org/10.1145/3365993",
    "publication_date": "2019-12-04",
    "publication_year": 2019,
    "authors": "Pushpita Roy; Ansuman Banerjee; Robert Wille; Bhargab B. Bhattacharya",
    "corresponding_authors": "",
    "abstract": "In this article, we consider the problem of droplet routing for Microelectrode-Dot-Array (MEDA) biochips. MEDA biochips today provide a host of useful features for droplet movement by making it possible to manoeuvre droplets at a much finer granularity and with significantly increased flexibility. More precisely, MEDA biochips support more degrees of freedom in navigation and volumetric manipulation such as diagonal movement, droplet reshaping, and fractional-level split-and-merge. This helps improve routing of droplets on microfluidic grids—in particular, when the space available on the grid is limited or blocked by obstacles. In this work, we discuss how these improved capabilities can be utilized in the realization of the desired routes on those biochips. To this end, we introduce a routing method that utilizes satisfiability solvers and guarantees the generation of optimal solutions, considering the set of MEDA operations we model. This significantly improves the state of the art, since previously proposed solutions either (1) relied on heuristics and, hence, were not able to guarantee the optimum or (2) only considered a subset of the MEDA features. The solution proposed in this work includes a formulation of all MEDA features, which, as illustrated by examples, allows for the determination of routing solutions with smaller completion times. Experimental evaluations confirm these findings.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2993015351",
    "type": "article"
  },
  {
    "title": "Hierarchical Ensemble Reduction and Learning for Resource-constrained Computing",
    "doi": "https://doi.org/10.1145/3365224",
    "publication_date": "2019-12-04",
    "publication_year": 2019,
    "authors": "Hongfei Wang; Jianwen Li; Kun He",
    "corresponding_authors": "",
    "abstract": "Generic tree ensembles (such as Random Forest, RF) rely on a substantial amount of individual models to attain desirable performance. The cost of maintaining a large ensemble could become prohibitive in applications where computing resources are stringent. In this work, a hierarchical ensemble reduction and learning framework is proposed. Experiments show our method consistently outperforms RF in terms of both accuracy and retained ensemble size. In other words, ensemble reduction is achieved with enhancement in accuracy rather than degradation. The method can be executed efficiently, up to &gt;590× time reduction than a recent ensemble reduction work. We also developed Boolean logic encoding techniques to directly tackle multiclass problems. Moreover, our framework bridges the gap between software-based ensemble methods and hardware computing in the IoT era. We developed a novel conversion paradigm that supports the automatic deployment of &gt;500 trees on a chip. Our proposed method reduces power consumption and overall area utilization by &gt;21.5% and &gt;62%, respectively, comparing with RF. The hierarchical approach provides rich opportunities to balance between the computation (training and response time), the hardware resource (memory and energy), and accuracy.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W3019567366",
    "type": "article"
  },
  {
    "title": "Predicting Memory Compiler Performance Outputs Using Feed-forward Neural Networks",
    "doi": "https://doi.org/10.1145/3385262",
    "publication_date": "2020-07-05",
    "publication_year": 2020,
    "authors": "Felix Last; M. Haeberlein; Ulf Schlichtmann",
    "corresponding_authors": "",
    "abstract": "Typical semiconductor chips include thousands of mostly small memories. As memories contribute an estimated 25% to 40% to the overall power, performance, and area (PPA) of a product, memories must be designed carefully to meet the system’s requirements. Memory arrays are highly uniform and can be described by approximately 10 parameters depending mostly on the complexity of the periphery. Thus, to improve PPA utilization, memories are typically generated by memory compilers. A key task in the design flow of a chip is to find optimal memory compiler parametrizations that, on the one hand, fulfill system requirements while, on the other hand, they optimize PPA. Although most compiler vendors also provide optimizers for this task, these are often slow or inaccurate. To enable efficient optimization in spite of long compiler runtimes, we propose training fully connected feed-forward neural networks to predict PPA outputs given a memory compiler parametrization. Using an exhaustive search-based optimizer framework that obtains neural network predictions, PPA-optimal parametrizations are found within seconds after chip designers have specified their requirements. Average model prediction errors of less than 3%, a decision reliability of over 99%, and productive usage of the optimizer for successful, large volume chip design projects illustrate the effectiveness of the approach.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W3121856613",
    "type": "article"
  },
  {
    "title": "A Compact High-Dimensional Yield Analysis Method using Low-Rank Tensor Approximation",
    "doi": "https://doi.org/10.1145/3483941",
    "publication_date": "2021-11-02",
    "publication_year": 2021,
    "authors": "Shi Xiao; Hao Yan; Qiancun Huang; Chengzhen Xuan; Lei He; Longxing Shi",
    "corresponding_authors": "",
    "abstract": "“Curse of dimensionality” has become the major challenge for existing high-sigma yield analysis methods. In this article, we develop a meta-model using Low-Rank Tensor Approximation (LRTA) to substitute expensive SPICE simulation. The polynomial degree of our LRTA model grows linearly with the circuit dimension. This makes it especially promising for high-dimensional circuit problems. Our LRTA meta-model is solved efficiently with a robust greedy algorithm and calibrated iteratively with a bootstrap-assisted adaptive sampling method. We also develop a novel global sensitivity analysis approach to generate a reduced LRTA meta-model which is more compact. It further accelerates the procedure of model calibration and yield estimation. Experiments on memory and analog circuits validate that the proposed LRTA method outperforms other state-of-the-art approaches in terms of accuracy and efficiency.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W3209576778",
    "type": "article"
  },
  {
    "title": "Reducing instruction bit-width for low-power VLIW architectures",
    "doi": "https://doi.org/10.1145/2442087.2442096",
    "publication_date": "2013-03-01",
    "publication_year": 2013,
    "authors": "Jongwon Lee; Jonghee M. Youn; Doosan Cho; Yunheung Paek",
    "corresponding_authors": "",
    "abstract": "VLIW (very long instruction word) architectures have proven to be useful for embedded applications with abundant instruction level parallelism. But due to the long instruction bus width it often consumes more power and memory space than necessary. One way to lessen this problem is to adopt a reduced bit-width instruction set architecture (ISA) that has a narrower instruction word length. This facilitates a more efficient hardware implementation in terms of area and power by decreasing bus-bandwidth requirements and the power dissipation associated with instruction fetches. In practice, however, it is impossible to convert a given ISA fully into an equivalent reduced bit-width one because the narrow instruction word, due to bit-width restrictions, can encode only a small subset of normal instructions in the original ISA. Consequently, existing processors provide narrow instructions in very limited cases along with severe restrictions on register accessibility. The objective of this work is to explore the possibility of complete conversion, as a case study, of an existing 32-bit VLIW ISA into a 16-bit one that supports effectively all 32-bit instructions. To this objective, we attempt to circumvent the bit-width restrictions by dynamically extending the effective instruction word length of the converted 16-bit operations. Further, we will show that our proposed ISA conversion can create a synergy effect with a VLES (variable length execution set) architecture that is adopted in most recent VLIW processors. According to our experiment, the code size becomes significantly smaller after the conversion to 16-bit VLIW code. Also at a slight run time cost, the machine with the 16-bit ISA consumes much less energy than the original machine.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W1978982849",
    "type": "article"
  },
  {
    "title": "Synthesis of networks of custom processing elements for real-time physical system emulation",
    "doi": "https://doi.org/10.1145/2442087.2442092",
    "publication_date": "2013-03-01",
    "publication_year": 2013,
    "authors": "Chen Huang; Bailey Miller; Frank Vahid; Tony Givargis",
    "corresponding_authors": "",
    "abstract": "Emulating a physical system in real-time or faster has numerous applications in cyber-physical system design and deployment. For example, testing of a cyber-device's software (e.g., a medical ventilator) can be done via interaction with a real-time digital emulation of the target physical system (e.g., a human's respiratory system). Physical system emulation typically involves iteratively solving thousands of ordinary differential equations (ODEs) that model the physical system. We describe an approach that creates custom processing elements (PEs) specialized to the ODEs of a particular model while maintaining some programmability, targeting implementation on field-programmable gate arrays (FPGAs). We detail the PE micro-architecture and accompanying automated compilation and synthesis techniques. Furthermore, we describe our efforts to use a high-level synthesis approach that incorporates regularity extraction techniques as an alternative FPGA-based solution, and also describe an approach using graphics processing units (GPUs). We perform experiments with five models: a Weibel lung model, a Lutchen lung model, an atrial heart model, a neuron model, and a wave model; each model consists of several thousand ODEs and targets a Xilinx Virtex 6 FPGA. Results of the experiments show that the custom PE approach achieves 4X-9X speedups (average 6.7X) versus our previous general ODE-solver PE approach, and 7X-10X speedups (average 8.7X) versus high-level synthesis, while using approximately the same or fewer FPGA resources. Furthermore, the approach achieves speedups of 18X-32X (average 26X) versus an Nvidia GTX 460 GPU, and average speedups of more than 100X compared to a six-core TI DSP processor or a four-core ARM processor, and 24X versus an Intel I7 quad core processor running at 3.06 GHz. While an FPGA implementation costs about 3X-5X more than the non-FPGA approaches, a speedup/dollar analysis shows 10X improvement versus the next best approach, with the trend of decreasing FPGA costs improving speedup/dollar in the future.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W1997712831",
    "type": "article"
  },
  {
    "title": "MCEmu",
    "doi": "https://doi.org/10.1145/2348839.2348840",
    "publication_date": "2012-10-01",
    "publication_year": 2012,
    "authors": "Chia-Heng Tu; Shih‐Hao Hung; Tung-Chieh Tsai",
    "corresponding_authors": "",
    "abstract": "Developing software for heterogeneous multicore systems is particularly challenging even for experienced developers. While emulators have proven useful to application development, very few heterogeneous multicore emulators have been made available by vendors so far, as building an emulator for a heterogeneous multicore system has been a time-consuming and difficult task. Thus, we proposed a framework, called MCEmu, to speed up the process of building a heterogeneous multicore emulator by integrating existing and/or new processor emulators. MCEmu is designed to help system and application development, with a basic multicore board support package, an interprocessor communication library, and tools for debugging, tracing, and performance monitoring. In addition, MCEmu can run on a multicore host system to accelerate the emulation of data parallel applications. We show that MCEmu can be very useful for developing system software before the system becomes available, as it has helped us catch numerous functional and performance bugs which could have been hard to find. In this article, we present the design of MCEmu and demonstrate its capabilities with our case studies.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2002933759",
    "type": "article"
  },
  {
    "title": "Using implications to choose tests through suspect fault identification",
    "doi": "https://doi.org/10.1145/2390191.2390205",
    "publication_date": "2013-01-01",
    "publication_year": 2013,
    "authors": "Jennifer Dworak; Kundan Nepal; Nuno Alves; Yiwen Shi; Nicholas Imbriglia; R. Iris Bahar",
    "corresponding_authors": "",
    "abstract": "As circuits continue to scale to smaller feature sizes, wearout and latent defects are expected to cause an increasing number of errors in the field. Online error detection techniques, including logic implication-based checker hardware, are capable of detecting at least some of these errors as they occur. However, recovery may be expensive, and the underlying problem may lead to multiple failures of a core over time. In this article, we will investigate the diagnostic capability of logic implications to identify possible failure locations when an error is detected online. We will then utilize this information to select a highly efficient test set that can be used to effectively test the identified suspect locations in both the failing core and in other identical cores in the system.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2088716948",
    "type": "article"
  },
  {
    "title": "Towards the formal verification of cache coherency at the architectural level",
    "doi": "https://doi.org/10.1145/2209291.2209293",
    "publication_date": "2012-06-01",
    "publication_year": 2012,
    "authors": "Freek Verbeek; Julien Schmaltz",
    "corresponding_authors": "",
    "abstract": "Cache coherency is one of the major issues in multicore systems. Formal methods, in particular model-checking, have been successful at verifying high-level protocols, but, to the best of our knowledge, the verification of cache coherency at the architectural level is still an open issue. All existing verification efforts assume a reliable interconnect, that is, messages eventually reach their destination. We discuss the challenge of discharging this assumption at the architectural level where implementation details of the interconnect are mixed with a cache coherency protocol. Our automatic approach is based on a well-defined set of primitives to express architectural models, a generic model of communication fabrics expressed in an automated theorem proving system, and a dedicated algorithm for deadlock and livelock detection. We argue that reliability depends on the interaction between the interconnect and the cache coherency protocol. They must be verified altogether as their combination creates intricate message dependencies. We sketch our verification approach and apply it to a simple write-invalidate protocol on the Spidergon network-on-chip from STMicroelectronics. Our approach is promising. For this simple protocol, networks with tens of agents and hundreds of components can be analyzed within seconds.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2110504488",
    "type": "article"
  },
  {
    "title": "A Yield and Reliability Improvement Methodology Based on Logic Redundant Repair with a Repairable Scan Flip-Flop Designed by Push Rule",
    "doi": "https://doi.org/10.1145/2159542.2159549",
    "publication_date": "2012-04-01",
    "publication_year": 2012,
    "authors": "Masanori Kurimoto; Jun Matsushima; S. Ohbayashi; Yoshiaki Fukui; Michio Komoda; Nobuhiro TSUDA",
    "corresponding_authors": "",
    "abstract": "We propose a yield improvement methodology which repairs a faulty chip due to logic defect by using a repairable scan flip-flop (R-SFF). Our methodology improves area penalty, which is a large issue for logic repair technology in actual products, by using repair grouping and a redundant cell insertion algorithm and by pushing the design rule for the repairable area of R-SFF. Additionally, compared with the conventional method, we reduce the number of wire connections around redundant cells by improving the replacement method of the faulty cell by the redundant cell. The proposed methodology reduces the total area penalty caused by the logic redundant repair to 3.6% and improves the yield, that is the number of good chips on a wafer, by 4.7% when the defect density is 1.0[1/cm^2]. Furthermore, we propose the strategy to repair the in-field failures due to latent defect for the chip whose repair function had not been used in the shipment test.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2142018126",
    "type": "article"
  },
  {
    "title": "Order statistics for correlated random variables and its application to at-speed testing",
    "doi": "https://doi.org/10.1145/2491477.2491486",
    "publication_date": "2013-07-01",
    "publication_year": 2013,
    "authors": "Yiyu Shi; Jinjun Xiong; Vladimir Zolotov; Chandu Visweswariah",
    "corresponding_authors": "",
    "abstract": "Although order statistics have been studied for several decades, most of the results are based on the assumption of independent and identically distributed (i.i.d.) random variables. In the literature, how to compute the m th order statistics of n correlated random variables is still a problem. This article proposes a recursive algorithm based on statistical min/max operations to compute order statistics for general correlated and not necessarily identically distributed random variables. The algorithm has an O( mn ) time complexity and O( m + n ) space complexity. A binary tree-based data structure is further developed to allow selective update of the order statistics with O( nm 2 ) time. As a vehicle to demonstrate the algorithm, we apply it to the path selection algorithm in at-speed testing. A novel metric multilayer process space coverage metric is proposed to quantitatively gauge the quality of path selection. We then show that such a metric is directly linked to the order statistics, and our recursive algorithm can thus be applied. By employing a branch-and-bound path selection algorithm with these techniques, this article shows that selecting an optimal set of paths for a multimillion-gate design can be performed efficiently. Compared to the state of the art, experimental results show both the efficiency of our algorithms and better quality of our path selection.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2142666223",
    "type": "article"
  },
  {
    "title": "Symbolic-Event-Propagation-Based Minimal Test Set Generation for Robust Path Delay Faults",
    "doi": "https://doi.org/10.1145/2348839.2348851",
    "publication_date": "2012-10-01",
    "publication_year": 2012,
    "authors": "Arijit Mondal; P. P. Chakrabarti; Pallab Dasgupta",
    "corresponding_authors": "",
    "abstract": "We present a symbolic-event-propagation-based scheme to generate hazard-free tests for robust path delay faults. This approach identifies all robustly testable paths in a circuit and the corresponding complete set of test vectors. We address the problem of finding a minimal set of test vectors that covers all robustly testable paths. We propose greedy and simulated-annealing-based algorithms to find the same. Results on ISCAS89 benchmark circuits show a considerable reduction in test vectors for covering all robustly testable paths.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2150401976",
    "type": "article"
  },
  {
    "title": "Integrated microarchitectural floorplanning and run-time controller for inductive noise mitigation",
    "doi": "https://doi.org/10.1145/2003695.2003706",
    "publication_date": "2011-10-01",
    "publication_year": 2011,
    "authors": "Michael B. Healy; Fayez Mohamood; Hsien-Hsin S. Lee; Sung Kyu Lim",
    "corresponding_authors": "",
    "abstract": "In this article, we propose a design methodology using two complementary techniques to address high-frequency inductive noise in the early design phase of a microprocessor. First, we propose a noise-aware floorplanning technique that uses microarchitectural profile information to create noise-aware floorplans. Second, we present the design of a dynamic inductive-noise controlling mechanism at the microarchitectural level, which limits the on-die current demand within predefined bounds, regardless of the native power and current characteristics of running applications. By dynamically monitoring the access patterns of microarchitectural modules, our mechanism can effectively limit simultaneous switching activity of close-by modules, thereby leveling voltage ringing at local power-pins. Compared to prior art, our di/dt alleviation technique is the first that takes the processor's floorplan, as well as its power-pin distribution, into account to provide a finer-grained control with minimal performance degradation. Based on the evaluation results using 2D floorplans, we show that our techniques can significantly improve inductive noise induced by current demand variation and reduce the average current variability by up to 7 times, with an average performance overhead of 4.0%. In addition, our floorplan reduces the noise margin violations using our noise-aware floorplan by an average of 56.3% while reducing the decap budget by 28%.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2170982639",
    "type": "article"
  },
  {
    "title": "Reducing the Complexity of Dataflow Graphs Using Slack-Based Merging",
    "doi": "https://doi.org/10.1145/2956232",
    "publication_date": "2017-01-09",
    "publication_year": 2017,
    "authors": "Hazem Ismail Ali; Sander Stuijk; Benny Åkesson; Luís Miguel Pinho",
    "corresponding_authors": "",
    "abstract": "There exist many dataflow applications with timing constraints that require real-time guarantees on safe execution without violating their deadlines. Extraction of timing parameters (offsets, deadlines, periods) from these applications enables the use of real-time scheduling and analysis techniques, and provides guarantees on satisfying timing constraints. However, existing extraction techniques require the transformation of the dataflow application from highly expressive dataflow computational models, for example, Synchronous Dataflow (SDF) and Cyclo-Static Dataflow (CSDF) to Homogeneous Synchronous Dataflow (HSDF). This transformation can lead to an exponential increase in the size of the application graph that significantly increases the runtime of the analysis. In this article, we address this problem by proposing an offline heuristic algorithm called slack-based merging . The algorithm is a novel graph reduction technique that helps in speeding up the process of timing parameter extraction and finding a feasible real-time schedule, thereby reducing the overall design time of the real-time system. It uses two main concepts: (a) the difference between the worst-case execution time of the SDF graph’s firings and its timing constraints (slack) to merge firings together and generate a reduced-size HSDF graph, and (b) the novel concept of merging called safe merge , which is a merge operation that we formally prove cannot cause a live HSDF graph to deadlock. The results show that the reduced graph (1) respects the throughput and latency constraints of the original application graph and (2) typically speeds up the process of extracting timing parameters and finding a feasible real-time schedule for real-time dataflow applications. They also show that when the throughput constraint is relaxed with respect to the maximal throughput of the graph, the merging algorithm is able to achieve a larger reduction in graph size, which in turn results in a larger speedup of the real-time scheduling algorithms.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2464718695",
    "type": "article"
  },
  {
    "title": "Scale &amp; Cap",
    "doi": "https://doi.org/10.1145/2994145",
    "publication_date": "2017-01-09",
    "publication_year": 2017,
    "authors": "Can Hankendi; Ayse K. Coskun",
    "corresponding_authors": "",
    "abstract": "As the number of cores per server node increases, designing multi-threaded applications has become essential to efficiently utilize the available hardware parallelism. Many application domains have started to adopt multi-threaded programming; thus, efficient management of multi-threaded applications has become a significant research problem. Efficient execution of multi-threaded workloads on cloud environments, where applications are often consolidated by means of virtualization, relies on understanding the multi-threaded specific characteristics of the applications. Furthermore, energy cost and power delivery limitations require data center server nodes to work under power caps, which bring additional challenges to runtime management of consolidated multi-threaded applications. This article proposes a dynamic resource allocation technique for consolidated multi-threaded applications for power-constrained environments. Our technique takes into account application characteristics specific to multi-threaded applications, such as power and performance scaling, to make resource distribution decisions at runtime to improve the overall performance, while accurately tracking dynamic power caps. We implement and evaluate our technique on state-of-the-art servers and show that the proposed technique improves the application performance by up to 21% under power caps compared to a default resource manager.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2568537891",
    "type": "article"
  },
  {
    "title": "Worst-Case Response Time Analysis of a Synchronous Dataflow Graph in a Multiprocessor System with Real-Time Tasks",
    "doi": "https://doi.org/10.1145/2997644",
    "publication_date": "2017-01-20",
    "publication_year": 2017,
    "authors": "Junchul Choi; Soonhoi Ha",
    "corresponding_authors": "",
    "abstract": "In this article, we propose a novel technique that estimates a tight upper bound of the worst-case response time (WCRT) of a synchronous dataflow (SDF) graph when the SDF graph shares processors with other real-time tasks. When an SDF graph is executed at runtime under a self-timed or static assignment scheduling policy on a multi-processor system, static scheduling of the SDF graph does not guarantee the satisfaction of latency constraints since changes to the schedule may result in timing anomalies. To estimate the WCRT of an SDF graph with a given mapping and scheduling result, we first construct a task instance dependency graph that depicts the dependency between node executions in a static schedule. The proposed technique combines two techniques in a novel way: schedule time bound analysis and response time analysis. The former is used to consider the interference between task instances in the same SDF graph, and the latter is used to consider the interference from other real-time tasks. Through extensive experiments with synthetic examples and benchmarks, we verify the superior performance of the proposed technique compared to other existent techniques.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2580454733",
    "type": "article"
  },
  {
    "title": "On the Restore Time Variations of Future DRAM Memory",
    "doi": "https://doi.org/10.1145/2967609",
    "publication_date": "2017-02-09",
    "publication_year": 2017,
    "authors": "Xianwei Zhang; Youtao Zhang; Bruce R. Childers; Jun Yang",
    "corresponding_authors": "",
    "abstract": "As the de facto main memory standard, DRAM (Dynamic Random Access Memory) has achieved dramatic density improvement in the past four decades, along with the advancements in process technology. Recent studies reveal that one of the major challenges in scaling DRAM into the deep sub-micron regime is its significant variations on cell restore time, which affect timing constraints such as write recovery time. Adopting traditional approaches results in either low yield rate or large performance degradation. In this article, we propose schemes to expose the variations to the architectural level. By constructing memory chunks with different access speeds and, in particular, exploiting the performance benefits of fast chunks, a variation-aware memory controller can effectively mitigate the performance loss due to relaxed timing constraints. We then proposed restore-time-aware rank construction and page allocation schemes to make better use of fast chunks. Our experimental results show that, compared to traditional designs such as row sparing and Error Correcting Codes, the proposed schemes help to improve system performance by about 16% and 20%, respectively, for 20nm and 14nm technology nodes on a four-core multiprocessor system.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2586596130",
    "type": "article"
  },
  {
    "title": "A Fast Hierarchical Adaptive Analog Routing Algorithm Based on Integer Linear Programming",
    "doi": "https://doi.org/10.1145/3035464",
    "publication_date": "2017-05-23",
    "publication_year": 2017,
    "authors": "Mohammad Torabi; Lihong Zhang",
    "corresponding_authors": "",
    "abstract": "The shrinking design window and high parasitic sensitivity in advanced technologies have imposed special challenges on analog and radio frequency (RF) integrated circuit design. The state-of-the-art analog routing research tends to favor linear programming to achieve various analog constraints, which, although effective, fail to offer high routing efficiency on its own. In this article, we propose a new methodology to address such a deficiency based on integer linear programming (ILP) but without compromising the capability of handling any special constraints for the analog routing problems. Our proposed method supports hierarchical routing, which can divide the entire routing area into multiple small heterogeneous regions where the ILP can efficiently derive routing solutions. Distinct from the conventional methods, our algorithm utilizes adaptive resolutions for various routing regions. For a more congested region, a routing grid with higher resolution is employed, whereas a lower-resolution grid is adopted to a less-crowded routing region. For a large empty space, routing efficiency can be even boosted by creating more routing hierarchy levels. This scheme is especially beneficial to the analog and RF layouts, which are far sparser than their digital counterparts. The experimental results show that our proposed adaptive ILP-based router is much faster than the conventional ones, since it spends much less time in the areas that need no accurate routing anyway. The higher efficiency is demonstrated for large circuits and especially sparse layouts along with promising routing quality in terms of analog constraints.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2619603071",
    "type": "article"
  },
  {
    "title": "Proof-Carrying Hardware via Inductive Invariants",
    "doi": "https://doi.org/10.1145/3054743",
    "publication_date": "2017-07-20",
    "publication_year": 2017,
    "authors": "Tobias Isenberg; Marco Platzner; Heike Wehrheim; Tobias Wiersema",
    "corresponding_authors": "",
    "abstract": "Proof-carrying hardware (PCH) is a principle for achieving safety for dynamically reconfigurable hardware systems. The producer of a hardware module spends huge effort when creating a proof for a safety policy. The proof is then transferred as a certificate together with the configuration bitstream to the consumer of the hardware module, who can quickly verify the given proof. Previous work utilized SAT solvers and resolution traces to set up a PCH technology and corresponding tool flows. In this article, we present a novel technology for PCH based on inductive invariants. For sequential circuits, our approach is fundamentally stronger than the previous SAT-based one since we avoid the limitations of bounded unrolling. We contrast our technology to existing ones and show that it fits into previously proposed tool flows. We conduct experiments with four categories of benchmark circuits and report consumer and producer runtime and peak memory consumption, as well as the size of the certificates and the distribution of the workload between producer and consumer. Experiments clearly show that our new induction-based technology is superior for sequential circuits, whereas the previous SAT-based technology is the better choice for combinational circuits.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2736313002",
    "type": "article"
  },
  {
    "title": "Exploring Energy-Efficient Cache Design in Emerging Mobile Platforms",
    "doi": "https://doi.org/10.1145/2843940",
    "publication_date": "2017-07-20",
    "publication_year": 2017,
    "authors": "Kaige Yan; Lu Peng; Mingsong Chen; Xin Fu",
    "corresponding_authors": "",
    "abstract": "Mobile devices are quickly becoming the most widely used processors in consumer devices. Since their major power supply is battery, energy-efficient computing is highly desired. In this article, we focus on energy-efficient cache design in emerging mobile platforms. We observe that more than 40% of L2 cache accesses are OS kernel accesses in interactive smartphone applications. Such frequent kernel accesses cause serious interferences between the user and kernel blocks in the L2 cache, leading to unnecessary block replacements and high L2 cache miss rate. We first propose to statically partition the L2 cache into two separate segments, which can be accessed only by the user code and kernel code, respectively. Meanwhile, the overall size of the two segments is shrunk, which reduces the energy consumption while still maintaining the similar cache miss rate. We then find completely different access behaviors between the two separated kernel and user segments and explore the multi-retention STT-RAM-based user and kernel segments to obtain higher energy savings in this static partition-based cache design. Finally, we propose to dynamically partition the L2 cache into the user and kernel segments to minimize overall cache size. We also integrate the short-retention STT-RAM into this dynamic partition-based cache design for maximal energy savings. The experimental results show that our static technique reduces cache energy consumption by 75% with 2% performance loss, and our dynamic technique further shows strong capability to reduce cache energy consumption by 85% with only 3% performance loss.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2739387436",
    "type": "article"
  },
  {
    "title": "An Adaptive Markov Model for the Timing Analysis of Probabilistic Caches",
    "doi": "https://doi.org/10.1145/3123877",
    "publication_date": "2017-08-31",
    "publication_year": 2017,
    "authors": "Chao Chen; Giovanni Beltrame",
    "corresponding_authors": "",
    "abstract": "Accurate timing prediction for real-time embedded software execution is becoming a problem due to the increasing complexity of computer architecture, and the presence of mixed-criticality workloads. Probabilistic caches were proposed to set bounds to Worst Case Execution Time (WCET) estimates and help designers improve real-time embedded system resource use. Static Probabilistic Timing Analysis (SPTA) for probabilistic caches is nevertheless difficult to perform, because cache accesses depend on execution history, and the computational complexity of SPTA makes it intractable for calculation as the number of accesses increases. In this paper, we explore and improve SPTA for caches with evict-on-miss random replacement policy using a state space modeling technique. A nonhomogeneous Markov model is employed for single-path programs in discrete-time finite state space representation. To make this Markov model tractable, we limit the number of states and use an adaptive method for state modification. Experiments show that compared to the state-of-the-art methodology, the proposed adaptive Markov chain approach provides better results at the occurrence probability of 10 −15 : in terms of accuracy, the state-of-the-art SPTA results are more conservative, by 11% more on average. In terms of computation time, our approach is not significantly different from the state-of-the-art SPTA.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2752742484",
    "type": "article"
  },
  {
    "title": "Improving Write Performance by Controlling Target Resistance Distributions in MLC PRAM",
    "doi": "https://doi.org/10.1145/2820610",
    "publication_date": "2016-01-28",
    "publication_year": 2016,
    "authors": "Young Sik Kim; Sungjoo Yoo; Sunggu Lee",
    "corresponding_authors": "",
    "abstract": "Multi-level cell (MLC) phase change RAM (PRAM) is expected to offer lower cost main memory than DRAM. However, poor write performance is one of the most critical problems for practical applications of MLC PRAM. In this article, we present two schemes to improve write performance by controlling the target resistance distribution of MLC PRAM cells. First, we propose multiple RESET/SET operations that relax the target resistance bands of intermediate logic levels with additional RESET/SET operations, which reduces the program time of intermediate logic levels, thereby improving write performance. Second, we propose a two-step write scheme consisting of lightweight write and idle-time completion write that exploits the fact that hot dirty data tend to be overwritten in a short time period and the MLC PRAM often has long idle times. Experimental results show that the multiple RESET/SET and two-step write schemes result in an average IPC improvement of 15.7% and 10.4%, respectively, on a hybrid DRAM/PRAM main memory subsystem. Furthermore, their integrated solution results in an average IPC improvement of 23.2% (up to 46.4%).",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2269850215",
    "type": "article"
  },
  {
    "title": "Clock-Tree-Aware Incremental Timing-Driven Placement",
    "doi": "https://doi.org/10.1145/2858793",
    "publication_date": "2016-04-19",
    "publication_year": 2016,
    "authors": "Vinicius Livramento; Renan Netto; Chrystian Guth; José Luís Güntzel; Luiz C. V. dos Santos",
    "corresponding_authors": "",
    "abstract": "The increasing impact of interconnections on overall circuit performance makes timing-driven placement (TDP) a crucial step toward timing closure. Current TDP techniques improve critical paths but overlook the impact of register placement on clock tree quality. On the other hand, register placement techniques found in the literature mainly focus on power consumption, disregarding timing and routabilty. Indeed, postponing register placement may undermine the optimization achieved by TDP, since the wiring between sequential and combinational elements would be touched. This work proposes a new approach for an effective coupling between register placement and TDP that relies on two key aspects to handle sequential and combinational elements separately: only the registers in the critical paths are touched by TDP (in practice they represent a small percentage of the total number of registers), and the shortening of clock tree wirelength can be obtained with limited variation in signal wirelength and placement density. The approach consists of two steps: (1) incremental register placement guided by a virtual clock tree to reduce clock wiring capacitance while preserving signal wirelength and density, and (2) incremental TDP to minimize the total negative slack. For the first step, we propose a novel technique that combines clock-net contraction and register clustering forces to reduce the clock wirelength. For the second step, we propose a novel Lagrangian Relaxation formulation that minimizes total negative slack for both setup and hold timing violations. To solve the formulation, we propose a TDP technique using a novel discrete search that employs a Euclidean distance to define a proper neighborhood. For the experimental evaluation of the proposed approach, we relied on the ICCAD 2014 TDP contest infrastructure and compared our results with the best results obtained from that contest in terms of timing closure, clock tree compactness, signal wirelength, and density. Assuming a long displacement constraint, our technique achieves worst and total negative slack reductions of around 24% and 26%, respectively. In addition, our approach leads to 44% shorter clock tree wirelength with negligible impact on signal wirelength and placement density. In the face of such results, the proposed coupling seems a useful approach to handle the challenges faced by contemporary physical synthesis.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2340959133",
    "type": "article"
  },
  {
    "title": "State Assignment and Optimization of Ultra-High-Speed FSMs Utilizing Tristate Buffers",
    "doi": "https://doi.org/10.1145/2905366",
    "publication_date": "2016-05-27",
    "publication_year": 2016,
    "authors": "Robert Czerwiński; Dariusz Kania",
    "corresponding_authors": "",
    "abstract": "The logic synthesis of ultra-high-speed FSMs is presented. The state assignment is based on a well-known method that uses output vectors. This technique is adjusted to include elements of two-level minimization and takes into account the limited number of terms contained in the programmable-AND/fixed-OR logic cell. The state assignment is based on a special form of the binary decision tree. The second phase of the FSM design is logic optimization. The optimization method is based on tristate buffers, thus making possible a one-logic-level FSM structure. The key point is to search partition variables that control the tristate buffers. This technique can also be applied to combinational circuits or the output block of FSMs only. Algorithms for state assignment and optimization are presented and richly illustrated by examples. The method is dedicated to using specific features of complex programmable logic devices. Experimental results prove its effectiveness (e.g., the implementation of the the 16-bit counter requires 136 logic cells and one-logic-cell level instead of 213 cells and four levels). The optimization method using tristate buffers and a state assignment binary decision tree can be directly applied to FPGA-dedicated logic synthesis.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2397971382",
    "type": "article"
  },
  {
    "title": "Ensemble Reduction via Logic Minimization",
    "doi": "https://doi.org/10.1145/2897515",
    "publication_date": "2016-05-27",
    "publication_year": 2016,
    "authors": "Hongfei Wang; R.D. Blanton",
    "corresponding_authors": "",
    "abstract": "An ensemble of machine learning classifiers usually improves generalization performance and is useful for many applications. However, the extra memory storage and computational cost incurred from the combined models often limits their potential applications. In this article, we propose a new ensemble reduction method called CANOPY that significantly reduces memory storage and computations. CANOPY uses a technique from logic minimization for digital circuits to select and combine particular classification models from an initial pool in the form of a Boolean function, through which the reduced ensemble performs classification. Experiments on 20 UCI datasets demonstrate that CANOPY either outperforms or is very competitive with the initial ensemble and one state-of-the-art ensemble reduction method in terms of generalization error, and is superior to all existing reduction methods surveyed for identifying the smallest numbers of models in the reduced ensembles.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2402097962",
    "type": "article"
  },
  {
    "title": "DReAM",
    "doi": "https://doi.org/10.1145/2939370",
    "publication_date": "2016-11-23",
    "publication_year": 2016,
    "authors": "Qixiao Liu; Miquel Moretó; Jaume Abella; Francisco J. Cazorla; Mateo Valero",
    "corresponding_authors": "",
    "abstract": "Accurate per-task energy estimation in multicore systems would allow performing per-task energy-aware task scheduling and energy-aware billing in data centers, among other applications. Per-task energy estimation is challenged by the interaction between tasks in shared resources, which impacts tasks’ energy consumption in uncontrolled ways. Some accurate mechanisms have been devised recently to estimate per-task energy consumed on-chip in multicores, but there is a lack of such mechanisms for DRAM memories. This article makes the case for accurate per-task DRAM energy metering in multicores, which opens new paths to energy/performance optimizations. In particular, the contributions of this article are (i) an ideal per-task energy metering model for DRAM memories; (ii) DReAM, an accurate yet low cost implementation of the ideal model (less than 5% accuracy error when 16 tasks share memory); and (iii) a comparison with standard methods (even distribution and access-count based) proving that DReAM is much more accurate than these other methods.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2552510698",
    "type": "article"
  },
  {
    "title": "Optimized Implementation of Multirate Mixed-Criticality Synchronous Reactive Models",
    "doi": "https://doi.org/10.1145/2968445",
    "publication_date": "2016-12-28",
    "publication_year": 2016,
    "authors": "Qingling Zhao; Zaid Al-bayati; Zonghua Gu; Haibo Zeng",
    "corresponding_authors": "",
    "abstract": "Model-based design using Synchronous Reactive (SR) models enables early design and verification of application functionality in a platform-independent manner, and the implementation on the target platform should guarantee the preservation of application semantic properties. Mixed-Criticality Scheduling (MCS) is an effective approach to addressing diverse certification requirements of safety-critical systems that integrate multiple subsystems with different levels of criticality. This article considers fixed-priority scheduling of mixed-criticality SR models, and considers two scheduling approaches: Adaptive MCS and Elastic MCS. We formulate the optimization problem of minimizing the total system cost of added functional delays in the implementation while guaranteeing schedulability, and present an optimal algorithm based on branch-and-bound search, and an efficient heuristic algorithm.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2561253484",
    "type": "article"
  },
  {
    "title": "A flexible datapath allocation method for architectural synthesis",
    "doi": "https://doi.org/10.1145/323480.323486",
    "publication_date": "1999-10-01",
    "publication_year": 1999,
    "authors": "Kyu-Myung Choi; Steven P. Levitan",
    "corresponding_authors": "",
    "abstract": "We present a robust datapath allocation method that is flexible enough to handle constraints imposed by a variety of target architectures. Key features of this method are its ability to handle accurate modeling of datapath units and the simultaneous optimization of direct objective functions. The proposed method consists of a new binding model construction scheme and an optimization technique based on simulated annealing. To illustrate the flexibility of this method, two datapath allocation procedures have been developed for two problem enviroments: (1) a procedure that incorporates interconnection area and delay estimates, where floor-planning is tightly integrated into datapath allocation; and (2) a procedure that handles registers, register files, and multiport memories for data storage, as well as random and linear topologies for interconnection architectures. Results from these two applications show our method produces competitive designs for benchmark circuits, as well as being flexible enough to be used for a variety of different domains.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2086725861",
    "type": "article"
  },
  {
    "title": "An algorithm for synthesis of large time-constrained heterogeneous adaptive systems",
    "doi": "https://doi.org/10.1145/375977.375979",
    "publication_date": "2001-04-01",
    "publication_year": 2001,
    "authors": "Nagaraj Shenoy; Alok Choudhary; Prithviraj Banerjee",
    "corresponding_authors": "",
    "abstract": "Large time-constrained applications are highly computer-intensive and are often implemented as a complex organization of pipelined data parallel tasks on a pool of embedded processors, DSP processors, and FPGAs. The large number of design alternatives available at each task level, the application as a whole, and the special needs of the reconfigurable devices (such as the FPGA) make the manual synthesis of such systems very tedious. The automatic synthesis algorithm in this paper combines exact (MILP-based) and heuristic techniques to solve this problem, which basically involves (1) propagation of timing constraints; (2) pipelining the loops to meet throughput requirements; (3) resource selection and scheduling, keeping the processing requirements and the timing constraints in view; (4) scheduling the resources across the tasks to ensure maximum utilization; and (5) hiding the reconfiguration delays of the FPGAs. While the use of MILP techniques helps in getting high-quality results, combining them with heuristics ensures acceptable synthesis times, striking a good balance between quality of results and synthesis time. Our experimental evaluation of the algorithm shows an average 40% in resource cost reduction (compared to manual synthesis) with synthesis times from minutes to as low as a few seconds in some cases.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W1986980197",
    "type": "article"
  },
  {
    "title": "Constrained polygon transformations for incremental floorplanning",
    "doi": "https://doi.org/10.1145/383251.383255",
    "publication_date": "2001-07-01",
    "publication_year": 2001,
    "authors": "Swanwa Liao; Mario A. López; Dinesh P. Mehta",
    "corresponding_authors": "",
    "abstract": "A productivity-driven methodology for incremental floorplanning is described and the constrained polygon transformation problem , a key step of this methodology, is formulated. The input to the problem consists of a floorplan computed using area estimates and the actual area required for each subcircuit of the floorplan. Informally, the objective is to change the areas of the modules without drastically changing their shapes or locations. We show that the constrained polygon transformation problem is NP-hard and present several fast algorithms that produce results within a few percent of a theoretical lower bound on several floorplans.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2051956882",
    "type": "article"
  },
  {
    "title": "Monotone bipartitioning problem in a planar point set with applications to VLSI",
    "doi": "https://doi.org/10.1145/544536.544537",
    "publication_date": "2002-04-01",
    "publication_year": 2002,
    "authors": "Parthasarathi Dasgupta; Peichen Pan; Subhas C. Nandy; Bhargab B. Bhattacharya",
    "corresponding_authors": "",
    "abstract": "A new problem called monotone bipartitioning of a planar point set is identified which is found to be useful in VLSI layout design. Let F denote a rectangular floor containing a set A of n points. The portion of a straight line formed by two points from the set A is called a line segment. A monotone increasing path ( MP ) in F is a connected and ordered sequence of line segments from the bottom-left corner of F to its top-right corner, such that the slope of each line segment is nonnegative, and each pair of consecutive line segments share a common point of A . An MP is said to be maximal ( MMP ) if no other point in A can be included in it preserving monotonicity. Let A L denote the subset of A corresponding to the end points of the line segments in an MMP , L . The path L partitions the set of points A \\ A L into two subsets lying on its two sides. The objective of monotone bipartitioning is to find an MMP L , such that the difference in the number of points in these two subsets is minimum. This problem can be formulated as finding a path between two designated vertices of an edge-weighted digraph (the weight of an edge being an integer lying in the range [- n, n ]), for which the absolute value of the algebraic sum of weights is minimized. An O ( n × e ) time algorithm is proposed for this problem, where e denotes the number of edges of the graph determined from the geometry of the point set. The monotone bipartitioning problem has various applications to image processing, facility location, and plant layout problems. A related problem arises while partitioning a VLSI floorplan. Given a floorplan with n rectangular blocks, the goal is to find a monotone staircase channel from one corner of the floor to its diagonally opposite corner such that the difference in the numbers of blocks lying on its two sides is minimum. The problem is referred to as the staircase bipartitioning problem. The proposed algorithm for a point set can be directly used to solve this problem in O ( n 2 ) time. However, an improved O ( n ) time algorithm is reported for this special case. This leads to an O ( n log n ) time algorithm for hierarchical decomposition of a floorplan with a sequence of staircase channels. Staircase bipartitioning has many applications to channel and global routing.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2069780601",
    "type": "article"
  },
  {
    "title": "A stimulus-free graphical probabilistic switching model for sequential circuits using dynamic bayesian networks",
    "doi": "https://doi.org/10.1145/1142980.1142990",
    "publication_date": "2004-06-07",
    "publication_year": 2004,
    "authors": "Sanjukta Bhanja; Karthikeyan Lingasubramanian; N. Ranganathan",
    "corresponding_authors": "",
    "abstract": "We propose a novel, nonsimulative probabilistic model for switching activity in sequential circuits, capturing both spatio-temporal correlations at internal nodes and higher order temporal correlations due to feedback. This model, which we refer to as the temporal dependency model (TDM), can be constructed from the logic structure and is shown to be a dynamic Bayesian network. Dynamic Bayesian networks are extremely powerful in modeling high order temporal, as well as spatial, correlations; TDM is an exact model for the underlying conditional independencies. The attractive feature of this graphical representation of the joint probability function is not only that it makes the dependency relationships amongst nodes explicit, but it also serves as a computational mechanism for probabilistic inference. We report average errors in switching probability of 0.006, with errors tightly distributed around mean error values, on ISCAS'89 benchmark circuits involving up to 10000 signals.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W1996235716",
    "type": "article"
  },
  {
    "title": "Zero cost indexing for improved processor cache performance",
    "doi": "https://doi.org/10.1145/1124713.1124715",
    "publication_date": "2006-01-01",
    "publication_year": 2006,
    "authors": "Tony Givargis",
    "corresponding_authors": "Tony Givargis",
    "abstract": "The increasing use of microprocessor cores in embedded systems as well as mobile and portable devices creates an opportunity for customizing the cache subsystem for improved performance. In traditional cache design, the index portion of the memory address bus consists of the K least significant bits, where K = log 2 D and D is the depth of the cache. However, in devices where the application set is known and characterized (e.g., systems that execute a fixed application set) there is an opportunity to improve cache performance by choosing a near-optimal set of bits used as index into the cache. This technique does not add any overhead in terms of area or delay. In this article, we present an efficient heuristic algorithm for selecting K index bits for improved cache performance. We show the feasibility of our algorithm by applying it to a large number of embedded system applications as well as the integer SPEC CPU 2000 benchmarks. Specifically, for data traces, we show up to 45% reduction in cache misses. Likewise, for instruction traces, we show up to 31% reduction in cache misses. When a unified data/instruction cache architecture is considered, our results show an average improvement of 14.5% for the Powerstone benchmarks and an average improvement of 15.2% for the SPEC'00 benchmarks.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2069410700",
    "type": "article"
  },
  {
    "title": "A gateway node with duty-cycled radio and processing subsystems for wireless sensor networks",
    "doi": "https://doi.org/10.1145/1455229.1455234",
    "publication_date": "2009-01-01",
    "publication_year": 2009,
    "authors": "Zhong-Yi Jin; Curt Schurgers; Rajesh K. Gupta",
    "corresponding_authors": "",
    "abstract": "Wireless sensor nodes are increasingly being tasked with computation and communication intensive functions while still subject to constraints related to energy availability. On these embedded platforms, once all low power design techniques have been explored, duty-cycling the various subsystems remains the primary option to meet the energy and power constraints. This requires the ability to provide spurts of high MIPS and high bandwidth connections. However, due to the large overheads associated with duty-cycling the computation and communication subsystems, existing high performance sensor platforms are not efficient in supporting such an option. In this article, we present the design and optimizations taken in a wireless gateway node (WGN) that bridges data from wireless sensor networks to Wi-Fi networks in an on-demand basis. We discuss our strategies to reduce duty-cycling related costs by partitioning the system and by reducing the amount of time required to activate or deactivate the high-powered components. We compare the design choices and performance parameters with those made in the Intel Stargate platform to show the effectiveness of duty-cycling on our platform. We have built a working prototype, and the experimental results with two different power management schemes show significant reductions in latency and average power consumption compared to the Stargate . The WGN running our power-gating scheme performs about six times better in terms of average system power consumption than the Stargate running the suspend-system scheme for large working-periods where the active power dominates. For short working-periods where the transition (enable/disable) power becomes dominant, we perform up to seven times better. The comparative performance of our system is even greater when the sleep power dominates.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W1964156804",
    "type": "article"
  },
  {
    "title": "Selective shielding technique to eliminate crosstalk transitions",
    "doi": "https://doi.org/10.1145/1529255.1529265",
    "publication_date": "2009-05-01",
    "publication_year": 2009,
    "authors": "Madhu Mutyam",
    "corresponding_authors": "Madhu Mutyam",
    "abstract": "With CMOS process technology scaling to deep submicron level, propagation delay across long on-chip buses is becoming one of the main performance limiting factors in high-performance designs. Propagation delay is very significant when adjacent wires are transitioning in opposite direction as compared to transitioning in the same direction. As opposite transitions on adjacent wires (called as crosstalk transitions ) have significant impact on propagation delay, several bus encoding techniques have been proposed in literature to eliminate such transitions. We propose selective shielding technique to eliminate crosstalk transitions. We show that the selective shielding technique requires ⌈3 n /2⌉ wires to encode a n -bit bus. SPICE simulations by considering 90nm technology nodes reveal that, for uniformly distributed random data, our technique achieves nearly 39% (21%) delay savings over 10 mm -length uncoded 32-bit bus for pipelined (nonpipelined) data transmission at the cost of nearly 7% energy overhead.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W1992483668",
    "type": "article"
  },
  {
    "title": "External memory layout vs. schematic",
    "doi": "https://doi.org/10.1145/1497561.1497573",
    "publication_date": "2009-03-01",
    "publication_year": 2009,
    "authors": "Yokesh Kumar; Prosenjit Gupta",
    "corresponding_authors": "",
    "abstract": "The circuit represented by a VLSI layout must be verified by checking it against the schematic circuit as an important part of the functional verification step. This involves two central problems of matching the circuit graphs with each other (graph isomorphism) and extracting a higher level of circuit from a given level by finding subcircuits in the circuit graph (subgraph isomorphism). Modern day VLSI layouts contain millions of devices. Hence the memory requirements of the data structures required by tools for verifying them become huge and can easily exceed the amount of internal memory available on a computer. In such a scenario, a program not aware of the memory hierarchy performs badly because of its unorganized input/output operations (I/Os) as the speed of a disk access is about a million times slower than accessing a main memory location. In this article, we present I/O-efficient algorithms for the graph isomorphism and subgraph isomorphism problems in the context of verification of VLSI layouts. Experimental results show the need and utility of I/O-efficient algorithms for handling problems with large memory requirements.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W1994124032",
    "type": "article"
  },
  {
    "title": "A design automation and power estimation flow for RFID systems",
    "doi": "https://doi.org/10.1145/1455229.1455236",
    "publication_date": "2009-01-01",
    "publication_year": 2009,
    "authors": "Swapna Dontharaju; Shenchih Tung; J.T. Cain; Leonid Mats; Marlin H. Mickle; Alex K. Jones",
    "corresponding_authors": "",
    "abstract": "While RFID has become a ubiquitous technology, there is still a need for RFID systems with different capabilities, protocols, and features depending on the application. This article describes a design automation flow and power estimation technique for fast implementation and design feedback of new RFID systems. Physical layer features are described using waveform features , which are used to automatically generate physical layer encoding and decoding hardware blocks. RFID primitives to be supported by the tag are enumerated with RFID macros and the behavior of each primitive is specified using ANSI-C within the template to automatically generate the tag controller. Case studies implementing widely used standards such as ISO 18000 Part 7 and ISO 18000 Part 6C using this automation technique are presented. The power macromodeling flow demonstrated here is shown to be within 5% to 10% accuracy, while providing results 100 times faster than traditional methods. When eliminating the need for certain features of ISO 18000 Part 6C, the design flow shows that the power required by the implementation is reduced by nearly 50%.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2049776769",
    "type": "article"
  },
  {
    "title": "An energy-efficient I/O request mechanism for multi-bank flash-memory storage systems",
    "doi": "https://doi.org/10.1145/1455229.1455235",
    "publication_date": "2009-01-01",
    "publication_year": 2009,
    "authors": "Chin-Hsien Wu",
    "corresponding_authors": "Chin-Hsien Wu",
    "abstract": "Emerging critical issues for flash-memory storage systems, especially with regard to implementation within many embedded systems, are the programmed I/O nature of data transfers and their energy-efficient nature. We propose an I/O request mechanism in the Memory-Technology-Device (MTD) layer to exploit the programmed I/O-based data transfers for flash-memory storage systems. We propose to revise the waiting function in the Memory-Technology-Device (MTD) layer to relieve the microprocessor from busy-waiting, in order to make more CPU cycles available for other tasks. An energy-efficient mechanism based on the I/O request mechanism is also presented for multi-bank flash-memory storage systems, which particularly focuses on switching the power state of each flash-memory bank. We demonstrate that the energy-efficient I/O request mechanism not only saves more CPU cycles to execute other tasks, but also reduces the energy consumption of flash-memory, based on experiments incorporating realistic system workloads.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2053270857",
    "type": "article"
  },
  {
    "title": "Efficient memory management for hardware accelerated Java Virtual Machines",
    "doi": "https://doi.org/10.1145/1562514.1562516",
    "publication_date": "2009-08-01",
    "publication_year": 2009,
    "authors": "Peter Bertels; Wim Heirman; Erik D’Hollander; Dirk Stroobandt",
    "corresponding_authors": "",
    "abstract": "Application-specific hardware accelerators can significantly improve a system's performance. In a Java-based system, we then have to consider a hybrid architecture that consists of a Java Virtual Machine running on a general-purpose processor connected to the hardware accelerator. In such a hybrid architecture, data communication between the accelerator and the general-purpose processor can incur a significant cost, which may even annihilate the original performance improvement of adding the accelerator. A careful layout of the data in the memory structure is therefore of major importance to maintain the acceleration performance benefits. This article addresses the reduction of the communication cost in a distributed shared memory consisting of the main memory of the processor and the accelerator's local memory, which are unified in the Java heap. Since memory access times are highly nonuniform, a suitable allocation of objects in either main memory or the accelerator's local memory can significantly reduce the communication cost. We propose several techniques for finding the optimal location for each Java object's data, either statically through profiling or dynamically at runtime. We show how we can reduce communication cost by up to 86% for the SPECjvm and DaCapo benchmarks. We also show that the best strategy is application dependent and also depends on the relative cost of remote versus local accesses. For a relative cost higher than 10, a self-learning dynamic approach often results in the best performance.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2059033134",
    "type": "article"
  },
  {
    "title": "Express Read in MLC Phase Change Memories",
    "doi": "https://doi.org/10.1145/3177876",
    "publication_date": "2018-02-23",
    "publication_year": 2018,
    "authors": "Majid Jalili; Hamid Sarbazi‐Azad",
    "corresponding_authors": "",
    "abstract": "In the era of big data, the capability of computer systems must be enhanced to support 2.5 quintillion byte/day data delivery. Among the components of a computer system, main memory has a great impact on overall system performance. DRAM technology has been used over the past four decades to build main memories. However, the scalability of DRAM technology has faced serious challenges. To keep pace with the ever-increasing demand for larger main memory, some new alternative technologies have been introduced. Phase change memory (PCM) is considered as one of such technologies for substituting DRAM. PCM offers some noteworthy properties such as low static power consumption, nonvolatility, and capability of storing more than one bit per cell (multilevel cell, or MLC). However, the short lifetime and long access latency of PCM (specifically MLC PCM) require feasible and efficient solutions. In this article, based on the observation that applications access a significant number of read-friendly data blocks, we propose Express Read to prevent the MLC PCM read circuit to spend unnecessary time sensing the cells of a memory block. A read-friendly data block (RFDB) is composed of only “11” and “00” bit pairs, and thus upon sensing the most significant bit of a cell, the read operation can be early terminated to reduce the MLC read time and power consumption. Moreover, we increase the number of RFDBs using two simple techniques to better exploit the benefits of Express Read. Results obtained from full-system simulation near 6% performance improvement and 21% energy gain, on average, over the baseline system.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2790712845",
    "type": "article"
  },
  {
    "title": "An Approximation Algorithm for Threshold Voltage Optimization",
    "doi": "https://doi.org/10.1145/3232538",
    "publication_date": "2018-11-06",
    "publication_year": 2018,
    "authors": "Siad Daboul; Stephan Held; Jens Vygen; Sonja Wittke",
    "corresponding_authors": "",
    "abstract": "We present a primal-dual approximation algorithm for minimizing the leakage power of an integrated circuit by assigning gate threshold voltages. While most existing techniques do not provide a performance guarantee, we prove an upper bound on the power consumption. The algorithm is practical and works with an industrial sign-off timer. It can be used for post-routing power reduction or for optimizing leakage power throughout the design flow. We demonstrate the practical performance on recent microprocessor units. Our implementation obtains significant leakage power reductions of up to 8% on top of one of the most successful algorithms for gate sizing and threshold voltage optimization. After timing-aware global routing, we achieve leakage power reductions of up to 34%.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2899604132",
    "type": "article"
  },
  {
    "title": "CASCA",
    "doi": "https://doi.org/10.1145/3241047",
    "publication_date": "2018-11-06",
    "publication_year": 2018,
    "authors": "Lorenzo Delledonne; Vittorio Zaccaria; Ruggero Susella; Guido Bertoni; Filippo Melzani",
    "corresponding_authors": "",
    "abstract": "Implementing a cryptographic circuit poses challenges not always acknowledged in the backing mathematical theory. One of them is the vulnerability against side-channel attacks . A side-channel attack is a procedure that uses information leaked by the circuit through, for example, its own power consumption or electromagnetic emissions, to derive sensitive data (e.g, the secret key used for encryption). Nowadays, we design circuitry to keep this sensitive information from leaking (i.e., a countermeasure ), but the path from specification down to implementation is far from being fully automatic. As we know, manual refinement steps can be error prone and the sheer potential of these errors can be devastating in a scenario such as the one we are dealing with. In this article, we investigate whether a single embedded domain specific language (EDSL) can, at the same time, help us in specifying and enforcing the functionality of the circuit as well as its protection against side-channel attacks. The EDSL is a fundamental block of an original design flow (named Countermeasure Against Side-Channel Attacks, i.e., CASCA) whose aim is to complement an existing industrial scenario and to provide the necessary guarantee that a secure primitive is not vulnerable up to a first-order attack. As a practical case study, we will show how we applied the proposed tools to ensure both functional and extra-functional correctness of a composite-field Advanced Encryption Standard (AES) S-Box. To ensure the reproducibility of this research, this article is accompanied by an open source release of the EDSL 1 that contains the presented S-Box implementation and an additional 3-Shares threshold implementation of the Keccak χ function [7].",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2899874511",
    "type": "article"
  },
  {
    "title": "Quality-Enhanced OLED Power Savings on Mobile Devices",
    "doi": "https://doi.org/10.1145/3243215",
    "publication_date": "2018-11-19",
    "publication_year": 2018,
    "authors": "Chun‐Han Lin; Chih-Kai Kang; Pi-Cheng Hsiu",
    "corresponding_authors": "",
    "abstract": "In the future, mobile systems will increasingly feature more advanced organic light-emitting diode (OLED) displays. The power consumption of these displays is highly dependent on the image content. However, existing OLED power-saving techniques either change the visual experience of users or degrade the visual quality of images in exchange for a reduction in the power consumption. Some techniques attempt to enhance the image quality by employing a compound objective function. In this article, we present a win-win scheme that always enhances the image quality while simultaneously reducing the power consumption. We define metrics to assess the benefits and cost for potential image enhancement and power reduction. We then introduce algorithms that ensure the transformation of images into their quality-enhanced power-saving versions. Next, the win-win scheme is extended to process videos at a justifiable computational cost. All the proposed algorithms are shown to possess the win-win property without assuming accurate OLED power models. Finally, the proposed scheme is realized through a practical camera application and a video camcorder on mobile devices. The results of experiments conducted on a commercial tablet with a popular image database and on a smartphone with real-world videos are very encouraging and provide valuable insights for future research and practices.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2900520822",
    "type": "article"
  },
  {
    "title": "Optimal Allocation of Computation and Communication in an IoT Network",
    "doi": "https://doi.org/10.1145/3236623",
    "publication_date": "2018-11-30",
    "publication_year": 2018,
    "authors": "Abhimanyu Chopra; Hakan Aydın; Setareh Rafatirad; Houman Homayoun",
    "corresponding_authors": "",
    "abstract": "Internet of things (IoT) is being developed for a wide range of applications from home automation and personal fitness to smart cities. With the extensive growth in adaptation of IoT devices comes the uncoordinated and substandard designs aimed at promptly making products available to the end consumer. This substandard approach restricts the growth of IoT in the near future and necessitates that studies understand requirements for an efficient design. A particular area where IoT applications have grown significantly is surveillance and monitoring. Applications of IoT in this domain are relying on distributed sensors, each equipped with a battery, capable of collecting images, processing images, and communicating the raw or processed data to the nearest node until it reaches the base station for decision making. In such an IoT network where processing can be distributed over the network, the important research question is how much of data each node should process and how much it should communicate for a given objective. This work answers this question and provides a deeper understanding of energy and delay tradeoffs in an IoT network with three different target metrics.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2906242844",
    "type": "article"
  },
  {
    "title": "SynergyFlow",
    "doi": "https://doi.org/10.1145/3275243",
    "publication_date": "2018-12-21",
    "publication_year": 2018,
    "authors": "Jiajun Li; Guihai Yan; Wenyan Lü; Shijun Gong; Shuhao Jiang; Jingya Wu; Xiaowei Li",
    "corresponding_authors": "",
    "abstract": "Neural networks (NNs) have achieved great success in a broad range of applications. As NN-based methods are often both computation and memory intensive, accelerator solutions have been proved to be highly promising in terms of both performance and energy efficiency. Although prior solutions can deliver high computational throughput for convolutional layers, they could incur severe performance degradation when accommodating the entire network model, because there exist very diverse computing and memory bandwidth requirements between convolutional layers and fully connected layers and, furthermore, among different NN models. To overcome this problem, we proposed an elastic accelerator architecture, called SynergyFlow, which intrinsically supports layer-level and model-level parallelism for large-scale deep neural networks. SynergyFlow boosts the resource utilization by exploiting the complementary effect of resource demanding in different layers and different NN models. SynergyFlow can dynamically reconfigure itself according to the workload characteristics, maintaining a high performance and high resource utilization among various models. As a case study, we implement SynergyFlow on a P395-AB FPGA board. Under 100MHz working frequency, our implementation improves the performance by 33.8% on average (up to 67.2% on AlexNet) compared to comparable provisioned previous architectures.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2906374897",
    "type": "article"
  },
  {
    "title": "Remote Attestation via Self-Measurement",
    "doi": "https://doi.org/10.1145/3279950",
    "publication_date": "2018-12-21",
    "publication_year": 2018,
    "authors": "Xavier Carpent; Norrathep Rattanavipanon; Gene Tsudik",
    "corresponding_authors": "",
    "abstract": "Remote attestation (RA) is a popular means of detecting malware in embedded and IoT devices. RA is usually realized as an interactive protocol, whereby a trusted party ( verifier ) measures software integrity of a potentially compromised remote device ( prover) . Early work focused on purely software-based and fully hardware-based techniques, neither of which is ideal for low-end embedded devices. More recent results yielded hybrid (SW/HW) architectures with a minimal set of features to support efficient and secure RA on low-end devices. All prior techniques require on-demand operation , i.e., RA is performed in real time . We identify some drawbacks of this general approach in the context of unattended devices: First, it fails to detect mobile malware that enters and leaves prover between successive RA instances. Second, it requires prover to engage in a potentially expensive (in terms of time and energy) computation, which can be harmful for mission-critical or real-time devices. To address these drawbacks, we introduce the concept of self-measurement , whereby prover periodically and securely measures and records its own software state, based on a pre-established schedule. A (possibly untrusted) verifier occasionally collects and verifies these measurements. We present the design of a concrete technique, called Efficient Remote Attestation via Self-Measurement for Unattended Settings, (ERASMUS), justify its features and evaluate its performance. In the process, we also define a new metric, Quality of Attestation (QoA). We believe that ERASMUS is well suited for time-sensitive and/or safety-critical applications that are not served well by on-demand RA. Finally, we show that ERASMUS is a promising stepping stone toward handling attestation of multiple devices (i.e., a group or swarm) with high mobility.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2906545987",
    "type": "article"
  },
  {
    "title": "Enhancing Speculative Execution With Selective Approximate Computing",
    "doi": "https://doi.org/10.1145/3307651",
    "publication_date": "2019-02-14",
    "publication_year": 2019,
    "authors": "Bernard Nongpoh; R. L. Ray; Moumita Das; Ansuman Banerjee",
    "corresponding_authors": "",
    "abstract": "Speculative execution is an optimization technique used in modern processors by which predicted instructions are executed in advance with an objective of overlapping the latencies of slow operations. Branch prediction and load value speculation are examples of speculative execution used in modern pipelined processors to avoid execution stalls. However, speculative executions incur a performance penalty as an execution rollback when there is a misprediction. In this work, we propose to aid speculative execution with approximate computing by relaxing the execution rollback penalty associated with a misprediction. We propose a sensitivity analysis method for data and branches in a program to identify the data load and branch instructions that can be executed without any rollback in the pipeline and yet can ensure a certain user-specified quality of service of the application with a probabilistic reliability. Our analysis is based on statistical methods, particularly hypothesis testing and Bayesian analysis. We perform an architectural simulation of our proposed approximate execution and report the benefits in terms of CPU cycles and energy utilization on selected applications from the AxBench, ACCEPT, and Parsec 3.0 benchmarks suite.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2913814439",
    "type": "article"
  },
  {
    "title": "Integrated Approach of Airgap Insertion for Circuit Timing Optimization",
    "doi": "https://doi.org/10.1145/3306494",
    "publication_date": "2019-02-14",
    "publication_year": 2019,
    "authors": "Daijoon Hyun; Youngsoo Shin",
    "corresponding_authors": "",
    "abstract": "Airgap technology enables air to be introduced in inter-metal dielectric (IMD). Airgap between certain wires reduces coupling capacitance due to the reduced permittivity; this can be utilized to decrease circuit delay. We propose an integrated approach of airgap insertion with the goal of circuit timing optimization. It consists of three sub-problems. We first select the layers that employ airgap, called airgap layers, that maximize total negative slack (TNS) improvement; this yields TNS improvement of 7% to 15% and worst negative slack (WNS) improvement of 2% to 8%, compared to a simple assumption of airgap layers. Second, we reassign the layers of wires such that more wires on critical paths can be placed in airgap layers. This is formulated as integer linear programming (ILP), and a more practical heuristic algorithm is also proposed. It provides an additional 17% TNS improvement and 6% WNS improvement. Finally, we perform airgap insertion through ILP formulation, where a number of design rules are modeled with linear constraints. To reduce the heavy runtime of ILP, a layout partitioning technique is also applied. It implements a feasible airgap mask in a manageable time where the amount of inserted airgap is close to the optimal solution.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2914723795",
    "type": "article"
  },
  {
    "title": "MEMS-IC Robustness Optimization Considering Electrical and Mechanical Design and Process Parameters",
    "doi": "https://doi.org/10.1145/3325068",
    "publication_date": "2019-06-14",
    "publication_year": 2019,
    "authors": "Florin Burcea; Andreas Herrmann; Bing Li; Helmut Graeb",
    "corresponding_authors": "",
    "abstract": "MEMS-based sensor circuits are traditionally designed separately using CAD tools specific to each energy domain (electrical and mechanical). This article presents a complete approach for combined MEMS-IC robustness optimization. Advanced methods for robustness analysis and optimization considering design, operating and process parameters, developed for integrated circuits, are transferred to MEMS-IC systems. Both electrical and mechanical design and process parameters are included in the optimization. The methodology is exemplified on two demonstrator examples: a MEMS microphone and a MEMS accelerometer, each with an integrated readout circuit. A successful optimization requires the simultaneous inclusion of design parameters and process tolerances from both energy domains. To save CPU time, a reduced-order, circuit-level model is used for the MEMS part and this model is created only when necessary. To integrate the generation of the simplified model into the optimization flow, a simulation-in-a-loop flow based on commercial tools for both the electrical and the mechanical domain has been implemented.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2949668965",
    "type": "article"
  },
  {
    "title": "A Novel Rule Mapping on TCAM for Power Efficient Packet Classification",
    "doi": "https://doi.org/10.1145/3328103",
    "publication_date": "2019-06-07",
    "publication_year": 2019,
    "authors": "Vegesna S. M. Srinivasavarma; Ashok Chakravarthy Nara; Noor Mahammad Sk",
    "corresponding_authors": "",
    "abstract": "Packet Classification is the enabling function performed in commodity switches for providing various services such as access control, intrusion detection, load balancing, and so on. Ternary Content Addressable Memories (TCAMs) are the de facto standard for performing packet classification at high speeds. However, TCAMs are highly costlier both in terms of cost and power consumption, forcing the switch vendors towards placing lots of effort for power management. Hence, power-efficient solutions for TCAM-based packet classification are highly relevant even today. In this article, we propose a novel rule placement algorithm based on the unique field values’ presence within the rule databases. We evaluate the total search that is needed to be inspected with respect to the traditional placement approach and the proposed placement approach based on the information content within the fields. Simulation results showed an average reduction of 30.55% in the search space by the proposed placement approach, thereby resulting in an average reduction of 18.85% per search energy over TCAM. With typical TCAM clock speeds ranging between 200--400MHz, this reduction in the per-search energy maps to a huge reduction in the total energy consumed by the TCAM-based network switches. The proposed solution is plug-and-play type requiring only minimal pre-processing within the Network Processing Unit (NPU) of the switches and edge routers.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2952819091",
    "type": "article"
  },
  {
    "title": "Runtime Stress Estimation for Three-dimensional IC Reliability Management Using Artificial Neural Network",
    "doi": "https://doi.org/10.1145/3363185",
    "publication_date": "2019-11-06",
    "publication_year": 2019,
    "authors": "Hai Wang; Xiao Tao; Darong Huang; Lang Zhang; Chi Zhang; He Tang; Yuan Yuan",
    "corresponding_authors": "",
    "abstract": "Heat dissipation and the related thermal-mechanical stress problems are the major obstacles in the development of the three-dimensional integrated circuit (3D IC). Reliability management techniques can be used to alleviate such problems and enhance the reliability of 3D IC. However, it is difficult to obtain the time-varying stress information at runtime, which limits the effectiveness of the reliability management. In this article, we propose a fast stress estimation method for runtime reliability management using artificial neural network (ANN). The new method builds ANN-based stress model by training offline using temperature and stress data. The ANN stress model is then used to estimate the important stress information, such as the maximum stress around each TSV, for reliability management at runtime. Since there are a variety of potential ANN structures to choose from for the ANN stress model, we analyze and test three ANN-based stress models with three major types of ANNs in this work: the normal ANN-based stress model, the ANN stress model with hand-crafted feature extraction, and the convolutional neural network–(CNN) based stress model. The structures of each ANN stress model and the functions of these structures in 3D IC stress estimation are demonstrated and explained. The new runtime stress estimation method is tested using the three ANN stress models with different layer configurations. Experiments show that the new method is able to estimate important stress information at extremely fast speed with good accuracy for runtime 3D IC reliability enhancement. Although all three ANN stress models show acceptable capabilities in runtime stress estimation, the CNN-based stress model achieves the best performance considering both stress estimation accuracy and computing overhead. Comparison with traditional method reveals that the new ANN-based stress estimation method is much more accurate with a slightly larger but still very small computing overhead.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2989443438",
    "type": "article"
  },
  {
    "title": "Reuse Distance-based Victim Cache for Effective Utilisation of Hybrid Main Memory System",
    "doi": "https://doi.org/10.1145/3380732",
    "publication_date": "2020-02-28",
    "publication_year": 2020,
    "authors": "Arijit Nath; Sukarn Agarwal; Hemangee K. Kapoor",
    "corresponding_authors": "",
    "abstract": "Hybrid main memories comprising DRAM and Non-volatile memories (NVM) are projected as potential replacements of the traditional DRAM-based memories. However, traditional cache management policies designed for improving the hit rate lack awareness of the comparative latency of read-write for NVM blocks where the write latency is more than the read latency. Therefore, developing cache management techniques that reduce costly write-backs of the NVM blocks, yet maintain a fair hit rate in the cache, is of paramount importance. We propose two techniques based on the use of a small victim cache associated with the last-level cache that helps in retaining on the chip critical DRAM and NVM blocks. Victim cache being a scarce resource, we intend to keep only performance-critical blocks in the victim cache by exploiting the idea of reuse distance. The first technique, Victim Cache Replacement Policy, works on the replacement policy of the victim cache by preferential eviction of DRAM blocks over NVM blocks. However, the second technique, Prioritized Partitioning of victim cache, logically partitions the victim cache, giving a smaller share to the DRAM blocks and a relatively larger share to the NVM blocks. Experimental evaluation on full-system simulator shows significant improvement in system performance and reduction in the number of write-backs to the NVM partition of the main memory compared to the baseline and existing technique. Additionally, NVM reads and DRAM miss rate are also improved, leading to further performance enhancement.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W3013138232",
    "type": "article"
  },
  {
    "title": "On Fundamental Principles for Thermal-Aware Design on Periodic Real-Time Multi-Core Systems",
    "doi": "https://doi.org/10.1145/3378063",
    "publication_date": "2020-02-06",
    "publication_year": 2020,
    "authors": "Shi Sha; Ajinkya S. Bankar; Xiaokun Yang; Wujie Wen; Gang Quan",
    "corresponding_authors": "",
    "abstract": "With the exponential rise of the transistor count in one chip, the thermal problem has become a pressing issue in computing system design. While there have been extensive methods and techniques published for design optimization with thermal awareness, there is a need for more rigorous and formal thermal analysis in designing real-time systems and applications that demand a strong exception guarantee. In this article, we analytically prove a series of fundamental properties and principles concerning the RC thermal model, peak temperature identification, and peak temperature reduction for periodic real-time systems, which are general enough to be applied on 2D and 3D multi-core platforms. These findings enhance the worst-case temperature predictability in runtime scenarios, as well as help to develop more effective thermal management policy, which is key to thermal-constrained periodic real-time system design.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W3023650607",
    "type": "article"
  },
  {
    "title": "Architectural Design of Flow-Based Microfluidic Biochips for Multi-Target Dilution of Biochemical Fluids",
    "doi": "https://doi.org/10.1145/3357604",
    "publication_date": "2020-05-13",
    "publication_year": 2020,
    "authors": "Nishant Kamal; Ankur Gupta; Ananya Singla; Shubham Tiwari; Parth Kohli; Sudip Roy; Bhargab B. Bhattacharya",
    "corresponding_authors": "",
    "abstract": "Microfluidic technologies enable replacement of time-consuming and complex steps of biochemical laboratory protocols with a tiny chip. Sample preparation (i.e., dilution or mixing of fluids) is one of the primary tasks of any bioprotocol. In real-life applications where several assays need to be executed for different diagnostic purposes, the same sample fluid is often required with different target concentration factors ( CF s). Although several multi-target dilution algorithms have been developed for digital microfluidic biochips, they are not efficient for implementation with continuous-flow-based microfluidic chips, which are preferred in the laboratories. In this article, we present a multi-target dilution algorithm ( MTDA ) for continuous-flow-based microfluidic biochips, which to the best of our knowledge is the first of its kind. We design a flow-based rotary mixer with a suitable number of segments depending on the target- CF profile, error tolerance, and optimization criteria. To schedule several intermediate fluid-mixing tasks, we develop a multi-target scheduling algorithm ( MTSA ) aiming to minimize the usage of storage units while producing dilutions with multiple CF s. Furthermore, we propose a storage architecture for efficiently loading (storing) of intermediate fluids from (to) the storage units.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W3028507340",
    "type": "article"
  },
  {
    "title": "Wire Load Oriented Analog Routing with Matching Constraints",
    "doi": "https://doi.org/10.1145/3403932",
    "publication_date": "2020-08-25",
    "publication_year": 2020,
    "authors": "Hao Yu; Chien Nan Jimmy Liu; Hung Ming Chen",
    "corresponding_authors": "",
    "abstract": "As design complexity is increased exponentially, electronic design automation (EDA) tools are essential to reduce design efforts. However, the analog layout design has still been done manually for decades because it is a sensitive and error-prone task. Tool-generated layouts are still not well-accepted by analog designers due to the performance loss under non-ideal effects. Most previous works focus on adding more layout constraints on the analog placement. Routing the nets is thus considered as a trivial step that can be done by typical digital routing methodology, which is to use vias to connect every horizontal and vertical lines. Those extra vias will significantly increase the wire loads and degrade the circuit performance. Therefore, in this article, a wire load oriented analog routing methodology is proposed to reduce the number of layer changing of each routing net. Wire load is considered in the optimization goal as well as the wire length to keep the circuit performance after layout, while the analog layout constraints like symmetry and length matching are still satisfied during routing. As shown in the experimental results, this approach significantly reduces the wire load and performance loss after layout with little overhead on wire length.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W3080284064",
    "type": "article"
  },
  {
    "title": "Efficient Parasitic-aware <i> g <sup>m</sup> </i> / <i> I <sup>D</sup> - </i> based Hybrid Sizing Methodology for Analog and RF Integrated Circuits",
    "doi": "https://doi.org/10.1145/3416946",
    "publication_date": "2020-10-28",
    "publication_year": 2020,
    "authors": "Tuotian Liao; Lihong Zhang",
    "corresponding_authors": "",
    "abstract": "As the primary second-order effect, parasitic issues have to be seriously addressed when synthesizing high-performance analog and RF integrated circuits (ICs). In this article, a two-phase hybrid sizing methodology for analog and RF ICs is proposed to take into account parasitic effect in the early design stage. It involves symbolic modeling and mixed-integer nonlinear programming (MINLP) in the first phase, and a many-objective evolutionary algorithm (many-OEA)-based sizing refiner in the second phase. With the aid of our proposed current density factor and piecewise curve fitting technique, the g m / I D concept, which is typically utilized to solve the analog circuit design problem, can provide theoretical support to our accurate symbolic modeling. Thus, the intrinsic and interconnect parasitics can be accurately considered in our work with moderate modeling effort. A variety of electrical, geometric, and parasitic (including parasitic mismatch) constraints can be conveniently integrated into our MINLP problem formulation. Moreover, numerical simulations are embedded into the many-OEA-based sizing phase, which is able to tackle floorplan co-optimization. With such dynamic floorplan variation, the parasitics accuracy can be sustained along the evolution. The experimental results demonstrate high efficacy of our proposed parasitic-aware hybrid sizing methodology.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W3097021646",
    "type": "article"
  },
  {
    "title": "Hardware/software approaches for reducing the process variation impact on instruction fetches",
    "doi": "https://doi.org/10.1145/2489778",
    "publication_date": "2013-10-01",
    "publication_year": 2013,
    "authors": "I. Kadayif; Mahir Turkcan; Seher Kiziltepe; Özcan Öztürk",
    "corresponding_authors": "",
    "abstract": "As technology moves towards finer process geometries, it is becoming extremely difficult to control critical physical parameters such as channel length, gate oxide thickness, and dopant ion concentration. Variations in these parameters lead to dramatic variations in access latencies in Static Random Access Memory (SRAM) devices. This means that different lines of the same cache may have different access latencies. A simple solution to this problem is to adopt the worst-case latency paradigm. While this egalitarian cache management is simple, it may introduce significant performance overhead during instruction fetches when both address translation (instruction Translation Lookaside Buffer (TLB) access) and instruction cache access take place, making this solution infeasible for future high-performance processors. In this study, we first propose some hardware and software enhancements and then, based on those, investigate several techniques to mitigate the effect of process variation on the instruction fetch pipeline stage in modern processors. For address translation, we study an approach that performs the virtual-to-physical page translation once, then stores it in a special register, reusing it as long as the execution remains on the same instruction page. To handle varying access latencies across different instruction cache lines, we annotate the cache access latency of instructions within themselves to give the circuitry a hint about how long to wait for the next instruction to become available.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W1968677371",
    "type": "article"
  },
  {
    "title": "Thread Warping",
    "doi": "https://doi.org/10.1145/1970353.1970365",
    "publication_date": "2011-06-01",
    "publication_year": 2011,
    "authors": "Greg Stitt; Frank Vahid",
    "corresponding_authors": "",
    "abstract": "We introduce thread warping, a dynamic optimization technique that customizes multicore architectures to a given application by dynamically synthesizing threads into custom accelerator circuits on FPGAs (Field-Programmable Gate Arrays). Thread warping builds upon previous dynamic synthesis techniques for single-threaded applications, enabling dynamic architectural adaptation to different amounts of thread-level parallelism, while also exploiting parallelism within each thread to further improve performance. Furthermore, thread warping maintains the important separation of function from architecture, enabling portability of applications to architectures with different quantities of microprocessors and FPGAs, an advantage not shared by static compilation/synthesis approaches. We introduce an approach consisting of CAD tools and operating system support that enables thread warping on potentially any microprocessor/FPGA architecture. We evaluate thread warping using a simulator for high-performance computing systems with different interconnections in addition to multicore embedded systems having between 4 and 64 ARM11 microprocessors. On average, thread warping achieved approximately 3x speedup compared to a high-performance quad-core Intel Xeon and 109x compared to an embedded system consisting of 4 ARM11 cores, with a size cost approximately equal to 36 ARM11 cores.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W1982377660",
    "type": "article"
  },
  {
    "title": "Design of Hardened Embedded Systems on Multi-FPGA Platforms",
    "doi": "https://doi.org/10.1145/2676551",
    "publication_date": "2014-11-18",
    "publication_year": 2014,
    "authors": "Cristiana Bolchini; Chiara Sandionigi",
    "corresponding_authors": "",
    "abstract": "The aim of this article is the definition of a reliability-aware methodology for the design of embedded systems on multi-FPGA platforms. The designed system must be able to detect the occurrence of faults globally and autonomously, in order to recover or to mitigate their effects. Two categories of faults are identified, based on their impact on the device elements; (i) recoverable faults, transient problems that can be fixed without causing a lasting effect namely and (ii) nonrecoverable faults, those that cause a permanent problem, making the portion of the fabric unusable. While some aspects can be taken from previous solutions available in literature, several open issues exist. In fact, no complete design methodology handling all the peculiar issues of the considered scenario has been proposed yet, a gap we aim at filling with our work. The final system exposes reliability properties and increases its overall lifetime and availability.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W1995795398",
    "type": "article"
  },
  {
    "title": "SmartCap",
    "doi": "https://doi.org/10.1145/2651402",
    "publication_date": "2014-11-18",
    "publication_year": 2014,
    "authors": "Xueliang Li; Guihai Yan; Yinhe Han; Xiaowei Li",
    "corresponding_authors": "",
    "abstract": "Power efficiency is increasingly critical to battery-powered smartphones. Given that the using experience is most valued by the user, we propose that the power optimization should directly respect the user experience. We conduct a statistical sample survey and study the correlation among the user experience, system runtime activities, and computational performance of an application processor. We find that there exists a minimal frequency requirement, called “saturated frequency”. Above this frequency, the device consumes more power but provides little improvements in user experience. This study motivates an intelligent self-adaptive scheme, SmartCap, that automatically identifies the most power-efficient state of the application processor. Compared to prior Linux power adaptation schemes, SmartCap can help save power from 11% to 84%, depending on applications, with little decline in user experience.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2013821507",
    "type": "article"
  },
  {
    "title": "A 36μW heartbeat-detection processor for a wireless sensor node",
    "doi": "https://doi.org/10.1145/2003695.2003711",
    "publication_date": "2011-10-01",
    "publication_year": 2011,
    "authors": "Filipa Duarte; Jos Hulzink; Jun Zhou; Jan Stuijt; Jos Huisken; Harmke de Groot",
    "corresponding_authors": "",
    "abstract": "In order to provide better services to elderly people, home healthcare monitoring systems have been increasingly deployed. Typically, these systems are based on wireless sensor nodes, and should utilize very low energy during their lifetimes, as they are powered by scavengers. In this article, we present an ultra-low power processing system for a wireless sensor node for very low duty cycle applications. In the CoolBio system-on-chip, we utilized several power reduction techniques at both the architecture level and the circuit level. These techniques include feature extraction, voltage and frequency scaling, clock and power gating and a redesign of key standard cells. In the design of the ultra-low power processing system, we paid special attention to the memory subsystem, as it is one of the most power-consuming modules in a design. We also designed a clock manager in order to reduce the power consumed by clocking, and a power manager that is able to power-off unutilized modules. The proposed wireless sensor node processing system consumes 36.4μW at 100MHz and 1.2V supply voltage, for a heartbeat-detection algorithm with a 0.01% duty cycle.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2027208086",
    "type": "article"
  },
  {
    "title": "A study of row-based area-array I/O design planning in concurrent chip-package design flow",
    "doi": "https://doi.org/10.1145/2442087.2442101",
    "publication_date": "2013-03-01",
    "publication_year": 2013,
    "authors": "Ren-Jie Lee; Hung-Ming Chen",
    "corresponding_authors": "",
    "abstract": "IC-centric design flow has been a common paradigm when designing and optimizing a system. Package and board/system designs are usually followed by almost-ready chip designs, which causes long turn-around time communicating with package and system houses. In this article, the realizations of area-array I/O design methodologies are studied. Different from IC-centric flow, we propose a chip-package concurrent design flow to speed up the design time. Along with the flow, we design the I/O-bump (and P/G-bump) tile that combines I/O (and P/G) and bump into a hard macro with the considerations of I/O power connection and electrostatic discharge (ESD) protection. We then employ an I/O-row based scheme to place I/O-bump tiles with existed metal layers. By such a scheme, it reduces efforts in I/O placement legalization and the redistribution layer (RDL) routing. With the emphasis on package design awareness, the proposed methods map package balls onto chip I/Os, thus providing an opportunity to design chip and package in parallel. Due to this early study of I/O and bump planning, faster convergence can be expected with concurrent design flow. The results are encouraging and the merits of this flow are reassuring.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2035517962",
    "type": "article"
  },
  {
    "title": "Mitigating the effects of large multiple cell upsets (MCUs) in memories",
    "doi": "https://doi.org/10.1145/2003695.2003705",
    "publication_date": "2011-10-01",
    "publication_year": 2011,
    "authors": "Juan Antonio Maestro; Pedro Reviriego; Sanghyeon Baeg; Shi-Jie Wen; Richard Wong",
    "corresponding_authors": "",
    "abstract": "Reliability is a critical issue for memories. Radiation particles that hit the device can cause errors in some cells, which can lead to data corruption. To avoid this problem, memories are protected with per-word error correction codes (ECCs). Typically, single-error correction and double-error detection (SEC-DED) codes are used. As technology scales, errors caused by radiation particles on memories tend to affect more than one cell—what is known as a multiple cell upset (MCU). To ensure that only a single cell is affected in each word, interleaving is used. With interleaving, cells that belong to the same word are placed at a sufficient distance such that an MCU will only affect a single cell on each word. The use of interleaving significantly increases the cost of the device. Also, determining the interleaving distance (ID) required to avoid MCUs causing double errors is not trivial. Typically, accelerated radiation experiments with a limited number of particle hits are used. They provide a lower bound on the required ID, but larger MCUs may occur with a low probability. But even if the percentage of such large MCUs is very low, the impact on reliability can be significant. This article presents a technique to mitigate the effects of large MCUs that is, those that exceed the ID, on memory reliability. The proposed approach is able to correct most double errors caused by large MCUs by exploiting the locality of the errors within an MCU.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2043237748",
    "type": "article"
  },
  {
    "title": "Data-Driven Optimization of Order Admission Policies in a Digital Print Factory",
    "doi": "https://doi.org/10.1145/2699836",
    "publication_date": "2015-03-02",
    "publication_year": 2015,
    "authors": "Qing Duan; Jun Zeng; Krishnendu Chakrabarty; Gary Dispoto",
    "corresponding_authors": "",
    "abstract": "On-demand digital print service is an example of a real-time embedded enterprise system. It offers mass customization and exemplifies personalized manufacturing services. Once a print order is submitted to the print factory by a client, the print service provider (PSP) needs to make a real-time decision on whether to accept or refuse this order. Based on the print factory's current capacity and the order's properties and requirements, an order is refused if its acceptance is not profitable for the PSP. The order is accepted with the most appropriate due date in order to maximize the profit that can result from this order. We have developed an automated learning-based order admission framework that can be embedded into an enterprise environment to provide real-time admission decisions for new orders. The framework consists of three classifiers: Support Vector Machine (SVM), Decision Tree (DT), and Bayesian Probabilistic Model (BPM). The classifiers are trained by history orders and used to predict completion status for new orders. A decision integration technique is implemented to combine the results of the classifiers and predict due dates. Experimental results derived using real factory data from a leading print service provider and Weka open-source software show that the order completion status prediction accuracy is significantly improved by the decision integration strategy. The proposed multiclassifier model also outperforms a standalone regression model.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2043648987",
    "type": "article"
  },
  {
    "title": "Destination-based congestion awareness for adaptive routing in 2D mesh networks",
    "doi": "https://doi.org/10.1145/2505055",
    "publication_date": "2013-10-01",
    "publication_year": 2013,
    "authors": "Rohit Sunkam Ramanujam; Bill Lin",
    "corresponding_authors": "",
    "abstract": "The choice of routing algorithm plays a vital role in the performance of on-chip interconnection networks. Adaptive routing is appealing because it offers better latency and throughput than oblivious routing, especially under nonuniform and bursty traffic. The performance of an adaptive routing algorithm is determined by its ability to accurately estimate congestion in the network. In this regard, maintaining global congestion state using a separate monitoring network offers better congestion visibility into distant parts of the network compared to solutions relying only on local congestion. However, the main challenge in designing such routing schemes is to keep the logic and bandwidth overhead as low as possible to fit into the tight power, area, and delay budgets of on-chip routers. In this article, we propose a minimal destination-based adaptive routing strategy (DAR), where every node estimates the delay to every other node in the network, and routing decisions are based on these per-destination delay estimates. DAR outperforms Regional Congestion Awareness (RCA), the best previously known adaptive routing algorithm that uses nonlocal congestion state. The performance improvement is brought about by maintaining fine-grained per-destination delay estimates in DAR that are more accurate than regional congestion metrics measured in RCA. The increased accuracy is a consequence of the fact that the per-destination delay estimates are not corrupted by congestion on links outside the admissible routing paths to the destination. A scalable version of DAR, referred to as SDAR, is also proposed for minimizing the overheads associated with DAR in large network topologies. We show that DAR outperforms local adaptive routing by up to 79% and RCA by up to 58% in terms of latency on SPLASH-2 benchmarks. DAR and SDAR also outperform existing adaptive and oblivious routing algorithms in latency and throughput under synthetic traffic patterns on 8×8 and 16times;16 mesh topologies, respectively.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2051663873",
    "type": "article"
  },
  {
    "title": "Near-optimal and scalable intrasignal in-place optimization for non-overlapping and irregular access schemes",
    "doi": "https://doi.org/10.1145/2534383",
    "publication_date": "2013-12-01",
    "publication_year": 2013,
    "authors": "Angeliki Kritikakou; Francky Catthoor; Vasilios Kelefouras; Costas E. Goutis",
    "corresponding_authors": "",
    "abstract": "Storage-size management techniques aim to reduce the resources required to store elements and to concurrently provide efficient addressing during element accessing. Existing techniques are less appropriate for large iteration spaces with increased numbers of irregularly spread holes. They either have to approximate the accessed regions, leading to overestimation of the final resources, or they require prohibited exploration time to find the storage size. In this work, we present a near-optimal and scalable methodology for storage-size, intrasignal, in-place optimization, that is, to compute the minimum amount of resources required to store the elements of a group (array), for irregular complex access schemes in the target domain of non-overlapping store and load accesses.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2057347751",
    "type": "article"
  },
  {
    "title": "Timing Optimization in Sequential Circuit by Exploiting Clock-Gating Logic",
    "doi": "https://doi.org/10.1145/2159542.2159548",
    "publication_date": "2012-04-01",
    "publication_year": 2012,
    "authors": "Shih-Hung Weng; Yu-Min Kuo; Shih-Chieh Chang",
    "corresponding_authors": "",
    "abstract": "Clock gating is a popular technique for reducing power dissipation. In a circuit with clock gating, the clock signal can be shut off without changing the functionality under certain clock-gating conditions. In this article, we observe that the clock-gating conditions and the next-state function of a Flip-Flop (FF) are correlated and can be used for sequential circuit optimization. We also show that the implementation of the next-state function of any FF can be just an inverter if the clock signal is appropriately gated. By exploiting the flexibility between the clock-gating conditions and the next-state function, we propose an iterative optimization algorithm to improve the timing of sequential circuits. We present experimental results of a set of benchmark circuits with a timing improvement of 10.20% on average.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2062763371",
    "type": "article"
  },
  {
    "title": "A New Algorithm for VHDL Parallel Simulation",
    "doi": "https://doi.org/10.1145/1970353.1970360",
    "publication_date": "2011-06-01",
    "publication_year": 2011,
    "authors": "Antonio García-Dopico; Antonio Pérez; Santiago Rodríguez; María Isabel García",
    "corresponding_authors": "",
    "abstract": "This article proposes a new algorithm for parallel synchronous simulation of VHDL designs to be executed on desktop computers. Besides executing VHDL processes in parallel, the algorithm focuses on parallelizing the simulation kernel with special emphasis on signal grouping while maintaining language semantics. Synchronous approaches are the most suitable for shared memory multiprocessor (SMP) desktop computers but may be difficult to parallelize because of the low activity detected in most of the designs. The degree of parallelism is increased in this approach by performing an exhaustive VHDL signal dependencies analysis and avoiding any sequential phase in the simulator. VHDL semantics impose a synchronization barrier after each phase, that is, the process and the kernel simulation phase, as the language definition does not allow simultaneous execution of kernel and processes. These barriers have been relaxed in order to increase the level of parallelism and obtain better performance. Another aspect the new algorithm takes into account is to improve load balancing and locality of references, both critical issues in synchronous simulators, by introducing a new load balancing algorithm that exploits the cyclic characteristics of circuit simulators. These developments make the algorithm suitable for commodity hardware, that is, SMP that are currently used as desktop personal computers.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2081530434",
    "type": "article"
  },
  {
    "title": "Postscheduling buffer management trade-offs in streaming software synthesis",
    "doi": "https://doi.org/10.1145/2209291.2209300",
    "publication_date": "2012-06-01",
    "publication_year": 2012,
    "authors": "Mohammad H. Foroozannejad; Trevor L. Hodges; Matin Hashemi; Soheil Ghiasi",
    "corresponding_authors": "",
    "abstract": "Streaming applications, which are abundant in many disciplines such as multimedia, networking, and signal processing, require efficient processing of a seemingly infinite sequence of input data. In the context of streaming software synthesis from data flow graphs, we study the inherent trade-off between memory requirement and compilation runtime, under a given task firing schedule. We utilize postscheduling analysis granularity to control the amount of details in characterization of buffer's spatio-temporal footprints. Subsequently, we transform the buffer allocation problem to two-dimensional packing of polygons, where complexity of the packing problem (e.g., polygon shapes) is determined by the analysis granularity. We develop an evolutionary packing optimization algorithm which readily yields buffer allocations. Experimental results highlight the trade-off between complexity of the analysis and the total buffer size of generated implementations. In addition, they show dramatic improvements in total buffer size, if one is willing to pay the additional cost in optimization runtime.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2092710969",
    "type": "article"
  },
  {
    "title": "Power-safe application of tdf patterns to flip-chip designs during wafer test",
    "doi": "https://doi.org/10.1145/2491477.2491487",
    "publication_date": "2013-07-01",
    "publication_year": 2013,
    "authors": "Wei Zhao; Junxia Ma; Mohammad Tehranipoor; Sreejit Chakravarty",
    "corresponding_authors": "",
    "abstract": "Due to high switching activities in test mode, circuit power consumption is higher than its functional operation. Large switching in the circuit during launch-to-capture cycles not only negatively impacts circuit performance causing overkill, but could also burn tester probes during wafer test due to the excessive current they must drive. It is necessary to develop a quick and effective method for evaluating each pattern, identifing high-power patterns considering functional and tester probes' current limits and making the final pattern set power-safe. Compared with previous low-power methods that deal with scan structure modification or pattern filling techniques, the new proposed method takes into account layout information and resistance in the power distribution network and can identify peak current among C4 power bumps. Post-processing steps replace power-unsafe patterns with low-power ones. The final pattern set provides considerable peak current reduction while fault coverage is maintained.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2127864206",
    "type": "article"
  },
  {
    "title": "<i>H</i> -Matrix-Based Finite-Element-Based Thermal Analysis for 3D ICs",
    "doi": "https://doi.org/10.1145/2714563",
    "publication_date": "2015-09-28",
    "publication_year": 2015,
    "authors": "Hai‐Bao Chen; Ying-Chi Li; Sheldon X.-D. Tan; Xin Huang; Hai Wang; Ngai Wong",
    "corresponding_authors": "",
    "abstract": "In this article, we propose an efficient finite-element-based (FE-based) method for both steady and transient thermal analyses of high-performance integrated circuits based on the hierarchical matrix ( H -matrix) representation. H -matrix has been shown to provide a data-sparse way to approximate the matrices and their inverses with almost linear-space and time complexities. In this work, we apply the H -matrix concept for solving heating diffusion problems modeled by parabolic partial differential equations (PDEs) based on the finite element method. We show that the matrix from a FE-based steady and transient thermal analysis can be represented by H -matrix without any approximation, and its inverse and Cholesky factors can be evaluated by H -matrix with controlled accuracy. We then show and prove that the memory and time complexities of the solver are bounded by O ( k 1 N log N ) and O ( k 1 2 N log 2 N ), respectively, where k 1 is a small quantity determined by accuracy requirements and N is the number of unknowns in the system. The comparison with existing product-quality LU solvers, CSPARSE and UMFPACK, on a number of 3D IC thermal matrices, shows that the new method is much more memory efficient than these methods, which however prevents CPU time comparison with those methods on large examples. But the proposed method can solve all the given thermal circuits with decent scalabilities, which shows good agreement with the predicted theoretical results.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2158684602",
    "type": "article"
  },
  {
    "title": "Lowering Minimum Supply Voltage for Power-Efficient Cache Design by Exploiting Data Redundancy",
    "doi": "https://doi.org/10.1145/2795229",
    "publication_date": "2015-12-02",
    "publication_year": 2015,
    "authors": "Dongha Jung; Hokyoon Lee; Seon Wook Kim",
    "corresponding_authors": "",
    "abstract": "Voltage scaling is known to be an efficient way of saving power and energy within a system, and large caches such as LLCs are good candidates for voltage scaling considering their constantly increasing size. However, the V CCMIN problem, in which the lower bound of scalable voltage is limited by process variation, has made it difficult to exploit the benefits of voltage scaling. Lowering V CCMIN incurs multibit faults, which cannot be efficiently resolved by current technologies due to their high complexity and power consumption. We overcame the limitation by exploiting the data redundancy of memory hierarchy. For example, cache coherence states and several layers of cache organization naturally expose the existence of redundancy within cache blocks. If blocks have redundant copies, their V CCMIN can be lowered; although more faults can occur in the blocks, they can be efficiently detected by simple error detection codes and recovered by reloading the redundant copies. Our scheme requires only minor modifications to the existing cache design. We verified our proposal on a cycle accurate simulator with SPLASH-2 and PARSEC benchmark suites and found that the V CCMIN of a 2MB L2 cache can be further lowered by 0.1V in 32nm technology with negligible degradation in performance. As a result, we could achieve 15.6% of reduction in dynamic power and 15.4% of reduction in static power compared to the previous minimum power.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2185403945",
    "type": "article"
  },
  {
    "title": "Offline Washing Schemes for Residue Removal in Digital Microfluidic Biochips",
    "doi": "https://doi.org/10.1145/2798726",
    "publication_date": "2015-12-02",
    "publication_year": 2015,
    "authors": "Debasis Mitra; Sarmishtha Ghoshal; Hafizur Rahaman; Krishnendu Chakrabarty; Bhargab B. Bhattacharya",
    "corresponding_authors": "",
    "abstract": "A digital microfluidic biochip (DMB) is often deployed for multiplexing several assays in space and in time. The residue left by one assay may contaminate the droplets used for subsequent assays. Biochemical assays involving cell culture and those based on particle microfluidics also require sweeping of residual media from an active droplet on-chip. Thus, fluidic operations such as washing or residue removal need to be performed routinely either to clean contamination from the droplet pathways or to rinse off certain droplets on the chip. In this work, several graph-based techniques are presented for offline washing of biochips that may have either a regular geometry (e.g., a 2D array of electrodes), or an irregular geometry (e.g., an application-specific layout). The schemes can be used for total washing, that is, for cleaning the entire biochip or for selective washing of sites or pathways located sparsely on the chip. The problem of reducing the path length and washing time of the droplets is investigated with or without capacity constraints. The proposed algorithms for offline washing make use of several techniques such as graph traversal, integer linear programming (ILP) modeling, and customized heuristics based on the nature of the geometric distribution of the contamination profile. The contaminated pathways are assumed to be Manhattan or curved, and hence the techniques are applicable to the conventional field-actuated DMBs as well as to the emerging classes of light-actuated and active-matrix DMBs. These techniques will be useful in enhancing the reliability of a wide class of emerging digital microfluidic healthcare devices",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2192515946",
    "type": "article"
  },
  {
    "title": "Scheduling Globally Asynchronous Locally Synchronous Programs for Guaranteed Response Times",
    "doi": "https://doi.org/10.1145/2740961",
    "publication_date": "2015-06-24",
    "publication_year": 2015,
    "authors": "Heejong Park; Avinash Malik; Zoran Salčić",
    "corresponding_authors": "",
    "abstract": "Safety-critical software systems need to guarantee functional correctness and bounded response times to external input events. Programs designed using reactive programming languages, based on formal mathematical semantics, can be automatically verified for functional correctness guarantees. Real-time guarantees on the other hand are much harder to achieve. In this article we provide a static analysis framework for guaranteeing response times for reactive programs developed using the Globally Asynchronous Locally Synchronous (GALS) model of computation. The proposed approach is applicable to scheduling of GALS programs for different target architectures with single or multiple processors or cores. A Satisfiability Modulo Theory (SMT) formulation in the quantifier free linear real arithmetic (QF_LRA) logic is used for scheduling. A novel technique to encode rendezvous used in synchronization of globally asynchronous processes in the presence of locally synchronous parallelism and arbitrary preemption into QF_LRA logic is presented. Finally, our SMT formulation is shown to produce schedules in reasonable time.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2251243674",
    "type": "article"
  },
  {
    "title": "Ax-BxP: Approximate Blocked Computation for Precision-reconfigurable Deep Neural Network Acceleration",
    "doi": "https://doi.org/10.1145/3492733",
    "publication_date": "2022-01-28",
    "publication_year": 2022,
    "authors": "R. Elangovan; Shubham Jain; Anand Raghunathan",
    "corresponding_authors": "",
    "abstract": "Precision scaling has emerged as a popular technique to optimize the compute and storage requirements of Deep Neural Networks (DNNs). Efforts toward creating ultra-low-precision (sub-8-bit) DNNs for efficient inference suggest that the minimum precision required to achieve a given network-level accuracy varies considerably across networks, and even across layers within a network. This translates to a need to support variable precision computation in DNN hardware. Previous proposals for precision-reconfigurable hardware, such as bit-serial architectures, incur high overheads, significantly diminishing the benefits of lower precision. We propose Ax-BxP, a method for approximate blocked computation wherein each multiply-accumulate operation is performed block-wise (a block is a group of bits), facilitating re-configurability at the granularity of blocks. Further, approximations are introduced by only performing a subset of the required block-wise computations to realize precision re-configurability with high efficiency. We design a DNN accelerator that embodies approximate blocked computation and propose a method to determine a suitable approximation configuration for any given DNN. For the AlexNet, ResNet50, and MobileNetV2 DNNs, Ax-BxP achieves improvement in system energy and performance, respectively, over an 8-bit fixed-point (FxP8) baseline, with minimal loss (&lt;1% on average) in classification accuracy. Further, by varying the approximation configurations at a finer granularity across layers and data-structures within a DNN, we achieve improvement in system energy and performance, respectively.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W3108338285",
    "type": "article"
  },
  {
    "title": "Encoder-Decoder Networks for Analyzing Thermal and Power Delivery Networks",
    "doi": "https://doi.org/10.1145/3526115",
    "publication_date": "2022-03-28",
    "publication_year": 2022,
    "authors": "Vidya A. Chhabria; Vipul Ahuja; Ashwath Prabhu; Nikhil A. Patil; Palkesh Jain; Sachin S. Sapatnekar",
    "corresponding_authors": "",
    "abstract": "Power delivery network (PDN) analysis and thermal analysis are computationally expensive tasks that are essential for successful integrated circuit (IC) design. Algorithmically, both these analyses have similar computational structure and complexity as they involve the solution to a partial differential equation of the same form. This article converts these analyses into image-to-image and sequence-to-sequence translation tasks, which allows leveraging a class of machine learning models with an encoder-decoder–based generative (EDGe) architecture to address the time-intensive nature of these tasks. For PDN analysis, we propose two networks: (i) IREDGe: a full-chip static and dynamic IR drop predictor and (ii) EMEDGe: electromigration (EM) hotspot classifier based on input power, power grid distribution, and power pad distribution patterns. For thermal analysis, we propose ThermEDGe, a full-chip static and dynamic temperature estimator based on input power distribution patterns for thermal analysis. These networks are transferable across designs synthesized within the same technology and packing solution. The networks predict on-chip IR drop, EM hotspot locations, and temperature in milliseconds with negligibly small errors against commercial tools requiring several hours.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W3210851702",
    "type": "article"
  },
  {
    "title": "MVP: An Efficient CNN Accelerator with Matrix, Vector, and Processing-Near-Memory Units",
    "doi": "https://doi.org/10.1145/3497745",
    "publication_date": "2022-02-24",
    "publication_year": 2022,
    "authors": "Sunjung Lee; Jaewan Choi; Wonkyung Jung; Byeongho Kim; Jaehyun Park; Hweesoo Kim; Jung Ho Ahn",
    "corresponding_authors": "",
    "abstract": "Mobile and edge devices become common platforms for inferring convolutional neural networks (CNNs) due to superior privacy and service quality. To reduce the computational costs of convolution (CONV) , recent CNN models adopt depth-wise CONV (DW-CONV) and Squeeze-and-Excitation (SE) . However, existing area-efficient CNN accelerators are sub-optimal for these latest CNN models because they were mainly optimized for compute-intensive standard CONV layers with abundant data reuse that can be pipelined with activation and normalization operations. In contrast, DW-CONV and SE are memory-intensive with limited data reuse. The latter also strongly depends on the nearby CONV layers, making an effective pipelining a daunting task. Therefore, DW-CONV and SE only occupy 10% of entire operations but become memory bandwidth bound, spending more than 60% of the processing time in systolic-array-based accelerators. We propose a CNN acceleration architecture called MVP, which efficiently processes both compute- and memory-intensive operations with a small area overhead on top of the baseline systolic-array-based architecture. We suggest a specialized vector unit tailored for processing DW-CONV, including multipliers, adder trees, and multi-banked buffers to meet the high memory bandwidth requirement. We augment the unified buffer with tiny processing elements to smoothly pipeline SE with the subsequent CONV, enabling concurrent processing of DW-CONV with standard CONV, thereby achieving the maximum utilization of arithmetic units. Our evaluation shows that MVP improves performance by 2.6 \\( \\times \\) and reduces energy by 47% on average for EfficientNet-B0/B4/B7, MnasNet, and MobileNet-V1/V2 with only a 9% area overhead compared to the baseline.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4213419979",
    "type": "article"
  },
  {
    "title": "Energy-Efficient LSTM Inference Accelerator for Real-Time Causal Prediction",
    "doi": "https://doi.org/10.1145/3495006",
    "publication_date": "2022-02-24",
    "publication_year": 2022,
    "authors": "Zhe Chen; Hugh T. Blair; Jason Cong",
    "corresponding_authors": "",
    "abstract": "Ever-growing edge applications often require short processing latency and high energy efficiency to meet strict timing and power budget. In this work, we propose that the compact long short-term memory (LSTM) model can approximate conventional acausal algorithms with reduced latency and improved efficiency for real-time causal prediction, especially for the neural signal processing in closed-loop feedback applications. We design an LSTM inference accelerator by taking advantage of the fine-grained parallelism and pipelined feedforward and recurrent updates. We also propose a bit-sparse quantization method that can reduce the circuit area and power consumption by replacing the multipliers with the bit-shift operators. We explore different combinations of pruning and quantization methods for energy-efficient LSTM inference on datasets collected from the electroencephalogram (EEG) and calcium image processing applications. Evaluation results show that our proposed LSTM inference accelerator can achieve 1.19 GOPS/mW energy efficiency. The LSTM accelerator with 2-sbit/16-bit sparse quantization and 60% sparsity can reduce the circuit area and power consumption by 54.1% and 56.3%, respectively, compared with a 16-bit baseline implementation.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4213420788",
    "type": "article"
  },
  {
    "title": "Degraded Mode-benefited I/O Scheduling to Ensure I/O Responsiveness in RAID-enabled SSDs",
    "doi": "https://doi.org/10.1145/3522755",
    "publication_date": "2022-03-10",
    "publication_year": 2022,
    "authors": "Zhibing Sha; Jun Li; Zhigang Cai; Min Huang; Jianwei Liao; François Trahay",
    "corresponding_authors": "",
    "abstract": "RAID-enabled SSDs commonly have unbalanced I/O workloads on their components (e.g., SSD channels), as the data/parity chunks in the same stripe may have varied access frequency, which greatly impacts I/O responsiveness. This article proposes a I/O scheduling scheme by resorting to the degraded read mode and the read-modify-write mode to reduce the long-tail latency of I/O requests in RAID-enabled SSDs. The basic idea is to avoid scheduling read or update requests to the heavily congested but targeted RAID components. Such requests are satisfied by accessing other relevant RAID components by certain XOR computations (we call the degraded modes ). Specially, we build a queuing overhead assessment model on the top of factors of data redundancy and the current blocked I/O traffics on SSD channels to precisely dispatch incoming I/O requests to be fulfilled with the degraded mode or not. The trace-driven experiments illustrate that the proposed scheme can reduce the long-tail latency of read requests by 23.1% on average at the 99.99th percentile, in contrast to state-of-the-art scheduling methods.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4220810936",
    "type": "article"
  },
  {
    "title": "Memory-Throughput Trade-off for CNN-Based Applications at the Edge",
    "doi": "https://doi.org/10.1145/3527457",
    "publication_date": "2022-03-28",
    "publication_year": 2022,
    "authors": "Svetlana Minakova; Todor Stefanov",
    "corresponding_authors": "",
    "abstract": "Many modern applications require execution of Convolutional Neural Networks (CNNs) on edge devices, such as mobile phones or embedded platforms. This can be challenging, as the state-of-the art CNNs are memory costly, whereas the memory budget of edge devices is highly limited. To address this challenge, a variety of CNN memory reduction methodologies have been proposed. Typically, the memory of a CNN is reduced using methodologies such as pruning and quantization. These methodologies reduce the number or precision of CNN parameters, thereby reducing the CNN memory cost. When more aggressive CNN memory reduction is required, the pruning and quantization methodologies can be combined with CNN memory reuse methodologies. The latter methodologies reuse device memory allocated for storage of CNN intermediate computational results, thereby further reducing the CNN memory cost. However, the existing memory reuse methodologies are unfit for CNN-based applications that exploit pipeline parallelism available within the CNNs or use multiple CNNs to perform their functionality. In this article, we therefore propose a novel CNN memory reuse methodology. In our methodology, we significantly extend and combine two existing CNN memory reuse methodologies to offer efficient memory reuse for a wide range of CNN-based applications.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4220816781",
    "type": "article"
  },
  {
    "title": "Magnetic Core TSV-Inductor Design and Optimization for On-chip DC-DC Converter",
    "doi": "https://doi.org/10.1145/3507700",
    "publication_date": "2022-03-07",
    "publication_year": 2022,
    "authors": "Chenyi Wen; Xiao Dong; Baixin Chen; Umamaheswara Rao Tida; Yiyu Shi; Cheng Zhuo",
    "corresponding_authors": "",
    "abstract": "The conventional on-chip spiral inductor consumes a significant top-metal routing area, thereby preventing its popularity in many on-chip applications. Recently through-silicon-via– (TSV) based inductor (also known as a TSV-inductor) with a magnetic core has been proved to be a viable option for the on-chip DC-DC converter. The operating conditions of these inductors play a major role in maximizing the performance and efficiency of the DC-DC converter. However, there is a critical need to study the design and optimization details of magnetic core TSV-inductors with the unique three-dimensional structure embedding magnetic core. This article aims to provide a clear understanding of the modeling details of a magnetic core TSV-inductor and a design and optimization methodology to assist efficient inductor design. Moreover, a machine learning–assisted model combining physical details and artificial neural network is also proposed to extract the equivalent circuit to further facilitate DC-DC converter design. Experimental results show that the optimized TSV-inductor with the magnetic core and air-gap can achieve inductance density improvement of up to 7.7 \\( \\times \\) and quality factor improvements of up to 1.6 \\( \\times \\) for the same footprint compared with the TSV-inductor without a magnetic core. For on-chip DC-DC converter applications, the converter efficiency can be improved by up to 15.9% and 6.8% compared with the conventional spiral and TSV-inductor without magnetic core, respectively.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4220952239",
    "type": "article"
  },
  {
    "title": "A Low-power Programmable Machine Learning Hardware Accelerator Design for Intelligent Edge Devices",
    "doi": "https://doi.org/10.1145/3531479",
    "publication_date": "2022-04-22",
    "publication_year": 2022,
    "authors": "Minkwan Kee; Gi-Ho Park",
    "corresponding_authors": "",
    "abstract": "With the advent of the machine learning and IoT, many low-power edge devices, such as wearable devices with various sensors, are used for machine learning–based intelligent applications, such as healthcare or motion recognition. While these applications are becoming more complex to provide high-quality services, the performance of conventional low-power edge devices with extremely limited hardware resources is insufficient to support the emerging intelligent applications. We designed a hardware accelerator, called an Intelligence Boost Engine (IBE), for low-power smart edge devices to enable the real-time processing of emerging intelligent applications with energy efficiency and limited programmability. The measurement results confirm that the proposed IBE can reduce the power consumption of the edge node device by 75% and achieve performance improvement in processing the kernel operations of applications such as motion recognition by 69.9 times.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4224295625",
    "type": "article"
  },
  {
    "title": "DRAGON: Dynamic Recurrent Accelerator for Graph Online Convolution",
    "doi": "https://doi.org/10.1145/3524124",
    "publication_date": "2022-05-23",
    "publication_year": 2022,
    "authors": "José Romero Hung; Chao Li; Taolei Wang; Jinyang Guo; Pengyu Wang; Chuanming Shao; Jing Wang; Guoyong Shi; Xiangwen Liu; Hanqing Wu",
    "corresponding_authors": "",
    "abstract": "Despite the extraordinary applicative potentiality that dynamic graph inference may entail, its practical-physical implementation has been a topic seldom explored in literature. Although graph inference through neural networks has received plenty of algorithmic innovation, its transfer to the physical world has not found similar development. This is understandable since the most preeminent Euclidean acceleration techniques from CNN have little implication in the non-Euclidean nature of relational graphs. Instead of coping with the challenges arising from forcing naturally sparse structures into more inflexible stochastic arrangements, in DRAGON, we embrace this characteristic in order to promote acceleration. Inspired by high-performance computing approaches like Parallel Multi-moth Flame Optimization for Link Prediction (PMFO-LP), we propose and implement a novel efficient architecture, capable of producing similar speed-up and performance than baseline but at a fraction of its hardware requirements and power consumption. We leverage the hidden parallelistic capacity of our previously developed static graph convolutional processor ACE-GCN and expanded it with RNN structures, allowing the deployment of a multi-processing network referenced around a common pool of proximity-based centroids. Experimental results demonstrate outstanding acceleration. In comparison with the fastest CPU-based software implementation available in the literature, DRAGON has achieved roughly 191× speed-up. Under the largest configuration and dataset, DRAGON was also able to overtake a more power-hungry PMFO-LP by almost 1.59× in speed, and at around 89.59% in power efficiency. More importantly than raw acceleration, we demonstrate the unique functional qualities of our approach as a flexible and fault-tolerant solution that makes it an interesting alternative for an anthology of applicative scenarios.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4281391768",
    "type": "article"
  },
  {
    "title": "Machine-learning-driven Architectural Selection of Adders and Multipliers in Logic Synthesis",
    "doi": "https://doi.org/10.1145/3560712",
    "publication_date": "2022-09-06",
    "publication_year": 2022,
    "authors": "Jiawen Cheng; Yong Xiao; Yun Shao; Guanghai Dong; Songlin Lyu; Wenjian Yu",
    "corresponding_authors": "",
    "abstract": "Designing high-performance adders and multiplier components for diverse specifications and constraints is of practical concern. However, selecting the best architecture for adder or multiplier, which largely affects the performance of synthesized circuits, is difficult. To tackle this difficulty, a machine-learning-driven approach is proposed for automatic architectural selection of adders and multipliers. It trains a machine learning model for classification through learning a number of existing design schemes and their performance data. Experimental results show that the proposed approach based on a multi-perception neural network achieves as high as 94% prediction accuracy with negligible inference time. On a CPU server, the proposed approach runs about 4× faster than a brute-force approach trying four candidate architectures and consumes 10%~20% less runtime than the DesignWare datapath generator for obtaining the optimal adder/multiplier circuit. The adder (multiplier) generated with the proposed approach achieves performance metrics close to the optimal and has 1.6% (5.2%) less area and 2.2% (7.1%) more worst negative slack averagely than that generated with the DesignWare datapath generator. Our experiment also shows that the proposed approach is not sensitive to the size of training subset.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4294733776",
    "type": "article"
  },
  {
    "title": "Worst-case Power Integrity Prediction Using Convolutional Neural Network",
    "doi": "https://doi.org/10.1145/3564932",
    "publication_date": "2022-10-03",
    "publication_year": 2022,
    "authors": "Xiao Dong; Yufei Chen; Jun Chen; Yu-Cheng Wang; Ji Li; Tianming Ni; Zhiguo Shi; Xunzhao Yin; Cheng Zhuo",
    "corresponding_authors": "",
    "abstract": "Power integrity analysis is an essential step in power distribution network (PDN) sign-off to ensure the performance and reliability of chips. However, with the growing PDN size and increasing scenarios to be validated, it becomes very time- and resource-consuming to conduct full-stack PDN simulation to check the power integrity for different test vectors. Recently, various works have proposed machine learning–based methods for PDN power integrity prediction, many of which still suffer from large training overhead, inefficiency, or non-scalability. Thus, this article proposed an efficient and scalable framework for the worst-case power integrity prediction, which can handle general tasks including dynamic noise prediction and bump current prediction. The framework first reduces the spatial and temporal redundancy in the PDN and input current vector and then employs efficient feature extraction as well as a novel convolutional neural network architecture to predict the worst-case power integrity. Experimental results show that the proposed framework consistently outperforms the commercial tool and the state-of-the-art machine learning method with only 0.63–1.02% mean relative error and 25–69× speedup for noise prediction and 0.22–1.06% mean relative error and 24–64× speedup for bump current prediction.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4300865726",
    "type": "article"
  },
  {
    "title": "Accelerating Graph Computations on 3D NoC-Enabled PIM Architectures",
    "doi": "https://doi.org/10.1145/3564290",
    "publication_date": "2022-10-07",
    "publication_year": 2022,
    "authors": "Dwaipayan Choudhury; Lizhi Xiang; Aravind Sukumaran-Rajam; Ananth Kalyanaraman; Partha Pratim Pande",
    "corresponding_authors": "",
    "abstract": "Graph application workloads are dominated by random memory accesses with the poor locality. To tackle the irregular and sparse nature of computation, ReRAM-based Processing-in-Memory (PIM) architectures have been proposed recently. Most of these ReRAM architecture designs have focused on mapping graph computations into a set of multiply-and-accumulate (MAC) operations. ReRAMs also offer a key advantage in reducing memory latency between cores and memory by allowing for PIM. However, when implemented on a ReRAM-based manycore architecture, graph applications still pose two key challenges—significant storage requirements (particularly due to wasted zero cell storage), and significant amount of on-chip traffic. To tackle these two challenges, in this article, we propose the design of a 3D NoC-enabled ReRAM-based manycore architecture. Our proposed architecture incorporates a novel crossbar-aware node reordering to reduce ReRAM storage requirements. Secondly, its 3D NoC-enabled design reduces on-chip communication latency. Our architecture outperforms the state-of-the-art in ReRAM-based graph acceleration by up to 5× in performance while consuming up to 10.3× less energy for a range of graph inputs and workloads.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4303427201",
    "type": "article"
  },
  {
    "title": "A Deep Learning Framework for Solving Stress-based Partial Differential Equations in Electromigration Analysis",
    "doi": "https://doi.org/10.1145/3567424",
    "publication_date": "2022-10-10",
    "publication_year": 2022,
    "authors": "Tianshu Hou; Peining Zhen; Zhigang Ji; Hai‐Bao Chen",
    "corresponding_authors": "",
    "abstract": "The electromigration-induced reliability issues (EM) in very large scale integration (VLSI) circuits have attracted continuous attention due to technology scaling. Traditional EM methods lead to inaccurate results incompatible with the advanced technology nodes. In this article, we propose a learning-based model by enforcing physical constraints of EM kinetics to solve the EM reliability problem. The method aims at solving stress-based partial differential equations (PDEs) to obtain the hydrostatic stress evolution on interconnect trees during the void nucleation phase, considering varying atom diffusivity on each segment, which is one of the EM random characteristics. The approach proposes a crafted neural network-based framework customized for the EM phenomenon and provides mesh-free solutions benefiting from the employment of automatic differentiation (AD). Experimental results obtained by the proposed model are compared with solutions obtained by competing methods, showing satisfactory accuracy and computational savings.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4304147710",
    "type": "article"
  },
  {
    "title": "Learning-based Phase-aware Multi-core CPU Workload Forecasting",
    "doi": "https://doi.org/10.1145/3564929",
    "publication_date": "2022-10-26",
    "publication_year": 2022,
    "authors": "E. Lozano; Andreas Gerstlauer",
    "corresponding_authors": "",
    "abstract": "Predicting workload behavior during workload execution is essential for dynamic resource optimization in multi-processor systems. Recent studies have proposed advanced machine learning techniques for dynamic workload prediction. Workload prediction can be cast as a time series forecasting problem. However, traditional forecasting models struggle to predict abrupt workload changes. These changes occur because workloads are known to go through phases. Prior work has investigated machine-learning-based approaches for phase detection and prediction, but such approaches have not been studied in the context of dynamic workload forecasting. In this article, we propose phase-aware CPU workload forecasting as a novel approach that applies long-term phase prediction to improve the accuracy of short-term workload forecasting. Phase-aware forecasting requires machine learning models for phase classification, phase prediction, and phase-based forecasting that have not been explored in this combination before. Furthermore, existing prediction approaches have only been studied in single-core settings. This work explores phase-aware workload forecasting with multi-threaded workloads running on multi-core systems. We propose different multi-core settings differentiated by the number of cores they access and whether they produce specialized or global outputs per core. We study various advanced machine learning models for phase classification, phase prediction, and phase-based forecasting in isolation and different combinations for each setting. We apply our approach to forecasting of multi-threaded Parsec and SPEC workloads running on an eight-core Intel Core-i9 platform. Our results show that combining GMM clustering with LSTMs for phase prediction and phase-based forecasting yields the best phase-aware forecasting results. An approach that uses specialized models per core achieves an average error of 23% with up to 22% improvement in prediction accuracy compared to a phase-unaware setup.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4307561137",
    "type": "article"
  },
  {
    "title": "Hardware-aware Quantization/Mapping Strategies for Compute-in-Memory Accelerators",
    "doi": "https://doi.org/10.1145/3569940",
    "publication_date": "2022-10-28",
    "publication_year": 2022,
    "authors": "Shanshi Huang; Hongwu Jiang; Shimeng Yu",
    "corresponding_authors": "",
    "abstract": "The emerging non-volatile memory (eNVM) based mixed-signal Compute-in-Memory (CIM) accelerators are of great interest in today's AI accelerators design due to their high energy efficiency. Various CIM architectures and circuit-level designs have been proposed, showing superior hardware performance for deep neural network (DNN) acceleration. However, hardware-aware quantization strategies for CIM-based accelerators are not systematically explored. Since there are a variety of design options for neural network mapping on CIM systems while improper strategies may narrow the circuit-level design space and further limit the hardware performance, it is important to make a comprehensive early-stage design space exploration and find appropriate quantization/mapping strategies to achieve better hardware performance. In this paper, we provide a joint algorithm-hardware analysis and compare the system-level hardware performance for various design options, including quantization algorithms, data representation methods and analog-to-digital converter (ADC) configurations. This work aims to propose guidelines for choosing more hardware-friendly design options for chip architects. According to our evaluation results for CIFAR-10/100 and ImageNet classification, the properly chosen quantization approach and optimal mapping strategy (dynamic fixed-point quantization + 2’s complement representation/shifted unsigned INT representation + optimized precision ADC) could achieve ∼2 × energy efficiency and 1.2 ∼ 1.6 × throughput with 5%∼25% reduced area overhead, compared to naïve strategy (fixed-point quantization + differential pair number representation + full precision ADC).",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4307927141",
    "type": "article"
  },
  {
    "title": "Mixed Integer Programming based Placement Refinement by RSMT Model with Movable Pins",
    "doi": "https://doi.org/10.1145/3639365",
    "publication_date": "2024-01-03",
    "publication_year": 2024,
    "authors": "Ke Tang; Lang Feng; Zhongfeng Wang",
    "corresponding_authors": "",
    "abstract": "Placement is a critical step in the physical design for digital application specific integrated circuits (ASICs), as it can directly affect the design qualities such as wirelength and timing. For many domain specific designs, the demands for high performance parallel computing result in repetitive hardware instances, such as the processing elements in the neural network accelerators. As these instances can dominate the area of the designs, the runtime of the complete design’s placement can be traded for optimizing and reusing one instance’s placement to achieve higher quality. Therefore, this work proposes a mixed integer programming (MIP)-based placement refinement algorithm for the repetitive instances. By efficiently modeling the rectilinear steiner tree wirelength, the placement can be precisely refined for better quality. Besides, the MIP formulations for timing-driven placement are proposed. A theoretical proof is then provided to show the correctness of the proposed wirelength model. For the instances in various popular fields, the experiments show that given the placement from the commercial placers, the proposed algorithm can perform further placement refinement to reduce 3.76%/3.64% detailed routing wirelength and 1.68%/2.42% critical path delay under wirelength/timing-driven mode, respectively, and also outperforms the state-of-the-art previous work.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4390547764",
    "type": "article"
  },
  {
    "title": "Detecting Adversarial Examples Utilizing Pixel Value Diversity",
    "doi": "https://doi.org/10.1145/3636460",
    "publication_date": "2024-01-16",
    "publication_year": 2024,
    "authors": "Jinxin Dong; Pingqiang Zhou",
    "corresponding_authors": "",
    "abstract": "In this article, we introduce two novel methods to detect adversarial examples utilizing pixel value diversity. First, we propose the concept of pixel value diversity (which reflects the spread of pixel values in an image) and two independent metrics (UPVR and RPVR) to assess the pixel value diversity separately. Then we propose two methods to detect adversarial examples based on the threshold method and Bayesian method respectively. Experimental results show that compared to an excellent prior method LID, our proposed methods achieve better performances in detecting adversarial examples. We also show the robustness of our proposed work against an adaptive attack method.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4390911165",
    "type": "article"
  },
  {
    "title": "Optimizing VLIW Instruction Scheduling via a Two-Dimensional Constrained Dynamic Programming",
    "doi": "https://doi.org/10.1145/3643135",
    "publication_date": "2024-01-25",
    "publication_year": 2024,
    "authors": "Can Deng; Zhaoyun Chen; Yang Shi; Yimin Ma; Mei Wen; Lei Luo",
    "corresponding_authors": "",
    "abstract": "Typical embedded processors, such as Digital Signal Processors (DSPs), usually adopt Very Long Instruction Word (VLIW) architecture to improve computing efficiency. The performance of VLIW processors heavily relies on Instruction-Level Parallelism (ILP). Therefore, it is crucial to develop an efficient instruction scheduling algorithm to explore more ILP. While heuristic algorithms are widely used in modern compilers due to simple implementation and low computational cost, they have limitations in providing accurate solutions and are prone to local optima. On the other hand, exact algorithms can usually find the optimal solution, but their high time overhead makes them less suitable for large-scale problems. This article proposes a two-dimensional constrained dynamic programming (TDCDP) approach and a quantitative model for instruction scheduling. The TDCDP approach achieves near-optimal solutions within an acceptable time overhead. Furthermore, we integrate our TDCDP approach into mainstream compiler architecture, encompassing Pre- and Post-RA (register allocation) scheduling. We conduct a quantitative evaluation of TDCDP compared with four heuristic algorithms on a typical VLIW processor. Our approach achieves an efficiency improvement of up to 58.34% in final solutions compared with the heuristic algorithms. Additionally, the Post-RA Scheduling enhances programs with an average speedup of 14.04% than solely applying the Pre-RA Scheduling.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4391222297",
    "type": "article"
  },
  {
    "title": "D <sup>3</sup> PBO: <u>D</u> ynamic <u>D</u> omain <u>D</u> ecomposition-based <u>P</u> arallel <u>B</u> ayesian <u>O</u> ptimization for Large-scale Analog Circuit Sizing",
    "doi": "https://doi.org/10.1145/3643811",
    "publication_date": "2024-01-31",
    "publication_year": 2024,
    "authors": "Aidong Zhao; Tianchen Gu; Zhaori Bi; Fan Yang; Changhao Yan; Xuan Zeng; Zixiao Lin; Walter Hu; Dian Zhou",
    "corresponding_authors": "",
    "abstract": "Bayesian optimization (BO) is an efficient global optimization method for expensive black-box functions, but the expansion for high-dimensional problems and large sample budgets still remains a severe challenge. In order to extend BO for large-scale analog circuit synthesis, a novel computationally efficient parallel BO method, D 3 PBO, is proposed for high-dimensional problems in this work. We introduce the dynamic domain decomposition method based on maximum variance between clusters. The search space is decomposed into subdomains progressively to limit the maximal number of observations in each domain. The promising domain is explored by multi-trust region-based batch BO with the local Gaussian process (GP) model. As the domain decomposition progresses, the basin-shaped domain is identified using a GP-assisted quadratic regression method and exploited by the local search method BOBYQA to achieve a faster convergence rate. The time complexity of D 3 PBO is constant for each iteration. Experiments demonstrate that D 3 PBO obtains better results with significantly less runtime consumption compared to state-of-the-art methods. For the circuit optimization experiments, D 3 PBO achieves up to 10× runtime speedup compared to TuRBO with better solutions.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4391402589",
    "type": "article"
  },
  {
    "title": "An Efficient FPGA Architecture with Turn-Restricted Switch Boxes",
    "doi": "https://doi.org/10.1145/3643809",
    "publication_date": "2024-02-03",
    "publication_year": 2024,
    "authors": "Fatemeh Serajeh Hassani; Mohammad Sadrosadati; Nezam Rohbani; Sebastian Pointner; Robert Wille; Hamid Sarbazi‐Azad",
    "corresponding_authors": "",
    "abstract": "Abstract. Field-Programmable Gate Arrays (FPGAs) employ a large number of SRAM cells to provide a flexible routing architecture which have a significant impact on the FPGA’s area and power consumption. This flexible routing allows for a rather easy realization of the desired functionality, but our evaluations show that the full routing flexibility is not required in many occasions. In this work, we focus on what is actually needed and introduce a new switch-box realization what we call Turn-Restricted Switch-Boxes which supports only a subset of possible turns. The proposed method increases the utilization rate of FPGA switch-boxes by eliminating the unemployed resources. Experimental evaluations confirm that the area and average power consumption can be reduced by 12.8% and 14.1%, on average, respectively and the FPGA routing susceptibility to SEU and MBU can be improved by 18.2%, on average, by imposing negligible performance. 1",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4391514743",
    "type": "article"
  },
  {
    "title": "IDeSyDe: Systematic Design Space Exploration via Design Space Identification",
    "doi": "https://doi.org/10.1145/3647640",
    "publication_date": "2024-02-10",
    "publication_year": 2024,
    "authors": "Rodolfo Jordão; Matthias Becker; Ingo Sander",
    "corresponding_authors": "",
    "abstract": "Design space exploration (DSE) is a key activity in embedded design processes, where a mapping between applications and platforms that meets the process design requirements must be found. Finding such mappings is very challenging due to the complexity of modern embedded platforms and applications. DSE tools aid in this challenge by potentially covering sections of the design space that could be unintuitive to designers, leading to more optimised designs. Despite this potential benefit, DSE tools remain relatively niche in the embedded industry. A significant obstacle hindering their wider adoption is integrating such tools into embedded design processes. We present two contributions that address this integration issue. First, we present the design space identification (DSI) approach for systematically constructing DSE solutions that are modular and tuneable. Modularity means that DSE solutions can be reused to construct other DSE solutions, while tuneability means that the most specific DSE solution is chosen for the target DSE problem. Moreover, DSI enables transparent cooperation between exploration algorithms. Second, we present IDeSyDe, an extensible DSE framework for DSE solutions based on DSI. IDeSyDe allows extensions to be developed in different programming languages in a manner compliant with the DSI approach. We showcase the relevance of these contributions through five different case studies. The case study evaluations showed that non-exploration DSI procedures create overheads, which are marginal compared to the exploration algorithms. Empirically, most evaluations average 2% of the total DSE request. More importantly, the case studies have shown that IDeSyDe indeed provides a modular and incremental framework for constructing DSE solutions. In particular, the last case study required minimal extensions over the previous case studies so that support for a new application type was added to IDeSyDe.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4391719079",
    "type": "article"
  },
  {
    "title": "Two-dimensional Search Space for Extracting Broadside Tests from Functional Test Sequences",
    "doi": "https://doi.org/10.1145/3650207",
    "publication_date": "2024-03-02",
    "publication_year": 2024,
    "authors": "Irith Pomeranz",
    "corresponding_authors": "Irith Pomeranz",
    "abstract": "Testing for delay faults after chip manufacturing is critical to correct chip operation. Tests for delay faults are applied using scan chains that provide access to internal memory elements. As a result, a circuit may operate under non-functional operation conditions during test application. This may lead to overtesting. The extraction of broadside tests from functional test sequences ensures that the tests create functional operation conditions. When N functional test sequences of length L +1 are available, the number of broadside tests that can be extracted is N · L . Depending on the source of the functional test sequences, the value of N · L may be large. In this case, it is important to select a subset of n ≤ N sequences and consider only the first l ≤ L clock cycles of every sequence for the extraction of n · l ≪ N · L broadside tests. The two-dimensional N × L search space for broadside tests is the subject of this article. Using a static procedure that considers fixed values of N and l , the article demonstrates that, for the same value of N · L , different circuits benefit from different values of N and l . It also describes a dynamic procedure that matches the parameters N and l to the circuit. The discussion is supported by experimental results for transition faults in benchmark circuits.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4392347992",
    "type": "article"
  },
  {
    "title": "Comparative Analysis of Dynamic Power Consumption of Parallel Prefix Adder",
    "doi": "https://doi.org/10.1145/3651984",
    "publication_date": "2024-03-11",
    "publication_year": 2024,
    "authors": "Ireneusz Brzozowski",
    "corresponding_authors": "Ireneusz Brzozowski",
    "abstract": "The Newcomb-Benford law, also known as Benford's law, is the law of anomalous numbers stating that in many real-life numerical datasets, including physical and statistical ones, numbers have a small initial digit. Numbers irregularity observed in nature leads to the question, is the arithmetical-logical unit, responsible for performing calculations in computers, optimal? Are there other architectures, not as regular as commonly used Parallel Prefix Adders, that can perform better, especially when operating on the datasets that are not purely random, but irregular? In this article, structures of a propagate-generate tree are compared including regular and irregular configurations—various structures are examined: regular, irregular, with gray cells only, with both gray and black, and with higher valency cells. Performance is evaluated in terms of energy consumption. The evaluation was performed using the extended power model of static CMOS gates. The model is based on changes of vectors, naturally taking into account spatio-temporal correlations. The energy parameters of the designed cells were calculated on the basis of electrical (Spice) simulation. Designs and simulations were done in the Cadence environment and calculations of the power dissipation were performed in MATLAB. The results clearly show that there are PPA structures that perform much better for a specific type of numerical data. Negligent design can lead to an increase greater than two times of power consumption. The novel architectures of PPA described in this work might find practical applications in specialized adders dealing with numerical datasets, such as, for example, sine functions commonly used in digital signal processing.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4392645486",
    "type": "article"
  },
  {
    "title": "Floorplanning with Edge-Aware Graph Attention Network and Hindsight Experience Replay",
    "doi": "https://doi.org/10.1145/3653453",
    "publication_date": "2024-03-22",
    "publication_year": 2024,
    "authors": "Bo Yang; Qi Xu; Hao Geng; Song Chen; Bei Yu; Yi Kang",
    "corresponding_authors": "",
    "abstract": "In this article, we focus on chip floorplanning, which aims to determine the location and orientation of circuit macros simultaneously, so the chip area and wirelength are minimized. As the highest level of abstraction in hierarchical physical design, floorplanning bridges the gap between the system-level design and the physical synthesis, whose quality directly influences downstream placement and routing. To tackle chip floorplanning, we propose an end-to-end reinforcement learning (RL) methodology with a hindsight experience replay technique. An edge-aware graph attention network (EAGAT) is developed to effectively encode the macro and connection features of the netlist graph. Moreover, we build a hierarchical decoder architecture mainly consisting of transformer and attention pointer mechanism to output floorplan actions. Since the RL agent automatically extracts knowledge about the solution space, the previously learned policy can be quickly transferred to optimize new unseen netlists. Experimental results demonstrate that, compared with state-of-the-art floorplanners, the proposed end-to-end methodology significantly optimizes area and wirelength on public GSRC and MCNC benchmarks.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4393085383",
    "type": "article"
  },
  {
    "title": "SEDONUT: A Single Event Double Node Upset Tolerant SRAM for Terrestrial Applications",
    "doi": "https://doi.org/10.1145/3651985",
    "publication_date": "2024-04-06",
    "publication_year": 2024,
    "authors": "Govind Prasad; Bipin Chandra Mandi; Maifuz Ali",
    "corresponding_authors": "",
    "abstract": "Radiation and its effect on neighboring nodes are critical not only for space applications but also for terrestrial applications at modern lower-technology nodes. This may cause static random-access memory (SRAM) failures due to single- and multi-node upset. Hence, this article proposes a 14T radiation-hardened-based SRAM cell to overcome soft errors for space and critical terrestrial applications. Simulation results show that the proposed cell can be resilient to any single event upset and single event double node upset at its storage nodes. This cell uses less power than others. The hold, read, and write stability increases compared with most considered cells. The higher critical charge of the proposed SRAM increases radiation resistance. Simulation results demonstrate that out of all compared SRAMs, only DNUSRM and the proposed SRAM show 0% probability of logical flipping. Also, other parameters such as total critical charge, write stability, read stability, hold stability, area, power, sensitive area, write speed, and read speed of the proposed SRAM are improved by –19.1%, 5.22%, 25.7%, –5.46%, 22.5%, 50.6%, 60.0%, 17.91%, and 0.74% compared with DNUSRM SRAM. Hence, the better balance among the parameters makes the proposed cell more suitable for space and critical terrestrial applications. Finally, the post-layout and Monte Carlo simulation validate the efficiency of SRAMs.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4394013544",
    "type": "article"
  },
  {
    "title": "Modeling Retention Errors of 3D NAND Flash for Optimizing Data Placement",
    "doi": "https://doi.org/10.1145/3659101",
    "publication_date": "2024-04-16",
    "publication_year": 2024,
    "authors": "Huanhuan Tian; Jiewen Tang; Jun Li; Zhibing Sha; Fan Yang; Zhigang Cai; Jianwei Liao",
    "corresponding_authors": "",
    "abstract": "Considering 3D NAND flash has a new property of process variation (PV) , which causes different raw bit error rates (RBER) among different layers of the flash block. This article builds a mathematical model for estimating the retention errors of flash cells, by considering the factor of layer-to-layer PV in 3D NAND flash memory, as well as the factors of program/erase (P/E) cycle and retention time of data. Then, it proposes classifying the layers of flash block in 3D NAND flash memory into profitable and unprofitable categories, according to the error correction overhead. After understanding the retention error variation of different layers in 3D NAND flash, we design a mechanism of data placement, which maps the write data onto a suitable layer of flash block, according to the data hotness and the error correction overhead of layers, to boost read performance of 3D NAND flash. The experimental results demonstrate that our proposed retention error estimation model can yield a R 2 value of 0.966 on average, verifying the accuracy of the model. Based on the estimated retention error rates of layers, the proposed data placement mechanism can noticeably reduce the read latency by 29.8 % on average, compared with state-of-the-art methods against retention errors for 3D NAND flash memory.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4394844171",
    "type": "article"
  },
  {
    "title": "Translating Test Responses to Images for Test-termination Prediction via Multiple Machine Learning Strategies",
    "doi": "https://doi.org/10.1145/3661310",
    "publication_date": "2024-04-25",
    "publication_year": 2024,
    "authors": "Hongfei Wang; Jingyao Li; Jiayi Wang; Zijun Ping; Hongcan Xiong; Wei Liu; Dongmian Zou",
    "corresponding_authors": "",
    "abstract": "Failure diagnosis is a software-based, data-driven procedure. Collecting an excessive amount of fail data not only increases the overall test cost but can also potentially reduce diagnostic resolution. Thus, test-termination prediction is proposed to dynamically determine the appropriate failing test pattern to terminate testing, producing an amount of test data that is sufficient for an accurate diagnosis analysis. In this work, we describe a set of novel methods utilizing advanced machine learning techniques for efficient test-termination prediction. To implement this approach, we first generate images representing failing test responses from failure-log files. These images are then used to train a multi-layer convolutional neural network (CNN) incorporating a residual block. The trained CNN model leverages the images and known diagnostic results to determine the optimal test-termination strategy within the testing process, ensuring efficient and high-quality diagnosis. In addition to the integration of test response-to-image translation, our approach harnesses two cutting-edge learning strategies to enhance fail data and boost performance in subsequent tasks. The first strategy is transfer learning, which utilizes sample-label information from one circuit to guide the decision of whether to continue or stop testing for another circuit lacking labels. The second strategy involves the use of a generative deep model to generate fail data in the form of synthetic images. This technique increases the modeling effectiveness by expanding the volume of training samples. Experimental results conducted on actual failing chips and standard benchmarks validate that our proposed method surpasses existing approaches. Our method creates opportunities to harness the power of recent advances in machine learning for improving test and diagnosis efficiency.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4395479245",
    "type": "article"
  },
  {
    "title": "DeepOTF: Learning Equations-constrained Prediction for Electromagnetic Behavior",
    "doi": "https://doi.org/10.1145/3663476",
    "publication_date": "2024-05-01",
    "publication_year": 2024,
    "authors": "Peng Xu; Siyuan Xu; Tinghuan Chen; Guojin Chen; Tsung-Yi Ho; Bei Yu",
    "corresponding_authors": "",
    "abstract": "High-quality passive devices are becoming increasingly important for the development of mobile devices and telecommunications, but obtaining such devices through simulation and analysis of electromagnetic (EM) behavior is time-consuming. To address this challenge, artificial neural network (ANN) models have emerged as an effective tool for modeling EM behavior, with NeuroTF being a representative example. However, these models are limited by the specific form of the transfer function, leading to discontinuity issues and high sensitivities. Moreover, previous methods have overlooked the physical relationship between distributed parameters, resulting in unacceptable numeric errors in the conversion results. To overcome these limitations, we propose two different neural network architectures: DeepOTF and ComplexTF. DeepOTF is a data-driven deep operator network for automatically learning feasible transfer functions for different geometric parameters. ComplexTF utilizes complex-valued neural networks to fit feasible transfer functions for different geometric parameters in the complex domain while maintaining causality and passivity. Our approach also employs an Equations-constraint Learning scheme to ensure the strict consistency of predictions and a dynamic weighting strategy to balance optimization objectives. The experimental results demonstrate that our framework shows superior performance than baseline methods, achieving up to 1,700× higher accuracy.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4396556569",
    "type": "article"
  },
  {
    "title": "An Open-Source ML-Based Full-Stack Optimization Framework for Machine Learning Accelerators",
    "doi": "https://doi.org/10.1145/3664652",
    "publication_date": "2024-05-11",
    "publication_year": 2024,
    "authors": "Hadi Esmaeilzadeh; Soroush Ghodrati; Andrew B. Kahng; Joon Kyung Kim; Sean Kinzer; Sayak Kundu; Rohan Mahapatra; Susmita Dey Manasi; Sachin S. Sapatnekar; Zhiang Wang; Ziqing Zeng",
    "corresponding_authors": "",
    "abstract": "Parameterizable machine learning (ML) accelerators are the product of recent breakthroughs in ML. To fully enable their design space exploration (DSE), we propose a physical-design-driven, learning-based prediction framework for hardware-accelerated deep neural network (DNN) and non-DNN ML algorithms. It adopts a unified approach that combines power, performance, and area (PPA) analysis with frontend performance simulation, thereby achieving a realistic estimation of both backend PPA and system metrics such as runtime and energy. In addition, our framework includes a fully automated DSE technique, which optimizes backend and system metrics through an automated search of architectural and backend parameters. Experimental studies show that our approach consistently predicts backend PPA and system metrics with an average 7% or less prediction error for the ASIC implementation of two deep learning accelerator platforms, VTA and VeriGOOD-ML, in both a commercial 12 nm process and a research-oriented 45 nm process.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4396834092",
    "type": "article"
  },
  {
    "title": "Applying reinforcement learning to learn best net to rip and re-route in global routing",
    "doi": "https://doi.org/10.1145/3664286",
    "publication_date": "2024-05-16",
    "publication_year": 2024,
    "authors": "Upma Gandhi; Erfan Aghaeekiasaraee; Sahir; Payam Mousavi; Ismail Bustany; Matthew E. Taylor; Laleh Behjat",
    "corresponding_authors": "",
    "abstract": "Physical designers typically employ heuristics to solve challenging problems in global routing. However, these heuristic solutions are not adaptable to the ever-changing fabrication demands, and the experience and creativity of designers can limit their effectiveness. Reinforcement learning (RL) is an effective method to tackle sequential optimization problems due to its ability to adapt and learn through trial and error. Hence, RL can create policies that can handle complex tasks. This work presents an RL framework for global routing that incorporates a self-learning model called RL-Ripper. The primary function of RL-Ripper is to identify the best nets that need to be ripped and rerouted in order to decrease the number of total short violations. In this work, we show that the proposed RL-Ripper framework’s approach can reduce the number of short violations for ISPD 2018 benchmarks when compared to the state-of-the-art global router CUGR. Moreover, RL-Ripper reduced the total number of short violations after the first iteration of detailed routing over the baseline while being on par with the wirelength, VIA, and runtime. The proposed framework’s major impact is providing a novel learning-based approach to global routing that can be replicated for newer technologies.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4396976032",
    "type": "article"
  },
  {
    "title": "Automatic Correction of Arithmetic Circuits in the Presence of Multiple Bugs by Groebner Basis Modification",
    "doi": "https://doi.org/10.1145/3672559",
    "publication_date": "2024-06-12",
    "publication_year": 2024,
    "authors": "Negar Aghapour Sabbagh; Bijan Alizadeh",
    "corresponding_authors": "",
    "abstract": "One promising approach to verify large arithmetic circuits is making use of Symbolic Computer Algebra (SCA), where the circuit and the specification are translated to a set of polynomials, and the verification is performed by the ideal membership testing. Here, the main problem is the monomial explosion for buggy arithmetic circuits, which makes obtaining the word-level remainder become unfeasible. So, automatic correction of such circuits remains a significant challenge. Our proposed correction method partitions the circuit based on primary output bits and modifies the related Groebner basis based on the given suspicious gates, which makes it independent of the word-level remainder. We have applied our method to various signed and unsigned multipliers, with various sizes and numbers of suspicious and buggy gates. The results show that the proposed method corrects the bugs without area overhead. Moreover, it is able to correct the buggy circuit on average 51.9× and 45.72× faster in comparison with the state-of-the-art correction techniques, having single and multiple bugs, respectively.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4399576184",
    "type": "article"
  },
  {
    "title": "Removal of SAT-Hard Instances in Logic Obfuscation Through Inference of Functionality",
    "doi": "https://doi.org/10.1145/3674903",
    "publication_date": "2024-06-25",
    "publication_year": 2024,
    "authors": "Isaac McDaniel; Michael Zuzak; Ankur Srivastava",
    "corresponding_authors": "",
    "abstract": "Logic obfuscation is a prominent approach to protect intellectual property within integrated circuits during fabrication. Many attacks on logic locking have been proposed, particularly in the Boolean satifiability (SAT) attack family, leading to the development of stronger obfuscation techniques. Some obfuscation techniques, including Full-Lock and InterLock, resist SAT attacks by inserting SAT-hard instances into the design, making the SAT attack infeasible. In this work, we observe that this class of obfuscation leaves most of the original design topology visible to an attacker, who can reverse-engineer the original design given the functionality of the SAT-hard instance. We show that an attacker can expose the SAT-hard instance functionality of Full-Lock or InterLock with a polynomial number of queries of its inputs and outputs. We then develop a mathematical framework showing how the functionality can be inferred using only a black-box oracle, as is commonly used in attacks in the literature. Using this framework, we develop a novel attack that allows a SAT-capable attacker to efficiently unlock designs obfuscated with Full-Lock. Our attack recovers the intellectual property from these obfuscation techniques that were previously thought secure. We empirically demonstrate the potency of our novel sensitization attack against benchmark circuits obfuscated with Full-Lock.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4400017381",
    "type": "article"
  },
  {
    "title": "PriorMSM: An Efficient Acceleration Architecture for Multi-Scalar Multiplication",
    "doi": "https://doi.org/10.1145/3678006",
    "publication_date": "2024-07-12",
    "publication_year": 2024,
    "authors": "Changxu Liu; Hao Zhou; Patrick Dai; Li Shang; Fan Yang",
    "corresponding_authors": "",
    "abstract": "Multi-Scalar Multiplication (MSM) is a computationally intensive task that operates on elliptic curves based on GF(P) . It is commonly used in zero-knowledge proof (ZKP), where it accounts for a significant portion of the computation time required for proof generation. In this article, we present PriorMSM, an efficient acceleration architecture for MSM. We propose a Priority-Based Scheduling Mechanism (PBSM) based on a multi-FIFO and multi-bank architecture to accelerate the implementation of MSM. By increasing the pairing success rate of internal points, PBSM reduces the number of bubbles in the pipeline of point addition (PADD), consequently improving the data throughput of the pipeline. We also introduce an advanced parallel bucket aggregation algorithm, leveraging PADD’s fully pipelined characteristics to significantly accelerate the implementation of bucket aggregation. We perform a sensitivity analysis on the crucial parameter of window size in MSM. The results indicate that the window size of the MSM significantly impacts its latency. Area-Time Product (ATP) metric is introduced to guide the selection of the optimal window size, balancing the performance and cost for practical applications of subsequent MSM implementations. PriorMSM is evaluated using the TSMC 28 nm process. It achieves a maximum speedup of 10.9× compared to the previous custom hardware implementations and a maximum speedup of 3.9× compared to the GPU implementations.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4400587717",
    "type": "article"
  },
  {
    "title": "Automatic Test Pattern Generation for Robust Quantum Circuit Testing",
    "doi": "https://doi.org/10.1145/3689333",
    "publication_date": "2024-08-20",
    "publication_year": 2024,
    "authors": "Kean Chen; Mingsheng Ying",
    "corresponding_authors": "",
    "abstract": "Quantum circuit testing is essential for detecting potential faults in realistic quantum devices, while the testing process itself also suffers from the inexactness and unreliability of quantum operations. This article alleviates the issue by proposing a novel framework of automatic test pattern generation (ATPG) for robust testing of logical quantum circuits. We introduce the stabilizer projector decomposition (SPD) for representing the quantum test pattern and construct the test application (i.e., state preparation and measurement) using Clifford-only circuits, which are rather robust and efficient as evidenced in the fault-tolerant quantum computation. However, it is generally hard to generate SPDs due to the exponentially growing number of the stabilizer projectors. To circumvent this difficulty, we develop an SPD generation algorithm, as well as several acceleration techniques that can exploit both locality and sparsity in generating SPDs. The effectiveness of our algorithms are validated by (1) theoretical guarantees under reasonable conditions and (2) experimental results on commonly used benchmark circuits, such as Quantum Fourier Transform (QFT), Quantum Volume (QV), and Bernstein-Vazirani (BV) in IBM Qiskit.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4401981864",
    "type": "article"
  },
  {
    "title": "An Efficient Method of DRC Violation Prediction with a Serial Deep Learning Model",
    "doi": "https://doi.org/10.1145/3694968",
    "publication_date": "2024-09-05",
    "publication_year": 2024,
    "authors": "J.J. Lin; Lin Wen-xiong; Shiyan Liang; Peng Gao; Yan Xing; Tingting Wu; Xiaoming Xiong; Shuting Cai",
    "corresponding_authors": "",
    "abstract": "In VLSI design, the utilization of Design Rule Check (DRC) tools in the early stage is crucial for predicting and resolving violations, thereby expediting the physical design process. In our study, we present an efficient model that predicts DRC violations prior to the routing stage. Additionally, our model incorporates a sliding-window technique to enhance the feature extraction process. We extract structural features using Graph Convolutional Networks and utilize feature reuse techniques to fully recover the lost information in neural layers, which serves as input to the Convolutional Neural Network model, resulting in more accurate hotspot prediction. The experimental results demonstrate that our model successfully identifies 95.78% of DRC violations, with a mere 4.17% false-alarm rate. Not only does our method deliver improved feature preprocessing results, but it also enhances prediction accuracy compared to alternative approaches.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4402269477",
    "type": "article"
  },
  {
    "title": "Performance Analysis of CNN Inference/Training with Convolution and Non-Convolution Operations on ASIC Accelerators",
    "doi": "https://doi.org/10.1145/3696665",
    "publication_date": "2024-09-26",
    "publication_year": 2024,
    "authors": "Hadi Esmaeilzadeh; Soroush Ghodrati; Andrew B. Kahng; Sean Kinzer; Susmita Dey Manasi; Sachin S. Sapatnekar; Zhiang Wang",
    "corresponding_authors": "",
    "abstract": "Today’s performance analysis frameworks for deep learning accelerators suffer from two significant limitations. First, although modern convolutional neural networks (CNNs) consist of many types of layers other than convolution, especially during training, these frameworks largely focus on convolution layers only. Second, these frameworks are generally targeted towards inference, and lack support for training operations. This work proposes a novel open-source performance analysis framework, SimDIT, for general ASIC-based systolic hardware accelerator platforms. The modeling effort of SimDIT comprehensively covers convolution and non-convolution operations of both CNN inference and training on a highly parameterizable hardware substrate. SimDIT is integrated with a backend silicon implementation flow and provides detailed end-to-end performance statistics (i.e., data access cost, cycle counts, energy, and power) for executing CNN inference and training workloads. SimDIT-enabled performance analysis reveals that on a 64 × 64 processing array, non-convolution operations constitute 59.5% of total runtime for ResNet-50 training workload. In addition, by optimally distributing available off-chip DRAM bandwidth and on-chip SRAM resources, SimDIT achieves 18 × performance improvement over a generic static resource allocation for ResNet-50 inference.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4402870437",
    "type": "article"
  },
  {
    "title": "Sensor-Aware Data Imputation for Time-Series Machine Learning on Low-Power Wearable Devices",
    "doi": "https://doi.org/10.1145/3698195",
    "publication_date": "2024-10-07",
    "publication_year": 2024,
    "authors": "Dina Hussein; Taha Belkhouja; Ganapati Bhat; Jana Doppa",
    "corresponding_authors": "",
    "abstract": "Wearable devices that have low-power sensors, processors, and communication capabilities are gaining wide adoption in several health applications. The machine learning algorithms on these devices assume that data from all sensors are available during runtime. However, data from one or more sensors may be unavailable due to energy or communication challenges. This loss of sensor data can result in accuracy degradation of the application. Prior approaches to handle missing data, such as generative models or training multiple classifiers for each combination of missing sensors are not suitable for low-energy wearable devices due to their high overhead at runtime. In contrast to prior approaches, we present an energy-efficient approach, referred to as Sensor-Aware iMputation (SAM), to accurately impute missing data at runtime and recover application accuracy. SAM first uses unsupervised clustering to obtain clusters of similar sensor data patterns. Next, it learns inter-relationship between clusters to obtain imputation patterns for each combination of clusters using a principled sensor-aware search algorithm. Using sensor data for clustering before choosing imputation patterns ensures that the imputation is aware of sensor data observations. Experiments on seven diverse wearable sensor-based time-series datasets demonstrate that SAM is able to maintain accuracy within 5% of the baseline with no missing data when one sensor is missing. We also compare SAM against generative adversarial imputation networks (GAIN), transformers, and k-nearest neighbor methods. Results show that SAM outperforms all three approaches on average by more than 25% when two sensors are missing with negligible overhead compared to the baseline.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4403195235",
    "type": "article"
  },
  {
    "title": "A Cascaded ReRAM-based Crossbar Architecture for Transformer Neural Network Acceleration",
    "doi": "https://doi.org/10.1145/3701034",
    "publication_date": "2024-10-18",
    "publication_year": 2024,
    "authors": "Jiahong Xu; Haikun Liu; Xiaoyang Peng; Zhuohui Duan; Xiaofei Liao; Hai Jin",
    "corresponding_authors": "",
    "abstract": "Emerging resistive random-access memory (ReRAM) based processing-in-memory (PIM) accelerators have been increasingly explored in recent years because they can efficiently perform in-situ matrix-vector multiplication (MVM) operations involved in a wide spectrum of artificial neural networks. However, there remain significant challenges to apply existing ReRAM-based PIM accelerators to the most popular Transformer neural networks. Since Transformers involve a series of matrix-matrix multiplication (MatMul) operations with data dependencies, they should write intermediate results of MatMuls to ReRAM crossbar arrays for further processing. Conventional ReRAM-based PIM accelerators often suffer from high latency of ReRAM writes and intra-layer pipeline stalls. In this paper, we propose ReCAT, a ReRAM-based PIM accelerator designed particularly for Transformers. ReCAT exploits transimpedance amplifiers (TIAs) to cascade a pair of crossbar arrays for MatMul operations involved in the self-attention mechanism. The intermediate result of a MatMul generated by one crossbar array can be directly mapped to another crossbar array, avoiding costly analog-to-digital conversions. In this way, ReCAT allows MVM operations to overlap with the corresponding data mapping, hiding the high latency of ReRAM writes. Furthermore, we propose an analog-to-digital converter (ADC) virtualization scheme to dynamically share scarce ADCs among a group of crossbar arrays, and thus significantly improve the utilization of ADCs to eliminate the performance bottleneck of MVM operations. Experimental results show that ReCAT achieves 207.3 ×, 2.11 ×, and 3.06 × performance improvement on average compared with other Transformer acceleration solutions—GPUs, ReBert, and ReTransformer, respectively.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4403546214",
    "type": "article"
  },
  {
    "title": "Watch Out for the Inherent Vulnerabilities in Developing Multi-tenant Cloud-FPGA: Communication Protocols",
    "doi": "https://doi.org/10.1145/3702324",
    "publication_date": "2024-11-04",
    "publication_year": 2024,
    "authors": "Ziyu Liu; Yukui Luo; Yuheng Zhang; Shijin Duan; Xiaolin Xu",
    "corresponding_authors": "",
    "abstract": "As FPGAs are being deployed in the cloud infrastructure for acceleration, the technology of multi-tenant FPGA has emerged as a topic of interest. This development has drawn considerable attention to its security issues. While previous research primarily focused on the security of applications, there has been limited exploration of the vulnerabilities inherent in FPGA IPs. In our work, we examine the vulnerabilities of two widely used data transmission protocols in modern FPGAs: the Advanced eXtensible Interface (AXI) and Peripheral Component Interconnect Express (PCIe). Our experiments, conducted with commercial FPGA development kits, launched fault injection attacks through the shared power distribution network (PDN). Through non-invasive electromagnetic (EM) trace measurement, we characterize the voltage fluctuation across various attack patterns. Subsequently, we simulate real-world data transfers using two crafted datasets with different statistical characteristics. The experimental results demonstrate the unique security vulnerabilities of the current AXI and PCIe protocols in the context of a multi-tenant cloud-FPGA. In response to such vulnerability, we further propose two defense strategies: InChAXI that utilizes integrity checking for AXI-based data, and FCPCIe that employs frequency scaling for PCIe-based data. The performance evaluation demonstrates that our proposed defenses can significantly reduce the fault injections on the AXI-based data transmission by 705 times with small overheads – 0.5% in hardware footprint and 7.9% in latency, respectively. On the other hand, FCPCIe effectively prevents the fault injection attack during the PCIe-based data transmission by reducing the user clock frequency, while incurring a 10.13% overhead on data throughput.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4404048208",
    "type": "article"
  },
  {
    "title": "SafeTI: a Hardware Traffic Injector for Complex MPSoC Platform Validation and Characterization",
    "doi": "https://doi.org/10.1145/3703910",
    "publication_date": "2024-11-13",
    "publication_year": 2024,
    "authors": "Francisco Fuentes; Sergi Alcaide; Raimon Casanova; Jaume Abella",
    "corresponding_authors": "",
    "abstract": "Functional and timing validation of high performing safety-related platforms requires testing specific traffic patterns in the network-on-chip interconnects. Generally, testing needs to be performed by using software tests whose degree of control on the traffic generated is indirect, and limited to behavior that can be triggered by software, thus often unable to produce traffic generated by peripherals. Therefore, untested traffic scenarios can be abundant and, to a large extent, it is hard to know what traffic scenarios have been effectively tested. This paper presents the safe traffic injector , SafeTI, which allows injecting programmable traffic in AMBA AHB interconnects with high flexibility and degree of control, thus easing achieving high coverage in terms of traffic scenarios tested, and mitigating the uncertainty due to the difficulties to relate software tests with actual traffic scenarios tested. We also integrate successfully the SafeTI in the safety open platform SELENE proving the effectiveness of the proposed traffic injector for characterizing the platform memory access capabilities under different patterns of contention on the multi-level cache system.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4404332181",
    "type": "article"
  },
  {
    "title": "ISOAcc: In-situ Shift Operation-based Accelerator For Efficient in-SRAM Multiplication",
    "doi": "https://doi.org/10.1145/3707205",
    "publication_date": "2024-12-05",
    "publication_year": 2024,
    "authors": "Guomin Zhao; Junzhong Shen; Rongzhen Lin; Hua Li; Yaohua Wang",
    "corresponding_authors": "",
    "abstract": "Digital SRAM-based CIM architectures must balance three critical factors: quantized neural network bitwidth, accuracy loss, and computational efficiency, each crucial to optimizing performance and efficiency. In Domain Specific Accelerators (DSAs), flexible and specific hardware design, when incorporated with tailored Power-of-2 (P-2) quantization schemes, addresses this issue. However, in CIMs, the absence of flexible and specific hardware to support dynamic switching between general and tailored quantization schemes hinders the adoption of efficient quantization methods. In this paper, we propose the I n-situ S hift O peration based Acc elerator ( ISOAcc ) for efficient SRAM-based multiplication. The key idea is to introduce transmission gates near the SRAM array to enable the selection of bits from either the same or the neighbor line when data flows from one row to another. This functionally equals a shift operation. By configuring the transmission gates array in a cascade manner, ISOAcc can support 0 to 15-bit shift with a negligible overhead. The ISOAcc can directly leverage P-2 quantization schemes in hardware, thereby greatly reducing multiplication cycles. We have chosen five well-known neural networks to evaluate ISOAcc. The evaluations show that ISOAcc achieves an average performance improvement of 3.24 × and an energy reduction of 75%, compared to the state-of-the-art (SOTA) SRAM-based CIM design, Bit-Parallel.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4405081692",
    "type": "article"
  },
  {
    "title": "From VHDL to efficient and first-time-right designs",
    "doi": "https://doi.org/10.1145/233539.233541",
    "publication_date": "1996-04-01",
    "publication_year": 1996,
    "authors": "P.F.A. Middelhoek; Sreeranga P. Rajan",
    "corresponding_authors": "",
    "abstract": "In this article we provide a practical transformational approach to the synthesis of correct synchronous digital hardware designs from high-level specifications. We do this while taking into account the complete life cycle of a design from early prototype to full custom implementation. Besides time-to-market, both flexibility with respect to target architecture and efficiency issues are addressed by the methodology. The utilization of user-selected behavior-preserving transformation steps ensures first-time-right design while exploiting the experience, flexibility, and creativity of the designer. To ensure that design transformations are indeed behavior-preserving a novel mechanized approach to the specification and verification of design transformations on control data flow graphs which is independent of a specific behavioral model or graph size has been developed. As a demonstration of an industrial application we use a video processing algorithm needed for the conversion from a line-interlaced to progressively scanned video format. Both a video signal processor-based prototype implementation as well as a very efficient full custom implementation are developed starting from a single high-level behavioral specification of the algorithm in VHDL. Results are compared with those previously obtained using different tools and methodologies.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W1977421287",
    "type": "article"
  },
  {
    "title": "Power reduction and power-delay trade-offs using logic transformations",
    "doi": "https://doi.org/10.1145/298865.298872",
    "publication_date": "1999-01-01",
    "publication_year": 1999,
    "authors": "Qi Wang; Sarma Vrudhula; Gary Yeap; Shantanu Ganguly",
    "corresponding_authors": "",
    "abstract": "We present an efficient technique to reduce the switching activity in a technology-mapped CMOS combinational circuit based on local logic transformations. The transformations consist of adding redundant connections or gates so as to reduce switching activity. We describe simple and efficient procedures, based on logic implication, for identifying the sources and targets of the redundant connections. Additionally, we give procedures that permit the designer to trade-off power and delay after the transformations. Results of experiments on both the MCNC benchmark circuits and the circuits of a PowerPC microprocessor chip are given. The results indicate that significant power reduction of a CMOS combinational circuit can be achieved with very low area overhead, delay penalty, and computational cost.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2045214881",
    "type": "article"
  },
  {
    "title": "A code-motion pruning technique for global scheduling",
    "doi": "https://doi.org/10.1145/329458.329461",
    "publication_date": "2000-01-01",
    "publication_year": 2000,
    "authors": "Luiz C. V. dos Santos; M.J.M. Heijligers; C.A.J. van Eijk; J. Van Eijnhoven; J.A.G. Jess",
    "corresponding_authors": "",
    "abstract": "In the high-level synthesis of ASICs or in the code generation for ASIPs, the presence of conditionals in the behavioral description represents an obstacle to exploit parallelism. Most existing methods use greedy choices in such a way that the search space is limited by the applied heuristics. For example, they might miss opportunities to optimize across basic block boundaries when treating conditional execution. We propose a constructive method which allows generalized code motions. Scheduling and code motion are encoded in the form of a unified resource-constrained optimization problem. In our approach many alternative solutions are constructed and explored by a search algorithm, while optimal solutions are kept in the search space. Our method can cope with issues like speculative execution and code such duplication. Moreover, it can tackle constraints imposed by the advance choice of a controller, such as pipelined-control delay and limited branch capabilities. The underlying timing models support chaining and multicycling. As tasking code motion into account may lead to a larger search space, a code-motion pruning technique is presented. This pruning is proven to keep optimal solutions in the search space for cost functions in terms of schedule lengths.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2054162055",
    "type": "article"
  },
  {
    "title": "An efficient register optimization algorithm for high-level synthesis from hierarchical behavioral specifications",
    "doi": "https://doi.org/10.1145/504914.504923",
    "publication_date": "2002-01-01",
    "publication_year": 2002,
    "authors": "Ranga Vemuri; Srinivas Katkoori; Meenakshi Kaul; J. Roy",
    "corresponding_authors": "",
    "abstract": "We address the problem of register optimization that arises during high-level synthesis from modular hierarchical behavioral specifications. Register optimization is the process of grouping carriers such that each group can be safely allocated to a hardware register. Global register optimization by inline expansion involves flattening the module hierarchy and using a heuristic register optimization procedure on the flattened description. Although inline expansion yields a near-optimal number of registers, it is very time consuming due to the large number of carrier compatibility relationships that must be considered. We present an efficient register optimization algorithm that achieves nearly the same effect of inline expansion without actually inline expanding. The distinguishing feature of the proposed algorithm is that it employs a hierarchical optimization phase which effectively exploits the properties of the module call graph and information gathered during local carrier lifecycle analysis of each module. Experimental results on a number of benchmarks show that the proposed algorithm produces nearly the same number of registers as inline expansion based global optimization and is faster by a factor of 7.0.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2160646603",
    "type": "article"
  },
  {
    "title": "Optimal time borrowing analysis and timing budgeting optimization for latch-based designs",
    "doi": "https://doi.org/10.1145/504914.504924",
    "publication_date": "2002-01-01",
    "publication_year": 2002,
    "authors": "Shi-Zheng Eric Lin; Chieh Changfan; Yu-Chin Hsu; Fur-Shing Tsai",
    "corresponding_authors": "",
    "abstract": "An interesting property of a latch-based design is that the combinational path delay is allowed to be longer than the clock cycle as long as it can \"borrow\" time from the shorter paths in the subsequent logic stages. This gives designers a lot of flexibility in designing circuits, especially high performance ones. However, it also increases the complexity in timing analysis. Finding the best clock period or determining how much time to borrow from the subsequent logic stages is difficult especially for designs containing multiple clocks, mixed-clock paths, user-specified multicycle paths, and false paths. In this article, we formulate the time borrowing problem as a linear programming problem. An optimal time borrowing solution can be found by solving the formulation. Based on this time borrowing solver, algorithms are proposed for timing optimization to achieve the optimal clock period. Experimental results show our algorithm is efficient and yields very good results.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W1965204794",
    "type": "article"
  },
  {
    "title": "Introducing redundant computations in RTL data paths for reducing BIST resources",
    "doi": "https://doi.org/10.1145/383251.383253",
    "publication_date": "2001-07-01",
    "publication_year": 2001,
    "authors": "Ishwar Parulkar; Sandeep K. Gupta; Melvin A. Breuer",
    "corresponding_authors": "",
    "abstract": "The need for considering BIST requirements during the scheduling and assignment stages of behavioral synthesis has been demonstrated in previous research and techniques for reducing BIST resources of a data path during these stages of synthesis have been developed. However, the degree of freedom that can be exploited during scheduling and assignment to minimize these resources is often limited by the data and control dependencies of a behavior. In this paper, we propose transformation of a behavior before scheduling and assignment, namely introducing redundant computations such that the resulting data path is testable using few BIST resources. The transformation makes use of spare capacity of modules to add redundancy that enables test paths to be shared among the modules. A technique for identifying potential BIST resource sharing problems in a behavior and resolving them by redundant computations is presented. Introduiction of redundant computations is performed without compromising the latency and functional resource requirement of the behavior.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2017276983",
    "type": "article"
  },
  {
    "title": "Parametric variability analysis for multistage analog circuits using analytical sensitivity modeling",
    "doi": "https://doi.org/10.1145/1344418.1344429",
    "publication_date": "2008-04-02",
    "publication_year": 2008,
    "authors": "Fang Liu; Sule Ozev; Plamen K. Nikolov",
    "corresponding_authors": "",
    "abstract": "Process variations play an increasingly important role on the success of analog circuits. State-of-the-art analog circuits are based on complex architectures and contain many hierarchical layers and parameters. Knowledge of the parameter variances and their contribution patterns is crucial for a successful design process. This information is valuable to find solutions for many problems in design, design automation, testing, and fault tolerance. In this article, we present a hierarchical variance analysis methodology for multistage analog circuits. Starting from the process/layout level, we derive implicit hierarchical relations and extract the sensitivity information analytically. We make use of previously computed values whenever possible so as to reduce computational time. The proposed approach is particularly geared for the domain of design and test automation, where multiple runs on slightly different circuits are necessary. Experimental results indicate that the proposed method provides both accuracy and computational efficiency when compared with prior approaches.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W1972861092",
    "type": "article"
  },
  {
    "title": "Speedups in embedded systems with a high-performance coprocessor datapath",
    "doi": "https://doi.org/10.1145/1255456.1255472",
    "publication_date": "2007-08-17",
    "publication_year": 2007,
    "authors": "Michalis D. Galanis; Gregory Dimitroulakos; Spyros Tragoudas; Costas E. Goutis",
    "corresponding_authors": "",
    "abstract": "This article presents the speedups achieved in a generic single-chip microprocessor system by employing a high-performance datapath. The datapath acts as a coprocessor that accelerates computational-intensive kernel sections thereby increasing the overall performance. We have previously introduced the datapath which is composed of Flexible Computational Components (FCCs). These components can realize any two-level template of primitive operations. The automated coprocessor synthesis method from high-level software description and its integration to a design flow for executing applications on the system is presented. For evaluating the effectiveness of our coprocessor approach, analytical study in respect to the type of the custom datapath and to the microprocessor architecture is performed. The overall application speedups of several real-life applications relative to the software execution on the microprocessor are estimated using the design flow. These speedups range from 1.75 to 5.84, with an average value of 3.04, while the overhead in circuit area is small. The design flow achieved the acceleration of the applications near to theoretical speedup bounds. A comparison with another high-performance datapath showed that the proposed coprocessor achieves smaller area-time products by an average of 23% for the generated datapaths. Additionally, the FCC coprocessor achieves better performance in accelerating kernels relative to software-programmable DSP cores.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2011126872",
    "type": "article"
  },
  {
    "title": "Synthesis of a novel timing-error detection architecture",
    "doi": "https://doi.org/10.1145/1297666.1297680",
    "publication_date": "2008-01-01",
    "publication_year": 2008,
    "authors": "Yu-Shih Su; Po-Hsien Chang; Shih-Chieh Chang; TingTing Hwang",
    "corresponding_authors": "",
    "abstract": "Delay variation can cause a design to fail its timing specification. Ernst et al. [2003] observe that the worst delay of a design is least probable to occur. They propose a mechanism to detect and correct occasional errors while the design can be optimized for the common cases. Their experimental results show significant performance (or power) gain as compared with the worst-case design. However, the architecture in Ernst et al. [2003] suffers the short path problem, which is difficult to resolve. In this article, we propose a novel error-detecting architecture to solve the short path problem. Our experimental results show considerable performance gain can be achieved with reasonable area overhead.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2039577315",
    "type": "article"
  },
  {
    "title": "Combining system scenarios and configurable memories to tolerate unpredictability",
    "doi": "https://doi.org/10.1145/1367045.1367058",
    "publication_date": "2008-07-01",
    "publication_year": 2008,
    "authors": "Concepción Sanz; Manuel Prieto; J.I. Gomez; Apostolos Papanikolaou; Miguel Miranda; Francky Catthoor",
    "corresponding_authors": "",
    "abstract": "Process variability and the dynamism of new applications increase the uncertainty of embedded systems and force designers to use pessimistic assumptions, which have a tremendous impact on both the performance and energy consumption of their memory organizations. In this article we introduce an experimental framework which tries to mitigate the effects of both sources of unpredictability. At compile time, an extensive profiling helps us to detect system scenarios and bounds application dynamism. At the organization level, we incorporate a heterogeneous memory architecture composed by several configurable memories. A calibration process and a runtime control system adapt the platform to the current application needs. Our approach manages to reduce significantly the energy overhead associated to both variability and application dynamism (up to 60%, according to our simulations) without compromising the timing constraints existing in our target domain of dynamic periodic multimedia applications.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2067055572",
    "type": "article"
  },
  {
    "title": "Resource sharing among mutually exclusive sum-of-product blocks for area reduction",
    "doi": "https://doi.org/10.1145/1367045.1367060",
    "publication_date": "2008-07-01",
    "publication_year": 2008,
    "authors": "Sabyasachi Das; Sunil P. Khatri",
    "corresponding_authors": "",
    "abstract": "In state-of-the-art digital designs, arithmetic blocks consume a major portion of the total area of the IC. The arithmetic sum-of-product (SOP) is the most widely used arithmetic block. Some of the examples of SOP are adder, subtractor, multiplier, multiply-accumulator (MAC), squarer, chain-of-adders, incrementor, decrementor, etc. In this article, we introduce a novel, area-efficient architecture to share different SOP blocks which are used in a mutually exclusive manner. We implement the core functions of the largest SOP only once and reuse different parts of the core subblocks for all other SOP operations with the help of multiplexers. This architecture can be used in the nontiming-critical paths of the design, to save significant amounts of area. Our experimental data shows that the proposed sharing-based architecture results in about 37% area savings compared to the results obtained from a commercially available best-in-class datapath synthesis tool. In addition, our proposed shared implementation consumes about 18% less power. These improvements were verified on placed-and-routed designs as well.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2068463139",
    "type": "article"
  },
  {
    "title": "Auxiliary state machines + context-triggered properties in verification",
    "doi": "https://doi.org/10.1145/1391962.1391970",
    "publication_date": "2008-09-01",
    "publication_year": 2008,
    "authors": "Ansuman Banerjee; Pallab Dasgupta; P. P. Chakrabarti",
    "corresponding_authors": "",
    "abstract": "Formal specifications of interface protocols between a design-under-test and its environment mostly consist of two types of correctness requirements, namely (a) a set of invariants that applies throughout the protocol execution and (b) a set of context-triggered properties that applies only when the protocol state belongs to a specific set of contexts. To model such requirements, an increasingly popular design choice in the assertion IP design community has been the use of abstract context state machines and state-oriented properties. In this paper, we formalize this modeling style and present algorithms for verifying such specifications. Specifically, we present a purely formal approach and a semi-formal approach for verifying such specifications. We demonstrate the use of this design style in modeling some of the industry standard protocol descriptions and present encouraging results.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2091292637",
    "type": "article"
  },
  {
    "title": "Machine Learning for Statistical Modeling",
    "doi": "https://doi.org/10.1145/3440014",
    "publication_date": "2021-01-13",
    "publication_year": 2021,
    "authors": "Urmimala Roy; Tanmoy Pramanik; Subhendu Roy; Avhishek Chatterjee; Leonard F. Register; S. Banerjee",
    "corresponding_authors": "",
    "abstract": "We propose a methodology to perform process variation-aware device and circuit design using fully physics-based simulations within limited computational resources, without developing a compact model. Machine learning (ML), specifically a support vector regression (SVR) model, has been used. The SVR model has been trained using a dataset of devices simulated a priori, and the accuracy of prediction by the trained SVR model has been demonstrated. To produce a switching time distribution from the trained ML model, we only had to generate the dataset to train and validate the model, which needed ∼500 hours of computation. On the other hand, if 10 6 samples were to be simulated using the same computation resources to generate a switching time distribution from micromagnetic simulations, it would have taken ∼250 days. Spin-transfer-torque random access memory (STTRAM) has been used to demonstrate the method. However, different physical systems may be considered, different ML models can be used for different physical systems and/or different device parameter sets, and similar ends could be achieved by training the ML model using measured device data.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W3120437304",
    "type": "article"
  },
  {
    "title": "Fault-based Built-in Self-test and Evaluation of Phase Locked Loops",
    "doi": "https://doi.org/10.1145/3427911",
    "publication_date": "2021-01-08",
    "publication_year": 2021,
    "authors": "Mehmet Ince; Ender Yılmaz; Wei Fu; Joon-Sung Park; K. Nagaraj; LeRoy Winemberg; Sule Ozev",
    "corresponding_authors": "",
    "abstract": "With the increasing pressure to obtain near-zero defect rates for the automotive industry, there is a need to explore built-in self-test and other non-traditional test techniques for embedded mixed-signal components, such as PLLs, DC-DC converters, and data converters. This article presents a very low-cost built-in self-test technique for PLLs specifically designed for fault detection. The methodology relies on exciting the PLL loop in one location via a pseudo-random signal with noise characteristics and observing the response from another location in the loop via all digital circuitry, thereby inducing low area and performance overhead. The BIST circuit along with a PLL under test is designed in 65 nm technology. Fault simulations performed at the transistor and system-level show that the majority of non-catastrophic faults that result in parametric failures can be detected with the proposed approach.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W3120760377",
    "type": "article"
  },
  {
    "title": "A Dynamic Huffman Coding Method for Reliable TLC NAND Flash Memory",
    "doi": "https://doi.org/10.1145/3446771",
    "publication_date": "2021-06-05",
    "publication_year": 2021,
    "authors": "Chin-Hsien Wu; Haowei Zhang; Chia‐Wei Liu; Ta-Ching Yu; Chi-Yen Yang",
    "corresponding_authors": "",
    "abstract": "With the progress of the manufacturing process, NAND flash memory has evolved from the single-level cell and multi-level cell into the triple-level cell (TLC). NAND flash memory has physical problems such as the characteristic of erase-before-write and the limitation of program/erase cycles. Moreover, TLC NAND flash memory has low reliability and short lifetime. Thus, we propose a dynamic Huffman coding method that can apply to the write operations of NAND flash memory. The proposed method exploits observations from a Huffman tree and machine learning from data patterns to dynamically select a suitable Huffman coding. According to the experimental results, the proposed method can improve the reliability of TLC NAND flash memory and also consider the compression performance for those applications that require the Huffman coding.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W3171192797",
    "type": "article"
  },
  {
    "title": "Placement of Digital Microfluidic Biochips via a New Evolutionary Algorithm",
    "doi": "https://doi.org/10.1145/3460230",
    "publication_date": "2021-06-28",
    "publication_year": 2021,
    "authors": "Chen Jiang; Bo Yuan; Tsung-Yi Ho; Xin Yao",
    "corresponding_authors": "",
    "abstract": "Digital microfluidic biochips (DMFBs) have been a revolutionary platform for automating and miniaturizing laboratory procedures with the advantages of flexibility and reconfigurability. The placement problem is one of the most challenging issues in the design automation of DMFBs. It contains three interacting NP-hard sub-problems: resource binding, operation scheduling, and module placement. Besides, during the optimization of placement, complex constraints must be satisfied to guarantee feasible solutions, such as precedence constraints, storage constraints, and resource constraints. In this article, a new placement method for DMFB is proposed based on an evolutionary algorithm with novel heuristic-based decoding strategies for both operation scheduling and module placement. Specifically, instead of using the previous list scheduler and path scheduler for decoding operation scheduling chromosomes, we introduce a new heuristic scheduling algorithm (called order scheduler) with fewer limitations on the search space for operation scheduling solutions. Besides, a new 3D placer that combines both scheduling and placement is proposed where the usage of the microfluidic array over time in the chip is recorded flexibly, which is able to represent more feasible solutions for module placement. Compared with the state-of-the-art placement methods (T-tree and 3D-DDM), the experimental results demonstrate the superiority of the proposed method based on several real-world bioassay benchmarks. The proposed method can find the optimal results with the minimum assay completion time for all test cases.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W3175804561",
    "type": "article"
  },
  {
    "title": "An Energy-Efficient Inference Method in Convolutional Neural Networks Based on Dynamic Adjustment of the Pruning Level",
    "doi": "https://doi.org/10.1145/3460972",
    "publication_date": "2021-08-01",
    "publication_year": 2021,
    "authors": "Mohammad Ali Maleki; Alireza Nabipour-Meybodi; Mehdi Kamal; Ali Afzali‐Kusha; Massoud Pedram",
    "corresponding_authors": "",
    "abstract": "In this article, we present a low-energy inference method for convolutional neural networks in image classification applications. The lower energy consumption is achieved by using a highly pruned (lower-energy) network if the resulting network can provide a correct output. More specifically, the proposed inference method makes use of two pruned neural networks (NNs), namely mildly and aggressively pruned networks, which are both designed offline. In the system, a third NN makes use of the input data for the online selection of the appropriate pruned network. The third network, for its feature extraction, employs the same convolutional layers as those of the aggressively pruned NN, thereby reducing the overhead of the online management. There is some accuracy loss induced by the proposed method where, for a given level of accuracy, the energy gain of the proposed method is considerably larger than the case of employing any one pruning level. The proposed method is independent of both the pruning method and the network architecture. The efficacy of the proposed inference method is assessed on Eyeriss hardware accelerator platform for some of the state-of-the-art NN architectures. Our studies show that this method may provide, on average, 70% energy reduction compared to the original NN at the cost of about 3% accuracy loss on the CIFAR-10 dataset.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W3189043577",
    "type": "article"
  },
  {
    "title": "Improving LDPC Decoding Performance for 3D TLC NAND Flash by LLR Optimization Scheme for Hard and Soft Decision",
    "doi": "https://doi.org/10.1145/3473305",
    "publication_date": "2021-09-13",
    "publication_year": 2021,
    "authors": "Lanlan Cui; Fei Wu; Xiaojian Liu; Meng Zhang; Renzhi Xiao; Changsheng Xie",
    "corresponding_authors": "",
    "abstract": "Low-density parity-check (LDPC) codes have been widely adopted in NAND flash in recent years to enhance data reliability. There are two types of decoding, hard-decision and soft-decision decoding. However, for the two types, their error correction capability degrades due to inaccurate log-likelihood ratio (LLR) . To improve the LLR accuracy of LDPC decoding, this article proposes LLR optimization schemes, which can be utilized for both hard-decision and soft-decision decoding. First, we build a threshold voltage distribution model for 3D floating gate (FG) triple level cell (TLC) NAND flash. Then, by exploiting the model, we introduce a scheme to quantize LLR during hard-decision and soft-decision decoding. And by amplifying a portion of small LLRs, which is essential in the layer min-sum decoder, more precise LLR can be obtained. For hard-decision decoding, the proposed new modes can significantly improve the decoder’s error correction capability compared with traditional solutions. Soft-decision decoding starts when hard-decision decoding fails. For this part, we study the influence of the reference voltage arrangement of LLR calculation and apply the quantization scheme. The simulation shows that the proposed approach can reduce frame error rate (FER) for several orders of magnitude.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W3200084847",
    "type": "article"
  },
  {
    "title": "Toward Taming the Overhead Monster for Data-flow Integrity",
    "doi": "https://doi.org/10.1145/3490176",
    "publication_date": "2021-11-17",
    "publication_year": 2021,
    "authors": "Lang Feng; Jiayi Huang; Jeff Huang; Jiang Hu",
    "corresponding_authors": "",
    "abstract": "Data-Flow Integrity (DFI) is a well-known approach to effectively detecting a wide range of software attacks. However, its real-world application has been quite limited so far because of the prohibitive performance overhead it incurs. Moreover, the overhead is enormously difficult to overcome without substantially lowering the DFI criterion. In this work, an analysis is performed to understand the main factors contributing to the overhead. Accordingly, a hardware-assisted parallel approach is proposed to tackle the overhead challenge. Simulations on SPEC CPU 2006 benchmark show that the proposed approach can completely enforce the DFI defined in the original seminal work while reducing performance overhead by 4x, on average.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W3212335816",
    "type": "article"
  },
  {
    "title": "Low-Power Hypercube Divided Memory FFT Engine Using 3D Integration",
    "doi": "https://doi.org/10.1145/1870109.1870114",
    "publication_date": "2010-11-01",
    "publication_year": 2010,
    "authors": "Thorlindur Thorolfsson; Samson Melamed; W. Rhett Davis; Paul D. Franzon",
    "corresponding_authors": "",
    "abstract": "In this article we demonstrate a floating point FFT processor that leverages both 3D integration and a unique hypercube memory division scheme to reduce the power consumption of a 1024 point FFT down to 4.227 μJ . The hypercube memory division scheme lowers the energy per memory access by 59.2% and increases the total required area by 16.8%. The use of 3D integration reduces the logic power by 5.2%. We describe the tool flow required to realize the 3D implementation and perform a thermal analysis of it.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W1967452983",
    "type": "article"
  },
  {
    "title": "Scenario-based timing verification of multiprocessor embedded applications",
    "doi": "https://doi.org/10.1145/1529255.1529259",
    "publication_date": "2009-05-01",
    "publication_year": 2009,
    "authors": "Dipankar Das; P. P. Chakrabarti; Rajeev Kumar",
    "corresponding_authors": "",
    "abstract": "This work presents a static timing-analysis method for verification of scenario-based real-time properties, on graphical task-level models of embedded applications. Scenario-based properties specify timing constraints which must be honored for specific control-flow behaviors and task execution orderings. Static checking of scenario-based properties currently requires computationally expensive model checking methods. Hence the proposed graph-based static timing-analysis algorithm improves upon the state-of-the-art. This is manifested in a significant performance advantage over timed model checking (up to 1000X in several cases), which suffers from state space explosion. The proposed algorithm also employs compositional reasoning and abstraction refinement for handling large problems. We also illustrate methods for using scenario-based timing analysis, which can act as alternatives to traditional timed model checking for verification of timed systems like FDDI and Fischer protocols. We implement this timing verification algorithm as a tool called SymTime and present experimental results for SymTime comparing it with SPIN, UPPAAL, and a TCTL model checker for Time Petri Nets, called Romeo.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W1995273792",
    "type": "article"
  },
  {
    "title": "A hardware platform for efficient worm outbreak detection",
    "doi": "https://doi.org/10.1145/1562514.1562517",
    "publication_date": "2009-08-01",
    "publication_year": 2009,
    "authors": "Miad Faezipour; Mehrdad Nourani; Rina Panigrahy‎",
    "corresponding_authors": "",
    "abstract": "Network Intrusion Detection Systems (NIDS) monitor network traffic to detect attacks or unauthorized activities. Traditional NIDSes search for patterns that match typical network compromise or remote hacking attempts. However, newer networking applications require finding the frequently repeated strings in a packet stream for further investigation of potential attack attempts. Finding frequently repeated strings within a given time frame of the packet stream has been quite efficient to detect polymorphic worm outbreaks. A novel real-time worm outbreak detection system using two-phase hashing and monitoring repeated common substrings is proposed in this article. We use the concept of shared counters to minimize the memory cost while efficiently sifting through suspicious strings. The worm outbreak system has been prototyped on Altera Stratix FPGA. We have tested the system for various settings and packet stream sizes. Experimental results verify that our system can support line speed of gigabit-rates with negligible false positive and negative rates.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2011796579",
    "type": "article"
  },
  {
    "title": "Low-overhead <i>F</i> <sub> <i>max</i> </sub> calibration at multiple operating points using delay-sensitivity-based path selection",
    "doi": "https://doi.org/10.1145/1698759.1698769",
    "publication_date": "2010-02-01",
    "publication_year": 2010,
    "authors": "Somnath Paul; Hamid Mahmoodi; Swarup Bhunia",
    "corresponding_authors": "",
    "abstract": "Maximum operating frequency ( F max ) of a system often needs to be determined at multiple operating points, defined by voltage and temperatures. Such calibration is important for the speed binning process, where the voltage-frequency (V- F max ) relation needs to be accurately determined to sort chips into different bins that can be used for different applications. Moreover, adaptive systems typically require F max calibration at multiple operating points in order to dynamically change operating condition such as supply voltage or body bias for power, temperature, or throughput management. For example, a Dynamic Voltage and Frequency Scaling (DVFS) system requires accurate delay calibration at multiple operating voltages in order to apply the correct operating frequency corresponding to a scaled supply. In this article, we propose a low-overhead design technique that allows efficient characterization of F max at different operating voltages and temperatures. The proposed method selects a set of representative timing paths in a circuit based on their temperature and voltage sensitivities and dynamically configures them into a ring oscillator to compute the critical path delay. Compared to existing F max calibration approaches, the proposed approach provides the following two main advantages: (1) it introduces a delay sensitivity metric to isolate few representative timing paths; (2) it considers actual timing paths instead of critical path replicas, thereby accounting for local within-die delay variations. The all-digital calibration method is robust under process variations and achieves high delay estimation accuracy (&gt; 4% error) at the cost of negligible design overhead (1.7% in delay, 0.3% in power, and 3.5% in die-area).",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2034285860",
    "type": "article"
  },
  {
    "title": "Dynamic security domain scaling on embedded symmetric multiprocessors",
    "doi": "https://doi.org/10.1145/1497561.1497567",
    "publication_date": "2009-03-01",
    "publication_year": 2009,
    "authors": "Hiroaki Inoue; Tsuyoshi Abe; Kazuhisa Ishizaka; Junji Sakai; Masato Edahiro",
    "corresponding_authors": "",
    "abstract": "We propose a method for dynamic security-domain scaling on SMPs that offers both highly scalable performance and high security for future high-end embedded systems. Its most important feature is its highly efficient use of processor resources, accomplished by dynamically changing the number of processors within a security-domain (i.e., dynamically yielding processors to other security-domains) in response to application load requirements. Two new technologies make this scaling possible without any virtualization software: (1) self-transition management and (2) unified virtual address mapping. Evaluations show that this domain control provides highly scalable performance and incurs almost no performance overhead in security-domains. The increase in OSs in binary code size is less than 1.5%, and the time required for individual state transitions is on the order of a single millisecond. This scaling is the first in the world to make possible the dynamic changing of the number of processors within a security-domain on an ARM SMP.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2081506245",
    "type": "article"
  },
  {
    "title": "Energy and switch area optimizations for FPGA global routing architectures",
    "doi": "https://doi.org/10.1145/1455229.1455242",
    "publication_date": "2009-01-01",
    "publication_year": 2009,
    "authors": "Yi Zhu; Yuanfang Hu; Michael Taylor; Chung‐Kuan Cheng",
    "corresponding_authors": "",
    "abstract": "Low energy and small switch area usage are two important design objectives in FPGA global routing architecture design. This article presents an improved MCF model based CAD flow that performs aggressive optimizations, such as topology and wire style optimization, to reduce the energy and switch area of FPGA global routing architectures. The experiments show that when compared to traditional mesh architecture, the optimized FPGA routing architectures achieve up to 10% to 15% energy savings and up to 20% switch area savings in average for a set of seven benchmark circuits.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2094175805",
    "type": "article"
  },
  {
    "title": "Symbolic Analyses of Dataflow Graphs",
    "doi": "https://doi.org/10.1145/3007898",
    "publication_date": "2017-01-04",
    "publication_year": 2017,
    "authors": "Adnan Bouakaz; Pascal Fradet; Alain Girault",
    "corresponding_authors": "",
    "abstract": "The synchronous dataflow model of computation is widely used to design embedded stream-processing applications under strict quality-of-service requirements (e.g., buffering size, throughput, input-output latency). The required analyses can either be performed at compile time (for design space exploration) or at runtime (for resource management and reconfigurable systems). However, these analyses have an exponential time complexity, which may cause a huge runtime overhead or make design space exploration unacceptably slow. In this article, we argue that symbolic analyses are more appropriate since they express the system performance as a function of parameters (i.e., input and output rates, execution times). Such functions can be quickly evaluated for each different configuration or checked with respect to different quality-of-service requirements. We provide symbolic analyses for computing the maximal throughput of acyclic synchronous dataflow graphs, the minimum required buffers for which as soon as possible (ASAP) scheduling achieves this throughput, and finally, the corresponding input-output latency of the graph. The article first investigates these problems for a single parametric edge. The results are extended to general acyclic graphs using linear approximation techniques. We assess the proposed analyses experimentally on both synthetic and real benchmarks.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2570429727",
    "type": "article"
  },
  {
    "title": "HoPE",
    "doi": "https://doi.org/10.1145/2999538",
    "publication_date": "2017-04-03",
    "publication_year": 2017,
    "authors": "Jaehyun Park; Seung-Cheol Baek; Hyung Gyu Lee; Chrysostomos Nicopoulos; Vinson Young; Jung­hee Lee; Jong‐Man Kim",
    "corresponding_authors": "",
    "abstract": "Data compression plays a pivotal role in improving system performance and reducing energy consumption, because it increases the logical effective capacity of a compressed memory system without physically increasing the memory size. However, data compression techniques incur some cost, such as non-negligible compression and decompression overhead. This overhead becomes more severe if compression is used in the cache. In this article, we aim to minimize the read-hit decompression penalty in compressed Last-Level Caches (LLCs) by speculatively decompressing frequently used cachelines. To this end, we propose a Hot-cacheline Prediction and Early decompression (HoPE) mechanism that consists of three synergistic techniques: Hot-cacheline Prediction (HP), Early Decompression (ED), and Hit-history-based Insertion (HBI). HP and HBI efficiently identify the hot compressed cachelines, while ED selectively decompresses hot cachelines, based on their size information. Unlike previous approaches, the HoPE framework considers the performance balance/tradeoff between the increased effective cache capacity and the decompression penalty. To evaluate the effectiveness of the proposed HoPE mechanism, we run extensive simulations on memory traces obtained from multi-threaded benchmarks running on a full-system simulation framework. We observe significant performance improvements over compressed cache schemes employing the conventional Least-Recently Used (LRU) replacement policy, the Dynamic Re-Reference Interval Prediction (DRRIP) scheme, and the Effective Capacity Maximizer (ECM) compressed cache management mechanism. Specifically, HoPE exhibits system performance improvements of approximately 11%, on average, over LRU, 8% over DRRIP, and 7% over ECM by reducing the read-hit decompression penalty by around 65%, over a wide range of applications.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2604324491",
    "type": "article"
  },
  {
    "title": "Application-Specific Residential Microgrid Design Methodology",
    "doi": "https://doi.org/10.1145/3007206",
    "publication_date": "2017-04-03",
    "publication_year": 2017,
    "authors": "Korosh Vatanparvar; Mohammad Abdullah Al Faruque",
    "corresponding_authors": "",
    "abstract": "In power systems, the traditional, non-interactive, and manually controlled power grid has been transformed to a cyber-dominated smart grid. This cyber-physical integration has provided the smart grid with communication, monitoring, computation, and controlling capabilities to improve its reliability, energy efficiency, and flexibility. A microgrid is a localized and semi-autonomous group of smart energy systems that utilizes the above-mentioned capabilities to drive modern technologies such as electric vehicle charging, home energy management, and smart appliances. Design, upgrading, test, and verification of these microgrids can get too complicated to handle manually. The complexity is due to the wide range of solutions and components that are intended to address the microgrid problems. This article presents a novel Model-Based Design (MBD) methodology to model, co-simulate, design, and optimize microgrid and its multi-level controllers. This methodology helps in the design, optimization, and validation of a microgrid for a specific application. The application rules, requirements, and design-time constraints are met in the designed/optimized microgrid while the implementation cost is minimized. Based on our novel methodology, a design automation, co-simulation, and analysis tool, called GridMAT, is implemented. Our experiments have illustrated that implementing a hierarchical controller reduces the average power consumption by 8% and shifts the peak load for cost saving. Moreover, optimizing the microgrid design using our MBD methodology considering smart controllers has decreased the total implementation cost. Compared to the conventional methodology, the cost decreases by 14% and compared to the MBD methodology where smart controllers are not considered, it decreases by 5%.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2604604993",
    "type": "article"
  },
  {
    "title": "Design Methodology of Fault-Tolerant Custom 3D Network-on-Chip",
    "doi": "https://doi.org/10.1145/3054745",
    "publication_date": "2017-05-20",
    "publication_year": 2017,
    "authors": "Katherine Shu-Min Li; Sying-Jyan Wang",
    "corresponding_authors": "",
    "abstract": "A systematic design methodology is presented for custom Network-on-Chip (NoC) in three-dimensional integrated circuits (3D-ICs). In addition, fault tolerance is supported in the NoC if extra links are included in the NoC topology. In the proposed method, processors and the communication architecture are synthesized simultaneously in the 3D floorplanning process. 3D-IC technology enables ICs to be implemented in smaller size with higher performance; on the flip side, 3D-ICs suffer yield loss due to multiple dies in a 3D stack and lower manufacturing yield of through-silicon vias (TSVs). To alleviate this problem, a known-good-dies (KGD) test can be applied to ensure every die to be packaged into a 3D-IC is fault-free. However, faulty TSVs cannot be tested in the KGD test. In this article, the proposed method deals with the problem by providing fault tolerance in the NoC topology. The efficiency of the proposed method is evaluated using several benchmark circuits, and the experimental results show that the proposed method produces 3D NoCs with comparable performance than previous methods when fault-tolerant features are not realized. With fault tolerance in NoCs, higher yield can be achieved at the cost of performance penalty and elevated power level.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2619607385",
    "type": "article"
  },
  {
    "title": "Generation of Transparent-Scan Sequences for Diagnosis of Scan Chain Faults",
    "doi": "https://doi.org/10.1145/3007207",
    "publication_date": "2017-05-23",
    "publication_year": 2017,
    "authors": "Irith Pomeranz",
    "corresponding_authors": "Irith Pomeranz",
    "abstract": "Diagnosis of scan chain faults is important for yield learning and improvement. Procedures that generate tests for diagnosis of scan chain faults produce scan-based tests with one or more functional capture cycles between a scan-in and a scan-out operation. The approach to test generation referred to as transparent-scan has several advantages in this context. (1) It allows functional capture cycles and scan shift cycles to be interleaved arbitrarily. This increases the flexibility to assign to the scan cells values that are needed for diagnosis. (2) Test generation under transparent-scan considers a circuit model where the scan logic is included explicitly. Consequently, the test generation procedure takes into consideration the full effect of a scan chain fault. It thus produces accurate tests. (3) For the same reason, it can also target faults inside the scan logic. (4) Transparent-scan results in compact test sequences. Compaction is important because of the large volumes of fail data that scan chain faults create. The cost of transparent-scan is that it requires simulation procedures for sequential circuits, and that arbitrary sequences would be applicable to the scan select input. Motivated by the advantages of transparent-scan, and the importance of diagnosing scan chain faults, this article describes a procedure for generating transparent-scan sequences for diagnosis of scan chain faults. The procedure is also applied to produce transparent-scan sequences for diagnosis of faults inside the scan logic.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2620506035",
    "type": "article"
  },
  {
    "title": "Efficient Mapping of Applications for Future Chip-Multiprocessors in Dark Silicon Era",
    "doi": "https://doi.org/10.1145/3055202",
    "publication_date": "2017-06-15",
    "publication_year": 2017,
    "authors": "Mohaddeseh Hoveida; Fatemeh Aghaaliakbari; Ramin Bashizade; Mohammad Arjomand; Hamid Sarbazi‐Azad",
    "corresponding_authors": "",
    "abstract": "The failure of Dennard scaling has led to the utilization wall that is the source of dark silicon and limits the percentage of a chip that can actively switch within a given power budget. To address this issue, a structure is needed to guarantee the limited power budget along with providing sufficient flexibility and performance for different applications with various communication requirements. In this article, we present a general-purpose platform for future many-core Chip-Multiprocessors (CMPs) that benefits from the advantages of clustering, Network-on-Chip (NoC) resource sharing among cores, and power gating the unused components of clusters. We also propose two task mapping methods for the proposed platform in which active and dark cores are dispersed appropriately, so that an excess of power budget can be obtained. Our evaluations reveal that the first and second proposed mapping mechanisms respectively reduce the execution time by up to 28.6% and 39.2% and the NoC power consumption by up to 11.1% and 10%, and gain an excess power budget of up to 7.6% and 13.4% over the baseline architecture.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2625223005",
    "type": "article"
  },
  {
    "title": "A Novel Range Matching Architecture for Packet Classification Without Rule Expansion",
    "doi": "https://doi.org/10.1145/3105958",
    "publication_date": "2017-08-01",
    "publication_year": 2017,
    "authors": "Shanmugakumar Murugesan; Noor Mahammad Sk",
    "corresponding_authors": "",
    "abstract": "The speed requirement for the routing table lookup and the packet classification is rapidly increasing due to the increase in the number of packets needed to be processed per second. The hardware-based packet classification relies on ternary content addressable memory (TCAM) to meet this speed requirement. However, TCAM consumes huge power and also supports only for longest prefix match and exact match, where the classification rule also has a range match (RM) field. Hence, it is mandatory to encode the RM into prefix match to accommodate the rule in TCAM. In the worst case, one rule is encoded into (2 W -2) 2 rules (where W is a number of bits to represent range). This work proposes a novel RM architecture, and a detailed analysis about the range field on the standard dataset and the real-life classifier rules are presented. In the literature, the existing RM architecture is used to avoid the range to prefix conversion, but due to the serial operation, it lacks in performance. For constant time lookup, TCAM is the best option, but it does not support RM. The proposed architecture takes one clock cycle for RM and does not require any encoding/ conversion. Hence, there will be a single entry for every rule. It is observed that just 4% of the two-dimensional range rules are present in this dataset, and it will increase the rule set size by 4 times in the best case and nearly 30 times in the worst case. The proposed RM circuit is operated in parallel with TCAM without compromising the speed, and this circuit saves huge power around 70% and area around 61%, where the range to prefix conversion/encoding is completely avoided. The proposed architecture is well suited for current IPv4- and IPv6-based networks, as well as in software-defined networks in the near future.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2741462290",
    "type": "article"
  },
  {
    "title": "Optimal Don’t Care Filling for Minimizing Peak Toggles During At-Speed Stuck-At Testing",
    "doi": "https://doi.org/10.1145/3084684",
    "publication_date": "2017-08-31",
    "publication_year": 2017,
    "authors": "A. Satya Trinadh; Seetal Potluri; Sobhan Babu; V. Kamakoti; Shiv Govind Singh",
    "corresponding_authors": "",
    "abstract": "Due to the increase in manufacturing/environmental uncertainties in the nanometer regime, testing digital chips under different operating conditions becomes mandatory. Traditionally, stuck-at tests were applied at slow speed to detect structural defects and transition fault tests were applied at-speed to detect delay defects. Recently, it was shown that certain cell-internal defects can only be detected using at-speed stuck-at testing . Stuck-at test patterns are power hungry, thereby causing excessive voltage droop on the power grid, delaying the test response, and finally leading to false delay failures on the tester. This motivates the need for peak power minimization during at-speed stuck-at testing. In this article, we use input toggle minimization as a means to minimize a circuit’s power dissipation during at-speed stuck-at testing under the Combinational State Preservation scan (CSP-scan) Design-For-Testability (DFT) scheme. For circuits whose test sets are dominated by don’t cares, this article maps the problem of optimal X-filling for peak input toggle minimization to a variant of the interval coloring problem and proposes a Dynamic Programming (DP) algorithm (DP-fill) for the same along with a theoretical proof for its optimality. For circuits whose test sets are not dominated by don’t cares, we propose a max scatter Hamiltonian path algorithm, which ensures that the ordering is done such that the don’t cares are evenly distributed in the final ordering of test cubes, thereby leading to better input toggle savings than DP-fill. The proposed algorithms, when experimented on ITC99 benchmarks, produced peak power savings of up to 48% over the best-known algorithms in literature. We have also pruned the solutions thus obtained using Greedy and Simulated Annealing strategies with iterative 1-bit neighborhood to validate our idea of optimal input toggle minimization as an effective technique for minimizing peak power dissipation during at-speed stuck-at testing.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2752142607",
    "type": "article"
  },
  {
    "title": "Adaptive Generation of Unique IDs for Digital Chips through Analog Excitation",
    "doi": "https://doi.org/10.1145/2732408",
    "publication_date": "2015-06-24",
    "publication_year": 2015,
    "authors": "Chandra K. H. Suresh; Sule Ozev; Ozgur Sinanoglu",
    "corresponding_authors": "",
    "abstract": "Globalization of the integrated circuit design and manufacturing flow has successfully ameliorated design complexity and fabrication cost challenges, and helped deliver cost-effective products while meeting stringent time-to-market requirements. On the flip side, it has resulted in various forms of security vulnerabilities in the supply chain that involves designers, fabs, test facilities, and distributors until the end-product reaches customers. One of the biggest threats to semiconductor industry today is the entry of aged, reject, or cloned parts, that is, counterfeit chips, into the supply chain, leading to annual revenue losses in the order of billions of dollars. While traceability of chips between trusted parties can help monitor the supply chain at various points in the flow, existing solutions are in the form of integrating costly hardware units on chip, or utilizing easy-to-circumvent inspection-based detection techniques. In this article, we propose a technique for adaptive unique ID generation that leverages process variations, enabling chip traceability. The proposed method stimulates digital chips with an analog signal from the supply lines, which serve as primary inputs to each gate in the signal path. Using a sinusoidal signal that exercises the transistors as gain components, we create a chip-specific response that can be post-processed into a digital ID. The proposed technique enables quick and cost-effective authenticity validation that requires no on-chip hardware support. Our simulation and experimentation on actual chips show that the proposed technique is capable of generating unique IDs even in the presence of environmental noise.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W1418844487",
    "type": "article"
  },
  {
    "title": "Integrated Resource Allocation and Binding in Clock Mesh Synthesis",
    "doi": "https://doi.org/10.1145/2611762",
    "publication_date": "2014-06-01",
    "publication_year": 2014,
    "authors": "Minseok Kang; Taewhan Kim",
    "corresponding_authors": "",
    "abstract": "The clock distribution network in a synchronous digital circuit delivers a clock signal to every storage element, that is, clock sink in the circuit. However, since the continued technology scaling increases PVT (process-voltage-temperature) variation, the increase of clock-skew variation is highly likely to cause performance degradation or system failure at runtime. Recently, to mitigate the clock-skew variation, many researchers have taken a profound interest in the clock mesh network. However, though the structure of the clock mesh network is excellent in tolerating timing variations, it demands significantly high power consumption due to the use of excessive mesh wire and buffer resources. Thus, optimizing the resources required in the mesh clock synthesis while maintaining the variation tolerance is crucially important. The three major tasks that greatly affect the cost of the resulting clock mesh are: (1) mesh segment allocation , (2) mesh buffer allocation and sizing , and (3) clock sink binding to mesh segments . Previous clock mesh optimization approaches solve the three tasks sequentially, one by one at a time, to manage the runtime complexity of the tasks at the expense of losing the quality of results. However, since the three tasks are tightly interrelated, simultaneously optimizing all three tasks is essential, if the runtime is ever permitted, to synthesize an economical clock mesh network. In this work, we propose an approach that is able to tackle the problem in an integrated fashion by combining the three tasks into an iterative framework of incremental updates and solving them simultaneously to find a globally optimal allocation of mesh resources while taking into account the clock-skew tolerance constraints. The core parts of this work are a precise analysis on the relation among the resource optimization tasks and an establishment of a mechanism for effective and efficient integration of the tasks. In particular, to handle the runtime problem, we propose a set of speedup techniques, that is, modeling the RC circuit for eliminating redundant matrix multiplications, exploiting a sliding-window scheme, and quickly estimating the buffer sizing effect, which are fitted into our context of fast clock-skew estimation in mesh resource optimization as well as an invention of early decision policies. Through extensive experiments with benchmark circuits, it is shown that our proposed clock mesh synthesizer is able to reduce the worst-case clock skew, total mesh wirelength, total size of mesh driving buffers, and total clock mesh power consumption including short-circuit power by 25.0%, 13.2%, 10.9%, and 11.0% on average compared to that produced by the best-known clock mesh synthesis method (MeshWorks), respectively.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W1978849206",
    "type": "article"
  },
  {
    "title": "<i>SPMCloud</i>",
    "doi": "https://doi.org/10.1145/2611755",
    "publication_date": "2014-06-01",
    "publication_year": 2014,
    "authors": "Luis Angel D. Bathen; Nikil Dutt",
    "corresponding_authors": "",
    "abstract": "The era of cloud computing on-a-chip is enabled by the aggressive move towards many-core platforms and the rapid adoption of Network-on-Chips. As a result, there is a need for large-scale distributed on-chip shared memories that are reliable, low power, and seamlessly manageable. In this work, we propose SPMCloud , a novel scratchpad-memory-based cloud-inspired volatile storage subsystem designed to meet the needs of future-generation many-core platforms. SPMCloud is composed of several concepts, including: (1) a highly scalable data-center-like memory subsystem that exploits two enterprise-network-inspired memory configurations, namely, embedded Network Attached Storage ( eNAS ) and embedded Storage Area Network ( eSAN ), and (2) on-demand allocation of reliable memory space through memory virtualization and the use of embedded RAIDs. Our experimental results on Mediabench/CHStone benchmarks show that the SPMCloud 's fully distributed reliable memory subsystems can achieve 48% energy savings and 70% latency reduction on average over state-of-the-art NoC memory reliability techniques. We then evaluate the scalability of the SPMCloud and compare it with traditional SPM allocation policies. The SPMCloud 's dynamic allocator outperforms the best competition by an average 60% ( eNAS ) and 46% ( eSAN ) when the platform runs at 250 MHz and by an average 80% ( eNAS ) and 40% when running at 1 GHz. Moreover, the SPMCloud achieves an average 83% energy savings across all configurations (number of cores) with respect to the best competitors when running at 250 MHz and 1 GHz. We then studied the SPM hit ratio across the various allocation policies discussed in this article and showed that on average the SPMCloud 's priority-driven dynamic allocation policy achieves 93.5% SPM hit ratio, 0.6% higher hit ratio than the closest allocation policy. We then showed that the eNAS and eSAN achieve an average of 67.9% and 29% reduction in execution time, respectively, over the best competitor. Similarly, the eNAS and eSAN achieve an average of 82.7% and 82.3% energy savings, respectively, over the best competitor. Furthermore, we evaluated the scalability of the SPMCloud and its performance/energy efficiency when providing support for some of the heavier E-RAID levels, and showed that the eNAS / eSAN configurations with SECDED achieve an average of 51.5% and 34.9% reduction in execution time, respectively, over the best competitor with SECDED. Similarly, the eNAS / eSAN configurations with E-RAID Level 1, + SECDED achieve an average of 82.3% and 75.6% energy savings, respectively, over the best competitor.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2008282197",
    "type": "article"
  },
  {
    "title": "A Formal Approach to Incremental Converter Synthesis for System-on-Chip Design",
    "doi": "https://doi.org/10.1145/2663344",
    "publication_date": "2014-11-18",
    "publication_year": 2014,
    "authors": "Roopak Sinha; Alain Girault; Gregor Goessler; Partha S. Roop",
    "corresponding_authors": "",
    "abstract": "A system-on-chip (SoC) contains numerous intellectual property blocks, or IPs. Protocol mismatches between IPs may affect the system-level functionality of the SoC. Mismatches are addressed by introducing converters to control inter-IP interactions. Current approaches towards converter generation find limited practical application as they use restrictive models, lack formal rigour, handle a small subset of commonly encountered mismatches, and/or are not scalable. We propose a formal technique for SoC design using incremental converter synthesis . The proposed formulation provides precise models for protocols and requirements, and provides a scalable algorithm that allows adding multiple components and requirements to an SoC incrementally. We prove that the technique is sound and complete. Experimental results obtained using real-life AMBA benchmarks show the scalability and wide range of mismatches handled by our approach.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2042491290",
    "type": "article"
  },
  {
    "title": "Multilevel Simulation of Nonfunctional Properties by Piecewise Evaluation",
    "doi": "https://doi.org/10.1145/2647955",
    "publication_date": "2014-08-01",
    "publication_year": 2014,
    "authors": "Nadereh Hatami; Rafał Baranowski; P. Prinetto; Hans-Joachim Wunderlich",
    "corresponding_authors": "",
    "abstract": "As the technology shrinks, nonfunctional properties (NFPs) such as reliability, vulnerability, power consumption, or heat dissipation become as important as system functionality. As NFPs often influence each other, depend on the application and workload of a system, and exhibit nonlinear behavior, NFP simulation over long periods of system operation is computationally expensive, if feasible at all. This article presents a piecewise evaluation method for efficient NFP simulation. Simulation time is divided into intervals called evaluation windows , within which the NFP models are partially linearized. High-speed functional system simulation is achieved by parallel execution of models at different levels of abstraction. A trade-off between simulation speed and accuracy is met by adjusting the size of the evaluation window. As an example, the piecewise evaluation technique is applied to analyze aging caused by two mechanisms, namely Negative Bias Temperature Instability (NBTI) and Hot Carrier Injection (HCI), in order to identify reliability hotspots. Experiments show that the proposed technique yields considerable simulation speedup at a marginal loss of accuracy.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2074256516",
    "type": "article"
  },
  {
    "title": "Constructing Large and Fast On-Chip Cache for Mobile Processors with Multilevel Cell STT-MRAM Technology",
    "doi": "https://doi.org/10.1145/2764903",
    "publication_date": "2015-09-28",
    "publication_year": 2015,
    "authors": "Lei Jiang; Bo Zhao; Jun Yang; Youtao Zhang",
    "corresponding_authors": "",
    "abstract": "Modern mobile processors integrating an increasing number of cores into one single chip demand large-capacity, on-chip, last-level caches (LLCs) in order to achieve scalable performance improvements. However, adopting traditional memory technologies such as SRAM and embedded DRAM (eDRAM) leakage and scalability problems. Spin-transfer torque magnetic RAM (STT-MRAM) is a novel nonvolatile memory technology that has emerged as a promising alternative for constructing on-chip caches in high-end mobile processors. STT-MRAM has many advantages, such as short read latency, zero leakage from the memory cell, and better scalability than eDRAM and SRAM. Multilevel cell (MLC) STT-MRAM further enlarges capacity and reduces per-bit cost by storing more bits in one cell. However, MLC STT-MRAM has long write latency which limits the effectiveness of MLC STT-MRAM-based LLCs. In this article, we address this limitation with three novel designs: line pairing (LP), line swapping (LS), and dynamic LP/LS enabler (DLE). LP forms fast cache lines by reorganizing MLC soft bits which are faster to write. LS dynamically stores frequently-written data into these fast cache lines. We then propose a dynamic LP/LS enabler (DLE) to enable LP and LS only if they help to improve the overall cache performance. Our experimental results show that the proposed designs improve system performance by 9--15% and reduce energy consumption by 14--21% for various types of mobile processors.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2074836897",
    "type": "article"
  },
  {
    "title": "WaveSync",
    "doi": "https://doi.org/10.1145/2647950",
    "publication_date": "2014-08-01",
    "publication_year": 2014,
    "authors": "Yoon Seok Yang; Reeshav Kumar; Gwan Choi; Paul V. Gratz",
    "corresponding_authors": "",
    "abstract": "WaveSync is a network-on-chip architecture for a globally asynchronous locally-synchronous (GALS) design. The WaveSync design facilitates low-latency communication leveraging the source-synchronous clock sent along with the data to time components in the datapath of a downstream router, reducing the number of synchronizations needed. WaveSync accomplishes this by partitioning the router components at each node into different clock domains, each synchronized with one of the orthogonal incoming source-synchronous clocks in a GALS 2D mesh network. The data and clock subsequently propagate through each node/router synchronously until the destination is reached, regardless of the number of hops this may take. As long as the data travels in the path of clock propagation and no congestion is encountered, it will be propagated without latching as if in a long combinatorial path, with both the clock and the data accruing delay at the same rate. The result is that the need for synchronization between the mesochronous nodes and/or the asynchronous control associated with the typical GALS network is completely eliminated. To further reduce the latency overhead of synchronization, for those occasions when synchronization is still required (when a flit takes a turn or arrives at the destination), we propose a novel less-than-one-cycle synchronizer. The proposed WaveSync network outperforms conventional GALS networks by 87--90% in average latency, synthesized using a 45nm CMOS library.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2130311883",
    "type": "article"
  },
  {
    "title": "DARP-MP",
    "doi": "https://doi.org/10.1145/2755558",
    "publication_date": "2015-12-02",
    "publication_year": 2015,
    "authors": "Hu Chen; Sanghamitra Roy; Koushik Chakraborty",
    "corresponding_authors": "",
    "abstract": "In this article, we demonstrate that the sensitized path delays in various microprocessor pipe stages exhibit intriguing temporal and spatial variations during the execution of real-world applications. To effectively exploit these delay variations, we propose dynamically adaptable resilient pipeline (DARP)—a series of runtime techniques to boost power-performance efficiency and fault tolerance in a pipelined microprocessor. DARP employs early error prediction to avoid a major portion of the timing errors. We combine DARP with the state-of-art topologically homogeneous and power-performance heterogeneous (THPH) architecture to build up a new frontier for the energy efficiency of multicore processors (DARP-MP). Using a rigorous circuit-architectural infrastructure, we demonstrate that DARP substantially improves the multicore processor performance (9.4--20%) and energy efficiency (10--28.6%) compared to state-of-the-art techniques. The energy-efficiency improvements of DARP-MP are 42% and 49.9% compared against the original THPH and another state-of-art multicore power management scheme, respectively.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2183118678",
    "type": "article"
  },
  {
    "title": "Layout Decomposition with Pairwise Coloring and Adaptive Multi-Start for Triple Patterning Lithography",
    "doi": "https://doi.org/10.1145/2764904",
    "publication_date": "2015-12-02",
    "publication_year": 2015,
    "authors": "Ye Zhang; Wai-Shing Luk; Yunfeng Yang; Hai Zhou; Changhao Yan; David Z. Pan; Xuan Zeng",
    "corresponding_authors": "",
    "abstract": "In this article we present a pairwise coloring (PWC) approach to tackle the layout decomposition problem for triple patterning lithography (TPL). The main idea is to reduce the problem to a set of bi-coloring problems. The overall solution is refined by applying a bi-coloring method for pairs of color sets per pass. One obvious advantage of this method is that the existing double patterning lithography (DPL) techniques can be reused effortlessly. Moreover, we observe that each pass can be fulfilled efficiently by integrating an SPQR-tree-graph-division-based bi-coloring method. In addition, to prevent the solution getting stuck in the local minima, an adaptive multi-start (AMS) approach is incorporated. Adaptive starting points are generated according to the vote of previous solutions. The experimental results show that our method is competitive with other works on both solution quality and runtime performance.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2184406719",
    "type": "article"
  },
  {
    "title": "Adaptive Burst-Writes (ABW)",
    "doi": "https://doi.org/10.1145/2753757",
    "publication_date": "2015-12-02",
    "publication_year": 2015,
    "authors": "Hsiang-Yun Cheng; M.J. Irwin; Yuan Xie",
    "corresponding_authors": "",
    "abstract": "Main memory latencies have become a major performance bottleneck for chip-multiprocessors (CMPs). Since reads are on the critical path, existing memory controllers prioritize reads over writes. However, writes must be eventually processed when the write queue is full. These writes are serviced in a burst to reduce the bus turnaround delay and increase the row-buffer locality. Unfortunately, a large number of reads may suffer long queuing delay when the burst-writes are serviced. The long write latency of future nonvolatile memory will further exacerbate the long queuing delay of reads during burst-writes. In this article, we propose a run-time mechanism, Adaptive Burst-Writes (ABW), to reduce the queuing delay of reads. Based on the row-buffer hit rate of writes and the arrival rate of reads, we dynamically control the number of writes serviced in a burst to trade off the write service time and the queuing latency of reads. For prompt adjustment, our history-based mechanism further terminates the burst-writes earlier when the row-buffer hit rate of writes in the previous burst-writes is low. As a result, our policy improves system throughput by up to 28% (average 10%) and 43% (average 14%) in CMPs with DRAM-based and PCM-based main memory.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2186359646",
    "type": "article"
  },
  {
    "title": "Enhanced Test Compaction for Multicycle Broadside Tests by Using State Complementation",
    "doi": "https://doi.org/10.1145/2778953",
    "publication_date": "2015-12-02",
    "publication_year": 2015,
    "authors": "Irith Pomeranz",
    "corresponding_authors": "Irith Pomeranz",
    "abstract": "Multicycle tests support test compaction by allowing each test to detect more target faults. The ability of multicycle broadside tests to provide test compaction depends on the ability of primary input sequences to take the circuit between pairs of states that are useful for detecting target faults. This ability can be enhanced by adding design-for-testability (DFT) logic that allows states to be complemented. This article describes a test compaction procedure that uses such DFT logic to form a compact multicycle broadside test set for transition faults where the tests use constant primary input vectors. The use of complemented states also allows the procedure to increase the transition fault coverage beyond the transition fault coverage of a broadside test set. The procedure has the option of increasing the switching activity of the tests gradually in order to explore the tradeoff between the number of tests, the fault coverage, and the switching activity.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2190312426",
    "type": "article"
  },
  {
    "title": "TSocket",
    "doi": "https://doi.org/10.1145/2837023",
    "publication_date": "2016-01-28",
    "publication_year": 2016,
    "authors": "Guoqing Chen; Yi Xu; Xing Hu; Xiangyang Guo; Jun Ma; Yu Hu; Yuan Xie",
    "corresponding_authors": "",
    "abstract": "As technology scales, thermal management for multicore architectures becomes a critical challenge due to increasing power density. Existing power budgeting techniques focus on maximizing performance under a given power budget by optimizing the core configurations. In multicore era, a chip-wide power budget, however, is not sufficient to ensure thermal constraints because the thermal sustainable power capacity varies with different threading strategies and core configurations. In this article, we propose two models to dynamically estimate the thermal sustainable power capacity in homogeneous multicore systems: uniform power model and nonuniform power model . These two models convert the thermal effect of threading strategies and core configurations into power capacity, which provide a context-based core power capacity for power budgeting. Based on these models, we introduce a power budgeting framework aiming to improve the performance within thermal constraints, named as TSocket. Compared to the chip-wide power budgeting solution, TSocket shows 19% average performance improvement for the PARSEC benchmarks in single program scenario and up to 11% performance improvement in multiprogram scenario. The performance improvement is achieved by reducing thermal violations and exploring thermal headrooms.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2262056517",
    "type": "article"
  },
  {
    "title": "Construction of Reconfigurable Clock Trees for MCMM Designs Using Mode Separation and Scenario Compression",
    "doi": "https://doi.org/10.1145/2883609",
    "publication_date": "2016-05-18",
    "publication_year": 2016,
    "authors": "Rickard Ewetz; Cheng‐Kok Koh",
    "corresponding_authors": "",
    "abstract": "The clock networks of many modern circuits have to operate in multiple corners and multiple modes (MCMM). We propose to construct mode-reconfigurable clock trees (MRCTs) based on mode separation and scenario compression. The technique of scenario compression is proposed to consider the timing constraints in multiple scenarios at the same time, compressing the MCMM problem into an equivalent single-corner multiple-mode (SCMM), or single-corner single-mode (SCSM) problem. The compression is performed by combining the skew constraints of the different scenarios in skew constraint graphs based on delay linearization and dominating skew constraints. An MRCT consists of several clock trees and mode separation involves, depending on the active mode, selecting one of the clock trees to deliver the clock signal. To limit the overhead, the bottom part (closer to the clock sinks) of all the different clock trees are shared and only the top part (closer to the clock source) of the clock network is mode reconfigurable. The reconfiguration is realized using OR-gates and a one-input-multiple-output demultiplexer. The experimental results show that for a set of synthesized MCMM circuits, with 715 to 13, 216 sequential elements, the proposed approach can achieve high yield.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2400862933",
    "type": "article"
  },
  {
    "title": "Index-Resilient Zero-Suppressed BDDs",
    "doi": "https://doi.org/10.1145/2905363",
    "publication_date": "2016-05-18",
    "publication_year": 2016,
    "authors": "Anna Bernasconi; Valentina Ciriani",
    "corresponding_authors": "",
    "abstract": "Zero-Suppressed Binary Decision Diagrams (ZDDs) are widely used data structures for representing and handling combination sets and Boolean functions. In particular, ZDDs are commonly used in CAD for the synthesis and verification of integrated circuits. The purpose of this article is to design an error-resilient version of this data structure: a self-repairing ZDD. More precisely, we design a new ZDD canonical form, called index-resilient reduced ZDD, such that a faulty index can be reconstructed in time O ( k ), where k is the number of nodes with a corrupted index. Moreover, we propose new versions of the standard algorithms for ZDD manipulation and construction that are error resilient during their execution and produce an index-resilient ZDD as output. The experimental results validate the proposed approach.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2403791807",
    "type": "article"
  },
  {
    "title": "Efficient Algorithms for Discrete Gate Sizing and Threshold Voltage Assignment Based on an Accurate Analytical Statistical Yield Gradient",
    "doi": "https://doi.org/10.1145/2896819",
    "publication_date": "2016-05-18",
    "publication_year": 2016,
    "authors": "S Ramprasath; V. Vasudevan",
    "corresponding_authors": "",
    "abstract": "In this article, we derive a simple and accurate expression for the change in timing yield due to a change in the gate delay distribution. It is based on analytical bounds that we have derived for the moments of the circuit and path delay. Based on this, we propose computationally efficient algorithms for (1) discrete gate sizing and (2) simultaneous gate sizing and threshold voltage ( V T ) assignment so that the circuit meets a timing yield specification under parameter variations. The use of this analytical yield gradient within a gradient-based timing yield optimization algorithm results in a significant improvement in the runtime as compared to the numerical method, while achieving the same final yield. It also allows us to explore a larger search space in each iteration more efficiently, which is required in the case of simultaneous resizing and V T assignment. We also propose heuristics for resizing/changing the V T of multiple gates in each iteration. This makes it possible to optimize the timing yield for large circuits. Results on ITC ’99 benchmarks show that the proposed multinode resizing algorithm results in a significant improvement in the runtime with a marginal average area penalty and no cost to the final yield achieved.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2407955805",
    "type": "article"
  },
  {
    "title": "Area-Aware Decomposition for Single-Electron Transistor Arrays",
    "doi": "https://doi.org/10.1145/2898998",
    "publication_date": "2016-09-14",
    "publication_year": 2016,
    "authors": "Ching-Hsuan Ho; Yung‐Chih Chen; Chun-Yao Wang; Ching-Yi Huang; Suman Datta; Vijaykrishnan Narayanan",
    "corresponding_authors": "",
    "abstract": "Single-electron transistor (SET) at room temperature has been demonstrated as a promising device for extending Moore’s law due to its ultra-low power consumption. Existing SET synthesis methods synthesize a Boolean network into a large reconfigurable SET array where the height of SET array equals the number of primary inputs. However, recent experiments on device level have shown that this height is restricted to a small number, say, 10, rather than arbitrary value due to the ultra-low driving strength of SET devices. On the other hand, the width of an SET array is also suggested to be a small value. Consequently, it is necessary to decompose a large SET array into a set of small SET arrays where each of them realizes a sub-function of the original circuit with no more than 10 inputs. Thus, this article presents two techniques for achieving area-efficient SET array decomposition: One is a width minimization algorithm for reducing the area of a single SET array; the other is a depth-bounded mapping algorithm, which decomposes a Boolean network into many sub-functions such that the widths of the corresponding SET arrays are balanced. The width minimization algorithm leads to a 25%--41% improvement compared to the state of the art, and the mapping algorithm achieves a 60% reduction in total area compared to a naïve approach.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2520542486",
    "type": "article"
  },
  {
    "title": "Scalable SMT-Based Equivalence Checking of Nested Loop Pipelining in Behavioral Synthesis",
    "doi": "https://doi.org/10.1145/2953879",
    "publication_date": "2016-12-26",
    "publication_year": 2016,
    "authors": "Mohammad Azarbad; Bijan Alizadeh",
    "corresponding_authors": "",
    "abstract": "In this article, we present a novel methodology based on SMT-solvers to verify equality of a high-level described specification and a pipelined RTL implementation produced by a high-level synthesis tool. The complex transformations existing in the high-level synthesis process, such as nested loop pipelining, cause the conventional methods of equivalence checking to be inefficient. The proposed equivalence checking method simultaneously attacks the two problems in this context: (1) state space explosion and (2) complex high-level synthesis transformations. To show the scalability and efficiency of the proposed method, the verification results of large designs are compared with those of the SAT-based method, including three different state-of-the-art SAT-solvers: the SMT-based procedure, the modular Horner expansion diagram (M-HED)-based method, and the M-HED partitioning approach. The results show 2470×, 2540×, and 142× average memory usage reduction and 252×, 28×, and 914× speedup in comparison with M-HED, M-HED partitioning, and SMT-solver without using the proposed method, respectively.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2567559802",
    "type": "article"
  },
  {
    "title": "A PPA Study of Reinforced Placement Parameter Autotuning: Pseudo-3D vs. True-3D Placers",
    "doi": "https://doi.org/10.1145/3582007",
    "publication_date": "2023-01-21",
    "publication_year": 2023,
    "authors": "Gauthaman Murali; Anthony Agnesina; Sung Kyu Lim",
    "corresponding_authors": "",
    "abstract": "D Place and Route (P&amp;R) flows either involve true-3D placement algorithms or use commercial 2D tools to transform a 2D design into a 3D design. Irrespective of the nature of the placers, several placement parameters in these tools affect the quality of the final 3D designs. Different parameter settings work well with different circuits, and it is impossible to manually tune them for a particular circuit. Automated approaches involving reinforcement learning have been shown to adapt and learn the parameter settings and create trained models. However, their effectiveness depends on the input dataset quality. Using a set of 10 netlists and 10–21 handpicked placement parameters in P&amp;R flows involving pseudo-3D or true-3D placement, the dataset quality is analyzed. The datasets are the design metrics obtained through different P&amp;R stages, such as placement optimization, clock tree synthesis, or 3D partitioning and global routing. The training runtime and the quality of the final design metrics are compared. On a pseudo-3D flow, the training takes around 126–290 hours, whereas, on a true-3D placer-based flow, it takes around 305–410 hours. It is observed that the datasets obtained from different stages lead to drastically different final design results. With the RL-based training processes, the quality of results in 3D designs improves by up to 23.7% compared to their corresponding untrained P&amp;R flows.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4317659172",
    "type": "article"
  },
  {
    "title": "A Generalized Methodology for Well Island Generation and Well-tap Insertion in Analog/Mixed-signal Layouts",
    "doi": "https://doi.org/10.1145/3580477",
    "publication_date": "2023-03-13",
    "publication_year": 2023,
    "authors": "S Ramprasath; Meghna Madhusudan; Arvind Sharma; Jitesh Poojary; Soner Yaldiz; Ramesh Harjani; Steven M. Burns; Sachin S. Sapatnekar",
    "corresponding_authors": "",
    "abstract": "Well island generation and well tap placement is an important problem in analog/mixed-signal (AMS) circuits. Well taps can only prevent latchups within a certain radius of influence within a well island, and hence must be appropriately inserted to cover all devices. However, existing automated AMS layout paradigms typically defer the insertion of well taps and creation of well islands to a post-processing step after placement. This alters the placement, resulting in increased area and wire length, as well as circuit performance degradation. Therefore, there is a strong need for a solution that generates well islands and inserts well taps during placement so the placer can account for well overheads in optimizing placement metrics. In this work, we propose a modular solution using a graph-based optimization scheme that can be used within multiple placement paradigms with minimal intrusion. We demonstrate the integration of this scheme into stochastic, analytical, and designer-driven row-based placement. The method is demonstrated in advanced FinFET technologies. Layouts generated using this scheme show better area, wire length, and performance metrics at the cost of a marginal runtime degradation when compared to the post-processing approach. Using our scheme, there is an average improvement of 3% and 4% and a maximum improvement of 23% and 11% in area and wirelength, respectively, of layouts of various classes of AMS circuits at the cost of 17% average and 29% maximum increase in total runtime.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4324049384",
    "type": "article"
  },
  {
    "title": "DRC-SG 2.0: Efficient Design Rule Checking Script Generation via Key Information Extraction",
    "doi": "https://doi.org/10.1145/3594666",
    "publication_date": "2023-05-06",
    "publication_year": 2023,
    "authors": "Binwu Zhu; Xinyun Zhang; Yibo Lin; Bei Yu; Martin C. S. Wong",
    "corresponding_authors": "",
    "abstract": "Design Rule Checking (DRC) is a critical step in integrated circuit design. DRC requires formatted scripts as the input to design rule checkers. However, these scripts are manually generated in the foundry, which is tedious and error prone for generation of thousands of rules in advanced technology nodes. To mitigate this issue, we propose the first DRC script generation framework, leveraging a deep learning-based key information extractor to automatically identify essential arguments from rules and a script translator to organize the extracted arguments into executable DRC scripts. We further enhance the performance of the extractor with three specific design rule generation techniques and a multi-task learning-based rule classification module. Experimental results demonstrate that the framework can generate a single rule script in 5.46 ms on average, with the extractor achieving 91.1% precision and 91.8% recall on the key information extraction. Compared with the manual generation, our framework can significantly reduce the turnaround time and speed up process design closure.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4372353003",
    "type": "article"
  },
  {
    "title": "Test Compression for Launch-on-Capture Transition Fault Testing",
    "doi": "https://doi.org/10.1145/3597433",
    "publication_date": "2023-05-16",
    "publication_year": 2023,
    "authors": "Dong Xiang",
    "corresponding_authors": "Dong Xiang",
    "abstract": "A new low-power test compression scheme, called Dcompress , is proposed for launch-on-capture transition fault testing by using a new seed encoding scheme, a new design for testability architecture, and a new low-power test application procedure. The new seed encoding scheme generates seeds for all tests by selecting a primitive polynomial that encodes all tests of a compact test set. A software-defined linear feedback shift register architecture, called SLFSR , is proposed to make the new method conform to the current flow of design and test. Experimental results on benchmark circuits show that test data volume can be compressed up to 6300X with the well-compacted baseline test set for a design with 11.8M gates and more than 1.1M scan flip-flops.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4376643806",
    "type": "article"
  },
  {
    "title": "Dynamic Power Management in Large Manycore Systems: A Learning-to-Search Framework",
    "doi": "https://doi.org/10.1145/3603501",
    "publication_date": "2023-06-06",
    "publication_year": 2023,
    "authors": "Gaurav Narang; Aryan Deshwal; Raid Ayoub; Michael Kishinevsky; Janardhan Rao Doppa; Partha Pratim Pande",
    "corresponding_authors": "",
    "abstract": "The complexity of manycore System-on-chips (SoCs) is growing faster than our ability to manage them to reduce the overall energy consumption. Further, as SoC design moves toward three-dimensional (3D) architectures, the core's power density increases leading to unacceptable high peak chip temperatures. In this article, we consider the optimization problem of dynamic power management (DPM) in manycore SoCs for an allowable performance penalty (say, 5%) and admissible peak chip temperature. We employ a machine learning– (ML) based DPM policy, which selects the voltage/frequency levels for different cluster of cores as a function of the application workload features such as core computation and inter-core traffic, and so on. We propose a novel learning-to-search (L2S) framework to automatically identify an optimized sequence of DPM decisions from a large combinatorial space for joint energy-thermal optimization for one or more given applications. The optimized DPM decisions are given to a supervised learning algorithm to train a DPM policy, which mimics the corresponding decision-making behavior. Our experiments on two different manycore architectures designed using wireless interconnect and monolithic 3D demonstrate that principles behind the L2S framework are applicable for more than one configuration. Moreover, L2S-based DPM policies achieve up to 30% energy-delay product savings and reduce the peak chip temperature by up to 17 °C compared to the state-of-the-art ML methods for an allowable performance overhead of only 5%.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4379513488",
    "type": "article"
  },
  {
    "title": "Improving the Performance of CNN Accelerator Architecture under the Impact of Process Variations",
    "doi": "https://doi.org/10.1145/3604236",
    "publication_date": "2023-06-08",
    "publication_year": 2023,
    "authors": "Jingweijia Tan; Weiren Wang; Maodi Ma; Xiaohui Wei; Kaige Yan",
    "corresponding_authors": "",
    "abstract": "Convolutional neural network (CNN) accelerators are popular specialized platforms for efficient CNN processing. As semiconductor manufacturing technology scales down to nano scale, process variation dramatically affects the chip’s quality. Process variation causes delay variation within the chip due to transistor parameter differences. CNN accelerators adopt a large number of processing elements (PEs) for parallel computing, which are highly susceptible to process variation effects. Fast CNN processing desires consistent performance among PEs; otherwise the processing speed is limited by the slowest PE within the chip. In this work, we first quantitatively model and analyze the impact of process variation on CNN accelerators’ operating frequency. We further analyze the utilization of CNN accelerators and the characteristics of CNN models. We then leverage the PE underutilization to propose a sub-matrix reformation mechanism and leverage the pixel similarity of images to propose a weight transfer technique. Both techniques are able to tolerate the low-frequency PEs and achieve performance improvement at chip level. Furthermore, a novel resilience-aware mapping technique that exploits the diversity in the importance of weights is also proposed to improve the performance. Evaluation results show that our techniques are able to achieve significant processing speed improvement with negligible accuracy loss.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4380049117",
    "type": "article"
  },
  {
    "title": "ProtFe: Low-Cost Secure Power Side-Channel Protection for General and Custom FeFET-Based Memories",
    "doi": "https://doi.org/10.1145/3604589",
    "publication_date": "2023-06-17",
    "publication_year": 2023,
    "authors": "Taixin Li; Boran Sun; Hongtao Zhong; Yixin Xu; Vijaykrishnan Narayanan; Liang Shi; Tianyi Wang; Yao Yu; Thomas Kämpfe; Kai Ni; Huazhong Yang; Xueqing Li",
    "corresponding_authors": "",
    "abstract": "Ferroelectric Field Effect Transistors (FeFETs) have spurred increasing interest in both memories and computing applications, thanks to their CMOS compatibility, low-power operation, and high scalability. However, new security threats to the FeFET-based memories also arise. A major threat is the power analysis side-channel attack (P-SCA), which exploits the power traces of the memory access to obtain data information. There have been several effective efforts on resistive nonvolatile memories (NVMs), but they fail to meet the requirements for secure FeFET-based memories due to the different capacitive FeFETs load. Directly applying these existing countermeasures to the P-SCA protection for FeFETs induces huge challenges, especially for the balance between power side-channel resistance and corresponding overheads. To address this issue, we leverage the unique features of FeFETs and propose ProtFe , namely the protection methods for FeFET-based memories, including the pipelined multi-step write strategy ( PiMWrite ) and the split array design ( SpA ). PiMWrite is proposed for general FeFET-based memories, and inserts specially designed intermediate states to mitigate information leakage with pipelined steps to reduce overheads. SpA is proposed for custom FeFET-based memories, and simultaneously writes two split portions of the array with shared minimized peripherals to go beyond the balance between security and overheads. Simulation results show that PiMWrite expands the search space of a single power trace to 21× and involves nearly zero hardware penalties. SpA presents 33× search space improvement with negligible latency, 0.6% area, and only 7.1% energy overhead. ProtFe achieves improved balance between security and overheads, compared with the state-of-the-art works.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4381053943",
    "type": "article"
  },
  {
    "title": "Yield Optimization for Analog Circuits over Multiple Corners via Bayesian Neural Networks: Enhancing Circuit Reliability under Environmental Variation",
    "doi": "https://doi.org/10.1145/3626321",
    "publication_date": "2023-10-06",
    "publication_year": 2023,
    "authors": "Nanlin Guo; Fulin Peng; Jiahe Shi; Fan Yang; Jun Tao; Xuan Zeng",
    "corresponding_authors": "",
    "abstract": "The reliability of circuits is significantly affected by process variations in manufacturing and environmental variation during operation. Current yield optimization algorithms take process variations into consideration to improve circuit reliability. However, the influence of environmental variations (e.g., voltage and temperature variations) is often ignored in current methods because of the high computational cost. In this article, a novel and efficient approach named BNN-BYO is proposed to optimize the yield of analog circuits in multiple environmental corners. First, we use a Bayesian Neural Network (BNN) to simultaneously model the yields and performances of interest in multiple corners efficiently. Next, the multi-corner yield optimization can be performed by embedding BNN into a Bayesian optimization framework. Since the correlation among yields and performances of interest in different corners is implicitly encoded in the BNN model, it provides great modeling capabilities for yields and their uncertainties to improve the efficiency of yield optimization. Our experimental results demonstrate that the proposed method can save up to 45.3% of simulation cost compared to other baseline methods to achieve the same target yield. In addition, for the same simulation cost, our proposed method can find better design points with 3.2% yield improvement.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4387398469",
    "type": "article"
  },
  {
    "title": "An Efficient Reinforcement Learning Based Framework for Exploring Logic Synthesis",
    "doi": "https://doi.org/10.1145/3632174",
    "publication_date": "2023-11-10",
    "publication_year": 2023,
    "authors": "Yu Qian; Xuegong Zhou; Hao Zhou; Lingli Wang",
    "corresponding_authors": "",
    "abstract": "Logic synthesis is a crucial step in electronic design automation tools. The rapid developments of reinforcement learning (RL) have enabled the automated exploration of logic synthesis. Existing RL based methods may lead to data inefficiency, and the exploration approaches for FPGA and ASIC technology mapping in recent works lack the flexibility of the learning process. This work proposes ESE, a reinforcement learning based framework to efficiently learn the logic synthesis process. The framework supports the modeling of logic optimization and technology mapping for FPGA and ASIC. The optimization for the execution time of the synthesis script is also considered. For the modeling of FPGA mapping, the logic optimization and technology mapping are combined to be learned in a flexible way. For the modeling of ASIC mapping, the standard cell based optimization and LUT optimization operations are incorporated into the ASIC synthesis flow. To improve the utilization of samples, the Proximal Policy Optimization model is adopted. Furthermore, the framework is enhanced by supporting MIG based synthesis exploration. Experiments show that for FPGA technology mapping on the VTR benchmark, the average LUT-Level-Product and script runtime are improved by more than 18.3% and 12.4% respectively than previous works. For ASIC mapping on the EPFL benchmark, the average Area-Delay-Product is improved by 14.5%.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4388568026",
    "type": "article"
  },
  {
    "title": "Application-level Validation of Accelerator Designs Using a Formal Software/Hardware Interface",
    "doi": "https://doi.org/10.1145/3639051",
    "publication_date": "2023-12-29",
    "publication_year": 2023,
    "authors": "Bo-Yuan Huang; Steven Lyubomirsky; Yi Li; Mike He; Gus Henry Smith; Thierry Tambe; Akash Gaonkar; Vishal Canumalla; A H Cheung; Gu-Yeon Wei; Aarti Gupta; Zachary Tatlock; Sharad Malik",
    "corresponding_authors": "",
    "abstract": "Ideally, accelerator development should be as easy as software development. Several recent design languages/tools are working toward this goal, but actually testing early designs on real applications end-to-end remains prohibitively difficult due to the costs of building specialized compiler and simulator support. We propose a new first-in-class, mostly automated methodology termed “3LA” to enable end-to-end testing of prototype accelerator designs on unmodified source applications. A key contribution of 3LA is the use of a formal software/hardware interface that specifies an accelerator’s operations and their semantics. Specifically, we leverage the Instruction-level Abstraction (ILA) formal specification for accelerators that has been successfully used thus far for accelerator implementation verification. We show how the ILA for accelerators serves as a software/hardware interface, similar to the Instruction Set Architecture for processors, that can be used for automated development of compilers and instruction-level simulators. Another key contribution of this work is to show how ILA-based accelerator semantics enables extending recent work on equality saturation to auto-generate basic compiler support for prototype accelerators in a technique we term “flexible matching.” By combining flexible matching with simulators auto-generated from ILA specifications, our approach enables end-to-end evaluation with modest engineering effort. We detail several case studies of 3LA, which uncovered an unknown flaw in a recently published accelerator and facilitated its fix.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4390393298",
    "type": "article"
  },
  {
    "title": "Efficient routability check algorithms for segmented channel routing",
    "doi": "https://doi.org/10.1145/348019.348574",
    "publication_date": "2000-07-01",
    "publication_year": 2000,
    "authors": "Cheng-Hsing Yang; Sao‐Jie Chen; Jan-Ming Ho; Chia‐Chun Tsai",
    "corresponding_authors": "",
    "abstract": "The segmented channel-routing problem arises in the context of row-based field programmable gate arrays (FPGAs). Since the K -segment channel-routing problem is NP-complete for K ≥ 2, an efficient algorithm using the weighted bipartite-matching approach is developed for this problem. Connections that;form a maximum clique are chosen first to be routed to the segmented channel. Then, another maximum clique of the remained connections is routed until all connections have been processed. In addition, a powerful “unroutability check” algorithm is uniquely proposed to tell whether the horizontal switches in an interval of the segmented channel are sufficient for routing or not. Hence, we can precisely discriminate the routable and the unroutable ones from all the test cases. As shown in the experiments, average discrimination ratios of 98.8% and 99.4% are obtained for the 2-segmentation and 3-segmentation models, respectively. Moreover, when applying our routing algorithm to the analyzed nonunroutable cases, a routing failure ratio of 1.5% is reported for the 2-segmentation model, compared to Zhu and Wong's 5.9%; also, a routing failure ratio of 0.8% (less than their 4.7%) is obtained for the 3-segmentation model. In total, the routing failure ratio of our routing algorithm is less than 21% of Zhu and Wong's.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W1980806272",
    "type": "article"
  },
  {
    "title": "Multimode scan",
    "doi": "https://doi.org/10.1145/944027.944033",
    "publication_date": "2003-10-01",
    "publication_year": 2003,
    "authors": "Adit D. Singh; M. Seuring; Michael Gössel; E.S. Sogomonyan",
    "corresponding_authors": "",
    "abstract": "Built-in self-test (BIST) is an attractive design-for-test methodology for core-based SoC design because of the minimal need for test access when tests are generated and evaluated within the core itself. However, the scan based logic BIST approach being widely considered for this application suffers from two significant weaknesses: slow test-per-scan execution, and a limited capability for detecting realistic timing and delay faults, critical in deep submicron technologies. The new multimode scan based approach presented here supports test-per-clock BIST, which runs orders of magnitude faster, and also provides significantly better delay fault coverage.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2044400348",
    "type": "article"
  },
  {
    "title": "A hierarchical modeling framework for on-chip communication architectures of multiprocessing SoCs",
    "doi": "https://doi.org/10.1145/1188275.1188281",
    "publication_date": "2007-01-01",
    "publication_year": 2007,
    "authors": "Xinping Zhu; Sharad Malik",
    "corresponding_authors": "",
    "abstract": "In multiprocessor-based SoCs, optimizing the communication architecture is often as important, if not more important, than optimizing the computation architecture. While there are mature platforms and techniques for the modeling and evaluation of architectures of processing elements, the same is not true for the communication architectures. This article presents an application-driven retargetable prototyping platform that fills this gap. This environment aims to facilitate the design exploration of the communication subsystem through application-level execution-driven simulations and quantitative analysis. Based on an analysis of a wide range of on-chip communication architectures, we describe how a specific hierarchical class library can be used to develop new on-chip communication architectures, or variants of existing ones with relatively little incremental effort. We demonstrate this through three case studies including two commercial on-chip bus systems and an on-chip packet switching network. Here we show that, through careful analysis and construction, it is possible for the modeling environment to support the common features of these architectures as part of the library and permit instantiation of the individual architectures as variants of the library design. Consequently, system-level design choices regarding the communication architecture can be made with high confidence in the early stages of design. In addition to improving design quality, this methodology also results in significantly shortening design-time.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2023338883",
    "type": "article"
  },
  {
    "title": "A versatile paradigm for scan chain diagnosis of complex faults using signal processing techniques",
    "doi": "https://doi.org/10.1145/1297666.1297675",
    "publication_date": "2008-01-01",
    "publication_year": 2008,
    "authors": "Chao-Wen Tzeng; Jheng-Syun Yang; Shi‐Yu Huang",
    "corresponding_authors": "",
    "abstract": "Scan chains are popularly used as the channels for silicon testing and debugging. However, they have also been identified as one of the culprits of silicon failure more recently. To cope with this problem, several scan chain diagnosis approaches have been proposed in the past. The existing methods, however, suffer from one common drawback—that is, they rely on fault models and matching heuristics to locate the faults. Such a paradigm may run into difficulty when the fault under diagnosis does not match the fault model exactly, for example, when there is a bridging between a flip-flop and a logic cell, or the fault is temporal and only manifests itself intermittently. In light of this, we propose in this article a more versatile model-free paradigm for locating the faulty flip-flops in a scan chain, incorporating a number of signal processing techniques, such as filtering and edge detection. These techniques performed on the test responses of the failing chip under diagnosis directly can effectively reveal the fault location(s) in a scan chain. As compared to the previous works, our approach is better capable of handling intermittent faults and bridging faults, even under nonideal conditions, for example, when the core logic is also faulty. Experimental results on several real designs indicate that this approach can indeed catch some nasty faults that previous methods could not catch.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2029149982",
    "type": "article"
  },
  {
    "title": "Access pattern-based code compression for memory-constrained systems",
    "doi": "https://doi.org/10.1145/1391962.1391968",
    "publication_date": "2008-09-01",
    "publication_year": 2008,
    "authors": "Özcan Öztürk; Mahmut Kandemir; Guangyu Chen",
    "corresponding_authors": "",
    "abstract": "As compared to a large spectrum of performance optimizations, relatively less effort has been dedicated to optimize other aspects of embedded applications such as memory space requirements, power, real-time predictability, and reliability. In particular, many modern embedded systems operate under tight memory space constraints. One way of addressing this constraint is to compress executable code and data as much as possible. While researchers on code compression have studied efficient hardware and software based code compression strategies, many of these techniques do not take application behavior into account; that is, the same compression/decompression strategy is used irrespective of the application being optimized. This article presents an application-sensitive code compression strategy based on control flow graph (CFG) representation of the embedded program. The idea is to start with a memory image wherein all basic blocks of the application are compressed, and decompress only the blocks that are predicted to be needed in the near future. When the current access to a basic block is over, our approach also decides the point at which the block could be compressed. We propose and evaluate several compression and decompression strategies that try to reduce memory requirements without excessively increasing the original instruction cycle counts. Some of our strategies make use of profile data, whereas others are fully automatic. Our experimental evaluation using seven applications from the MediaBench suite and three large embedded applications reveals that the proposed code compression strategy is very successful in practice. Our results also indicate that working at a basic block granularity, as opposed to a procedure granularity, is important for maximizing memory space savings.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2051149669",
    "type": "article"
  },
  {
    "title": "A predictive decode filter cache for reducing power consumption in embedded processors",
    "doi": "https://doi.org/10.1145/1230800.1230806",
    "publication_date": "2007-04-01",
    "publication_year": 2007,
    "authors": "Weiyu Tang; Arun Kejariwal; Alexander V. Veidenbaum; Alexandru Nicolau",
    "corresponding_authors": "",
    "abstract": "With advances in semiconductor technology, power management has increasingly become a very important design constraint in processor design. In embedded processors, instruction fetch and decode consume more than 40% of processor power. This calls for development of power minimization techniques for the fetch and decode stages of the processor pipeline. For this, filter cache has been proposed as an architectural extension for reducing the power consumption. A filter cache is placed between the CPU and the instruction cache (I-cache) to provide the instruction stream. A filter cache has the advantages of shorter access time and lower power consumption. However, the downside of a filter cache is a possible performance loss in case of cache misses. In this article, we present a novel technique---decode filter cache (DFC)---for minimizing power consumption with minimal performance impact. The DFC stores decoded instructions. Thus, a hit in the DFC eliminates instruction fetch and its subsequent decoding. The bypassing of both instruction fetch and decode reduces processor power. We present a runtime approach for predicting whether the next fetch source is present in the DFC. In case a miss is predicted, we reduce the miss penalty by accessing the I-cache directly. We propose to classify instructions as cacheable or noncacheable, depending on the decode width. For efficient use of the cache space, a sectored cache design is used for the DFC so that both cacheable and noncacheable instructions can coexist in the DFC sector. Experimental results show that the DFC reduces processor power by 34% on an average and our next fetch prediction mechanism reduces miss penalty by more than 91%.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2064898124",
    "type": "article"
  },
  {
    "title": "Wavelet-based dynamic power management for nonstationary service requests",
    "doi": "https://doi.org/10.1145/1297666.1297679",
    "publication_date": "2008-01-01",
    "publication_year": 2008,
    "authors": "A. Abbasian; Safar Hatami; Ali Afzali‐Kusha; Massoud Pedram",
    "corresponding_authors": "",
    "abstract": "In this article, a wavelet-based dynamic power management policy (WBDPM) is proposed. In this approach, the workload source (service requester) is modeled by a nonstationary time series which, in turn, represented by a nondecimated Haar wavelet as its basis. The proposed approach is robust and has the ability to minimize energy dissipation under different performance constraints. To assess the accuracy of the model, the algorithm was implemented for data extracted from the hard disks of computers. Prediction results of this approach for the case of a nonstationary service requester exhibit accuracies of more than 95%.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2077828512",
    "type": "article"
  },
  {
    "title": "An Efficient Non-Gaussian Sampling Method for High Sigma SRAM Yield Analysis",
    "doi": "https://doi.org/10.1145/3174866",
    "publication_date": "2018-03-16",
    "publication_year": 2018,
    "authors": "Jinyuan Zhai; Changhao Yan; Sheng-Guo Wang; Dian Zhou; Hai Zhou; Xuan Zeng",
    "corresponding_authors": "",
    "abstract": "Yield 1 analysis of SRAM is a challenging issue, because the failure rates of SRAM cells are extremely small. In this article, an efficient non-Gaussian sampling method of cross entropy optimization is proposed for estimating the high sigma SRAM yield. Instead of sampling with the Gaussian distribution in existing methods, a non-Gaussian distribution, i.e., a joint one-dimensional generalized Pareto distribution and ( n -1)-dimensional Gaussian distribution, is taken as the function family of practical distribution, which is proved to be more suitable to fit the ideal distribution in the view of extreme failure event. To minimize the cross entropy between practical and ideal distributions, a sequential quadratic programing solver with multiple starting points strategy is applied for calculating the optimal parameters of practical distributions. Experimental results show that the proposed non-Gaussian sampling is a 2.2--4.1× speedup over the Gaussian sampling, on the whole, it is about a 1.6--2.3× speedup over state-of-the-art methods with low- and high-dimensional cases without loss of accuracy",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2792683422",
    "type": "article"
  },
  {
    "title": "P3",
    "doi": "https://doi.org/10.1145/3236625",
    "publication_date": "2018-11-28",
    "publication_year": 2018,
    "authors": "Siam U. Hussain; Farinaz Koushanfar",
    "corresponding_authors": "",
    "abstract": "This article presents the first privacy-preserving localization method based on provably secure primitives for smart automotive systems. Using this method, a car that is lost due to unavailability of GPS can compute its location with assistance from three nearby cars, while the locations of all the participating cars including the lost car remain private. Technological enhancement of modern vehicles, especially in navigation and communication, necessitates parallel enhancement in security and privacy. Previous approaches to maintaining user location privacy suffered from one or more of the following drawbacks: trade-off between accuracy and privacy, one-sided privacy, and the need of a trusted third party that presents a single point to attack. The localization method presented here is one of the very first location-based services that eliminates all these drawbacks. Two protocols for computing the location is presented here based on two Secure Function Evaluation (SFE) techniques that allow multiple parties to jointly evaluate a function on inputs that are encrypted to maintain privacy. The first one is based on the two-party protocol named Yao’s Garbled Circuit (GC). The second one is based on the Beaver-Micali-Rogaway (BMR) protocol that allows inputs from more than two parties. The two secure localization protocols exhibit trade-offs between performance and resilience against collusion. Along with devising the protocols, we design and optimize netlists for the functions required for location computation by leveraging conventional logic synthesis tools with custom libraries optimized for SFE. Proof-of-concept implementation of the protocol shows that the complete operation can be performed within only 355ms. The fast computing time enables localization of even moving cars.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2794128473",
    "type": "article"
  },
  {
    "title": "Partially Invariant Patterns for <i>LFSR</i> -Based Generation of Close-to-Functional Broadside Tests",
    "doi": "https://doi.org/10.1145/3201405",
    "publication_date": "2018-05-29",
    "publication_year": 2018,
    "authors": "Irith Pomeranz",
    "corresponding_authors": "Irith Pomeranz",
    "abstract": "Close-to-functional scan-based tests are expected to create close-to-functional operation conditions in order to avoid overtesting of delay faults. Existing metrics for the proximity to functional operation conditions are based on the scan-in state. For example, they consider the distance between the scan-in state and a reachable state (a state that the circuit can visit during functional operation). However, the deviation from functional operation conditions can increase during a test beyond the deviation that is measured by the scan-in state. To ensure that the deviation does not increase, this article introduces the concept of a partially invariant pattern. The article describes a procedure for extracting partially invariant patterns from functional broadside tests whose scan-in states are reachable states. Being partially specified, partially invariant patterns are suitable for test data compression. The article studies the use of partially invariant patterns for linear-feedback shift-register ( LFSR ) based test data compression. Noting that a seed may not exist for a given partially invariant pattern with a given LFSR , the procedure described in this article uses an iterative process that not only matches a seed to a partially invariant pattern, but also adjusts the partially invariant pattern based on the test that the seed produces. The article also addresses the selection of LFSR s for the generation of close-to-functional broadside tests based on partially invariant patterns. Experimental results are presented to demonstrate the feasibility of the procedure.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2806212214",
    "type": "article"
  },
  {
    "title": "iTimerM",
    "doi": "https://doi.org/10.1145/3149818",
    "publication_date": "2018-06-11",
    "publication_year": 2018,
    "authors": "Pei‐Yu Lee; Iris Hui-Ru Jiang",
    "corresponding_authors": "",
    "abstract": "As designs continue to grow in size and complexity, EDA paradigm shifts from flat to hierarchical timing analysis. In this article, we present compact and accurate timing macro modeling, which is the key to efficient and accurate hierarchical timing analysis. Our goal is to contain only a minimal amount of interface logic in our timing macro model. The main idea is to separate the interface logic into variant and constant timing regions. Then, the variant timing region is reserved for accuracy, while the constant timing region is reduced for compactness. For reducing the constant timing region, we propose anchor pin insertion and deletion by generalizing existing timing graph reduction techniques. Furthermore, we devise a lookup table index selection technique to achieve high model accuracy over the possible operating condition range. Compared with two common models used in industry, extracted timing model and interface logic model, our model has high model accuracy and small model size. Based on the TAU 2016 and 2017 timing macro modeling contest benchmark suites, our results show that our algorithm delivers superior efficiency and accuracy: Hierarchical timing analysis using our model can significantly reduce runtime and memory compared with flat timing analysis on the original design. Moreover, our algorithm outperforms TAU 2016 and 2017 contest winners in model accuracy, model size, model generation performance, and model usage performance.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2808273492",
    "type": "article"
  },
  {
    "title": "Enhancing Flash Memory Reliability by Jointly Considering Write-back Pattern and Block Endurance",
    "doi": "https://doi.org/10.1145/3229192",
    "publication_date": "2018-08-22",
    "publication_year": 2018,
    "authors": "Tseng‐Yi Chen; Yuan-Hao Chang; Yuan-Hung Kuan; Ming-Chang Yang; Yu-Ming Chang; Pi-Cheng Hsiu",
    "corresponding_authors": "",
    "abstract": "Owing to high cell density caused by the advanced manufacturing process, the reliability of flash drives turns out to be rather challenging in flash system designs. To enhance the reliability of flash drives, error-correcting code (ECC) has been widely utilized in flash drives to correct error bits during programming/reading data to/from flash drives. Although ECC can effectively enhance the reliability of flash drives by correcting error bits, the capability of ECC would degrade while the program/erase (P/E) cycles of flash blocks is increased. Finally, ECC could not correct a flash page, because a flash page contains too many error bits. As a result, reducing error bits is an effective solution to further improve the reliability of flash drives when a specific ECC is adopted in the flash drive. This work focuses on how to reduce the probability of producing error bits in a flash page. Thus, we propose a pattern-aware write strategy for flash reliability enhancement. The proposed write strategy considers both the P/E cycle of blocks and the pattern of written data while a flash block is allocated to store the written data. Since the proposed write strategy allocates young blocks (respectively, old blocks) for hot data (respectively, cold data) and flips the bit pattern of the written data to the appropriate bit pattern, the proposed strategy can effectively improve the reliability of flash drives. The experimental results show that the proposed strategy can reduce the number of error pages by up to 50%, compared with the well-known DFTL solution. Moreover, the proposed strategy is orthogonal with all ECC mechanisms so that the reliability of the flash drives with ECC mechanisms can be further improved by the proposed strategy.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2888139573",
    "type": "article"
  },
  {
    "title": "Instinctive Assistive Indoor Navigation using Distributed Intelligence",
    "doi": "https://doi.org/10.1145/3212720",
    "publication_date": "2018-11-28",
    "publication_year": 2018,
    "authors": "Md Muztoba; Rohit Voleti; Fatih Karabacak; Jaehyun Park; Ümit Y. Ogras",
    "corresponding_authors": "",
    "abstract": "Cyber-physical systems (CPS) and the Internet of Things (IoT) offer a significant potential to improve the effectiveness of assistive technologies for those with physical disabilities. Practical assistive technologies should minimize the number of inputs from users to reduce their cognitive and physical effort. This article presents an energy-efficient framework and algorithm for assistive indoor navigation with multi-modal user input. The goal of the proposed framework is to simplify the navigation tasks and make them more instinctive for the user. Our framework automates indoor navigation using only a few user commands captured through a wearable device. The proposed methodology is evaluated using both a virtual smart building and a prototype. The evaluations for three different floorplans show one order of magnitude reduction in user effort and communication energy required for navigation, when compared to conventional navigation methodologies that require continuous user inputs.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2903525615",
    "type": "article"
  },
  {
    "title": "Three-dimensional Floorplan Representations by Using Corner Links and Partial Order",
    "doi": "https://doi.org/10.1145/3289179",
    "publication_date": "2018-12-21",
    "publication_year": 2018,
    "authors": "Ilgweon Kang; Fang Qiao; Dong-Won Park; Daniel M. Kane; Evangeline F. Y. Young; Chung‐Kuan Cheng; Ronald Graham",
    "corresponding_authors": "",
    "abstract": "Three-dimensional integrated circuit (3D IC) technology offers a potential breakthrough to enable a paradigm-shift strategy, called “more than Moore,” with novel features and advantages over the conventional 2D process technology. By having three-dimensional interconnections, 3D IC provides substantial wirelength reduction and a massive amount of bandwidth, which gives significant performance improvement to overcome many of the nontrivial challenges in semiconductor industry. Moreover, 3D integration technology enables to stack disparate technologies with various functionalities into a single system-in-package (SiP), introducing “true 3D IC” design. As the first physical design (PD) step, IC floorplanning takes a crucial role to determine IC’s overall design qualities such as footprint area, timing closure, power distribution, thermal management, and so on. However, lack of efficient 3D floorplanning algorithms that practically implement advantages of 3D integration technology is a critical bottleneck for PD automation of 3D IC design and implementation. 3D floorplanning (or packing, block partitioning) is a well-known NP-hard problem, and most of 3D floorplanning algorithms rely on heuristics and iterative improvements. Thus, developing complete and efficient 3D floorplan representations is important, since floorplan representation provides the foundation of data structure to search the solution space for 3D IC floorplanning. A well-defined floorplan representation provides a well-organized and cost-effective methodology to design high-performance 3D IC. We propose a new 3D IC floorplan representation methodology using corner links and partial order . Given a fixed number of cuboidal blocks and their volume, algorithmic 3D floorplan representations describe topological structure and physical positions/orientations of each block relative to the origin in the 3D floorplan space. In this article, (1) we introduce our novel 3D floorplan representation, called corner links representation , (2) we analyze the equivalence relation between the corner links representation and its corresponding partial order representation , and (3) we discuss several key properties of the corner links representation and partial order representation. The corner links representation provides a complete and efficient structure to assemble the original 3D mosaic floorplan. Also, the corner links representation for the non-degenerate 3D mosaic floorplan can be equivalently expressed by the four trees representation . The partial order representation defines the topological structure of the 3D floorplan with three transitive closure graphs (TCG) for each direction and captures all stitching planes in the 3D floorplan in the order of their respective directions. We demonstrate that the corner links representation can be reduced to its corresponding partial order representation, indicating that the corner links representation shares well-defined and -studied features/properties of 3D TCG-based floorplan representation. If the partial order representation describes relations between any pairs of blocks in the 3D floorplan, then the floorplan is a valid floorplan. We show that the partial order representation can restore the absolute coordinates of all blocks in the 3D mosaic floorplan by using the given physical dimensions of blocks.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2906355196",
    "type": "article"
  },
  {
    "title": "Integrated Latch Placement and Cloning for Timing Optimization",
    "doi": "https://doi.org/10.1145/3301613",
    "publication_date": "2019-02-09",
    "publication_year": 2019,
    "authors": "Jinwook Jung; Gi-Joon Nam; Woohyun Chung; Youngsoo Shin",
    "corresponding_authors": "",
    "abstract": "This article presents an algorithm for integrated timing-driven latch placement and cloning. Given a circuit placement, the proposed algorithm relocates some latches while circuit timing is improved. Some latches are replicated to further improve the timing; the number of replicated latches along with their locations are automatically determined. After latch cloning, each of the replicated latches is set to drive a subset of the fanouts that have been driven by the original single latch. The proposed algorithm is then extended such that relocation and cloning are applied to some latches together with their neighbor logic gates. Experimental results demonstrate that the worst negative slack and the total negative slack are improved by 24% and 59%, respectively, on average of test circuits. The negative impacts on circuit area and power consumption are both marginal, at 0.7% and 1.9% respectively.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2912779250",
    "type": "article"
  },
  {
    "title": "SSA-AC",
    "doi": "https://doi.org/10.1145/3314575",
    "publication_date": "2019-04-02",
    "publication_year": 2019,
    "authors": "Sara Ayman Metwalli; Yuko Hara–Azumi",
    "corresponding_authors": "",
    "abstract": "Recently, the quest to reduce energy consumption in digital systems has been the subject of a number of ongoing studies. One of the most researched focuses is approximate computing (AC) . AC is a new computing paradigm in both hardware and software designs that aim to achieve energy-efficient digital systems. Although a variety of AC techniques have been studied so far, the main question, “How (in which section) can a program or a circuit be approximated?,” has not been answered yet. This work addresses the above issue by developing a software framework Static Significance Analysis for Approximate Computing (SSA-AC) to analyze the target application program and guide the designers to identify parts of the program to which approximation can or cannot be applied. SSA-AC statically analyzes the significance of variables in the precise version of the program and thus needs no trial-and-error evaluation or specific test data. Experimental results show that SSA-AC can successfully extract the significance ranking of inputs/variables to be approximated in much shorter time than existing statistical works that are inevitably data dependent.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2925629836",
    "type": "article"
  },
  {
    "title": "Comparing Platform-aware Control Design Flows for Composable and Predictable TDM-based Execution Platforms",
    "doi": "https://doi.org/10.1145/3315572",
    "publication_date": "2019-03-28",
    "publication_year": 2019,
    "authors": "Juan Valencia; Dip Goswami; Kees Goossens",
    "corresponding_authors": "",
    "abstract": "We compare three platform-aware feedback control design flows that are tailored for a composable and predictable Time Division Multiplexing (TDM)-based execution platform. The platform allows for independent execution of multiple applications. Using the precise timing knowledge of the platform execution, we accurately characterise the execution of the control application (i.e., sensing, computing, and actuating operations) to design efficient feedback controllers with high control performance in terms of settling time. The design flows are derived for Single-Rate (SR) and Multi-Rate (MR) sampling schemes. We show the applicability of the design flows based on two design considerations and their trade-off: control performance and resource utilisation. The design flows are validated by means of MATLAB and Hardware-in-the-Loop (HIL) experiments for a motion control application.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2927794059",
    "type": "article"
  },
  {
    "title": "Revealing Cluster Hierarchy in Gate-level ICs Using Block Diagrams and Cluster Estimates of Circuit Embeddings",
    "doi": "https://doi.org/10.1145/3329081",
    "publication_date": "2019-06-12",
    "publication_year": 2019,
    "authors": "Burçin Çakır; Sharad Malik",
    "corresponding_authors": "",
    "abstract": "Contemporary integrated circuits (ICs) are increasingly being constructed using intellectual property blocks (IPs) obtained from third parties in a globalized supply chain. The increased vulnerability to adversarial changes during this untrusted supply chain raises concerns about the integrity of the end product. The difference in the levels of abstraction between the initial specification and the final available circuit design poses a challenge for analyzing the final circuit for malicious insertions. Reverse engineering presents one way to help reduce the difficulty of circuit analysis and inspection. In this work, we provide a framework that given (i) a gate-level netlist of a design and (ii) a block diagram for the design with relative sizes of the blocks, outputs a matching between the partitions of the circuit and blocks in the block diagram. We first compute a geometric embedding for each node in the circuit and then apply a clustering algorithm on the embedding features to obtain circuit partitions. Each partition is then mapped to the high-level blocks in the block diagram. These partitions can then be further analyzed for malicious insertions with much reduced complexity in comparison with the full chip. We tested our algorithm on different designs with varying sizes to evaluate the efficacy of algorithm, including the open-source processor OpenSparc T1, and showed that we can successfully match over 90% of gates to their corresponding blocks.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2952043869",
    "type": "article"
  },
  {
    "title": "On Chip Reconfigurable CMOS Analog Circuit Design and Automation Against Aging Phenomena",
    "doi": "https://doi.org/10.1145/3325069",
    "publication_date": "2019-06-28",
    "publication_year": 2019,
    "authors": "Engín Afacan; Günhan Dündar; Faík Başkaya; Alí Emre Pusane; Mustafa Berke Yelten",
    "corresponding_authors": "",
    "abstract": "Performance of analog circuits degrades over time due to several time-dependent degradation mechanisms. Due to the increased aging problems in ever-shrinking dimensions, reliability of complementary metal-oxide-semiconductor analog circuits has become a major concern. Overdesign is a popular aging-aware circuit design approach, where circuit operation is guardbanded by choosing the design point beyond the optimal region. For the sake of reliability, power consumption and chip area are sacrificed in this approach, which is undesirable considering strict energy limitations in modern applications. Conversely, Sense and React (S8R) approach serves the same purpose without any additional power consumption, in which degradation of circuit features is detected by online monitoring and recovered immediately. Furthermore, such systems enable remote control and healing of circuits. However, design of an S8R system is quite complicated. In particular, determination of efficient aging signatures and design of recovery strategy are highly challenging problems. This study thoroughly discusses the design process of S8R systems and proposes computer-aided-design-based design strategies that reduce the designer effort considerably. A novel design automation tool for S8R systems was developed, in which signature selection and recovery determination were integrated. To demonstrate proposed design strategies, two different S8R systems are implemented, simulated, and discussed in detail.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2953609977",
    "type": "article"
  },
  {
    "title": "Machine Learning-based Defect Coverage Boosting of Analog Circuits under Measurement Variations",
    "doi": "https://doi.org/10.1145/3408063",
    "publication_date": "2020-08-21",
    "publication_year": 2020,
    "authors": "Nektar Xama; Martin Andraud; Jhon Gomez; Baris Esen; Wim Dobbelaere; Ronny Vanhooren; Anthony Coyette; Georges Gielen",
    "corresponding_authors": "",
    "abstract": "Safety-critical and mission-critical systems, such as airplanes or (semi-)autonomous cars, are relying on an ever-increasing number of embedded integrated circuits. Consequently, there is a need for complete defect coverage during the testing of these circuits to guarantee their functionality in the field. In this context, reducing the escape rate of defects during production testing is crucial, and significant progress has been made to this end. However, production testing using automatic test equipment is subject to various measurement parasitic variations, which may have a negative impact on the testing procedure and therefore limit the final defect coverage. To tackle this issue, this article proposes an improved test flow targeting increased analog defect coverage, both at the system and block levels, by analyzing and improving the coverage of typical functional and structural tests under these measurement variations. To illustrate the flow, the technique of inserting a pseudo-random signal at available circuit nodes and applying machine learning techniques to its response is presented. A DC-DC converter, derived from an industrial product, is used as a case study to validate the flow. In short, results show that system-level tests for the converter suffer strongly from the measurement variations and are limited to just under 80% coverage, even when applying the proposed test flow. Block-level testing, however, can achieve only 70% fault coverage without improvements but is able to consistently achieve 98% of fault coverage at a cost of at most 2% yield loss with the proposed machine learning–based boosting technique.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W3080588109",
    "type": "article"
  },
  {
    "title": "Buffer Optimization and Dispatching Scheme for Embedded Systems with Behavioral Transparency",
    "doi": "https://doi.org/10.1145/2348839.2348845",
    "publication_date": "2012-10-01",
    "publication_year": 2012,
    "authors": "An-Ping Wang; Jiwon Hahn; M. Roumi; Pai H. Chou",
    "corresponding_authors": "",
    "abstract": "This article presents a buffer minimization scheme with low dispatching overhead for embedded software processes. To accomplish this, we exploit behavioral transparency in the model of computation. In such a model (e.g., synchronous dataflow), the state of buffer requirements is determined completely by the firing sequence of the actors without requiring functional simulation of the actors. Fine-grained buffer allocation incurs high and code pointer overhead while coarse-grained allocation suffers from memory fragmentation. Instead, we propose a medium-grained, “access-contiguous” buffer allocation scheme that minimizes the total buffer space and pointer overhead. We formulate the buffer allocation problem as 2D tiles that represent the lifetime of the buffers to minimize their memory occupation spatially and temporally. Experimental results show that our scheme uses less data memory than existing techniques by 26% on average, or up to 57% in the best case. Our technique retains code modularity for dynamic configuration and, more importantly, enables many more applications that otherwise would not fit if implemented using previous state-of-the-art techniques.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W1972756936",
    "type": "article"
  },
  {
    "title": "Thread-based multi-engine model checking for multicore platforms",
    "doi": "https://doi.org/10.1145/2491477.2491480",
    "publication_date": "2013-07-01",
    "publication_year": 2013,
    "authors": "Gianpiero Cabodi; Sergio Nocco; Stefano Quer",
    "corresponding_authors": "",
    "abstract": "This article describes a multithreaded, portfolio-based approach to model checking, where multiple cores are exploited as the underlying computing framework to support concurrent execution of cooperative engines. We introduce a portfolio-based approach to model checking. Our portfolio is first driven by an approximate runtime predictor that provides a heuristic approximation to a perfect oracle and suggests which engines are more suitable for each verification instance. Scalability and robustness of the overall model-checking effort highly rely on a concurrent, multithreaded model of execution. Following similar approaches in related application fields, we dovetail data partitioning, focused on proving several properties in parallel, and engine partitioning, based on concurrent runs of different model-checking engines competing for completion of the same problem. We investigate concurrency not only to effectively exploit several available engines, which operate independently, but also to show that a cooperative effort is possible. In this case, we adopt a straightforward, light-weight, model of inter-engine communication and data sharing. We provide a detailed description of the ideas, algorithms, and experimental results obtained on the benchmarks from the Hardware Model Checking Competition suites (HWMCC'10 and HWMCC'11).",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W1981164177",
    "type": "article"
  },
  {
    "title": "ECR",
    "doi": "https://doi.org/10.1145/2348839.2348854",
    "publication_date": "2012-10-01",
    "publication_year": 2012,
    "authors": "Tak-Kei Lam; Wai-Chung Tang; Xiaoqing Yang; Yu‐Liang Wu",
    "corresponding_authors": "",
    "abstract": "Rewiring is known to be a class of logic restructuring technique that is at least equally powerful in flexibility compared to other logic transformation techniques. Especially it is wiring sensitive and is particularly useful for interconnect-based circuit synthesis processes. One of the most well-studied rewiring techniques is the ATPG-based Redundancy Addition and Removal (RAR) technique which adds a redundant alternative wire to make an originally irredundant target wire become redundant and thus removable. In this article, we propose a new Error-Cancellation-based Rewiring scheme (ECR) which can also identify non-RAR-based rewiring operations with high efficiency. In ECR scheme, it is not necessary for alternative wires to be redundant. Based on the notion of error cancellation, we analyze and reformulate the rewiring problem, and a more generalized rewiring scheme is developed to detect more rewiring cases which are not obtainable by existing schemes while it still maintains a low runtime complexity. Comparing with the most recent non-RAR rewiring tool IRRA, the total number of alternative wires found by our approach is about doubled (202%) while the CPU time used is just slightly more (8%) upon benchmarks preoptimized by ABC’s rewriting. Our experimental results also suggest that the ECR engine is more powerful than IRRA in FPGA technology mapping.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2020871752",
    "type": "article"
  },
  {
    "title": "Synthesis of Adaptable Hybrid Adders for Area Optimization under Timing Constraint",
    "doi": "https://doi.org/10.1145/2348839.2348847",
    "publication_date": "2012-10-01",
    "publication_year": 2012,
    "authors": "Yonghwan Kim; Sanghoon Kwak; Taewhan Kim",
    "corresponding_authors": "",
    "abstract": "Satisfying the timing constraint is the utmost concern in the integrated circuit design and it is true that most critical timing paths in a circuit cover one or more arithmetic components such as adder, subtractor, and multiplier of which addition logic is commonly involved. This work addresses the problem of redesigning the addition logic (in a form of hybrid adder) on a critical timing path to meet the timing constraint while minimally allocating the required addition logic. Unlike the conventional hybrid adder design schemes in which they assume uniform or specific patterns of input signal arrival times and minimize the latest timing of the output signals, our work extracts the required timing of each output signal as well as the input arrival times directly from the circuit and resynthesizes the addition logic by creating a customized hybrid adder that is best suited, in terms of logic area, for meeting the timing constraint of the circuit. Specifically, we propose a systematic approach of hybrid adder design exploration, basically following the principle of dynamic programming with well-controlled pruning techniques. This work is realistic and practically very useful in that it can be used as a timing optimizer to the computation-intensive circuits with a tight timing budget. We provide a set of diverse experimental data to show how much the proposed hybrid adder scheme is effective in meeting or reducing timing while maintaining the circuit area as minimal as possible.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2024263487",
    "type": "article"
  },
  {
    "title": "A Special Section on Multicore Parallel CAD",
    "doi": "https://doi.org/10.1145/1970353.1970354",
    "publication_date": "2011-06-01",
    "publication_year": 2011,
    "authors": "Kurt Keutzer; Peng Li; Li Shang; Hai Zhou",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2033208810",
    "type": "article"
  },
  {
    "title": "Analog layout retargeting using geometric programming",
    "doi": "https://doi.org/10.1145/2003695.2003710",
    "publication_date": "2011-10-01",
    "publication_year": 2011,
    "authors": "Shaoxi Wang; Xinzhang Jia; Arthur B. Yeh; Lihong Zhang",
    "corresponding_authors": "",
    "abstract": "To satisfy the requirements of complex and special analog layout constraints, a new analog layout retargeting method is presented in this article. Our approach uses geometric programming (GP) to achieve new technology design rules, implement device symmetry and matching constraints, and manage parasitics optimization. The GP, a class of nonlinear optimization problem, can be transferred or fitted into a convex optimization problem. Therefore, a global optimum solution can be achieved. Moreover, the GP can address problems with large-scale variables and constraints without setting an initialization variable range. To meet the prerequisites of the GP methodology for analog layout automation, we propose three kinds of mathematical transformations, including negative coefficient transformation, fraction transformation, and maximum of posynomial transformation. The efficiency and effectiveness of the proposed algorithm, as compared with the other existing methods, are demonstrated by a basic case-study example: a two-stage Miller-compensated operational amplifier and a single-ended folded cascode operational amplifier.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2039730318",
    "type": "article"
  },
  {
    "title": "Coverage-directed observability-based validation for embedded software",
    "doi": "https://doi.org/10.1145/2442087.2442090",
    "publication_date": "2013-03-01",
    "publication_year": 2013,
    "authors": "José C. Costa; José Monteiro",
    "corresponding_authors": "",
    "abstract": "Motivated by the need for validation methodologies for embedded systems we propose a method for embedded software testing that can be integrated with existing hardware methods. Existing coverage-directed validation methods guarantee the execution of a certain percentage of the program code under test. Yet they do not generally verify whether the statements executed have any influence on the program's output. In the proposed method, a program statement is considered covered not simply for belonging to the executed path, but only if its execution has influence in some observable output. The paths are generated by searching the longest path in terms of the number of statements in the path. Given that not all paths are valid, we check their feasibility using a method based on Mixed Integer Linear Programming (MILP). Variable aliasing is accounted for by representing variables by their memory addresses when building this MILP problem. In this manner, for feasible paths, we obtain immediately the input values that allow the execution of the path. Using these inputs, we determine the statements actually observed. We repeat this process until a user-specified level of coverage has been achieved. In the generation of each new path, the statement coverage obtained so far and the feasibility of previous paths is taken into account. We present results that demonstrate the effectiveness of this methodology.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2053296447",
    "type": "article"
  },
  {
    "title": "IC power delivery",
    "doi": "https://doi.org/10.1145/2442087.2442100",
    "publication_date": "2013-03-01",
    "publication_year": 2013,
    "authors": "Zhiyu Zeng; Suming Lai; Peng Li",
    "corresponding_authors": "",
    "abstract": "Modern IC power delivery systems encompass large on-chip passive power grids and active on-chip or off-chip voltage converters and regulators. While there exists little work targeting on holistic design of such complex IC subsystems, the optimal system-level design of power delivery is critical for achieving power integrity and power efficiency. In this article, we conduct a systematic design analysis on power delivery networks that incorporate Buck Converters (BCs) and on-chip Low-Dropout voltage regulators (LDOs) for the entire chip power supply. The electrical interactions between active voltage converters, regulators as well as passive power grids and their influence on key system design specifications are analyzed comprehensively. With the derived design insights, the system-level codesign of a complete power delivery network is facilitated by a proposed automatic optimization flow in which key design parameters of buck converters and on-chip LDOs as well as on-chip decoupling capacitance are jointly optimized. The experimental results demonstrate significant performance improvements resulted from the proposed system cooptimization in terms of achievable area overhead, supply noise and power efficiency. Impacts of different decoupling capacitance technologies are also investigated.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2058129208",
    "type": "article"
  },
  {
    "title": "Design and Implementation of a Throughput-Optimized GPU Floorplanning Algorithm",
    "doi": "https://doi.org/10.1145/1970353.1970356",
    "publication_date": "2011-06-01",
    "publication_year": 2011,
    "authors": "Yiding Han; Koushik Chakraborty; Sanghamitra Roy; Vilasita Kuntamukkala",
    "corresponding_authors": "",
    "abstract": "In this article, we propose a novel floorplanning algorithm for GPUs. Floorplanning is an inherently sequential algorithm, far from the typical programs suitable for Single-Instruction Multiple-Thread (SIMT)-style concurrency in a GPU. We propose a fundamentally different approach of exploring the floorplan solution space, where we evaluate concurrent moves on a given floorplan. We illustrate several performance optimization techniques for this algorithm in GPUs. To improve the solution quality, we present a comprehensive exploration of the design space, including various techniques to adapt the annealing approach in a GPU. Compared to the sequential algorithm, our techniques achieve 6--188X speedup for a range of MCNC and GSRC benchmarks, while delivering comparable or better solution quality.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2064869192",
    "type": "article"
  },
  {
    "title": "Launch-on-Shift Test Generation for Testing Scan Designs Containing Synchronous and Asynchronous Clock Domains",
    "doi": "https://doi.org/10.1145/2348839.2348852",
    "publication_date": "2012-10-01",
    "publication_year": 2012,
    "authors": "Shianling Wu; Laung‐Terng Wang; Xiaoqing Wen; Wen-Ben Jone; Michael S. Hsiao; Fangfang Li; James Chien-Mo Li; Jiun-Lang Huang",
    "corresponding_authors": "",
    "abstract": "This article presents a hybrid Automatic Test Pattern Generation (ATPG) technique using the staggered Launch-On-Shift (LOS) scheme followed by the one-hot launch-on-shift scheme for testing delay faults in a scan design containing asynchronous clock domains. Typically, the staggered scheme produces small test sets but needs long ATPG runtime, whereas the one-hot scheme takes short ATPG runtime but yields large test sets. The proposed hybrid technique is intended to reduce test pattern count with acceptable ATPG runtime for multimillion-gate scan designs. In case the scan design contains multiple synchronous clock domains, and each group of synchronous clock domains is treated as a clock group and tested using a launch-aligned or a capture-aligned LOS scheme. By combining these schemes together, we found the pattern counts for two large industrial designs were reduced by approximately 1.6X to 1.8X, while the ATPG runtime was increased by 40% to 50%, when compared to the one-hot clocking scheme alone.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2099984546",
    "type": "article"
  },
  {
    "title": "IO connection assignment and RDL routing for flip-chip designs",
    "doi": "https://doi.org/10.1145/2003695.2003707",
    "publication_date": "2011-10-01",
    "publication_year": 2011,
    "authors": "Jin-Tai Yan",
    "corresponding_authors": "Jin-Tai Yan",
    "abstract": "Given a set of IO buffers and a set of bump balls with the capacity constraints between two adjacent bump balls, based on the construction of the Delaunary triangulation and a Manhattan Voronoi diagram, an O( n 2 ) assignment algorithm is proposed to assign all the IO connections in a single redistribution layer for IO connection assignment, where n is the number of bump balls in a flip-chip design. Furthermore, based on the computation of the probabilistic congestion for the assigned IO connections, an O( n 2 ) routing algorithm is proposed to minimize the total wirelength to route all the assigned IO connections while satisfying the capacity constraints for single-layer RDL routing. Compared with the combination of a greedy IO assignment and our RDL routing, our IO assignment reduces the total wirelength by 9.9% and improves the routability by 8.8% on the average for 6 tested circuits. Compared with the combination of a greedy IO assignment, the single-layer BGA global router [Tomioka and Takahashi 2006] and our RDL detailed routing, our IO connection assignment and RDL routing reduces the total wirelength by 12.9% and improve the routability by 10.2% on the average for 6 tested circuits. Besides that the experimental results show that our IO connection assignment and RDL routing can reduce 52.1% of the total wirelength on the average to achieve 100% routability for 12 tested industrial circuits under reasonable CPU time.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2623608546",
    "type": "article"
  },
  {
    "title": "The edge-based design rule model revisited",
    "doi": "https://doi.org/10.1145/293625.293633",
    "publication_date": "1998-07-01",
    "publication_year": 1998,
    "authors": "Michael A. Riepe; Karem A. Sakallah",
    "corresponding_authors": "",
    "abstract": "A model for integrated circuit design rules based on rectangle edge constraints has been proposed by Jeppson, Christensson, and Hedenstierna. This model appears to be the most rigorous proposed to date for the description of such edge-based design rules. However, in certain rare circumstances their model is unable to express the correct design rule when the constrained edges are not adjacent in the layout. We introduce a new notation, called an edge path, which allows us to extend their model to allow for constraints between edges separated by an arbitrary number of intervening edges. Using this notation we enumerate all edge paths that are required to correctly model the original design rule macros of the JCH model, and prove that these macros are sufficient to model the most common rules. We also show how this notation alows us to directly specify many kinds of conditional design rules that required ad hoc specification under the JCH model.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2007486748",
    "type": "article"
  },
  {
    "title": "A methodology and algorithms for the design of hard real-time multitasking ASICs",
    "doi": "https://doi.org/10.1145/323480.323491",
    "publication_date": "1999-10-01",
    "publication_year": 1999,
    "authors": "Miodrag Potkonjak; Wayne Wolf",
    "corresponding_authors": "",
    "abstract": "Traditional high-level synthesis concentrates on the implementation of a single task (e.g. filter, linear controller, A/D converter). However, many applications—multifunctional embedded controllers intelligent wireless end-points, and DSP and multimedia servers—are defined as sets of several computational tasks. This paper describes new techniques for the synthesis of ASIC implementations that realize multiple computational processes under hard real-time constraints. Our synthesis methodology establishes connections between two important comengineering domains: operating systems and behavioral synthesis. Our hierarchical approach starts from an incompletely-specified preliminary solution and uses, interchangeably, operating system and behavioral synthesis techniques to derive increasingly more detailed and accurate design solutions. We have experimented with both optimal and heuristic algorithms to implement this methodology. The optimal algorithm uses several heuristics to speed up the average run time of an exhaustive branch-and-bound search. Force-directed optimization is the core of the heuristic synthesis method. Analysis of the proposed algorithms and the experiments shows that matching the number of bits and type of operational in taskes assigned to the same application-specific processor was the most important factor in obtaining area-efficient designs.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2064736805",
    "type": "article"
  },
  {
    "title": "A search-based bump-and-refit approach to incremental routing for ECO applications in FPGAs",
    "doi": "https://doi.org/10.1145/605440.605449",
    "publication_date": "2002-10-01",
    "publication_year": 2002,
    "authors": "Shantanu Dutt; Vinay Verma; Hasan Arslan",
    "corresponding_authors": "",
    "abstract": "Incremental physical CAD is encountered frequently in the so-called engineering change order (ECO) process in which design changes are made typically late in the design process in order to correct logical and/or technological problems in the circuit. Incremental routing is a significant part of an incremental physical design methodology. Typically after an ECO process, a small portion of the circuit netlist is changed, and in order to capitalize on the enormous resources and time already spent on routing the circuit it is desirable to reroute only the ECO-affected portion of the circuit, while minimizing any routing changes in the much larger unaffected part. Incremental rerouting also needs to be fast and to effectively use available routing resources. In this article, we develop a complete incremental routing methodology for FPGAs using a novel approach called bump and refit (B&amp;R). The basic B&amp;R idea (which was originally proposed in Dutt et al. [1999] in the much simpler context of extending some nets by a segment for the purpose of fault tolerance) in our algorithms is to rearrange some portions of some existing nets on other tracks within their current channels in order to find valid routings for the new/modified nets without requiring any extra routing resources and with little effect on the electrical properties of existing nets. Here we significantly extend the B&amp;R concept to global and detailed incremental routing for FPGAs with complex switchboxes (SBox's) such as those in Lucent's ORCA and Xilinx's Virtex series. We introduce new concepts such as a B&amp;R cost in global routing and the optimal subnet set to relocate for each bumped net (determined using an efficient dynamic programming formulation). We developed optimal and near-optimal algorithms (called Subsec_B&amp;R and Subnet_B&amp;R, respectively) to find incremental routing solutions using the B&amp;R paradigm in complex FPGAs (e.g., Lucent&amp;apos;s ORCA FPGA) with &lt;i&gt;i&lt;/i&gt;-to-&lt;i&gt;j&lt;/i&gt; SBox's, as well as an optimal version Fullnet_B&amp;R for the VPR architecture from the University of Toronto using the simpler &lt;i&gt;i&lt;/i&gt;-to-&lt;i&gt;i&lt;/i&gt; SBox&amp;apos;s. We compared our algorithms (simply called B&amp;R when no distinction needs to be made between our versions) to two recent incremental routing techniques, Standard (Std) and Rip-up&amp;Reroute (R&amp;R), and to Lucent's A_PAR routing tool and the University of Toronto's VPR router used in complete rerouting modes. Experimental results for the ORCA show that B&amp;R is 10 to 20 times faster than complete rerouting using A_PAR, and that B&amp;R is also nearly 27&amp;percnt; faster and yields new nets with nearly 10&amp;percnt; smaller lengths compared to previous incremental routers. Furthermore, B&amp;R routers do not change either the lengths or topologies of existing nets, a significant advantage in ECO applications, in contrast to R&amp;R which increases the length of ripped-up nets by an average of 8.75 to 13.6&amp;percnt;. Experimental results for the VPR architecture are dominated by the significantly larger (in many cases, orders of magnitude more) number of nets left unrouted by Std and R&amp;R compared to B&amp;R, which highlights the much greater efficacy of B&amp;R-based incremental routing. However, B&amp;R is significantly slower than the other two incremental routers, although on an absolute scale it is quite fast for two of four cases we simulated; in one case, it is about 25 times faster than VPR used in the full rerouting mode. The relative slowness of B&amp;R for the VPR architecture arises from the fact that we used &lt;i&gt;i&lt;/i&gt;-to-&lt;i&gt;i&lt;/i&gt; SBox&amp;apos;s which forces each net to be routed on the same track, thus causing significantly more bumpings and searches for rearranged solutions compared to &lt;i&gt;i&lt;/i&gt;-to-&lt;i&gt;j&lt;/i&gt; SBox&amp;apos;s where a net can be routed on different interconnected tracks to minimize the amount of bumpings (as we did for the ORCA). Since modern FPGAs generally have the latter type of SBox&amp;apos;s, B&amp;R would be fast as well as very effective on them.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2061217021",
    "type": "article"
  },
  {
    "title": "Technology mapping algorithms for domino logic",
    "doi": "https://doi.org/10.1145/544536.544541",
    "publication_date": "2002-04-01",
    "publication_year": 2002,
    "authors": "Min Zhao; Sachin S. Sapatnekar",
    "corresponding_authors": "",
    "abstract": "We present an efficient algorithm for technology mapping of domino logic to a parameterized library. The algorithm is optimal for mapping trees consisting of two-input AND/OR nodes, and has a computation time that is polynomial in terms of constraint size. The mapping method is then extended to DAG covering that permits the implicit duplication of logic nodes. Our synthesis procedure maps the complementary logic cones independently when AND/OR logic is to be implemented, and together using dual-monotonic gates in the case of XOR/XNOR logic. The mapping procedure solves the output phase assignment problem as a preprocessing step. Based on a key observation that the output phase assignment could reduce the implementation cost due to the possible large cost difference between two polarities, a 0--1 integer linear programming formulation was designed to minimize the implementation cost. Our experimental results show the effectiveness of the proposed techniques.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2081932102",
    "type": "article"
  },
  {
    "title": "A codesign back-end approach for embedded system design",
    "doi": "https://doi.org/10.1145/348019.348156",
    "publication_date": "2000-07-01",
    "publication_year": 2000,
    "authors": "Guy Gogniat; Michel Auguin; Luc Bianco; Alain Pégatoquet",
    "corresponding_authors": "",
    "abstract": "Continuous advances in processor and ASIC technologies enable the integration of more and more complex embedded systems. Since their implementations generally require the use of heterogeneous resources (e.g., processor cores, ASICs) in one system with stringent design constraints, the importance of hardware/software codesign methodologies increases steadily. Interfacing heterogeneous hardware and software components together through a communication structure is particularly error prone and time consuming. Hence, on the basis of a generic architecute dedicated to telecommunication and multimedia applications, we proposed an extended communication synthesis method that provides characterization of communications and their implementation schemes in the target architecture. This method takes place after the partitioning and scheduling phase and may constitute the basis of a back-end of a codesign framework leading to HW/SW integration.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2165245782",
    "type": "article"
  },
  {
    "title": "Manhattan-diagonal routing in channels and switchboxes",
    "doi": "https://doi.org/10.1145/966137.966141",
    "publication_date": "2004-01-01",
    "publication_year": 2004,
    "authors": "Sandip Das; Susmita Sur‐Kolay; Bhargab B. Bhattacharya",
    "corresponding_authors": "",
    "abstract": "New techniques are presented for routing straight channels, L-channels, switchboxes, and staircase channels in a two-layer Manhattan-diagonal (MD) model with tracks in horizontal, vertical, and ± 45° directions. First, an O ( l.d ) time algorithm is presented for routing a straight channel of length l and density d with no cyclic vertical constraints . It is shown that the number of tracks h used by the algorithm for routing multiterminal nets satisfies d ≤ h ≤ ( d + 1). Second, an output-sensitive algorithm is reported that can route a channel with cyclic vertical constraints in O ( l.h ) time using h tracks, allowing overlapping of wire segments in two layers. Next, the routing problem for a multiterminal L-channel of length l and height h is solved by an O ( l.h ) time algorithm. If no cyclic vertical constraints exist, its time complexity reduces to O ( l.d ) where d is the density of the L-channel. Finally, the switchbox routing problem in the MD model is solved elegantly. These techniques, easily extendible to the routing of staircase channels, yield efficient solutions to detailed routing in general floorplans. Experimental results on benchmarks show significantly low via count and reduced wire length, thus establishing the superiority of MD routing to classical strategies. The proposed algorithms are also potentially useful for general non-Manhattan area routing and multichip modules (MCMs).",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W1965798923",
    "type": "article"
  },
  {
    "title": "Bipartitioning and encoding in low-power pipelined circuits",
    "doi": "https://doi.org/10.1145/1044111.1044114",
    "publication_date": "2005-01-01",
    "publication_year": 2005,
    "authors": "Shanq-Jang Ruan; Kun-Lin Tsai; Edwin Naroska; Feipei Lai",
    "corresponding_authors": "",
    "abstract": "In this article, we present a bipartition dual-encoding architecture for low-power pipelined circuits. We exploit the bipartition approach as well as encoding techniques to reduce power dissipation not only of combinational logic blocks but also of the pipeline registers. Based on Shannon expansion, we partition a given circuit into two subcircuits such that the number of different outputs of both subcircuits are reduced, and then encode the output of both subcircuits to minimize the Hamming distance for transitions with a high switching probability. We measure the benefits of four different combinational bipartitioning and encoding architectures for comparison. The transistor-level simulation results show that bipartition dual-encoding can effectively reduce power by 72.7% for the pipeline registers and 27.1% for the total power consumption on average. To the best of our knowledge, it is the first work that presents an in-depth study on bipartition and encoding techniques to optimize power for pipelined circuits.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2079702144",
    "type": "article"
  },
  {
    "title": "Voltage scheduling under unpredictabilities: a risk management paradigm",
    "doi": "https://doi.org/10.1145/1059876.1059884",
    "publication_date": "2005-04-01",
    "publication_year": 2005,
    "authors": "Azadeh Davoodi; Ankur Srivastava",
    "corresponding_authors": "",
    "abstract": "This article addresses the problem of voltage scheduling in unpredictable situations. The voltage scheduling problem assigns voltages to operations such that the power is minimized under a clock delay constraint. In the presence of unpredictabilities, meeting the clock latency constraint cannot be guaranteed. This article proposes a novel risk management based technique to solve this problem. Here, the risk management paradigm assigns a quantified value to the amount of risk the designer is willing to take on the clock cycle constraint. The algorithm then assigns voltages in order to meet the expected value of clock cycle constraint while keeping the maximum delay within the specified “risk” and minimizing the power. The proposed algorithm is based on dynamic programming and is optimal for trees. Experimental results show that the traditional voltage scheduling approach is incapable of handling unpredictabilities. Our approach is capable of generating an effective tradeoff between power and “risk”: the more the risk, the less the power. The results show that a small increase in design risk positively affects the power dissipation.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2130685092",
    "type": "article"
  },
  {
    "title": "A Conditionally Chaotic Physically Unclonable Function Design Framework with High Reliability",
    "doi": "https://doi.org/10.1145/3460004",
    "publication_date": "2021-08-12",
    "publication_year": 2021,
    "authors": "Saranyu Chattopadhyay; Pranesh Santikellur; Rajat Subhra Chakraborty; Jimson Mathew; Marco Ottavi",
    "corresponding_authors": "",
    "abstract": "Physically Unclonable Function (PUF) circuits are promising low-overhead hardware security primitives, but are often gravely susceptible to machine learning–based modeling attacks. Recently, chaotic PUF circuits have been proposed that show greater robustness to modeling attacks. However, they often suffer from unacceptable overhead, and their analog components are susceptible to low reliability. In this article, we propose the concept of a conditionally chaotic PUF that enhances the reliability of the analog components of a chaotic PUF circuit to a level at par with their digital counterparts. A conditionally chaotic PUF has two modes of operation: bistable and chaotic , and switching between these two modes is conveniently achieved by setting a mode-control bit (at a secret position) in an applied input challenge. We exemplify our PUF design framework for two different PUF variants—the CMOS Arbiter PUF and a previously proposed hybrid CMOS-memristor PUF, combined with a hardware realization of the Lorenz system as the chaotic component. Through detailed circuit simulation and modeling attack experiments, we demonstrate that the proposed PUF circuits are highly robust to modeling and cryptanalytic attacks, without degrading the reliability of the original PUF that was combined with the chaotic circuit, and incurs acceptable hardware footprint.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W3195388298",
    "type": "article"
  },
  {
    "title": "Demand-Driven Multi-Target Sample Preparation on Resource-Constrained Digital Microfluidic Biochips",
    "doi": "https://doi.org/10.1145/3474392",
    "publication_date": "2021-09-13",
    "publication_year": 2021,
    "authors": "Sudip Poddar; Sukanta Bhattacharjee; Shao‐Yun Fang; Tsung-Yi Ho; Bhargab B. Bhattacharya",
    "corresponding_authors": "",
    "abstract": "Microfluidic lab-on-chips offer promising technology for the automation of various biochemical laboratory protocols on a minuscule chip. Sample preparation (SP) is an essential part of any biochemical experiments, which aims to produce dilution of a sample or a mixture of multiple reagents in a certain ratio. One major objective in this area is to prepare dilutions of a given fluid with different concentration factors, each with certain volume, which is referred to as the demand-driven multiple-target (DDMT) generation problem. SP with microfluidic biochips requires proper sequencing of mix-split steps on fluid volumes and needs storage units to save intermediate fluids while producing the desired target ratio. The performance of SP depends on the underlying mixing algorithm and the availability of on-chip storage, and the latter is often limited by the constraints imposed during physical design. Since DDMT involves several target ratios, solving it under storage constraints becomes even harder. Furthermore, reduction of mix-split steps is desirable from the viewpoint of accuracy of SP, as every such step is a potential source of volumetric split error. In this article, we propose a storage-aware DDMT algorithm that reduces the number of mix-split operations on a digital microfluidic lab-on-chip. We also present the layout of the biochip with <?TeX $k$?> -storage cells and their allocation technique for <?TeX $k \\ge 0$?> . Simulation results reveal the superiority of the proposed method compared to the state-of-the-art multi-target SP algorithms.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W3199061047",
    "type": "article"
  },
  {
    "title": "Synthesizing Brain-network-inspired Interconnections for Large-scale Network-on-chips",
    "doi": "https://doi.org/10.1145/3480961",
    "publication_date": "2021-10-15",
    "publication_year": 2021,
    "authors": "Mengke Ge; Xiaobing Ni; Qi Xu; Song Chen; Jinglei Huang; Yi Kang; Feng Wu",
    "corresponding_authors": "",
    "abstract": "Brain network is a large-scale complex network with scale-free, small-world, and modularity properties, which largely supports this high-efficiency massive system. In this article, we propose to synthesize brain-network-inspired interconnections for large-scale network-on-chips. First, we propose a method to generate brain-network-inspired topologies with limited scale-free and power-law small-world properties, which have a low total link length and extremely low average hop count approximately proportional to the logarithm of the network size. In addition, given the large-scale applications, considering the modularity of the brain-network-inspired topologies, we present an application mapping method, including task mapping and deterministic deadlock-free routing, to minimize the power consumption and hop count. Finally, a cycle-accurate simulator BookSim2 is used to validate the architecture performance with different synthetic traffic patterns and large-scale test cases, including real-world communication networks for the graph processing application. Experiments show that, compared with other topologies and methods, the brain-network-inspired network-on-chips (NoCs) generated by the proposed method present significantly lower average hop count and lower average latency. Especially in graph processing applications with a power-law and tightly coupled inter-core communication, the brain-network-inspired NoC has up to 70% lower average hop count and 75% lower average latency than mesh-based NoCs.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W3207386547",
    "type": "article"
  },
  {
    "title": "FPGAPRO: A Defense Framework Against Crosstalk-Induced Secret Leakage in FPGA",
    "doi": "https://doi.org/10.1145/3491214",
    "publication_date": "2021-11-17",
    "publication_year": 2021,
    "authors": "Yukui Luo; Shijin Duan; Xiaolin Xu",
    "corresponding_authors": "",
    "abstract": "With the emerging cloud-computing development, FPGAs are being integrated with cloud servers for higher performance. Recently, it has been explored to enable multiple users to share the hardware resources of a remote FPGA, i.e., to execute their own applications simultaneously. Although being a promising technique, multi-tenant FPGA unfortunately brings its unique security concerns. It has been demonstrated that the capacitive crosstalk between FPGA long-wires can be a side-channel to extract secret information, giving adversaries the opportunity to implement crosstalk-based side-channel attacks. Moreover, recent work reveals that medium-wires and multiplexers in configurable logic block (CLB) are also vulnerable to crosstalk-based information leakage. In this work, we propose FPGAPRO: a defense framework leveraging P lacement, R outing, and O bfuscation to mitigate the secret leakage on FPGA components, including long-wires, medium-wires, and logic elements in CLB. As a user-friendly defense strategy, FPGAPRO focuses on protecting the security-sensitive instances meanwhile considering critical path delay for performance maintenance. As the proof-of-concept, the experimental result demonstrates that FPGAPRO can effectively reduce the crosstalk-caused side-channel leakage by 138 times. Besides, the performance analysis shows that this strategy prevents the maximum frequency from timing violation.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W3212359234",
    "type": "article"
  },
  {
    "title": "Leakage reduction, delay compensation using partition-based tunable body-biasing techniques",
    "doi": "https://doi.org/10.1145/1562514.1562521",
    "publication_date": "2009-08-01",
    "publication_year": 2009,
    "authors": "Po‐Yuan Chen; Chiao-Chen Fang; TingTing Hwang; Hsi‐Pin Ma",
    "corresponding_authors": "",
    "abstract": "In recent years, fabrication technology of CMOS has scaled to nanometer dimensions. As scaling progresses, several new challenges follow. Among them, the most noticeable two are process variations and leakage current of the circuit. To tackle the problems of process variations and leakage current, an effective way is to use a body-biasing technique. In substance, using the RBB technique can minimize leakage current but increase the delay of a gate. Contrary to RBB, the FBB technique decreases the delay but increases leakage current of a gate. In the previous work, a single body-biasing is applied to the whole circuit. In a slow circuit, since the FBB is applied to the whole circuit, the leakage current of all gates in the circuit increases dramatically. On the other hand, in a fast circuit, RBB is applied to decrease the leakage current. However, without violating the timing specification, the value of body-biasing is restricted by the critical paths, and the saving of leakage current is limited. In this article, we propose a design flow to partition the circuit into subcircuits so that each subcircuit can be applied its individual RBB or FBB. Experiments show that our method is able to save leakage current from 42% to 47% as compared to designs not using a body-biasing technique. Under process variations, our method can save 42% to 49% leakage on fast circuits and 20% to 35% on slow circuits.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W1998618592",
    "type": "article"
  },
  {
    "title": "Provably efficient algorithms for resolving temporal and spatial difference constraint violations",
    "doi": "https://doi.org/10.1145/1455229.1455237",
    "publication_date": "2009-01-01",
    "publication_year": 2009,
    "authors": "Ali Dasdan",
    "corresponding_authors": "Ali Dasdan",
    "abstract": "A system of difference constraints is a formal model of temporal and spatial constraints in many areas such as scheduling, constraint satisfaction, and layout compaction. During construction of such a system, constraint violations often arise, and they need to be resolved. Previous algorithms for this task fall into two groups: those algorithms that are fast but cannot resolve all violations, and those algorithms that can resolve all violations but are exponentially slow. We propose the first algorithms that are fast as well as able to resolve all violations. Moreover, unlike the previous algorithms, our algorithms support the ordering of violations using their inherent criticality or user-defined priority. We provably and experimentally justify the efficiency and efficacy of our algorithms.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2019162551",
    "type": "article"
  },
  {
    "title": "Opposite-phase register switching for peak current minimization",
    "doi": "https://doi.org/10.1145/1455229.1455243",
    "publication_date": "2009-01-01",
    "publication_year": 2009,
    "authors": "Shih-Hsu Huang; Chia-Ming Chang; Yow-Tyng Nieh",
    "corresponding_authors": "",
    "abstract": "In a synchronous sequential circuit, huge current peaks are often observed at the moment of clock transition (since all registers are clocked). Previous works focus on reducing the number of switching registers. However, even though the switching registers are the same, different combinations of switching directions still result in different peak currents. Based on that observation, in this article, we propose an ECO (engineering change order) approach to minimize the peak current by considering the switching directions of registers. Our approach is well suitable for reducing the peak current in IC testing. Experimental data consistently show that our approach works well in practice.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2062318551",
    "type": "article"
  },
  {
    "title": "System-level PVT variation-aware power exploration of on-chip communication architectures",
    "doi": "https://doi.org/10.1145/1497561.1497563",
    "publication_date": "2009-03-01",
    "publication_year": 2009,
    "authors": "Sudeep Pasricha; Young-Hwan Park; Nikil Dutt; Fadi Kurdahi",
    "corresponding_authors": "",
    "abstract": "With the shift towards deep submicron (DSM) technologies, the increase in leakage power and the adoption of power-aware design methodologies have resulted in potentially significant variations in power consumption under different process, voltage, and temperature (PVT) corners. In this article, we first investigate the impact of PVT corners on power consumption at the system-on-chip (SoC) level, especially for the on-chip communication infrastructure. Given a target technology library, we then show how it is possible to “scale up” and abstract the PVT variability at the system level, allowing characterization of the PVT-aware design space early in the design flow. We conducted several experiments to estimate power for PVT corner cases, at the gate level, as well as at the higher system level. Our preliminary results are very interesting, and indicate that (i) there are significant variations in power consumption across PVT corners; and (ii) the PVT-aware power estimation problem may be amenable to a reasonably simple abstraction at the system level.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2141089164",
    "type": "article"
  },
  {
    "title": "Computation of Seeds for <i>LFSR</i> -Based <i>n</i> -Detection Test Generation",
    "doi": "https://doi.org/10.1145/2994144",
    "publication_date": "2017-01-04",
    "publication_year": 2017,
    "authors": "Irith Pomeranz",
    "corresponding_authors": "Irith Pomeranz",
    "abstract": "This article describes a new procedure that generates seeds for LFSR -based test generation when the goal is to produce an n -detection test set. The procedure does not use test cubes in order to avoid the situation where a seed does not exist for a given test cube with a given LFSR . Instead, the procedure starts from a set of seeds that produces a one-detection test set. It modifies seeds to obtain new seeds such that the tests they produce increase the numbers of detections of target faults. The modification procedure also increases the number of faults that each additional seed detects. Experimental results are presented to demonstrate the effectiveness of the procedure.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2570421387",
    "type": "article"
  },
  {
    "title": "Spatio-Temporal Scheduling of Preemptive Real-Time Tasks on Partially Reconfigurable Systems",
    "doi": "https://doi.org/10.1145/3056561",
    "publication_date": "2017-06-13",
    "publication_year": 2017,
    "authors": "Sangeet Saha; Arnab Sarkar; Amlan Chakrabarti",
    "corresponding_authors": "",
    "abstract": "Reconfigurable devices that promise to offer the twin benefits of flexibility as in general-purpose processors along with the efficiency of dedicated hardwares often provide a lucrative solution for many of today’s highly complex real-time embedded systems. However, online scheduling of dynamic hard real-time tasks on such systems with efficient resource utilization in terms of both space and time poses an enormously challenging problem. We attempt to solve this problem using a combined offline-online approach. The offline component generates and stores various optional feasible placement solutions for different sub-sets of tasks that may possibly be co-mapped together. Given a set of periodic preemptive real-time tasks that requires to be executed at runtime, the online scheduler first carries out an admission control procedure and then produces a schedule, which is guaranteed to meet all timing constraints provided it is spatially feasible to place designated subsets of these tasks at specified scheduling points within a future time interval. These feasibility checks are done and actual placement solutions are obtained through a low overhead search of the statically precomputed placement solutions. Based on this approach, we have proposed a periodic preemptive real-time scheduling methodology for runtime partially reconfigurable devices. Effectiveness of the proposed strategy has been verified through simulation based experiments and we observed that the strategy achieves high resource utilization with low task rejection rates over various simulation scenarios.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2624889741",
    "type": "article"
  },
  {
    "title": "Incremental Layer Assignment for Timing Optimization",
    "doi": "https://doi.org/10.1145/3083727",
    "publication_date": "2017-06-13",
    "publication_year": 2017,
    "authors": "Derong Liu; Bei Yu; Salim Chowdhury; David Z. Pan",
    "corresponding_authors": "",
    "abstract": "With VLSI technology nodes scaling into the nanometer regime, interconnect delay plays an increasingly critical role in timing. For layer assignment, most works deal with via counts or total net delays, ignoring critical paths of each net and resulting in potential timing issues. In this article, we propose an incremental layer assignment framework targeting delay optimization in timing the critical path of each net. A set of novel techniques are presented: self-adaptive quadruple partition based on K × K division benefits the runtime; semidefinite programming is utilized for each partition; and the sequential mapping algorithm guarantees integer solutions while satisfying edge capacities; additionally, concurrent mapping offers a global view of assignment and post delay optimization reduces the path timing violations. The effectiveness of our work is verified by ISPD’08 benchmarks.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2625969775",
    "type": "article"
  },
  {
    "title": "VFI-Based Power Management to Enhance the Lifetime of High-Performance 3D NoCs",
    "doi": "https://doi.org/10.1145/3092843",
    "publication_date": "2017-08-31",
    "publication_year": 2017,
    "authors": "Sourav Das; Dongjin Lee; Wonje Choi; Janardhan Rao Doppa; Partha Pratim Pande; Krishnendu Chakrabarty",
    "corresponding_authors": "",
    "abstract": "The emergence of 3D network-on-chip (NoC) has revolutionized the design of high-performance and energy-efficient manycore chips. However, the anticipated performance gain can be compromised due to the degradation and failure of vertical links (VLs). The Through-Silicon-Via (TSV)-enabled VLs may fail due to workload-induced stress; the failure of a VL can affect the neighboring VLs, thereby causing a cascade of failures and reducing the lifetime of the chip. To enhance the reliability of 3D NoC-enabled manycore chips, we propose to incorporate a voltage-frequency island (VFI)-based power management strategy that helps to reduce the energy consumption and hence, the workload-induced stress of the highly utilized VLs. The adopted power-management strategy relies on control decisions about the voltage/frequency (V/F) levels on VLs. We demonstrate that compared to the well-known spare TSV allocation and adaptive routing strategies, power management is more effective in enhancing the reliability of a 3D NoC. VFI-based power management improves the reliability of the 3D NoC by one order of magnitude compared to both adaptive routing and spare allocation while running popular SPLASH-2 and PARSEC benchmarks. The principal benefit of power management is that it is capable of reducing the operating temperature of the system, which in turn enhances the Mean-Time-To-Failure (MTTF) of the VLs and reliability of the overall 3D NoC.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2750802292",
    "type": "article"
  },
  {
    "title": "Architectural Supports to Protect OS Kernels from Code-Injection Attacks and Their Applications",
    "doi": "https://doi.org/10.1145/3110223",
    "publication_date": "2017-08-31",
    "publication_year": 2017,
    "authors": "Hyungon Moon; Jin‐Yong Lee; Dongil Hwang; Seonhwa Jung; Jiwon Seo; Yunheung Paek",
    "corresponding_authors": "",
    "abstract": "The kernel code injection is a common behavior of kernel-compromising attacks where the attackers aim to gain their goals by manipulating an OS kernel. Several security mechanisms have been proposed to mitigate such threats, but they all suffer from non-negligible performance overhead. This article introduces a hardware reference monitor, called Kargos, which can detect the kernel code injection attacks with nearly zero performance cost. Kargos monitors the behaviors of an OS kernel from outside the CPU through the standard bus interconnect and debug interface available with most major microprocessors. By watching the execution traces and memory access events in the monitored target system, Kargos uncovers attempts to execute malicious code with the kernel privilege. On top of this, we also applied the architectural supports for Kargos to the detection of ROP attacks. KS-Stack is the hardware component that builds and maintains the shadow stacks using the existing supports to detect this ROP attacks. According to our experiments, Kargos detected all the kernel code injection attacks that we tested, yet just increasing the computational loads on the target CPU by less than 1% on average. The performance overhead of the KS-Stack was also less than 1%.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2751885091",
    "type": "article"
  },
  {
    "title": "Recovering from Biased Distribution of Faulty Cells in Memory by Reorganizing Replacement Regions through Universal Hashing",
    "doi": "https://doi.org/10.1145/3131241",
    "publication_date": "2017-10-05",
    "publication_year": 2017,
    "authors": "Jaeyung Jun; Kyu Hyun Choi; HoKwon Kim; Sang Ho Yu; Seon Wook Kim; Youngsun Han",
    "corresponding_authors": "",
    "abstract": "Recently, scaling down dynamic random access memory (DRAM) has become more of a challenge, with more faults than before and a significant degradation in yield. To improve the yield in DRAM, a redundancy repair technique with intra-subarray replacement has been extensively employed to replace faulty elements (i.e., rows or columns with defective cells) with spare elements in each subarray. Unfortunately, such technique cannot efficiently handle a biased distribution of faulty cells because each subarray has a fixed number of spare elements. In this article, we propose a novel redundancy repair technique that uses a hashing method to solve this problem. Our hashing technique reorganizes replacement regions by changing the way in which their replacement information is referred, thus making faulty cells become evenly distributed to the regions. We also propose a fast repair algorithm to find the best hash function among all possible candidates. Even if our approach requires little hardware overhead, it significantly improves the yield when compared with conventional redundancy techniques. In particular, the results of our experiment show that our technique saves spare elements by about 57% and 55% for a yield of 99% at BER 1e-6 and 5e-7, respectively.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2762037143",
    "type": "article"
  },
  {
    "title": "Runtime Slack Creation for Processor Performance Variability using System Scenarios",
    "doi": "https://doi.org/10.1145/3152158",
    "publication_date": "2017-12-21",
    "publication_year": 2017,
    "authors": "Michail Noltsis; Dimitrios Rodopoulos; Nikolaos Zompakis; Francky Catthoor; Dimitrios Soudris",
    "corresponding_authors": "",
    "abstract": "Modern microprocessors contain a variety of mechanisms used to mitigate errors in the logic and memory, referred to as Reliability, Availability, and Serviceability (RAS) techniques. Many of these techniques, such as component disabling, come at a performance cost. With the aggressive downscaling of device dimensions, it is reasonable to expect that chip-wide error rates will intensify in the future and perhaps vary throughout system lifetime. As a result, it is important to reclaim the temporal RAS overheads in a systematic way and enable dependable performance. The current article presents a closed-loop control scheme that actuates processor’s frequency based on detected timing interference to ensure performance dependability. The concepts of slack and deadline vulnerability factor are introduced to support the formulation of a discrete time control problem. Default application timing is derived using the system scenario methodology, the applicability of which is demonstrated through simulations. Additionally, the proposed concept is demonstrated on a real platform and application: a Proportional-Integral-Differential controller, implemented within the application, actuates the Dynamic Voltage and Frequency Scaling (DVFS) framework of the Linux kernel to effectively reclaim temporal overheads injected at runtime. The current article discusses the responsiveness and energy efficiency of the proposed performance dependability scheme. Finally, additional formulation is introduced to predict the upper bound of timing interference that can be absorbed by actuating the DVFS of any processor and is also validated on a representative reduction to practice.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2776092915",
    "type": "article"
  },
  {
    "title": "A Symbolic Approach to Detecting Hardware Trojans Triggered by Don’t Care Transitions",
    "doi": "https://doi.org/10.1145/3558392",
    "publication_date": "2022-08-22",
    "publication_year": 2022,
    "authors": "Ruochen Dai; Tuba Yavuz",
    "corresponding_authors": "",
    "abstract": "Due to the globalization of Integrated Circuit supply chain, hardware Trojans and the attacks that can trigger them have become an important security issue. One type of hardware Trojans leverages the “don’t care transitions” in Finite-state Machines (FSMs) of hardware designs. In this article, we present a symbolic approach to detecting don’t care transitions and the hidden Trojans. Our detection approach works at both register-transfer level (RTL) and gate level, does not require a golden design, and works in three stages. In the first stage, it explores the reachable states. In the second stage, it performs an approximate analysis to find the don’t care transitions and any discrepancies in the register values or output lines due to don’t care transitions. The second stage can be used for both predicting don’t care triggered Trojans and for guiding don’t care aware reachability analysis. In the third stage, it performs a state-space exploration from reachable states that have incoming don’t care transitions to explore the Trojan payload and to find behavioral discrepancies with respect to what has been observed in the first stage. We also present a pruning technique based on the reachability of FSM states. We present a methodology that leverages both RTL and gate-level for soundness and efficiency. Specifically, we show that don’t care transitions and Trojans that leverage them must be detected at the gate-level, i.e., after synthesis has been performed, for soundness. However, under specific conditions, Trojan payload exploration can be performed more efficiently at RTL. Additionally, the modular design of our approach also provides a fast Trojan prediction method even at the gate level when the reachable states of the FSM is known a priori . Evaluation of our approach on a set of benchmarks from OpenCores and TrustHub and using gate-level representation generated by two synthesis tools, YOSYS and Synopsis Design Compiler (SDC), shows that our approach is both efficient (up to 10× speedup w.r.t. no pruning) and precise (0% false positives both at RTL and gate-level netlist) in detecting don’t care transitions and the Trojans that leverage them. Additionally, the total analysis time can achieve up to 1.62× (using YOSYS) and 1.92× (using SDC) speedup when synthesis preserves the FSM structure, the foundry is trusted, and the Trojan detection is performed at RTL.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W3211476435",
    "type": "article"
  },
  {
    "title": "E2HRL: An Energy-efficient Hardware Accelerator for Hierarchical Deep Reinforcement Learning",
    "doi": "https://doi.org/10.1145/3498327",
    "publication_date": "2022-02-24",
    "publication_year": 2022,
    "authors": "Aidin Shiri; Uttej Kallakuri; Hasib-Al Rashid; Bharat Prakash; Nicholas R. Waytowich; Tim Oates; Tinoosh Mohsenin",
    "corresponding_authors": "",
    "abstract": "Recently, Reinforcement Learning (RL) has shown great performance in solving sequential decision-making and control in dynamic environment problems. Despite its achievements, deploying Deep Neural Network (DNN)-based RL is expensive in terms of time and power due to the large number of episodes required to train agents with high dimensional image representations. Additionally, at the interference the large energy footprint of deep neural networks can be a major drawback. Embedded edge devices as the main platform for deploying RL applications are intrinsically resource-constrained and deploying deep neural network-based RL on them is a challenging task. As a result, reducing the number of actions taken by the RL agent to learn desired policy, along with the energy-efficient deployment of RL, is crucial. In this article, we propose Energy Efficient Hierarchical Reinforcement Learning (E2HRL), which is a scalable hardware architecture for RL applications. E2HRL utilizes a cross-layer design methodology for achieving better energy efficiency, smaller model size, higher accuracy, and system integration at the software and hardware layers. Our proposed model for RL agent is designed based on the learning hierarchical policies, which makes the network architecture more efficient for implementation on mobile devices. We evaluated our model in three different RL environments with different level of complexity. Simulation results with our analysis illustrate that hierarchical policy learning with several levels of control improves RL agents training efficiency and the agent learns the desired policy faster compared to a non-hierarchical model. This improvement is specifically more observable as the environment or the task becomes more complex with multiple objective subgoals. We tested our model with different hyperparameters to achieve the maximum reward by the RL agent while minimizing the model size, parameters, and required number of operations. E2HRL model enables efficient deployment of RL agent on resource-constraint-embedded devices with the proposed custom hardware architecture that is scalable and fully parameterized with respect to the number of input channels, filter size, and depth. The number of processing engines (PE) in the proposed hardware can vary between 1 to 8, which provides the flexibility of tradeoff of different factors such as latency, throughput, power, and energy efficiency. By performing a systematic hardware parameter analysis and design space exploration, we implemented the most energy-efficient hardware architectures of E2HRL on Xilinx Artix-7 FPGA and NVIDIA Jetson TX2. Comparing the implementation results shows Jetson TX2 boards achieve 0.1 ∼ 1.3 GOP/S/W energy efficiency while Artix-7 FPGA achieves 1.1 ∼ 11.4 GOP/S/W, which denotes 8.8× ∼ 11× better energy efficiency of E2HRL when model is implemented on FPGA. Additionally, compared to similar works our design shows better performance and energy efficiency.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4213412700",
    "type": "article"
  },
  {
    "title": "Implication of Optimizing NPU Dataflows on Neural Architecture Search for Mobile Devices",
    "doi": "https://doi.org/10.1145/3513085",
    "publication_date": "2022-02-24",
    "publication_year": 2022,
    "authors": "Jooyeon Lee; Junsang Park; Seunghyun Lee; Jaeha Kung",
    "corresponding_authors": "",
    "abstract": "Recent advances in deep learning have made it possible to implement artificial intelligence in mobile devices. Many studies have put a lot of effort into developing lightweight deep learning models optimized for mobile devices. To overcome the performance limitations of manually designed deep learning models, an automated search algorithm, called neural architecture search ( NAS ), has been proposed. However, studies on the effect of hardware architecture of the mobile device on the performance of NAS have been less explored. In this article, we show the importance of optimizing a hardware architecture, namely, NPU dataflow, when searching for a more accurate yet fast deep learning model. To do so, we first implement an optimization framework, named FlowOptimizer, for generating a best possible NPU dataflow for a given deep learning operator. Then, we utilize this framework during the latency-aware NAS to find the model with the highest accuracy satisfying the latency constraint. As a result, we show that the searched model with FlowOptimizer outperforms the performance by 87.1% and 92.3% on average compared to the searched model with NVDLA and Eyeriss, respectively, with better accuracy on a proxy dataset. We also show that the searched model can be transferred to a larger model to classify a more complex image dataset, i.e., ImageNet, achieving 0.2%/5.4% higher Top-1/Top-5 accuracy compared to MobileNetV2-1.0 with 3.6 \\( \\times \\) lower latency.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4213427773",
    "type": "article"
  },
  {
    "title": "BoA-PTA: A Bayesian Optimization Accelerated PTA Solver for SPICE Simulation",
    "doi": "https://doi.org/10.1145/3555805",
    "publication_date": "2022-08-13",
    "publication_year": 2022,
    "authors": "Wei Xing; Xiang Jin; Feng Tian; Dan Niu; Weisheng Zhao; Zhou Jin",
    "corresponding_authors": "",
    "abstract": "One of the greatest challenges in integrated circuit design is the repeated executions of computationally expensive SPICE simulations, particularly when highly complex chip testing/verification is involved. Recently, pseudo-transient analysis (PTA) has shown to be one of the most promising continuation SPICE solvers. However, the PTA efficiency is highly influenced by the inserted pseudo-parameters. In this work, we proposed BoA-PTA, a Bayesian optimization accelerated PTA that can substantially accelerate simulations and improve convergence performance without introducing extra errors. Furthermore, our method does not require any pre-computation data or offline training. The acceleration framework can either speed up ongoing, repeated simulations (e.g., Monte-Carlo simulations) immediately or improve new simulations of completely different circuits. BoA-PTA is equipped with cutting-edge machine learning techniques, such as deep learning, Gaussian process, Bayesian optimization, non-stationary monotonic transformation, and variational inference via reparameterization. We assess BoA-PTA in 43 benchmark circuits and real industrial circuits against other SOTA methods and demonstrate an average of 1.5x (maximum 3.5x) for the benchmark circuits and up to 250x speedup for the industrial circuit designs over the original CEPTA without sacrificing any accuracy.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4291202462",
    "type": "article"
  },
  {
    "title": "<scp>Virtuoso</scp> : Energy- and Latency-aware Streamlining of Streaming Videos on Systems-on-Chips",
    "doi": "https://doi.org/10.1145/3564289",
    "publication_date": "2022-10-03",
    "publication_year": 2022,
    "authors": "Jayoung Lee; Pengcheng Wang; Ran Xu; Sarthak Jain; Venkat Dasari; Noah Weston; Yin Li; Saurabh Bagchi; Somali Chaterji",
    "corresponding_authors": "",
    "abstract": "Efficient and adaptive computer vision systems have been proposed to make computer vision tasks, such as image classification and object detection, optimized for embedded or mobile devices. These solutions, quite recent in their origin, focus on optimizing the model (a deep neural network) or the system by designing an adaptive system with approximation knobs. Despite several recent efforts, we show that existing solutions suffer from two major drawbacks. First , while mobile devices or systems-on-chips usually come with limited resources including battery power, most systems do not consider the energy consumption of the models during inference. Second , they do not consider the interplay between the three metrics of interest in their configurations, namely, latency, accuracy, and energy. In this work, we propose an efficient and adaptive video object detection system— Virtuoso , which is jointly optimized for accuracy, energy efficiency, and latency. Underlying Virtuoso is a multi-branch execution kernel that is capable of running at different operating points in the accuracy-energy-latency axes, and a lightweight runtime scheduler to select the best fit execution branch to satisfy the user requirement. We position this work as a first step in understanding the suitability of various object detection kernels on embedded boards in the accuracy-latency-energy axes, opening the door for further development in solutions customized to embedded systems and for benchmarking such solutions. Virtuoso is able to achieve up to 286 FPS on the NVIDIA Jetson AGX Xavier board, which is up to 45× faster than the baseline EfficientDet D3 and 15× faster than the baseline EfficientDet D0. In addition, we also observe up to 97.2% energy reduction using Virtuoso compared to the baseline YOLO (v3)—a widely used object detector designed for mobiles. To fairly compare with Virtuoso , we benchmark 15 state-of-the-art or widely used protocols, including Faster R-CNN (FRCNN) [NeurIPS’15], YOLO v3 [CVPR’16], SSD [ECCV’16], EfficientDet [CVPR’20], SELSA [ICCV’19], MEGA [CVPR’20], REPP [IROS’20], FastAdapt [EMDL’21], and our in-house adaptive variants of FRCNN+, YOLO+, SSD+, and EfficientDet+ (our variants have enhanced efficiency for mobiles). With this comprehensive benchmark, Virtuoso has shown superiority to all the above protocols, leading the accuracy frontier at every efficiency level on NVIDIA Jetson mobile GPUs. Specifically, Virtuoso has achieved an accuracy of 63.9%, which is more than 10% higher than some of the popular object detection models, FRCNN at 51.1% and YOLO at 49.5%.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4300865491",
    "type": "article"
  },
  {
    "title": "Accuracy Configurable Adders with Negligible Delay Overhead in Exact Operating Mode",
    "doi": "https://doi.org/10.1145/3549936",
    "publication_date": "2022-10-26",
    "publication_year": 2022,
    "authors": "Farhad Ebrahimi-Azandaryani; Omid Akbari; Mehdi Kamal; Ali Afzali‐Kusha; Massoud Pedram",
    "corresponding_authors": "",
    "abstract": "In this paper, two accuracy configurable adders capable of operating in approximate and exact modes are proposed. In the adders, which include a block-based carry propagate and a parallel prefix structure, the carry chains are cut off in the approximate mode limiting the carry chain depth to two blocks. In the case of parallel prefix adder, we propose a special carry generate tree equipped with a power gating means. In both of the proposed structures, the critical paths of the adders are not increased in the exact operating mode. Thus, the main objective of proposing these approximate adder structures is to present an accuracy configurable adder structure whose delay in the exact mode is almost the same as an exact adder. The efficacies of the proposed accuracy configurable adders are compared with some state-of-the-art adder structures using a 15nm CMOS technology. In addition, their efficacies are evaluated in two error-resilient applications. These studies show that the proposed carry-propagate adder has 22% (51%) lower energy consumption (error rate) compared to the best prior works. Also, the proposed parallel prefix adder provides, on average, 20% lower energy consumption compared to the exact parallel prefix adders.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4308520830",
    "type": "article"
  },
  {
    "title": "GANDSE: Generative Adversarial Network-based Design Space Exploration for Neural Network Accelerator Design",
    "doi": "https://doi.org/10.1145/3570926",
    "publication_date": "2022-11-09",
    "publication_year": 2022,
    "authors": "Lang Feng; Wenjian Liu; Chuliang Guo; Ke Tang; Cheng Zhuo; Zhongfeng Wang",
    "corresponding_authors": "",
    "abstract": "With the popularity of deep learning, the hardware implementation platform of deep learning has received increasing interest. Unlike the general purpose devices, e.g., CPU or GPU, where the deep learning algorithms are executed at the software level, neural network hardware accelerators directly execute the algorithms to achieve higher energy efficiency and performance improvements. However, as the deep learning algorithms evolve frequently, the engineering effort and cost of designing the hardware accelerators are greatly increased. To improve the design quality while saving the cost, design automation for neural network accelerators was proposed, where design space exploration algorithms are used to automatically search the optimized accelerator design within a design space. Nevertheless, the increasing complexity of the neural network accelerators brings the increasing dimensions to the design space. As a result, the previous design space exploration algorithms are no longer effective enough to find an optimized design. In this work, we propose a neural network accelerator design automation framework named GANDSE, where we rethink the problem of design space exploration, and propose a novel approach based on the generative adversarial network (GAN) to support an optimized exploration for high-dimension large design space. The experiments show that GANDSE is able to find the more optimized designs in negligible time compared with approaches including multilayer perceptron and deep reinforcement learning.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4308731133",
    "type": "article"
  },
  {
    "title": "Inferencing on Edge Devices: A Time- and Space-aware Co-scheduling Approach",
    "doi": "https://doi.org/10.1145/3576197",
    "publication_date": "2022-12-15",
    "publication_year": 2022,
    "authors": "Danny Pereira; Anirban Ghose; Sumana Ghosh; Soumyajit Dey",
    "corresponding_authors": "",
    "abstract": "Neural Network (NN)-based real-time inferencing tasks are often co-scheduled on GPGPU-style edge platforms. Existing works advocate using different NN parameters for the same detection task in different environments. However, realizing such approaches remains challenging, given accelerator devices’ limited on-chip memory capacity. As a solution, we propose a multi-pass, time- and space-aware scheduling infrastructure for embedded platforms with GPU accelerators. The framework manages the residency of NN parameters in the limited on-chip memory while simultaneously dispatching relevant compute operations. The mapping decisions for memory operations and compute operations to the underlying resources of the platform are first determined in an offline manner. For this, we proposed a constraint solver-assisted scheduler that optimizes for schedule makespan. This is followed by memory optimization passes, which take the memory budget into account and accordingly adjust the start times of memory and compute operations. Our approach reports a 74%–90% savings in peak memory utilization with 0%–33% deadline misses for schedules that suffer miss percentage in ranges of 25%–100% when run using existing methods.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4311609529",
    "type": "article"
  },
  {
    "title": "Two-level logic minimization for low power",
    "doi": "https://doi.org/10.1145/298865.298869",
    "publication_date": "1999-01-01",
    "publication_year": 1999,
    "authors": "Jyh-Mou Tseng; Jing-Yang Jou",
    "corresponding_authors": "",
    "abstract": "In this paper we present a complete Boolean method for reducing the power consumption in two-level combinational circuits. The two-level logic optimizer performs the logic minimization for low power targeting static PLA, general logic gates, and dynamic PLA implementations. We modify the espresso algorithm by adding our heuristics, which bias logic minimization toward lowering power dissipation. In our heuristics, signal probabilities and transition densities are two important parameters. The experimental results are promising.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W1974854535",
    "type": "article"
  },
  {
    "title": "Functional test generation for delay faults in combinational circuits",
    "doi": "https://doi.org/10.1145/290833.290845",
    "publication_date": "1998-04-01",
    "publication_year": 1998,
    "authors": "Irith Pomeranz; S.M. Reddy",
    "corresponding_authors": "",
    "abstract": "We propose a functional fault model for delay faults in combinational circuits and describe a functional test generation procedure based on this model. The proposed method is most suitable when a gate-level description of the circuit-under-test, necessary for employing existing gate-level delay fault test generators, is not available or does not accurately describe the circuit. It is also suitable for generating tests in early design stages of a circuit, before a gate-level implementation is selected. In addition, it can potentially be employed to supplement conventional test generators for gate-level circuits to reduce the cost of handling large numbers of paths. A parameter called Δ is used to control the number of funtional faults targeted and thus the number of tests generated. If Δ is unlimited, the functional test set detects every robustly testable path delay fault in any gate-level implementation of the given ciruit. An appropriate subset of tests can be selected once the implentation is known. The test sets generated for various values of Δ are fault simulated on gate-level realizations to demonstrate their effectiveness. The experiments indicate that functional test sets may be able to identify functions whose realizations have low path delay fault coverage.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W1975311952",
    "type": "article"
  },
  {
    "title": "Register estimation in unscheduled dataflow graphs",
    "doi": "https://doi.org/10.1145/234860.234866",
    "publication_date": "1996-07-01",
    "publication_year": 1996,
    "authors": "Rafael Moreno‐Vozmediano; R. Hermida; M. Fernández",
    "corresponding_authors": "",
    "abstract": "A method for register number estimation in unscheduled or partially scheduled dataflow graphs is presented. The strategy consists of studying the probability that an edge between two nodes crosses the boundary between two control steps, and its is based on a model that associates probabilities with the different scheduling alternatives of each node. These probabilities are computed by means of an analytic method that takes into account the distribution of operations in the dataflow graph and the hardware modules available in the library. The results highlight that the estimation method is very accurate becaused the error between the estimated value and the real value is always within a narrow margin.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W1988653522",
    "type": "article"
  },
  {
    "title": "Address code generation for DSP instruction-set architectures",
    "doi": "https://doi.org/10.1145/785411.785417",
    "publication_date": "2003-07-01",
    "publication_year": 2003,
    "authors": "J.-Y. Lee; In‐Cheol Park",
    "corresponding_authors": "",
    "abstract": "This paper presents a new DSP-oriented code optimization method to enhance performance by exploiting the specific architectural features of digital signal processors. In the proposed method, a source code is translated into the static single assignment form while preserving the high-level information related to the address computation of array accesses. The information is used in generating auto-modification addressing operations provided by most digital signal processors. In addition to the conventional control-data flow graph, a new graph is employed to find auto-modification addressing modes efficiently. Experimental results on benchmark programs show that the proposed method is effective in improving performance and reducing code size.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W1969182567",
    "type": "article"
  },
  {
    "title": "Analysis of FPGA/FPIC switch modules",
    "doi": "https://doi.org/10.1145/606603.606605",
    "publication_date": "2003-01-01",
    "publication_year": 2003,
    "authors": "Yao‐Wen Chang; Kai Zhu; Guangming Wu; Martin D. F. Wong; Chris K.C. Wong",
    "corresponding_authors": "",
    "abstract": "Switch modules are the most important component of the routing resources in FPGAs/FPICs. Previous works have shown that switch modules with higher routability result in better area performance for practical applications. We consider in this paper an FPGA/FPIC switch-module analysis problem: the inputs consist of a switch-module description and the number of nets required to be routed through the switch module; the question is to determine if there exists a feasible routing for the routing requirements on the switch module. As a fundamental problem for the analysis of switch modules, this problem is applicable to the design and routability evaluation of FPGA/FPIC switch modules and FPGA/FPIC routing. We present a network-flow-based approximation algorithm for this problem. Based on mathematical analyses, we show that this algorithm has provably good performance with the bounds 5 and 5/4 away from the optima for two types of switch modules, respectively. Extensive experiments show that this algorithm is highly accurate and runs very efficiently.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W1972762977",
    "type": "article"
  },
  {
    "title": "Decomposition of instruction decoders for low-power designs",
    "doi": "https://doi.org/10.1145/1179461.1179465",
    "publication_date": "2006-10-01",
    "publication_year": 2006,
    "authors": "Wu-An Kuo; TingTing Hwang; Allen C.-H. Wu",
    "corresponding_authors": "",
    "abstract": "During the execution of processor instruction, decoding the instructions is a major task in identifying instructions and generating control signals for data paths. In this article, we propose two instruction decoder decomposition techniques for low-power designs. First, by tracing program execution sequences, we propose an algorithm that explores the relations between frequently executed instructions. Second, we propose a two-stage low-power decomposition structure for decoding instructions. Experimental results demonstrate that our proposed techniques achieve an average of 34.18% in power reduction and 12.93% in critical-path delay reduction for the instruction decoder.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W1979745722",
    "type": "article"
  },
  {
    "title": "A game-theoretic framework for multimetric optimization of interconnect delay, power, and crosstalk noise during wire sizing",
    "doi": "https://doi.org/10.1145/1142980.1142988",
    "publication_date": "2004-06-07",
    "publication_year": 2004,
    "authors": "Narender Hanchate; N. Ranganathan",
    "corresponding_authors": "",
    "abstract": "The continuous scaling of interconnect wires in deep submicron (DSM) circuits results in increased interconnect delay, power, and crosstalk noise. In this work, we develop a game-theoretic framework and multimetric optimization algorithms for the simultaneous optimization during wire sizing of (i) interconnect delay and crosstalk noise, and (ii) interconnect delay, power, and crosstalk noise. We formulate the wire sizing optimization problem as a normal form-game model and solve it using Nash equilibrium theory. Game theory allows the optimization of multiple metrics with conflicting objectives. This property is exploited in modeling the wire sizing problem while simultaneously optimizing various design parameters like interconnect delay, power, and crosstalk noise, which are conflicting in nature. The nets connecting the driving cell and the driven cell are divided into net segments. The net segments within a channel are modeled as players and the range of possible wire sizes forms the set of strategies. The payoff function is modeled (i) as the geometric mean of interconnect delay and crosstalk noise in the case of first formulation, and (ii) as the weighted sum of interconnect delay, power, and crosstalk noise in the second formulation. The net segments are optimized from the ones closest to the driven cell towards the ones at the driving cell. Complete information about the coupling effects among the nets is extracted after the detailed routing phase. The time and space complexities of the proposed wire sizing formulations are linear in terms of the number of net segments. Experimental results on several medium and large open-core designs indicate that the proposed algorithm for simultaneous optimization of interconnect delay and crosstalk noise yields an average reduction of 21.48% in interconnect delay and a 26.25% reduction in crosstalk noise without any area overhead, over and above the optimization from the Cadence place and route tools. It is shown through experimental results that the algorithm performs significantly better than simulated annealing and genetic search. Further, new simple but accurate models are developed for three parallel interconnect net segments. It is shown that these models yield the same level of accuracy with significantly better run times compared to the models reported in Chen et al. [2004]. A mathematical proof of existence for the Nash equilibrium solution for the proposed wire sizing formulation is also provided.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W1991319506",
    "type": "article"
  },
  {
    "title": "Synthesis of time-constrained multitasking embedded software",
    "doi": "https://doi.org/10.1145/1179461.1179463",
    "publication_date": "2006-10-01",
    "publication_year": 2006,
    "authors": "André C. Nácul; Tony Givargis",
    "corresponding_authors": "",
    "abstract": "In modern embedded systems, software development plays a vital role. Many key functions are being migrated to software, aiming at a shorter time to market and easier upgrades. Multitasking is increasingly common in embedded software, and many of these tasks incorporate real-time constraints. Although multitasking simplifies coding, it demands an operating system and imposes significant overhead on the system. The use of serializing compilers, such as the Phantom compiler, allows the synthesis of a monolithic code from a multitasking C application, eliminating the need for an operating system. In this article, we introduce the synthesis of multitasking applications that execute in a timely manner. We incorporate the notion of timing constraints into the Phantom compiler, and show that our approach is effective in meeting such constraints, allowing fine-grained concurrency among the tasks. As an additional case study, we present the implementation of a software-based modem and show that real-time applications such as the modem have guaranteed performance in the serialized code generated by the Phantom compiler.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W1993389307",
    "type": "article"
  },
  {
    "title": "The open family of temporal logics",
    "doi": "https://doi.org/10.1145/1080334.1080337",
    "publication_date": "2005-07-01",
    "publication_year": 2005,
    "authors": "Ansuman Banerjee; Pallab Dasgupta",
    "corresponding_authors": "",
    "abstract": "Assume-guarantee style verification of modules relies on the appropriate modeling of the interaction of the module with its environment. Popular temporal logics such as Computation Tree Logic (CTL) and Linear Temporal Logic (LTL) that were originally defined for closed systems (Kripke structures) do not make any syntactic discrimination between input and output variables. As a result, these logics and their recent derivatives (such as System Verilog, Sugar, Forspec, etc) permit the specification of properties that have some semantic problems when interpreted over open systems or modules. These semantic problems are quite common in practice, but are computationally hard to detect within a given specification. In this article, we propose a new style for writing temporal specifications of open systems that helps the designer to avoid most of these problems. In the proposed style, the basic temporal operators (such as next and until ) are annotated with assume constraints over the input variables. We formalize this style through an extension of LTL, namely Open-LTL and an extension of CTL with fairness, called Open-CTL. We show that this simple syntactic separation between the assume and the guarantee achieves the desired results. We show that the proposed style can be integrated with traditional symbolic model-checking techniques and present a complete tool for the verification of Verilog RTL modules in isolation.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2007635637",
    "type": "article"
  },
  {
    "title": "Reliable crosstalk-driven interconnect optimization",
    "doi": "https://doi.org/10.1145/1124713.1124720",
    "publication_date": "2006-01-01",
    "publication_year": 2006,
    "authors": "Iris Hui-Ru Jiang; Song-Ra Pan; Yao‐Wen Chang; Jing-Yang Jou",
    "corresponding_authors": "",
    "abstract": "As technology advances apace, crosstalk becomes a design metric of comparable importance to area and delay. This article focuses mainly on the crosstalk issue, specifically on the impacts of physical design and process variation on crosstalk. While the feature size shrinks below 0.25μ m , the impact of process variation on crosstalk increases rapidly. Hence, a crosstalk insensitive design is desirable in the deep submicron regime. In this article, crosstalk sensitivity is referred to as the influence of process variation on crosstalk in a circuit. We show that the lower bound of crosstalk sensitivity grows quadratically, while that of crosstalk increases linearly. Therefore, designers should also consider crosstalk sensitivity, when optimizing other design objectives such as crosstalk, area, and delay. According to our modeling, these objectives are all in posynomial forms, and thus the multi-objective optimization problem can optimally be solved by Lagrangian relaxation. Experimental results show that our method is effective and efficient. For instance, a circuit of 2856 gates and 5272 wires is optimized using 13-minute runtime and 2.8-MB memory on a Pentium III 1.0 GHz PC with 256-MB memory. In particular, by relaxing Lagrange multipliers to the critical paths, it takes only two iterations for all solutions to converge to the global optimal, which is much more efficient than related previous work. This relaxation scheme provides a key insight into the rapid convergence in Lagrangian relaxation.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2068010482",
    "type": "article"
  },
  {
    "title": "Circuit-simulated obstacle-aware Steiner routing",
    "doi": "https://doi.org/10.1145/1255456.1255465",
    "publication_date": "2007-08-17",
    "publication_year": 2007,
    "authors": "Yiyu Shi; Paul Mesa; Hao Yu; Lei He",
    "corresponding_authors": "",
    "abstract": "This article develops circuit-simulated routing algorithms. We model the routing graph by an RC network with terminals as inputs, and show that the faster an output reaches its peak, the higher the possibility for the corresponding Hanan or escape node to become a Steiner point. This enables us to select Steiner points and then apply any minimum spanning tree algorithm to obtain obstacle-free or obstacle-aware Steiner routing. Compared with existing algorithms, our algorithms have significant gain on either wirelength or runtime for obstacle-free routing, and on both wirelength and runtime for obstacle-aware routing.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W1994369701",
    "type": "article"
  },
  {
    "title": "Introduction to special issue on demonstrable software systems and hardware platforms",
    "doi": "https://doi.org/10.1145/1255456.1255457",
    "publication_date": "2007-08-17",
    "publication_year": 2007,
    "authors": "Sung Kyu Lim; Massoud Pedram",
    "corresponding_authors": "",
    "abstract": "introduction Introduction to special issue on demonstrable software systems and hardware platforms Authors: Sung Kyu Lim Atlanta, Georgia Atlanta, GeorgiaView Profile , Massoud Pedram Los Angeles, California Los Angeles, CaliforniaView Profile Authors Info & Claims ACM Transactions on Design Automation of Electronic SystemsVolume 12Issue 3August 2007 Article No.: 20pp 1–3https://doi.org/10.1145/1255456.1255457Published:22 May 2008Publication History 1citation283DownloadsMetricsTotal Citations1Total Downloads283Last 12 Months1Last 6 weeks1 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteGet Access",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2010770640",
    "type": "article"
  },
  {
    "title": "SAT-based ATPG using multilevel compatible don't-cares",
    "doi": "https://doi.org/10.1145/1344418.1344420",
    "publication_date": "2008-04-02",
    "publication_year": 2008,
    "authors": "Nikhil Saluja; Kanupriya Gulati; Sunil P. Khatri",
    "corresponding_authors": "",
    "abstract": "In a typical IC design flow, circuits are optimized using multilevel don't cares. The computed don't cares are discarded before Technology Mapping or Automatic Test Pattern Generation (ATPG). In this paper, we present two combinational ATPG algorithms for combinational designs. These algorithms utilize the multilevel don't cares that are computed for the design during technology independent logic optimization. They are based on Boolean Satisfiability (SAT), and utilize the single stuck-at fault model. Both algorithms make use of the Compatible Observability Don't Cares (CODCs) associated with nodes of the circuit, to speed up the ATPG process. For large circuits, both algorithms make use of approximate CODCs (ACODCs), which we can compute efficiently. Our first technique speeds up fault propagation by modifying the active clauses in the transitive fanout (TFO) of the fault site. In our second technique, we define new j - active variables for specific nodes in the transitive fanin (TFI) of the fault site. Using these j-active variables we write additional clauses to speed up fault justification. Experimental results demonstrate that the combination of these techniques (when using CODCs) results in an average reduction of 45% in ATPG runtimes. When ACODCs are used, a speed-up of about 30% is obtained in the ATPG run-times for large designs. We compare our method against a commercial structural ATPG tool as well. Our method is slower for small designs, but for large designs, we obtain a 31% average speedup over the commercial tool.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2019365076",
    "type": "article"
  },
  {
    "title": "Reuse and optimization of testbenches and properties in a TLM-to-RTL design flow",
    "doi": "https://doi.org/10.1145/1367045.1367056",
    "publication_date": "2008-07-01",
    "publication_year": 2008,
    "authors": "Nicola Bombieri; Franco Fummi; Graziano Pravadelli",
    "corresponding_authors": "",
    "abstract": "In transaction-level modeling (TLM), verification methodologies based on transactions allow testbenches, properties, and IP cores in mixed TL-RTL designs to be reused. However, no papers in the literature analyze the effectiveness of transaction-based verification (TBV) in comparison to the more traditional RTL approach. The first contribution of this article is the introduction of a functional-fault-model-based methodology for demonstrating the effectiveness of reuse through TBV. A second contribution is the introduction of a similar methodology for efficient property checking which identifies and removes redundant properties prior to assertion-based verification or model checking.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2089301990",
    "type": "article"
  },
  {
    "title": "Idle energy minimization by mode sequence optimization",
    "doi": "https://doi.org/10.1145/1278349.1278351",
    "publication_date": "2007-09-01",
    "publication_year": 2007,
    "authors": "Jinfeng Liu; Pai H. Chou",
    "corresponding_authors": "",
    "abstract": "This article presents techniques for reducing idle energy by mode-sequence optimization (MSO) under timing constraints. Our component-level CoMSO algorithm computes energy-optimal mode-transition sequences for different lengths of idle intervals. Our system-level SyMSO algorithm shifts tasks within slack intervals while satisfying all timing and resource constraints in the given schedule. Experimental results on a commercial software-defined radio show that these new techniques can reduce idle energy by 50--70%, or 30--50% of total system energy over previous offline-optimal but unsequenced techniques based on localized break-even-time analysis, thanks to rich options offered by mode sequencing.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2163690241",
    "type": "article"
  },
  {
    "title": "Repair of FPGA-Based Real-Time Systems With Variable Slacks",
    "doi": "https://doi.org/10.1145/3144533",
    "publication_date": "2018-01-15",
    "publication_year": 2018,
    "authors": "Leonardo Pereira-Santos; Gabriel L. Nazar; Luigi Carro",
    "corresponding_authors": "",
    "abstract": "Field-programmable gate arrays (FPGAs) based on SRAM cells are an attractive alternative for real-time system designers, as they offer high density, low cost, and high performance. The use of SRAM cells in the FPGA’s configuration memory, while enabling these desirable characteristics, also creates a reliability hazard as RAM cells are susceptible to single-event upsets (SEUs). The usual approach is the use of double or triple redundancy allied with a correction mechanism, such as periodic scrubbing. Although scrubbing is an effective technique to remove SEU-induced errors, the repair of real-time systems presents specific challenges, such as avoiding failures by missing real-time deadlines. In this article, a novel approach is proposed to use a deadline-aware scrubbing scheme with negligible area costs that dynamically chooses the scrubbing starting position. Such a scheme allows us to avoid missing real-time deadlines while maximizing the repair probability given a bounded repair time. Our approach reduces the failure rate, considering the probability of missing deadlines due to faults, by 33.39% on average, with an average area cost of 1.23%.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2783397962",
    "type": "article"
  },
  {
    "title": "Multicast Testing of Interposer-Based 2.5D ICs",
    "doi": "https://doi.org/10.1145/3177879",
    "publication_date": "2018-02-23",
    "publication_year": 2018,
    "authors": "Shengcheng Wang; Ran Wang; Krishnendu Chakrabarty; Mehdi B. Tahoori",
    "corresponding_authors": "",
    "abstract": "Interposer-based 2.5D integrated circuits (ICs) are seen today as a precursor to 3D ICs based on through-silicon vias (TSVs). All the dies in a 2.5D IC must be adequately tested for product qualification. However, due to the limited number of package pins, it is a major challenge to test 2.5D ICs using conventional methods. Moreover, due to higher integration levels, test-application time and test power consumption for 2.5D ICs are also increased compared to their 2D counterparts. Therefore, it is imperative to take these issues into account during 2.5D IC testing. In this article, we present an efficient multicast test architecture for targeting defects in dies, in which multiple dies can be tested simultaneously to reduce the test-application time under constraints on test power and fault coverage. We also propose a test scheduling and optimization technique that can be utilized with the multicast test architecture. By considering the trade-off between test-application time, test-power budget, and test quality, the proposed technique provides test schedules with minimum test-application time under constraints on power consumption and fault coverage. Compared to previous work, the proposed technique can reduce test-application time by up to 53.4 for benchmark designs while achieving higher fault coverage. Since the loss in fault coverage due to multicast testing is extremely small, we can use top-off patterns to achieve full fault coverage for the dies at negligible additional cost.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2793115540",
    "type": "article"
  },
  {
    "title": "An Integration Flow for Mixed-Critical Embedded Systems on a Flexible Time-Triggered Platform",
    "doi": "https://doi.org/10.1145/3190837",
    "publication_date": "2018-05-09",
    "publication_year": 2018,
    "authors": "Philipp Ittershagen; Kim Grüttner; Wolfgang Nebel",
    "corresponding_authors": "",
    "abstract": "The rise of mixed-critical embedded systems imposes novel challenges on the specification, development, and functional validation in a design flow. In the emerging dynamic scheduling context of mixed-criticality platforms, the system behaviour needs to be estimated in an early step in the design flow to assess the integration impact, especially for quality of service-driven, low-critical subsystems. We provide a modelling and integration flow for specifying, estimating, and evaluating software functions, ranging from an initial executable specification to an implementation candidate on an MPSoC. Based on a data-driven model to evaluate dynamic resource consumption effects of high-critical subsystems and the scheduling overhead, we propose a systematic method for constructing workload models of high-critical software components on the target. Our proxies provide an integration environment for low-critical functions by mimicking the high-critical temporal behaviour on the target. By integrating a low-critical video encoding subsystem with a benchmark suite as the high-critical subsystem we show that the performance model allows for evaluating end-to-end execution times in the low-critical function with an average error of 0.37% and the application proxy only introduces a maximum error of 1.14% in a performance evaluation.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2802658972",
    "type": "article"
  },
  {
    "title": "Variation-Aware Global Placement for Improving Timing-Yield of Carbon-Nanotube Field Effect Transistor Circuit",
    "doi": "https://doi.org/10.1145/3175500",
    "publication_date": "2018-06-11",
    "publication_year": 2018,
    "authors": "Chen Wang; Yanan Sun; Shiyan Hu; Li Jiang; Weikang Qian",
    "corresponding_authors": "",
    "abstract": "As the conventional silicon-based CMOS technology marches toward the sub-10nm region, the problem of high power density becomes increasingly serious. Under this circumstance, the carbon-nanotube field effect transistors (CNFETs) emerge as a promising alternative to the conventional silicon-based CMOS devices. However, they experience a much larger variation than the silicon-based CMOS devices, which results in a large circuit delay variation and hence, a significant timing yield loss. One of the main variation sources is the carbon-nanotube (CNT) density variation. However, it shows a special property not existing for silicon-based CMOS devices, namely the asymmetric spatial correlation. In this work, we propose novel global placement algorithms to reduce the timing yield loss caused by the CNT density variation. To effectively reduce the statistical circuit delay, we first develop a statistical delay measure for a segment of gates. Based on this measure, we further develop a segment-based strategy and a path-based placement strategy to reduce the delays of the statistically critical paths. Experimental results demonstrated that both of our approaches effectively improve the timing yield.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2808637031",
    "type": "article"
  },
  {
    "title": "Improving Test and Diagnosis Efficiency through Ensemble Reduction and Learning",
    "doi": "https://doi.org/10.1145/3328754",
    "publication_date": "2019-06-05",
    "publication_year": 2019,
    "authors": "Hongfei Wang; Kun He",
    "corresponding_authors": "",
    "abstract": "Machine learning is a powerful lever for developing, improving, and optimizing test methodologies to cope with the demand from the advanced nodes. Ensemble methods are a particular learning paradigm that uses multiple models to boost performance. In this work, ensemble reduction and learning is explored for integrated circuit test and diagnosis. For testing, the proposed method is able to reduce the number of system-level tests without incurring substantial increase in defect escapes or yield losses. Significant cost from test execution and set-up preparation can thereby be saved. Experiments are performed on two designs of commercially fabricated chips, for an overall population of &gt;264,000 chips. The results demonstrate that our method is able to reduce 29.27% and 21.74% of the number of tests for the two chips, respectively, at the cost of very low defect escapes. For failure diagnosis, the framework is able to predict an adequate amount of test data necessary for accurate failure diagnosis. Experiments performed on five standard benchmarks demonstrate that our method outperforms a state-of-the-art work in terms of data-volume reduction. The proposed ensemble-based methodology creates opportunities for improving test and diagnosis efficiency.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2952788544",
    "type": "article"
  },
  {
    "title": "Reducing DRAM Refresh Rate Using Retention Time Aware Universal Hashing Redundancy Repair",
    "doi": "https://doi.org/10.1145/3339851",
    "publication_date": "2019-07-10",
    "publication_year": 2019,
    "authors": "Kyu Hyun Choi; Jaeyung Jun; Minseong Kim; Seon Wook Kim",
    "corresponding_authors": "",
    "abstract": "As the device capacity of Dynamic Random Access Memory (DRAM) increases, refresh operation becomes a significant contributory factor toward total power consumption and memory throughput of the device. To reduce the problems associated with the refresh operation, a multi-rate refresh technique that changes the refresh period based on the retention time of DRAM cells has been proposed. Unfortunately, the multi-rate refresh technique has a scalability issue, because the additional storage and logic overhead on a memory controller increases as the device capacity increases. In this article, we propose a novel redundancy repair technique to increase the refresh period of DRAM by using a universal hashing technique. Our redundancy repair technique efficiently repairs both hard faults, which occur during the manufacturing process, and weak cells that have short retention time using the remaining spare elements after the process. Also, our technique solves the Variable Retention Time problem by repairing weak cells at boot time by exploiting the Built-in self-repair (BISR) technique and Error Correction Code. Our technique outperforms a conventional BISR redundancy repair with very little hardware overhead, and ensure reliability with more extended refresh period in the entire system. In particular, our experimental results show that our BISR technique achieves 100% repair rate at a 384ms refresh period in 1.0e-6 hard fault BER configuration, and reduces the refresh energy consumption by 83.9% compared to the 64ms refresh and 12% compared to the conventional multi-rate refresh technique for the state-of-the-art 4Gb device.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2957415245",
    "type": "article"
  },
  {
    "title": "Optimization of Threshold Logic Networks with Node Merging and Wire Replacement",
    "doi": "https://doi.org/10.1145/3358748",
    "publication_date": "2019-10-14",
    "publication_year": 2019,
    "authors": "Yung‐Chih Chen; Li-Cheng Zheng; Fu-Lian Wong",
    "corresponding_authors": "",
    "abstract": "In this article, we present an optimization method for threshold logic networks (TLNs) based on observability don’t-care-based node merging. To reduce gate count in a TLN, it iteratively merges two gates that are functionally equivalent or whose differences are never observed at the primary outputs. Furthermore, it is able to identify redundant wires and replace wires for removing more gates. Basically, the proposed method is primarily adapted from an ATPG-based node-merging approach which works for conventional Boolean logic networks. To extend the approach for TLNs, we develop a method for computing mandatory assignments of a stuck-at fault test on a threshold gate and a method for conducting logic implication in a TLN. Additionally, to achieve a better optimization quality, we integrate the proposed method with other optimization methods. The experimental results show that the overall optimization method can save an average of approximately 4.7% threshold gates for a set of TLNs which are generated by using the latest TLN synthesis method. The experimental results also demonstrate the efficiency of the optimization method.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2980750261",
    "type": "article"
  },
  {
    "title": "Improving FPGA-Based Logic Emulation Systems through Machine Learning",
    "doi": "https://doi.org/10.1145/3399595",
    "publication_date": "2020-07-05",
    "publication_year": 2020,
    "authors": "Anthony Agnesina; Sung Kyu Lim; Étienne Lepercq; Jose Escobedo Del Cid",
    "corresponding_authors": "",
    "abstract": "We present a machine learning (ML) framework to improve the use of computing resources in the FPGA compilation step of a commercial FPGA-based logic emulation flow. Our ML models enable highly accurate predictability of the final place and route design qualities, runtime, and optimal mapping parameters. We identify key compilation features that may require aggressive compilation efforts using our ML models. Experiments based on our large-scale database from an industry’s emulation system show that our ML models help reduce the total number of jobs required for a given netlist by 33%. Moreover, our job scheduling algorithm based on our ML model reduces the overall time to completion of concurrent compilation runs by 24%. In addition, we propose a new method to compute “recommendations” from our ML model to perform re-partitioning of difficult partitions. Tested on a large-scale industry system on chip design, our recommendation flow provides additional 15% compile time savings for the entire system on chip. To exploit our ML model inside the time-critical multi-FPGA partitioning step, we implement it in an optimized multi-threaded representation.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W3040269983",
    "type": "article"
  },
  {
    "title": "Energy-Efficient GPU L2 Cache Design Using Instruction-Level Data Locality Similarity",
    "doi": "https://doi.org/10.1145/3408060",
    "publication_date": "2020-08-18",
    "publication_year": 2020,
    "authors": "Jingweijia Tan; Kaige Yan; Shuaiwen Leon Song; Xin Fu",
    "corresponding_authors": "",
    "abstract": "This article presents a novel energy-efficient cache design for massively parallel, throughput-oriented architectures like GPUs. Unlike L1 data cache on modern GPUs, L2 cache shared by all of the streaming multiprocessors is not the primary performance bottleneck, but it does consume a large amount of chip energy. We observe that L2 cache is significantly underutilized by spending 95.6% of the time storing useless data. If such “dead time” on L2 is identified and reduced, L2’s energy efficiency can be drastically improved. Fortunately, we discover that the SIMT programming model of GPUs provides a unique feature among threads: instruction-level data locality similarity, which can be used to accurately predict the data re-reference counts at L2 cache block level. We propose a simple design that leverages this Lo cality S imilarity to build an energy-efficient GPU L2 Cache , named LoSCache . Specifically, LoSCache uses the data locality information from a small group of cooperative thread arrays to dynamically predict the L2-level data re-reference counts of the remaining cooperative thread arrays. After that, specific L2 cache lines can be powered off if they are predicted to be “dead” after certain accesses. Experimental results on a wide range of applications demonstrate that our proposed design can significantly reduce the L2 cache energy by an average of 64% with only 0.5% performance loss. In addition, LoSCache is cost effective, independent of the scheduling policies, and compatible with the state-of-the-art L1 cache designs for additional energy savings.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W3054696703",
    "type": "article"
  },
  {
    "title": "Thermal Management for FPGA Nodes in HPC Systems",
    "doi": "https://doi.org/10.1145/3423494",
    "publication_date": "2020-10-23",
    "publication_year": 2020,
    "authors": "Yingyi Luo; Joshua C. Zhao; Arnav Aggarwal; Seda Ogrenci-Memik; Kazutomo Yoshii",
    "corresponding_authors": "",
    "abstract": "The integration of FPGAs into large-scale computing systems is gaining attention. In these systems, real-time data handling for networking, tasks for scientific computing, and machine learning can be executed with customized datapaths on reconfigurable fabric within heterogeneous compute nodes. At the same time, thermal management, particularly battling the cooling cost and guaranteeing the reliability, is a continuing concern. The introduction of new heterogeneous components into HPC nodes only adds further complexities to thermal modeling and management. The thermal behavior of multi-FPGA systems deployed within large compute clusters is less explored. In this article, we first show that the thermal behaviors of different FPGAs of the same generation can vary due to their physical locations in a rack and process variation, even though they are running the same tasks. We present a machine learning–based model to capture the thermal behavior of each individual FPGA in the cluster. We then propose two thermal management strategies guided by our thermal model. First, we mitigate thermal variation and hotspots across the cluster by proactive thermal-aware task placement. Under the tested system and benchmarks, we achieve up to 26.4° C and on average 13.3° C system temperature reduction with no performance penalty. Second, we utilize this thermal model to guide HLS parameter tuning at the task design stage to achieve improved thermal response after deployment.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W3094033150",
    "type": "article"
  },
  {
    "title": "Logic Diagnosis with Hybrid Fail Data",
    "doi": "https://doi.org/10.1145/3433929",
    "publication_date": "2020-12-17",
    "publication_year": 2020,
    "authors": "Irith Pomeranz; M. Enamul Amyeen",
    "corresponding_authors": "",
    "abstract": "Yield improvement requires information about the defects present in faulty units. This information is derived by applying a logic diagnosis procedure to the fail data collected by a tester from faulty units. It is typical in the early stages of yield learning to find faulty units that produce excessive volumes of fail data. The current practice is to terminate the fail data collection and possibly discard the fail data already collected for the unit. An earlier study shows that a faulty unit may produce excessive volumes of fail data for some tests but not for others. Based on this observation, a possible solution is to collect full fail data only for tests where this is feasible and pass/fail information for other tests. For this approach to be practical, it is necessary to be able to perform logic diagnosis with hybrid fail data that consists of full fail data for some tests and only pass/fail information for other tests. The main challenge in designing such a procedure is to balance the use of the two types of data to produce accurate logic diagnosis results. This article describes a logic diagnosis procedure, from the class of procedures used by commercial tools, that addresses this challenge. Experimental results for benchmark circuits demonstrate the importance of pass/fail information in this scenario.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W3112423244",
    "type": "article"
  },
  {
    "title": "COPE",
    "doi": "https://doi.org/10.1145/3428149",
    "publication_date": "2020-12-31",
    "publication_year": 2020,
    "authors": "Dipika Deb; John Jose; Maurizio Palesi",
    "corresponding_authors": "",
    "abstract": "Prefetching helps in reducing the memory access latency in multi-banked NUCA architecture, where the Last Level Cache (LLC) is shared. In such systems, an application running on core generates significant traffic on the shared resources, the underlying network and LLC. While prefetching helps to increase application performance, but an inaccurate prefetcher can cause harm by generating unwanted traffic that additionally increases network and LLC contention. Increased network contention results in untimely prefetching of cache blocks, thereby reducing the effectiveness of a prefetcher. Prefetch accuracy is extensively used to reduce unwanted prefetches that can mitigate the prefetcher caused contention. However, the conventional prefetch accuracy parameter has major limitations in NUCA architectures. The article exposes that prefetch accuracy can create two major false-positive cases of prefetching, Under-estimation and Over-estimation problems, and false feedback loop that can mislead a prefetcher in generating more unwanted traffic. We propose a novel technique, Coordinated Prefetching for Efficient (COPE), which addresses these issues by redefining prefetch accuracy for such architectures and identifies additional parameters that can avoid generating unwanted prefetch requests. Experiment conducted using PARSEC benchmark on a 64-core system shows that COPE achieve 3% reduction in L1 cache miss rate, 12.64% improvement in IPC, 23.2% reduction in average packet latency and 18.56% reduction in dynamic power consumption of the underlying network.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W3114469832",
    "type": "article"
  },
  {
    "title": "Approximate Learning and Fault-Tolerant Mapping for Energy-Efficient Neuromorphic Systems",
    "doi": "https://doi.org/10.1145/3436491",
    "publication_date": "2020-12-31",
    "publication_year": 2020,
    "authors": "Anteneh Gebregirogis; Mehdi B. Tahoori",
    "corresponding_authors": "",
    "abstract": "Brain-inspired deep neural networks such as Convolutional Neural Network (CNN) have shown great potential in solving difficult cognitive problems such as object recognition and classification. However, such architectures have high computational energy demand and sensitivity to variation effects, making them inapplicable for energy-constrained embedded learning platforms. To address this issue, we propose a learning and mapping approach that utilizes approximate computing during early design phases for a layer-wise pruning and fault tolerant weight mapping scheme of reliable and energy-efficient CNNs. In the proposed approach, approximate CNN is prepared first by layer-wise pruning of approximable neurons, which have high error tolerance margins using a two-level approximate learning methodology. Then, the pruned network is retrained to improve its accuracy by fine-tuning the weight values. Finally, a fault-tolerant layer-wise neural weight mapping scheme is adopted to aggressively reduce memory operating voltage when loading the weights of error resilient layers for energy-efficiency. Thus, the combination of approximate learning and fault tolerance aware memory operating voltage downscaling techniques enable us to implement robust and energy-efficient approximate inference engine for CNN applications. Simulation results show that the proposed fault tolerant and approximate learning approach can improve the energy-efficiency of CNN inference engines by more than 50% with less than 5% reduction in classification accuracy. Additionally, more than 26% energy-saving is achieved by using the proposed layer-wise mapping-based cache memory operating voltage down-scaling.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W3115673245",
    "type": "article"
  },
  {
    "title": "Multi-objective Optimization of Mapping Dataflow Applications to MPSoCs Using a Hybrid Evaluation Combining Analytic Models and Measurements",
    "doi": "https://doi.org/10.1145/3431814",
    "publication_date": "2020-12-31",
    "publication_year": 2020,
    "authors": "Martín Letras; Joachim Falk; Tobias Schwarzer; Jürgen Teich",
    "corresponding_authors": "",
    "abstract": "Dataflow modeling is well suited for a large variety of applications for modern multi-core architectures, e.g., from the signal processing and the control domain. Furthermore, Design Space Exploration (DSE) can be used to explore mappings of tasks to hardware resources (cores of an MPSoC) and their scheduling to obtain optimized trade-off solutions between throughput and resource costs. However, the throughput evaluation of an implementation candidate via compilation-in-the-loop or simulation-based approaches can be extremely time-consuming. Such a deficiency is very detrimental, because a typical DSE run needs to evaluate thousands of implementation candidates. As a remedy, we propose a hybrid-adaptive DSE where a max-plus algebra-based analytic throughput calculation method is used in the initial DSE phase to enable a fast progress of the search space exploration. However, as this analysis may be inaccurate as neglecting some real-world effects like cache and scheduling overhead, throughput measurements are taken later in the DSE. Moreover, we explore the trade-off between scheduling efficiency of implementation candidates—in favor of reducing concurrency—and exploiting concurrency to a large extent for parallel execution of the application. To find solutions of highest achievable throughput, it is shown that not only highly scheduling efficient implementation candidates but also highly parallel implementation candidates are essential when determining the initial population. In this realm, we contribute a method for diversity-based population initialization. For a representative set of benchmarks, it is shown that the combination of the two major contributions allows us to find much higher throughput multi-core solutions within a given exploration time compared to a state-of-the-art DSE approach.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W3115724506",
    "type": "article"
  },
  {
    "title": "Impact of intercluster communication mechanisms on ILP in clustered VLIW architectures",
    "doi": "https://doi.org/10.1145/1217088.1217089",
    "publication_date": "2007-01-01",
    "publication_year": 2007,
    "authors": "Anup Gangwar; S. Balakrishnan; Anshul Kumar",
    "corresponding_authors": "",
    "abstract": "VLIW processors have started gaining acceptance in the embedded systems domain. However, monolithic register file VLIW processors with a large number of functional units are not viable. This is because of the need for a large number of ports to support FU requirements, which makes them expensive and extremely slow. A simple solution is to break the register file into a number of smaller register files with a subset of FUs connected to it. These architectures are termed clustered VLIW processors.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4253933660",
    "type": "article"
  },
  {
    "title": "Resource-aware architectures for adaptive particle filter based visual target tracking",
    "doi": "https://doi.org/10.1145/2442087.2442093",
    "publication_date": "2013-03-01",
    "publication_year": 2013,
    "authors": "Domenic Forte; Ankur Srivastava",
    "corresponding_authors": "",
    "abstract": "There are a growing number of visual tracking applications now being envisioned for mobile devices. However, since computer vision algorithms such as particle filtering have large computational demands, they can result in high energy consumption and temperatures in mobile devices. Conventional approaches for distributed target tracking with a camera node and a receiver node are either sender-based (SB) or receiver-based (RB). The SB approach uses little energy and bandwidth, but requires a sender with large computational resources. The RB approach fits applications where computational resources are completely unavailable to the sender, but requires very large energy and bandwidth. In this article, we propose three architectures for distributed particle filtering that (i) reduce particle filtering workload and (ii) allow for dynamic migration of workload between nodes participating in tracking. We also discuss an adaptive particle filtering extension that adapts particle filter computational complexity and can be applied to both the conventional and proposed architectures for improved energy efficiency. Results show that the proposed solutions require low additional overhead, improve on tracking system lifetime, balance node temperatures, maintain track of the desired target, and are more effective than conventional approaches in many scenarios.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W1973287945",
    "type": "article"
  },
  {
    "title": "Critical-path-aware high-level synthesis with distributed controller for fast timing closure",
    "doi": "https://doi.org/10.1145/2566670",
    "publication_date": "2014-03-01",
    "publication_year": 2014,
    "authors": "Seokhyun Lee; Ki‐Young Choi",
    "corresponding_authors": "",
    "abstract": "Centralized controllers commonly used in high-level synthesis often require long wires and cause high load capacitance, and that is why critical paths typically occur on paths from controllers to data registers instead of paths from data registers to data registers. However, conventional high-level synthesis has focused on delays within a datapath, making it difficult to solve the timing closure problem during physical synthesis. This article presents hardware architecture with a distributed controller, which makes the timing closure problem much easier. A novel critical-path-aware high-level synthesis flow is also presented for synthesizing such hardware through datapath partitioning, register binding, and controller optimization. We explore the design space related to the number of partitions, which is an important design parameter for target architecture. According to our experiments, the proposed approach reduces the critical path delay excluding FUs by 29.3% and that including FUs by 10.0%, with 2.2% area overhead on average compared to centralized controller architecture.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W1990026810",
    "type": "article"
  },
  {
    "title": "Improving the performance of port range check for network packet filtering",
    "doi": "https://doi.org/10.1145/2523069",
    "publication_date": "2013-12-01",
    "publication_year": 2013,
    "authors": "Yen-Jen Chang; Hsiang-Yu Lu",
    "corresponding_authors": "",
    "abstract": "This article introduces a high-performance packet filter design in which we propose the partial parallel range check (PPRC) technique for speeding up port range check. Unlike the conventional serial design that uses cascading cells to perform the serial check, PPRC divides the single path into several segments. All PPRC segments perform the range compare simultaneously, that is, parallel check, and then the results of each segment are serialized to generate the final check result. Besides theoretical analyses, we also use UMC 90nm CMOS process to implement the PPRC design and verify its effect on the check performance. Compared to state-of-the-art range check techniques, the results show that the PPRC design with the best configuration can improve check performance by 28%, at least. In addition, the PPRC design is more stable and energy efficient than related designs, even though it requires more transistors to implement the peripheral circuitry. The range of energy improvement achieved by the PPRC design is about 35%--70%.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W1991250698",
    "type": "article"
  },
  {
    "title": "A Generalized Definition of Unnecessary Test Vectors in Functional Test Sequences",
    "doi": "https://doi.org/10.1145/2699853",
    "publication_date": "2015-03-02",
    "publication_year": 2015,
    "authors": "Irith Pomeranz",
    "corresponding_authors": "Irith Pomeranz",
    "abstract": "A class of static test compaction procedures for functional test sequences is based on the omission of unnecessary test vectors. According to the definition used by these procedures, a test vector is unnecessary if all the target faults continue to be detected after it is omitted. This article introduces a more general definition of unnecessary test vectors that allows additional ones to be omitted. According to this definition, a test vector is unnecessary if every target fault can be detected by a sequence that is obtained after omitting the vector, and possibly other vectors. The article develops a procedure for omitting test vectors based on this definition and discusses its effects on the storage requirements and test application time.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W1997017248",
    "type": "article"
  },
  {
    "title": "Multithreaded Simulation for Synchronous Dataflow Graphs",
    "doi": "https://doi.org/10.1145/1970353.1970358",
    "publication_date": "2011-06-01",
    "publication_year": 2011,
    "authors": "Chia‐Jui Hsu; José Luis Pino; Shuvra S. Bhattacharyya",
    "corresponding_authors": "",
    "abstract": "For system simulation, Synchronous DataFlow (SDF) has been widely used as a core model of computation in design tools for digital communication and signal processing systems. The traditional approach for simulating SDF graphs is to compute and execute static schedules in single-processor desktop environments. Nowadays, however, multicore processors are increasingly popular desktop platforms for their potential performance improvements through thread-level parallelism. Without novel scheduling and simulation techniques that explicitly explore thread-level parallelism for executing SDF graphs, current design tools gain only minimal performance improvements on multicore platforms. In this article, we present a new multithreaded simulation scheduler, called MSS, to provide simulation runtime speedup for executing SDF graphs on multicore processors. MSS strategically integrates graph clustering, intracluster scheduling, actor vectorization, and intercluster buffering techniques to construct InterThread Communication (ITC) graphs at compile-time. MSS then applies efficient synchronization and dynamic scheduling techniques at runtime for executing ITC graphs in multithreaded environments. We have implemented MSS in the Advanced Design System (ADS) from Agilent Technologies. On an Intel dual-core, hyper-threading (4 processing units) processor, our results from this implementation demonstrate up to 3.5 times speedup in simulating modern wireless communication systems (e.g., WCDMA3G, CDMA 2000, WiMax, EDGE, and Digital TV).",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2029163387",
    "type": "article"
  },
  {
    "title": "Accurate Analysis and Prediction of Enterprise Service-Level Performance",
    "doi": "https://doi.org/10.1145/2757279",
    "publication_date": "2015-09-28",
    "publication_year": 2015,
    "authors": "Qing Duan; Abhishek Koneru; Jun Zeng; Krishnendu Chakrabarty; Gary Dispoto",
    "corresponding_authors": "",
    "abstract": "An enterprise service-level performance time series is a sequence of data points that quantify demand, throughput, average order-delivery time, quality of service, or end-to-end cost. Analytical and predictive models of such time series can be embedded into an enterprise information system (EIS) in order to provide meaningful insights into potential business problems and generate guidance for appropriate solutions. Time-series analysis includes periodicity detection, decomposition, and correlation analysis. Time-series prediction can be modeled as a regression problem to forecast a sequence of future time-series datapoints based on the given time series. The state-of-the-art (baseline) methods employed in time-series prediction generally apply advanced machine-learning algorithms. In this article, we propose a new univariate method for dealing with midterm time-series prediction. The proposed method first analyzes the hierarchical periodic structure in one time series and decomposes it into trend, season, and noise components. By discarding the noise component, the proposed method only focuses on predicting repetitive season and smoothed trend components. As a result, this method significantly improves upon the performance of baseline methods in midterm time-series prediction. Moreover, we propose a new multivariate method for dealing with short-term time-series prediction. The proposed method utilizes cross-correlation information derived from multiple time series. The amount of data taken from each time series for training the regression model is determined by results from hierarchical cross-correlation analysis. Such a data-filtering strategy leads to improved algorithm efficiency and prediction accuracy. By combining statistical methods with advanced machine-learning algorithms, we have achieved a significantly superior performance in both short-term and midterm time-series predictions compared to state-of-the-art (baseline) methods.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2029756330",
    "type": "article"
  },
  {
    "title": "Integrated Coherence Prediction",
    "doi": "https://doi.org/10.1145/2611756",
    "publication_date": "2014-06-01",
    "publication_year": 2014,
    "authors": "Libo Huang; Zhiying Wang; Nong Xiao; Yongwen Wang; Qiang Dou",
    "corresponding_authors": "",
    "abstract": "Multicore architectures with Network-on-Chips (NoCs) have been widely recognized as the de facto design for the efficient utilization of the continuously increasing density of transistors on a chip. A key challenge in designing such an NoC-based multicore processor is maintaining cache coherence in an efficient manner. Directory-based protocols avoid the bandwidth overhead of snoop-based protocols, therefore scaling to a large number of cores. However, conventional directory structures add significant indirection delay to cache-to-cache accesses in larger multicore processor. In this article we propose a novel hardware coherence technique, called integrated coherence prediction (ICP). This approach adopts a prediction technique for managing shared data to reduce or eliminate the cache-to-cache delay in coherence accesses. ICP has two unique features that differ from previous coherence prediction techniques. First, ICP introduces a new integrated prediction scheme that combines two kinds of predictors: owner predictor, which predicts the data writers and avoids the indirection through directory, and data predictor, which predicts the access address and prefetches data from remote nodes directly. Second, ICP uses a request replication method to reduce the negative effect of wrong owner prediction operations, thus facilitating overall performance improvement. We present the design and implementation details of the ICP approach. Using detailed full-system simulations, we conclude that the ICP provides a cost-effective solution for designing high-performance multicore processors.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2071208495",
    "type": "article"
  },
  {
    "title": "The Design and Experiments of A SID-Based Power-Aware Simulator for Embedded Multicore Systems",
    "doi": "https://doi.org/10.1145/2699834",
    "publication_date": "2015-03-02",
    "publication_year": 2015,
    "authors": "Cheng-Yen Lin; Chung-Wen Huang; Chi-Bang Kuan; Shi‐Yu Huang; Jenq‐Kuen Lee",
    "corresponding_authors": "",
    "abstract": "Embedded multicore systems are playing increasingly important roles in the design of consumer electronics. The objective of such systems is to optimize both performance and power characteristics of mobile devices. However, currently there are no power metrics supporting popular application design platforms (such as SID) that application developers use to develop their applications. This hinders the ability of application developers to optimize power consumption. In this article we present the design and experiments of a SID-based power-aware simulation framework for embedded multicore systems. The proposed power estimation flow includes two phases: IP-level power modeling and power-aware system simulation. The first phase employs PowerMixer IP to construct the power model for the processor IP and other major IPs, while the second phase involves a power abstract interpretation method for summarizing the simulation trace, then, with a CPE module, estimating the power consumption based on the summarized trace information and the input of IP power models. In addition, a Manager component is devised to map each digital signal processor (DSP) component to a host thread and maintain the access to shared resources. The aim is to maintain the simulation performance as the number of simulated DSP components increases. A power-profiling API is also supported that developers of embedded software can use to tune the granularity of power-profiling for a specific code section of the target application. We demonstrate via case studies and experiments how application developers can use our SID-based power simulator for optimizing the power consumption of their applications. We characterize the power consumption of DSP applications with the DSPstone benchmark and discuss how compiler optimization levels with SIMD intrinsics influence the performance and power consumption. A histogram application and an augmented-reality application based on human-face-based RMS (recognition, mining, and synthesis) application are deployed as running examples on multicore systems to demonstrate how our power simulator can be used by developers in the optimization process to illustrate different views of power dissipations of applications.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2086056732",
    "type": "article"
  },
  {
    "title": "Hybrid Cache Designs for Reliable Hybrid High and Ultra-Low Voltage Operation",
    "doi": "https://doi.org/10.1145/2658988",
    "publication_date": "2014-11-18",
    "publication_year": 2014,
    "authors": "Bojan Maric; Jaume Abella; Francisco J. Cazorla; Mateo Valero",
    "corresponding_authors": "",
    "abstract": "Geometry scaling of semiconductor devices enables the design of ultra-low-cost (e.g., below 1 USD) battery-powered resource-constrained ubiquitous devices for environment, urban life, and body monitoring. These sensor-based devices require high performance to react in front of infrequent particular events as well as extreme energy efficiency in order to extend battery lifetime during most of the time when low performance is required. In addition, they require real-time guarantees. The most suitable technological solution for these devices consists of using hybrid processors able to operate at: (i) high voltage to provide high performance and (ii) near-/subthreshold voltage to provide ultra-low energy consumption. However, the most efficient SRAM memories for each voltage level differ and trading off different SRAM designs is mandatory. This is particularly true for cache memories, which occupy most of the processor's area. In this article, we propose new, simple, single-Vcc-domain hybrid L1 cache architectures suitable for reliable hybrid high and ultra-low voltage operation. In particular, the cache is designed by combining heterogeneous SRAM cell types: some of the cache ways are optimized to satisfy high-performance requirements during high voltage operation, whereas the rest of the ways provide ultra-low energy consumption and reliability during near-/subthreshold voltage operation. We analyze the performance, energy, and power impact of the proposed cache designs when using them to implement L1 caches in a processor. Experimental results show that our hybrid caches can efficiently and reliably operate across a wide range of voltages, consuming little energy at near-/subthreshold voltage as well as providing high performance at high voltage without decreasing reliability levels to provide strong performance guarantees, as required for our target market.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2091312386",
    "type": "article"
  },
  {
    "title": "Architecture customization of on-chip reconfigurable accelerators",
    "doi": "https://doi.org/10.1145/2493384",
    "publication_date": "2013-10-01",
    "publication_year": 2013,
    "authors": "Jonghee Yoon; Jongeun Lee; Sang‐Hyun Park; Yong‐Joo Kim; Jin‐Yong Lee; Yunheung Paek; Doosan Cho",
    "corresponding_authors": "",
    "abstract": "Integrating coarse-grained reconfigurable architectures (CGRAs) into a System-on-a-Chip (SoC) presents many benefits as well as important challenges. One of the challenges is how to customize the architecture for the target applications efficiently and effectively without performing explicit design space exploration. In this article we present a novel methodology for incremental interconnect customization of CGRAs that can suggest a new interconnection architecture which is able to maximize the performance for a given set of application kernels while minimizing the hardware cost. In our methodology, we translate the problem of interconnect customization into that of inexact graph matching, and we devised a heuristic for A* search algorithm to efficiently solve the inexact graph matching problem. Our experimental results demonstrate that our customization method can quickly find application-optimized interconnections that exhibit 80% higher performance on average compared to the base architecture which has mesh interconnections, with little energy and hardware increase in interconnections and muxes.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2116069425",
    "type": "article"
  },
  {
    "title": "Resource-constrained multiprocessor synthesis for floating-point applications on FPGAs",
    "doi": "https://doi.org/10.1145/2003695.2003701",
    "publication_date": "2011-10-01",
    "publication_year": 2011,
    "authors": "Xiaofang Wang; Pallav Gupta",
    "corresponding_authors": "",
    "abstract": "Although state-of-the-art field-programmable gate arrays offer exciting new opportunities in exploring low-cost high-performance architectures for data-intensive scientific applications, they also present serious challenges. Multiprocessor-on-programmable-chip, which integrates software programmability and hardware reconfiguration, provides substantial flexibility that results in shorter design cycles, higher performance, and lower cost. In this article, we present an application-specific design methodology for multiprocessor-on-programmable-chip architectures that target applications involving large matrices and floating-point operations. Given an application with specific energy-performance and resource constraints, our methodology aims to customize the architecture to match the diverse computation and communication requirements of the application tasks. Graph-based analysis of the application drives system synthesis that employs a precharacterized, parameterized hardware component library of functional units. Extensive experimental results for three diverse applications are presented to demonstrate the efficacy of our design methodology.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2132993912",
    "type": "article"
  },
  {
    "title": "The survivability of design-specific spare placement in FPGA architectures with high defect rates",
    "doi": "https://doi.org/10.1145/2442087.2442104",
    "publication_date": "2013-03-01",
    "publication_year": 2013,
    "authors": "Amit Agarwal; Jason Cong; Brian Tagiku",
    "corresponding_authors": "",
    "abstract": "We address the problem of optimizing fault tolerance in FPGA architectures with high defect rates (such as nano-FPGAs) without significantly degrading performance. Our methods address fault tolerance during the placement and reconfiguration stages of FPGA programming. First, we provide several complexity results for both the fault reconfiguration and fault-tolerance placement problems. Then, we propose a placement algorithm which, in the presence of randomly generated faults, optimizes spare placement to maximize the probability that the FPGA can be reconfigured to meet a specified timing constraint. We also give heuristics for reconfiguration after faults have been detected. Despite the hardness results for both the placement and reconfiguration problems, we show our heuristics perform well in simulation (in one scenario, increasing the probability of successful reconfiguration by as much as 55% compared to a uniform spare placement).",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2137680068",
    "type": "article"
  },
  {
    "title": "Memory Management Scheme to Improve Utilization Efficiency and Provide Fast Contiguous Allocation without a Statically Reserved Area",
    "doi": "https://doi.org/10.1145/2770871",
    "publication_date": "2015-12-02",
    "publication_year": 2015,
    "authors": "Myungsun Kim; Jinkyu Koo; Hyojung Lee; James R. Geraci",
    "corresponding_authors": "",
    "abstract": "Fast allocation of large blocks of physically contiguous memory plays a crucial role to boost the performance of multimedia applications in modern memory-constrained portable devices, such as smartphones, tablets, etc. Existing systems have addressed this issue by provisioning a large statically reserved memory area (SRA) in which only dedicated applications can allocate pages. However, this in turn degrades the performance of applications that are prohibited to utilize the SRA due to the reduced available memory pool. To overcome this drawback while maintaining the benefits of the SRA, we propose a new memory management scheme that uses a special memory region, called page-cache-preferred area (PCPA), in concert with a quick memory reclaiming algorithm. The key of the proposed scheme is to enhance the memory utilization efficiency by enabling to allocate page-cached pages of all applications in the PCPA until predetermined applications require to allocate big chunks of contiguous memory. At this point, clean page-cached pages in the PCPA are rapidly evicted without write-back to a secondary storage. Compared to the SRA scheme, experimental results show that the average launch time of real-world applications and the execution time of I/O-intensive benchmarks are reduced by 9.2% and 24.7%, respectively.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2187091322",
    "type": "article"
  },
  {
    "title": "Auxiliary Variables in Temporal Specifications",
    "doi": "https://doi.org/10.1145/2811260",
    "publication_date": "2016-01-28",
    "publication_year": 2016,
    "authors": "Laurence Pierre",
    "corresponding_authors": "Laurence Pierre",
    "abstract": "Assertion-based verification (ABV) for IP blocks given as synchronous RTL (register transfer level) descriptions has now widely gained acceptance. The challenge addressed here is ABV for systems on chip (SoC) modeled at the system level in SystemC TLM (Transactional Level Modeling). Requirements to be verified at this level of abstraction usually express temporal constraints on the interactions and communications in the SoC. We use the IEEE standard language PSL to formalize these temporal assertions which represent properties on communication actions and their parameters. Auxiliary variables are often indispensable for this formalization, but their use may induce semantic issues. This article discusses this matter, analyzes various existing approaches and proposes a summary of their advantages and shortcomings. They are also compared to our syntactic and semantic framework, implemented in a verification tool. The proposed operational semantics has the advantages of being simple and intuitive while supporting both global and local auxiliary variables. Experimental results on industrial case studies illustrate its applicability.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2253024290",
    "type": "article"
  },
  {
    "title": "Parallel Power Grid Analysis Based on Enlarged Partitions",
    "doi": "https://doi.org/10.1145/2806885",
    "publication_date": "2016-01-28",
    "publication_year": 2016,
    "authors": "Le Zhang; Vivek Sarin",
    "corresponding_authors": "",
    "abstract": "As the size and complexity of current VLSI circuits grows, faster power grid simulation is becoming more and more desirable. In this article, we present a parallel iterative method for static VLSI power grid simulation. In the proposed enlarged-partition-based preconditioned conjugate gradient (EPPCG) power grid solver, the power grid is divided into disjoint partitions that are subsequently enlarged to obtain accurate solution within each partition. The global solution obtained by solving enlarged partition problems concurrently acts as a highly effective parallel preconditioner. The combination of effective preconditioning and efficient parallelization helps achieve very high performance. The experiments show that our parallel implementation can achieve significant speed improvement [61X--142X] over a state-of-the-art direct solver.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2255308470",
    "type": "article"
  },
  {
    "title": "Design-for-Testability for Functional Broadside Tests under Primary Input Constraints",
    "doi": "https://doi.org/10.1145/2831231",
    "publication_date": "2016-01-28",
    "publication_year": 2016,
    "authors": "Irith Pomeranz",
    "corresponding_authors": "Irith Pomeranz",
    "abstract": "Functional broadside tests avoid overtesting of delay faults by creating functional operation conditions during the clock cycles where delay faults are detected. When a circuit is embedded in a larger design, a functional broadside test needs to take into consideration the functional constraints that the design creates for its primary input vectors. At the same time, application of primary input vectors as part of a scan-based test requires hardware support. An earlier work considered the case where a primary input vector is held constant during a test. The approach described in this article matches the hardware for applying primary input vectors to the functional constraints that the design creates. This increases the transition fault coverage that can be achieved by functional broadside tests. This article also considers the effect on the transition fault coverage achievable using close-to-functional broadside tests.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2267298653",
    "type": "article"
  },
  {
    "title": "Analytical Clustering Score with Application to Postplacement Register Clustering",
    "doi": "https://doi.org/10.1145/2894753",
    "publication_date": "2016-05-11",
    "publication_year": 2016,
    "authors": "Chang Xu; Guojie Luo; Peixin Li; Yiyu Shi; Iris Hui-Ru Jiang",
    "corresponding_authors": "",
    "abstract": "Circuit clustering is usually done through discrete optimizations to enable circuit size reduction or design-specific cluster formation. In this article, we are interested in the register-clustering technique for clock-power reduction by leveraging new opportunities introduced by multibit flip-flop (MBFF). Currently, INTEGRA is the only existing postplacement MBFF clustering optimizer with a subquadratic time complexity. However, it severely degrades the wirelength, especially for realistic designs, which may nullify the benefits of MBFF clustering. In contrast, we formulate an analytical clustering score with a nonlinear programming framework, in which the wirelength objective can be seamlessly integrated and the solver has empirical subquadratic time complexity. With the MBFF library, the application of our analytical clustering method achieves comparable clock power to the state-of-the-art techniques, but further reduces the wirelength by about 25%. Even without the MBFF library, we can still achieve 30% clock wirelength reduction. In addition, the proposed method can potentially be integrated into an in-placement MBFF clustering solver and be applied to other problems that require formulating clustering scores in their objective functions.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2387618302",
    "type": "article"
  },
  {
    "title": "Non-enumerative Generation of Path Delay Distributions and Its Application to Critical Path Selection",
    "doi": "https://doi.org/10.1145/2940327",
    "publication_date": "2016-12-13",
    "publication_year": 2016,
    "authors": "Ahish Mysore Somashekar; Spyros Tragoudas; R. Jayabharathi; Sreenivas Gangadhar",
    "corresponding_authors": "",
    "abstract": "A Monte Carlo-based approach is proposed capable of identifying in a non-enumerative and scalable manner the distributions that describe the delay of every path in a combinational circuit. Furthermore, a scalable approach to select critical paths from a potentially exponential number of path candidates is presented. Paths and their delay distributions are stored in Zero Suppressed Binary Decision Diagrams. Experimental results on some of the largest ISCAS-89 and ITC-99 benchmarks shows that the proposed method is highly scalable and effective.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2404101323",
    "type": "article"
  },
  {
    "title": "EBL Overlapping Aware Stencil Planning for MCC System",
    "doi": "https://doi.org/10.1145/2888394",
    "publication_date": "2016-05-16",
    "publication_year": 2016,
    "authors": "Bei Yu; Kun Yuan; Jhih-Rong Gao; Shiyan Hu; David Z. Pan",
    "corresponding_authors": "",
    "abstract": "Electron beam lithography (EBL) is a promising, maskless solution for the technology beyond 14nm logic nodes. To overcome its throughput limitation, industry has proposed character projection (CP) technique, where some complex shapes (characters) can be printed in one shot. Recently, the traditional EBL system was extended into a multi-column cell (MCC) system to further improve the throughput. In an MCC system, several independent CPs are used to further speed-up the writing process. Because of the area constraint of stencil, the MCC system needs to be packed/planned carefully to take advantage of the characters. In this article, we prove that the overlapping aware stencil planning (OSP) problem is NP-hard. Then we propose E-BLOW, a tool to solve the MCC system OSP problem. E-BLOW involves several novel speedup techniques, such as successive relaxation and dynamic programming. Experimental results show that, compared with previous works, E-BLOW demonstrates better performance for both the conventional EBL system and the MCC system.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2406393984",
    "type": "article"
  },
  {
    "title": "Resource Sharing Centric Dynamic Voltage and Frequency Scaling for CMP Cores, Uncore, and Memory",
    "doi": "https://doi.org/10.1145/2897394",
    "publication_date": "2016-05-27",
    "publication_year": 2016,
    "authors": "Jae-Yeon Won; Paul V. Gratz; Srinivas Shakkottai; Jiang Hu",
    "corresponding_authors": "",
    "abstract": "With the breakdown of Dennard’s scaling over the past decade, performance growth of modern microprocessor design has largely relied on scaling core count in chip multiprocessors (CMPs). The challenge of chip power density, however, remains and demands new power management solutions. This work investigates a coordinated CMP systemwide Dynamic Voltage and Frequency Scaling (DVFS) policy centered around shared resource utilization. This approach represents a new angle on the problem, differing from the conventional core-workload-driven approaches. The key component of our work is per-core DVFS leveraging a technique similar to TCP Vegas congestion control from networking. This TCP Vegas–based DVFS can potentially identify the synergy between power reduction and performance improvement. Further, this work includes uncore (on-chip interconnect and shared last level cache) and main memory DVFS policies coordinated with the per-core DVFS policy. Full system simulations on PARSEC benchmarks show that our technique reduces total energy dissipation by over 47% across all benchmarks with less than 2.3% performance degradation. Our work also leads to 12% more energy savings compared to a prior work CMP DVFS policy.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2407590042",
    "type": "article"
  },
  {
    "title": "Timing Path-Driven Cycle Cutting for Sequential Controllers",
    "doi": "https://doi.org/10.1145/2893473",
    "publication_date": "2016-06-22",
    "publication_year": 2016,
    "authors": "William Lee; Vikas S. Vij; Kenneth S. Stevens",
    "corresponding_authors": "",
    "abstract": "Power and performance optimization of integrated circuits is performed by timing-driven algorithms that operate on directed acyclic graphs. Sequential circuits and circuits with topological feedback contain cycles. Cyclic circuits must be represented as directed acyclic graphs to be optimized and evaluated using static timing analysis. Algorithms in commercial electronic design automation tools generate the required acyclic graphs by cutting cycles without considering timing paths. This work reports on a method for generating directed acyclic circuit graphs that do not cut the specified timing paths. The algorithm is applied to over 125 benchmark designs and asynchronous handshake controllers. The runtime is less than 1 second, even for even the largest published controllers. Circuit timing graphs generated using this method retain the necessary timing paths, which enables circuit validation and optimization employing the commercial tools. Additional benefits show these designs are on an average a third in size, operate 33.3% faster, and consume one-fourth the energy.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2465766305",
    "type": "article"
  },
  {
    "title": "Hierarchical Statistical Leakage Analysis and Its Application",
    "doi": "https://doi.org/10.1145/2896820",
    "publication_date": "2016-09-02",
    "publication_year": 2016,
    "authors": "Yang Xu; Jürgen Teich",
    "corresponding_authors": "",
    "abstract": "In this article, we investigate a hierarchical statistical leakage analysis (HSLA) design flow where module-level statistical leakage models supplied by IP vendors are used to improve the efficiency and capacity of SoC statistical leakage power analysis. To solve the challenges of incorporating spatial correlations between IP modules at system level, we first propose a method to extract correlation-inclusive leakage models. Then a method to handle the spatial correlations at system level is proposed. Using this method, the runtime of system statistical leakage analysis (SLA) can be significantly improved without disclosing the netlists of the IP modules. Experimental results demonstrate that the proposed HSLA method is about 100 times faster than gate-level full-chip SLA methods while maintaining the accuracy. In addition, we also investigate one application of this HSLA method, a leakage-yield-driven floorplanning framework, to demonstrate the benefits of such an HSLA method in practice. Moreover, an optimized hierarchical leakage analysis method dedicated to the floorplanning framework is proposed. The effectiveness of the floorplanning framework and the optimized method are confirmed by extensive experimental results.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2509992958",
    "type": "article"
  },
  {
    "title": "Code generation of nested loops for DSP processors with heterogeneous registers and structural pipelining",
    "doi": "https://doi.org/10.1145/315773.315776",
    "publication_date": "1999-07-01",
    "publication_year": 1999,
    "authors": "Wei‐Kai Cheng; Youn-Long Lin",
    "corresponding_authors": "",
    "abstract": "We propose a microcode-optimizing method targeting a programmable DSP processor. Efficient generation of microcodes is essential to better utilize the computation power of a DSP processor. Since most state-of-the-art DSP processors feature some sort of irregular architectures and most DSP applications have nested loop constructs, their code generation is a nontrivial task. In this paper, we consider two features frequently found in contemporary DSP processors — structural pipelining and heterogeneous registers. We propose a code generator that performs instruction scheduling and register allocation simultaneously. The proposed approach has been implemented and evaluated using a set of benchmark core algorithms. Simulation of the generated codes targeted towards the TI TMS320C40 DSP processor shows that our system is indeed more effective compared with a commercial optimizing DSP compiler.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2043381627",
    "type": "article"
  },
  {
    "title": "Parallel logic simulation on a network of workstations using parallel virtual machine",
    "doi": "https://doi.org/10.1145/253052.253082",
    "publication_date": "1997-04-01",
    "publication_year": 1997,
    "authors": "M. Kormicki; Ausif Mahmood; B.S. Carlson",
    "corresponding_authors": "",
    "abstract": "This paper explores parallel logic simulation on a network of workstations using a parallel virtual machine (PVM). A novel parallel implementation of the centralized-time event-driven logic simulation algorithm is carried out such that no global controlling workstation is needed to synchronize the advance of simulation time. Further advantages of our new approach include a random partitioning of the circuit onto available workstations and a pipelined execution of the different phases of the simulation algorithm. To achieve a better load balance, we employ a semioptimistic scheme for gate evaluations (in conjunction with a centralized-time algorithm) such that no rollback is required. The performance of this implementation has been evaluated using the ISCAS benchmark circuits. Speedups improve with the size of the circuit and the activity level in the circuit. Analyses of the communication overhead show that the techniques developed here will yield even higher gains as newer networking technologies like ATM are employed to connect workstations.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2073907115",
    "type": "article"
  },
  {
    "title": "Optimal river routing with crosstalk constraints",
    "doi": "https://doi.org/10.1145/293625.293636",
    "publication_date": "1998-07-01",
    "publication_year": 1998,
    "authors": "Hai Zhou; Martin D. F. Wong",
    "corresponding_authors": "",
    "abstract": "With the increasing density of VLSI circuits, the interconnection wires are being packed even closer. This has increased the effect of interaction among these wires on circuit performance and hence, the importance of controlling crosstalk. In this article, we consider river routing with crosstalk constraints. Given the positions of the pins in a single-layer routing channel and the maximum tolerable crosstalk between each pair of neighboring nets, we give a polynomial time algorithm to decide whether there is a feasible river routing solution and produce one with minimum crosstalk when it is feasible.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2075693636",
    "type": "article"
  },
  {
    "title": "Analysis of RC interconnections under ramp input",
    "doi": "https://doi.org/10.1145/253052.253137",
    "publication_date": "1997-04-01",
    "publication_year": 1997,
    "authors": "Andrew B. Kahng; S. Muddu",
    "corresponding_authors": "",
    "abstract": "We give new methods for calculating the time-domain response for a finite-length distributed RC line that is stimulated by a ramp input. The following are our contributions. First, we obtain the solution of the diffusion equation for a seminfinite distributed RC line with ramp input. We then present a general and, in the limit, exact approach to compute the time-domain response for finite-length RC lines under ramp input by summing distinct diffusions starting at either end of the line. Next, we obtain analytical expressions for the finite time-domain voltage response for an open-ended finite RC line and for a finite RC line with capacitive load. The delay estimates using this method are very close to SPICE-computing delays. Finally, we present a general recursive equation for computing the higher-order diffusion components due to reflections at the source and load ends. Future work extends our method to response computations in general interconnection trees by modeling both reflection and transmission coefficients at discontinuities.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2103018341",
    "type": "article"
  },
  {
    "title": "Power optimization of technology-dependent circuits based on symbolic computation of logic implications",
    "doi": "https://doi.org/10.1145/348019.348028",
    "publication_date": "2000-07-01",
    "publication_year": 2000,
    "authors": "R. Iris Bahar; Ernest T. Lampe; Enrico Macii",
    "corresponding_authors": "",
    "abstract": "This paper presents a novel approach to the problem of optimizing combinational circuits for low power. The method is inspired by the fact that power analysis performed on a technology mapped network gives more realistic estimates than it would at the technology-independent level. After each node's switching activity in the circuit is determined, high-power nodes are eliminated through redundancy addition and removal. To do so, the nodes are sorted according to their switching activity, they are considered one at a time, and learning is used to identify direct and indirect logic implications inside the network. These logic implications are exploited to add gates and connections to the circuit; this may help in eliminating high-power dissipating nodes, thus reducing the total switching activity and power dissipation of the entire circuit. The process is iterative; each iteration starts with a different target node. The end result is a circuit with a decreased switching power. Besides the general optimization algorithm, we propose a new BDD-based method for computing satisfiability and observability implications in a logic network; futhermore, we present heuristic techniques to add and remove redundancy at the technology-dependent level, that is, restructure the logic in selected places without destroying the topology of the mapped circuit. Experimental results show the effectiveness of the proposed technique. On average, power is reduced by 34%, and up to a 64% reduction of power is possible, with a negligible increase in the circuit delay.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W1971013612",
    "type": "article"
  },
  {
    "title": "Microarchitectural synthesis of performance-constrained, low-power VLSI designs",
    "doi": "https://doi.org/10.1145/504914.504919",
    "publication_date": "2002-01-01",
    "publication_year": 2002,
    "authors": "L. Goodby; Alex Orailoğlu; P.M. Chau",
    "corresponding_authors": "",
    "abstract": "New portable signal-processing applications such as mobile telephony, wireless computing, and personal digital assistants place stringent power consumption limits on their constituent components. Substantial power savings can be realized if 5 V designs are translated to use the new lower supply voltage standards. This conversion, however, is not achieved easily: a design originally targeted for implementation in a 5 V technology will typically require significant rework to meet timing and throughput requirements at the lower operating voltage. In this paper we describe a high-level synthesis system which assists the designer in performing this task, minimizing the need for manual redesign. Techniques employed in this work include pipelining and a new approach to module selection that minimizes power consumption subject to timing constraints. Using these and other high-level synthesis techniques to target designs to 3.3 V libraries, we show that it is possible to reduce power consumption by as much as 56% as compared to the original 5 V implementation, while meeting specified minimum throughput and maximum latency constraints.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W1979764693",
    "type": "article"
  },
  {
    "title": "Global array reference allocation",
    "doi": "https://doi.org/10.1145/544536.544542",
    "publication_date": "2002-04-01",
    "publication_year": 2002,
    "authors": "Guido Araújo; Guilherme Ottoni; Marcelo Cintra",
    "corresponding_authors": "",
    "abstract": "Embedded systems executing specialized programs have been increasingly responsible for a large share of the computer systems manufactured every year. This trend has increased the demand for processors that can guarantee high-performance under stringent cost, power, and code size constraints. Indirect addressing is by far the most used addressing mode in programs running on these systems, since it enables the design of small and faster instructions. This paper proposes a solution to the problem of allocating registers to array references using auto-increment addressing modes. It extends previous work in the area by enabling efficient allocation in the presence of control-flow statements. The solution is based on an algorithm that merges address registers' live ranges pairwise. An optimizing DSP compiler, from Mindspeed Technologies Inc., is used to validate this idea. Experimental results reveal a substantial improvement in code performance, when comparing to a combination of local auto-increment detection and priority-based register coloring.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2007875098",
    "type": "article"
  },
  {
    "title": "Stochastic sequential machine synthesis with application to constrained sequence generation",
    "doi": "https://doi.org/10.1145/348019.348566",
    "publication_date": "2000-07-01",
    "publication_year": 2000,
    "authors": "Diana Marculescu; Radu Mărculescu; Massoud Pedram",
    "corresponding_authors": "",
    "abstract": "In power estimation, one is faced with two problems: (1) generating input vector sequences that satisfy a given statistical behavior (in terms of signal probabilities and correlations among bits); (2) making these sequences as short as possible so as to improve the efficiency of power simulators. Stochastic sequential machines (SSMs) can be used to solve both problems. In particular, this paper presents a general procedure for SSM synthesis and describes a new framework for sequence characterization to match designers' needs for sequence generation or compaction. Experimental results demonstrate that compaction ratios of 1–3 orders of magnitude can be obtained without much loss in accuracy of total power estimates.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2058130634",
    "type": "article"
  },
  {
    "title": "Von Neumann hybrid cellular automata for generating deterministic test sequences",
    "doi": "https://doi.org/10.1145/383251.383254",
    "publication_date": "2001-07-01",
    "publication_year": 2001,
    "authors": "Dimitri Kagaris; Spyros Tragoudas",
    "corresponding_authors": "",
    "abstract": "We propose an on-chip test pattern generator that uses an one-dimensional cellular automaton (CA) to generate either a precomputed sequence of test patterns or pairs of test patterns for path delay faults. To our knowledge, this is the first approach that guarantees successful on-chip generation of a given test pattern sequence (or a given test set for path delay faults) using a finite number of CA cells. Given a pair of columns (C u , C v ) of the test matrix, the proposed method uses alternative “link procedures” P j that compute the number of extra CA cells to enable the generation of (C u , C v ) by the CA. A systematic approach uses the link procedures to minimize the total number of needed CA cells. The performance of the scheme depends on an appropriate choice of link procedures P j .",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2058841704",
    "type": "article"
  },
  {
    "title": "A fast algorithm for context-aware buffer insertion",
    "doi": "https://doi.org/10.1145/504914.504922",
    "publication_date": "2002-01-01",
    "publication_year": 2002,
    "authors": "Ashok Jagannathan; Sung-Woo Hur; John Lillis",
    "corresponding_authors": "",
    "abstract": "We study the problem of performing buffer insertion in the context of a given layout. In a practical situation, there are restrictions on where buffers may be inserted; for instance, it may be possible to route wires over a preplaced macro cell, but may not be possible to insert buffers in that region. As a result, it is desirable to perform route planning and buffer insertion simultaneously. Furthermore it is necessary that such an algorithm be aware of the trade-off between cost (e.g., total capacitance) and delay. In this context we propose the delay reduction to cost ratio (DRCR) problem and present a fast algorithm for the same. Solutions identified by the algorithm are characterized with respect to the overall cost versus performance trade-off curve. Computational experiments demonstrate the viability of the approach.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2078281078",
    "type": "article"
  },
  {
    "title": "Using complete-1-distinguishability for FSM equivalence checking",
    "doi": "https://doi.org/10.1145/502175.502183",
    "publication_date": "2001-10-01",
    "publication_year": 2001,
    "authors": "Pranav Ashar; Aarti Gupta; Sharad Malik",
    "corresponding_authors": "",
    "abstract": "This article introduces the notion of a Complete-1-Distinguishability (C-1-D) property for simplifying equivalence checking of finite state machines (FSMs). When a specification machine has the C-1-D property, the traversal of the product machine can be eliminated. Instead, a much simpler check suffices. The check consists of first obtaining a 1-equivalence mapping between the individually reachable states of the specification and the implementation machines, and then checking that it is a bisimulation relation. The C-1-D property can be used directly for specification machines on which it naturally holds---a condition that has not been exploited thus far in FSM verification. We also show how this property can be enforced on an arbitrary FSM by exposing some of its latch outputs as pseudo-primary outputs during synthesis and verification. In this sense, our synthesis/verification methodology provides another point in the trade-off curve between constraints-on-synthesis versus complexity-of-verification. Practical experiences with this methodology have resulted in success with several examples for which it is not possible to complete verification using existing implicit state space traversal techniques.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2080343948",
    "type": "article"
  },
  {
    "title": "Deterministic replay for message-passing-based concurrent programs",
    "doi": "https://doi.org/10.1145/2209291.2209295",
    "publication_date": "2012-06-01",
    "publication_year": 2012,
    "authors": "Mohamed Elwakil; Zijiang Yang",
    "corresponding_authors": "",
    "abstract": "The Multicore Communications API (MCAPI) is a new message-passing API that was released by the Multicore Association. MCAPI provides an interface designed for closely distributed embedded systems with multiple cores on a chip and/or chips on a board. Similar to parallel programs in other domains, debugging MCAPI programs is a challenging task due to their nondeterministic behavior. In this article we present a tool that is capable of deterministically replaying MCAPI program executions, which provides valuable insight for MCAPI developers in case of failure.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W1965569645",
    "type": "article"
  },
  {
    "title": "An ILP solution to address code generation for embedded applications on digital signal processors",
    "doi": "https://doi.org/10.1145/2209291.2209301",
    "publication_date": "2012-06-01",
    "publication_year": 2012,
    "authors": "Hassan Salamy; J. Ramanujam",
    "corresponding_authors": "",
    "abstract": "Digital Signal Processors (DSPs) are a family of embedded processors designed under tight memory, area, and cost constraints. Many DSPs use irregular addressing modes where base-plus-offset mode is not supported. However, they often have Address Generation Units (AGUs) that can perform auto-increment/decrement address arithmetic instructions in parallel with Load/Store instructions. This feature can be utilized to reduce the number of explicit address arithmetic instructions and thus reduce the embedded application code size. This code size reduction is essential for this family of DSP as the code usually resides in the ROM and hence the code size directly translates into silicon area. An effective technique for optimized code generation is offset assignment. This is a well-used technique in the literature to decrease the code size by finding an offset assignment that can effectively utilize auto-increment/decrement. This problem is known as simple offset assignment when there is only one address register and as General Offset Assignment (GOA) for multiple available address registers. In this article, we present an optimal Integer Linear Programming (ILP) solution to the offset assignment problem with variable coalescing where more than one variable can share the same memory location. Variable permutation is also formulated to find the best access sequence to achieve the best offset assignment that decreases the code size the most. Experimental results on several benchmarks show the effectiveness of our variable permutation technique as well as the large improvement from the ILP-based solutions compared to heuristics.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W1973164084",
    "type": "article"
  },
  {
    "title": "Rectilinear Steiner trees on a checkerboard",
    "doi": "https://doi.org/10.1145/238997.239033",
    "publication_date": "1996-10-01",
    "publication_year": 1996,
    "authors": "Joseph L. Ganley; James P. Cohoon",
    "corresponding_authors": "",
    "abstract": "The rectilinear Steiner tree problem is to find a minimum-length set of horizontal and vertical line segments that interconnect a given set of points in the plane. Here we study the thumbnail rectilinear Steiner tree problem, where the input points are drawn from a small integer grid. Specifically, we devise a fully-set decomposition algorithm for computing optimal thumbnail rectilinear Steiner trees. We then present experimental results comparing the performance of this algorithm with two existing algorithms for computing optimal rectilinear Steiner trees. The thumbnail rectilinear Steiner tree problem has applications in VLSI placement algorithms, based on geometric partitioning, global routing of field-programmable gate arrays, and routing estimation during floorplanning.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W1970630754",
    "type": "article"
  },
  {
    "title": "POSE",
    "doi": "https://doi.org/10.1145/371254.371263",
    "publication_date": "2001-01-01",
    "publication_year": 2001,
    "authors": "Pao‐Ann Hsiung",
    "corresponding_authors": "Pao‐Ann Hsiung",
    "abstract": "Design automation tools and methodologies always encounter a problem of how systems may be designed efficiently, including issues such as static modeling and dynamic manipulation of system parts. With the rapid progress of design technology, the continuously increasing number of different choices per system part and the growing complexity of today's systems, the efficiency of the design environment is not only a major concern now, but will also be a demanding problem in the near future. In contrast to heuristic methods, a novel environment called POSE is proposed that increases efficiency during design without losing optimality in the final design results. System parts are modeled using the popular object-oriented modeling technique and are dynamically manipulated using the parallel design technique. A complete integration of object-oriented and parallel techniques is one of the major feature of POSE. Common problems related to parallel design such as emptiness and deadlock are also elegantly solved within POSE. Experimental results and formal analysis based on POSE all show its practical and theoretical usefulness. POSE can be used at any level of synthesis as long as off-the-shelf building-blocks manipulation is required. POSE can be applied especially to system-level synthesis, whose targets can be parallel computer architectures, systems-on-chip, or embedded systems. We will show how POSE has been applied to ICOS, a recently proposed synthesis methodology. Furthermore, POSE can be easily integrated with other heuristic design methodologies to allow increased design efficiency.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W1981374489",
    "type": "article"
  },
  {
    "title": "Test sequence generation for controller verification and test with high coverage",
    "doi": "https://doi.org/10.1145/1179461.1179467",
    "publication_date": "2006-10-01",
    "publication_year": 2006,
    "authors": "Sezer Gören; F.J. Ferguson",
    "corresponding_authors": "",
    "abstract": "Verification and test are critical phases in the development of any hardware or software system. This article focuses on black box testing of the control part of hardware and software systems. Black box testing involves specification, test generation, and fault coverage. Finite state machines (FSMs) are commonly used for specifying controllers. FSMs may have shortcomings in modeling complex systems. With the introduction of X-machines, complex systems can be modeled at higher levels of abstraction. An X-machine can be converted into an FSM while preserving the level of abstraction. The fault coverage of a test sequence for an FSM specification provides a confidence level. We propose a fault coverage metric for an FSM specification based on the transition fault model, and using this metric, we derive the coverage of a test sequence. The article also presents a method which generates short test sequences that meet a specific coverage level and then extends this metric to determine the coverage of a test sequence for an FSM driven by an FSM network. We applied our FSM verification technique to a real-life FSM, namely, the fibre channel arbitrated loop port state machine, used in the field of storage area networks.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W1970880128",
    "type": "article"
  },
  {
    "title": "LVS verification across multiple power domains for a quad-core microprocessor",
    "doi": "https://doi.org/10.1145/1142155.1142166",
    "publication_date": "2006-04-01",
    "publication_year": 2006,
    "authors": "Wei Li; Daniel P. Blakely; Scott Van Sooy; Keven Dunn; David Kidd; R. Rogenmoser; Dian Zhou",
    "corresponding_authors": "",
    "abstract": "A unique LVS (layout-versus-schematic) methodology has been developed for the verification of a four-core microprocessor with multiple power domains using a triple-well 90-nm CMOS technology. The chip is migrated from its previous generation that is for a twin-well process. Due to the design reuse, VDD and GND are designed as global nets but they are not globally connected across the entire chip. The standard LVS flow is unable to handle the additional design complexity and there seems to be no published literature tackling the problem. This paper presents a two-phase LVS methodology: a standard LVS phase where power and ground nets are defined as global nets and a multi-power-domain LVS phase where power and ground nets are treated as local nets. The first phase involves verifying LVS at the block level as well as the full-chip level. The second phase aims at verifying the integrity of the multi-power-domain power grid that is not covered in the first phase LVS. The proposed LVS methodology was successfully verified by real silicon.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2008522746",
    "type": "article"
  },
  {
    "title": "Stairway compaction using corner block list and its applications with rectilinear blocks",
    "doi": "https://doi.org/10.1145/989995.989998",
    "publication_date": "2004-04-01",
    "publication_year": 2004,
    "authors": "Yuchun Ma; Xianlong Hong; Sheqin Dong; Yici Cai; Chung‐Kuan Cheng; Jun Gu",
    "corresponding_authors": "",
    "abstract": "Corner Block List (CBL) was recently proposed as an efficient representation for MOSAIC packing of rectangles. Although the original method is really innovative, there still remains room for improvement for our purpose. This article proposes a compact algorithm for placement based on corner block list. By introducing the dummy blocks in CBL, our algorithm can intellectively employ dummy blocks in the packing to represent the placement including empty rooms, which corner block list cannot represent. Our algorithm can obtain the fast convergence to an optimal solution. Based on the compact approach, we propose a new way to handle arbitrary shaped rectilinear modules. The experimental results are demonstrated by some benchmark data and the performance shows effectiveness of the proposed method.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2027248990",
    "type": "article"
  },
  {
    "title": "Multiple wire reconnections based on implication flow graph",
    "doi": "https://doi.org/10.1145/1179461.1179468",
    "publication_date": "2006-10-01",
    "publication_year": 2006,
    "authors": "Zhong-Zhen Wu; Shih-Chieh Chang",
    "corresponding_authors": "",
    "abstract": "Global flow optimization (GFO) can perform multiple fanout/fanin wire reconnections at a time by modeling the problem of multiple wire reconnections with a flow graph, and then solving the problem using the maxflow-mincut algorithm on the flow graph. In this article, we propose an efficient multiple wire reconnection technique that modifies the framework of GFO, and as a result, can obtain better optimization quality. First, we observe that the flow graph in GFO cannot fully characterize wire reconnections, which causes the GFO to lose optimality in several obvious cases. In addition, we find that fanin reconnection can have more optimization power than fanout reconnection, but requires more sophisticated modeling. We reformulate the problem of fanout/fanin reconnections by a new graph, called the implication flow graph (IFG). We show that the problem of wire reconnections on the implication flow graph is NP-complete and also propose an efficient heuristic on the new graph. To demonstrate the effectiveness of our proposed method, we conduct an application which utilizes the flexibility of the wire reconnections explored in the logic domain to further minimize interconnects in the physical layout. Our experimental results are very exciting.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2069278063",
    "type": "article"
  },
  {
    "title": "A Delay-Adjustable, Self-Testable Flip-Flop for Soft-Error Tolerability and Delay-Fault Testability",
    "doi": "https://doi.org/10.1145/3462171",
    "publication_date": "2021-06-28",
    "publication_year": 2021,
    "authors": "Dave Y.-W. Lin; Charles H.‐P. Wen",
    "corresponding_authors": "",
    "abstract": "As the demand of safety-critical applications (e.g., automobile electronics) increases, various radiation-hardened flip-flops are proposed for enhancing design reliability. Among all flip-flops, Delay-Adjustable D-Flip-Flop (DAD-FF) is specialized in arbitrarily adjusting delay in the design to tolerate soft errors induced by different energy levels. However, due to a lack of testability on DAD-FF, its soft-error tolerability is not yet verified, leading to uncertain design reliability. Therefore, this work proposes Delay-Adjustable, Self-Testable Flip-Flop (DAST-FF), built on top of DAD-FF with two extra MUXs (one for scan test and the other for latching-delay verification) to achieve both soft-error tolerability and testability. Meanwhile, a built-in self-test method is also developed on DAST-FFs to verify the cumulative latching delay before operation. The experimental result shows that for a design with 8,802 DAST-FFs, the built-in self-test method only takes 946 ns to ensure the soft-error tolerability. As to the testability, the enhanced scan capability can be enabled by inserting one extra transmission gate into DAST-FF with only 4.5 area overhead.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W3174737455",
    "type": "article"
  },
  {
    "title": "A Novel Hybrid Cache Coherence with Global Snooping for Many-core Architectures",
    "doi": "https://doi.org/10.1145/3462775",
    "publication_date": "2021-09-13",
    "publication_year": 2021,
    "authors": "Sri Harsha Gade; Sujay Deb",
    "corresponding_authors": "",
    "abstract": "Cache coherence ensures correctness of cached data in multi-core processors. Traditional implementations of existing protocols make them unscalable for many core architectures. While snoopy coherence requires unscalable ordered networks, directory coherence is weighed down by high area and energy overheads. In this work, we propose Wireless-enabled Share-aware Hybrid (WiSH) to provide scalable coherence in many core processors. WiSH implements a novel Snoopy over Directory protocol using on-chip wireless links and hierarchical, clustered Network-on-Chip to achieve low-overhead and highly efficient coherence. A local directory protocol maintains coherence within a cluster of cores, while coherence among such clusters is achieved through global snoopy protocol. The ordered network for global snooping is provided through low-latency and low-energy broadcast wireless links. The overheads are further reduced through share-aware cache segmentation to eliminate coherence for private blocks. Evaluations show that WiSH reduces traffic by <?TeX $59.83\\%$?> and runtime by <?TeX $2.2\\times$?> , while requiring <?TeX $99\\%$?> smaller storage and <?TeX $58.55\\%$?> lower energy as compared to existing hierarchical and hybrid coherence protocols. Owing to its modularity, WiSH provides highly efficient and scalable coherence for many core processors.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W3199884367",
    "type": "article"
  },
  {
    "title": "Leveraging Automatic High-Level Synthesis Resource Sharing to Maximize Dynamical Voltage Overscaling with Error Control",
    "doi": "https://doi.org/10.1145/3473909",
    "publication_date": "2021-11-02",
    "publication_year": 2021,
    "authors": "Prattay Chowdhury; Benjamin Carrión Schäfer",
    "corresponding_authors": "",
    "abstract": "Approximate Computing has emerged as an alternative way to further reduce the power consumption of integrated circuits (ICs) by trading off errors at the output with simpler, more efficient logic. So far the main approaches in approximate computing have been to simplify the hardware circuit by pruning the circuit until the maximum error threshold is met. One of the critical issues, though, is the training data used to prune the circuit. The output error can significantly exceed the maximum error if the final workload does not match the training data. Thus, most previous work typically assumes that training data matches with the workload data distribution. In this work, we present a method that dynamically overscales the supply voltage based on different workload distribution at runtime. This allows to adaptively select the supply voltage that leads to the largest power savings while ensuring that the error will never exceed the maximum error threshold. This approach also allows restoring of the original error-free circuit if no matching workload distribution is found. The proposed method also leverages the ability of High-Level Synthesis (HLS) to automatically generate circuits with different properties by setting different synthesis constraints to maximize the available timing slack and, hence, maximize the power savings. Experimental results show that our proposed method works very well, saving on average 47.08% of power as compared to the exact output circuit and 20.25% more than a traditional approximation method.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W3208673028",
    "type": "article"
  },
  {
    "title": "Enabling multimedia using resource-constrained video processing techniques",
    "doi": "https://doi.org/10.1145/1297666.1297684",
    "publication_date": "2008-01-01",
    "publication_year": 2008,
    "authors": "Nicholas H. Zamora; Xiao Hu; Ümit Y. Ogras; Radu Mărculescu",
    "corresponding_authors": "",
    "abstract": "Successful proliferation of multimedia-enabled devices and advances in very large-scale integration (VLSI) technology has spawned new research efforts in migrating video processing applications onto ever smaller and more inexpensive devices. This article focuses on the technical challenges associated with that migration. Due to limitations in size, battery lifetime, and, ultimately, cost, mapping complex video applications onto resource-constrained systems is a very challenging proposition. To this end, we first consider a technique, region-of-interest (ROI) processing, of defining a window within a video frame and only operating on the data inside that window, ignoring the rest of the frame. By using this lossy technique, the processing requirements can be reduced by roughly 80% while the error introduced in the quality of the results is roughly 10%. The other technique is adaptive data partitioning (ADP) combined with a content-based power management algorithm. By distributing video processing among multiple processors and shutting them down when they are not needed, the energy consumed per processor can be reduced by 60% without sacrificing the performance of the underlying video-based application. Taken together, these novel techniques enable ambient multimedia systems and maintain the needed overall efficiency in video processing.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W1967480923",
    "type": "article"
  },
  {
    "title": "Spatial locality exploitation for runtime reordering of JPEG2000 wavelet data layouts",
    "doi": "https://doi.org/10.1145/1640457.1640465",
    "publication_date": "2009-12-01",
    "publication_year": 2009,
    "authors": "Bert Geelen; V. Ferentinos; Francky Catthoor; Gauthier Lafruit; Diederik Verkest; Rudy Lauwereins; T. Stouraitis",
    "corresponding_authors": "",
    "abstract": "Exploitation of spatial locality is essential for memories to increase the access bandwidth and to reduce the access-related latency and energy per word. Spatial locality exploitation of a kernel can be improved by modifying placement of data in memory, but this may be felt not only by the kernel itself, but also in other application components accessing the same data. Thus care is needed to avoid global miss-rate improvements are thwarted by miss-rate increases in other application components. This article examines application-level miss-rate increases due to handling modified Wavelet Transform data layouts by explicitly reordering at runtime, exploiting the execution order freedom within a reordering buffer when the layout of surrounding components is known. For the JPEG2000 application, taking into account the reordering costs still results in 80% net WT miss-rate gains.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2051939192",
    "type": "article"
  },
  {
    "title": "Performance-constrained voltage assignment in multiple supply voltage SoC floorplanning",
    "doi": "https://doi.org/10.1145/1640457.1640460",
    "publication_date": "2009-12-01",
    "publication_year": 2009,
    "authors": "Meng-Chen Wu; Ming-ching Lu; Chen Hung-Ming; Jing-Yang Jou",
    "corresponding_authors": "",
    "abstract": "Using voltage island methodology to reduce power consumption for System-on-a-Chip (SoC) designs has become more and more popular recently. Currently this approach has been considered either in system-level architecture or postplacement stage. Since hierarchical design and reusable intellectual property (IP) are widely used, it is necessary to optimize floorplanning/placement methodology considering voltage islands generation to solve power and critical path delay problems. In this article, we propose a floorplanning methodology considering voltage islands generation and performance constraints. Our method is flexible and can be extended to hierarchical design. The experimental results on some MCNC benchmarks show that our method is effective in meeting performance constraints and can simultaneously consider the tradeoff between power routing cost and total power dissipation.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2060898124",
    "type": "article"
  },
  {
    "title": "Effective decap insertion in area-array SoC floorplan design",
    "doi": "https://doi.org/10.1145/1391962.1391974",
    "publication_date": "2008-09-01",
    "publication_year": 2008,
    "authors": "Chao-Hung Lu; Hung-Ming Chen; Chien‐Nan Jimmy Liu",
    "corresponding_authors": "",
    "abstract": "As VLSI technology enters the nanometer era, supply voltages continue to drop due to the reduction of power dissipation, but it makes power integrity problems even worse. Employing decoupling capacitances (decaps) in floorplan stage is a common approach to alleviating supply noise problems. Previous researches overestimate the decap budget and do not fully utilize the empty space of the floorplan. A floorplan usually has a lot of available space that can be used to insert the decap without increasing the floorplan area. Therefore, the goal of this work is to develop a better model to calculate the required decap to solve the power supply noise problem in area-array based designs, and increase the usage of available space in the floorplan to reduce the area overhead caused by decap insertion. The experimental results of this work are encouraging. Compared with previous approaches, our methodology reduces 38% of the decap budget in average for MCNC benchmarks but can still meet the power supply noise requirements. The final floorplan areas with decap are also smaller than the numbers reported in previous works.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2128487118",
    "type": "article"
  },
  {
    "title": "A MATLAB Vectorizing Compiler Targeting Application-Specific Instruction Set Processors",
    "doi": "https://doi.org/10.1145/2996182",
    "publication_date": "2017-01-04",
    "publication_year": 2017,
    "authors": "Ioannis Latifis; Karthick Parashar; Grigoris Dimitroulakos; Hans Cappelle; Christakis Lezos; Κωνσταντίνος Μασσέλος; Francky Catthoor",
    "corresponding_authors": "",
    "abstract": "This article discusses a MATLAB-to-C vectorizing compiler that exploits custom instructions, for example, for Single Instruction Multiple Data (SIMD) processing and instructions for complex arithmetic present in Application-Specific Instruction Set Processors (ASIPs). Custom instructions are represented via specialized intrinsic functions in the generated code, and the generated code can be used as input to any C/C++ compiler supporting the target processor. Furthermore, the specialized instruction set of the target processor is described in a parameterized way using a target processor-independent architecture description approach, thus allowing the support of any processor. The compiler has been used for the generation of application code for two different ASIPs for several benchmarks. The code generated by the compiler achieves a speedup between 2× --74× and 2× --97× compared to the code generated by the MathWorks MATLAB-to-C compiler. Experimental results also prove that the compiler efficiently exploits SIMD custom instructions achieving a 3.3 factor speedup compared to cases where no SIMD processing is used. Thus the compiler can be employed to reduce the development time/effort/cost and time to market through raising the abstraction of application design in an embedded systems/system-on-chip development context.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2569816949",
    "type": "article"
  },
  {
    "title": "PeaPaw",
    "doi": "https://doi.org/10.1145/2999540",
    "publication_date": "2017-03-10",
    "publication_year": 2017,
    "authors": "Li Tang; Richard Frederick Barrett; Jeanine Cook; Xiaobo Sharon Hu",
    "corresponding_authors": "",
    "abstract": "Performance and energy are two major concerns for application development on heterogeneous platforms. It is challenging for application developers to fully exploit the performance/energy potential of heterogeneous platforms. One reason is the lack of reliable prediction of the system’s performance/energy before application implementation. Another reason is that a heterogeneous platform presents a large design space for workload partitioning between different processors. To reduce such development cost, this article proposes a framework, PeaPaw, to assist application developers to identify a workload partition (WP) that has high potential leading to high performance or energy efficiency before actual implementation. The PeaPaw framework includes both analytical performance/energy models and two sets of workload partitioning guidelines. Based on the design goal, application developers can obtain a workload partitioning guideline from PeaPaw for a given platform and follow it to design one or multiple WPs for a given workload. Then PeaPaw can be used to estimate the performance/energy of the designed WPs, and the WP with the best estimated performance/energy can be selected for actual implementation. To demonstrate the effectiveness of PeaPaw, we have conducted three case studies. Results from these case studies show that PeaPaw can faithfully estimate the performance/energy relationships of WPs and provide effective workload partitioning guidelines.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2597212175",
    "type": "article"
  },
  {
    "title": "SSAGA",
    "doi": "https://doi.org/10.1145/3014163",
    "publication_date": "2017-04-21",
    "publication_year": 2017,
    "authors": "Shamik Saha; Prabal Basu; Chidhambaranathan Rajamanikkam; Aatreyi Bal; Koushik Chakraborty; Sanghamitra Roy",
    "corresponding_authors": "",
    "abstract": "The emergence of GPGPU applications, bolstered by flexible GPU programming platforms, has created a tremendous challenge in maintaining high energy efficiency in modern GPUs. In this article, we demonstrate that customizing a Streaming Multiprocessor (SM) of a GPU at a lower frequency is significantly more energy efficient compared to employing DVFS on an SM designed for a high-frequency operation. Using a system-level CAD technique, we propose SSAGA—Streaming Multiprocessors Synthesized for Asymmetric GPGPU Applications —an energy-efficient GPU design paradigm. SSAGA creates architecturally identical SM cores, customized for different voltage-frequency domains. Our rigorous cross-layer methodology demonstrates an average of 20% improvement in energy efficiency over a spatially multitasking GPU across a range of GPGPU applications.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2606737494",
    "type": "article"
  },
  {
    "title": "Automated Integration of Dual-Edge Clocking for Low-Power Operation in Nanometer Nodes",
    "doi": "https://doi.org/10.1145/3054744",
    "publication_date": "2017-05-20",
    "publication_year": 2017,
    "authors": "Andrea Bonetti; Nicholas Preyss; Adam Teman; Andreas Burg",
    "corresponding_authors": "",
    "abstract": "Clocking power, including both clock distribution and registers, has long been one of the primary factors in the total power consumption of many digital systems. One straightforward approach to reduce this power consumption is to apply dual-edge-triggered (DET) clocking, as sequential elements operate at half the clock frequency while maintaining the same throughput as with conventional single-edge-triggered (SET) clocking. However, the DET approach is rarely taken in modern integrated circuits, primarily due to the perceived complexity of integrating such a clocking scheme. In this article, we first identify the most promising conditions for achieving low-power operation with DET clocking and then introduce a fully automated design flow for applying DET to a conventional SET design. The proposed design flow is demonstrated on three benchmark circuits in a 40nm CMOS technology, providing as much as a 50% reduction in clock distribution and register power consumption.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2619517799",
    "type": "article"
  },
  {
    "title": "Noc-HMP",
    "doi": "https://doi.org/10.1145/3073416",
    "publication_date": "2017-06-13",
    "publication_year": 2017,
    "authors": "Zoran Salčić; Heejong Park; Jürgen Teich; Avinash Malik; Muhammad Nadeem",
    "corresponding_authors": "",
    "abstract": "Scalability and performance in multicore processors for embedded and real-time systems usually don't go well each with the other. Networks on Chip (NoCs) provide scalable execution platforms suitable for such kind of embedded systems. This article presents a NoC-based Heterogeneous Multi-Processor system, called NoC-HMP, which is a scalable platform for embedded systems developed in the GALS language SystemJ. NoC-HMP uses a time-predictable TDMA-MIN NoC to guarantee latencies and communication time between the two types of time-predictable cores and can be customized for a specific performance goal through the execution strategy and scheduling of SystemJ program deployed across multiple cores. Examples of different execution strategies are introduced, explored and analyzed via measurements. The number of used cores can be minimized to achieve the target performance of the application. TDMA-MIN allows easy extensions of NoC-HMP with other cores or IP blocks. Experiments show a significant improvement of performance over a single core system and demonstrate how the addition of cores affects the performance of the designed system.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2625660785",
    "type": "article"
  },
  {
    "title": "A Hierarchical Technique for Statistical Path Selection and Criticality Computation",
    "doi": "https://doi.org/10.1145/3107030",
    "publication_date": "2017-08-31",
    "publication_year": 2017,
    "authors": "P. R. Chithira; V. Vasudevan",
    "corresponding_authors": "",
    "abstract": "Due to process variations, every path in the circuit is associated with a probability of being critical and a measure of this probability is the criticality of the path. Identification of critical paths usually proceeds in two steps, namely, generation of a candidate path set followed by computation of path criticality. As criticality computation is expensive, the candidate path set is chosen using simpler metrics. However, these metrics are not directly related to path criticality and, often, the set also contains low criticality paths that do not need to be tested. In this article, we propose a hierarchical technique that directly gives all paths above a global criticality threshold. The circuit is divided into disjoint groups at various levels. We show that the criticality of a group at each level of hierarchy can be computed using criticality of the parent group and the local complementary delay within the group. Low criticality groups are pruned at every level, making the computation efficient. This recursive partitioning and group criticality computation is continued until the group criticality falls below a threshold. Beyond this, the path selection within the group is done using branch-and-bound algorithm with global criticality as the metric. This is possible, since our method for criticality computation is very efficient. Unlike other techniques, path selection and criticality computation are integrated together so that when the path selection is complete, path criticality is also obtained. The proposed algorithm is tested with ISCAS’85, ISCAS’89, and ITC’99 benchmark circuits and the results are verified using Monte Carlo simulation. The experimental results suggest that the proposed method gives better accuracy on average with around 90% reduction in run-time.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2751627017",
    "type": "article"
  },
  {
    "title": "An Efficient False Path-Aware Heuristic Critical Path Selection Method with High Coverage of the Process Variation Space",
    "doi": "https://doi.org/10.1145/3177866",
    "publication_date": "2018-02-23",
    "publication_year": 2018,
    "authors": "Sheis Abolmaali; Mehdi Kamal; Ali Afzali‐Kusha; Massoud Pedram",
    "corresponding_authors": "",
    "abstract": "In this article, we present a critical path selection method that efficiently finds true (sensitizable) critical paths of a circuit in the presence of process variations. The method, which is based on the viability analysis, tries to select the least number of true critical paths that cover all of circuit critical gates. Critical gates are those that make a path critical with a probability higher than a predefined threshold value. Selecting fewer critical paths leads to less computation time for the algorithm and shorter test time of fabricated chips. For this purpose, an efficient Statistical Static Timing Analysis– (SSTA) based technique is suggested. This technique tries to find circuit-critical gates whose process parameter variations cover a major part of the process space. Improving the process space coverage using fewer paths is achieved by considering both spatial (proximity of gates) and structural (having common gates) correlations in the analysis of choosing the critical paths. In the selection process, paths with low similarities in their characteristics are preferred. In addition, only true paths whose delays affect the maximum delay of the circuit are included. The selected paths can be used in the test process of the fabricated chips to determine if the chip meets its timing requirements. Also, a modified viability analysis that incorporates statistical computations is used in the SSTA. The efficacy of the proposed method is evaluated by comparing its results for combinational and sequential ISCAS benchmarks with those obtained by exhaustive search. Results indicate although, on average, only 4.38% of all the critical paths found by the exhaustive search are selected by the proposed method, the maximum probability of criticality for the paths that are not considered in our method is, on average, less than 4%.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2793417036",
    "type": "article"
  },
  {
    "title": "Optimal Allocation of LDOs and Decoupling Capacitors within a Distributed On-Chip Power Grid",
    "doi": "https://doi.org/10.1145/3177877",
    "publication_date": "2018-05-09",
    "publication_year": 2018,
    "authors": "Sayed Abdullah Sadat; Mustafa S. Canbolat; Selçuk Köse",
    "corresponding_authors": "",
    "abstract": "Parallel on-chip voltage regulation, where multiple regulators are connected to the same power grid, has recently attracted significant attention with the proliferation of small on-chip voltage regulators. In this article, the number, size, and location of parallel low-dropout (LDO) regulators and intentional decoupling capacitors are optimized using mixed integer non-linear programming formulation. The proposed optimization function concurrently considers multiple objectives such as area, power noise, and overall power consumption. Certain objectives are optimized by putting constraints on the other objectives with the proposed technique. Additional constraints have been added to avoid the overlap of LDOs and decoupling capacitors in the optimization process. The results of an optimized LDO allocation in the POWER8 chip is compared with the recent LDO allocation in the same IBM chip in a case study where a 20% reduction in the noise is achieved. The results of the proposed multi-criteria objective function under a different area, power, and noise constraints are also evaluated with a sample ISPD’11 benchmark circuits in another case study.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2799981517",
    "type": "article"
  },
  {
    "title": "Rapid Triggering Capability Using an Adaptive Overlay during FPGA Debug",
    "doi": "https://doi.org/10.1145/3241045",
    "publication_date": "2018-11-30",
    "publication_year": 2018,
    "authors": "Fatemeh Eslami; Steven J. E. Wilton",
    "corresponding_authors": "",
    "abstract": "Field Programmable Gate Array (FPGA) technology is rapidly gaining traction in a wide range of applications. Nonetheless, FPGAs still require long design and debug cycles. To debug hardware circuits, trace-based instrumentation is inserted into the design that enables capturing data during the circuit execution into on-chip memories for later offline analysis. Since on-chip memories are limited, a trigger circuitry is used to only record data related to specific events during the execution. However, during debugging, a circuit recompilation is required on modifying these instruments. This can be very slow, reducing debug productivity. In this article, we propose a non-intrusive and rapid triggering solution with a tailored overlay fabric and mapping algorithm that seeks to enable fast debug iterations without performing a recompilation. This overlay is specialized for small combinational and sequential circuits with a single output; such circuits are typical of common trigger functions. We present an adaptive strategy to construct the overlay fabric using spare FPGA resources at compile time. At debug time, our proposed trigger mapping algorithms adapt to this specialized overlay to rapidly implement combinational and sequential trigger circuits. Our results show that the overlay fabric can be reconfigured to map different triggering scenarios in less than 40s instead of recompiling the circuit during debug iterations, increasing debug productivity.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2905522727",
    "type": "article"
  },
  {
    "title": "Breakpoints and breakpoint detection in source-level emulation",
    "doi": "https://doi.org/10.1145/290833.290843",
    "publication_date": "1998-04-01",
    "publication_year": 1998,
    "authors": "Gernot Koch; Wolfgang Rosenstiel; U. Kebschull",
    "corresponding_authors": "",
    "abstract": "We present an approach for accelerating the validation speed of behavioral system descriptions through hardware emulation. The method allows source-level debuggingof running hardware specified in behavioral VH DL in a way similar to sorce-leve debugging in software programing languages. We discuss breakpoints in source-level emulation and how the circuit generated by high-level synthesis has to be modified to work with breakpoints. Breakpoint encoding and detection are shown in detail. Our approach allows breakpoint detection by hardware with seriously slowing the circuit or dramitically increasing its size.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W1973912520",
    "type": "article"
  },
  {
    "title": "A performance-driven IC/MCM placement algorithm featuring explicit design space exploration",
    "doi": "https://doi.org/10.1145/250243.250250",
    "publication_date": "1997-01-01",
    "publication_year": 1997,
    "authors": "H. Esbensen; E.S. Kuh",
    "corresponding_authors": "",
    "abstract": "A genetic algorithm for building-block placement of ICs and MCMs is presented that simultaneously minimizes layout area and an Elmore-based estimate of the maximum path delay while trying to meet a target aspect ratio. Explicit design space exploration is performed by using a vector-valued, 3-dimensional cost function and searching for a set of distinct solutions representing the best trade-offs of the cost dimensions. From the output solutions, the designer can choose the solution with the preferred trade-off. In contrast to existing approaches, the required properties of the output solutions are specified without using weights or bounds. Consequently, the practical problems of specifying these quantities are eliminated. Promising experimental results are obtained for various placement problems, including a real-world design. Solution sets representing good, balanced cost trade-offs are found using a reasonable amount of runtime. Furthermore, the performance is shown to be comparable to that of simulated annealing in the special case of 1-dimensional optimization, in which direct comparison is possible.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W1974344272",
    "type": "article"
  },
  {
    "title": "Structural diagnosis of interconnects by coloring",
    "doi": "https://doi.org/10.1145/290833.290848",
    "publication_date": "1998-04-01",
    "publication_year": 1998,
    "authors": "Xingyu Chen; F.J. Meyer; Fabrizio Lombardi",
    "corresponding_authors": "",
    "abstract": "This paper presents a new approach for diagnosing shorts in interconnects in which the adjacencies between nets are known. This structural approach exploits different graph coloring techniques to generate a test set with no aliasing and confounding, i.e., full diagnosis (detection and location) is accomplished. Initially, a simple coloring approach based on a greedy condition of the adjacency graph is proposed for fault detection. Then, the conditions for aliasing and confounding are analyzed with respect to the sizes of the possible shorts. These results are used to generate new colors using a process called color mixing. Color mixing guarantees that additional tests, required in order to avoid aliasing/confounding, will use appropriate codes. The characteristics of unbalanced/balanced codes for encoding the colors in the vector-generation process of interconnect diagnosis are discussed and are proved to yield full diagnosis using a novel method. An algorithm for full diagnosis is then presented; this algorithm has an execution complexity of O ( max { N 2 , N × D 3 }) where N is the number of nets and D is the maximum degree of the nodes in the adjacency graph. Simulation results show that the proposed approach requires a smaller number of test vectors than previous approaches.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2022153663",
    "type": "article"
  },
  {
    "title": "A functionality-directed clustering technique for low-power MTCMOS design—computation of simultaneously discharging current",
    "doi": "https://doi.org/10.1145/1255456.1255467",
    "publication_date": "2007-08-17",
    "publication_year": 2007,
    "authors": "Ang-Chih Hsieh; Tzu-Teng Lin; Tsuang-Wei Chang; TingTing Hwang",
    "corresponding_authors": "",
    "abstract": "Multithreshold CMOS (MTCMOS) is a circuit style that can effectively reduce leakage power consumption. Sleep transistor sizing is the key issue when a MTCMOS circuit is designed. If the size of sleep transistor is large enough, the circuit performance can surely be maintained but the area and dynamic power consumption of the sleep transistor may increase. On the other hand, if the sleep transistor size is too small, there will be significant performance degradation because of the increased resistance to ground. Previous approaches [Kao et al. 1998; Anis et al. 2002] to designing sleep transistor size are based mainly on mutually-exclusive discharge patterns. However, these approaches considered only the topology of a circuit (i.e., interconnections of nodes in the circuit-graph saving the functionality of node). We observed that any two possible simultaneously switching gates may not discharge at the same time in terms of functionality. Thus, we propose an algorithm to determine how to cluster cells to share sleep transistors, while taking both topology and functionality into consideration. Moreover, one placement refinement algorithm that takes clustering information into account will be presented. At the logic level, the results show that the proposed clustering method can achieve an average of 22% reduction in terms of the number of unit-size sleep transistors as compared to a method that does not consider functionality. At the physical level, two placement results are discussed. The first is produced by a traditional placement tool plus topology check (functionality check) for insertion of sleep transistors. It shows that the functionality check algorithm produces 9% less chip area as compared with the topology check algorithm. The second result is produced by a placement refinement algorithm where the initial placement is done in the first placement experiment. It shows that the placement refinement algorithm achieves 5% more reduction in area at the expense of 4% increase in wire length. Totally, around 14% reduction is achieved by utilizing the clustering information.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W1969841268",
    "type": "article"
  },
  {
    "title": "The exact channel density and compound design for generic universal switch blocks",
    "doi": "https://doi.org/10.1145/1230800.1230811",
    "publication_date": "2007-04-01",
    "publication_year": 2007,
    "authors": "Hongbing Fan; Jiping Liu; Yu‐Liang Wu; Ray C. C. Cheung",
    "corresponding_authors": "",
    "abstract": "A switch block of k sides W terminals on each side is said to be universal (a ( k , W )-USB) if it is routable for every set of 2-pin nets of channel density at most W . The generic optimum universal switch block design problem is to design a ( k , W )-USB with the minimum number of switches for every pair of ( k , W ). This problem was first proposed and solved for k =4 in Chang et al. [1996], and then solved for even W or for k ≤6 in Shuy et al. [2000] and Fan et al. [2002b]. No optimum ( k , W )-USB is known for k ≥7 and odd W ≥3. But it is already known that when W is a large odd number, a near-optimum ( k , W )-USB can be obtained by a disjoint union of ( W − f 2 ( k ))/2 copies of the optimum ( k , 2)-USB and a noncompound ( k , f 2 ( k ))-USB, where the value of f 2 ( k ) is unknown for k ≥8. In this article, we show that f 2 ( k ) = k +3− i /3, where 1≤ i ≤6 and i ≡ k (mod 6), and present an explicit design for the noncompound ( k , f 2 ( k ))-USB. Combining these two results we obtain the exact designs of ( k , W )-USBs for all k ≥7 and odd W ≥3. The new ( k , W )-USB designs also yield an efficient detailed routing algorithm.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W1972041243",
    "type": "article"
  },
  {
    "title": "Methodology for operation shuffling and L0 cluster generation for low energy heterogeneous VLIW processors",
    "doi": "https://doi.org/10.1145/1278349.1278354",
    "publication_date": "2007-09-01",
    "publication_year": 2007,
    "authors": "Y. Kobayashi; Murali Jayapala; Praveen Raghavan; Francky Catthoor; Masaharu Imai",
    "corresponding_authors": "",
    "abstract": "Clustering L0 buffers is effective for energy reduction in the instruction memory hierarchy of embedded VLIW processors. However, the efficiency of the clustering depends on the schedule of the target application. Especially in heterogeneous or data clustered VLIW processors, determining energy efficient scheduling is more constraining. This article proposes a realistic technique supported by a tool flow to explore operation shuffling for improving generation of L0 clusters. The tool flow explores assignment of operations for each cycle and generates various schedules. This approach makes it possible to reduce energy consumption for various processor architectures. However, the computational complexity is large because of the huge exploration space. Therefore, some heuristics are also developed, which reduce the size of the exploration space while the solution quality remains reasonable. Furthermore, we also propose a technique to support VLIW processors with multiple data clusters, which is essential to apply the methodology to real world processors. The experimental results indicate potential gains of up to 27.6% in energy in L0 buffers, through operation shuffling for heterogeneous processor architectures as well as a homogeneous architecture. Furthermore, the proposed heuristics drastically reduce the exploration search space by about 90%, while the results are comparable to full search, with average differences of less than 1%. The experimental results indicate that energy efficiency can be improved in most of the media benchmarks by the proposed methodology, where the average gain is around 10% in comparison with generating clusters without operation shuffling.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W1979965005",
    "type": "article"
  },
  {
    "title": "Clock skew scheduling with race conditions considered",
    "doi": "https://doi.org/10.1145/1278349.1278358",
    "publication_date": "2007-09-01",
    "publication_year": 2007,
    "authors": "Shih-Hsu Huang; Yow-Tyng Nieh",
    "corresponding_authors": "",
    "abstract": "In this article, we provide a fresh viewpoint to the interactions between clock skew scheduling and delay insertion. A race-condition-aware (RCA) clock skew scheduling is proposed to determine the clock skew schedule by taking race conditions (i.e., hold violations) into account. Our objective is not only to optimize the clock period, but also to minimize heuristically the required inserted delay. Compared with previous work, our major contribution includes the following two aspects. First, our approach achieves exactly the same results, but has significant improvement in time complexity. Second, our viewpoint can be generalized to other sequential timing optimization techniques.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2037994569",
    "type": "article"
  },
  {
    "title": "Area reduction by deadspace utilization on interconnect optimized floorplan",
    "doi": "https://doi.org/10.1145/1188275.1188278",
    "publication_date": "2007-01-01",
    "publication_year": 2007,
    "authors": "Chiu‐Wing Sham; Evangeline F. Y. Young",
    "corresponding_authors": "",
    "abstract": "Interconnect optimization has become the major concern in floorplanning. Many approaches would use simulated annealing (SA) with a cost function composed of a weighted sum of area, wirelength, and interconnect cost. These approaches can reduce the interconnect cost efficiently but the area penalty of the interconnect optimized floorplan is usually quite large. In this article, we propose an approach called deadspace utilization (DSU) to reclaim the unused area of an interconnect optimized floorplan by linear programming. Since modules are not necessarily rectangular in shape in floorplanning, some deadspace can be redistributed to the modules to increase the area occupied by each module. If the area of each module can be expanded by the same ratio, the whole floorplan can be compacted by that ratio to give a smaller floorplan. However, we will limit the compaction ratio to prevent overcongestion. Experiments show that we can apply this deadspace utilization technique to reduce the area and total wirelength of an interconnect optimized floorplan further while the routability can be maintained at the same time.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2075084427",
    "type": "article"
  },
  {
    "title": "An Optimized Cost Flow Algorithm to Spread Cells in Detailed Placement",
    "doi": "https://doi.org/10.1145/3317575",
    "publication_date": "2019-04-02",
    "publication_year": 2019,
    "authors": "Jucemar Monteiro; Marcelo Johann; Laleh Behjat",
    "corresponding_authors": "",
    "abstract": "Placement is an important and challenging step in VLSI physical design. The placement solution can significantly impact timing and routability. In sub-nanometric technology nodes, several restrictions have been imposed on the placement solutions. These restrictions make designing an optimized and legal solution very hard. Achieving optimized placement solutions is especially challenging in regions with high-density utilization. The quality of placement solution can significantly impact the final circuit implementation. In this work, we present a cell spreading algorithm to move cells out from high-density utilization regions. Our algorithm opens up new spaces in regions with high cell concentration. These spaces can then be exploited by detailed placement algorithms to further optimize the placement solution. The objective of our technique is to reduce area density utilization while considering cell displacement and circuit delay. The outcome of the proposed algorithm is to obtain a uniform distribution of cells in the placement area while having minimal effects on the delay. To achieve this goal, our proposed algorithm uses branch and cut, and network flow techniques. Experimental results on industrial and academic circuits illustrate that our proposed algorithm can minimize circuit delay (up to 25%), cell displacement (up to 17μ m ), dynamic power consumption (up to 5.3%), and leakage power (up to 15%).",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2925797319",
    "type": "article"
  },
  {
    "title": "Augmenting Operating Systems with OpenCL Accelerators",
    "doi": "https://doi.org/10.1145/3315569",
    "publication_date": "2019-03-28",
    "publication_year": 2019,
    "authors": "Chia-Heng Tu; Te-Sheng Lin",
    "corresponding_authors": "",
    "abstract": "Heterogeneous computing leverages more than one kind of processors to boost the performance of user-space applications with the heterogeneous programming languages, e.g., OpenCL. While some works have been done to accelerate the computations required by Linux kernel software, they are either application-specific solutions or tightly coupled with the certain computing platforms and are not able to support the general-purpose in-kernel accelerations using different types of processors. In this article, the general-purpose software framework called Kernel acceleration with OpenCL (KOCL), is proposed to tackle the problem. KOCL exposes a set of the high-level programming interfaces for the Linux kernel module developers to offload compute-intensive tasks on different hardware accelerators without managing and coordinating the platform-specific computing and memory resources. The simplified programming efforts are achieved by the developed platform management and memory models, which provide a systematic means of managing the heterogeneous hardware resources. In addition, the one- and zero-copy data-buffering schemes are offered by KOCL, so that the offloaded tasks deliver high performance on the platforms with different memory architectures. We have developed the prototype system to accelerate the Network-Attached Storage server applications. Significant performance improvements are achieved with the three different types of accelerators, i.e., the multicore processor, the integrated GPU, and the discrete GPU, respectively. We believe that KOCL is useful for the design of embedded appliances to evaluate the performance of design alternatives.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2933270146",
    "type": "article"
  },
  {
    "title": "Analysis of Dissipative Losses in Modular Reconfigurable Energy Storage Systems Using SystemC TLM and SystemC-AMS",
    "doi": "https://doi.org/10.1145/3321387",
    "publication_date": "2019-05-09",
    "publication_year": 2019,
    "authors": "T. Zimmermann; Mathias Mora; Sebastian Steinhorst; Daniel Mueller-Gritschneder; Andreas Jossen",
    "corresponding_authors": "",
    "abstract": "Battery storage systems are becoming more popular in the automotive industry as well as in stationary applications. To fulfill the requirements in terms of power and energy, the literature is increasingly discussing electrically reconfigurable interconnection topologies. However, these topologies use switching elements on the cell and module level that exhibit an electric resistance due to their design and hence generate undesirable dissipative losses. In this article, we propose a new analysis and optimization framework to examine and minimize the losses in such topologies. For this purpose, we develop a SystemC model to investigate static and dynamic load scenarios, e.g., from the automotive domain. The model uses SystemC TLM for the digital subsystem, SystemC-AMS for the mixed-signal subsystem, and host-compiled simulation for the microcontroller executing the embedded software. Here, we analyze the impact of the dissipative losses on the system efficiency that depend on the modularization level, implying the number of serial and parallel switching elements. Our analysis clearly shows that in reconfigurable topologies, the modularization level has a significant influence on the losses, which in our automotive example covers several orders of magnitude. For the topologies we have investigated, the highest efficiency can be reached when a parallel-only modularization is aspired and the number of serial switching elements is minimized. It is also shown that the losses of the state-of-the-art topology with one battery pack protection switch are almost as high as in a smart cell approach in which each energy storage cell has its own switching element. However, due to the high number of switching elements, this results in a reduction of energy density and increases the system costs, showing that this is a multi-criteria optimization problem.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2943849606",
    "type": "article"
  },
  {
    "title": "Layout Resynthesis by Applying Design-for-manufacturability Guidelines to Avoid Low-coverage Areas of a Cell-based Design",
    "doi": "https://doi.org/10.1145/3325066",
    "publication_date": "2019-05-29",
    "publication_year": 2019,
    "authors": "Nai‐Xing Wang; Irith Pomeranz; S.M. Reddy; Arani Sinha; Srikanth Venkataraman",
    "corresponding_authors": "",
    "abstract": "Design-for-manufacturability (DFM) guidelines are recommended layout design practices intended to capture layout features that are difficult to manufacture correctly. Avoiding such features prevents the occurrence of potential systematic defects. Layout features that result in DFM guideline violations may not be avoided completely due to the design constraints of chip area, performance, and power consumption. A framework for translating DFM guideline violations into potential systematic defects, and faults, was described earlier. In a cell-based design, the translated faults may be internal or external to cells. In this article, we focus on undetectable faults that are external to cells. Using a resynthesis procedure that makes fine changes to the layout while maintaining the design constraints, we target areas of the design where large numbers of external faults related to DFM guideline violations are undetectable. By eliminating the corresponding DFM guideline violations, we ensure that the circuit does not suffer from low-coverage areas that may result in detectable systematic defects escaping detection, but failing the circuit in the field. The layout resynthesis procedure is applied to benchmark circuits and logic blocks of the OpenSPARC T1 microprocessor. Experimental results indicate that the improvement in the coverage of potential systematic defects is significant.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2947292684",
    "type": "article"
  },
  {
    "title": "Approximate Data Reuse-based Accelerator Design for Embedded Processor",
    "doi": "https://doi.org/10.1145/3342098",
    "publication_date": "2019-08-21",
    "publication_year": 2019,
    "authors": "Hisashi Osawa; Yuko Hara–Azumi",
    "corresponding_authors": "",
    "abstract": "Due to increasing diversity and complexity of applications in embedded systems, accelerator designs trading-off area/energy-efficiency and design-productivity are becoming a further crucial issue. Targeting applications in the category of Recognition, Mining, and Synthesis (RMS), this study proposes a novel accelerator design to achieve a good trade-off in efficiency and design-productivity (or reusability) by introducing a new computing paradigm called “approximate computing” (AC). Leveraging from the facts that frequently executed parts of applications (i.e., hotspots) are conventionally the target of acceleration and that RMS applications are error-tolerant and often take similar input data repeatedly, our proposed accelerator reuses previous computational results of similar enough data to reduce computations. The proposed accelerator is composed of a simple controller and a dedicated memory to store limited sets of previous input data with corresponding computational results in a hotspot. Therefore, this accelerator can be applied to different and/or multiple hotspots/applications only through small extension of the controller, to achieve efficient accelerator design and resolve the design-productivity issue. We conducted quantitative evaluations using a representative RMS application (image compression) to demonstrate the effectiveness of our method over conventional ones with precise computing. Moreover, we provide important findings on parameter exploration for our accelerator design, offering a wider applicability of our accelerator to other applications.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2969555579",
    "type": "article"
  },
  {
    "title": "Analog/RF Post-silicon Tuning via Bayesian Optimization",
    "doi": "https://doi.org/10.1145/3365577",
    "publication_date": "2019-11-25",
    "publication_year": 2019,
    "authors": "Renjian Pan; Jun Tao; Yangfeng Su; Dian Zhou; Xuan Zeng; Xin Li",
    "corresponding_authors": "",
    "abstract": "Tunable analog/RF circuit has emerged as a promising technique to address the significant performance uncertainties caused by process variations. To optimize these tunable circuits after fabrication, most existing post-silicon programming methods are developed by using real-valued performance metrics. However, when measuring a performance of interest on silicon, it is often substantially more expensive to obtain a real-valued measurement than a binary testing outcome (i.e., pass or fail). In this article, we propose a Gaussian Process Classification model to capture the binary performance metrics of tunable analog/RF circuits. Based on these models, post-silicon programming is cast into an optimization problem that can be solved by a novel Bayesian optimization algorithm. Moreover, measurement noises are further incorporated into our proposed post-silicon programming to produce a robust circuit. Two circuit examples demonstrate that the proposed approach can efficiently program tunable circuits with binary performance metrics while other conventional methods are not applicable.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2989830252",
    "type": "article"
  },
  {
    "title": "Single-Layer Obstacle-Aware Substrate Routing via Iterative Pin Reassignment and Wire Assignment",
    "doi": "https://doi.org/10.1145/3378162",
    "publication_date": "2020-02-06",
    "publication_year": 2020,
    "authors": "Jin-Tai Yan",
    "corresponding_authors": "Jin-Tai Yan",
    "abstract": "It is known that single-layer obstacle-aware substrate routing is necessary for modern IC/Package designs. In this article, given a set of two-pin nets and a set of rectangular obstacles inside a single-layer routing plane, a two-phase routing algorithm including an iterative routing phase and a rip-up-and-reroute phase can be proposed to maximize the number of the routed nets in single-layer obstacle-aware substrate routing. In the iterative routing phase, based on the pin and path distribution of the routing nets and the locations of the obstacles inside a single-layer routing plane, the start or target pins on some routing nets inside dense obstacle regions may be firstly reassigned to complete the partial wiring paths on the nets. Based on the region extraction of two intersected nets in single-layer routing, the private regions of some routing nets inside sparse obstacle regions can be extracted and the nets inside the extracted regions can be further routed by using maze routing. In the rip-up-and-reroute phase, the routability of the routing nets can be improved by ripping up some routed nets and rerouting the unrouted nets. Compared with Liu's modified algorithm and Yan's flow-based algorithm in single-layer obstacle-aware substrate routing, the experimental results show that the proposed algorithm can use less CPU time to increase 3.4% and 1.8% of the routability on the routing nets for eight tested examples on the average. Additionally, the percentage of the tested examples with the 100% routability of the routing nets on the eight tested examples has been improved from 25% to 62.5%.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W3015651936",
    "type": "article"
  },
  {
    "title": "A Theoretical Foundation for Timing Synchronous Systems Using Asynchronous Structures",
    "doi": "https://doi.org/10.1145/3373355",
    "publication_date": "2020-02-03",
    "publication_year": 2020,
    "authors": "Ramy N. Tadros; Peter A. Beerel",
    "corresponding_authors": "",
    "abstract": "Timing of synchronous systems is an everlasting stumbling block to the booming demands for lower power consumption and higher operation speeds in the electronics industry. This hardship is aggravated by the growing levels of variability in state-of-the-art silicon dimensions and in other beyond-CMOS technologies. Although some designers continue to strongly believe in the performance advantages of being fully synchronous, others have radically shifted toward extremely robust delay-insensitive domains. Targeting a different compromise of both performance and robustness, this article provides sufficient conditions for an asynchronous system to be able to generate the periodic signals necessary for the timing of a fully synchronous system and highlights a specific hierarchical clocking structure that with a single tunable delay satisfies these conditions. Using an asynchronous clock distribution network benefits from both the natural robustness of asynchronous structures and the advantageous performance of synchronous clocking.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W3023678816",
    "type": "article"
  },
  {
    "title": "Soft-HaT",
    "doi": "https://doi.org/10.1145/3396521",
    "publication_date": "2020-06-23",
    "publication_year": 2020,
    "authors": "Md Mahbub Alam; Adib Nahiyan; Mehdi Sadi; Domenic Forte; Mark Tehranipoor",
    "corresponding_authors": "",
    "abstract": "A hardware Trojan is a malicious modification to an integrated circuit (IC) made by untrusted third-party vendors, fabrication facilities, or rogue designers. Although existing hardware Trojans are designed to be stealthy, they can, in theory, be detected by post-manufacturing and acceptance tests due to their physical connections to IC logic. Manufacturing tests can potentially trigger the Trojan and propagate its payload to an output. Even if the Trojan is not triggered, the physical connections to the IC can enable detection due to additional side-channel activity (e.g., power consumption). In this article, we propose a novel hardware Trojan design, called Soft-HaT , which only becomes physically connected to other IC logic after activation by a software program. Using an electrically programmable fuse (E-fuse), the hardware can be “re-programmed” remotely. We illustrate how Soft-HaT can be used for offensive applications in system-on-chips. Examples of Soft-HaT attacks are demonstrated on an open source system-on-chip (OrpSoC) and implemented in Virtex-7 FPGA to show their efficacy in terms of stealthiness.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W3038103856",
    "type": "article"
  },
  {
    "title": "A Locality Optimizer for Loop-dominated Applications Based on Reuse Distance Analysis",
    "doi": "https://doi.org/10.1145/3398189",
    "publication_date": "2020-07-07",
    "publication_year": 2020,
    "authors": "Christakis Lezos; Grigoris Dimitroulakos; Ioannis Latifis; Κωνσταντίνος Μασσέλος",
    "corresponding_authors": "",
    "abstract": "Source code optimization can heavily improve software code implementation quality while still being complementary to conventional compilers’ optimizations. Source code analysis tools are very useful in supporting source code optimization. This article discusses MemAssist, a source-level optimization environment for semi-automatic locality optimization of loop-dominated code. MemAssist applies reuse distance analysis and a relevant optimization algorithm to explore the design space. It generates a set of suggestions for locality optimizing loop transformations that reduce data cache miss rate and execution time. MemAssist has been used to optimize a number of applications. Experimental results show that MemAssist leads to cache miss rate reduction at all cache layers, memory accesses reduction by up to 42%, and to a speedup of up to three times. Therefore, MemAssist can be used for efficient early-stage software optimization leading to development effort and time reduction.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W3041392772",
    "type": "article"
  },
  {
    "title": "FaultDroid",
    "doi": "https://doi.org/10.1145/3410336",
    "publication_date": "2020-09-01",
    "publication_year": 2020,
    "authors": "Indrani Roy; Chester Rebeiro; Aritra Hazra; Swarup Bhunia",
    "corresponding_authors": "",
    "abstract": "Fault attacks belong to a potent class of implementation-based attacks that can compromise a crypto-device within a few milliseconds. Out of the large numbers of faults that can occur in the device, only a very few are exploitable in terms of leaking the secret key. Ignorance of this fact has resulted in countermeasures that have either significant overhead or inadequate protection. This article presents a framework, referred to as FaultDroid, for automated vulnerability analysis of fault attacks. It explores the entire fault attack space, identifies the single/multiple fault scenarios that can be exploited by a differential fault attack, rank-orders them in terms of criticality, and provides design guidance to mitigate the vulnerabilities at low cost. The framework enables a designer to automatically evaluate the fault attack vulnerabilities of a block cipher implementation and then incorporate efficient countermeasures. FaultDroid uses a formal model of fault attacks on a high-level specification of a block cipher and hence is equally applicable to both software and hardware implementation of the cipher. As case studies, we employ FaultDroid to comprehensively evaluate the fault scenarios in several common ciphers—AES, CLEFIA, CAMELLIA, SMS4, SIMON, PRESENT, and GIFT—and assess their vulnerability.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W3081566533",
    "type": "article"
  },
  {
    "title": "SmartDR",
    "doi": "https://doi.org/10.1145/3417133",
    "publication_date": "2020-10-23",
    "publication_year": 2020,
    "authors": "Stèphano M. M. Gonçalves; Leomar S. da Rosa; Felipe Marques",
    "corresponding_authors": "",
    "abstract": "Detailed routing is one of the most time-consuming steps of physical synthesis of integrated circuits. Also, it is very challenging due to the complexity of the design rules that the router must obey. In this article, we present SmartDR, a detailed routing system that focuses on good design rule handling and fast runtime. To attend these objectives, we propose a novel pin access approach and a fast design rule aware A*-interval-based path search algorithm. The pin access method uses resource sharing ghost pin access paths with dynamic legalization check. We also propose a design rule check algorithm to detect thick metal shapes that are widely created using the proposed pin access method. The path search algorithm integrates design rule check on its core, handling many design rules that would not be possible to be solved by postprocessing. It is aware of the minimum area rule, the cut spacing of via cuts within the same path, and the via library. We also present a new technique to improve A*-based path search in detailed routing. The technique makes the path search algorithm aware of the global routing guides, accelerating the search. Using ISPD 2018 Contest benchmarks, our experiments show that our router is superior to the state-of-the-art routers that were also tested using the same benchmarks. Our router has presented, on average, 77.6% less runtime, 73.5% less design rule violations, with respect to Dr. CU 2.0, which is the better of the compared routers.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W3094293902",
    "type": "article"
  },
  {
    "title": "HeM3D: Heterogeneous Manycore Architecture Based on Monolithic 3D Vertical Integration.",
    "doi": null,
    "publication_date": "2020-01-01",
    "publication_year": 2020,
    "authors": "Aqeeb Iqbal Arka; Biresh Kumar Joardar; Ryan Kim; Dae Hyun Kim; Janardhan Rao Doppa; Partha Pratim Pande",
    "corresponding_authors": "",
    "abstract": "Heterogeneous manycore architectures are the key to efficiently execute compute- and data-intensive applications. Through silicon via (TSV)-based 3D manycore system is a promising solution in this direction as it enables integration of disparate computing cores on a single system. However, the achievable performance of conventional through-silicon-via (TSV)-based 3D systems is ultimately bottlenecked by the horizontal wires (wires in each planar die). Moreover, current TSV 3D architectures suffer from thermal limitations. Hence, TSV-based architectures do not realize the full potential of 3D integration. Monolithic 3D (M3D) integration, a breakthrough technology to achieve - More Moore and More Than Moore - and opens up the possibility of designing cores and associated network routers using multiple layers by utilizing monolithic inter-tier vias (MIVs) and hence, reducing the effective wire length. Compared to TSV-based 3D ICs, M3D offers the true benefits of vertical dimension for system integration: the size of a MIV used in M3D is over 100x smaller than a TSV. In this work, we demonstrate how M3D-enabled vertical core and uncore elements offer significant performance and thermal improvements in manycore heterogeneous architectures compared to its TSV-based counterpart. To overcome the difficult optimization challenges due to the large design space and complex interactions among the heterogeneous components (CPU, GPU, Last Level Cache, etc.) in an M3D-based manycore chip, we leverage novel design-space exploration algorithms to trade-off different objectives. The proposed M3D-enabled heterogeneous architecture, called HeM3D, outperforms its state-of-the-art TSV-equivalent counterpart by up to 18.3% in execution time while being up to 19 degrees Celcius cooler.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W3133147379",
    "type": "article"
  },
  {
    "title": "Fault Localization Scheme for Missing Gate Faults in Reversible Circuits",
    "doi": "https://doi.org/10.1145/3503539",
    "publication_date": "2022-03-08",
    "publication_year": 2022,
    "authors": "Mousum Handique; Jantindra Kumar Deka; Santosh Biswas",
    "corresponding_authors": "",
    "abstract": "This article introduces a fault localization method to extract the exact location of single and multiple missing gate faults in reversible \\( k \\) -CNOT -based circuits. The primary target of the proposed method is to obtain the complete test set for localizing faults in \\( k \\) -CNOT circuits. We propose a fault localization algorithm to construct a fault localization tree that can be used to find equivalent and non-equivalent faults. For the non-equivalent faults, the test sequences can be obtained from the fault localization tree that uniquely localizes the non-equivalent faults. Finally, this article presents the experimental results and comparative analysis with existing works.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4221035946",
    "type": "article"
  },
  {
    "title": "Memory-aware Partitioning, Scheduling, and Floorplanning for Partially Dynamically Reconfigurable Systems",
    "doi": "https://doi.org/10.1145/3534968",
    "publication_date": "2022-05-23",
    "publication_year": 2022,
    "authors": "Bo Ding; Jinglei Huang; Qi Xu; Junpeng Wang; Song Chen; Yi Kang",
    "corresponding_authors": "",
    "abstract": "Partially dynamic reconfiguration (PDR) technology can accelerate the reconfiguration process and overcome hardware resource constraints when facing the challenge of high performance with respect to applications and resources constraints on field-programmable gate arrays (FPGAs). On FPGAs with PDR technology, the available on-chip Block RAM (BRAM) resources may not satisfy the memory requirements for all data. If we reserve more BRAM resources, then the total area of the dynamically reconfigurable region (DRR) that is used for calculation will decrease, with a reduction in system performance. We propose a memory-aware optimization framework to search for the optimal solution considering partitioning, scheduling, and floorplanning, where we make a tradeoff between performance and on-chip memory resources utilization. We then propose methods for memory allocation: An ILP model and a heuristic algorithm are provided to determine the minimum memory requirements and the number of corresponding memory blocks for data, as well as to determine whether the memory block with its stored data is assigned on-chip or off-chip by formulating the problem into a 0-1 knapsack problem and solving it using dynamic programming. Experimental results show that the memory-aware optimization framework and methods of memory allocation can increase the amount of on-chip data access to 29.65% of the total data volume with guaranteed performance.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4281288286",
    "type": "article"
  },
  {
    "title": "A Low-Overhead and High-Security Cryptographic Circuit Design Utilizing the TIGFET-Based Three-Phase Single-Rail Pulse Register against Side-Channel Attacks",
    "doi": "https://doi.org/10.1145/3498339",
    "publication_date": "2022-05-24",
    "publication_year": 2022,
    "authors": "Yanjiang Liu; Tongzhou Qu; Zibin Dai",
    "corresponding_authors": "",
    "abstract": "Side-channel attack (SCA) reveals confidential information by statistically analyzing physical manifestations, which is the serious threat to cryptographic circuits. Various SCA circuit-level countermeasures have been proposed as fundamental solutions to reduce the side-channel vulnerabilities of cryptographic implementations; however, such approaches introduce non-negligible power and area overheads. Among all of the circuit components, flip-flops are the main source of information leakage. This article proposes a three-phase single-rail pulse register (TSPR) based on the three-independent-gate field effect transistor (TIGFET) to achieve all desired properties with improved metrics of area and security. TIGFET-based TSPR consumes a constant power (MCV is 0.25%), has a low delay (12 ps), and employs only 10 TIGFET devices, which is applicable for the low-overhead and high-security cryptographic circuit design compared to the existing flip-flops. In addition, a set of TIGFET-based combinational basic gates are designed to reduce the area occupation and power consumption as much as possible. As a proof of concept, a simplified advanced encryption algorithm (AES), SM4 block cipher algorithm (SM4), and light-weight cryptographic algorithm (PRESENT) are built with the TIGFET-based library. SCA is implemented on the cryptographic implementations to prove its SCA resilience, and the SCA results show that the correct key of cryptographic circuits with TIGFET-based TSPRs is not guessed within 2,000 power traces.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4281477238",
    "type": "article"
  },
  {
    "title": "AIMCU-MESO: An In-Memory Computing Unit Constructed by MESO Device",
    "doi": "https://doi.org/10.1145/3539575",
    "publication_date": "2022-05-26",
    "publication_year": 2022,
    "authors": "Junwei Zeng; Nuo Xu; Yabo Chen; Chenglong Huang; Zhiwei Li; Liang Fang",
    "corresponding_authors": "",
    "abstract": "Traditional CMOS-based von-Neumann computer architecture faces the issue of memory wall that the limitation of bus-bandwidth and the speed mismatch between processor and memory restrict the efficiency of data processing along with an irreducible energy consumption conducted by data movement, especially in some data-intensive applications. Recently, some novel in-memory computing (IMC) paradigms developed by utilizing the characteristics of different non-volatile memories provide promising ways to overcome the bottleneck of memory wall. Here, we propose a new IMC unit based on a memory array with the core element of magnetoelectric spin-orbit logic (MESO) device (AIMCU-MESO), in which the characteristics of the MESO device are exploited to achieve several in-memory logic operations with the functions of NAND, NOR, and XOR in the MESO-based memory array. With the aid of some transistor-based switches, these logic operations can be achieved between any two MESOs in the array. Furthermore, the computing process of a 1-bit full adder (FA) is achieved in AIMCU-MESO by the in-memory logic manner to demonstrate the ability of logic cascading. The result of SPICE simulation for achieving the 1-bit FA using MESO devices is demonstrated, and the performances are compared with other designs of spintronics-based devices. Compared to multilevel voltage-controlled spin-orbit torque–based magnetic memory, the proposed design demonstrates 71.4% and 49.2% reductions in terms of storage delay and logic delay, respectively.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4281557968",
    "type": "article"
  },
  {
    "title": "Performance-driven Wire Sizing for Analog Integrated Circuits",
    "doi": "https://doi.org/10.1145/3559542",
    "publication_date": "2022-08-26",
    "publication_year": 2022,
    "authors": "Yaguang Li; Yishuang Lin; Meghna Madhusudan; Arvind Sharma; Sachin S. Sapatnekar; Ramesh Harjani; Jiang Hu",
    "corresponding_authors": "",
    "abstract": "Analog IC performance has a strong dependence on interconnect RC parasitics, which are significantly affected by wire sizes in recent technologies, where minimum-width wires have high resistance. However, performance-driven wire sizing for analog ICs has received very little research attention. In order to fill this void, we develop several techniques to facilitate an end-to-end automatic wire sizing approach. They include a circuit performance model based on customized graph neural network (GNN) and two optimization techniques: one using Bayesian optimization accelerated by the GNN model, and the other based on TensorFlow training. Experimental results show that our technique can achieve 11% circuit performance improvement or 8.7× speedup compared to a conventional Bayesian optimization method.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4293182229",
    "type": "article"
  },
  {
    "title": "Machine Learning Assisted Circuit Sizing Approach for Low-Voltage Analog Circuits with Efficient Variation-Aware Optimization",
    "doi": "https://doi.org/10.1145/3567422",
    "publication_date": "2022-10-13",
    "publication_year": 2022,
    "authors": "Ling-Yen Song; Chih-Yun Chou; Tung-Chieh Kuo; Chien‐Nan Jimmy Liu; Juinn-Dar Huang",
    "corresponding_authors": "",
    "abstract": "Low-power analog design is a hot topic for various power efficient applications. Sizing low-power analog circuits is not easy because the increasing uncertainties from low-voltage techniques magnify process variation effects on the design yield. Simulation-based approaches are often adopted for analog circuit sizing because of its high accuracy and adaptability in different cases. However, if process variation is also considered, the huge number of simulations becomes almost infeasible for large circuits. Although there are some recent works that adopt machine learning (ML) techniques to speed up the optimization process, the process variation effects are still hard to be considered in those approaches. Using the popular evolutionary algorithm (EA) as an example, this paper proposes an ML-assisted prediction model to speed up the variation-aware circuit sizing technique for low-voltage analog circuits. By predicting the likelihood for a design that has worse performance, the enhanced EA process is able to skip many unnecessary simulations to reduce the convergence time. Moreover, a novel force-directed model is proposed to guide the optimization toward better yield. Based on the performance of prior circuit samples in the EA optimization, the proposed force model is able to predict the likelihood of a design that has better yield without time-consuming Monte Carlo simulations. Compared with prior works, the proposed approach significantly reduces the number of simulations in the yield-aware EA optimization, which helps to generate practical low-voltage designs with high reliability and low cost.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4304944806",
    "type": "article"
  },
  {
    "title": "IMPRoVED: Integrated Method to Predict PostRouting setup Violations in Early Design Stages",
    "doi": "https://doi.org/10.1145/3572546",
    "publication_date": "2022-11-29",
    "publication_year": 2022,
    "authors": "Suhas Krishna Kashyap; Sule Ozev",
    "corresponding_authors": "",
    "abstract": "The detail routing process is by far the most time consuming during the physical design flow. Routing starts with an estimation of timing slacks and aims to meet the timing specifications at signoff. In this paper, we propose an improved method to predict the net delays using RandomForestRegressor and thereby predict critical paths early on at the placement stage. Quick timing prediction is also essential in making time-sensitive edits to stepping of the chip based on post-Si feedback. The proposed algorithm is based on five novel features, namely, targeted feature selection, introduction of a one-hot encoding scheme, an outlier identification method, post-route buffer-bloat prediction, and post-route cell sizing prediction. Experimental results on academic benchmarks and industry circuits, both on advanced 10nm process node show that the proposed algorithm has led to significant improvements in accurately predicting timing slacks when compared with state of the art. The proposed algorithm predicts slack within 0.598% of signoff results, whereas the state of art results are erroneous by an average of 53.33% for the same metric. Overall time savings of 44.1% is seen when compared to running the traditional flow, and savings of 90% is seen for obtaining the timing results.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4310251154",
    "type": "article"
  },
  {
    "title": "CNNFlow: Memory-driven Data Flow Optimization for Convolutional Neural Networks",
    "doi": "https://doi.org/10.1145/3577017",
    "publication_date": "2022-12-19",
    "publication_year": 2022,
    "authors": "Qi Nie; Sharad Malik",
    "corresponding_authors": "",
    "abstract": "Convolution Neural Networks (CNNs) are widely deployed in computer vision applications. The datasets are large, and the data reuse across different parts is heavily interleaved. Given that memory access (SRAM and especially DRAM) is more expensive in both performance and energy than computation, maximizing data reuse to reduce data movement across the memory hierarchy is critical to improving execution efficiency. This is even more important for the common use case of CNNs on mobile devices where computing/memory resources are limited. We propose CNNFlow, a memory-driven dataflow optimization framework to automatically schedule CNN computation on a given CNN architecture to maximize data reuse at each level of the memory hierarchy. We provide a mathematical calculation for data reuses in terms of parameters including loop ordering, blocking, and memory-bank allocation for tensors in CNN. We then present a series of techniques that help prune the large search space and reduce the cost of the exploration. This provides, for the first time, an exact and practical search algorithm for optimal solutions to minimize memory access cost for CNN. The efficacy is demonstrated for two widely used CNN algorithms: AlexNet and VGG16 with 5 and 13 convolution layers, respectively. CNNFlow finds the optimal solution for each layer within tens of minutes of compute time. Its solution requires about 20% fewer DRAM accesses and 40%–80% fewer SRAM accesses compared to state-of-the-art algorithms in the literature.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4313408248",
    "type": "article"
  },
  {
    "title": "Design of Ultra-Low Power Scalable-Throughput Many-Core DSP Applications",
    "doi": "https://doi.org/10.1145/2720018",
    "publication_date": "2015-06-24",
    "publication_year": 2015,
    "authors": "Meeta Srivastav; Mohammed Ehteshamuddin; Kyle Stegner; Leyla Nazhandali",
    "corresponding_authors": "",
    "abstract": "We propose a system-level solution in designing process variation aware (PVA) scalable-throughput many-core systems for energy constrained applications. In our proposed methodology, we leverage the benefits of voltage scaling for obtaining energy efficiency while compensating for the loss in throughput by exploiting parallelism present in various DSP designs. We demonstrate that such a hybrid method consumes 6.27%- 28.15% less power as compared to simple dynamic voltage scaling over different workload environments. Design details of a prototype chip fabricated on 90 nm technology node and its findings are presented. Chip consists of 8 homogeneous FIR cores, which are capable of running from near-threshold to nominal voltages. In our 20 chip population, we observe 7% variation in speed among the cores at nominal voltage (0.9V) and 26% at near threshold voltage (0.55V). We also observe 54% variation in power consumption of the cores. For any desired throughput, the optimum number of cores and their optimum operating voltage is chosen based on the speed and power characteristics of the cores present inside the chip. We will also present analysis on energy-efficiency of such systems based on changes in ambient temperature.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W1189103277",
    "type": "article"
  },
  {
    "title": "Decoupling Capacitance Design Strategies for Power Delivery Networks with Power Gating",
    "doi": "https://doi.org/10.1145/2700825",
    "publication_date": "2015-06-24",
    "publication_year": 2015,
    "authors": "Tong Xu; Peng Li; Savithri Sundareswaran",
    "corresponding_authors": "",
    "abstract": "Power gating is a widely used leakage power saving strategy in modern chip designs. However, power gating introduces unique power integrity issues and trade-offs between switching and rush current (wake-up) supply noises. At the same time, the amount of power saving intrinsically trades off with power integrity. In addition, these trade-offs significantly vary with supply voltage. In this article, we propose systemic decoupling capacitors (decaps) optimization strategies that optimally trade-off between power integrity and leakage saving. Specially, new global decap and reroutable decap design concepts are proposed to relax the tight interaction between power integrity and leakage saving of power gated PDNs with a single supply voltage level. Furthermore, we propose a flexible decap allocation technique to deal with the design trade-offs under multiple supply voltage levels. The proposed strategies are implemented in an automatic design flow for choosing the optimal amount of local decaps, global decaps and reroutable decaps. The conducted experiments demonstrate that leakage saving can be increased significantly compared with the conventional PDN design approach with a single supply voltage level using the proposed techniques without jeopardizing power integrity. For PDN designs operating at two supply voltage levels, the optimal performance is achieved at each voltage level.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W1683469016",
    "type": "article"
  },
  {
    "title": "Implementation and Analysis of History-Based Output Channel Selection Strategies for Adaptive Routers in Mesh NoCs",
    "doi": "https://doi.org/10.1145/2647952",
    "publication_date": "2014-08-01",
    "publication_year": 2014,
    "authors": "John Jose; Madhu Mutyam",
    "corresponding_authors": "",
    "abstract": "The efficiency and effectiveness of an adaptive router in an NoC-based multicore system is evaluated by the performance it achieves under varying inter-core communication traffic. A well-designed selection strategy plays an important role in an adaptive router to act upon dynamic traffic variations. The effectiveness of a selection strategy depends on what metric is used to represent congestion, how precisely this metric captures the actual congestion, and how much cost is involved in capturing the congestion on a real-time scale. Congestion is formed over a period of time due to cumulative and chain reaction effects. We propose novel history-based selection strategies that could be used with any adaptive, deadlock-free, minimal routing in mesh NoCs. Buffer occupancy time and rate of flit flow across reachable ports of neighboring routers in the recent past are captured, propagated, and maintained in a cost-effective way to compute the selection metric. Experimental results on real and synthetic workloads show that our proposed selection strategies significantly outperform state-of-the-art techniques.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W1977636521",
    "type": "article"
  },
  {
    "title": "Low-power skewed-load tests based on functional broadside tests",
    "doi": "https://doi.org/10.1145/2566664",
    "publication_date": "2014-03-01",
    "publication_year": 2014,
    "authors": "Irith Pomeranz",
    "corresponding_authors": "Irith Pomeranz",
    "abstract": "This article studies the generation of low-power skewed-load tests such that the signal transitions (and line values) they create during their fast functional clock cycles match those of functional broadside tests. Functional broadside tests create functional operation conditions during their fast functional clock cycles. As a result, the signal transitions that occur during these clock cycles can also occur during functional operation. The procedure described in this article matches these signal-transitions on a line-by-line basis when generating low-power skewed-load tests. The procedure accepts a functional broadside test set for transition faults. In one of its basic steps, the procedure modifies a functional broadside test into a skewed-load test. This allows it to retain many of the signal transitions (and line values) of the functional broadside test in the skewed-load test. Experimental results for benchmark circuits demonstrate the extent to which it is possible to match the signal-transitions of skewed-load tests with those of functional broadside tests while achieving the high transition fault coverage that is typical of skewed-load tests.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2019618674",
    "type": "article"
  },
  {
    "title": "An Application Adaptation Approach to Mitigate the Impact of Dynamic Thermal Management on Video Encoding",
    "doi": "https://doi.org/10.1145/2753758",
    "publication_date": "2015-09-28",
    "publication_year": 2015,
    "authors": "Ali Mirtar; Sujit Dey; Anand Raghunathan",
    "corresponding_authors": "",
    "abstract": "Due to limitations of cooling methods such as using fan and heat sink, dynamic thermal management (DTM) is being widely adopted to manage the temperature of computing systems. However, application of DTM can reduce the system performance and thereby affect the quality of real-time applications. Real-time video encoding, which has high computational need and hard deadlines, is a commonly used application that can be severely affected by the usage of DTM. We study the effect of DTM on a widely used H.264 video encoder and formulate a multidimensional optimization problem to maximize video quality and minimize bit rate while ensuring that the video encoder can run in real time in spite of DTM effects. We model the effects of adapting encoding parameters on video quality, bit rate, and encoder speed. We propose a dynamic application adaptation method to efficiently solve the optimization problem by optimally adapting the encoding parameters in response to DTM effects. In addition, we show that the proposed dynamic application adaptation method would reduce the need for cooling methods such as forced convection cooling. We implement the proposed approach on an Intel® Core™ 2 Duo platform where dynamic voltage and frequency scaling (DVFS) is used for DTM. Our measurements with several videos reveal that when DTM is applied, the video quality is affected significantly. However, using the proposed adaptation algorithm, the encoder can run in real time, and the quality loss is minimized with only a marginal increase in the bit rate.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2030570353",
    "type": "article"
  },
  {
    "title": "Understanding SRAM Stability via Bifurcation Analysis",
    "doi": "https://doi.org/10.1145/2647957",
    "publication_date": "2014-08-01",
    "publication_year": 2014,
    "authors": "Yenpo Ho; Garng M. Huang; Peng Li",
    "corresponding_authors": "",
    "abstract": "In the past decades, aggressive scaling of transistor feature size has been a primary force driving higher Static Random Access Memory (SRAM) integration density. Due to technology scaling, nanometer SRAM designs become increasingly vulnerable to stability challenges. The traditional way of analyzing stability is through the use of Static Noise Margins (SNMs). SNMs are not capable of capturing the key nonlinear dynamics associated with memory operations, leading to imprecise characterization of stability. This work rigorously develops dynamic stability concepts and, more importantly, captures them in physically based analytical models. By leveraging nonlinear stability theory, we develop analytical models that characterize the minimum required amplitude and duration of injected current noises that can flip the SRAM state. These models, which are parameterized in key design, technology, and operating condition parameters, provide important design insights and offer a basis for predicting scaling trends of SRAM dynamic stability.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2089571499",
    "type": "article"
  },
  {
    "title": "Locality-Aware Network Utilization Balancing in NoCs",
    "doi": "https://doi.org/10.1145/2743012",
    "publication_date": "2015-12-02",
    "publication_year": 2015,
    "authors": "Ankit More; Barış Taşkın",
    "corresponding_authors": "",
    "abstract": "Hierarchical and multi-network networks-on-chip (NoCs) have been proposed in the literature to improve the energy- and performance-efficient scalability of the traditional flat-mesh NoC architecture. Theoretically, based on a small-world network-based analysis, traditional hierarchical NoCs are expected to provide good scalability. However, the traditional theoretical analysis (e.g. for small-worldness) does not take into account the congestion phenomenon experienced in such networks. Counterintuitively, as shown in this work, breaking the hierarchy in traditional hierarchical NoCs and utilizing the proposed locality-aware network utilization (NU) balancing technique performs better. This improvement in performance is observed through experimental analysis, which is contrasted with the theoretical analysis that does not account for congestion. In addition to the novelties for hierarchical networks, the application of the proposed locality-aware NU balancing scheme is extended to multi-network NoC topologies (with already separated networks). Results of the analysis show the superiority of applying the locality-aware NU balancing technique for a throughput and energy-efficient scaling of the multi-network NoC architectures, much like those of the hierarchical NoCs. For instance, for a NoC with 1024 nodes, the proposed NU balancing technique provides up to 95% higher throughput efficiency and consumes up to 29% less energy per flit compared to the best NoC topology without the NU balancing technique. The analysis also helps to render the choice of a NoC topology for traffic patterns varying in locality and nonlocality on exascale computing CMPs.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2185021801",
    "type": "article"
  },
  {
    "title": "A C2RTL Framework Supporting Partition, Parallelization, and FIFO Sizing for Streaming Applications",
    "doi": "https://doi.org/10.1145/2797135",
    "publication_date": "2016-01-28",
    "publication_year": 2016,
    "authors": "Daming Zhang; Shuangchen Li; Yongpan Liu; Xiaobo Sharon Hu; Xinyu He; Yining Zhang; Pei Zhang; Huazhong Yang",
    "corresponding_authors": "",
    "abstract": "Developing circuits for streaming applications written in C (or its variants) can benefit greatly from C-to-RTL (C2RTL) synthesis. Yet, most existing C2RTL tools lack system-level options to trade off various design constraints, such as delay and area. This article introduces a systematic way to accomplish C2RTL synthesis for streaming applications containing thousands of lines of C (or its variants) codes. Synthesizing circuits for such large applications presents serious challenges for existing C2RTL tools. Specifically, the proposed approach determines simultaneously the number of pipeline stages and the number of times that each functional block is duplicated in each pipeline stage. A mixed integer linear programming-based solution is formulated for obtaining the optimal solution. Furthermore, a heuristic algorithm is developed for large-scale problems. To accommodate the differences of the data rates between the adjacent hardware modules, first-in-first-out (FIFO) buffers are indispensable, but their overheads are nonnegligible. A parallelism-aware FIFO sizing method is also introduced to determine the optimal sizes of FIFOs. Experimental results on seven real-world applications demonstrate that the algorithms in the synthesis flow can make effective design trade-offs and find superior solutions in a short time compared with existing approaches. Furthermore, the algorithms achieve optimal results in most cases with subsecond running time.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2268471718",
    "type": "article"
  },
  {
    "title": "Path Selection for Real-Time Communication on Priority-Aware NoCs",
    "doi": "https://doi.org/10.1145/2866572",
    "publication_date": "2016-07-21",
    "publication_year": 2016,
    "authors": "Hany Kashif; Hiren Patel; Sebastian Fischmeister",
    "corresponding_authors": "",
    "abstract": "This work investigates selecting paths for communication flows when deploying a hard real-time application on a chip-multiprocessor system. This chip-multiprocessor system uses a priority-aware real-time network-on-chip interconnect between the processors. Given a mapping of the computation tasks onto the chip-multiprocessor, the problem we address in this work is to discover paths the communication flows take such that hard real-time deadlines of flows are met. Furthermore, we must ensure that deadlines are met even in the presence of direct and indirect interference from other flows sharing network links on the path. To achieve this, our algorithm utilizes a stage-level analysis for real-time communication to determine the impact of a network link being used by a flow, and its effect on other flows sharing the link. The path selection algorithm uses heuristics such as selecting links with least interference, and considering lower-priority flows when dedicating links to paths of higher-priority flows since an optimal one is intractable. The algorithm also considers constraints on the number of virtual channels at each router port in the network. The statistically significant experimental results show an improvement in schedulability by 5% and 12% over existing path selection algorithms such as Minimum Interference Routing and Widest Shortest Path algorithms, respectively. We also present a set-top box case study to further illustrate the benefits of using the proposed algorithm.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2482041307",
    "type": "article"
  },
  {
    "title": "Genetic-Algorithm-Based FPGA Architectural Exploration Using Analytical Models",
    "doi": "https://doi.org/10.1145/2939372",
    "publication_date": "2016-09-02",
    "publication_year": 2016,
    "authors": "Hossein Mehri; Bijan Alizadeh",
    "corresponding_authors": "",
    "abstract": "FPGA architectural optimization has emerged as one of the most important digital design challenges. In recent years, experimental methods have been replaced by analytical ones to find the optimized architecture. Time is the main reason for this replacement. Conventional Geometric Programming (GP) is a routine framework to solve analytical models, including area, delay, and power models. In this article, we discuss the application of the Genetic Algorithm (GA) to the design of FPGA architectures. The performance model has been integrated into the Genetic Algorithm framework in order to investigate the impact of various architectural parameters on the performance efficiency of FPGAs. This way, we are able to rapidly analyze FPGA architectures and select the best one. The main advantages of using GA versus GP are concurrency and speed. The results show that concurrent optimization of high-level architecture parameters, including lookup table size ( K ) and cluster size ( N ), and low-level parameters, like scaling of transistors, is possible for GA, whereas GP does not capture K and N under its concurrency and it needs to exhaustively search all possible combinations of K and N . The results also show that more than two orders of magnitude in runtime improvement in comparison with GP-based analysis is achieved.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2507388367",
    "type": "article"
  },
  {
    "title": "Hybrid Power Management for Office Equipment",
    "doi": "https://doi.org/10.1145/2910582",
    "publication_date": "2016-11-23",
    "publication_year": 2016,
    "authors": "Ganesh Gingade; Wenyi Chen; Yung-Hsiang Lu; Jan Allebach; Hernan Ildefonso Gutierrez-Vazquez",
    "corresponding_authors": "",
    "abstract": "Office machines (such as printers, scanners, facsimile machines, and copiers) can consume significant amounts of power. Most office machines have sleep modes to save power. Power management of these machines is usually timeout-based: a machine sleeps after being idle long enough. Setting the time-out duration can be difficult: if it is too long, the machine wastes power during idleness. If it is too short, the machine sleeps too soon and too often—the wake-up delay can significantly degrade productivity. Thus, power management is a tradeoff between saving energy and keeping response time short. Many power management policies have been published and one policy may outperform another in some scenarios. There is no definite conclusion regarding which policy is always better. This article describes two methods for office equipment power management. The first method adaptively reduces power based on a constraint of the wake-up delay. The second is a hybrid method with multiple candidate policies and it selects the most appropriate power management policy. Using 6 months of request traces from 18 different printers, we demonstrate that the hybrid policy outperforms individual policies. We also discover that power management based on business hours does not produce consistent energy savings.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2553115009",
    "type": "article"
  },
  {
    "title": "CALM",
    "doi": "https://doi.org/10.1145/2950045",
    "publication_date": "2016-12-26",
    "publication_year": 2016,
    "authors": "Di Zhu; Siyu Yue; Massoud Pedram; Lizhong Chen",
    "corresponding_authors": "",
    "abstract": "With the emergence of many-core multiprocessor system-on-chips (MPSoCs), on-chip networks are facing serious challenges in providing fast communication among various tasks and cores. One promising on-chip network design approach shown in recent studies is to add express channels to traditional mesh network as shortcuts to bypass intermediate routers, thereby reducing packet latency. This approach not only changes the packet latency models, but also greatly affects network traffic behaviors, both of which have not been fully exploited in existing mapping algorithms. In this article, we explore the opportunities in optimizing application mapping for flattened butterfly, a popular express channel-based on-chip network. Specifically, we identify the unique characteristics of flattened butterfly, analyze the opportunities and new challenges, and propose an efficient heuristic mapping algorithm. The proposed algorithm Contention-Aware Latency Minimal (CALM) is able to reduce unnecessary turns that would otherwise impose additional router pipeline latency to packets, as well as adjust forwarding traffic to reduce network contention latency. Simulation results show that the proposed algorithm can achieve, on average, 3.4X reduction in the number of turns, 24.8% reduction in contention latency, and 14.12% reduction in the overall packet latency.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2566486278",
    "type": "article"
  },
  {
    "title": "Accurately Measuring Contention in Mesh NoCs in Time-Sensitive Embedded Systems",
    "doi": "https://doi.org/10.1145/3582006",
    "publication_date": "2023-01-24",
    "publication_year": 2023,
    "authors": "Jordi Cardona; Carles Hernàndez; Jaume Abella; Enrico Mezzetti; Francisco J. Cazorla",
    "corresponding_authors": "",
    "abstract": "The computing capacity demanded by embedded systems is on the rise as software implements more functionalities, ranging from best-effort entertainment functions to performance-guaranteed safety-related functions. Heterogeneous manycore processors, using wormhole mesh (wmesh) Network-on-Chips (NoCs) as the main communication means, and contention block among applications, are increasingly considered to deliver the required computing performance. Most research efforts on software timing analysis have focused on deriving bounds (estimates) to the contention that tasks can suffer when accessing wmesh NoCs. However, less effort has been devoted to an equally important problem, namely, accurately measuring the actual contention tasks generate each other on the wmesh which is instrumental during system validation to diagnose any software timing misbehavior and determine which tasks are particularly affected by contention on specific wmesh routers. In this article, we work on the foundations of contention measuring in wmesh NoCs and propose and explain the rationale of a golden metric , called task PairWise Contention (PWC). PWC allows ascribing the actual share of the contention a given task suffers in the wmesh to each of its co-runner tasks at packet level. We also introduce and formalize a Golden Reference Value (GRV) for PWC that specifically defines a criterion to fairly break down the contention suffered by a task among its co-runner tasks in the wmesh. Our evaluation shows that GRV effectively captures how contention occurs by identifying the actual core (task) causing contention and whether contention is caused by local or remote interference in the wmesh.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4317831464",
    "type": "article"
  },
  {
    "title": "Optimal Pattern Retargeting in IEEE 1687 Networks: A SAT-based Upper-Bound Computation",
    "doi": "https://doi.org/10.1145/3585074",
    "publication_date": "2023-02-27",
    "publication_year": 2023,
    "authors": "Abrar A. Ibrahim; Ahmed Ibrahim; M. Watheq El‐Kharashi; Mona Safar",
    "corresponding_authors": "",
    "abstract": "A growing number of embedded instruments is being integrated into System-on-Chips for testing, monitoring, and several other purposes. To standardize their access protocols, the IEEE 1687 (IJTAG) standard has defined a flexible network infrastructure. Finding the shortest path in such networks requires a comprehensive search over a solution space, bounded by a limited number of time frames. This bound must be selected carefully, as it can neither be too large (to avoid unnecessary long execution time) nor too small (to avoid missing the optimal solution). Previous work was not efficiently applicable to all segments of IJTAG networks, with some providing unrealistic bounds and others having scope limitations or scalability issues. In this work, we present a new methodology for computing the upper-bound on the number of time frames using the Boolean Satisfiability Problem (SAT). Our proposed technique can also be customized to perfectly adapt to instruments access procedures, which in turn increases efficiency by reducing the time spent searching for required configurations. Results show the effectiveness of our work in computing the upper-bound for irregular benchmarks that are not constrained by a specific network design. This is achieved with a controlled increase in execution time, in contrast to previous work.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4322397474",
    "type": "article"
  },
  {
    "title": "A Chisel Framework for Flexible Design Space Exploration through a Functional Approach",
    "doi": "https://doi.org/10.1145/3590769",
    "publication_date": "2023-04-05",
    "publication_year": 2023,
    "authors": "Bruno Ferres; Olivier Muller; Frédéric Rousseau",
    "corresponding_authors": "",
    "abstract": "As the need for efficient digital circuits is ever growing in the industry, the design of such systems remains daunting, requiring both expertise and time. In an attempt to close the gap between software development and hardware design, powerful features such as functional and object-oriented programming have been used to define new languages, known as Hardware Construction Languages. In this article, we investigate the usage of such languages—more precisely, of Chisel—in the context of Design Space Exploration, and propose a novel design methodology to build custom and adaptable design flows. We apply an innovative functional approach to define flexible strategies for design space exploration, based on the composition of basic exploration steps, and provide a library of basic strategies along with a proof-of-concept framework—which we believe to be the first Chisel-based DSE framework. This framework fully integrates within the ecosystem of Chisel to allow users to define their DSE processes in the same framework (and language) they use to describe their designs. We demonstrate our methodology through several use cases, illustrating how our functional approach makes it possible to consider various metrics of interest when building exploration processes—in particular, we provide a quality of service -driven exploration example. The methodology presented in this work makes use of designers’ expertise to reduce the time required for hardware design, in particular for Design Space Exploration, and its application should ease digital design and enhance hardware developers’ productivity.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4362632752",
    "type": "article"
  },
  {
    "title": "A Reliability-Aware Splitting Duty-Cycle Physical Unclonable Function Based on Trade-off Process, Voltage, and Temperature Variations",
    "doi": "https://doi.org/10.1145/3594667",
    "publication_date": "2023-04-28",
    "publication_year": 2023,
    "authors": "Jingchang Bian; Zhengfeng Huang; Peng Ye; Zhao Yang; Huaguo Liang",
    "corresponding_authors": "",
    "abstract": "The physical unclonable function (PUF) is a hardware security primitive that can be used to prevent malicious attacks aimed at obtaining device information at the hardware level. The ring oscillator (RO) PUF has attracted considerable research attention. To improve the reliability of the RO PUF under voltage and temperature changes, the response of the duty-cycle (DC) PUF was obtained by comparing the duty cycle of the RO rather than the period. However, this method reduces the effective utilization of process variations, which limits its implementation in mature advanced manufacturing processes. In this study, a splitting duty-cycle (SDC) PUF was proposed to balance the effective extraction of process variations and robustness under voltage and temperature changes. The sensibility formula between the performance of SDC PUF and process, voltage, and temperature was established through a circuit model and statistical methodology, and the comprehensive characteristics of SDC PUF were analyzed theoretically. Next, 16 SDC PUFs with 128-bit responses were implemented and measured on a Xilinx Virtex-7 device. The experimental results revealed that the average native reliability of SDC PUF was 98.97%, and the reliability was 97.32% under various voltage and temperature conditions. This result revealed advantages over the DC PUF implemented in the same device. The uniqueness of the SDC PUF was 50.42%, and it passed the NIST SP 800-22 randomness and autocorrelation function tests.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4367313937",
    "type": "article"
  },
  {
    "title": "Mitigating Mode-switch through Run-time Computation of Response Time",
    "doi": "https://doi.org/10.1145/3597432",
    "publication_date": "2023-05-19",
    "publication_year": 2023,
    "authors": "Angeliki Kritikakou; Stefanos Skalistis",
    "corresponding_authors": "",
    "abstract": "Mixed-critical systems consist of applications with different criticality. In these systems, different confidence levels of Worst-Case Execution Time (WCET) estimations are used. Dual criticality systems use a less pessimistic, but with lower level of assurance, WCET estimation, and a safe, but pessimistic, WCET estimation. Initially, both high and low criticality tasks are executed. When a high criticality task exceeds its less pessimistic WCET, the system switches mode and low criticality tasks are usually dropped, reducing the overall system Quality of Service (QoS). To postpone mode switch, and thus, improve QoS, existing approaches explore the slack, created dynamically, when the actual execution of a task is faster than its WCET. However, existing approaches observe this slack only after the task has finished execution. To enhance dynamic slack exploitation, we propose a fine-grained approach that is able to expose the slack during the progress of a task, and safely uses it to postpone mode switch. The evaluation results show that the proposed approach has lower cost and achieves significant improvements in avoiding mode-switch, compared to existing approaches.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4377099183",
    "type": "article"
  },
  {
    "title": "A Brain-Inspired Hardware Architecture for Evolutionary Algorithms Based on Memristive Arrays",
    "doi": "https://doi.org/10.1145/3598421",
    "publication_date": "2023-05-23",
    "publication_year": 2023,
    "authors": "Zilu Wang; Xinming Shi; Xin Yao",
    "corresponding_authors": "",
    "abstract": "Brain-inspired computing takes inspiration from the brain to create energy-efficient hardware systems for information processing, capable of performing highly sophisticated tasks. Systems built with emerging electronics, such as memristive devices, can achieve gains in speed and energy by mimicking the distributed topology of the brain. In this work, a brain-inspired hardware architecture for evolutionary algorithms is proposed based on memristive arrays, which can realize sparse and approximate computing as a result of the parallel analog computing characteristic of the memristive arrays. On this basis, an efficient evolvable brain-inspired hardware system is implemented. We experimentally show that the approach can offer at least a four orders of magnitude speed improvement. We also use experimentally grounded simulations to explore fault tolerance and different parameter settings in the implemented hardware system. The experimental results show that the evolvable hardware system, implemented based on the proposed hardware architecture, can continuously evolve toward a better system even if there are failures or parameter changes in the memristive arrays, demonstrating that the proposed hardware architecture has good adaptability and fault tolerance.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4377825140",
    "type": "article"
  },
  {
    "title": "Guest Editor's Introduction: Machine Learning for VLSI Physical Design",
    "doi": "https://doi.org/10.1145/3592606",
    "publication_date": "2023-05-31",
    "publication_year": 2023,
    "authors": "Igor L. Markov; Fan Yang; Li Shang; Hai Zhou",
    "corresponding_authors": "",
    "abstract": "introduction Share on Guest Editor's Introduction: Machine Learning for VLSI Physical Design Authors: Igor Markov Facebook Facebook 0000-0002-3826-527XView Profile , Fan Yang Fudan University Fudan University 0000-0003-2164-8175View Profile , Li Shang Fudan University Fudan University 0000-0003-3944-7531View Profile , Hai Zhou Northwestern University Northwestern University 0000-0003-4824-7179View Profile Authors Info & Claims ACM Transactions on Design Automation of Electronic SystemsVolume 28Issue 431 May 2023Article No.: 48pp 1–3https://doi.org/10.1145/3592606Published:31 May 2023Publication History 0citation45DownloadsMetricsTotal Citations0Total Downloads45Last 12 Months45Last 6 weeks38 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteGet Access",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4378837271",
    "type": "article"
  },
  {
    "title": "AD <sup>2</sup> VNCS: <u>A</u> dversarial <u>D</u> efense and <u>D</u> evice <u>V</u> ariation-tolerance in Memristive Crossbar-based <u>N</u> euromorphic <u>C</u> omputing <u>S</u> ystems",
    "doi": "https://doi.org/10.1145/3600231",
    "publication_date": "2023-05-30",
    "publication_year": 2023,
    "authors": "Yongtian Bi; Qi Xu; Hao Geng; Song Chen; Yi Kang",
    "corresponding_authors": "",
    "abstract": "In recent years, memristive crossbar-based neuromorphic computing systems (NCS) have obtained extremely high performance in neural network acceleration. However, adversarial attacks and conductance variations of memristors bring reliability challenges to NCS design. First, adversarial attacks can fool the neural network and pose a serious threat to security critical applications. However, device variations lead to degradation of the network accuracy. In this article, we propose DFS (Deep neural network Feature importance Sampling) and BFS (Bayesian neural network Feature importance Sampling) training strategies, which consist of Bayesian Neural Network (BNN) prior setting, clustering-based loss function, and feature importance sampling techniques, to simultaneously combat device variation, white-box attack, and black-box attack challenges. Experimental results clearly demonstrate that the proposed training framework can improve the NCS reliability.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4381282673",
    "type": "article"
  },
  {
    "title": "A Constructive Approach for Threshold Function Identification",
    "doi": "https://doi.org/10.1145/3606371",
    "publication_date": "2023-06-30",
    "publication_year": 2023,
    "authors": "Meng-Jing Li; Y. L. Yen; Yiting Li; Yung‐Chih Chen; Chun-Yao Wang",
    "corresponding_authors": "",
    "abstract": "Threshold Function (TF) is a subset of Boolean function that can be represented with a single linear threshold gate (LTG). In the research about threshold logic, the identification of TF is an important task that determines whether a given function is a TF or not. In this article, we propose a sufficient and necessary condition for a function being a TF. With the proposed sufficient and necessary condition, we devise a TF identification algorithm. The experimental results show that the proposed approach saves 80% CPU time for identifying all the 8-input NP-class TFs as compared with the state-of-the-art. Furthermore, the LTGs corresponding to the identified TFs obtained by the proposed approach have smaller weights and threshold values than the state-of-the-art.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4382680307",
    "type": "article"
  },
  {
    "title": "Harmonic Estimation and Comparative Analysis of Ultra-High Speed Flip-Flop and Latch Topologies for Low Power and High Performance Future Generation Micro-/Nano Electronic Systems",
    "doi": "https://doi.org/10.1145/3590770",
    "publication_date": "2023-07-18",
    "publication_year": 2023,
    "authors": "Muhammad Imran Khan",
    "corresponding_authors": "Muhammad Imran Khan",
    "abstract": "This paper presents estimation and analysis of the higher order harmonics, power features, and real performance of flip-flop and master-slave latch topologies. This research article outlines the impact of transistor model quality and input signal selection on the estimate of higher order harmonic contents of switching waveform emitted by the digital integrated circuits. Highly integrated systems require accurate estimation of higher order harmonics to control noise. This work presents simulations of 12 kinds of flip-flop and latch topologies on different process technologies i.e., 28 nm, 45 nm, 65 nm, and 130 nm. It is implied that the steeper the spectrum roll-off, the fewer the contents of higher order harmonics. Results of 28 nm process design kit are improved compared to 45 nm, 65 nm, and 130 nm process design kits. Furthermore, the results of the comparison of representative flip-flop and latch topologies illustrate the advantage of the approach and the suitability for high performance and low power consumption.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4384695956",
    "type": "article"
  },
  {
    "title": "Mitigating Memory Wall Effects in CNN Engines with On-the-Fly Weights Generation",
    "doi": "https://doi.org/10.1145/3611673",
    "publication_date": "2023-08-04",
    "publication_year": 2023,
    "authors": "Stylianos I. Venieris; Javier Fernández-Marqués; Nicholas D. Lane",
    "corresponding_authors": "",
    "abstract": "The unprecedented accuracy of convolutional neural networks (CNNs) across a broad range of AI tasks has led to their widespread deployment in mobile and embedded settings. In a pursuit for high-performance and energy-efficient inference, significant research effort has been invested in the design of field-programmable gate array (FPGA)–based CNN accelerators. In this context, single computation engines constitute a popular design approach that enables the deployment of diverse models without the overhead of fabric reconfiguration. Nevertheless, this flexibility often comes with significantly degraded performance on memory-bound layers and resource underutilisation due to the suboptimal mapping of certain layers on the engine’s fixed configuration. In this work, we investigate the implications in terms of CNN engine design for a class of models that introduce a pre-convolution stage to decompress the weights at runtime. We refer to these approaches as on-the-fly . This article presents unzipFPGA, a novel CNN inference system that counteracts the limitations of existing CNN engines. The proposed framework comprises a novel CNN hardware architecture that introduces a weights generator module that enables the on-chip on-the-fly generation of weights, alleviating the negative impact of limited bandwidth on memory-bound layers. We further enhance unzipFPGA with an automated hardware-aware methodology that tailors the weights generation mechanism to the target CNN-device pair, leading to an improved accuracy–performance balance. Finally, we introduce an input selective processing element (PE) design that balances the load between PEs in suboptimally mapped layers. Quantitative evaluation shows that the proposed framework yields hardware designs that achieve an average of 2.57× performance efficiency gain over highly optimised GPU designs for the same power constraints and up to 3.94× higher performance density over a diverse range of state-of-the-art FPGA-based CNN accelerators.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4385584193",
    "type": "article"
  },
  {
    "title": "Systemization of Knowledge: Robust Deep Learning using Hardware-software co-design in Centralized and Federated Settings",
    "doi": "https://doi.org/10.1145/3616868",
    "publication_date": "2023-08-23",
    "publication_year": 2023,
    "authors": "Ruisi Zhang; Shehzeen Hussain; Huili Chen; Mojan Javaheripi; Farinaz Koushanfar",
    "corresponding_authors": "",
    "abstract": "Deep learning (DL) models are enabling a significant paradigm shift in a diverse range of fields, including natural language processing and computer vision, as well as the design and automation of complex integrated circuits. While the deep models – and optimizations based on them, e.g., Deep Reinforcement Learning (RL) – demonstrate a superior performance and a great capability for automated representation learning, earlier works have revealed the vulnerability of DL to various attacks. The vulnerabilities include adversarial samples, model poisoning, and fault injection attacks. On the one hand, these security threats could divert the behavior of the DL model and lead to incorrect decisions in critical tasks. On the other hand, the susceptibility of DL to potential attacks might thwart trustworthy technology transfer as well as reliable DL deployment. In this work, we investigate the existing defense techniques to protect DL against the above-mentioned security threats. Particularly, we review end-to-end defense schemes for robust deep learning in both centralized and federated learning settings. Our comprehensive taxonomy and horizontal comparisons reveal an important fact that defense strategies developed using DL/software/hardware co-design outperform the DL/software-only counterparts and show how they can achieve very efficient and latency-optimized defenses for real-world applications. We believe our systemization of knowledge sheds light on the promising performance of hardware-software co-design of DL security methodologies and can guide the development of future defenses.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4386099529",
    "type": "article"
  },
  {
    "title": "Self Adaptive Logical Split Cache Techniques for Delayed Aging of NVM LLC",
    "doi": "https://doi.org/10.1145/3616871",
    "publication_date": "2023-08-24",
    "publication_year": 2023,
    "authors": "S. Sivakumar; John Jose",
    "corresponding_authors": "",
    "abstract": "Due to the technological advancements in the last few decades, several applications have emerged that demand more computing power and on-chip and off-chip memories. However, the scaling of memory technologies is not at par with computing throughput of modern day multi-core processors. Conventional memory technologies such as SRAM and DRAM have technological limitations to meet large on-chip memory requirements owing to their low packaging density and high leakage power. In order to meet the ever-increasing demand for memory, researchers came up with alternative solutions, such as emerging non-volatile memory technologies such as STT-RAM, PCM, and ReRAM. However, these memory technologies have limited write endurance and high write energy. This emphasizes the need for a policy that will reduce the writes or distribute the writes uniformly across the memory thereby enhancing its lifetime by delaying the early wear out of memory cells due to frequent writes. We propose two techniques, Enhanced-Virtually Split Cache (E-ViSC) and Protean-Virtually Split Cache (P-ViSC), which dynamically adjust the cache configuration to distribute the writes uniformly across the memory to enhance the lifetime. Experimental studies show that E-ViSC and P-ViSC improve lifetime of NVM L2 caches by upto 2.31× and 1.97× respectively.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4386136607",
    "type": "article"
  },
  {
    "title": "Surrogate Lagrangian Relaxation: A Path to Retrain-Free Deep Neural Network Pruning",
    "doi": "https://doi.org/10.1145/3624476",
    "publication_date": "2023-09-19",
    "publication_year": 2023,
    "authors": "Shanglin Zhou; Mikhail A. Bragin; Deniz Gurevin; Lynn Pepin; Fei Miao; Caiwen Ding",
    "corresponding_authors": "",
    "abstract": "Network pruning is a widely used technique to reduce computation cost and model size for deep neural networks. However, the typical three-stage pipeline (i.e., training, pruning, and retraining (fine-tuning)) significantly increases the overall training time. In this article, we develop a systematic weight-pruning optimization approach based on surrogate Lagrangian relaxation (SLR), which is tailored to overcome difficulties caused by the discrete nature of the weight-pruning problem. We further prove that our method ensures fast convergence of the model compression problem, and the convergence of the SLR is accelerated by using quadratic penalties. Model parameters obtained by SLR during the training phase are much closer to their optimal values as compared to those obtained by other state-of-the-art methods. We evaluate our method on image classification tasks using CIFAR-10 and ImageNet with state-of-the-art multi-layer perceptron based networks such as MLP-Mixer; attention-based networks such as Swin Transformer; and convolutional neural network based models such as VGG-16, ResNet-18, ResNet-50, ResNet-110, and MobileNetV2. We also evaluate object detection and segmentation tasks on COCO, the KITTI benchmark, and the TuSimple lane detection dataset using a variety of models. Experimental results demonstrate that our SLR-based weight-pruning optimization approach achieves a higher compression rate than state-of-the-art methods under the same accuracy requirement and also can achieve higher accuracy under the same compression rate requirement. Under classification tasks, our SLR approach converges to the desired accuracy × faster on both of the datasets. Under object detection and segmentation tasks, SLR also converges 2× faster to the desired accuracy. Further, our SLR achieves high model accuracy even at the hardpruning stage without retraining, which reduces the traditional three-stage pruning into a two-stage process. Given a limited budget of retraining epochs, our approach quickly recovers the model’s accuracy.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4386864749",
    "type": "article"
  },
  {
    "title": "Sequential Routing-based Time-division Multiplexing Optimization for Multi-FPGA Systems",
    "doi": "https://doi.org/10.1145/3626322",
    "publication_date": "2023-10-05",
    "publication_year": 2023,
    "authors": "Lin Wen-xiong; Haojie Wu; Peng Gao; Wenjun Luo; Shuting Cai; Xiaoming Xiong",
    "corresponding_authors": "",
    "abstract": "Multi-field programming gate array (FPGA) systems are widely used in various circuit design-related areas, such as hardware emulation, virtual prototypes, and chiplet design methodologies. However, a physical resource clash between inter-FPGA signals and I/O pins can create a bottleneck in a multi-FPGA system. Specifically, inter-FPGA signals often outnumber I/O pins in a multi-FPGA system. To solve this problem, time-division multiplexing (TDM) is introduced. However, undue time delay caused by TDM may impair the performance of a multi-FPGA system. Therefore, a more efficient TDM solution is needed. In this work, we propose a new routing sequence strategy to improve the efficiency of TDM. Our strategy consists of two parts: a weighted routing algorithm and TDM assignment optimization. The algorithm takes into account the weight of the net to generate a high-quality routing topology. Then, a net-based TDM assignment is performed to obtain a lower TDM ratio for the multi-FPGA system. Experiments on the public dataset of CAD Contest 2019 at ICCAD showed that our routing sequence strategy achieved good results. Especially in those testcases of unbalanced designs, the performance of multi-FPGA systems was improved up to 2.63. Moreover, we outperformed the top two contest finalists as to TDM results in most of the testcases.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4387377842",
    "type": "article"
  },
  {
    "title": "Mathematical Framework for Optimizing Crossbar Allocation for ReRAM-based CNN Accelerators",
    "doi": "https://doi.org/10.1145/3631523",
    "publication_date": "2023-11-02",
    "publication_year": 2023,
    "authors": "Wanqian Li; Yinhe Han; Xiaoming Chen",
    "corresponding_authors": "",
    "abstract": "The resistive random-access memory (ReRAM) has widely been used to accelerate convolutional neural networks (CNNs) thanks to its analog in-memory computing capability. ReRAM crossbars not only store layers’ weights, but also perform in-situ matrix-vector multiplications which are core operations of CNNs. To boost the performance of ReRAM-based CNN accelerators, crossbars can be duplicated to explore more intra-layer parallelism. The crossbar allocation scheme can significantly influence both the computing throughput and bandwidth requirements of ReRAM-based CNN accelerators. Under the resource constraints (i.e., crossbars and memory bandwidths), how to find the optimal number of crossbars for each layer to maximize the inference performance for an entire CNN is an unsolved problem. In this work, we find the optimal crossbar allocation scheme by mathematically modeling the problem as a constrained optimization problem and solving it with a dynamic programming based solver. Experiments demonstrate that our model for CNN inference time is almost precise, and the proposed framework can obtain solutions with near-optimal inference time. We also emphasize that communication (i.e., data access) is an important factor and must also be considered when determining the optimal crossbar allocation scheme.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4388210331",
    "type": "article"
  },
  {
    "title": "Optimal Model Partitioning with Low-Overhead Profiling on the PIM-based Platform for Deep Learning Inference",
    "doi": "https://doi.org/10.1145/3628599",
    "publication_date": "2023-11-02",
    "publication_year": 2023,
    "authors": "Seok Young Kim; Jae-Wook Lee; Yoonah Paik; Chang Hyun Kim; Won Jun Lee; Seon Wook Kim",
    "corresponding_authors": "",
    "abstract": "Recently Processing-in-Memory (PIM) has become a promising solution to achieve energy-efficient computation in data-intensive applications by placing computation near or inside the memory. In most Deep Learning (DL) frameworks, a user manually partitions a model’s computational graph (CG) onto the computing devices by considering the devices’ capability and the data transfer. The Deep Neural Network (DNN) models become increasingly complex for improving accuracy; thus, it is exceptionally challenging to partition the execution to achieve the best performance, especially on a PIM-based platform requiring frequent offloading of large amounts of data. This article proposes two novel algorithms for DL inference to resolve the challenge: low-overhead profiling and optimal model partitioning. First, we reconstruct CG by considering the devices’ capability to represent all the possible scheduling paths. Second, we develop a profiling algorithm to find the required minimum profiling paths to measure all the node and edge costs of the reconstructed CG. Finally, we devise the model partitioning algorithm to get the optimal minimum execution time using the dynamic programming technique with the profiled data. We evaluated our work by executing the BERT, RoBERTa, and GPT-2 models on the ARM multicores with the PIM-modeled FPGA platform with various sequence lengths. For three computing devices in the platform, i.e., CPU serial/parallel and PIM executions, we could find all the costs only in four profile runs, three for node costs and one for edge costs. Also, our model partitioning algorithm achieved the highest performance in all the experiments over the execution with manually assigned device priority and the state-of-the-art greedy approach.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4388229519",
    "type": "article"
  },
  {
    "title": "<scp>Flip</scp> : Data-centric Edge CGRA Accelerator",
    "doi": "https://doi.org/10.1145/3631118",
    "publication_date": "2023-11-03",
    "publication_year": 2023,
    "authors": "Dan Wu; Peng Chen; Thilini Kaushalya Bandara; Zhaoying Li; Tulika Mitra",
    "corresponding_authors": "",
    "abstract": "Coarse-Grained Reconfigurable Arrays (CGRA) are promising edge accelerators due to the outstanding balance in flexibility, performance, and energy efficiency. Classic CGRAs statically map compute operations onto the processing elements (PE) and route the data dependencies among the operations through the Network-on-Chip. However, CGRAs are designed for fine-grained static instruction-level parallelism and struggle to accelerate applications with dynamic and irregular data-level parallelism, such as graph processing. To address this limitation, we present Flip , a novel accelerator that enhances traditional CGRA architectures to boost the performance of graph applications. Flip retains the classic CGRA execution model while introducing a special data-centric mode for efficient graph processing. Specifically, it leverages the inherent data parallelism of graph algorithms by mapping graph vertices onto PEs rather than the operations and supporting dynamic routing of temporary data according to the runtime evolution of the graph frontier. Experimental results demonstrate that Flip achieves up to 36× speedup with merely 19% more area compared to classic CGRAs. Compared to state-of-the-art large-scale graph processors, Flip has similar energy efficiency and 2.2× better area efficiency at a much-reduced power/area budget.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4388282052",
    "type": "article"
  },
  {
    "title": "Scalable and Accelerated Self-healing Control Circuit Using Evolvable Hardware",
    "doi": "https://doi.org/10.1145/3634682",
    "publication_date": "2023-11-24",
    "publication_year": 2023,
    "authors": "S Deepanjali; Noor Mahammad Sk",
    "corresponding_authors": "",
    "abstract": "Controllers are mission-critical components of any electronic design. By sending control signals, they decide which and when other data path elements must operate. Faults, especially Single Event Upset (SEU) occurrence in these components, can lead to functional/mission failure of the system when deployed in harsh environments. Hence, competence to self-heal from SEU is highly required in the control path of the digital system. Reconfiguration is critical for recovering from a faulty state to a non-faulty state. Compared to native reconfiguration, the Virtual Reconfigurable Circuit (VRC) is an FPGA-generic reconfiguration mechanism. The non-partial reconfiguration in VRC and extensive architecture are considered hindrances in extending the VRC-based Evolvable Hardware (EHW) to real-time fault mitigation. To confront this challenge, we have proposed an intrinsic constrained evolution to improve the scalability and accelerate the evolution process for VRC-based fault mitigation in mission-critical applications. Experimentation is conducted on complex ACM/SIGDA benchmark circuits and real-time circuits used in space missions, which are not included in related works. In addition, a comparative study is made between existing and proposed methodologies for brushless DC motor control circuits. The hardware utilization in the multiplexer has been significantly reduced, resulting in up to a 77% reduction in the existing VRC architecture. The proposed methodology employs a fault localization approach to narrow the search space effectively. This approach has yielded an 87% improvement on average in convergence speed, as measured by the evolution time, compared to the existing work.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4388977684",
    "type": "article"
  },
  {
    "title": "BIFEST",
    "doi": "https://doi.org/10.1145/307988.307992",
    "publication_date": "1999-04-01",
    "publication_year": 1999,
    "authors": "Kuen-Jong Lee; Jing-Jou Tang; Tsung‐Chu Huang",
    "corresponding_authors": "",
    "abstract": "This paper presents BIFEST, an ATPG system that employs the built-in intermediate voltage test technique in an efficient ATPG process to deal with CMOS bridging faults. Fast and accurate calculations of the intermediate bridging voltages and the variant threshold tolerance margins on a resistive bridging fault model are presented. A PODEM-like, PPSFP-based ATPG process is developed to generate test patterns for faults that are conventionally logic-testable. The remaining faults are then dealt with by special circuits, called built-in intermediate voltage sensors (BIVSs). By this methodology, almost the same fault coverage as that employing I DDQ testing can be achieved with only logic monitoring required.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W1999484948",
    "type": "article"
  },
  {
    "title": "Effects of resource sharing on circuit delay",
    "doi": "https://doi.org/10.1145/290833.290852",
    "publication_date": "1998-04-01",
    "publication_year": 1998,
    "authors": "Subhrajit Bhattacharya; Sujit Dey; Franc Breglez",
    "corresponding_authors": "",
    "abstract": "This paper analyzes the effect of resource sharing and assignment on the clock period of the synthesized circuit. The assignment phase assigns or binds operations of the scheduled behavioral description to a set of allocated resources. We focus on control-flow intensive descriptions, characterized by the presence of mutually exclusive paths due to the presence of nested conditional branches and loops. We show that clustering multiple operations in the same state of the schedule, possibly leading to chaining of functional units (FUs) in the RTL circuit, is an effective way to minimize the total number of clock cycles, and hence total execution time. We present an assignment algorithm that is particularly effective for such design styles by minimizing data chaining and hence the clock period of the circuit, thereby leading to further reduction in total execution time. Existing resource sharing and assignment approaches for reducing the clock period of the resulting circuit either increase the resource allocation or use faster modules, both leading to leading to larger area requirements. In this paper we show that even when the type of available resource units and the number of resource units of each type is fixed, different assignments may lead to circuits with significant differences in clock period. We provide a comprehensive analysis of how resource sharing and assignment introduces long paths in the circuit. Based on the analysis, we develop an assignment algorithm that uses a high-level delay estimator to asign operations to a fixed set of available resources so as to minimize the clock period of the resultant circuit, with no or minimal effect on the area of the circuit. Experimental results on several conditional-intensive designs demonstrate the effectiveness of the assignment algorithm.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2009309972",
    "type": "article"
  },
  {
    "title": "Eliminating false loops caused by sharing in control path",
    "doi": "https://doi.org/10.1145/293625.293635",
    "publication_date": "1998-07-01",
    "publication_year": 1998,
    "authors": "Alan P. Su; Yu-Chin Hsu; Ta-Yung Liu; Mike Tien-Chien Lee",
    "corresponding_authors": "",
    "abstract": "In high-level synthesis, resource sharing may result in a circuit containing false loops that create great difficulty in timing validation during the design sign-off phase. It is hence desirable to avoid generating any false loops in a synthesized circuit. Previous work [Stok 1992; Huang et al. 1995] considered mainly data path sharing for false loop elimination. However, for a complete circuit with both data path and control path, false loops can be created due to control logic sharing. In this article, we present a novel approach to detect and eleminate the false loops caused by control logic sharing. An effective filter is devised to reduce the computational complexity of false loop detection, which is based on checking the level numbers that are propagated from data path operators to imputs and outputs of the control path. Only the input/output pairs of the control path identified by the filter are further investigated by traversing into the data path for false loop detection. A removal algorithm is then applied to eliminate the detected false loops, followed by logic minimization to further optimize the circuit. Experimental results show that for the nine example circuits we tested, the final designs after false loop removal and logic minimization give only slightly larger area than the original ones that contain false loops.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2056723461",
    "type": "article"
  },
  {
    "title": "Environment modeling and language universality",
    "doi": "https://doi.org/10.1145/348019.348572",
    "publication_date": "2000-07-01",
    "publication_year": 2000,
    "authors": "Richard Raimi; Ramin Hojati; Kedar S. Namjoshi",
    "corresponding_authors": "",
    "abstract": "In this paper we outline a theory for the environment-modeling problem , the problem of abstracting component finite state machines (FSMs)bordering a particular FSM of interest within a network of interacting FSMs. The goal is to lay a theoretical foundation for the automatic state reduction of large FSM networks. We feel this is a prerequisite for the efficient use of many verification techniques. We focus on computing conditions for the safe removal of a component FSM in a FSM network, where removal is safe if it preserves a certain well-defined trace equivalence. We present an optimized algorithm for determining language universality of a FSM, as well as determining independence of a FSM from those of its inputs connected to outputs of neighboring FSMs. These two properties, input independence and language universality, provide the necessary and sufficient conditions for safe removal. In addition, we show how simulation relations can be utilized, both to reduce the cost of computing safe removal and to create an appropriate abstract FSM when safe removal is not possible.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2006451236",
    "type": "article"
  },
  {
    "title": "Diagnostic simulation of stuck-at faults in sequential circuits using compact lists",
    "doi": "https://doi.org/10.1145/502175.502177",
    "publication_date": "2001-10-01",
    "publication_year": 2001,
    "authors": "I. Hartanto; Srikanth Venkataraman; W.K. Fuchs; E.M. Rudnick; J.H. Patel; Sreejit Chakravarty",
    "corresponding_authors": "",
    "abstract": "This article describes a diagnostic fault simulator for stuck-at faults in sequential circuits that is both time and space efficient. The simulator represents indistinguishable classes of faults as memory efficient lists. The use of lists reduces the number of output response comparisons between faults and hence speeds up the simulation process. The lists also make it easy to drop faults when they are fully distinguished from other faults. Experimental results on the ISCAS89 circuits show that the simulator runs significantly faster than an earlier work based on distinguishability matrices, and for large circuits is faster and more memory efficient than a recent method based on lists of indistinguishable faults. The paper provides the first reports on pessimistic and optimistic diagnostic measures for all faults of the large ISCAS circuits with known deterministic tests. The diagnostic fault simulator has also been modified to diagnose defects, given the output responses of failing devices. Results on simulated bridging defects show that the diagnosis time is comparable to the time for fault simulation with fault dropping.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2050986420",
    "type": "article"
  },
  {
    "title": "Sequential optimization in the absence of global reset",
    "doi": "https://doi.org/10.1145/762488.762493",
    "publication_date": "2003-04-01",
    "publication_year": 2003,
    "authors": "Vigyan Singhal; Carl Pixley; Adnan Aziz; Shaz Qadeer; Robert K. Brayton",
    "corresponding_authors": "",
    "abstract": "We study the problem of optimizing synchronous sequential circuits. There have been previous efforts to optimize such circuits. However, all previous attempts make implicit or explicit assumptions about the design or the environment of the design. For example, it is widespread practice to assume the existence of a hardware reset line and consequently a fixed power-up state; in the absence of the same, a common premise is that the design's environment will apply an initializing sequence. We review the concept of safe replaceability which does away with these assumptions and the delay-safe replaceability notion, which is applicable when the design's output is not used for a certain number of cycles after power-up. We then develop procedures for optimizing the combinational next-state and output logic, as well as routines for reencoding the state space and removing state bits under these replaceability criteria. Experimental results demonstrate the effectiveness of our algorithms.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2063800151",
    "type": "article"
  },
  {
    "title": "Synthesis of low-power selectively-clocked systems from high-level specification",
    "doi": "https://doi.org/10.1145/348019.348050",
    "publication_date": "2000-07-01",
    "publication_year": 2000,
    "authors": "Luca Benini; G. De Micheli",
    "corresponding_authors": "",
    "abstract": "We propose a technique for synthesizing low-power systems from behavioral specifications. We analyze the control flow of the specification model to detect mutually exclusive sections of the computation. A selectively-clocked interconnection of interacting FSMs is automatically generated and optimized, where each FSM controls the execution of one section of computation. Only one of the interacting FSMs is active for a high fraction of the operation time, while the others are idle and their clocks are stopped. Periodically, the active machine releases the control of the system to another FSM and stops. Our interacting FSM implementation achieves consistently lower power dissipation than the functionally equivalent monolithic implementation. On average, 37% power savings and 12% speedup are obtained, despite a 30% area overhead.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2125781115",
    "type": "article"
  },
  {
    "title": "Postlayout optimization for synthesis of Domino circuits",
    "doi": "https://doi.org/10.1145/1179461.1179462",
    "publication_date": "2006-10-01",
    "publication_year": 2006,
    "authors": "Aiqun Cao; Ruibing Lu; Chen Li; Cheng‐Kok Koh",
    "corresponding_authors": "",
    "abstract": "Logic duplication, a commonly used synthesis technique to remove trapped inverters in reconvergent paths of Domino circuits, incurs high area and power penalties. In this article, we propose a synthesis scheme to reduce the duplication cost by allowing inverters in Domino logic under certain timing constraints for both simple and complex gates. Moreover, we can include the logic duplication minimization during technology mapping for synthesis of Domino circuits with complex gates. In order to guarantee the robustness of such Domino circuits, we perform the logic optimization as a postlayout step. Experimental results show significant reduction in duplication cost, which translates into significant improvements in area and power. As a byproduct, the timing performance is also improved owing to smaller layout area and/or logic depth.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2006038198",
    "type": "article"
  },
  {
    "title": "Performance-driven technology mapping with MSG partition and selective gate duplication",
    "doi": "https://doi.org/10.1145/1179461.1179469",
    "publication_date": "2006-10-01",
    "publication_year": 2006,
    "authors": "Chi-Shong Wang; Chingwei Yeh",
    "corresponding_authors": "",
    "abstract": "Traditionally, technology mapping is done by first partitioning a circuit into a forest of trees. Each individual tree is then mapped using dynamic programming. The links among the mappings of different trees are provided via propagating the essential mapping information along multiple fanout branches. While this approach may achieve optimality within each tree, the overall result is compromised from the very first treatment of fanouts. In this article, we propose a new scheme that greatly improves technology mapping. Instead of a forest of trees, we partition the circuit into a set of maximal super-gates (MSGs). These are used to transform the original circuit into trees. We then apply the dynamic programming technique to the trees and allow duplication of gates in the mapping of each individual MSG. Experimental results on ISCAS'85 benchmarks show that our approach delivers an average of 20.6% reduction in delay with only a 9.5% increase on area.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2055782118",
    "type": "article"
  },
  {
    "title": "Crosstalk minimization in logic synthesis for PLAs",
    "doi": "https://doi.org/10.1145/1179461.1179466",
    "publication_date": "2006-10-01",
    "publication_year": 2006,
    "authors": "Yiyu Liu; Kuo‐Hua Wang; TingTing Hwang",
    "corresponding_authors": "",
    "abstract": "We propose a maximum crosstalk effect minimization algorithm that takes logic synthesis into consideration for PLA structures. To minimize the crosstalk effect, a technique for permuting wire is used which contains the following steps. First, product terms are partitioned into long and short sets, and then the product terms in the long and short sets are interleaved. After that, we take advantage of the crosstalk immunity of product terms in the long set to further reduce the maximum coupling capacitance of the PLA. Finally, synthesis techniques such as local and global transformations are taken into consideration to search for a better result. The experiments demonstrate that our algorithm can effectively minimize the maximum coupling capacitance of a circuit by 51% as compared with the original area-minimized PLA without crosstalk effect minimization.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2148039614",
    "type": "article"
  },
  {
    "title": "A Metric for Quantifying Similarity between Timing Constraint Sets in Real-Time Systems",
    "doi": "https://doi.org/10.1145/1970353.1970368",
    "publication_date": "2011-06-01",
    "publication_year": 2011,
    "authors": "Yue Yu; Shangping Ren; Xiaobo Sharon Hu",
    "corresponding_authors": "",
    "abstract": "Real-time systems are systems in which their timing behaviors must satisfy a specified set of timing constraints and they often operate in a real-world environment with scarce resources. As a result, the actual runtime performance of these systems may deviate from the design, either inevitably due to unpredictable factors or by intention in order to improve system’s other Quality-of-Service (QoS) properties. In this article, we first introduce a new metric, timing constraint set similarity , to quantify the resemblance between two different timing constraint sets. Because directly calculating the exact value of the metric involves calculating the size of a polytope which is a # P -hard problem, we instead introduce an efficient method for estimating its bound. We further illustrate how this metric can be exploited for improving system predictability and for evaluating trade-offs between timing constraint compromises and the system’s other QoS property gains.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W1971506061",
    "type": "article"
  },
  {
    "title": "Verification work reduction methodology in low-power chip implementation",
    "doi": "https://doi.org/10.1145/2390191.2390203",
    "publication_date": "2013-01-01",
    "publication_year": 2013,
    "authors": "Masanori Kurimoto; Takeshi Yamamoto; Satoshi Nakano; Atsuto Hanami; Hiroyuki Kondo",
    "corresponding_authors": "",
    "abstract": "In order to achieve satisfactory verification for complicated low-power demands in green products, we propose a verification work reduction methodology. It consists of three step, namely virtual, direct actual, and actual model simulations. Virtual low-power simulation inserts low-power cells, such as isolators or level shifters, virtually and simulates logical behavior for design under test (DUT) based on user-defined power mode. Direct actual low-power simulation replaces behavior models without non-logical pins for some of modules with actual models with non-logical pins, which are Vdd and Gnd, and simulates DUT in mixed level. Actual low-power simulation simulates DUT by using actual models with non-logical pins for all cells and hard macros. We introduce techniques which classify the type of the bugs on which we focus at each verification step and prevent the concerned bugs from leaking to the latter verification step as much as possible. We applied our methodology to an actual chip and could reduce the total simulation period until tape-out by 38.8% and the total chip development period by 10%, compared with the conventional methodology.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W1975875633",
    "type": "article"
  },
  {
    "title": "An Extended SystemC Framework for Efficient HW/SW Co-Simulation",
    "doi": "https://doi.org/10.1145/2159542.2159543",
    "publication_date": "2012-04-01",
    "publication_year": 2012,
    "authors": "Meng-Huan Wu; Peng-Chih Wang; Cheng-Yang Fu; Ren‐Song Tsay",
    "corresponding_authors": "",
    "abstract": "In this article, we propose an extended SystemC framework that directly enables software simulation in SystemC. Although SystemC has been widely adopted for system-level simulation of hardware designs nowadays, to complete HW/SW co-simulation, it still requires an additional instruction set simulator (ISS) for software execution. However, the heavy intercommunication overheads between the two heterogeneous simulators would significantly slow down simulation performance. To deal with this issue, our proposed approach automatically generates high-speed and equivalent SystemC models for target software applications that can be directly integrated with hardware models for complete HW/SW co-simulation. In addition, to properly handle multitasking, an efficient OS model is devised to support accurate preemptive scheduling. Since both the generated application model and the OS model are constructed in SystemC modules, our approach avoids heavy intercommunication overheads and achieves over 1,000 times faster simulation than that of the conventional ISS-SystemC approach. Experimental results demonstrate that our extended SystemC approach can perform at 50 to 220 MIPS while offering accurate simulation results.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W1988304682",
    "type": "article"
  },
  {
    "title": "A parallel dual-scanline algorithm for partitioning parameterized 45-degree polygons",
    "doi": "https://doi.org/10.1145/2505015",
    "publication_date": "2013-10-01",
    "publication_year": 2013,
    "authors": "Yao-Lin Chang; I-Lun Tseng",
    "corresponding_authors": "",
    "abstract": "In order to use rectangular corner stitching data structures in storing parameterized orthogonal layouts, parameterized polygons in the layouts must be partitioned into rectangles. Likewise, in order to use trapezoidal corner stitching data structures in storing parameterized 45-degree layouts, parameterized polygons in the layouts have to be partitioned into trapezoids. In this article, a parallel polygon partitioning algorithm is proposed; the algorithm is capable of partitioning parameterized orthogonal polygons into parameterized rectangles as well as partitioning parameterized 45-degree polygons into parameterized trapezoids. Additionally, the algorithm can be used to partition fixed-coordinate polygons. By adopting the dual-scanline technique, which involves using two scanlines to concurrently sweep an input polygon, the parallel partitioning algorithm can process vertices and edges of the input polygon efficiently. The parallel polygon partitioning algorithm has been implemented in C++ with the use of OpenMP. Compared with a sequential partitioning program which uses a single scanline, our parallel partitioning program can achieve 20% to 30% speedup while partitioning large parameterized polygons or partitioning parameterized polygons with complex constraints.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2012198150",
    "type": "article"
  },
  {
    "title": "Editorial to special section on networks on chip",
    "doi": "https://doi.org/10.1145/2541012.2541013",
    "publication_date": "2013-10-01",
    "publication_year": 2013,
    "authors": "Diana Marculescu; Chita R. Das",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2018616430",
    "type": "article"
  },
  {
    "title": "Low-power resource binding by postsilicon customization",
    "doi": "https://doi.org/10.1145/2442087.2442097",
    "publication_date": "2013-03-01",
    "publication_year": 2013,
    "authors": "Mehrdad Majzoobi; Joonho Kong; Farinaz Koushanfar",
    "corresponding_authors": "",
    "abstract": "This article proposes the first postsilicon customization method for resource binding to achieve power reduction application specific integrated circuits (ASICs) design. Instead of committing to one configuration of resource binding during synthesis, our new synthesis method produces a diverse set of candidate bindings for the design. To ensure diversity of the resource usage patterns, we introduce a binding candidate formation method based on the orthogonal arrays. Additional control components are added to enable post manufacturing selection of one of the binding candidates. The resource binding candidate that minimizes the power consumption is selected by considering the specific power characteristics of each chip. An efficient methodology for embedding several binding candidates in one design is developed. Evaluations on benchmark designs show the low overhead and the effectiveness of the proposed methods. As an example, applying our method results in an average of 14.2% (up to 24.0%) power savings on benchmark circuits for a variation model in 45nm CMOS technology. The power efficiency of our customized postsilicon binding is expected to improve with scaling of the technology and the likely resulting higher process variations.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2024735290",
    "type": "article"
  },
  {
    "title": "<i>Ordering</i> circuit establishment in multiplane NoCs",
    "doi": "https://doi.org/10.1145/2500752",
    "publication_date": "2013-10-01",
    "publication_year": 2013,
    "authors": "Ahmed Abousamra; Alex K. Jones; Rami Melhem",
    "corresponding_authors": "",
    "abstract": "Segregating networks-on-chips (NoCs) into data and control planes yields several opportunities for improving power and performance in chip-multiprocessor systems (CMPs). This article describes a hybrid packet/circuit switched multiplane network optimized to reduce latency in order to improve system performance and/or reduce system energy. Unlike traditional circuit preallocation techniques which require timestamps to reserve circuit resources, this article proposes an order-based preallocation scheme . By enforcing the order in which resources are scheduled and utilized rather than a fixed time, the NoC can take advantage of messages that arrive early while naturally tolerating message delays due to contention. Ordered circuit establishment is presented using two techniques. First, Déjà Vu switching preestablishes circuits for data messages once a cache hit is detected and prior to the requested data becoming available. Second, using Red Carpet Routing , circuits are proactively reserved for a return data message as a request message traverses the NoC. The reduced communication latency over configured circuits enable system performance improvement or saving NoC energy by reducing voltage and frequency without sacrificing performance. In simulations of 16 and 64 core CMPs, Déjà Vu switching enabled average NoC energy savings of 43% and 53% respectively. On the other hand, simulations of communication sensitive benchmarks using Red Carpet Routing show speedup in execution time of up to 16%, with an average of 10% over a purely packet switched NoC and an average of 8% over preconfiguring circuits using Déjà Vu switching .",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2025823997",
    "type": "article"
  },
  {
    "title": "Concurrency-aware compiler optimizations for hardware description languages",
    "doi": "https://doi.org/10.1145/2390191.2390201",
    "publication_date": "2013-01-01",
    "publication_year": 2013,
    "authors": "Kalyan Saladi; Harikumar Somakumar; Mahadevan Ganapathi",
    "corresponding_authors": "",
    "abstract": "In this article, we discuss the application of compiler technology for eliminating redundant computation in hardware simulation. We discuss how concurrency in hardware description languages (HDLs) presents opportunities for expression reuse across different threads. While accounting for discrete event simulation semantics, we extend the data flow analysis framework to concurrent threads. In this process, we introduce a rewriting scheme named ∂VF and a graph representation to model sensitivity relationships among threads. An algorithm for identifying common subexpressions as applied to HDLs is presented. Related issues, such as scheduling correctness, are also considered.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2032165755",
    "type": "article"
  },
  {
    "title": "A full lifecycle performance verification methodology for multicore systems-on-chip",
    "doi": "https://doi.org/10.1145/2209291.2209294",
    "publication_date": "2012-06-01",
    "publication_year": 2012,
    "authors": "Jim Holt; Jaideep Dastidar; David Lindberg; John Pape; Peng Yang",
    "corresponding_authors": "",
    "abstract": "Multicore Systems-on-Chip (MCSoC) are comprised of a rich set of processor cores, specialized hardware accelerators, and I/O interfaces. Functional verification of these complex designs is a critical and demanding task, however, focusing only on functional verification is very risky because the motivation for building such systems in the first place is to achieve high levels of system throughput. Therefore a functionally correct MCSoC that does not exhibit sufficient performance will fail in the market. In addition, limiting performance verification efforts to analyzing individual system components in isolation is insufficient due to: (1) the degree of system-level resource contention that an application domain imposes on the MCSoC, and (2) the degree of configuration flexibility that is typically afforded by an MCSoC. These factors motivate system-level performance verification of MCSoC. This article presents an important industrial case study of MCSoC performance verification involving both pre- and postsilicon analysis, highlighting the methodology used, the lessons learned, and recommendations for improvement.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2033855210",
    "type": "article"
  },
  {
    "title": "GALS-Designer",
    "doi": "https://doi.org/10.1145/2003695.2003699",
    "publication_date": "2011-10-01",
    "publication_year": 2011,
    "authors": "Wei-Tsun Sun; Zoran Salčić",
    "corresponding_authors": "",
    "abstract": "GALS-Designer is a framework for the design of software systems which comply with the formal Globally Asynchronous Locally Synchronous model of computation (GALS). Those systems consist of single or multiple GALS programs and their immediate environment, which can be other programs and any other modules described in SystemC. The framework integrates our libGALS library for writing GALS programs and SystemC. It enables modeling and simulation of single and multiple GALS programs within the single SystemC executable model on the host (simulation) operating system. The same GALS programs can then be run without SystemC on a target operating system for which the libGALS runtime library is available. The use of the GALS-Designer is demonstrated on an example of a complex embedded system. As libGALS can execute on multiprocessor platforms both the simulation and target models of the GALS system can take advantage of multiprocessor and multicore systems, which is not possible when using standard SystemC. Results of running simulation models of GALS programs demonstrate simulation performance improvement when executing on multicore platforms.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2045792879",
    "type": "article"
  },
  {
    "title": "Migration-Resistant Policies for Probe-Wear Leveling in MEMS Storage Devices",
    "doi": "https://doi.org/10.1145/2348839.2348853",
    "publication_date": "2012-10-01",
    "publication_year": 2012,
    "authors": "Mohammed G. Khatib",
    "corresponding_authors": "Mohammed G. Khatib",
    "abstract": "Probes (read/write heads) in a MEMS storage device are susceptible to wear. We study probe wear, and analyze the causes of uneven wear. We show that under real-world workloads some probes can wear one order of magnitude faster than others. This premature expiry has severe consequences for reliability, timing performance, energy efficiency, and lifetime. Wear leveling precludes premature expiry and is thus necessary. We discuss the fundamental differences between probe wear in MEMS storage and medium wear in Flash, calling for a different treatment. We devise three policies to level probe wear. The policies provide a spectrum between best lifetime and least influence on the response time and energy efficiency of a MEMS storage device. We make the case that data migration can be prevented by augmenting the policies with a simple rule. We study the influence of the data layout configuration on the leveling performance of the policies.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2071871407",
    "type": "article"
  },
  {
    "title": "Model-driven automation for simulation-based functional verification",
    "doi": "https://doi.org/10.1145/2209291.2209304",
    "publication_date": "2012-06-01",
    "publication_year": 2012,
    "authors": "Éamonn Linehan; Eamonn O'Toole; Siobhàn Clarke",
    "corresponding_authors": "",
    "abstract": "Developing testbenches for dynamic functional verification of hardware designs is a software-intensive process that lies on the critical path of electronic system design. The increasing capabilities of electronic components is contributing to the construction of complex verification environments that are increasingly difficult to understand, maintain, extend, and reuse across projects. Model-driven software engineering addresses issues of complexity, productivity, and code quality through the use of high-level system models and subsequent automatic transformations. Reasoning about verification testbench decomposition becomes simpler at higher levels of abstraction. In particular, the aspect-oriented paradigm, when applied at the model level, can minimize the overlap in functionality between modules, improving maintainability and reusability. This article presents an aspect-oriented model-driven engineering process and toolset for the development of hardware verification testbenches. We illustrate how this process and toolset supports modularized design and automatic transformation to verification environment-specific models and source code through an industry case study.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2079417464",
    "type": "article"
  },
  {
    "title": "MicroFix",
    "doi": "https://doi.org/10.1145/1929943.1929948",
    "publication_date": "2011-03-01",
    "publication_year": 2011,
    "authors": "Guihai Yan; Yinhe Han; Hui Liu; Xiaoyao Liang; Xiaowei Li",
    "corresponding_authors": "",
    "abstract": "Traditional DVFS schemes are oblivious to fine-grained adaptability resulting from path-grained timing imbalance. With the awareness of such fine-grained adaptability, better power-performance efficiency can be obtained. We propose a new scheme, MicroFix, to exploit such fine-grained adaptability. We first show the potential resulted from the path-grained timing imbalance and then present a new technique, Timing Interpolation, to reap the fine-grained adaptability for power reduction. Moreover, to eliminate the conservative margins of traditional DVFS, unlike the previous approaches such as Razor that reactively handle the delay errors (induced by aggressively scaled voltage/frequcncy) by enabling error detection and recovery, we propose a proactive approach by error prediction, thereby obviate the high-cost recovery routines. MicroFix was evaluated based on ISCAS89 benchmarks and the floating-point unit adopted by OpenSPARC T1 processor. Compared to ideal traditional DVFS schemes, the experimental results show that for most of the evaluated circuits, MicroFix can help saving up to 20% power consumption without compromising with frequency, at the expense of less than 5% area overhead. Compared to nonideal DVFS schemes (with 10% voltage margin), the power reduction can even reach up to 38% on average.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2102781011",
    "type": "article"
  },
  {
    "title": "A fast heuristic approach for parametric yield enhancement of analog designs",
    "doi": "https://doi.org/10.1145/2209291.2209308",
    "publication_date": "2012-06-01",
    "publication_year": 2012,
    "authors": "Chien‐Nan Jimmy Liu; Yen‐Lung Chen; Chin-Cheng Kuo; I-Ching Tsai",
    "corresponding_authors": "",
    "abstract": "In traditional yield enhancement approaches, a lot of computation efforts have to be paid first to find the feasible regions and the Pareto fronts, which will become a heavy cost for large analog circuits. In order to reduce the computation efforts, this article proposes a fast heuristic approach that tries to finish all iteration steps of the yield enhancement flow at behavior level. First, a novel force-directed Nominal Point Moving (NPM) algorithm is proposed to find a better nominal point without building the feasible regions. Then, an equation-based behavior-level sizing approach is proposed to map the NPM results at performance level to behavior-level parameters. A fast behavior-level Monte Carlo simulation is also proposed to shorten the iterative yield enhancement flow. Finally, using the obtained behavioral parameters as the sizing targets of each subblock, the device sizing time is significantly reduced instead of sizing from the system-level specifications directly. As demonstrated on several analog circuits, this heuristic approach could be another efficient methodology to help designers improve their analog circuits toward better yield.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2155751543",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2541012",
    "publication_date": "2013-10-01",
    "publication_year": 2013,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Reducing energy consumption in multiprocessor systems-on-chip (MPSoCs) where communication happens via the network-on-chip (NoC) approach calls for multiple voltage/frequency island (VFI)-based designs. In turn, such multi-VFI architectures need ...",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4233935325",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2159542",
    "publication_date": "2012-04-01",
    "publication_year": 2012,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "In this article, we propose an extended SystemC framework that directly enables software simulation in SystemC. Although SystemC has been widely adopted for system-level simulation of hardware designs nowadays, to complete HW/SW co-simulation, it still ...",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4238649083",
    "type": "paratext"
  },
  {
    "title": "Algorithms to compute bridging fault coverage of<i><b>I</b><sub>DDQ</sub></i>test sets",
    "doi": "https://doi.org/10.1145/264995.264999",
    "publication_date": "1997-07-01",
    "publication_year": 1997,
    "authors": "Paul J. Thadikaran; Sreejit Chakravarty; J.H. Patel",
    "corresponding_authors": "",
    "abstract": "We present two algorithms, called list-based scheme and tree-based scheme, to compute bridging fault (BF) coverage of I DDQ tests. These algorithms use the novel ideal of “indistinguishable pairs,” which makes it more efficient and versatile than known fault simulation algorithms. Unlike known algorithms, the two algorithms can be used for combinational as well as sequential circuits and for arbitrary sets of BFs. Experiments show that the tree-based scheme is, in general, better than the list-based scheme. But the list-based scheme is better for some classes of faults.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2005388837",
    "type": "article"
  },
  {
    "title": "Optimal folding of standard and custom cells",
    "doi": "https://doi.org/10.1145/225871.225897",
    "publication_date": "1996-01-01",
    "publication_year": 1996,
    "authors": "V. Thanvantri; Sartaj Sahni",
    "corresponding_authors": "",
    "abstract": "We study the problem of folding an ordered list of standard and custom cells into rows of a chip so as to minimize either the routing area or the total chip area. Nine versions of the folding problem are formulated and fast polynomial time algorithms are obtained for each. Two of our formulations correspond to problems formulated in Paik and Sahni [1993] for the folding of a stack of bit-slice components. Our algorithms for these two formulations are asymptotically superior to those of Paik and Sahni [1993].",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2036920100",
    "type": "article"
  },
  {
    "title": "Functional design for testability of control-dominated architectures",
    "doi": "https://doi.org/10.1145/253052.253064",
    "publication_date": "1997-04-01",
    "publication_year": 1997,
    "authors": "Franco Fummi; U. Rovati; Donatella Sciuto",
    "corresponding_authors": "",
    "abstract": "Control-dominated architectures are usually described in a hardware description language (HDL) by means of interacting FSMs. A VHDL or Verilog specification can be translated into an interacting FSM (IFSM) representation as described here. The IFSM model allows us to approach the testable synthesis problem at the level of each FSM. The functionality is modified by the addition of transparency to data flow. The complete testability of the IFSM implementation is thus achieved by connecting fully testable implementations of each modified FSM. In this way, test sequences separately generated for each FSM are directly applied to the IFSM to achieve complete fault coverage. The addition of test functionality to each FSM description, and its simultaneous synthesis with the FSM functionality, produces a lower area overhead than that necessary for the application of a partial-scan technique. Moreover, the test generation problem is highly simplified since it is reduced to the test generation for each separate FSM.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2091913526",
    "type": "article"
  },
  {
    "title": "Logic transformation for low-power synthesis",
    "doi": "https://doi.org/10.1145/544536.544539",
    "publication_date": "2002-04-01",
    "publication_year": 2002,
    "authors": "K. W. Kim; Taewhan Kim; TingTing Hwang; Sung-Mo Kang; C. L. Liu",
    "corresponding_authors": "",
    "abstract": "In this article we present a new approach to the problem of local logic transformation for reducing power dissipation in logic circuits. The proposed approach overcomes one of the critical limitations common to the previous approaches of local logic transformations for low power, namely, a sequential greedy transformation that identifies signals with high switching activities and then resynthesizes the signals one by one. Instead, we identify a set of signal lines as a group for logic transformation, and determine an order of transformation of the signals with the maximum reduction of power dissipation in the circuit. As a practically feasible solution to this problem, we develop a power model called a finite state input transition (FIT) model, which allows the efficient measurement of the change of power dissipation of the circuit for every possible sequence of logic transformations among the signal lines. Experimental results show that the proposed approach performs an extensive local logic transformation, reducing power consumption by 33% on average without any increase of circuit delay.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2099833794",
    "type": "article"
  },
  {
    "title": "Effective congestion reduction for IC package substrate routing",
    "doi": "https://doi.org/10.1145/1754405.1754412",
    "publication_date": "2010-05-01",
    "publication_year": 2010,
    "authors": "Shenghua Liu; Guoqiang Chen; Tom Tong Jing; Lei He; Robi Dutta; Xianlong Hong",
    "corresponding_authors": "",
    "abstract": "Off-chip substrate routing for high-density packages is challenging due to requirements such as high density, lack of vertical detour, non-Manhattan routing, and primarily planar routing. The existing substrate routing algorithms often result in a large number of unrouted nets that have to be routed manually. This article develops an effective yet efficient diffusion-driven method D-Router to reduce congestion. Starting with an initial routing, we develop an effective diffusion-based congestion reduction. We iteratively find a congested window and spread out connections to reduce congestion inside the window by a simulated diffusion process based on the duality between congestion and concentration. The window is released after the congestion is eliminated. Compared with the state-of-the-art substrate routing method that leads to 480 nets unrouted for ten industrial designs with a total of 6415 nets, the D-Router reduces the amount of unrouted nets to 104, a reduction to the 4.6 multiple. In addition, the D-Router obtains a similar reduction on unrouted nets but runs up to 94 times faster when compared with a negotiation-based substrate routing.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2004186266",
    "type": "article"
  },
  {
    "title": "ACM Transactions on Design Automation of Electronic Systems (TODAES) special section call for papers",
    "doi": "https://doi.org/10.1145/1640457.1640466",
    "publication_date": "2009-12-01",
    "publication_year": 2009,
    "authors": "Kurt Keutzer; Peng Li; Li Shang; Hai Zhou",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2026122999",
    "type": "paratext"
  },
  {
    "title": "Reducing fault dictionary size for million-gate large circuits",
    "doi": "https://doi.org/10.1145/1497561.1497570",
    "publication_date": "2009-03-01",
    "publication_year": 2009,
    "authors": "Yu-Ru Hong; Juinn-Dar Huang",
    "corresponding_authors": "",
    "abstract": "In general, fault dictionary is prevented from practical applications in fault diagnosis due to its extremely large size. Several previous works are proposed for the fault dictionary size reduction. However, some of them fail to bring down the size to an acceptable level, and others might not be able to handle today's million-gate circuits due to their high time and space complexity. In this article, an algorithm is presented to reduce the size of pass-fail dictionary while still preserving high diagnostic resolution. The proposed algorithm possesses low time and space complexity by avoiding constructing the huge distinguishability table, which inevitably boosts up the required computation complexity. Experimental results demonstrate that the proposed algorithm is capable of handling industrial million-gate large circuits in a reasonable amount of runtime and memory.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2080655584",
    "type": "article"
  },
  {
    "title": "Serialized parallel code generation framework for MPSoC",
    "doi": "https://doi.org/10.1145/1698759.1698761",
    "publication_date": "2010-02-01",
    "publication_year": 2010,
    "authors": "Seongnam Kwon; Soonhoi Ha",
    "corresponding_authors": "",
    "abstract": "The models of computations that express concurrency naturally are preferred for initial specification of MPSoC system, since popular programming languages such as C and C++ are designed for sequential execution. In our previous work, we proposed a design framework where two models are used for the initial specification of the system behavior; task model at the top level and dataflow model inside each task. After the partition and mapping process is performed with each architecture candidate, the target code is automatically generated for both Design-Space Exploration (DSE) and final implementation. In this article, we focus on parallel code generation for MPSoC, proposing two main techniques. The first is to express functional and data parallelism differently following the partition and mapping decision. In the proposed technique, the generated code consists of multiple tasks running concurrently, which achieves functional parallelism. On the other hand, we use OpenMP directives to express data parallelism inside a task. Second is to adopt the code serialization technique to execute a multitasking application without OS scheduler, aiming to generate the highly portable code on various platforms for an efficient DSE process. We extend the previous code serialization techniques to multiprocessor systems and utilize the formal properties of the dataflow model for efficient code generation. The experiments including H.263 codec example show the viability of the proposed technique and the efficiency of the generated code.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2100335090",
    "type": "article"
  },
  {
    "title": "Layer Assignment of Escape Buses with Consecutive Constraints in PCB Designs",
    "doi": "https://doi.org/10.1145/3012010",
    "publication_date": "2017-03-10",
    "publication_year": 2017,
    "authors": "Jin-Tai Yan",
    "corresponding_authors": "Jin-Tai Yan",
    "abstract": "It is important for cost and reliability consideration to minimize the number of the used layers in a PCB design. In this article, given a set of n circular escape buses with their escape directions between two adjacent components and a set of m consecutive constraints on the escape buses, the problem of assigning the given escape buses between two adjacent components onto the minimized layers is first formulated for bus-oriented escape routing. Furthermore, an efficient approach is proposed to minimize the number of the used layers for the given escape buses with the consecutive constraints and assign the escape buses onto the available layers. Compared with Yan's approach [Yan and Chen 2012] for the layer assignment of the linear escape buses with no consecutive constraint and Ma's approach [Ma et al. 2011a] for the layer assignment of the circular escape buses with consecutive constraints, the experimental results show that the proposed approach obtains the same optimal results on the number of the used layers and reduces 43.6% and 90.5% of CPU time for the tested examples on the average, respectively.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2595900504",
    "type": "article"
  },
  {
    "title": "Leak Stopper",
    "doi": "https://doi.org/10.1145/3015770",
    "publication_date": "2017-03-10",
    "publication_year": 2017,
    "authors": "Yin-Chi Peng; Chien-Chih Chen; Hsiang-Jen Tsai; Keng-Hao Yang; Pei-Zhe Huang; Shih-Chieh Chang; Wen-Ben Jone; Tien-Fu Chen",
    "corresponding_authors": "",
    "abstract": "To alleviate high energy dissipation of unnecessary snooping accesses, snoop filters have been designed to reduce snoop lookups. These filters have the problem of decreasing filtering efficiency, and thus usually rely on partial or whole filter reset by detecting block evictions. Unfortunately, the reset conditions occur infrequently or unevenly (called passive filter deletion ). This work proposes the concept of revitalized snoop filter (RSF) design, which can actively renew the destination filter by employing a generation wrapping-around scheme for various reference behaviors. We further utilize a sampling mechanism for RSF to timely trigger precise filter revitalizations, so that unnecessary RSF flushing can be minimized. The proposed RSF can be integrated to various existent inclusive snoop filters with only a minor change to their designs. We evaluate our proposed design and demonstrate that RSF eliminates 58.6% of snoop energy compared to JETTY on average while inducing only 6.5% of revitalization energy overhead. In addition, RSF eliminates 45.5% of snoop energy compared to stream registers on average and only induces 2.5% of revitalization energy overhead. Overall, these RSFs reduce the total L2 cache energy consumption by 52.1% (58.6% -- 6.5%) as compared to JETTY and by 43% (45.5% -- 2.5%) as compared to stream registers. Furthermore, RSF improves the overall performance by 1% to 1.4% on average compared to JETTY and stream registers for various benchmark suites.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2596527186",
    "type": "article"
  },
  {
    "title": "A Comprehensive BIST Solution for Polar Transceivers Using On-Chip Resources",
    "doi": "https://doi.org/10.1145/3084689",
    "publication_date": "2017-08-01",
    "publication_year": 2017,
    "authors": "Jae Woong Jeong; Vishwanath Natarajan; Shreyas Sen; TM Mak; Jennifer Kitchen; Sule Ozev",
    "corresponding_authors": "",
    "abstract": "This article presents a Built-in self-test (BIST) solution for polar transceivers with low cost and high accuracy. Radio frequency (RF) Polar transceivers are desirable for portable devices due to higher power efficiency compared to traditional RF Cartesian transceivers. Unfortunately, their design is quite challenging due to substantially different signal paths that need to work coherently to ensure signal quality. In the receiver, phase and gain mismatches degrade sensitivity and error vector magnitude. In the transmitter, delay skew between the envelope and phase signals and the finite envelope bandwidth can create intermodulation distortion, which leads to violation of spectral mask requirements. Typically, these parameters are not directly measured but calibrated through spectral analysis using expensive RF equipment, leading to lengthy and costly measurement/calibration cycles. However, characterization and calibration of these parameters with analytical model would reduce the test time and cost considerably. In this article, we propose a technique to measure with the intent to calibrate impairments of the polar transceiver in the loop-back mode. Simulation and hardware measurement results show that the proposed technique can characterize the targeted impairments accurately.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2740964443",
    "type": "article"
  },
  {
    "title": "C-Mine",
    "doi": "https://doi.org/10.1145/3144534",
    "publication_date": "2017-11-29",
    "publication_year": 2017,
    "authors": "Chen-Hsuan Lin; Lu Wan; Deming Chen",
    "corresponding_authors": "",
    "abstract": "The better-than-worst-case (BTW) design methodology can achieve higher circuit energy efficiency, performance, or reliability by allowing timing errors for rare cases and rectifying them with error correction mechanisms. Therefore, the performance of BTW design heavily depends on the correctness of common cases, which are frequent input patterns in a workload. However, most existing methods do not provide sufficiently scalable solutions and also overlook the whole picture of the design. Thus, we propose a new technique, common-case mining method (C-Mine), which combines two scalable techniques, data mining and Boolean satisfiability (SAT) solving, to overcome these limitations. Data mining can efficiently extract patterns from an enormous dataset, and SAT solving is famous for its scalable verification. In this article, we present two versions of C-Mine, C-Mine-DCT and C-Mine-APR, which aim at faster runtime and better energy saving, respectively. The experimental results show that, compared to a recent publication, C-Mine-DCT can achieve compatible performance with an additional 8% energy savings and 54x speedup for bigger benchmarks on average. Furthermore, C-Mine-APR can achieve up to 13% more energy saving than C-Mine-DCT while confronting designs with more common cases.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2769752062",
    "type": "article"
  },
  {
    "title": "Efficient equivalence checking of multi-phase designs using phase abstraction and retiming",
    "doi": "https://doi.org/10.1145/296333.296348",
    "publication_date": "1998-10-01",
    "publication_year": 1998,
    "authors": "Gagan Hasteer; Anmol Mathur; P. Bannerjee",
    "corresponding_authors": "",
    "abstract": "Equivalence checking of finite state machines (FSMs) traditionally assumes single phase machines where a single clock (implicit or explicit) synchronizes the state of the FSM. We extend the equivalence checking paradignm to FSMs with multi-phase clocks. Such designs are becoming increasingly popular in high performance microprocessors since they result in lower synchronization overhead. In addition, aggressive pipelining and the use of “sparse” encodings results in designs where the ratio of steady states to the total state space is very low. In this paper, we show that automatically transforming such designs to ones that have more “dense” encodings can result in significant benefits in using implicit BDD-based techniques for their verification. We explore two such techniques: phase abstraction and retiming and demonstrate their utility in the context of FSM equivalence checking. The main contributions of our work are: —We show that a multi-phase FSM can be transformed to a functionally equivalent one phase FSM and this phase abstraction leads to significant improvement in the size of FSMs that can be checked for equivalence. —We show that min-latch retiming preserves equivalence and can be performed efficiently in multi-phase designs, even when latch borrowing and discarding is allowed at the primary inputs and outputs. —We demonstrate the utility of our approach on several controller FSMs from the industry.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2001953066",
    "type": "article"
  },
  {
    "title": "Cluster-cover",
    "doi": "https://doi.org/10.1145/270580.270584",
    "publication_date": "1998-01-01",
    "publication_year": 1998,
    "authors": "C.‐J. Richard Shi; Janusz Brzozowski",
    "corresponding_authors": "",
    "abstract": "This article introduces a mathematical framework called cluster-cover. We show that this framework captures the combinatorial structure of a class of VLSI design optimization problems, including two-level logic minimization, constrained encoding, multilayer topological planar routing, application timing assignment for delay-fault testing, and minimization of monitoring logic for BIST enchancement. These apparently unrelated problems can all be cast into two metaproblems in our framework: finding a maximum cluster and finding a minimum cover. We describe paradigms for developing algorithms for these problems. First, a simple heuristic called greedy peeling is presented and characterized. We derive sufficient conditions that guarantee optimum solutions by greedy peeling. We generalize the performance analysis of a multilayer topological planar routing heuristic to greedy peeling for the general cluster-cover problems. We propose a performance bound of greedy set covering that can be computed efficiently for a given problem instance; this bound is much tighter than the previously known bounds. Second, prime covering—orignally developed for logic minimization—is generalized to finding exact solutions for cluster-cover problems. Previously, only the connection between logic minimizaton and constrained encoding was known.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2014706585",
    "type": "article"
  },
  {
    "title": "Power optimization using divide-and-conquer techniques for minimization of the number of operations",
    "doi": "https://doi.org/10.1145/323480.323489",
    "publication_date": "1999-10-01",
    "publication_year": 1999,
    "authors": "Inki Hong; Miodrag Potkonjak; Ramesh Karri",
    "corresponding_authors": "",
    "abstract": "We introduce an approach for power optimization using a set of compilation and architectural techniques. The key technical innovation is a novel divide-and-conquer compilation technique to minimize the number of operations for general computations. Our technique optimizes not only a significantly wider set of computations than the previously published techniques, but also outperforms (or performs at least as well as other techniques) on all examples. Along the architectural dimension, we investigate coordinated impact of compilation techniques on the number of processors which provide optimal trade-off between cost and power. We demonstrate that proper compilation techniques can significantly reduce power with bounded hardware cost. The effectiveness of all techniques and algorithms is documented on numerous real-life designs.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2107069695",
    "type": "article"
  },
  {
    "title": "Path delay fault testing using test points",
    "doi": "https://doi.org/10.1145/606603.606604",
    "publication_date": "2003-01-01",
    "publication_year": 2003,
    "authors": "Spyros Tragoudas; Nathan Denny",
    "corresponding_authors": "",
    "abstract": "Inserting controllable/observable points in the test architecture has been shown to be a viable method for reducing the number of path delay faults that need to be tested in a circuit. In order to have a minimal impact on the operation clock and more accuracy in testing, it is proposed that test points should be inserted with the additional constraint that every path has a bounded number of test points. A polynomial time solvable integer linear programming (ILP) formulation serves as the basis for the presented test placement methodology. Due to the ILP's global optimization property we achieve results that are comparable to those by an existing greedy technique for the less constrained test point placement problem.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2012025797",
    "type": "article"
  },
  {
    "title": "A data acquisition methodology for on-chip repair of embedded memories",
    "doi": "https://doi.org/10.1145/944027.944037",
    "publication_date": "2003-10-01",
    "publication_year": 2003,
    "authors": "D. Niggemeyer; E.M. Rudnick",
    "corresponding_authors": "",
    "abstract": "Systems-on-Chips often contain a large amount of embedded memory. In order to obtain sufficiently high yield, efficient diagnosis and repair facilities are needed for the memories. A novel and efficient approach for collecting complete failure data during on-chip memory testing is proposed that can be combined with a row/column reconfiguration algorithm for complete on-chip memory repair. A sequence of diagnostic tests of linear order is utilized that detects and localizes all cells involved in single-cell faults and two-cell coupling faults, such as idempotent coupling faults, and provides this information to on-chip circuitry for memory repair. Failure data are collected at the operating speed of the memory-under-test so that tests can be applied at speed. The data acquisition circuitry evaluates the test results and classifies faults as column failures, coupling faults, or single-cell faults for near-optimal allocation of spare resources. The proposed test and data acquisition algorithm can be realized as compact Built-In Self-Test (BIST) circuitry using standard design libraries.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2015754562",
    "type": "article"
  },
  {
    "title": "Design Automation for Tree-based Nearest Neighborhood–aware Placement of High-speed Cellular Automata on FPGA with Scan Path Insertion",
    "doi": "https://doi.org/10.1145/3446206",
    "publication_date": "2021-04-22",
    "publication_year": 2021,
    "authors": "Ayan Palchaudhuri; Sandeep Sharma; Anindya Sundar Dhar",
    "corresponding_authors": "",
    "abstract": "Cellular Automata (CA) is attractive for high-speed VLSI implementation due to modularity, cascadability, and locality of interconnections confined to neighboring logic cells. However, this outcome is not easily transferable to tree-structured CA, since the neighbors having half and double the index value of the current CA cell under question can be sufficiently distanced apart on the FPGA floor. Challenges to meet throughput requirements, seamlessly translate algorithmic modifications for changing application specifications to gate level architectures and to address reliability challenges of semiconductor chips are ever increasing. Thus, a proper design framework assisting automation of synthesizable, delay-optimized VLSI architecture descriptions facilitating testability is desirable. In this article, we have automated the generation of hardware description of tree-structured CA that includes a built-in scan path realized with zero area and delay overhead. The scan path facilitates seeding the CA, state modification, and fault localization on the FPGA fabric. Three placement algorithms were proposed to ensure maximum physical adjacency amongst neighboring CA cells, arranged in a multi-columnar fashion on the FPGA grid. Our proposed architectures outperform implementations arising out of standard placers and behavioral designs, existing tree mapping strategies, and state-of-the-art FPGA centric error detection architectures in area and speed.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W3157536469",
    "type": "article"
  },
  {
    "title": "QuadSeal: Quadruple Balancing to Mitigate Power Analysis Attacks with Variability Effects and Electromagnetic Fault Injection Attacks",
    "doi": "https://doi.org/10.1145/3443706",
    "publication_date": "2021-06-05",
    "publication_year": 2021,
    "authors": "Darshana Jayasinghe; Aleksandar Ignjatović; Roshan Ragel; Jude Angelo Ambrose; Sri Parameswaran",
    "corresponding_authors": "",
    "abstract": "Side channel analysis attacks employ the emanated side channel information to deduce the secret keys from cryptographic implementations by analyzing the power traces during execution or scrutinizing faulty outputs. To be effective, a countermeasure must remove or conceal as many as possible side channels. However, many of the countermeasures against side channel attacks are applied independently. In this article, the authors present a novel countermeasure (referred to as QuadSeal ) against Power Analysis Attacks and Electromagentic Fault Injection Attacks (FIAs), which is an extension of the work proposed in Reference [27]. The proposed solution relies on algorithmically balancing both Hamming distances and Hamming weights (where the bit transitions on the registers and gates are balanced, and the total number of 1s and 0s are balanced) by the use of four identical circuits with differing inputs and modified SubByte tables. By randomly rotating the four encryptions, the system is protected against variations, path imbalances, and aging effects. After generating the ciphertext, the output of each circuit is compared against each other to detect any fault injections or to correct the faulty ciphertext to gain reliability. The proposed countermeasure allows components to be switched off to save power or to run four executions in parallel for high performance when resistance against power analysis attacks is not of high priority, which is not available with the existing countermeasures (except software based where source code can be changed). The proposed countermeasure is implemented for Advanced Encryption Standard (AES) and tested against Correlation Power Analysis and Mutual Information Attacks attacks (for up to a million traces), and none of the secret keys was found even after one million power traces (the unprotected AES circuit is vulnerable for power analysis attacks within 5,000 power traces). A detection circuit (referred to as C-FIA circuit) is operated using the algorithmic redundancy presented in four circuits of QuadSeal to mitigate Electromagnetic Fault Injection Attacks. Using Synopsys PrimeTime, we measured the power dissipation of QuadSeal registers and XOR gates to test the effectiveness of Quadruple balancing methodology. We tested the QuadSeal countermeasure with C-FIA circuit against Differential Fault Analysis Attacks up to one million traces; no bytes of the secret key were found. This is the smallest known circuit that is capable of withstanding power-based side channel attacks when electromagnetic injection attack resistance, process variations, path imbalances, and aging effects are considered.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W3171880430",
    "type": "article"
  },
  {
    "title": "An Adaptive Application Framework with Customizable Quality Metrics",
    "doi": "https://doi.org/10.1145/3477428",
    "publication_date": "2021-11-02",
    "publication_year": 2021,
    "authors": "Liu Liu; Sibren Isaacman; Ulrich Kremer",
    "corresponding_authors": "",
    "abstract": "Many embedded environments require applications to produce outcomes under different, potentially changing, resource constraints. Relaxing application semantics through approximations enables trading off resource usage for outcome quality. Although quality is a highly subjective notion, previous work assumes given, fixed low-level quality metrics that often lack a strong correlation to a user’s higher-level quality experience. Users may also change their minds with respect to their quality expectations depending on the resource budgets they are willing to dedicate to an execution. This motivates the need for an adaptive application framework where users provide execution budgets and a customized quality notion. This article presents a novel adaptive program graph representation that enables user-level, customizable quality based on basic quality aspects defined by application developers. Developers also define application configuration spaces, with possible customization to eliminate undesirable configurations. At runtime, the graph enables the dynamic selection of the configuration with maximal customized quality within the user-provided resource budget. An adaptive application framework based on our novel graph representation has been implemented on Android and Linux platforms and evaluated on eight benchmark programs, four with fully customizable quality. Using custom quality instead of the default quality, users may improve their subjective quality experience value by up to 3.59×, with 1.76× on average under different resource constraints. Developers are able to exploit their application structure knowledge to define configuration spaces that are on average 68.7% smaller as compared to existing, structure-oblivious approaches. The overhead of dynamic reconfiguration averages less than 1.84% of the overall application execution time.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W3208403752",
    "type": "article"
  },
  {
    "title": "Plasticine: A Cross-layer Approximation Methodology for Multi-kernel Applications through Minimally Biased, High-throughput, and Energy-efficient SIMD Soft Multiplier-divider",
    "doi": "https://doi.org/10.1145/3486616",
    "publication_date": "2021-11-02",
    "publication_year": 2021,
    "authors": "Zahra Ebrahimi; Dennis Klar; Mohammad Aasim Ekhtiyar; Akash Kumar",
    "corresponding_authors": "",
    "abstract": "The rapid evolution of error-resilient programs intertwined with their quest for high throughput has motivated the use of Single Instruction, Multiple Data (SIMD) components in Field-Programmable Gate Arrays (FPGAs). Particularly, to exploit the error-resiliency of such applications, Cross-layer approximation paradigm has recently gained traction, the ultimate goal of which is to efficiently exploit approximation potentials across layers of abstraction. From circuit- to application-level, valuable studies have proposed various approximation techniques, albeit linked to four drawbacks: First, most of approximate multipliers and dividers operate only in SISD mode. Second, imprecise units are often substituted, merely in a single kernel of a multi-kernel application, with an end-to-end analysis in Quality of Results (QoR) and not in the gained performance. Third, state-of-the-art (SoA) strategies neglect the fact that each kernel contributes differently to the end-to-end QoR and performance metrics. Therefore, they lack in adopting a generic methodology for adjusting the approximation knobs to maximize performance gains for a user-defined quality constraint. Finally, multi-level techniques lack in being efficiently supported, from application-, to architecture-, to circuit-level, in a cohesive cross-layer hierarchy. In this article, we propose Plasticine , a cross-layer methodology for multi-kernel applications, which addresses the aforementioned challenges by efficiently utilizing the synergistic effects of a chain of techniques across layers of abstraction. To this end, we propose an application sensitivity analysis and a heuristic that tailor the precision at constituent kernels of the application by finding the most tolerable degree of approximations for each of consecutive kernels, while also satisfying the ultimate user-defined QoR. The chain of approximations is also effectively enabled in a cross-layer hierarchy, from application- to architecture- to circuit-level, through the plasticity of SIMD multiplier-dividers, each supporting dynamic precision variability along with hybrid functionality. The end-to-end evaluations of Plasticine on three multi-kernel applications employed in bio-signal processing, image processing, and moving object tracking for Unmanned Air Vehicles (UAV) demonstrate 41%–64%, 39%–62%, and 70%–86% improvements in area, latency, and Area-Delay-Product (ADP), respectively, over 32-bit fixed precision, with negligible loss in QoR. To springboard future research in reconfigurable and approximate computing communities, our implementations will be available and open-sourced at https://cfaed.tu-dresden.de/pd-downloads.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W3210398271",
    "type": "article"
  },
  {
    "title": "Low test application time resource binding for behavioral synthesis",
    "doi": "https://doi.org/10.1145/1230800.1230808",
    "publication_date": "2007-04-01",
    "publication_year": 2007,
    "authors": "Mohammad Hosseinabady; Pejman Lotfi-Kamran; Zainalabedin Navabi",
    "corresponding_authors": "",
    "abstract": "Recent advances in process technology have led to a rapid increase in the density of integrated circuits (ICs). Increased density and the need to test for new types of defects in nanometer technologies have resulted in a tremendous increase in test application time (TAT). This article presents a test synthesis method to reduce test application time for testing the datapath of a design. The test application time is reduced by applying a test-time-aware resource sharing algorithm on a scheduled control data flow graph (CDFG) of a design.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W1979538201",
    "type": "article"
  },
  {
    "title": "Postplacement voltage assignment under performance constraints",
    "doi": "https://doi.org/10.1145/1367045.1367055",
    "publication_date": "2008-07-01",
    "publication_year": 2008,
    "authors": "Huaizhi Wu; Martin D. F. Wong; Wilsin Gosti",
    "corresponding_authors": "",
    "abstract": "Multi-Vdd is an effective method to reduce both leakage and dynamic power. A key challenge in a multi-Vdd design is to control the complexity of the power-supply system and limit the demand for level shifters. This can be tackled by grouping cells of different supply voltages into a small number of voltage islands. Recently, an elegant algorithm was proposed for generating voltage islands that balance the power-versus-design-cost tradeoff under performance requirement, according to the placement proximity of the critical cells. One prerequisite of this algorithm is an initial voltage assignment at the standard-cell level that meets timing. In this article, we present a novel method to produce quality voltage assignment which not only meets timing but also forms good proximity of the critical cells to provide a smooth input to the aforementioned voltage island generation. Our algorithm is based on effective delay budgeting and efficient computation of physical proximity by Voronoi diagram. Our extensive experiments on real industrial designs show that our algorithm leads to 25%--75% improvement in the voltage island generation in terms of the number of voltage islands generated, with computation time only linear to design size.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2022562040",
    "type": "article"
  },
  {
    "title": "A high-level clustering algorithm targeting dual V <sub>dd</sub> FPGAs",
    "doi": "https://doi.org/10.1145/1391962.1391965",
    "publication_date": "2008-09-01",
    "publication_year": 2008,
    "authors": "Rajarshi Mukherjee; Song Liu; Seda Öǧrenci Memik; Somsubhra Mondal",
    "corresponding_authors": "",
    "abstract": "Recent advanced power optimizations deployed in commercial FPGAs, laid out a roadmap towards FPGA devices that can be integrated into ultra low power systems. In this article, we present a high-level design tool to support the process of mapping an application onto a FPGA device with dual supply voltages. Our main contribution in this paper is an algorithm, which creates voltage scaling ready clusters by utilizing the timing slack available in the designs. We propose to first create clusters of CLBs within a given CLB-level netlist. This clustering algorithm intends to group chains of CLBs possessing similar amounts of timing slack along their critical path together. Once these clusters are identified, they are placed onto respective V dd partitions on the device. We have evaluated different dual V dd fabrics and the potential gain in power consumption is explored. When a subset of the logic blocks on the device can be driven by low V dd levels (either with a dedicated low V dd supply or with a programmable selection between low and high V dd levels for these blocks) this affects placement and routing. As a result the maximum frequency of the designs may be affected. In order to evaluate the overall impact of creating voltage islands, we measured the Energy-Delay Product for our benchmark designs. We observed that the Energy-Delay product can be decreased by 26.9% when the placement of the designs into different voltage levels is guided by our clustering algorithm.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2056400177",
    "type": "article"
  },
  {
    "title": "Scan-BIST based on cluster analysis and the encoding of repeating sequences",
    "doi": "https://doi.org/10.1145/1188275.1188279",
    "publication_date": "2007-01-01",
    "publication_year": 2007,
    "authors": "Lei Li; Zhong Lin Wang; Krishnendu Chakrabarty",
    "corresponding_authors": "",
    "abstract": "We present a built-in self-test (BIST) approach for full-scan designs that extracts the most frequently occurring sequences from deterministic test patterns. The extracted sequences are stored on-chip, and are used during test application. Three sets of test patterns are applied to the circuit under test during a BIST test session; these include pseudorandom patterns, semirandom patterns, and deterministic patterns. The semirandom patterns are generated based on the stored sequences and they are more likely to detect hard-to-detect faults than pseudorandom patterns. The deterministic patterns are encoded using either the stored sequences or the LFSR reseeding technique to reduce test data volume. We use the cluster analysis technique for sequence extraction to reduce the amount of data to be stored. Experimental results for the ISCAS-89 benchmark circuits show that the proposed approach often requires less on-chip storage and test data volume than other recent BIST methods.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2147240545",
    "type": "article"
  },
  {
    "title": "Optimizing wirelength and routability by searching alternative packings in floorplanning",
    "doi": "https://doi.org/10.1145/1297666.1297687",
    "publication_date": "2008-01-01",
    "publication_year": 2008,
    "authors": "Chiu‐Wing Sham; Evangeline F. Y. Young; Hai Zhou",
    "corresponding_authors": "",
    "abstract": "Recent advances in VLSI technology have made optimization of the interconnect delay and routability of a circuit more important. We should consider interconnect planning as early as possible. We propose a postfloorplanning step to reduce the interconnect cost of a floorplan by searching alternative packings. If a packing contains a rectangular bounding box of a group of modules, we can rearrange the blocks in the bounding box to obtain a new floorplan with the same area, but possibly with a smaller interconnect cost. Experimental results show that we can reduce the interconnect cost of a packing without any penalty in area.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2151244776",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1278349",
    "publication_date": "2007-09-01",
    "publication_year": 2007,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Improving logic capacity by time-sharing, dynamically reconfigurable Field Gate Programmable Arrays (FPGAs) are employed to handle designs of high complexity and functionality. In this paper, we use a novel graph-based topological floorplan ...",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4237262538",
    "type": "paratext"
  },
  {
    "title": "Area reduction by deadspace utilization on interconnect optimized floorplan",
    "doi": "https://doi.org/10.1145/1217088.1217091",
    "publication_date": "2007-01-01",
    "publication_year": 2007,
    "authors": "Chiu‐Wing Sham; Evangeline F. Y. Young",
    "corresponding_authors": "",
    "abstract": "Interconnect optimization has become the major concern in floorplanning. Many approaches would use simulated annealing (SA) with a cost function composed of a weighted sum of area, wirelength, and interconnect cost. These approaches can reduce the interconnect cost efficiently but the area penalty of the interconnect optimized floorplan is usually quite large. In this article, we propose an approach called deadspace utilization (DSU) to reclaim the unused area of an interconnect optimized floorplan by linear programming. Since modules are not necessarily rectangular in shape in floorplanning, some deadspace can be redistributed to the modules to increase the area occupied by each module. If the area of each module can be expanded by the same ratio, the whole floorplan can be compacted by that ratio to give a smaller floorplan. However, we will limit the compaction ratio to prevent overcongestion. Experiments show that we can apply this deadspace utilization technique to reduce the area and total wirelength of an interconnect optimized floorplan further while the routability can be maintained at the same time.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4244110453",
    "type": "article"
  },
  {
    "title": "Instruction set synthesis with efficient instruction encoding for configurable processors",
    "doi": "https://doi.org/10.1145/1217088.1217096",
    "publication_date": "2007-01-01",
    "publication_year": 2007,
    "authors": "Jongeun Lee; Ki‐Young Choi; Nikil Dutt",
    "corresponding_authors": "",
    "abstract": "Application-specific instructions can significantly improve the performance, energy-efficiency, and code size of configurable processors. While generating new instructions from application-specific operation patterns has been a common way to improve the instruction set (IS) of a configurable processor, automating the design of ISs for given applications poses new challenges---how to create as well as utilize new instructions in a systematic manner, and how to choose the best set of application-specific instructions considering the various effects the new instructions may have on the data path and the compilation? To address these problems, we present a novel IS synthesis framework that optimizes the IS through an efficient instruction encoding for the given application as well as for the given data path architecture. We first build a library of new instructions created with various encoding alternatives taking into account the data path architecture constraints, and then select the best set of instructions while satisfying the instruction bitwidth constraint. We formulate the problem using integer linear programming and also present an effective heuristic algorithm. Experimental results using our technique generate ISs that show improvements of up to about 40% over the native IS for several application benchmarks running on typical embedded RISC processors.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4246896219",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1367045",
    "publication_date": "2008-07-01",
    "publication_year": 2008,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4251364933",
    "type": "paratext"
  },
  {
    "title": "Series-parallel functions and FPGA logic module design",
    "doi": "https://doi.org/10.1145/225871.225891",
    "publication_date": "1996-01-01",
    "publication_year": 1996,
    "authors": "Shashidhar Thakur; Martin D. F. Wong",
    "corresponding_authors": "",
    "abstract": "The need for a two-way interaction between logic synthesis and FPGA logic module design has been stressed recently. Having a logic module that can implement many functions is a good idea only if one can also give a synthesis strategy that makes efficient use of this functionality. Traditionally, technology mapping algorithms have been developed after the logic architecture has been designed. We follow a dual approach, by focusing on a specific technology mapping algorithm, namely, the structural tree-based mapping algorithm, and designing a logic module that can be mapped efficiently by this algorithm. It is known that the tree-based mapping algorithm makes optimal use of a library of functions, each of which can be represented by a tree of AND, OR, and NOT gates (series-parallel or SP functions). We show how to design a SP function with a minimum number of inputs that can implement all possible SP functions with a specified number of inputs. For instances, we demonstrate a seven-input SP function that can implement all four-input SP functions. Mapping results show that, on an average, the number blocks of this function needed to map benchmark circuits are 12% less than those for Actel's ACT1 logic modules. Our logic modules show a 4% improvement over ACT1, if the block count is scaled to take into account the number of transistors needed to implement different logic modules.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2008067009",
    "type": "article"
  },
  {
    "title": "Hmap",
    "doi": "https://doi.org/10.1145/253052.253098",
    "publication_date": "1997-04-01",
    "publication_year": 1997,
    "authors": "Cheng-Hsing Yang; Chia‐Chun Tsai; Jan-Ming Ho; Sao‐Jie Chen",
    "corresponding_authors": "",
    "abstract": "A fast and efficient algorithm for technology mapping of electrically programmable gate arrays (EPGAs) is proposed. This Hmap algorithm covers the Boolean network with programmed logic modules bottom-up. The covering operation is based on collapsing the fanins of a node to form a bigger supernode such that fewer clusters are needed to be detected. Then Boolean matching is used to detect whether the collapsed supernode can be mapped into a logic module by looking up an extended GBDD hash table. The use of this table look-up matching can shorten the matching time significantly. As shown in the experiments, the average running time of Hmap is 20 times faster than that of MIS-pga2.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2090356086",
    "type": "article"
  },
  {
    "title": "AGENTS",
    "doi": "https://doi.org/10.1145/250243.250248",
    "publication_date": "1997-01-01",
    "publication_year": 1997,
    "authors": "Dilvan de Abreu Moreira; Les T. Walczowski",
    "corresponding_authors": "",
    "abstract": "The AGENTS system is a set of programs designed to generate automatically the mask-level layout of full custom CMOS, BICMOS, and bipolar leaf cells. The system is formed from four sever programs: the placer, router, database, and broker. The placer places components in a cell, the router wires the circuits sent to it, the database stores all the information that is dependent upon the fabrication process, such as the design rules, and the Broker makes the services of the other servers available. These servers communicate over a computer network using the TCP/IP Internet Protocol. The Placer server receives from its client the description and netlist of the circuit to be generated using EDIF (Electronic Design Interchange Format.) The output to its client is the mask layout of the circuit, again codified in EDIF. The comcept of agents as software components which have the ability to communicate and cooperate with each other is at the heart of the AGENTS system. This concept is not only used at the higher level, for the four servers, but at a lower level as well, inside the Router and Placer servers, where small relatively simple agents work together to accomplish complex tasks. These small agents are responsible for all the reasoning carried out by the two servers, as they hold the basic inference routines and the knowledge needed by the servers. The system's philosophy is that competence should emerge out of the collective behavior of a large number of relatively simple agents. In addition and integrated to these small agents, the system uses a genetic algorithm to improve components' placement before routing.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2139955410",
    "type": "article"
  },
  {
    "title": "A mapping algorithm for computer-assisted exploration in the design of embedded systems",
    "doi": "https://doi.org/10.1145/371254.371273",
    "publication_date": "2001-01-01",
    "publication_year": 2001,
    "authors": "E.P. Mariatos; Alexios Birbas; Michael Birbas",
    "corresponding_authors": "",
    "abstract": "We present a technique for automatic exploration of architectural alternatives in the design of complex electronic embedded systems and systems-on-a-chip. The technique transforms the problem into a set of simple model-to-model operations and a mapping algorithm that becomes the core of the entire design process. The mapping algorithm is formulated as an assignment-type problem (ATP), which is, in turn, solved by a straightforward optimization method. The result is a design assistance tool, which is demonstrated through a telecommunication systems example.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2045817102",
    "type": "article"
  },
  {
    "title": "Integrated test of interacting controllers and datapaths",
    "doi": "https://doi.org/10.1145/383251.383258",
    "publication_date": "2001-07-01",
    "publication_year": 2001,
    "authors": "Mehrdad Nourani; Joan Carletta; C. Papachristou",
    "corresponding_authors": "",
    "abstract": "In systems consisting of interacting datapaths and controllers and utilizing built-in self test (BIST), the datapaths and controllers are traditionally tested separately by isolating each component from the environment of the system during test. This work facilitates the testing of datapath/controller pairs in an integrated fashion . The key to the approach is the addition of logic to the system that interacts with the existing controller to push the effects of controller faults into the data flow , so that they can be observed at the datapath registers rather than directly at the controller outputs. The result is to reduce the BIST overhead over what is needed if the datapath and controller are tested independently, and to allow a more complete test of the interface between datapath and controller, including the faults that do not manifest themselves in isolation. Fault coverage and overhead results are given for four example circuits.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2053602242",
    "type": "article"
  },
  {
    "title": "Efficient list-approximation techniques for floorplan area minimization",
    "doi": "https://doi.org/10.1145/383251.383257",
    "publication_date": "2001-07-01",
    "publication_year": 2001,
    "authors": "Xiaobo Sharon Hu; Danny Z. Chen; Rajeshkumar Sambandam",
    "corresponding_authors": "",
    "abstract": "As the sizes of many IC design problems become increasingly larger, approximation has become a valuable approach for arriving at satisfactory results without incurring exorbitant computational cost. In this paper, we present several approximation techniques for solving floorplan area minimization problems. These new techniques enable us to reduce both the time and space complexities of the previously best known approximation algorithms by more than a factor of n and n 2 for rectangular and L-shaped subfloorplans, respectively (where n is the number of given implementions). The improvements in the time and space complexities of such approximation techniques is critical to their applicability in floorplan area minimization algorithms. The techniques are quite general, and may be applicable to other classes of approximation problems.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2055240106",
    "type": "article"
  },
  {
    "title": "Optimizing designs containing black boxes",
    "doi": "https://doi.org/10.1145/502175.502184",
    "publication_date": "2001-10-01",
    "publication_year": 2001,
    "authors": "Tai-Hung Liu; Adnan Aziz; Vigyan Singhal",
    "corresponding_authors": "",
    "abstract": "We are concerned with optimizing gate-level netlists containing “black boxes,” that is, components whose functionality is not available to the optimization tool. We establish a notion of equivalence for gate-level netlists containing black boxes, and prove that it is sound and complete. We show that conventional approaches to optimizing such netlists fail to fully exploit the don't care flexibility available for synthesis. Based on our new notion of equivalence, we introduce a procedure that computes the complete don't care set. Experiments indicate that our procedure can achieve more minimization than conventional synthesis.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2056934608",
    "type": "article"
  },
  {
    "title": "Folded Circuit Synthesis",
    "doi": "https://doi.org/10.1145/3229082",
    "publication_date": "2018-08-22",
    "publication_year": 2018,
    "authors": "Inhak Han; Youngsoo Shin",
    "corresponding_authors": "",
    "abstract": "The area required by combinational logic of a sequential circuit based on standard flip-flops can be reduced by identifying subcircuits that are identical. Pairs of matching subcircuits can then be replaced by circuits in which dual-edge-triggered flip-flops operate on multiplexed data at the rising and falling edges of the clock signal. We show how to modify the Boolean network describing a combinational logic to increase the opportunities for folding, without affecting its function. Experiments with benchmark circuits achieved an average reduction in circuit area of 18%.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2888391482",
    "type": "article"
  },
  {
    "title": "An Algorithmic Approach to Formally Verify an ECC Library",
    "doi": "https://doi.org/10.1145/3224205",
    "publication_date": "2018-08-25",
    "publication_year": 2018,
    "authors": "K Keerthi; Chester Rebeiro; Aritra Hazra",
    "corresponding_authors": "",
    "abstract": "The weakest link in cryptosystems is quite often due to the implementation rather than the mathematical underpinnings. A vast majority of attacks in the recent past have targeted programming flaws and bugs to break security systems. Due to the complexity, empirically verifying such systems is practically impossible, while manual verification as well as testing do not provide adequate guarantees. In this article, we leverage model checking techniques to prove the functional correctness of an elliptic curve cryptography (ECC) library with respect to its formal specification. We demonstrate how the huge state space of the C library can be aptly verified using a hierarchical assume-guarantee verification strategy. To test the scalability of this approach, we verify the correctness of five NIST-specified elliptic curve implementations. We also verify the newer curve25519 elliptic curve, which is finding multiple applications, due to its higher security and simpler implementation. The 192-bit NIST elliptic curve took 1 day to verify. This was the smallest curve we verified. The largest curve with a 521-bit prime field took 26 days to verify. Curve25519 took 1.5 days to verify.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2888872530",
    "type": "article"
  },
  {
    "title": "Introduction to the Special Section on Advances in Physical Design Automation",
    "doi": "https://doi.org/10.1145/3199220",
    "publication_date": "2018-07-17",
    "publication_year": 2018,
    "authors": "Chris Chu; Mustafa Özdal",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2888994318",
    "type": "article"
  },
  {
    "title": "Boundary-Functional Broadside and Skewed-Load Tests",
    "doi": "https://doi.org/10.1145/3276976",
    "publication_date": "2018-12-21",
    "publication_year": 2018,
    "authors": "Irith Pomeranz",
    "corresponding_authors": "Irith Pomeranz",
    "abstract": "Close-to-functional broadside tests are used for avoiding overtesting of delay faults that can result from non-functional operation conditions, while avoiding test escapes because of faults that cannot be detected under functional operation conditions. When a close-to-functional broadside test deviates from functional operation conditions, the deviation can affect the entire circuit. This article defines the concept of a boundary-functional broadside test where non-functional operation conditions are prevented from crossing a preselected boundary. Using the procedure described in this article, the boundary maintains the same values under a boundary-functional broadside test as under a functional broadside test from which it is derived. Indirectly, this ensures that the deviations from functional operation conditions throughout the entire circuit are limited. The concept of a boundary-functional broadside test is extended to skewed-load tests, and to partial-boundary-functional tests. Experimental results are presented for benchmark circuits to demonstrate the fault coverage improvements that can be achieved using boundary-functional broadside and skewed-load tests as well as partial-boundary-functional tests of both types.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2905884899",
    "type": "article"
  },
  {
    "title": "Programmable Gates Using Hybrid CMOS-STT Design to Prevent IC Reverse Engineering",
    "doi": "https://doi.org/10.1145/3236622",
    "publication_date": "2018-11-30",
    "publication_year": 2018,
    "authors": "Ted Winograd; Gaurav Shenoy; Hassan Salmani; Hamid Mahmoodi; Setareh Rafatirad; Houman Homayoun",
    "corresponding_authors": "",
    "abstract": "This article presents a rigorous step towards design-for-assurance by introducing a new class of logically reconfigurable design resilient to design reverse engineering. Based on the non-volatile spin transfer torque (STT) magnetic technology, we introduce a basic set of non-volatile reconfigurable Look-Up-Table (LUT) logic components (NV-STT-based LUTs). An STT-based LUT with a significantly different set of characteristics compared to CMOS provides new opportunities to enhance design security yet makes it challenging to remain highly competitive with custom CMOS or even SRAM-based LUT in terms of power, performance, and area. To address these challenges, we propose several algorithms to select and replace custom CMOS gates with reconfigurable STT-based LUTs during design implementation such that the functionality of STT-based components and therefore the entire design cannot be determined in any manageable time, rendering any design reverse engineering attack ineffective. Our study, conducted on a large number of standard circuit benchmarks, concludes significant resiliency of hybrid STT-CMOS circuits against various types of attacks. Furthermore, the selection algorithms on average have a small impact on the performance of the circuit. We also tested these techniques against satisfiability attacks developed recently and show that these techniques also render more advanced reverse-engineering techniques computationally infeasible.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2905969040",
    "type": "article"
  },
  {
    "title": "Incomplete Tests for Undetectable Faults to Improve Test Set Quality",
    "doi": "https://doi.org/10.1145/3306493",
    "publication_date": "2019-02-13",
    "publication_year": 2019,
    "authors": "Irith Pomeranz",
    "corresponding_authors": "Irith Pomeranz",
    "abstract": "The presence of undetectable faults in a set of target faults implies that tests, which may be important for detecting defects, are missing from the test set. This article suggests an approach for addressing missing tests that fits with the rationale for computing an n -detection test set. The artcile defines the concept of an incomplete test that is relevant when a target fault is undetectable. An incomplete test activates the fault but fails to detect it because of one or more assignments that are missing from the test. The procedure described in this article improves the quality of a test set by attempting to ensure that every undetectable fault has n incomplete tests with the smallest possible numbers of missing assignments, for a constant n ≥ 1. The incomplete tests are expected to contribute to the detection of detectable defects around the site of the undetectable fault. The computation of missing assignments for a test is performed in linear time by avoiding fault simulation and considering all the undetectable faults simultaneously. Experimental results demonstrate the extent to which a given test set can be improved without increasing the number of tests.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2913181721",
    "type": "article"
  },
  {
    "title": "Formal Modeling and Verification of a Victim DRAM Cache",
    "doi": "https://doi.org/10.1145/3306491",
    "publication_date": "2019-02-13",
    "publication_year": 2019,
    "authors": "Debiprasanna Sahoo; Swaraj Sha; Manoranjan Satpathy; Madhu Mutyam; S. Ramesh; Partha S. Roop",
    "corresponding_authors": "",
    "abstract": "The emerging Die-stacking technology enables DRAM to be used as a cache to break the “Memory Wall” problem. Recent studies have proposed to use DRAM as a victim cache in both CPU and GPU memory hierarchies to improve performance. DRAM caches are large in size and, hence, when realized as a victim cache, non-inclusive design is preferred. This non-inclusive design adds significant differences to the conventional DRAM cache design in terms of its probe, fill, and writeback policies. Design and verification of a victim DRAM cache can be much more complex than that of a conventional DRAM cache. Hence, without rigorous modeling and formal verification, ensuring the correctness of such a system can be difficult. The major focus of this work is to show how formal modeling is applied to design and verify a victim DRAM cache. In this approach, we identify the agents in the victim DRAM cache design and model them in terms of interacting state machines. We derive a set of properties from the specifications of a victim cache and encode them using Linear Temporal Logic. The properties are then proven using symbolic and bounded model checking. Finally, we discuss how these properties are related to the dataflow paths in a victim DRAM cache.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2914765870",
    "type": "article"
  },
  {
    "title": "A Cross-level Verification Methodology for Digital IPs Augmented with Embedded Timing Monitors",
    "doi": "https://doi.org/10.1145/3308565",
    "publication_date": "2019-03-11",
    "publication_year": 2019,
    "authors": "Sara Vinco; Nicola Bombieri; Daniele Jahier Pagliari; Franco Fummi; Enrico Macii; Massimo Poncino",
    "corresponding_authors": "",
    "abstract": "Smart systems are characterized by the integration in a single device of multi-domain subsystems of different technological domains, namely, analog, digital, discrete and power devices, MEMS, and power sources. Such challenges, emerging from the heterogeneous nature of the whole system, combined with the traditional challenges of digital design, directly impact on performance and on propagation delay of digital components. This article proposes a design approach to enhance the RTL model of a given digital component for the integration in smart systems with the automatic insertion of delay sensors, which can detect and correct timing failures. The article then proposes a methodology to verify such added features at system level. The augmented model is abstracted to SystemC TLM, which is automatically injected with mutants (i.e., code mutations) to emulate delays and timing failures. The resulting TLM model is finally simulated to identify timing failures and to verify the correctness of the inserted delay monitors. Experimental results demonstrate the applicability of the proposed design and verification methodology, thanks to an efficient sensor-aware abstraction methodology, by applying the flow to three complex case studies.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2920799176",
    "type": "article"
  },
  {
    "title": "A Novel Resistive Memory-based Process-in-memory Architecture for Efficient Logic and Add Operations",
    "doi": "https://doi.org/10.1145/3306495",
    "publication_date": "2019-03-21",
    "publication_year": 2019,
    "authors": "Taozhong Li; Qin Wang; Yongxin Zhu; Jianfei Jiang; Guanghui He; Jing Jin; Zhigang Mao; Naifeng Jing",
    "corresponding_authors": "",
    "abstract": "The coming era of big data revives the Processing-in-memory (PIM) architecture to relieve the memory wall problem that embarrasses the modern computing system. However, most existing PIM designs just put computing units closer to memory, rather than a complete integration of them due to their incompatibility in CMOS manufacturing. Fortunately, the emerging Resistive-RAM (ReRAM) offers new hope to this dilemma owing to its inherent memory and computing capability using the same device. In this article, we propose a ReRAM memory structure with efficient PIM capability of both logic and add operations. It first leverages non-linearity to suppress sneak current and thus sustains high memory density. Using a differential bit cell, it also enables efficient processing of arbitrary logic functions using the same memory cells with non-destructive operations. Then, a novel PIM adder is proposed, which customizes a sneak current path as the carry-chain for fast carry propagation and improves adder performance significantly. In the experiment, the proposed PIM demonstrates higher efficiency in both computing area and performance for logic and addition, which greatly increases the ReRAM PIM applicability for future computable architectures.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2925928499",
    "type": "article"
  },
  {
    "title": "Fault Tolerance Technique Offlining Faulty Blocks by Heap Memory Management",
    "doi": "https://doi.org/10.1145/3329079",
    "publication_date": "2019-06-05",
    "publication_year": 2019,
    "authors": "Jaeyung Jun; Yoonah Paik; Gyeong Il Min; Seon Wook Kim; Youngsun Han",
    "corresponding_authors": "",
    "abstract": "As dynamic random access memory (DRAM) cells continue to be scaled down for higher density and capacity, they have more faults. Thus, DRAM reliability becomes a major concern in computer systems. Previous studies have proposed many techniques preserving the reliability in various system components, such as DRAM internal, memory controller, caches, and operating systems. By reviewing the techniques, we identified the following two considerations: First, it is possible to recover faults with reasonable overhead at high fault rate only if the recovery unit is fine-grained. Second, since hardware modification requires additional cost in the employment of a technique, a pure software-based recovery technique is preferable. However, in the existing software-based recovery technique, the recovery unit is too coarse-grained to tolerate the high fault rate. In this article, we propose a pure software-based recovery technique with fine-granularity. Our key idea is based on heap segments being managed by the system library with variable-sized chunks to handle dynamic allocation in user applications. In our technique, faulty blocks in pages are offlined by marking them as allocated chunks. Thus, not only fault-free pages but also the remaining clean blocks in faulty pages are allowed to be usable space. Our technique is implemented by modifying the operating system and the system library. Since hardware assistance is unnecessary in the implementation, we evaluated our method on a real machine. Our evaluation results show that our technique has negligible performance overhead at high bit error rate (BER) 5.12e-5, which a hardware-based recovery technique could not tolerate without unacceptable area overhead. Also, at the same BER, our method provides 5.22× usable space, compared with page-offline, which is the state-of-the-art pure software-based technique.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2951924315",
    "type": "article"
  },
  {
    "title": "Adaptive Test for RF/Analog Circuit Using Higher Order Correlations among Measurements",
    "doi": "https://doi.org/10.1145/3308566",
    "publication_date": "2019-06-26",
    "publication_year": 2019,
    "authors": "Yanjun Li; Ender Yılmaz; Pete Sarson; Sule Ozev",
    "corresponding_authors": "",
    "abstract": "As process variations increase and devices get more diverse in their behavior, using the same test list for all devices is increasingly inefficient. Methodologies that adapt the test sequence with respect to lot, wafer, or even a device's own behavior help contain the test cost while maintaining test quality. In adaptive test selection approaches, the initial test list, a set of tests that are applied to all devices to learn information, plays a crucial role in the quality outcome. Most adaptive test approaches select this initial list based on fail probability of each test individually. Such a selection approach does not take into account the correlations that exist among various measurements and potentially will lead to the selection of correlated tests. In this work, we propose a new adaptive test algorithm that includes a mathematical model for initial test ordering that takes correlations among measurements into account. The proposed method can be integrated within an existing test flow running in the background to improve not only the test quality but also the test time. Experimental results using four distinct industry circuits and large amounts of measurement data show that the proposed technique outperforms prior approaches considerably.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2955518464",
    "type": "article"
  },
  {
    "title": "Energy-Efficient and Quality-Assured Approximate Computing Framework Using a Co-Training Method",
    "doi": "https://doi.org/10.1145/3342239",
    "publication_date": "2019-08-16",
    "publication_year": 2019,
    "authors": "Li Jiang; Zhuoran Song; Haiyue Song; Chengwen Xu; Qiang Xu; Naifeng Jing; Weifeng Zhang; Xiaoyao Liang",
    "corresponding_authors": "",
    "abstract": "Approximate computing is a promising design paradigm that introduces a new dimension—error—into the original design space. By allowing the inexact computation in error-tolerance applications, approximate computing can gain both performance and energy efficiency. A neural network (NN) is a universal approximator in theory and possesses a high level of parallelism. The emerging deep neural network accelerators deployed with NN-based approximator is thereby a promising candidate for approximate computing. Nevertheless, the approximation result must satisfy the users’ requirement, and the approximation result varies across different applications. We normally deploy an NN-based classifier to ensure the approximation quality. Only the inputs predicted to meet the quality requirement can be executed by the approximator. The potential of these two NNs, however, is fully explored; the involving of two NNs in approximate computing imposes critical optimization questions, such as two NNs’ distinct views of the input data space, how to train the two correlated NNs, and what are their topologies. In this article, we propose a novel NN-based approximate computing framework with quality insurance. We advocate a co-training approach that trains the classifier and the approximator alternately to maximize the agreement of the two NNs on the input space. In each iteration, we coordinate the training of the two NNs with a judicious selection of training data. Next, we explore different selection policies and propose to select training data from multiple iterations, which can enhance the invocation of the approximate accelerator. In addition, we optimize the classifier by integrating a dynamic threshold tuning algorithm to improve the invocation of the approximate accelerator further. The increased invocation of accelerator leads to higher energy efficiency under the same quality requirement. We propose two efficient algorithms to explore the smallest topology of the NN-based approximator and the classifier to achieve the quality requirement. The first algorithm straightforward searches the minimum topology using a greedy strategy. However, the first algorithm incurs too much training overhead. To solve this issue, the second one gradually grows the topology of NNs to match the quality requirement by transferring the learned parameters. Experimental results show significant improvement on the quality and the energy efficiency compared to the existing NN-based approximate computing frameworks.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2967826572",
    "type": "article"
  },
  {
    "title": "Investigating the Impact of Image Content on the Energy Efficiency of Hardware-accelerated Digital Spatial Filters",
    "doi": "https://doi.org/10.1145/3341819",
    "publication_date": "2019-09-30",
    "publication_year": 2019,
    "authors": "Rajkumar Raval; Atta Badii",
    "corresponding_authors": "",
    "abstract": "Battery-operated low-power portable computing devices are becoming an inseparable part of human daily life. One of the major goals is to achieve the longest battery life in such a device. Additionally, the need for performance in processing multimedia content is ever increasing. Processing image and video content consume more power than other applications. A widely used approach to improving energy efficiency is to implement the computationally intensive functions as digital hardware accelerators. Spatial filtering is one of the most commonly used methods of digital image processing. As per the Fourier theory, an image can be considered as a two-dimensional signal that is composed of spatially extended two-dimensional sinusoidal patterns called gratings. Spatial frequency theory states that sinusoidal gratings can be characterised by its spatial frequency, phase, amplitude, and orientation. This article presents results from our investigation into assessing the impact of these characteristics of a digital image on the energy efficiency of hardware-accelerated spatial filters employed to process the same image. Two greyscale images each of size 128 × 128 pixels comprising two-dimensional sinusoidal gratings at maximum spatial frequency of 64 cycles per image orientated at 0° and 90°, respectively, were processed in a hardware implemented Gaussian smoothing filter. The energy efficiency of the filter was compared with the baseline energy efficiency of processing a featureless plain black image. The results show that energy efficiency of the filter drops to 12.5% when the gratings are orientated at 0° whilst rises to 72.38% at 90°.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2980321619",
    "type": "article"
  },
  {
    "title": "An Implication-based Test Scheme for Both Diagnosis and Concurrent Error Detection Applications",
    "doi": "https://doi.org/10.1145/3364681",
    "publication_date": "2019-11-22",
    "publication_year": 2019,
    "authors": "Chih-Hao Wang; Tong-Yu Hsieh",
    "corresponding_authors": "",
    "abstract": "This article describes a diagnosis-aware hybrid concurrent error detection ( DAH-CED ) scheme that can facilitate both off-line and on-line test applications. By using the proposed scheme, not only the probability of detecting errors (on-line) but also the diagnosability of the target circuit (off-line) can be significantly enhanced. The proposed scheme combines the implication-based method with the parity check method. In particular, novel algorithms are developed to identify specific implications for enhancing the diagnosability for the modeled faults proactively. Furthermore, a reduction algorithm is also presented to minimize the number of the employed implications, while no loss on probability of detecting errors and diagnosability is also guaranteed. To the best of our knowledge, this issue is not addressed in the literature. To validate the proposed scheme, not only stuck-at faults but also transition faults are considered to simulate the timing-related errors. The experimental results on nine ITC’99 benchmark circuits show that the diagnosability for stuck-at (transition) faults is enhanced by 6.88% (7.78%) by applying the proposed scheme. As for the probability of detecting errors, 97.73% (97.10%) is achieved for errors caused by stuck-at (transition) faults. Moreover, only 3.11% of implications are needed.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2991096953",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3370083",
    "publication_date": "2019-12-04",
    "publication_year": 2019,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Today, it is common knowledge in the cyber-physical systems domain that the tight interaction between the cyber and physical elements provides the possibility of substantially improving the performance of these systems that is otherwise impossible. On ...",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4244905843",
    "type": "paratext"
  },
  {
    "title": "A Module-Level Configuration Methodology for Programmable Camouflaged Logic",
    "doi": "https://doi.org/10.1145/3640462",
    "publication_date": "2024-01-12",
    "publication_year": 2024,
    "authors": "Jianfeng Wang; Zhonghao Chen; Jiahao Zhang; Yixin Xu; Tongguang Yu; Ziheng Zheng; Enze Ye; Sumitha George; Huazhong Yang; Yongpan Liu; Kai Ni; Vijaykrishnan Narayanan; Xueqing Li",
    "corresponding_authors": "",
    "abstract": "Logic camouflage is a widely adopted technique that mitigates the threat of intellectual property (IP) piracy and overproduction in the integrated circuit (IC) supply chain. Camouflaged logic achieves functional obfuscation through physical-level ambiguity and post-manufacturing programmability. However, discussions on programmability are confined to the level of logic cells/gates, limiting the broader-scale application of logic camouflage. In this work, we propose a novel module-level configuration methodology for programmable camouflaged logic that can be implemented without additional hardware ports and with negligible resources. We prove theoretically that the configuration of the programmable camouflaged logic cells can be achieved through the inputs and netlist of the original module. Further, we propose a novel lightweight ferroelectric FET (FeFET)-based reconfigurable logic gate (rGate) family and apply it to the proposed methodology. With the flexible replacement and the proposed configuration-aware conversion algorithm, this work is characterized by the input-only programming scheme as well as the combination of high output error rate and point-function-like defense. Evaluations show an average of &gt;95% of the alternative rGate location for camouflage, which is sufficient for the security-aware design. We illustrate the exponential complexity in function state traversal and the enhanced defense capability of locked blackbox against Boolean Satisfiability (SAT) attacks compared with key-based methods. We also preserve an evident output Hamming distance and introduce negligible hardware overheads in both gate-level and module-level evaluations under typical benchmarks.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4390814802",
    "type": "article"
  },
  {
    "title": "Reduced On-chip Storage of Seeds for Built-in Test Generation",
    "doi": "https://doi.org/10.1145/3643810",
    "publication_date": "2024-02-01",
    "publication_year": 2024,
    "authors": "Irith Pomeranz",
    "corresponding_authors": "Irith Pomeranz",
    "abstract": "Logic built-in self-test ( LBIST ) approaches use an on-chip logic block for test generation and thus enable in-field testing. Recent reports of silent data corruption underline the importance of in-field testing. In a class of storage-based LBIST approaches, compressed tests are stored on-chip and decompressed by an on-chip decompression logic. The on-chip storage requirements may become a bottleneck when the number of compressed tests is large. In this case, using each compressed test for applying several different tests allows the storage requirements to be reduced. However, producing different tests from each compressed test has a hardware overhead. This article suggests a new on-chip storage scheme for compressed tests that eliminates the additional hardware overhead. Under the new storage scheme, a set of N B -bit compressed tests targeting a set of faults F 0 is translated into a sequence S of N ⋅ B bits. Every B consecutive bits of S are considered as a compressed test. The sequence S thus yields close to N ⋅ B compressed tests, magnifying the test data stored in S almost B times. Taking advantage of the extra tests, the article describes a software procedure that is applied offline to reduce S without losing fault coverage of F 0 . Experimental results for benchmark circuits demonstrate significant reductions in the storage requirements of S and significant increases in the fault coverage of a second set of faults, F 1 .",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4391436643",
    "type": "article"
  },
  {
    "title": "<tt>FortiFix</tt> : A Fault Attack Aware Compiler Framework for Crypto Implementations",
    "doi": "https://doi.org/10.1145/3650029",
    "publication_date": "2024-03-01",
    "publication_year": 2024,
    "authors": "K Keerthi; Chester Rebeiro",
    "corresponding_authors": "",
    "abstract": "Fault attacks are one of the most powerful forms of cryptanalytic attack on embedded systems, which can corrupt a cipher’s operations leading to a breach of confidentiality and integrity. A single precisely injected fault during the execution of a cipher can be exploited to retrieve the secret key in a few milliseconds. Naive countermeasures introduced into implementation can lead to huge overheads, making them unusable in resource-constraint environments. However, optimized countermeasures require significant knowledge, not only about the attack but also on the the cryptographic properties of the cipher, the program structure, and the underlying hardware architecture. This makes the protection against fault attacks tedious and error prone. In this article, we introduce FortiFix , the first automated compiler framework that can detect and patch fault exploitable regions in a block cipher implementation. The framework has two phases. The pre-compilation phase identifies regions in the source code of a block cipher that are vulnerable to fault attacks. The second phase is incorporated as transformation passes in the LLVM compiler to find exploitable instructions, quantify the impact of a fault on these instructions, and finally insert appropriate countermeasures based on user-defined security requirements. As a proof of concept, we have evaluated two block cipher implementations, AES-128 and CLEFIA-128, on three different hardware platforms: MSP430 (16-bit), ARM (32-bit), and RISCV (32-bit).",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4392357388",
    "type": "article"
  },
  {
    "title": "Incremental Concolic Testing of Register-Transfer Level Designs",
    "doi": "https://doi.org/10.1145/3655621",
    "publication_date": "2024-03-30",
    "publication_year": 2024,
    "authors": "Hasini Witharana; Aruna Jayasena; Prabhat Mishra",
    "corresponding_authors": "",
    "abstract": "Concolic testing is a scalable solution for automated generation of directed tests for validation of hardware designs. Unfortunately, concolic testing fails to cover complex corner cases such as hard-to-activate branches. In this article, we propose an incremental concolic testing technique to cover hard-to-activate branches in register-transfer level (RTL) models. We show that a complex branch condition can be viewed as a sequence of easy-to-activate events. We map the branch coverage problem to the coverage of a sequence of events. We propose an efficient algorithm to cover the sequence of events using concolic testing. Specifically, the test generated to activate the current event is used as the starting point to activate the next event in the sequence. Experimental results demonstrate that our approach can be used to generate directed tests to cover complex corner cases in RTL models while state-of-the-art methods fail to activate them.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4393342225",
    "type": "article"
  },
  {
    "title": "ZoneTrace: Zone Monitoring Tool for F2FS on ZNS SSDs",
    "doi": "https://doi.org/10.1145/3656172",
    "publication_date": "2024-04-05",
    "publication_year": 2024,
    "authors": "Ping-Xiang Chen; Dongjoo Seo; Changhoon Sung; J. O. Park; Minchul Lee; Huaicheng Li; Matias Bjørling; Nikil Dutt",
    "corresponding_authors": "",
    "abstract": "We present ZoneTrace , a runtime monitoring tool for the Flash-friendly File System (F2FS) on Zoned Namespace (ZNS) Solid-state Drives (SSDs). ZNS SSD organizes its storage into zones of sequential write access. Due to ZNS SSD’s sequential write nature, F2FS is a log-structured file system that has recently been adopted to support ZNS SSDs. To present the space management with the zone concept between F2FS and the underlying ZNS SSD, we developed ZoneTrace , a tool that enables users to visualize and analyze the space management of F2FS on ZNS SSDs. ZoneTrace utilizes the extended Berkeley Packet Filter (eBPF) to trace the updated segment bitmap in F2FS and visualize each zone space usage accordingly. Furthermore, ZoneTrace is able to analyze on file fragmentation in F2FS and provides users with informative fragmentation histogram to serve as an indicator of file fragmentation. Using ZoneTrace ’s visualization, we are able to identify the current F2FS space management scheme’s inability to fully optimize space for streaming data recording in autonomous systems, which leads to serious file fragmentation on ZNS SSDs. Our evaluations show that ZoneTrace is lightweight and assists users in getting useful insights for effortless monitoring on F2FS with ZNS SSD with both synthetic and realistic workloads. We believe ZoneTrace can help users analyze F2FS with ease and open up space management research topics with F2FS on ZNS SSDs.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4393992390",
    "type": "article"
  },
  {
    "title": "Wages: The Worst Transistor Aging Analysis for Large-scale Analog Integrated Circuits via Domain Generalization",
    "doi": "https://doi.org/10.1145/3659950",
    "publication_date": "2024-08-13",
    "publication_year": 2024,
    "authors": "Tinghuan Chen; Hao Geng; Qi Sun; Sanping Wan; Yongsheng Sun; Huatao Yu; Bei Yu",
    "corresponding_authors": "",
    "abstract": "Transistor aging leads to the deterioration of analog circuit performance over time. The worst aging degradation is used to evaluate the circuit reliability. It is extremely expensive to obtain it since several circuit stimuli need to be simulated. The worst degradation collection cost reduction brings an inaccurate training dataset when a machine learning (ML) model is used to fast perform the estimation. Motivated by the fact that there are many similar subcircuits in large-scale analog circuits, in this article we propose Wages to train an ML model on an inaccurate dataset for the worst aging degradation estimation via a domain generalization technique. A sampling-based method on the feature space of the transistor and its neighborhood subcircuit is developed to replace inaccurate labels. A consistent estimation for the worst degradation is enforced to update model parameters. Label updating and model updating are performed alternately to train an ML model on the inaccurate dataset. Experimental results on the very advanced 5 nm technology node show that our Wages can significantly reduce the label collection cost with a negligible estimation error for the worst aging degradations compared to the traditional methods.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4394880716",
    "type": "article"
  },
  {
    "title": "CuPBoP: Making CUDA a Portable Language",
    "doi": "https://doi.org/10.1145/3659949",
    "publication_date": "2024-04-23",
    "publication_year": 2024,
    "authors": "Ruobing Han; Jun Chen; Bhanu Garg; Xule Zhou; John Lu; Jeffrey Young; Jaewoong Sim; Hyesoon Kim",
    "corresponding_authors": "",
    "abstract": "CUDA is designed specifically for NVIDIA GPUs and is not compatible with non-NVIDIA devices. Enabling CUDA execution on alternative backends could greatly benefit the hardware community by fostering a more diverse software ecosystem. To address the need for portability, our objective is to develop a framework that meets key requirements, such as extensive coverage, comprehensive end-to-end support, superior performance, and hardware scalability. Existing solutions that translate CUDA source code into other high-level languages, however, fall short of these goals. In contrast to these source-to-source approaches, we present a novel framework, CuPBoP , which treats CUDA as a portable language in its own right. Compared to two commercial source-to-source solutions, CuPBoP offers a broader coverage and superior performance for the CUDA-to-CPU migration. Additionally, we evaluate the performance of CuPBoP against manually optimized CPU programs, highlighting the differences between CPU programs derived from CUDA and those that are manually optimized. Furthermore, we demonstrate the hardware scalability of CuPBoP by showcasing its successful migration of CUDA to AMD GPUs. To promote further research in this field, we have released CuPBoP as an open-source resource.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4395038396",
    "type": "article"
  },
  {
    "title": "A Scenario-Based DVFS-Aware Hybrid Application Mapping Methodology for MPSoCs",
    "doi": "https://doi.org/10.1145/3660633",
    "publication_date": "2024-04-23",
    "publication_year": 2024,
    "authors": "Jan Spieck; Stefan Wildermann; Jürgen Teich",
    "corresponding_authors": "",
    "abstract": "Sound techniques for mapping soft real-time applications to resources are indispensable for meeting the application deadlines and minimizing objectives such as energy consumption, particularly on heterogeneous MPSoC architectures. For applications with input-dependent workload variations, static mappings are not able to sufficiently cope with the run-time variation, which can lead to deadline misses or unnecessary energy consumption. As a remedy, hybrid application mapping (HAM) techniques combine a design-time optimization with run-time management that adapts the mappings dynamically to the changes of the arriving input. This paper focuses on scenario-based HAM techniques. Here, the application input space is systematically clustered such that data inside the same scenario exhibit similar characteristics concerning workload when being processed under the same operating points. This static clustering of the input space into data scenarios has proven to be a good abstraction layer for simplifying the design and employment of high-quality run-time managers. However, existing state-of-the-art scenario-based HAM approaches neglect or underutilize the synergistic interplay between mapping selection and the usage of dynamic voltage/frequency scaling (DVFS) when adapting to workload variation. By combining mapping and DVFS selection, variations in the input can be either compensated by a complete re-mapping of the application, evoking a potential high reconfiguration overhead or by just changing the DVFS settings of the resources, offering a low-overhead adaptation alternative and thus significantly reducing the necessary overhead compared to DVFS-agnostic HAM. Furthermore, DVFS enables a fine-grained adaptation of a mapped application to the input data variation, e.g., by slowing down tasks with no impact on the end-to-end latency for the current input using low-frequency DVFS settings. It is shown that this combined approach can save even more energy than a pure mapping adaptation scheme, especially in the presence of data scenarios. In particular, scenario-based design operates as a catalyst for eliciting the synergies between a combined DVFS and mapping optimization and the peculiarities inside a data scenario, i.e., exploiting the commonalities inside a data scenario by perfectly tailored DVFS settings and task mapping. In this scope, this paper proposes two supplementary scenario-based DVFS-aware HAM approaches that consistently outperform existing state-of-the-art mapping approaches in terms of the number of deadline misses and energy consumption as we demonstrate in an empirical study on the basis of four different applications and three different architectures. It is also shown that these benefits still apply to target architectures with increasing mapping migration overheads, thwarting frequent mapping reconfigurations.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4395038489",
    "type": "article"
  },
  {
    "title": "Semi-Permanent Stuck-At Fault injection attacks on Elephant and GIFT lightweight ciphers",
    "doi": "https://doi.org/10.1145/3662734",
    "publication_date": "2024-04-29",
    "publication_year": 2024,
    "authors": "Priyanka Joshi; Bodhisatwa Mazumdar",
    "corresponding_authors": "",
    "abstract": "Fault attacks pose a potent threat to modern cryptographic implementations, particularly those used in physically approachable embedded devices in IoT environments. Information security in such resource-constrained devices is ensured using lightweight ciphers, where combinational circuit implementations of SBox are preferable over look-up tables as they are more efficient regarding area, power, and memory requirements. Most existing fault analysis techniques focus on fault injection in memory cells and registers. Recently, a novel fault model and analysis technique, namely Semi-Permanent Stuck-At (SPSA) fault analysis, has been proposed to evaluate the security of ciphers with combinational circuit implementation of Substitution layer elements, SBox. In this work, we propose optimized techniques to recover the key in a minimum number of ciphertexts in such implementations of lightweight ciphers. Based on the proposed techniques, a key recovery attack on the NIST lightweight cryptography (NIST-LWC) standardization process finalist, Elephant AEAD, has been proposed. The proposed key recovery attack is validated on two versions of Elephant cipher. The proposed fault analysis approach recovered the secret key within 85–240 ciphertexts, calculated over 1,000 attack instances. To the best of our knowledge, this is the first work on fault analysis attacks on the Elephant scheme. Furthermore, an optimized combinational circuit implementation of Spongent SBox (SBox used in Elephant cipher) is proposed, having a smaller gate count than the optimized implementation reported in the literature. The proposed fault analysis techniques are validated on primary and optimized versions of Spongent SBox through Verilog simulations. Further, we pinpoint SPSA hotspots in the lightweight GIFT cipher SBox architecture. We observe that GIFT SBox exhibits resilience toward the proposed SPSA fault analysis technique under the single fault adversarial model. However, eight SPSA fault patterns reduce the nonlinearity of the SBox to zero, rendering it vulnerable to linear cryptanalysis. Conclusively, SPSA faults may adversely affect the cryptographic properties of an SBox, thereby leading to trivial key recovery. The GIFT cipher is used as an example to focus on two aspects: (i) its SBox construction is resilient to the proposed SPSA analysis and therefore characterizing such constructions for SPSA resilience and (ii) an SBox even though resilient to the proposed SPSA analysis, may exhibit vulnerabilities toward other classical analysis techniques when subjected to SPSA faults. Our work reports new vulnerabilities in fault analysis in the combinational circuit implementations of cryptographic protocols.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4396220302",
    "type": "article"
  },
  {
    "title": "Enhanced Watermarking for Paper-Based Digital Microfluidic Biochips",
    "doi": "https://doi.org/10.1145/3661309",
    "publication_date": "2024-04-29",
    "publication_year": 2024,
    "authors": "Jian-De Li; Sying-Jyan Wang; Katherine Shu-Min Li; Tsung-Yi Ho",
    "corresponding_authors": "",
    "abstract": "Paper-based digital microfluidic biochip (PB-DMFB) technology provides a promising solution to many biochemical applications. However, the PB-DMFB manufacturing process may suffer from potential security threats. For example, a Trojan insertion attack may affect the functionality of PB-DMFBs. To ensure the correct functionality of PB-DMFBs, we propose a watermarking scheme to hide information in the PB-DMFB layout, which allows users to check design integrity and authenticate the source of the PB-DMFB design. As a result, the proposed method serves as a countermeasure against Trojan insertion attacks in addition to proof of authorship.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4396220356",
    "type": "article"
  },
  {
    "title": "HLS-IRT: Hardware Trojan Insertion through Modification of Intermediate Representation During High-Level Synthesis",
    "doi": "https://doi.org/10.1145/3663477",
    "publication_date": "2024-05-03",
    "publication_year": 2024,
    "authors": "Rijoy Mukherjee; Archisman Ghosh; Rajat Subhra Chakraborty",
    "corresponding_authors": "",
    "abstract": "Modern integrated circuit (IC) design incorporates the usage of proprietary computer-aided design (CAD) software and integration of third-party hardware intellectual property (IP) cores. Subsequently, the fabrication process for the design takes place in untrustworthy offshore foundries that raises concerns regarding security and reliability. Hardware Trojans (HTs) are difficult to detect malicious modifications to IC that constitute a major threat, which if undetected prior to deployment, can lead to catastrophic functional failures or the unauthorized leakage of confidential information. Apart from the risks posed by rogue human agents, recent studies have shown that high-level synthesis (HLS) CAD software can serve as a potent attack vector for inserting HTs. In this article, we introduce a novel automated attack vector, which we term “HLS-IRT”, by inserting HT in the register transfer logic (RTL) description of circuits generated during an HLS based IC design flow, by directly modifying the compiler-generated intermediate representation (IR) corresponding to the design. We demonstrate the attack using a design and implementation flow based on the open-source Bambu HLS software and Xilinx FPGA, on several hardware accelerators spanning different application domains. Our results show that the resulting HTs are surreptitious and effective, while incurring minimal design overhead. We also propose a novel detection scheme for HLS-IRT, since existing techniques are found to be inadequate to detect the proposed HTs.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4396624567",
    "type": "article"
  },
  {
    "title": "A Cost-Driven Chip Partitioning Method for Heterogeneous 3D Integration",
    "doi": "https://doi.org/10.1145/3672558",
    "publication_date": "2024-06-14",
    "publication_year": 2024,
    "authors": "C. A. Lin; Kuan‐Ting Chen; Yi-Yu Liu; Allen C.-H. Wu; TingTing Hwang",
    "corresponding_authors": "",
    "abstract": "Three-dimensional integration circuit (3D IC) offers significant benefits in terms of performance and cost. Existing research in through-silicon via (TSV)-based 3D IC partitioning has focused on minimizing the number of TSVs to reduce costs. Partitioning methods based on heterogeneous integration have emerged as viable approaches for cost optimization. Leveraging mature processes to manufacture not timing-critical blocks can yield cost benefits. Nevertheless, none of the previous 3D partitioning work has focused on reducing the overall cost, including both design and manufacturing costs, for heterogeneous 3D integration. Moreover, throughput constraints have not been considered. This article presents a cost-aware integer linear programming-based formulation and a heuristic algorithm that partition the functional blocks in the design into different technological groups. Each group of functional blocks will be implemented using a particular process technology, and then integrated into a 3D IC. Our results show that 3D heterogeneous integration chip implementation can reduce overall cost while satisfying various timing constraints.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4399677160",
    "type": "article"
  },
  {
    "title": "A Power Optimization Approach for Large-scale RM-TB Dual Logic Circuits Based on an Adaptive Multi-Task Intelligent Algorithm",
    "doi": "https://doi.org/10.1145/3677033",
    "publication_date": "2024-07-10",
    "publication_year": 2024,
    "authors": "Xiaoqian Wu; Huaxiao Liu; Peng Wang; Lei Liu; Zhenxue He",
    "corresponding_authors": "",
    "abstract": "Logic synthesis is a crucial step in integrated circuit design, and power optimization is an indispensable part of this process. However, power optimization for large-scale Mixed Polarity Reed-Muller (MPRM) logic circuits is an NP-hard problem. In this article, we divide Boolean circuits into small-scale circuits based on the idea of divide and conquer using the proposed Dynamic Adaptive Grouping Strategy (DAGS) and the proposed circuit decomposition model (CDM). Each small-scale Boolean circuit is transformed into an MPRM logic circuit by a polarity transformation algorithm. Based on the gate-level integration, we integrate small-scale circuits into an MPRM and Boolean Dual Logic (RBDL) circuit. Furthermore, the power optimization problem of RBDL circuits is a multi-task, multi-extremal, high-dimensional combinatorial optimization problem, for which we propose an Adaptive Multi-task Intelligent Algorithm (AMIA), which includes global task optimization, population reproduction, valuable knowledge transfer (VKT), and local exploration to search for the lowest power for RBDL circuits. Moreover, based on the proposed Fast Power Decomposition Algorithm (FPDA), we proposed a Power Optimization Approach (POA) for an RBDL circuit with the lowest power using the AMIA. Experimental results based on Microelectronics Center of North Carolina (MCNC) Benchmark test circuits demonstrate the effectiveness and superiority of the POA compared to state-of-the-art POAes.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4400500498",
    "type": "article"
  },
  {
    "title": "Multi-Stream Scheduling of Inference Pipelines on Edge Devices - a DRL Approach",
    "doi": "https://doi.org/10.1145/3677378",
    "publication_date": "2024-07-11",
    "publication_year": 2024,
    "authors": "Danny Pereira; Sumana Ghosh; Soumyajit Dey",
    "corresponding_authors": "",
    "abstract": "Low-power edge devices equipped with Graphics Processing Units (GPUs) are a popular target platform for real-time scheduling of inference pipelines. Such application-architecture combinations are popular in Advanced Driver-assistance Systems for aiding in the real-time decision-making of automotive controllers. However, the real-time throughput sustainable by such inference pipelines is limited by resource constraints of the target edge devices. Modern GPUs, both in edge devices and workstation variants, support the facility of concurrent execution of computation kernels and data transfers using the primitive of streams , also allowing for the assignment of priority to these streams. This opens up the possibility of executing computation layers of inference pipelines within a multi-priority, multi-stream environment on the GPU. However, manually co-scheduling such applications while satisfying their throughput requirement and platform memory budget may require an unmanageable number of profiling runs. In this work, we propose a Deep Reinforcement Learning (DRL)-based method for deciding the start time of various operations in each pipeline layer while optimizing the latency of execution of inference pipelines as well as memory consumption. Experimental results demonstrate the promising efficacy of the proposed DRL approach in comparison with the baseline methods, particularly in terms of real-time performance enhancements, schedulability ratio, and memory savings. We have additionally assessed the effectiveness of the proposed DRL approach using a real-time traffic simulation tool IPG CarMaker.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4400550281",
    "type": "article"
  },
  {
    "title": "A Robust Newton Iteration Method for Mixed-Cell-Height Circuit Legalization Under Technology and Region Constraints",
    "doi": "https://doi.org/10.1145/3689436",
    "publication_date": "2024-08-22",
    "publication_year": 2024,
    "authors": "Chen–Can Zhou; Yang Cao; Quan Shi; Lu-Xin Wang; Xiaoqing Wen",
    "corresponding_authors": "",
    "abstract": "The evolution of advanced technology nodes has prompted a shift toward mixed-cell-height circuit design, while the introduction of technology and fence region constraints further increases the complexity of placement. In this article, we innovatively transform the mixed-cell-height circuit legalization problem into a generalized absolute value equation (GAVE) and propose a novel and effective robust Newton (RN) iteration method to address the challenge of the legalization problem. 1 First, the window-based cell insertion technique is applied to obtain the initial cell row allocation and cell order, and the cells are allocated to the matching region based on the R-tree structure. Then, the legalization problem of cells within the region is transformed into a GAVE, and an RN iteration method is proposed to solve the GAVE. Finally, the maximum displacement cells and technology violation cells are optimized based on a greedy method. Experimental results confirm the efficiency and robustness of the proposed method compared with the state-of-the-art methods.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4401768560",
    "type": "article"
  },
  {
    "title": "Transfer Learning Enabled Modeling Paradigm for PVT-aware Circuit Performance Estimation",
    "doi": "https://doi.org/10.1145/3689435",
    "publication_date": "2024-08-23",
    "publication_year": 2024,
    "authors": "Deepthi Amuru; Raja Mavullu Vechalapu; Zia Abbas",
    "corresponding_authors": "",
    "abstract": "Designing robust performance models for modern complex digital circuits in the face of rapidly accelerating process variations is a critical yet demanding task. This paper introduces an efficient statistical performance modeling approach for VLSI digital circuits that incurs minimal computational expense. The fundamental concept involves capitalizing on knowledge gained from circuit modeling in one technology node to streamline the modeling process in another. This is achieved by merging previously established statistical models of process technology with a limited set of simulation data from a subsequent process technology through transfer learning. Comprehensive experiments conducted across diverse technology nodes demonstrate that the proposed framework is robust, precise, efficient in data usage, and computationally superior to other cutting-edge performance modeling techniques.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4401819964",
    "type": "article"
  },
  {
    "title": "Placement Flow Study and Detailed Placement for Hybrid-Row-Height Designs",
    "doi": "https://doi.org/10.1145/3690385",
    "publication_date": "2024-08-28",
    "publication_year": 2024,
    "authors": "Wei-Kai Fang; Wai-Kei Mak",
    "corresponding_authors": "",
    "abstract": "At the 3 nm node, a hybrid-row-height design paradigm has emerged for better power efficiency and performance optimization. A diverse cell library that includes multiple variants of a cell with different fin counts is available. Instead of using cells with the same fin count for the entire chip, a design may combine cells with two different fin counts. Cells with the same fin count can be laid down in the same row resulting in a chip with hybrid row heights. With this brand-new design paradigm, revisiting and revamping the conventional VLSI placement flow becomes necessary. There were attempts that addressed the placement problem associated with hybrid-row-height design at the global placement stage or the placement legalization stage. In this work, we first propose an effective detailed placement approach suitable for hybrid-row-height designs and then conduct a comprehensive study to evaluate the different options of forming a complete hybrid-row-height design placement flow. For the first time, the advantage of considering the row configuration early on in the global placement stage is confirmed. Besides, our proposed detailed placement approach can improve the final half-perimeter wirelength by over 7% on average which more than double the improvement obtainable by a basic detailed placement algorithm similar to the well-known FastDP.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4401960426",
    "type": "article"
  },
  {
    "title": "AmLuCEP: <u>Am</u> algamating <u>LU</u> T-based <u>C</u> ompression and Adaptive Encoding Assisted Block <u>P</u> lacement To Improve Lifetime of PCM-based Main Memories",
    "doi": "https://doi.org/10.1145/3689334",
    "publication_date": "2024-08-20",
    "publication_year": 2024,
    "authors": "Arijit Nath; Hemangee K. Kapoor",
    "corresponding_authors": "",
    "abstract": "With the rising demands for high capacity memory and poor scalability of the existing DRAM-based main memories, the emerging Non-volatile memories captures higher attention due to their high density and low leakage power consumption. However, the possible consideration of such memories as alternatives of DRAM is largely hindered by their intrinsic drawbacks like high write latency, high write energy and low write endurance. In this article, we propose an integrated solution by combining the effect of compression and encoding assisted block placement to improve lifetime of NVMs. We have developed a compression technique called LUT_Comp by exploiting the word-level redundancy present in the words of the incoming cache blocks to NVM. LUT_Comp remains effective in reducing bit-flips in NVMs by offering a balance in compression ratio and coverage (Cov). Additionally, we also propose an encoding based block placement policy that places the compressed blocks in the appropriate half within the memory. The integrated approach of compression and block placement termed AmLuCEP offers a uniform bit-flips distribution while further reducing bit-flips in NVM. Experimental results show that AmLuCEP reduces bit-flips by 54%, 42%, 37%, 21%; energy consumption by 41%, 28%, 24%, 13%; and improves lifetime by 57%, 40%, 38%, 21% over baseline and the existing techniques READ [ 38 ], COEF [ 39 ] and SELEC [ 13 ], respectively.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4401976614",
    "type": "article"
  },
  {
    "title": "Introduction to the Special Issue on Embedded System Software/Tools",
    "doi": "https://doi.org/10.1145/3682061",
    "publication_date": "2024-09-04",
    "publication_year": 2024,
    "authors": "Ganapati Bhat; Biresh Kumar Joardar; Mengying Zhao",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4402236390",
    "type": "article"
  },
  {
    "title": "MCMCF-Router: Multi-capacity Ordered Escape Routing Algorithms for Grid/Staggered Pin Array",
    "doi": "https://doi.org/10.1145/3695253",
    "publication_date": "2024-09-14",
    "publication_year": 2024,
    "authors": "Zhenyi Gao; Sheqin Dong; Zhicong Tang; Wenjian Yu",
    "corresponding_authors": "",
    "abstract": "Ordered escape routing (OER), which means the pins need to be routed to the boundary of a pin array in a given order, is an important research topic in PCB design. Although OER has been widely investigated, most works assume that the routing capacity between two adjacent pins is just 1 and the structure of the pin array is a grid pin array (GPA). In this article, we focus on multi-capacity OER (MC-OER) both in grid pin arrays and staggered pin arrays (SPA), which means multiple wires are allowed to pass through between two adjacent pins. We first propose a multi-capacity multi-commodity flow (MC-MCF) model for the MC-OER problem. To accelerate the routing process, MCMCF-Router is proposed. In MCMCF-Router, a wiring resources driven partition strategy (WRDPS) is proposed to reduce the problem size, followed by the approach based on routing conflicts. These approaches largely accelerate the MC-MCF model based method and increase the routability with minimal sacrifice on wire length. Experiments on various cases (with up to 525 pins) show that the proposed method achieves 100% routability within reasonable time (&lt; 810 seconds). Compared to the state-of-the-art works for single-capacity OER (SC-OER) problems, MCMCF-Router performs similarly well or better.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4402542619",
    "type": "article"
  },
  {
    "title": "A Bridge-based Algorithm for Simultaneous Primal and Dual Defects Compression on Topologically Quantum-error-corrected Circuits",
    "doi": "https://doi.org/10.1145/3695252",
    "publication_date": "2024-09-14",
    "publication_year": 2024,
    "authors": "W. F. Tseng; Yao‐Wen Chang",
    "corresponding_authors": "",
    "abstract": "Topological quantum error correction (TQEC) using the surface code is among the most promising techniques for fault-tolerant quantum circuits. The required resource of a TQEC circuit can be modeled as a space-time volume of a three-dimensional diagram by describing the defect movement along the time axis. For large-scale complex problems, it is crucial to minimize the space-time volume for a quantum algorithm with a reasonable physical qubit number and computation time. Previous work proposed an automated tool for bridge compression on a large-scale TQEC circuit. However, the existing automated bridge compression is only for dual defects and not for primal defects. This paper presents an algorithm to simultaneously perform bridge compression on primal and dual defects. In addition, the automatic compression algorithm performs initialization/measurement simplification and flipping to improve the compression. Compared with the state-of-the-art work, experimental results show that our proposed algorithm can averagely reduce space-time volumes by 53%.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4402542963",
    "type": "article"
  },
  {
    "title": "Realizing In-Memory Computing using Reliable Differential 8T SRAM for Improved Latency",
    "doi": "https://doi.org/10.1145/3696666",
    "publication_date": "2024-09-23",
    "publication_year": 2024,
    "authors": "Ayush Dahiya; Poornima Mittal; Rajesh Rohilla",
    "corresponding_authors": "",
    "abstract": "Traditional von Neumann computing architectures suffer from high energy and lower speed as compared to the requirements of modern applications like those required in neural network accelerators. A modified differential eight transistor (8 + T) static random access memory (SRAM)-based in-memory computing (IMC) structure was presented for realizing bit-wise Boolean logic operations. The 8 + T SRAM-IMC is designed at the 32 nm technology node with throughput of 2.1849, 2.4815, 2.5795, 2.6240, 2.6495, 2.6619, 2.6690, 2.6732, and 2.6749 giga outputs per second for 0.5 to 1.3 V supply voltage range, respectively. The differential 8T cell used to implement logic operations supports NAND and NOR operations with minimal overhead while also performing the standard storage operation with added stability over the conventional 6T and 8T SRAM cells. The SRAM-IMC offers reliable Boolean logic operations by using asymmetric sensing strategy for all process corners, TT, SS, SF, FS, and FF for an operating temperature range of 220 K to 400 K. Monte Carlo simulation considering global threshold voltage deviation of 50 mV was performed for various operating conditions to study the impact of variations on design parameters such as latency.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4402728113",
    "type": "article"
  },
  {
    "title": "Assertion-Based Validation using Clustering and Dynamic Refinement of Hardware Checkers",
    "doi": "https://doi.org/10.1145/3696108",
    "publication_date": "2024-09-16",
    "publication_year": 2024,
    "authors": "Sahan Sanjaya; Hasini Witharana; Prabhat Mishra",
    "corresponding_authors": "",
    "abstract": "Post-silicon validation is a vital step in System-on-Chip (SoC) design cycle. A major challenge in post-silicon validation is the limited observability of internal signal states using trace buffers. Hardware assertions are promising to improve observability during post-silicon debug. Unfortunately, we cannot synthesize thousands (or millions) of pre-silicon assertions as hardware checkers (coverage monitors) due to hardware overhead constraints. Therefore, we need to select the most profitable assertions based on design constraints. However, the design constraints can also change dynamically during the device lifetime due to changes in use-case scenarios as well as input variations. Therefore, assertion selection needs to dynamically adapt based on changing circumstances. In this paper, we propose an assertion-based post-silicon validation framework to address the above challenges. Specifically, this paper makes two important contributions. We propose a clustering-based assertion selection technique that can select the most profitable pre-silicon assertions to maximize the fault coverage. We also present a cost-aware dynamic refinement technique that can select beneficial hardware checkers during runtime based on changing design constraints. Experimental evaluation demonstrates that our proposed pre-silicon assertion selection can outperform state-of-the-art assertion ranking methods (Goldmine and HARM). The results also highlight that our proposed post-silicon dynamic refinement can accurately predict area (less than 5% error) and power consumption (less than 3% error) of hardware checkers at runtime. This accurate prediction enables the identification of the most profitable hardware checkers based on design constraints.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4402806400",
    "type": "article"
  },
  {
    "title": "SHAREDD: Sharing of Test Data and Design-for-Testability Logic for Transition Fault Tests under Standard Scan",
    "doi": "https://doi.org/10.1145/3698198",
    "publication_date": "2024-09-28",
    "publication_year": 2024,
    "authors": "Irith Pomeranz",
    "corresponding_authors": "Irith Pomeranz",
    "abstract": "High reliability requirements in certain systems are combined with constraints on test overheads including test data volume, test application time and design-for-testability ( DFT ) logic. The overheads can be reduced if they are shared among different types of tests and optimized together. Several observations are combined in this article to allow sharing of overheads when the goal is to produce a compact transition fault test set with a high fault coverage and low storage requirements supported by design-for-testability ( DFT ) logic under standard scan. Based on these observations, the iterative procedure described in this article optimizes four parameters together: (1) the transition fault coverage, (2) the number of stored tests, (3) the number of applied tests, and (4) the size of the DFT logic. Experimental results for benchmark circuits in an academic environment demonstrate the effectiveness of the procedure.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4402949355",
    "type": "article"
  },
  {
    "title": "Layout Congestion Prediction Based on Regression-ViT",
    "doi": "https://doi.org/10.1145/3698196",
    "publication_date": "2024-09-30",
    "publication_year": 2024,
    "authors": "Guiqi Mo; Yimin Xia; Jianhong Ou; Shuting Cai; Xiaoming Xiong",
    "corresponding_authors": "",
    "abstract": "To accelerate the back-end design flow of integrated circuit (IC), numerous studies have made exploratory advancements in machine learning (ML) for electronic design automation (EDA). However, most research works are limited to deep learning (DL) models predominantly based on convolutional neural networks, and the models often suffer from poor generalization due to the scarcity of data. In this study, we propose the Double generative adversarial networks (D-GAN) model to enrich the dataset and propose the Regression Vision Transformer (R-ViT) model to predict layout congestion information. Compared to the baseline model, experimental results show improvements of 3.03% and 2.64% in Receiver Operating Characteristic-Area under Curve (ROC-AUC) and Precision-Recall Curve-Area under Curve (PRC-AUC) respectively. To further enhance the prediction accuracy of the model, an adaptive Huber loss function is designed to optimize the training process, resulting in an improvement of up to 11.03% in ROC-AUC compared with the baseline model. Lastly, extended experiments are conducted to study the effects of parameters and convolutional kernel size on performance, which find a better configuration.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4402991159",
    "type": "article"
  },
  {
    "title": "Fast Candidate Screening for Post-diagnosis Refinement",
    "doi": "https://doi.org/10.1145/3698197",
    "publication_date": "2024-09-30",
    "publication_year": 2024,
    "authors": "Hongfei Wang; Longyun Bian; Hongcan Xiong; Hai Jin",
    "corresponding_authors": "",
    "abstract": "Oftentimes fault candidates produced by logic diagnosis are too many to effectively guide the follow-on failure analysis. In this work, we propose a novel two-stage fast screening method to sift through large amount of candidates in the fault callout outputted by the commercial diagnosis tool. Candidates that are unlikely to be true ones are re-assigned lower ranks or discarded as diagnosis noise. Experimental results based on benchmark designs from various sources show that within the new categorical ranking list, the number of remaining candidates is only 53.78% of the original ones produced by the diagnosis tool, while ensuring an average accuracy of 91.65%, leading to a 1.98 × increase in diagnostic resolution. Our fast screening method only takes seconds of model training and computation, while using no other additional resource besides necessary inputs for generic logic diagnosis.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4402992061",
    "type": "article"
  },
  {
    "title": "Real-time Blood Pressure Prediction on Wearable Devices using Edge Based Deep Neural Networks: A Hardware-software Co-design Approach",
    "doi": "https://doi.org/10.1145/3699512",
    "publication_date": "2024-10-07",
    "publication_year": 2024,
    "authors": "Tresa Joseph; T. S. Bindiya",
    "corresponding_authors": "",
    "abstract": "This paper presents the hardware realization of a real-time blood pressure (BP) prediction model for wearable devices, utilizing long short-term memory (LSTM) deep neural networks (DNNs). The proposed system uses both electrocardiogram (ECG) and photoplethysmogram (PPG) signal values for BP prediction. It aims to address the limitations of traditional BP measurement methods, providing a low error, minimal computational overhead, more accurate and convenient alternative system for individuals with hypertension or at risk for cardiovascular diseases. The utilization of split matrix approach leads to a reduction in hardware complexity across the entire system. This technique involves breaking down the larger weight matrices used in the computations of DNNs into smaller matrices. This fragmentation results in a decrease in the complexity of the hardware responsible for performing matrix vector multiplications (MVMs) within LSTMs. The resultant architecture of the predictive model gains several advantages, including a lowered level of complexity in terms of the space occupied by individual cells, decreased processing delay, and reduced power consumption. Furthermore, this approach enables the achievement of a notably improved minimum achievable clock period of 2.972 ns. This prediction model can operate locally on wearable devices, reducing the reliance on cloud computing and improving privacy and security. The performance evaluations are carried out using both analytical and implementation results. The results indicate that the proposed model can be practically applied to real-world problems and can potentially enhance the accuracy of various machine-learning tasks.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4403195199",
    "type": "article"
  },
  {
    "title": "PROTECTS: Progressive Rtl Obfuscation with ThrEshold Control Technique during architectural Synthesis",
    "doi": "https://doi.org/10.1145/3701032",
    "publication_date": "2024-10-17",
    "publication_year": 2024,
    "authors": "Sonam Sharma; Dipanjan Roy; Digambar Pawar",
    "corresponding_authors": "",
    "abstract": "Due to the supply chain globalization of the semiconductor industry, securing heterogeneous System-on-Chip (SoC) is becoming necessary. A malicious alteration, inserting Hardware Trojan, infringement, or counterfeiting of design via Reverse Engineering (RE) is the primary reason. As RE allows attackers to uncover proprietary algorithms, design specifications, and other intellectual property, exploiting the design becomes easier. This has a havoc impact on the manufacturer’s revenue as well as erodes consumer trust in the authenticity of the devices. This enforces a robust framework from the topmost design abstraction level to protect against RE attacks. This article proposed a robust, architectural synthesis-driven dual-phase functional obfuscation framework for securing Register Transfer Level design. In this framework, obfuscation is achieved for both the datapath (DP) and control unit (CU) of design. Further, the robustness of obfuscated design is tested against sophisticated DP and CU level attacks. Moreover, to protect the design from brute force attack, a Consecutive Design Mis-Authentication Prevention Mechanism (CDMAP) is proposed. The proposed framework is validated using six standard Hardware Accelerator (HA) benchmarks and evaluated based on design overhead and robustness for different key sizes. A significant improvement is achieved in terms of security (∼1800 times) and (∼5.2 times) and strength of obfuscation (∼1.87 × 10 56 times) and (∼5.94 × 10 33 times) at a lower design cost of around (∼20.4%) and (∼10.4%) compared to two closely related approaches.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4403490311",
    "type": "article"
  },
  {
    "title": "STCO: Enhancing Training Efficiency via Structured Sparse Tensor Compilation Optimization",
    "doi": "https://doi.org/10.1145/3701033",
    "publication_date": "2024-10-21",
    "publication_year": 2024,
    "authors": "Shiyuan Huang; Fangxin Liu; Tian Li; Zongwu Wang; Ning Yang; Haoming Li; Li Jiang",
    "corresponding_authors": "",
    "abstract": "Network sparsification serves as an effective technique to accelerate Deep Neural Network (DNN) inference. However, existing sparsification techniques often rely on structured sparsity, which yields limited benefits. This is primarily due to the significant memory and computational overhead introduced by numerous sparse storage formats during address generation and gradient updates. Additionally, many of these solutions are tailored solely for the inference phase, neglecting the crucial training phase. In this article, we introduce STCO, a novel Sparse Tensor Compilation Optimization technique that significantly enhances training efficiency through structured sparse tensor compilation. Central to STCO is the Tensorization-aware Index Entity (TIE) format, which effectively represents structured sparse tensors by eliminating redundant indices and minimizing storage overhead. The TIE format plays a pivotal role in the Address-carry flow (AC flow) pass, which optimizes the data layout at the computational graph level. This pass leverages the TIE format to enhance the efficiency of tensor representations, enabling more compact and efficient sparse tensor storage. Meanwhile, a shape inference pass utilizes the AC flow to derive optimized tensor shapes, further refining the performance of sparse tensor operations. Moreover, the Address-Carry TIE Flow dynamically tracks nonzero addresses, extending the benefits of sparse optimization to both forward and backward propagation. This seamless integration into the training pipeline enables a smooth transition to sparse tensor compilation without significant modifications to existing codebases. To further boost training performance, we implement an operator-level AC flow optimization pass tailored for structured sparse tensors. This pass generates efficient addresses, ensuring minimal computational overhead during sparse tensor operations. The flexibility of STCO allows it to be efficiently integrated into various frameworks or compilers, providing a robust solution for enhancing training efficiency with structured sparse tensors. Experiments demonstrated that STCO achieved impressive speedups of 3.64×, 5.43×, 4.89×, and 3.91× when compared to state-of-the-art sparse formats on VGG16, ResNet-18, MobileNetV1, and MobileNetV2, respectively. These findings underscore the efficiency and superiority of our proposed approach in leveraging unstructured sparsity for DNN inference acceleration.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4403584939",
    "type": "article"
  },
  {
    "title": "Adversarial Circuit Rewriting against Graph Neural Network-based Operator Detection",
    "doi": "https://doi.org/10.1145/3703911",
    "publication_date": "2024-11-11",
    "publication_year": 2024,
    "authors": "Guangwei Zhao; Kaveh Shamsi",
    "corresponding_authors": "",
    "abstract": "Recent work has shown that graph neural networks (GNNs) can be used to recover high-level word operators and their boundaries in gate-level netlists. Unlike formal methods, however, the GNN does not prove functional equivalence. As such, there is a question of whether structural transforms like circuit rewrites that preserve the functionality of the circuit can diminish the performance of GNN-based operator detection. In this work, we explore this problem by performing simple rewrites on benchmark circuits and showing that indeed there is a performance degradation. We propose new features and learning strategies that can alleviate this. Finally, we develop a rewriting framework that aims to optimize GNN accuracy degradation, which translates to a fine-grained adversarial circuit rewriting of sorts. This can have applications in circuit obfuscation or further improving reverse engineering by providing synthetic training data. We show how this methodology beats non-adversarial rewriting under the same area overhead.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4404247359",
    "type": "article"
  },
  {
    "title": "SIMTAM: Generation Diversity Test Programs for FPGA Simulation Tools Testing Via Timing Area Mutation",
    "doi": "https://doi.org/10.1145/3705730",
    "publication_date": "2024-11-23",
    "publication_year": 2024,
    "authors": "Zhihao Xu; Shikai Guo; Xiaochen Li; Zun Wang; He Jiang",
    "corresponding_authors": "",
    "abstract": "Field-Programmable Gate Array (FPGA) timing simulation is essential in electronic circuit design, allowing for the verification of timing characteristics like delays and clock frequencies. However, bugs in timing simulation tools can lead to inaccurate results, potentially causing designers to miss critical issues in chip performance. Traditional testing methods often fall short in thoroughly assessing these tools, as current FPGA testing primarily focuses on synthesis and behavioral simulation, neglecting timing aspects. To address this issue, we propose SIMTAM for testing timing simulation tools. Specifically, SIMTAM consists of three components: equivalent delay region construction, diversity program segment generation, and differential testing. Given a seed circuit design file written by hardware description language such as Verilog, the delay region construction component randomly identifies delay structures for inertial delay in the design file to construct equivalent delay sleep regions. In the sleep region, the simulator skips the signal pulse whose width is less than the specified delay, thus ensuring the equivalence of the variations. The diversity program segment generation component combines Verilog expressions using generation operators and inject them into the sleep region to generate diverse design files. The differential testing component compares the seed and variant design files to find compilation inconsistency issues. In five months, SIMTAM reported 16 bugs to developers in two popular timing simulation tools Iverilog and Vivado; ten of which are confirmed.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4404650601",
    "type": "article"
  },
  {
    "title": "Global Placement Exploiting Soft 2D Regularity",
    "doi": "https://doi.org/10.1145/3705729",
    "publication_date": "2024-11-25",
    "publication_year": 2024,
    "authors": "Donghao Fang; Boyang Zhang; H. HU; Wuxi Li; Bo Yuan; Jiang Hu",
    "corresponding_authors": "",
    "abstract": "Cell placement is a step of paramount importance in chip physical design and requests relentless effort for continuous improvement. Recently, designs with 2D processing element arrays have become popular primarily due to their deep neural network hardware applications. The 2D array regularity is similar to but different from the regularity of conventional datapath designs. To exploit the 2D array regularity, this work develops a new global placement technique, PASOR (Placement of Arrays with SOft Regularity), built upon RePlAce, the state-of-the-art placement framework. Experimental results from various designs show that the proposed approach can reduce global routing wirelength by 11% and 6% compared to RePlAce and a previous work on datapath driven placement, respectively.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4404699396",
    "type": "article"
  },
  {
    "title": "STRIVE: Empowering a Low Power Tensor Processing Unit with Fault Detection and Error Resilience",
    "doi": "https://doi.org/10.1145/3705003",
    "publication_date": "2024-12-02",
    "publication_year": 2024,
    "authors": "Noel Daniel Gundi; Sanghamitra Roy; Koushik Chakraborty",
    "corresponding_authors": "",
    "abstract": "Rapid growth in Deep Neural Network (DNN) workloads has increased the energy footprint of the Artificial Intelligence (AI) computing realm. For optimum energy efficiency, we propose operating a DNN hardware in the Low-Power Computing (LPC) region. However, operating at LPC causes increased delay sensitivity to Process Variation (PV). Delay faults are an intriguing consequence of PV. In this paper, we demonstrate the vulnerability of DNNs to delay variations, substantially lowering the prediction accuracy. To overcome delay faults, we present STRIVE—a post-fabrication fault detection and reactive error reduction technique. We also introduce a time-borrow correction technique to ensure error-free DNN computation.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4404903257",
    "type": "article"
  },
  {
    "title": "Enhancing the Effectiveness of STLs for GPUs via Bounded Model Checking",
    "doi": "https://doi.org/10.1145/3706635",
    "publication_date": "2024-12-04",
    "publication_year": 2024,
    "authors": "Nikolaos I. Deligiannis; Tobias Faller; Josie E. Rodriguez Condia; Riccardo Cantoro; Bernd Becker; M. Sonza Reorda",
    "corresponding_authors": "",
    "abstract": "Graphics Processing Units (GPUs) are becoming widespread, even in safety-critical applications. In that case, it is imperative to guarantee that the probability of producing critical failures due to hardware faults is lower than a given threshold. To detect possible permanent hardware faults as soon as they appear during the operational phase (e.g., due to aging), Software Test Libraries (STLs) have gained significant traction as a widely adopted test solution due to their effectiveness in terms of fault detection capabilities, test application time, and flexibility. However, a major drawback of this solution is the lack of automation in the STL generation phase. As a result, high manual labor is required for their generation. This becomes even more arduous in complex architectures that require in-depth knowledge to cover hard-to-test faults. In this paper, we introduce a methodology based on Bounded Model Checking to support the generation and improvement of stuck-at-oriented STLs for hard-to-test units in GPUs, showing that we can enhance the test coverage achieved by pre-existing STLs while also identifying a set of functionally untestable faults. To experimentally validate the proposed method’s effectiveness, we use the FlexGripPlus GPU model to target two hard-to-test units, one medium to low complexity sub-unit and one high complexity sub-unit, as study cases. For both units, we had pre-existing STLs written for the stuck-at model. Resorting to the proposed method, the STLs’ test coverage was increased by 9.57% and 2.19%, respectively. In addition, the method also identified a significant number of functionally untestable faults.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4405003447",
    "type": "article"
  },
  {
    "title": "PACE: A Piece-Wise Approximate Floating-Point Divider with Runtime Configurability and High Energy Efficiency",
    "doi": "https://doi.org/10.1145/3706634",
    "publication_date": "2024-12-16",
    "publication_year": 2024,
    "authors": "Chenyi Wen; Haonan Du; Jiayi Wang; Zhengrui Chen; Li Zhang; Qi Sun; Cheng Zhuo",
    "corresponding_authors": "",
    "abstract": "Approximate computing emerges as a viable solution to enhance energy efficiency in applications sensitive to human perception, particularly on edge devices. This work introduces a novel piece-wise approximate floating-point divider that boasts resource efficiency and runtime configurability. Our method leverages a piece-wise approximation algorithm for computing 1/ y by exploiting powers of 2, complemented by an error compensation technique grounded in thorough mathematical analysis. This approach facilitates the realization of a reciprocal-based floating-point divider devoid of multipliers, which not only mitigates hardware resource consumption but also reduces latency. Additionally, we unveil a multi-level runtime configurable hardware architecture that significantly improves flexibility across diverse application contexts. Compared to the existing state-of-the-art approximate dividers and truncated exact dividers, our proposed solution achieves a superior compromise between precision and resource efficiency. Application-level evaluations reveal that our design provides over 87.7% energy saving, while maintaining a negligible impact on output quality.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4405452714",
    "type": "article"
  },
  {
    "title": "Harnessing Machine Learning in Dynamic Thermal Management in Embedded CPU-GPU Platforms",
    "doi": "https://doi.org/10.1145/3708890",
    "publication_date": "2024-12-20",
    "publication_year": 2024,
    "authors": "Srijeeta Maity; Anirban Majumder; Rudrajyoti Roy; Ashish R. Hota; Soumyajit Dey",
    "corresponding_authors": "",
    "abstract": "With increasing transistor density, modern heterogeneous embedded processors often exhibit high temperature gradients due to complex application scheduling scenarios which may have missed design considerations. In many use cases, off-chip ”active” cooling solutions are considered prohibitive in such reduced form factors. Core frequency throttling by existing dynamic thermal management techniques often compromises the Quality-of-Service (QoS) and violates real-time deadlines. This necessitates the adoption of intelligent resource management that simultaneously manages both thermal and latency performance. Coupled with the complexity of modern heterogeneous multi-cores, the periodic application updates that cater to ever-changing user requirements often render model-driven thermal-aware resource allocation approaches unsuitable for heterogeneous multi-core systems. For such application-architecture scenarios, we propose a novel self-learning based resource manager using Reinforcement Learning that intelligently manipulates core frequencies and task set mappings to fulfil thermal and latency objectives. Our framework employs a data-driven system modeling technique using Gaussian Process Regression to enable efficient offline training of this learning-based resource manager to avoid challenges associated with initial online training. We evaluate the approach on a heterogeneous embedded CPU-GPU platform with real workloads and observe a significant reduction in peak operating temperature when compared to the default onboard frequency governor as well as other learning-based state-of-the-art approaches.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4405647934",
    "type": "article"
  },
  {
    "title": "Scheduling and optimal register placement for synchronous circuits derived using software pipelining techniques",
    "doi": "https://doi.org/10.1145/1059876.1059877",
    "publication_date": "2005-04-01",
    "publication_year": 2005,
    "authors": "Noureddine Chabini; E.M. Aboulhamid; Ismaïl Chabini; Yvon Savaria",
    "corresponding_authors": "",
    "abstract": "Data dependency constraints constitute a lower bound P on the minimal clock period of single-phase clocked sequential circuits. In contrast to methods based on basic retiming, clocked sequential circuits with clock period P can always be obtained using software pipelining techniques. Such circuits can be derived by any method that can be framed in the following four-step process: Step 1, determine P; Step 2, compute a valid periodic schedule of the computational elements; Step 3, place registers back to the circuit; Step 4, assign the clock signals to control registers.Methods with polynomial run-time to implement this process are proposed in the literature. They implement these steps sequentially, starting with Step 1. These methods do not know how to optimally place registers which leads to an unnecessary number of registers. In this article, we address the problem of how to simultaneously implement Steps 2 and 3 in order to minimize the total number of registers. We conjecture that the problem is NP-hard in its general form. We formulate the problem for the first time in the literature, and devise a Mixed Integer Linear Program (MILP) to solve it. From this MILP, we derive a linear program to determine approximate solutions to the problem for large general circuits. We show that the proposed approach can handle nonzero clock skew. Experimental results confirm the effectiveness of the approach and show that significant reductions of the number of registers can be obtained although register sharing is not used. When the schedule is given, the proposed approach provides solutions to the problem of how to place the minimal number of registers in Step 3.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W1972225499",
    "type": "article"
  },
  {
    "title": "A framework for systematic validation and debugging of pipeline simulators",
    "doi": "https://doi.org/10.1145/1080334.1080336",
    "publication_date": "2005-07-01",
    "publication_year": 2005,
    "authors": "Arnab Roy; S.K. Panda; Rajeev Kumar; P.P. Chakrabarti",
    "corresponding_authors": "",
    "abstract": "Microprocessor pipeline simulation at the system level is an extremely important activity in the architecture exploration process. In this article, we address the problem of validating and debugging a pipeline simulator from the specific perspective of instruction scheduling. We propose a general framework for a systematic validation process and show that the assumptions made are justified for most standard pipeline models. The framework does not need any formal specification of the pipeline logic and hence can be readily integrated into the simulation and iteration-based architectural design space exploration process. We propose a concept of semantic equivalence between two simulations called D* equivalence which effectively captures the dataflow between instructions through registers. We then proceed to propose an algorithm which decides this equivalence in time polynomial in the number of instructions executed and the number of registers. We implement the algorithm and demonstrate how the framework facilitates debugging.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W1976832701",
    "type": "article"
  },
  {
    "title": "A new approach for integration of min-area retiming and min-delay padding for simultaneously addressing short-path and long-path constraints",
    "doi": "https://doi.org/10.1145/1013948.1013949",
    "publication_date": "2004-07-01",
    "publication_year": 2004,
    "authors": "Vijay Sundararajan; Sachin S. Sapatnekar; Keshab K. Parhi",
    "corresponding_authors": "",
    "abstract": "This article describes a polynomial time algorithm for min-area retiming for edge-triggered circuits to handle both setup and hold constraints. Given a circuit G and a target clock period c , our algorithm either outputs a retimed version of G satisfying setup and hold constraints or reports that such a solution is not possible, in O (∣V∣ 3 log ∣ V ∣ log (∣ V ∣ C )) steps, where ∣ V ∣ corresponds to number of gates in the circuit and C is equal to the number of registers in the circuit. This is the first polynomial-time algorithm ever reported for min-area retiming with constraints on both long and short-paths. An alternative problem formulation that takes practical issues into consideration and lowers the problem complexity is also developed. Both the problem formulations have many parallels with the original formulation of long path only retiming by Leiserson and Saxe and all the speed improvements that have been obtained on that problem statement are also demonstrated in simulation for the approach presented here. Finally, a basis is provided for deriving efficient heuristics for addressing both long-path and short-path requirements by combining the techniques of retiming and min-delay padding.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W1984027599",
    "type": "article"
  },
  {
    "title": "Synthesis of skewed logic circuits",
    "doi": "https://doi.org/10.1145/1059876.1059878",
    "publication_date": "2005-04-01",
    "publication_year": 2005,
    "authors": "Aiqun Cao; Naran Sirisantana; Cheng‐Kok Koh; Kaushik Roy",
    "corresponding_authors": "",
    "abstract": "Skewed logic circuits belong to a noise-tolerant high-performance static circuit family. Skewed logic circuits can achieve performance comparable to that of Domino logic circuits but with much lower power consumption. Two factors contribute to the reduction in power. First, by exploiting the static nature of skewed logic circuits, we can alleviate the cost of logic duplication which is typically required to overcome the logic reconvergence problem in both Domino logic and skewed logic circuits. Second, a selective clocking scheme can be applied to a skewed logic circuit to reduce the clock load and hence, clock power. In this article, we propose a two-step synthesis scheme of skewed logic circuits. In the first step, an integer linear programming-based approach is presented to overcome the logic reconvergence problem in skewed logic circuits with minimal logic duplication cost. In the second step, a dynamic programming-based heuristic is applied to achieve an optimal selective clocking scheme. Experimental results show that the average power saving of skewed logic circuits over Domino logic circuits is 41.1%.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2078421471",
    "type": "article"
  },
  {
    "title": "Target Faults for Test Compaction Based on Multicycle Tests",
    "doi": "https://doi.org/10.1145/3375278",
    "publication_date": "2020-01-17",
    "publication_year": 2020,
    "authors": "Irith Pomeranz",
    "corresponding_authors": "Irith Pomeranz",
    "abstract": "The use of multicycle tests, with several functional capture cycles between scan operations, contributes significantly to the ability to compact a test set. Multicycle tests have the added benefit that they can contribute to the detection of defects with complex behaviors that are not detected by single-cycle or two-cycle tests. To ensure that this benefit is materialized when test compaction is applied to transition faults, this article suggests to incorporate into the test compaction procedure an additional fault model whose fault coverage increases when multicycle tests are used. To ensure that the computational complexity of test compaction is not increased by a fault model with a large number of faults, or faults with complex behaviors, the added fault model is required to have the same characteristics as the transition fault model. A type of transition fault called unspecified transition fault satisfies these requirements. The article describes a test compaction procedure for transition faults that incorporates unspecified transition faults, and presents experimental results for benchmark circuits to demonstrate the levels of test compaction and fault coverage that can be achieved.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W3005913602",
    "type": "article"
  },
  {
    "title": "Generating Representative Test Sequences from Real Workload for Minimizing DRAM Verification Overhead",
    "doi": "https://doi.org/10.1145/3391891",
    "publication_date": "2020-05-27",
    "publication_year": 2020,
    "authors": "Yoonah Paik; Seon Wook Kim; Dongha Jung; Minseong Kim",
    "corresponding_authors": "",
    "abstract": "Dynamic Random Access Memory (DRAM) standards have evolved for higher bandwidth, larger capacity, and lower power consumption, so their specifications have become complicated to satisfy the design goals. These complex implementations have significantly increased the test time overhead for design verification; thus, a tremendous amount of command sequences are used. However, since the sequences generated by real machines or memory simulators are the results of scheduling for high performance, they result in low test coverage with repetitive patterns. Eventually, various workloads should be applied to increase the coverage, but this approach incurs significant test time overhead. A few preliminary studies have been proposed to generate predefined or random sequences to cover various test cases or increase test coverage. However, they have limitations in representing various memory behaviors of real workloads. In this article, we define a performance metric for estimating the test coverage when using command sequences. Then, our experiment shows that the coverage of a real machine and a simulator is low and similar. Also, the coverage patterns are almost the same in all tested benchmarks. To alleviate the problem, we propose a test-oriented command scheduling algorithm that increases the test coverage while preserving the memory behaviors of workloads and reducing the test time overhead by extracting representative sequences based on the similarity between command sequences. For the sequence extraction and the coverage estimation, our test sequences are embedded into vectors using bag-of-Ngrams. Compared to the simulator, our algorithm achieves 2.94x higher coverage while reducing the test overhead to 7.57%.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W3034298806",
    "type": "article"
  },
  {
    "title": "Performance-Driven Post-Processing of Control Loop Execution Schedules",
    "doi": "https://doi.org/10.1145/3421505",
    "publication_date": "2020-10-19",
    "publication_year": 2020,
    "authors": "Sumana Ghosh; Soumyajit Dey; Pallab Dasgupta",
    "corresponding_authors": "",
    "abstract": "The increasing demand for mapping diverse embedded features onto shared electronic control units has brought about novel ways to co-design control tasks and their schedules. These techniques replace traditional implementations of control with new methods, such as pattern-based scheduling of control tasks and adaptive sharing of bandwidth among control loops through orchestration of their execution patterns. In the current practice of control design, once the static execution schedule is prepared for control tasks, no further control-related optimization is attempted for improving the control performance. We introduce, for the first time, an algorithmic mechanism that re-engineers a recurrent control task by enforcing switching between multiple control laws, which are designed for compensating the non-uniform gaps between successive executions of the control task. We establish that such post-processing of control task schedules may potentially help in improving the combined control performance of the co-scheduled control loops that are executing on a shared platform.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W3094047427",
    "type": "article"
  },
  {
    "title": "A Novel Architecture Design for Output Significance Aligned Flow with Adaptive Control in ReRAM-based Neural Network Accelerator",
    "doi": "https://doi.org/10.1145/3510819",
    "publication_date": "2022-05-23",
    "publication_year": 2022,
    "authors": "Taozhong Li; Naifeng Jing; Jianfei Jiang; Qin Wang; Zhigang Mao; Yiran Chen",
    "corresponding_authors": "",
    "abstract": "Resistive-RAM-based (ReRAM-based) computing shows great potential on accelerating DNN inference by its highly parallel structure. Regrettably, computing accuracy in practical is much lower than expected due to the non-ideal ReRAM device. Conventional computing flow with fixed wordline activation scheme can effectively protect computing accuracy but at the cost of significant performance and energy savings reduction. For such embarrassment of accuracy, performance and energy, this article proposes a new Adaptive-Wordline-Activation control scheme ( AWA-control ) and combines it with a theoretical Output-Significance-Aligned computing flow ( OSA-flow ) to enable fine-grained control on output significance with distinct impact on final result. We demonstrate AWA-control -supported OSA-flow architecture with maximal compatibility to conventional crossbar by input retiming and weight remapping using shifting registers to enable the new flow. However, in contrast to the conventional computing architecture, the OSA-flow architecture shows the better capability to exploit data sparsity commonly seen in DNN models. So we also design a sparsity-aware OSA-flow architecture for further DNN speedup. Evaluation results show that OSA-flow architecture can provide significant performance improvement of 21.6×, and energy savings of 96.2% over conventional computing architecture with similar DNN accuracy.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4281397851",
    "type": "article"
  },
  {
    "title": "A Multilevel Spectral Framework for Scalable Vectorless Power/Thermal Integrity Verification",
    "doi": "https://doi.org/10.1145/3529534",
    "publication_date": "2022-06-15",
    "publication_year": 2022,
    "authors": "Zhiqiang Zhao; Zhuo Feng",
    "corresponding_authors": "",
    "abstract": "Vectorless integrity verification is becoming increasingly critical to the robust design of nanoscale integrated circuits. This article introduces a general vectorless integrity verification framework that allows computing the worst-case voltage drops or temperature (gradient) distributions across the entire chip under a set of local and global workload (power density) constraints. To address the computational challenges introduced by the large power grids and three-dimensional mesh-structured thermal grids, we propose a novel spectral approach for highly scalable vectorless verification of large chip designs by leveraging a hierarchy of almost linear-sized spectral sparsifiers of input grids that can well retain effective resistances between nodes. As a result, the vectorless integrity verification solution obtained on coarse-level problems can effectively help compute the solution of the original problem. Our approach is based on emerging spectral graph theory and graph signal processing techniques, which consists of a graph topology sparsification and graph coarsening phase, an edge weight scaling phase, as well as a solution refinement procedure. Extensive experimental results show that the proposed vectorless verification framework can efficiently and accurately obtain worst-case scenarios in even very large designs.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4282935176",
    "type": "article"
  },
  {
    "title": "Power Converter Circuit Design Automation Using Parallel Monte Carlo Tree Search",
    "doi": "https://doi.org/10.1145/3549538",
    "publication_date": "2022-07-21",
    "publication_year": 2022,
    "authors": "Shaoze Fan; Shun Zhang; Jianbo Liu; Ningyuan Cao; Xiaoxiao Guo; Jing Li; Xin Zhang",
    "corresponding_authors": "",
    "abstract": "The tidal waves of modern electronic/electrical devices have led to increasing demands for ubiquitous application-specific power converters. A conventional manual design procedure of such power converters is computation- and labor-intensive, which involves selecting and connecting component devices, tuning component-wise parameters and control schemes, and iteratively evaluating and optimizing the design. To automate and speed up this design process, we propose an automatic framework that designs custom power converters from design specifications using Monte Carlo Tree Search. Specifically, the framework embraces the upper-confidence-bound-tree (UCT), a variant of Monte Carlo Tree Search, to automate topology space exploration with circuit design specification-encoded reward signals. Moreover, our UCT-based approach can exploit small offline data via the specially designed default policy and can run in parallel to accelerate topology space exploration. Further, it utilizes a hybrid circuit evaluation strategy to substantially reduce design evaluation costs. Empirically, we demonstrated that our framework could generate energy-efficient circuit topologies for various target voltage conversion ratios. Compared to existing automatic topology optimization strategies, the proposed method is much more computationally efficient—the sequential version can generate topologies with the same quality while being up to 67% faster. The parallelization schemes can further achieve high speedups compared to the sequential version.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4286493996",
    "type": "article"
  },
  {
    "title": "A Problem-tailored Adversarial Deep Neural Network-Based Attack Model for Feed-Forward Physical Unclonable Functions",
    "doi": "https://doi.org/10.1145/3557742",
    "publication_date": "2022-08-16",
    "publication_year": 2022,
    "authors": "Ahmad O. Aseeri",
    "corresponding_authors": "Ahmad O. Aseeri",
    "abstract": "With the exceeding advancement in technology, the sophistication of attacks is considerably increasing. Standard security methods fall short of achieving the security essentials of IoT against physical attacks due to the nature of IoTs being resource-constrained elements. Physical Unclonable Functions (PUFs) have been successfully employed as a lightweight memoryless solution to secure IoT devices. PUF is a device that exploits the integrated circuits’ inherent randomness originated during the fabrication process to give each physical entity a unique identifier. Nevertheless, because PUFs are vulnerable to mathematical clonability, Feed-Forward Arbiter PUF (FF PUF) was introduced to withstand potential attack methods. Motivated by the necessity to expose a critical vulnerability of the standard FF PUFs design, we introduce a problem-tailored adversarial model to attack FF PUF design using a carefully engineered loop-specific neural network-based design calibrated and trained using FPGA-based in-silicon implementation data to exhibit real-world attacking scenarios posed on FF PUFs, in addition to applying simulated data. The empirical results show that the proposed adversarial model adds outperforming results to the existing studies in attacking FF PUFs, manifesting the improved efficiency in breaking FF PUFs. We demonstrate our high-performing results in numerical experiments of language modeling using the deep Neural Networks method.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4291972623",
    "type": "article"
  },
  {
    "title": "CoVerPlan: A <u>Co</u> mprehensive <u>Ver</u> ification <u>Plan</u> ning Framework Leveraging PSS Specifications",
    "doi": "https://doi.org/10.1145/3543175",
    "publication_date": "2022-06-11",
    "publication_year": 2022,
    "authors": "Sourav Das; S. Sanyal; Aritra Hazra; Pallab Dasgupta",
    "corresponding_authors": "",
    "abstract": "With increasing design complexity, the portability of tests across different designs and platforms becomes a key criterion for accelerating verification closure. The Portable Test and Stimulus Standard (PSS) is an emerging industry standard prepared by Accellera for system-on-chip verification and testing. It provides language constructs to create a target-agnostic representation of stimulus and test scenarios reused by various users across many levels of integration. In this article, we present CoVerPlan , a comprehensive verification framework built to explore the power of action inferencing on test models written in PSS. The proposed verification framework leverages a Boolean satisfiability problem planner to unwind the actual verification flow from the PSS specifications and automatically synthesizes target-specific constraint-random testbenches and formal assertions. CoVerPlan also carries out assertion-based verification of the synthesized properties. We demonstrate the efficacy of our proposed framework over several case studies, like the Advanced Microcontroller Bus Architecture advanced peripheral bus protocol, a simple Reduced Instruction Set Computer processor, and a cache coherence protocol.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4293083971",
    "type": "article"
  },
  {
    "title": "Introduction to the Special Section on Energy-Efficient AI Chips",
    "doi": "https://doi.org/10.1145/3538502",
    "publication_date": "2022-09-21",
    "publication_year": 2022,
    "authors": "Vikas Chandra; Yiran Chen; Sungjoo Yoo",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4296711044",
    "type": "article"
  },
  {
    "title": "Enhancing Lifetime and Performance of MLC NVM Caches Using Embedded Trace Buffers",
    "doi": "https://doi.org/10.1145/3659102",
    "publication_date": "2024-04-16",
    "publication_year": 2024,
    "authors": "S. Sivakumar; John Jose; Vijaykrishnan Narayanan",
    "corresponding_authors": "",
    "abstract": "Large volumes of on-chip and off-chip memory are required by contemporary applications. Emerging non-volatile memory technologies including STT-RAM, PCM, and ReRAM are becoming popular for on-chip and off-chip memories as a result of their desirable properties. Compared to traditional memory technologies such as SRAM and DRAM, they have minimal leakage current and high packing density. Non Volatile Memories (NVM), however, have a low write endurance, a high write latency, and high write energy. Non-volatile Single Level Cell (SLC) memories can store a single bit of data in each memory cell, whereas Multi Level Cells (MLC) can store two or more bits in each memory cell. Although MLC NVMs have substantially higher packing density than SLCs, their lifetime and access speed are key concerns. For a given cache size, MLC caches consume 1.84× less space and 2.62× less leakage power than SLC caches. We propose Trace buffer Assisted Non-volatile Memory Cache (TANC), an approach that increases the lifespan and performance of MLC-based last-level caches using the underutilized Embedded Trace Buffers (ETB). TANC improves the lifetime of MLC LLCs up to 4.36× and decreases average memory access time by 4% compared to SLC NVM LLCs and by 6.41× and 11%, respectively, compared to baseline MLC LLCs.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4394844556",
    "type": "article"
  },
  {
    "title": "CPSim: Simulation Toolbox for Security Problems in Cyber-Physical Systems",
    "doi": "https://doi.org/10.1145/3674904",
    "publication_date": "2024-06-25",
    "publication_year": 2024,
    "authors": "Mengyu Liu; Lin Zhang; Weizhe Xu; Shixiong Jiang; Fanxin Kong",
    "corresponding_authors": "",
    "abstract": "There are various applications of Cyber-Physical systems (CPSs) that are life-critical where failure or malfunction can result in significant harm to human life, the environment, or substantial economic loss. Therefore, it is important to ensure their reliability, security, and robustness to the attacks. However, there is no widely used toolbox to simulate CPS and target security problems, especially the simulation of sensor attacks and defense strategies against them. In this work, we introduce our toolbox CPSim, a user-friendly simulation toolbox for security problems in CPS. CPSim aims to simulate common sensor attacks and countermeasures to these sensor attacks. We have implemented bias attacks, delay attacks, and replay attacks. Additionally, we have implemented various recovery-based methods against sensor attacks. The sensor attacks and recovery methods configurations can be customized with the given APIs. CPSim has built-in numerical simulators and various implemented benchmarks. Moreover, CPSim is compatible with other external simulators and can be deployed on a real testbed for control purposes. 1",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4400017388",
    "type": "article"
  },
  {
    "title": "MAB-BMC: A Formal Verification Enhancer by Harnessing Multiple BMC Engines Together",
    "doi": "https://doi.org/10.1145/3675168",
    "publication_date": "2024-08-13",
    "publication_year": 2024,
    "authors": "Devleena Ghosh; Sumana Ghosh; Ansuman Banerjee; Raj Kumar Gajavelly; Sudhakar Surendran",
    "corresponding_authors": "",
    "abstract": "In recent times, Bounded Model Checking (BMC) engines have gained wide prominence in formal verification. Different BMC engines exist, differing in their optimization, representations and solving mechanisms used to represent and navigate the underlying state transition of the given design to be verified. The objective of this article is to examine if combinations of BMC engines can help to combine their strengths. We propose an approach that can create a sequencing of BMC engines that can reach better depth in formal verification, as opposed to executing them alone for a specified time. Our approach uses machine learning, specifically, the Multi-Armed Bandit paradigm of reinforcement learning, to predict the best-performing BMC engine for a given unrolling depth of the underlying circuit design. We evaluate our approach on a set of benchmark designs from the Hardware Model Checking Competition (HWMCC) benchmarks and show that it outperforms the state-of-the-art BMC engines in terms of the depth reached or time taken to deduce a property violation. The synthesized BMC engine sequences reach better depths than HWMCC results and the state-of-the-art technique, super_deep, for more than 80% of the cases. It also outperforms single engine runs for more than 92% of the cases where a property violation is not found within a given time duration. For designs where property violations are found within the given time duration, the synthesized sequences found the property violation in a lesser time than HWMCC for all the designs and outperformed both super_deep and single engine runs for more than 87% of the designs.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4400246441",
    "type": "article"
  },
  {
    "title": "Deadline and Period Assignment for Guaranteeing Timely Response of the Cyber-Physical System",
    "doi": "https://doi.org/10.1145/3689048",
    "publication_date": "2024-08-24",
    "publication_year": 2024,
    "authors": "Quan Zhou; Si Cai; Jianjun Li; Yi Gao; Zhi Yong Qu; Tao Jin",
    "corresponding_authors": "",
    "abstract": "Cyber-physical systems (CPSs) need to respond to each change of each monitored object in time. The entire response process can be divided into two stages: the update stage and the control stage. Tasks in CPSs can thus be divided into two kinds: update tasks and control tasks. Assigning deadlines and periods for tasks to ensure a timely response to each change of each monitored object is an important problem in CPS research. Existing methods can ensure that all changes of all objects can receive timely responses if tasks are schedulable. However, these methods have not made efforts to ensure the schedulability of tasks. Therefore, some tasks that can actually receive services cannot be serviced under these methods. In this article, we study the problem of assigning deadlines and periods for tasks while ensuring timely responses and maximizing the schedulability of tasks. Specifically, we find that the delayed deadline assignment for update tasks is the main factor that causes the low scheduling capability of existing methods. A new deadline and period assignment method is proposed based on an optimized deadline calculation scheme and an advanced deadline determination mechanism. Theoretical analysis proves the correctness and superiority of the proposed method. Experimental results show that the new method can improve 30.02% acceptance ratio and save 98.48% runtime on average, as compared to the state-of-the-art deadline and period assignment method.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4401846822",
    "type": "article"
  },
  {
    "title": "Area-driven Boolean bi-decomposition by function approximation",
    "doi": "https://doi.org/10.1145/3698879",
    "publication_date": "2024-10-08",
    "publication_year": 2024,
    "authors": "Anna Bernasconi; Valentina Ciriani; Jordi Cortadella; Marco Costa; Tiziano Villa",
    "corresponding_authors": "",
    "abstract": "Bi-decomposition rewrites logic functions as the composition of simpler components. It is related to Boolean division, where a given function is rewritten as the product of a divisor and a quotient, but bi-decomposition can be defined for any Boolean operation of two operands. The key questions are how to find a good divisor and then how to compute the quotient. In this article, we select the divisor by approximation of the original function and then characterize by an incompletely specified function the full flexibility of the quotient for each binary operator. We target area-driven exact bi-decomposition, and we apply it to the bi-decomposition of Sum-of-Products (SOP) forms. We report experiments that exhibit significant gains in literals of SOP forms when rewritten as bi-decompositions with respect to the product operator. This suggests the application of this framework to other logic forms and binary operations, both for exact and approximate implementations.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4403221911",
    "type": "article"
  },
  {
    "title": "DeLoSo: Detecting Logic Synthesis Optimization Faults Based on Configuration Diversity",
    "doi": "https://doi.org/10.1145/3701232",
    "publication_date": "2024-10-26",
    "publication_year": 2024,
    "authors": "He Jiang; Peiyu Zou; Xiaochen Li; Zhide Zhou; Xu Zhao; Yi Zhang; Shikai Guo",
    "corresponding_authors": "",
    "abstract": "Logic synthesis tools are the core components of digital circuit design, which convert programs written in hardware description languages into gate-level netlists, and optimize the netlists. However, the netlist optimization is complex, with numerous optimization parameters to be configured. Any minor optimization faults in logic synthesis tools may cause circuit diagrams to significantly deviate from the original design, posing risks in target systems. We propose DeLoSo, the De tector of Lo gic S ynthesis o ptimization faults, the first method specifically designed to identify potential faults in the optimization processes of logic synthesis tools. DeLoSo relies on netlist differences and parameter variations to guide the generation of diverse Logic Synthesis Optimization Configuration (LSOC) combinations to thoroughly test the optimization process. DeLoSo consists of three components: LSOC generator, which generates diverse LSOC combinations through configuration recombination and mutation; LSOC diversity evaluator, which assesses the diversity of optimization configurations; and LSOC validator, which validates the generated LSOC combinations to discover optimization faults. DeLoSo identified 19 faults in two established logic synthesis tools (i.e., Vivado and Yosys); 15 of them have been fixed by vendors. Particularly, the community maintainers of Yosys have considered incorporating DeLoSo into Yosys’ existing test suite.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4403790227",
    "type": "article"
  },
  {
    "title": "Physics-Informed Learning Based Multiphysics Simulation for Fast Transient TSV Electromigration Analysis",
    "doi": "https://doi.org/10.1145/3706106",
    "publication_date": "2024-11-29",
    "publication_year": 2024,
    "authors": "Xiaoman Yang; Hai‐Bao Chen; Yuhan Zhang; Tianshu Hou; Pengpeng Ren; Runsheng Wang; Zhigang Ji; Ru Huang",
    "corresponding_authors": "",
    "abstract": "Through Silicon Vias (TSVs) are vulnerable to electromigration (EM) degradation due to their high local current densities, thereby reducing the reliability of 3D ICs with stack dies and TSVs. Due to the broad application of 3D ICs, it is necessary to analyze the electromigration reliability of TSVs. To overcome the weakness of traditional method for EM modeling of TSVs, we propose a physics-informed learning approach for transient analysis of electromigration modeling in TSV by solving the conventional mass balance equation. The proposed method allows simultaneous consideration of atomic depletion and accumulation, effective resistance degradation, electric current evolution, and stress distribution. In particular, we propose a customized neural network to simulate the EM process in TSV without the need for fine grid meshing and temporal iteration in traditional methods. Considering that the loss function of the proposed model is a combination of different loss terms, we propose a modified self-adaptive loss balanced method to automatically adjust the weights of multiple loss terms to enhance network performance. Given the prediction uncertainty due to data randomness or model architecture constraints, Gaussian probabilistic model is constructed to define the self-adaptive weights and update the dynamic weights per epoch built on maximum likelihood estimation. Compared with the finite element method, the proposed physics informed neural network method can lead to a speedup with less than 0.1% mean square error. Experimental results also show that the proposed model achieves excellent performance over other competing methods and high robustness under values of initial weights, different numbers of hidden layers and neurons per layer.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4404859644",
    "type": "article"
  },
  {
    "title": "An efficient ILP-based scheduling algorithm for control-dominated VHDL descriptions",
    "doi": "https://doi.org/10.1145/268424.268428",
    "publication_date": "1997-10-01",
    "publication_year": 1997,
    "authors": "M. Münch; Norbert Wehn; Manfred Glesner",
    "corresponding_authors": "",
    "abstract": "To adopt behavioral synthesis techniques in existing design flows, the synthesis methodology must provide the designer with a mechanism to specify a component's interface timing. This will permit pre- and postsynthesis validation through cosimulation with other subsystems or even through formal verification. In control-flow dominated designs, additional timing constraints will result in a complex specification/constraint system for which the scheduling problem has been shown to be NP-complete. In this article, we present a mathematical framework for solving a special instance of the scheduling problem in control-flow dominated behavioral VHDL descriptions given that the timing of I/O signals has been completely or partially specified. It is based on a code-transformation approach that fully preserves the VHDL semantics. The scheduling problem is mapped onto an integer linear program (ILP) solvable in polynomial time assuming a restricted partial order on selected statements. It captures both control-flow and timing constraints in a single model and also exploits dataflow information to optimize the statement sequence across basic block boundaries.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W1983798852",
    "type": "article"
  },
  {
    "title": "Auxiliary variables for BDD-based representation and manipulation of Boolean functions",
    "doi": "https://doi.org/10.1145/293625.293626",
    "publication_date": "1998-07-01",
    "publication_year": 1998,
    "authors": "Gianpiero Cabodi; P. Camurati; Stefano Quer",
    "corresponding_authors": "",
    "abstract": "BDDs are the state-of-the-art technique for representing and manipulating Boolean functions. Their introduction caused a major leap forward in synthesis, verification, and testing. However, they are often unmanageable because of the large amount of nodes. To attack this problem, we insert auxiliary variables that decompose monolithic BDDs in smaller ones. This method works very well for Boolean function representation. As far as combinational circuits are concerned, representing their functions is the main issue. Going into the sequential domain, we focus on traversal techniques. We show that, once we have Boolean functions in decomposed form, symbolic manipulations are viable and efficient. We investigate the relation between auxiliary variables and static and dynamic ordering strategies. Experimental evidence shows that we achieve a certain degree of independence from variable ordering. Thus, this approach can be an alternative to dynamic re-ordering. Experimental results on Boolean function representation, and exact and approximate forward symbolic traversal of FSMs, demonstrate the benefits both in terms of memory requirements and of CPU time.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W1994049223",
    "type": "article"
  },
  {
    "title": "On measuring the effectiveness of various design validation approaches for PowerPC microprocessor embedded arrays",
    "doi": "https://doi.org/10.1145/296333.296335",
    "publication_date": "1998-10-01",
    "publication_year": 1998,
    "authors": "Li-C. Wang; Magdy S. Abadir; Jing Zeng",
    "corresponding_authors": "",
    "abstract": "Design validation for embedded arrays remains as a challenging problem in today's microprocessor design environment. At Somerset, validation of array designs relies on both formal verification and vector simulation. Although several methods for array design validation have been proposed and had great success [Ganguly et al. 1996; Pandey et al. 1996, 1997; Wang and Abadir 1997], little evidence has been reported for the effectiveness of these methods with respect to the detection of design errors. In this paper, we measure the effectiveness of different validation approaches based on automatic design error injection and simulation. The technique provides a systematic way to evaluate various validation approaches at both logic and transistor levels. Experimental results on recent PowerPC microprocessor arrays will be discussed and reported.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2005056089",
    "type": "article"
  },
  {
    "title": "ATM switch design by high-level modeling, formal verification and high-level synthesi",
    "doi": "https://doi.org/10.1145/296333.296342",
    "publication_date": "1998-10-01",
    "publication_year": 1998,
    "authors": "Sreeranga P. Rajan; Masahiro Fujita; K. Yuan; Mingu Lee",
    "corresponding_authors": "",
    "abstract": "Asynchronous Transfer Mode (ATM) has emerged as a backbone for high-speed broadband telecommunication networks. In this paper, we present ATM switch design, starting from a parametric high-level model and debugging the model using a combination of formal verification and simulation. The model has been used to synthesize ATM switches according to customers' choices, by choosing concrete values for each of the generic parameters. We provide a pragmatic combination of simulation, model checking, and theorem proving to gain confidence in the ATM switch design correctness.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2067380131",
    "type": "article"
  },
  {
    "title": "Behavioral synthesis of combinational logic using spectral-based heuristics",
    "doi": "https://doi.org/10.1145/307988.308000",
    "publication_date": "1999-04-01",
    "publication_year": 1999,
    "authors": "Mitchell A. Thornton; Vivek Nair",
    "corresponding_authors": "",
    "abstract": "A prototype system developed to convert a behavioral representation of a Boolean function in OBDD form into an initial structural representation is described and experimental results are given. The system produces a multilevel circuit using heuristic rules based on properties of a subset of spectral coefficients. Since the behavioral description is in OBDD form, efficient methods are used to quickly compute the small subset of spectral coefficients needed for the application of the heuristics. The heuristics guide subsequent decompositions of the OBDD, resulting in an iterative construction of the structural form. At each stage of the translation, the form of the decomposition is chosen in order to achieve optimization goals.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2169966284",
    "type": "article"
  },
  {
    "title": "Testing high-performance pipelined circuits with slow-speed testers",
    "doi": "https://doi.org/10.1145/944027.944034",
    "publication_date": "2003-10-01",
    "publication_year": 2003,
    "authors": "Muhammad Nummer; Manoj Sachdev",
    "corresponding_authors": "",
    "abstract": "This article presents a methodology for testing high-performance pipelined circuits with slow-speed testers. The technique uses a clock timing circuit to control data transfer in the pipeline in test mode. The technique adds no extra hardware in the data path of the pipeline and therefore has virtually no performance penalty. A clock timing circuit capable of achieving a timing resolution of 50 ps in 0.18 μm CMOS technology is presented. The design provides the ability to test the clock timing circuit itself. The effectiveness of the technique is demonstrated using a 16-bit pipelined multiplier as a test vehicle. Simulations show that we are able to detect delay faults as small as 50 ps at an input clock frequency of 100 MHz.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W1974526541",
    "type": "article"
  },
  {
    "title": "Compacting sequences with invariant transition frequencies",
    "doi": "https://doi.org/10.1145/762488.762492",
    "publication_date": "2003-04-01",
    "publication_year": 2003,
    "authors": "Ali Pınar; C. L. Liu",
    "corresponding_authors": "",
    "abstract": "Simulation-based power estimation is commonly used for its high accuracy despite excessive computation times. Techniques have been proposed to speed it up by compacting an input sequence while preserving its power-consumption characteristics. We propose a novel method to compact a sequence that preserves transition frequencies. We prove the problem is NP-complete, and propose a graph model to reduce it to that of finding a heaviest-weighted trail, and a heuristic utilizing this model. We also propose using multiple sequences for better accuracy with even shorter sequences. Experiments show that power dissipation can be estimated with an error of only 2.3%, while simulation times are reduced by 10. Proposed methods generate solutions that effectively preserve transition frequencies and that are very close to optimal. Experiments also show that multiple sequences grant more accurate results with even shorter sequences.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2048511995",
    "type": "article"
  },
  {
    "title": "ASP-Based Encoding Model of Architecture Synthesis for Smart Cameras in Distributed Networks",
    "doi": "https://doi.org/10.1145/2701419",
    "publication_date": "2015-03-02",
    "publication_year": 2015,
    "authors": "Franck Yonga; Michael Mefenza; Christophe Bobda",
    "corresponding_authors": "",
    "abstract": "A synthesis approach based on Answer Set Programming (ASP) for heterogeneous system-on-chips to be used in distributed camera networks is presented. In such networks, the tight resource limitations represent a major challenge for application development. Starting with a high-level description of applications, the physical constraints of the target devices, and the specification of network configuration, our goal is to produce optimal computing infrastructures made of a combination of hardware and software components for each node of the network. Optimization aims at maximizing speed while minimizing chip area and power consumption. Additionally, by performing the architecture synthesis simultaneously for all cameras in the network, we are able to minimize the overall utilization of communication resources and consequently reduce power consumption. Because of its reconfiguration capabilities, a Field Programmable Gate Array (FPGA) has been chosen as the target device, which enhances the exploration of several design alternatives. We present several realistic network scenarios to evaluate and validate the proposed synthesis approach.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W1989018305",
    "type": "article"
  },
  {
    "title": "FOLD",
    "doi": "https://doi.org/10.1145/2764455",
    "publication_date": "2015-09-28",
    "publication_year": 2015,
    "authors": "Irith Pomeranz",
    "corresponding_authors": "Irith Pomeranz",
    "abstract": "This article introduces a new approach to extreme static test compaction for functional test sequences that modifies the sequence in order to enhance the ability to omit test vectors from it and thus compact it. In the new approach, modification of the sequence and omission of test vectors from it are tightly coupled by focusing both subprocedures on subsequences of limited lengths. In a new process that is referred to as folding, a subsequence is partitioned into two halves, and the goal of the modification is to ensure that the two halves are as similar as possible. With similar halves, the expectation is that it will be possible to omit test vectors from the subsequence. Experimental results demonstrate that the procedure produces extremely short functional test sequences for benchmark circuits.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2026790637",
    "type": "article"
  },
  {
    "title": "Configurable range memory for effective data reuse on programmable accelerators",
    "doi": "https://doi.org/10.1145/2566662",
    "publication_date": "2014-03-01",
    "publication_year": 2014,
    "authors": "Jongeun Lee; Seongseok Seo; Jongkyung Paek; Ki‐Young Choi",
    "corresponding_authors": "",
    "abstract": "While programmable accelerators such as application-specific processors and reconfigurable architectures can dramatically speed up compute-intensive kernels of an application, application performance can still be severely limited by the communication between processors. To minimize the communication overhead, a shared memory such as a scratchpad memory may be employed between the main processor and the accelerator coprocessor. However, this setup poses a significant challenge to the main processor, which now must manage data on the scratchpad explicitly, resulting in superfluous data copying due to the inflexibility of a scratchpad. In this article, we present an enhancement of a scratchpad, Configurable Range Memory (CRM), whose address range can be reprogrammed to minimize unnecessary data copying between processors and therefore promote data reuse on the accelerator, and also present a software management algorithm for the CRM. Our experimental results involving detailed simulation of full multimedia applications demonstrate that our CRM architecture can reduce the communication overhead quite effectively, reducing the kernel execution time by up to 28% and the application runtime by up to 12.8%, in addition to considerable system energy reduction, compared to the conventional architecture based on a scratchpad.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2139468240",
    "type": "article"
  },
  {
    "title": "Introduction to the Special Issue on Reliable, Resilient, and Robust Design of Circuits and Systems",
    "doi": "https://doi.org/10.1145/2796541",
    "publication_date": "2015-09-28",
    "publication_year": 2015,
    "authors": "R. Iris Bahar; Alex K. Jones; Yuan Xie",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2152198940",
    "type": "article"
  },
  {
    "title": "Complementary Synthesis for Encoder with Flow Control Mechanism",
    "doi": "https://doi.org/10.1145/2794079",
    "publication_date": "2015-12-02",
    "publication_year": 2015,
    "authors": "Ying Qin; Shengyu Shen; Qingbo Wu; Huadong Dai; Yan Jia",
    "corresponding_authors": "",
    "abstract": "Complementary synthesis automatically generates an encoder's decoder with the assumption that the encoder's all input variables can always be uniquely determined by its output symbol sequence. However, to prevent the faster encoder from overwhelming the slower decoder, many encoders employ flow control mechanism that fails this assumption. Such encoders, when their output symbol sequences are too fast to be processed by the decoders, will stop transmitting data symbols, but instead transmitting idle symbols that can only uniquely determine a subset of the encoder's input variables. And the decoder should recognize and discard these idle symbols. This mechanism fails the assumption of all complementary synthesis algorithms, because some input variables can't be uniquely determined by the idle symbol. A novel algorithm is proposed to handle such encoders. First, it identifies all input variables that can be uniquely determined, and takes them as flow control variables. Second, it infers a predicate over these flow control variables that enables all other input variables to be uniquely determined. Third, it characterizes the decoder's Boolean function with Craig interpolant. Experimental results on several complex encoders indicate that this algorithm can always correctly identify the flow control variables, infer the predicates and generate the decoder's Boolean functions.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2182762928",
    "type": "article"
  },
  {
    "title": "Clock Period Minimization with Minimum Leakage Power",
    "doi": "https://doi.org/10.1145/2778954",
    "publication_date": "2015-12-02",
    "publication_year": 2015,
    "authors": "Shih-Hsu Huang; Hua-Hsin Yeh; Yow-Tyng Nieh",
    "corresponding_authors": "",
    "abstract": "In the design of nonzero clock skew circuits, an increase of the short-path delay may improve circuit speed or reduce leakage power. However, the impact of increasing the short-path delay on the trade-off between circuit speed and leakage power has not been well studied. An analysis of previous works shows that they can be classified into two independent groups. One group uses extra buffers to increase the short-path delay for achieving the lower bound of the clock period; however, this group has a large overhead of leakage power. The other group uses the combination of threshold voltage assignment and gate sizing (TVA/GS) to increase the short-path delay as possible for reducing leakage power; however, this group often does not work with the lower bound of the clock period. Accordingly, this article considers the simultaneous application of buffer insertion and TVA/GS during clock skew scheduling. Our objective is to minimize the leakage power for working with the lower bound of the clock period. To the best of our knowledge, our approach is the first leakage-power-aware clock skew scheduling that guarantees working with the lower bound of the clock period. Benchmark data consistently show that our approach achieves good results in terms of both the circuit speed and the leakage power.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2183222073",
    "type": "article"
  },
  {
    "title": "A New Uncertainty Budgeting-Based Method for Robust Analog/Mixed-Signal Design",
    "doi": "https://doi.org/10.1145/2778959",
    "publication_date": "2015-12-02",
    "publication_year": 2015,
    "authors": "Jin Sun; Claudio Talarico; Priyank Gupta; Janet Roveda",
    "corresponding_authors": "",
    "abstract": "This article proposes a novel methodology for robust analog/mixed-signal IC design by introducing a notion of budget of uncertainty. This method employs a new conic uncertainty model to capture process variability and describes variability-affected circuit design as a set-based robust optimization problem. For a prespecified yield requirement, the proposed method conducts uncertainty budgeting by associating performance yield with the size of uncertainty set for process variations. Hence the uncertainty budgeting problem can be further translated into a tractable robust optimization problem. Compared with the existing robust design flow based on ellipsoid model, this method is able to produce more reliable design solutions by allowing varying size of conic uncertainty set at different design points. In addition, the proposed method addresses the limitation that the size of the ellipsoid model is calculated solely relying on the distribution of process parameters, while neglecting the dependence of circuit performance upon these design parameters. The proposed robust design framework has been verified on various analog/mixed-signal circuits to demonstrate its efficiency against the ellipsoid model. Up to 24% reduction of design cost has been achieved by using the uncertainty budgeting-based method.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2214653368",
    "type": "article"
  },
  {
    "title": "Yield and Speedup Improvements in Extensible Processors by Allocating Extra Cycles to Some Custom Instructions",
    "doi": "https://doi.org/10.1145/2830566",
    "publication_date": "2016-01-28",
    "publication_year": 2016,
    "authors": "Mehdi Kamal; Ali Afzali‐Kusha; Saeed Safari; Massoud Pedram",
    "corresponding_authors": "",
    "abstract": "In this article, we investigate the application of different techniques for mitigating the impact of process variations on the custom functional unit (CFU) of extensible processors. The techniques include using extra cycles for the CFU and extending the clock period for the extensible processor. The former technique is based on providing an extra clock cycle to those custom instructions (CIs) that have timing yields smaller than one. For this purpose, we make use of a lookup table (LUT) for each fabricated processor. Based on a post-fabrication analysis, the need for an extra clock cycle for some CIs is determined. Consequently, the CI timing violations are prevented, and all manufactured extensible processors will work with a predefined clock cycle time. To study the effect of the objective function (used during the CI selection phase) on the efficacy of the suggested architectural technique, we investigate three different objective functions. In the second technique, the clock period extension is used to guarantee a design yield of one. Our results demonstrate that combining both techniques helps increase the speedup achieved by the extensible processor. To assess the efficacies of the proposed methods, several benchmarks from different application domains are used. Results of the study reveal that the suggested techniques provide considerable improvements in the speedups of the extensible processors when compared to those of approaches that do not consider the impact of process variations.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2256557278",
    "type": "article"
  },
  {
    "title": "Adapting to Varying Distribution of Unknown Response Bits",
    "doi": "https://doi.org/10.1145/2835489",
    "publication_date": "2016-01-28",
    "publication_year": 2016,
    "authors": "Chandra K. H. Suresh; Ozgur Sinanoglu; Sule Ozev",
    "corresponding_authors": "",
    "abstract": "Traditionally, test patterns that are generated for a given circuit are applied in an identical manner to all manufactured devices until each device under test either fails or passes each test. With increasing process variations, the statistical diversity of manufactured devices is increasing, making such one-size-fits-all approaches increasingly inefficient. Adaptive test techniques address this problem by tailoring the test decisions for the statistical characteristics of the device under test. In this article, we present several adaptive strategies to enable adaptive unknown bit masking for faster-than-at-speed testing so as to ensure no yield loss while attaining the maximum test quality based on tester memory constraints. We also develop a tester-enabled compression scheme that helps alleviate memory constraints further, shifting the tradeoff space favorably to improve test quality.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2261800295",
    "type": "article"
  },
  {
    "title": "Array Size Computation under Uniform Overlapping and Irregular Accesses",
    "doi": "https://doi.org/10.1145/2818643",
    "publication_date": "2016-01-28",
    "publication_year": 2016,
    "authors": "Angeliki Kritikakou; Francky Catthoor; Vasilios Kelefouras; Costas E. Goutis",
    "corresponding_authors": "",
    "abstract": "The size required to store an array is crucial for an embedded system, as it affects the memory size, the energy per memory access, and the overall system cost. Existing techniques for finding the minimum number of resources required to store an array are less efficient for codes with large loops and not regularly occurring memory accesses. They have to approximate the accessed parts of the array leading to overestimation of the required resources. Otherwise, their exploration time is increased with an increase over the number of the different accessed parts of the array. We propose a methodology to compute the minimum resources required for storing an array which keeps the exploration time low and provides a near-optimal result for regularly and non-regularly occurring memory accesses and overlapping writes and reads.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2271130898",
    "type": "article"
  },
  {
    "title": "Performance-Driven Assignment of Buffered I/O Signals in Area-I/O Flip-Chip Designs",
    "doi": "https://doi.org/10.1145/2818642",
    "publication_date": "2016-01-28",
    "publication_year": 2016,
    "authors": "Jin-Tai Yan",
    "corresponding_authors": "Jin-Tai Yan",
    "abstract": "Due to the inappropriate assignment of bump pads or the improper assignment of I/O buffers, the constructed buffered I/O signals in an area-I/O flip-chip design may yield longer maximum delay. In this article, the problem of assigning performance-driven buffered I/O signals in an area-I/O flip-chip design is first formulated. Furthermore, the assignment of the buffered I/O signals can be divided into two sequential phases: Construction of performance-driven I/O signals and Assignment of timing-constrained I/O buffers. Finally, an efficient matching-based approach is proposed to construct the performance-driven I/O signals for the given I/O pins and assign the timing-constrained I/O buffers into the constructed I/O signals in the assignment of the buffered I/O signals in an area-I/O flip-chip design. Compared with the experimental results of seven tested circuits in the Elmore delay model, the experimental results show that the matching-based assignment in our proposed approach can reduce 3.56% of the total path delay, 9.72% of the maximum input delay, 5.90% of the input skew, 5.64% of the maximum output delay, and 6.25% of the output skew on average by reassigning the I/O buffers. Our proposed approach can further reduce 38.89% of the total path delay, 44.00% of the maximum input delay, 49.13% of the input skew, 44.93% of the maximum output delay, and 50.82% of output skew on average by reconstructing the I/O signals and reassigning the I/O buffers into the I/O signals. Compared with the experimental results of seven tested circuits in Peng's [Peng et al. 2006] publication, the experimental results show that our proposed matching-based approach can further reduce 71.06% of the total path delay, 67.83% of the maximum input delay, 59.84% of the input skew, 68.87% of the maximum output delay, and 61.46% of the output skew on average. On the other hand, compared with the experimental results of five tested circuits in Lai's [Lai and Chen 2008] publication, the experimental results show that our proposed approach can further reduce 75.36% of the total path delay, 48.94% of the input skew, and 52.80% of the output skew on the average.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2272169140",
    "type": "article"
  },
  {
    "title": "Differential Write-Conscious Software Design on Phase-Change Memory",
    "doi": "https://doi.org/10.1145/2842613",
    "publication_date": "2016-04-19",
    "publication_year": 2016,
    "authors": "Sungkwang Lee; Taemin Lee; Hyunsun Park; Junwhan Ahn; Sungjoo Yoo; Youjip Won; Sunggu Lee",
    "corresponding_authors": "",
    "abstract": "Phase-change memory (PCM) has several benefits including low cost, non-volatility, byte-addressability, etc., and limitations such as write endurance. There have been several hardware approaches to exploit the benefits while minimizing the negative impact of limitations. Software approaches could give further improvements, when used together with hardware approaches, by taking advantage of write behavior present in the program, e.g., write behavior on dynamically allocated data, which is hardly captured by hardware approaches. This work proposes a software design methodology to reduce costly PCM writes. First, on top of existing hardware approach such as Flip-N-Write, we advocate exploiting the capability of PCM bit-level differential write in the software by judiciously reusing previously allocated memory resource. In order to avoid wear-out incurred by the reuse, we present software-based wear-leveling methods that distribute writes across PCM cells. In order to further reduce PCM writes, we propose identifying data, the loss of which does not affect the functionality of the underlying software, and then diverting write traffic for those data items to volatile memory. To evaluate the effectiveness of these methods, as a case study, we applied the proposed methods to the design of journaling in SQLite, which is an important database application commonly used in smartphones. For the experiments, we used an in-house PCM-based prototype board. Our experiments with four representative mobile applications show that the proposed design methods, which is applied on top of the hardware approach, Flip-N-Write, result in 75.2% further reduction in total bit updates in PCM, on average, without aggravating wear-out compared with the baseline of PCM-based journaling, which is based only on the hardware approach. Also, the proposed design methods result in 49.4% reduction in energy consumption and 52.3% reduction in runtime compared to a typical FIFO management of free resources.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2337432218",
    "type": "article"
  },
  {
    "title": "Novel Adaptive Power-Gating Strategy and Tapered TSV Structure in Multilayer 3D IC",
    "doi": "https://doi.org/10.1145/2894752",
    "publication_date": "2016-04-20",
    "publication_year": 2016,
    "authors": "Seungwon Kim; Seokhyeong Kang; Ki Jin Han; Youngmin Kim",
    "corresponding_authors": "",
    "abstract": "Among power dissipation components, leakage power has become more dominant with each successive technology node. Power-gating techniques have been widely used to reduce the standby leakage energy. In this work, we investigate a power-gating strategy for through-silicon via (TSV)-based 3D IC stacking structures. Power-gating control is becoming more complicated as more dies are stacked. We combine the on-chip PDN and TSV in a multilayered 3D IC to perform power-gating analysis of the static and dynamic voltage drops and in-rush current. Then, we propose a novel power-gating strategy that optimizes the in-rush current profile, subject to the voltage-drop constraints. Our power-gating strategy provides a minimal wake-up latency such that the voltage noise safety margins are not violated. In addition, the layer dependency of the 3D IC on the power gating is analyzed in terms of the wake-up time reduction. We achieve an average wake-up time reduction of 43% for all cases with our adaptive power-gating method that exploits location (or layer) information regarding the aggressors in a 3D IC. A tapered TSV architecture based on the layer dependency has been analyzed; it exhibits up to 18% wake-up time reduction compared to that of circuits with uniform TSVs.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2339195741",
    "type": "article"
  },
  {
    "title": "Process Independent Design Methodology for the Active RC and Single-Inverter-Based Rail Clamp",
    "doi": "https://doi.org/10.1145/2851490",
    "publication_date": "2016-05-16",
    "publication_year": 2016,
    "authors": "Ramachandran Venkatasubramanian; Robert Elio; Sule Ozev",
    "corresponding_authors": "",
    "abstract": "RC and single-inverter-based rail clamps are widely used in semiconductor products for electrostatic discharge (ESD) protection. We propose a technology-node-independent design methodology for these rail clamp circuits that takes process, voltage, and temperature variations into consideration. The methodology can be used as a cookbook by the designer or be used to automate the entire design process. Tradeoffs between various design metrics such as ESD performance (Human Body Model), leakage, and area are considered. Simplified circuit models for the rail clamp are presented to gain insights into its working and to size the circuit components. A rail clamp for core power domain is designed using the proposed approach in 40nm low-power process and performance results of the design are also presented. The effectiveness of the design methodology is proven in three different technology nodes by comparing the obtained design with the best design from among 250,000 designs obtained by randomly sampling from the design space.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2396076384",
    "type": "article"
  },
  {
    "title": "Statistical Rare-Event Analysis and Parameter Guidance by Elite Learning Sample Selection",
    "doi": "https://doi.org/10.1145/2875422",
    "publication_date": "2016-05-27",
    "publication_year": 2016,
    "authors": "Yue Zhao; Taeyoung Kim; Hosoon Shin; Sheldon X.-D. Tan; Xin Li; Hai‐Bao Chen; Hai Wang",
    "corresponding_authors": "",
    "abstract": "Accurately estimating the failure region of rare events for memory-cell and analog circuit blocks under process variations is a challenging task. In this article, we propose a new statistical method, called EliteScope , to estimate the circuit failure rates in rare-event regions and to provide conditions of parameters to achieve targeted performance. The new method is based on the iterative blockade framework to reduce the number of samples, but consists of two new techniques to improve existing methods. First, the new approach employs an elite-learning sample-selection scheme, which can consider the effectiveness of samples and well coverage for the parameter space. As a result, it can reduce additional simulation costs by pruning less effective samples while keeping the accuracy of failure estimation. Second, the EliteScope identifies the failure regions in terms of parameter spaces to provide a good design guidance to accomplish the performance target. It applies variance-based feature selection to find the dominant parameters and then determine the in-spec boundaries of those parameters. We demonstrate the advantage of our proposed method using several memory and analog circuits with different numbers of process parameters. Experiments on four circuit examples show that EliteScope achieves a significant improvement on failure-region estimation in terms of accuracy and simulation cost over traditional approaches. The 16b 6T-SRAM column example also demonstrates that the new method is scalable for handling large problems with large numbers of process variables.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2398476818",
    "type": "article"
  },
  {
    "title": "Obstacle-Avoiding Wind Turbine Placement for Power Loss and Wake Effect Optimization",
    "doi": "https://doi.org/10.1145/2905365",
    "publication_date": "2016-05-27",
    "publication_year": 2016,
    "authors": "Yuwei Wu; Yiyu Shi; Sudip Roy; Tsung-Yi Ho",
    "corresponding_authors": "",
    "abstract": "As finite energy resources are being consumed at faster rate than they can be replaced, renewable energy resources have drawn extensive attention. Wind power development is one such example growing significantly throughout the world. The main difficulty in wind power development is that wind turbines interfere with each other. The produced turbulence—wake effect—directly reduces the power generation. In addition, wirelength of the collection network among wind turbines is not merely an economic factor; it also decides power loss on the wind farm. Moreover, in reality, obstacles (buildings, lakes, etc.) exist on the wind farm, which are unavoidable. Nevertheless, to the best of our knowledge, none of the existing works consider wake effect, wirelength, and avoidance of obstacles all together in the wind turbine placement problem. In this article, we propose an analytical method to obtain the obstacle-avoiding placement of wind turbines, thus minimizing both power loss and wake effect. We also propose a postprocessing method to fine-tune the solution obtained from the analytical method to find a better solution. Simulation results show that our tool is 12x faster than the state-of-the-art industrial tool AWS OpenWind and 203x faster than the state-of-the-art academic tool TDA with almost the same produced power.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2400784593",
    "type": "article"
  },
  {
    "title": "Periodic Scan-In States to Reduce the Input Test Data Volume for Partially Functional Broadside Tests",
    "doi": "https://doi.org/10.1145/2911983",
    "publication_date": "2016-05-27",
    "publication_year": 2016,
    "authors": "Irith Pomeranz",
    "corresponding_authors": "Irith Pomeranz",
    "abstract": "This article describes a procedure for test data compression targeting functional and partially functional broadside tests. The scan-in state of such a test is either a reachable state or has a known Hamming distance from a reachable state. Reachable states are fully specified, while the popular LFSR -based test data compression methods require the use of incompletely specified test cubes. The test data compression approach considered in this article is based on the use of periodic scan-in states. Such states require the storage of a period that can be significantly shorter than a scan-in state, thus providing test data compression. The procedure computes a set of periods that is sufficient for detecting all the detectable target faults. Considering the scan-in states that the periods produce, the procedure ranks the periods based on the distances of the scan-in states from reachable states, and the lengths of the periods. Functional and partially functional broadside tests are generated preferring shorter periods with smaller Hamming distances. The results are compared with those of an LFSR -based approach.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2403019319",
    "type": "article"
  },
  {
    "title": "<i>N</i> -Detection Test Sets for Circuits with Multiple Independent Scan Chains",
    "doi": "https://doi.org/10.1145/2897514",
    "publication_date": "2016-05-18",
    "publication_year": 2016,
    "authors": "Irith Pomeranz",
    "corresponding_authors": "Irith Pomeranz",
    "abstract": "In a circuit with multiple independent scan chains, it is possible to operate groups of scan chains independently in functional or shift mode. This design-for-testability approach can be used to increase the quality of a test set. This article describes an N -detection test generation procedure for increasing the quality of a transition fault test set in such a circuit. The procedure uses the possibility of applying the same test, with the scan chains operating in different modes, to increase the numbers of detections without increasing the number of tests that need to be generated or stored on a tester. This results in reduced input storage requirements compared with a conventional N -detection test set and an increased number of applied tests. The increased quality of the test set is verified by its bridging fault coverage.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2408214455",
    "type": "article"
  },
  {
    "title": "Preface to Special Section on New Physical Design Techniques for the Next Generation of Integration Technology",
    "doi": "https://doi.org/10.1145/2902365",
    "publication_date": "2016-07-21",
    "publication_year": 2016,
    "authors": "Evangeline F. Y. Young; Azadeh Davoodi",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2477050703",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2597648",
    "publication_date": "2014-03-01",
    "publication_year": 2014,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Simulation is a common approach for assisting system design and optimization. For system-wide optimization, energy and computational resources are often the two most critical issues. Monitoring the energy state of each hardware component and measuring ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4232224950",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2939671",
    "publication_date": "2016-09-22",
    "publication_year": 2016,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Sorting is a fundamental problem in computer science and has been studied extensively. Thus, a large variety of sorting methods exist for both software and hardware implementations. For the latter, there is a trade-off between the throughput achieved ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4234238340",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2830627",
    "publication_date": "2015-09-28",
    "publication_year": 2015,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "In this article, we propose an efficient finite-element-based (FE-based) method for both steady and transient thermal analyses of high-performance integrated circuits based on the hierarchical matrix (H-matrix) representation. H-matrix has been shown to ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4245083530",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2888405",
    "publication_date": "2016-01-28",
    "publication_year": 2016,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Developing circuits for streaming applications written in C (or its variants) can benefit greatly from C-to-RTL (C2RTL) synthesis. Yet, most existing C2RTL tools lack system-level options to trade off various design constraints, such as delay and area. ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4246846935",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2852253",
    "publication_date": "2015-12-02",
    "publication_year": 2015,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "The high density of interconnects, closer proximity of modules, and routing phase are pivotal during the layout of a performance-centric three-dimensional integrated circuit (3D IC). Heuristic-based approaches are typically used to handle such NP-...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4247227310",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2663459",
    "publication_date": "2014-08-01",
    "publication_year": 2014,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "FlexRay has now become a well-established in-vehicle communication bus at most original equipment manufacturers (OEMs) such as BMW, Audi, and GM. Given the increasing cost of verification and the high degree of crosslinking between components in ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4249868515",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2796316",
    "publication_date": "2015-06-24",
    "publication_year": 2015,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "We propose a system-level solution in designing process variation aware (PVA) scalable-throughput many-core systems for energy constrained applications. In our proposed methodology, we leverage the benefits of voltage scaling for obtaining energy ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4250527122",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2948199",
    "publication_date": "2016-12-28",
    "publication_year": 2016,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "It is challenging to manage the thermal behavior of many-core microprocessors while still keeping them running at high performance since the control complexity increases as the core number increases. In this article, a novel hierarchical dynamic thermal ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4251520311",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2634048",
    "publication_date": "2014-06-01",
    "publication_year": 2014,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "The era of cloud computing on-a-chip is enabled by the aggressive move towards many-core platforms and the rapid adoption of Network-on-Chips. As a result, there is a need for large-scale distributed on-chip shared memories that are reliable, low power, ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4252220198",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2690851",
    "publication_date": "2014-11-18",
    "publication_year": 2014,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "High-assurance systems found in safety-critical infrastructures are facing steadily increasing cyber threats. These critical systems require rigorous guarantees in information flow security to prevent confidential information from leaking to an ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4252871292",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2926747",
    "publication_date": "2016-07-26",
    "publication_year": 2016,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "The placement problem has become more complex and challenging due to a wide variety of complicated constraints imposed by modern process technologies. Some of the most challenging constraints and objectives were highlighted during the most recent ACM/...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4253325769",
    "type": "paratext"
  },
  {
    "title": "Modeling layout tools to derive forward estimates of area and delay at the RTL level",
    "doi": "https://doi.org/10.1145/348019.348148",
    "publication_date": "2000-07-01",
    "publication_year": 2000,
    "authors": "Donald S. Gelosh; Dorothy E. Steliff",
    "corresponding_authors": "",
    "abstract": "Forward estimates of area and delay facilitate effective decision-making when searching the solution space of digital designs. Current estimation techniques focus on modeling the layout result and fail to deliver timely or accurate estimates. This paper presents a novel approach to deriving these area and delay estimates at the RTL level by modeling the layout tool, rather than the layout result. This approach uses machine learning techniques to capture the relationships between general design features (i.e., topology, connectivity, common input, and common output) and layout concepts (i.e., relative placement). Experiments illustrate the formulation of the training set for machine learning in this domain, and also show how we can derive different tool models. Finally, they show how we can use the resultant model to derive forward estimates of area and delay in real-world designs.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2043864413",
    "type": "article"
  },
  {
    "title": "Allocation of FIFO structures in RTL data paths",
    "doi": "https://doi.org/10.1145/348019.348044",
    "publication_date": "2000-07-01",
    "publication_year": 2000,
    "authors": "M. Balakrishnan; Heman Khanna",
    "corresponding_authors": "",
    "abstract": "Along with functional units, storage and interconnects contribute significantly to data path costs. This paper addresses the issue of reducing the costs of storage and interconnect. In a post-datapath synthesis phase, one or more queues can be allocated and variables bound to it, with the goal of reducing storage and interconnect costs. Further, in contrast to earlier work, we support “irregular” cdfgs and multicycle functional units for queue synthesis. Initial results on HLS benchmark examples have been encouraging, and show the potential of using queue synthesis to reduce datapath cost. A novel feature of our work is the formulation of the problem for a variety of FIFO structures with their own “queueing” criteria.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2052441552",
    "type": "article"
  },
  {
    "title": "Three-layer bubble-sorting-based nonManhattan channel routing",
    "doi": "https://doi.org/10.1145/348019.350285",
    "publication_date": "2000-07-01",
    "publication_year": 2000,
    "authors": "Jin-Tai Yan",
    "corresponding_authors": "Jin-Tai Yan",
    "abstract": "It is well known that a nonManhattan channel router can use fewer routing tracks, and is never worse than a Manhattan router in a channel. To my knowledge, a three-layer bubble-sorting-based nonManhattan channel routing problem is always solved by the solution in a two-layer bubble-sorintg-based nonManhattan channel routing problem. Recently, an O ( kn 2 ) heuristic algorithm [Chaudhary et al. 1991] and an O ( kn 2 ) optimal algorithm [Chen et al. 1994] have been proposed, where k is the number of two-layer routing tracks and n is the number of terminals in a bubble-sorintg-based nonManhattan channel. In this paper we propose an optimal three-layer bubble-sorintg-based nonManhattan routing algorithm to minimize the number of three-layer routing tracks. Furthermore, the time complexity of theis optimal algorithm is proven to be in O ( hn ) time, where h is the number of three-layer routing tracks and n is the number of terminals in a bubble-sorting-based nonManhattan channel.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2059436783",
    "type": "article"
  },
  {
    "title": "Efficient One-pass Synthesis for Digital Microfluidic Biochips",
    "doi": "https://doi.org/10.1145/3446880",
    "publication_date": "2021-04-22",
    "publication_year": 2021,
    "authors": "Naser Mohammadzadeh; Robert Wille; Oliver Keszöcze",
    "corresponding_authors": "",
    "abstract": "Digital microfluidics biochips are a promising emerging technology that provides fluidic experimental capabilities on a chip (i.e., following the lab-on-a-chip paradigm). However, the design of such biochips still constitutes a challenging task that is usually tackled by multiple individual design steps, such as binding, scheduling, placement, and routing. Performing these steps consecutively may lead to design gaps and infeasible results. To address these shortcomings, the concept of one-pass design for digital microfluidics biochips has recently been proposed—a holistic approach avoiding the design gaps by considering the whole synthesis process as large. But implementations of this concept available thus far suffer from either high computational effort or costly results. In this article, we present an efficient one-pass solution that is runtime efficient (i.e., rarely needing more than a second to successfully synthesize a design) while, at the same time, producing better results than previously published heuristic approaches. Experimental results confirm the benefits of the proposed solution and allow for realizing really large assays composed of thousands of operations in reasonable runtime.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W3161787199",
    "type": "article"
  },
  {
    "title": "A Framework for Validation of Synthesized MicroElectrode Dot Array Actuations for Digital Microfluidic Biochips",
    "doi": "https://doi.org/10.1145/3460437",
    "publication_date": "2021-07-30",
    "publication_year": 2021,
    "authors": "Pushpita Roy; Ansuman Banerjee",
    "corresponding_authors": "",
    "abstract": "Digital Microfluidics is an emerging technology for automating laboratory procedures in biochemistry. With more and more complex biochemical protocols getting mapped to biochip devices and microfluidics receiving a wide adoption, it is becoming indispensable to develop automated tools and synthesis platforms that can enable a smooth transformation from complex cumbersome benchtop laboratory procedures to biochip execution. Given an informal/semi-formal assay description and a target microfluidic grid architecture on which the assay has to be implemented, a synthesis tool typically translates the high-level assay operations to low-level actuation sequences that can drive the assay realization on the grid. With more and more complex biochemical assay protocols being taken up for synthesis and biochips supporting a wider variety of operations (e.g., MicroElectrode Dot Arrays (MEDAs)), the task of assay synthesis is getting intricately complex. Errors in the synthesized assay descriptions may have undesirable consequences in assay operations, leading to unacceptable outcomes after execution on the biochips. In this work, we focus on the challenge of examining the correctness of synthesized protocol descriptions, before they are taken up for realization on a microfluidic biochip. In particular, we take up a protocol description synthesized for a MEDA biochip and adopt a formal analysis method to derive correctness proofs or a violation thereof, pointing to the exact operation in the erroneous translation. We present experimental results on a few bioassay protocols and show the utility of our framework for verifiable protocol synthesis.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W3193158517",
    "type": "article"
  },
  {
    "title": "Fault Injection Attack Emulation Framework for Early Evaluation of IC Designs",
    "doi": "https://doi.org/10.1145/3480962",
    "publication_date": "2021-10-15",
    "publication_year": 2021,
    "authors": "Qiang Liu; Honghui Tang; Peiran Zhang",
    "corresponding_authors": "",
    "abstract": "Fault injection attack (FIA) has become a serious threat to the confidentiality and fault tolerance of integrated circuits (ICs). Circuit designers need an effective method to evaluate the countermeasures of the IC designs against the FIAs at the design stage. To address the need, this article, based on FPGA emulation, proposes an in-circuit early evaluation framework, in which FIAs are emulated with parameterized fault models. To mimic FIAs, an efficient scan approach is proposed to inject faults at any time at any circuit nodes, while both the time and area overhead of fault injection are reduced. After the circuit design under test (CUT) is submitted to the framework, the scan chains insertion, fault generation, and fault injection are executed automatically, and the evaluation result of the CUT is generated, making the evaluation a transparent process to the designers. Based on the framework, the confidentiality and fault-tolerance evaluations are demonstrated with an information-based evaluation approach. Experiment results on a set of ISCAS89 benchmark circuits show that on average, our approach reduces the area overhead by 41.08% compared with the full scan approach and by over 20.00% compared with existing approaches. The confidentiality evaluation experiments on AES-128 and DES-56 and the fault-tolerance evaluation experiments on two CNN circuits, a RISC-V core, a Cordic core, and the float point arithmetic units show the effectiveness of the proposed framework.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W3207357913",
    "type": "article"
  },
  {
    "title": "ParTBC: Faster Estimation of Top- <i>k</i> Betweenness Centrality Vertices on GPU",
    "doi": "https://doi.org/10.1145/3486613",
    "publication_date": "2021-11-02",
    "publication_year": 2021,
    "authors": "Somesh Singh; Tejas Shah; Rupesh Nasre",
    "corresponding_authors": "",
    "abstract": "Betweenness centrality (BC) is a popular centrality measure, based on shortest paths, used to quantify the importance of vertices in networks. It is used in a wide array of applications including social network analysis, community detection, clustering, biological network analysis, and several others. The state-of-the-art Brandes’ algorithm for computing BC has time complexities of and for unweighted and weighted graphs, respectively. Brandes’ algorithm has been successfully parallelized on multicore and manycore platforms. However, the computation of vertex BC continues to be time-consuming for large real-world graphs. Often, in practical applications, it suffices to identify the most important vertices in a network; that is, those having the highest BC values. Such applications demand only the top vertices in the network as per their BC values but do not demand their actual BC values. In such scenarios, not only is computing the BC of all the vertices unnecessary but also exact BC values need not be computed. In this work, we attempt to marry controlled approximations with parallelization to estimate the k -highest BC vertices faster, without having to compute the exact BC scores of the vertices. We present a host of techniques to determine the top- k vertices faster , with a small inaccuracy, by computing approximate BC scores of the vertices. Aiding our techniques is a novel vertex-renumbering scheme to make the graph layout more structured , which results in faster execution of parallel Brandes’ algorithm on GPU. Our experimental results, on a suite of real-world and synthetic graphs, show that our best performing technique computes the top- k vertices with an average speedup of 2.5× compared to the exact parallel Brandes’ algorithm on GPU, with an error of less than 6%. Our techniques also exhibit high precision and recall, both in excess of 94%.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W3211289297",
    "type": "article"
  },
  {
    "title": "Uncertainty Theory Based Partitioning for Cyber-Physical Systems with Uncertain Reliability Analysis",
    "doi": "https://doi.org/10.1145/3490177",
    "publication_date": "2021-11-17",
    "publication_year": 2021,
    "authors": "Si Chen; Guoqi Xie; Renfa Li; Keqin Li",
    "corresponding_authors": "",
    "abstract": "Reasonable partitioning is a critical issue for cyber-physical system (CPS) design. Traditional CPS partitioning methods run in a determined context and depend on the parameter pre-estimations, but they ignore the uncertainty of parameters and hardly consider reliability. The state-of-the-art work proposed an uncertainty theory based CPS partitioning method, which includes parameter uncertainty and reliability analysis, but it only considers linear uncertainty distributions for variables and ignores the uncertainty of reliability. In this paper, we propose an uncertainty theory based CPS partitioning method with uncertain reliability analysis. We convert the uncertain objective and constraint into determined forms; such conversion methods can be applied to all forms of uncertain variables, not just for linear. By applying uncertain reliability analysis in the uncertainty model, we for the first time include the uncertainty of reliability into the CPS partitioning, where the reliability enhancement algorithm is proposed. We study the performance of the reliability obtained through uncertain reliability analysis, and experimental results show that the system reliability with uncertainty does not change significantly with the growth of task module numbers.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W3211879899",
    "type": "article"
  },
  {
    "title": "Energy Efficient Error Resilient Multiplier Using Low-power Compressors",
    "doi": "https://doi.org/10.1145/3488837",
    "publication_date": "2021-11-17",
    "publication_year": 2021,
    "authors": "Skandha Deepsita S.; Dhayala Kumar M; Noor Mahammad Sk",
    "corresponding_authors": "",
    "abstract": "The approximate hardware design can save huge energy at the cost of errors incurred in the design. This article proposes the approximate algorithm for low-power compressors, utilized to build approximate multiplier with low energy and acceptable error profiles. This article presents two design approaches (DA1 and DA2) for higher bit size approximate multipliers. The proposed multiplier of DA1 have no propagation of carry signal from LSB to MSB, resulted in a very high-speed design. The increment in delay, power, and energy are not exponential with increment of multiplier size ( n ) for DA1 multiplier. It can be observed that the maximum combinations lie in the threshold Error Distance of 5% of the maximum value possible for any particular multiplier of size n . The proposed 4-bit DA1 multiplier consumes only 1.3 fJ of energy, which is 87.9%, 78%, 94%, 67.5%, and 58.9% less when compared to M1, M2, LxA, MxA, accurate designs respectively. The DA2 approach is recursive method, i.e., n -bit multiplier built with n/2-bit sub-multipliers. The proposed 8-bit multiplication has 92% energy savings with Mean Relative Error Distance (MRED) of 0.3 for the DA1 approach and at least 11% to 40% of energy savings with MRED of 0.08 for the DA2 approach. The proposed multipliers are employed in the image processing algorithm of DCT, and the quality is evaluated. The standard PSNR metric is 55 dB for less approximation and 35 dB for maximum approximation.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W3212085066",
    "type": "article"
  },
  {
    "title": "Accelerating UNISIM-Based Cycle-Level Microarchitectural Simulations on Multicore Platforms",
    "doi": "https://doi.org/10.1145/1970353.1970359",
    "publication_date": "2011-06-01",
    "publication_year": 2011,
    "authors": "Xiongfei Liao; Thambipillai Srikanthan",
    "corresponding_authors": "",
    "abstract": "UNISIM has been shown to ease the development of simulators for multi-/many-core systems. However, UNISIM cycle-level simulations of large-scale multiprocessor systems could be very time consuming. In this article, we propose a systematic framework for accelerating UNISIM cycle-level simulations on multicore platforms. The proposed framework relies on exploiting the fine-grained parallelism within the simulated cycles using POSIX threads. A multithreaded simulation engine has been devised from the single-threaded UNISIM SystemC engine to facilitate the exploitation of inherent parallelism. An adaptive technique that manages the overall computation workload by adjusting the number of threads employed at any given time is proposed. In addition, we have introduced a technique to balance the workloads of multithreaded executions. This load balancing involves the distributions of SystemC objects among threads. A graph-partitioning-based technique has been introduced to automate such distributions. Finally, two strategies are proposed for realizing nonautomated and fully automated adaptive multithreaded simulations, respectively. Our investigations show that notable acceleration can be achieved by deploying the proposed framework. In particular, we show that simulations on an 8-core multicore platform can provide for close to 6X speedups when simulating many-core systems with large number of cores.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W1965490579",
    "type": "article"
  },
  {
    "title": "Call for papers",
    "doi": "https://doi.org/10.1145/1929943.1929944",
    "publication_date": "2011-03-01",
    "publication_year": 2011,
    "authors": "Massoud Pedram",
    "corresponding_authors": "Massoud Pedram",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W1972157316",
    "type": "paratext"
  },
  {
    "title": "Built-in generation of multicycle functional broadside tests with observation points",
    "doi": "https://doi.org/10.1145/2534396",
    "publication_date": "2013-12-01",
    "publication_year": 2013,
    "authors": "Irith Pomeranz",
    "corresponding_authors": "Irith Pomeranz",
    "abstract": "Functional broadside tests allow overtesting to be avoided as part of a scheme that considers both test generation and the analysis of output responses, by ensuring that delay faults are detected under functional operation conditions. Compared with two-cycle tests, multicycle tests allow more faults to be detected with each test, thus reducing the number of tests that need to be applied. They also provide an opportunity for nonfunctional electrical effects, which are caused by switching between modes of operation, to subside before the clock cycles where delay faults are detected. Built-in test generation facilitates at-speed testing and reduces the test data volume. Motivated by these observations, this article describes the modification of a built-in test generation method for two-cycle functional broadside tests so as to generate multicycle functional broadside tests. The size of the hardware is not increased by the modification. The article investigates the following issues related to this method: (1) the effect of using multicycle tests on the number of tests that need to be applied; (2) fault simulation for tailoring the test generation hardware to a circuit that takes into account, to different extents, the need to allow nonfunctional electrical effects to subside; (3) the insertion of observation points in order to increase the transition fault coverage.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W1990905411",
    "type": "article"
  },
  {
    "title": "Parallel circuit simulation with adaptively controlled projective integration",
    "doi": "https://doi.org/10.1145/2003695.2003704",
    "publication_date": "2011-10-01",
    "publication_year": 2011,
    "authors": "Dong Wei; Peng Li",
    "corresponding_authors": "",
    "abstract": "In this article, a parallel transient circuit simulation approach based on an adaptively-controlled time-stepping scheme is proposed. Different from the widely-used implicit numerical integration techniques in most transient simulators, this work exploits the recently-developed explicit telescopic projective numerical integration method for efficient parallel circuit simulation. Because telescopic projective integration addresses the well-known stability issue of explicit numerical integrations by adopting combinations of inner integrators and outer integrators in a multilevel fashion, the simulation time-step is no longer limited by the smallest time constant in the circuit. With dynamic control of telescopic projective integration, the proposed projective integration framework not only leads to noticeable efficiency improvement in circuit simulation, it also lends itself to straightforward parallelization due to its explicit nature. The latter has led to encouraging runtime efficiencies, observed on shared-memory parallel platforms. In addition to solving standard initial-value problems (IVPs) of differential equations, the same telescopic integration framework is adopted for solving final-value problems (FVPs), where the system is integrated backwards in time. Through a new elegant formulation, we show how an IVP and FVP can be simultaneously solved to allow for a coarse-grained bidirectional parallel circuit simulation scheme. Such a bidirectional approach is demonstrated in the context of parallel shooting-Newton-based steady-state circuit analysis. The proposed bidirectional approach has unique and favorable properties: the solutions of the two ODE problems are completely data-independent with built-in automatic load balancing.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2000056668",
    "type": "article"
  },
  {
    "title": "Reducing the switching activity of test sequences under transparent-scan",
    "doi": "https://doi.org/10.1145/1929943.1929949",
    "publication_date": "2011-03-01",
    "publication_year": 2011,
    "authors": "Irith Pomeranz; S.M. Reddy",
    "corresponding_authors": "",
    "abstract": "Transparent-scan is a test application scheme for scan circuits. It provides unique opportunities for test compaction that do not exist with the standard test application scheme. We show that it also provides unique opportunities for reducing the power dissipation of a scan-based test set. After translating a standard scan-based test set into a transparent-scan sequence, we apply two operations for reducing the power dissipation of the sequence. The first operation attempts to remove a test vector that causes high power dissipation. The second operation attempts to replace a scan clock cycle with a functional clock cycle, or a functional clock cycle with a scan clock cycle, in order to reduce the power dissipation. Both operations are implemented such that they reduce the power dissipation without reducing the fault coverage. We also consider a third operation that attempts to complement arbitrary values in the transparent-scan sequence in order to further reduce the power dissipation.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2015088363",
    "type": "article"
  },
  {
    "title": "2011 ACM TODAES best paper award",
    "doi": "https://doi.org/10.1145/2003695.2003696",
    "publication_date": "2011-10-01",
    "publication_year": 2011,
    "authors": "Meikang Qiu; Edwin H.‐M. Sha",
    "corresponding_authors": "",
    "abstract": "In high-level synthesis for real-time embedded systems using heterogeneous functional units (FUs), it is critical to select the best FU type for each task. However, some tasks may not have fixed execution times. This article models each varied execution time as a probabilistic random variable and solves the heterogeneous assignment with probability (HAP) problem. The solution of the HAP problem assigns a proper FU type to each task such that the total cost is minimized while the timing constraint is satisfied with a guaranteed confidence probability. The solutions to the HAP problem are useful for both hard real-time and soft real-time systems. Optimal algorithms are proposed to find the optimal solutions for the HAP problem when the input is a tree or a simple path. Two other algorithms, one is optimal and the other is near-optimal heuristic, are proposed to solve the general problem. The experiments show that our algorithms can effectively reduce the total cost while satisfying timing constraints with guaranteed confidence probabilities. For example, our algorithms achieve an average reduction of 33.0% on total cost with 0.90 confidence probability satisfying timing constraints compared with the previous work using the worst-case scenario.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2031155920",
    "type": "article"
  },
  {
    "title": "Routability optimization for crossbar-switch structured ASIC design",
    "doi": "https://doi.org/10.1145/2491477.2491483",
    "publication_date": "2013-07-01",
    "publication_year": 2013,
    "authors": "Mei-Hsiang Tsai; Po-Yang Hsu; Hung-Yi Li; Yi-Huang Hung; Yi-Yu Liu",
    "corresponding_authors": "",
    "abstract": "In the routing architecture of a structured application-specific integrated circuit (ASIC), the crossbar is one of the most area-efficient switch blocks. Nevertheless, a dangling wire occurs when there is a routing bend in a crossbar switch. Dangling wires incur longer wire lengths as well as a higher interconnection capacitance. In this article, we tackle dangling wire issues for structured ASIC routability optimization. We first propose a compact graph model for crossbar-switch routing. With our graph model, switch connectivity relations can be removed to keep the 2D structured ASIC routing graph efficient and to speed up the runtime of our routing algorithm. Furthermore, we propose a heuristic dangling-wire-avoidance routing framework containing deferred pin assignment, Steiner point reassignment, and anchor pair insertion in order to minimize dangling wires and channel width. Finally, in order to take routing bends and channel width into account simultaneously, we propose concurrent and sequential integer linear programming (ILP) formulations and ILP variable/constraint degeneration techniques. The experimental results demonstrate that our proposed heuristic routing framework reduces dangling wires by 19%, channel width by 38%, and wire length by 13% to VPR using the crossbar switch (VPR-C). In addition, our sequential ILP router reduces dangling wires by 38%, channel width by 40%, and wire length by 15% compared to VPR-C. Thus, the runtime efficiency of our sequential ILP router is attractive for crossbar-switch structured ASIC routing.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2062934711",
    "type": "article"
  },
  {
    "title": "On bottleneck analysis in stochastic stream processing",
    "doi": "https://doi.org/10.1145/2491477.2491478",
    "publication_date": "2013-07-01",
    "publication_year": 2013,
    "authors": "Raj Rao Nadakuditi; Igor L. Markov",
    "corresponding_authors": "",
    "abstract": "Past improvements in clock frequencies have traditionally been obtained through technology scaling, but most recent technology nodes do not offer such benefits. Instead, parallelism has emerged as the key driver of chip-performance growth. Unfortunately, efficient simultaneous use of on-chip resources is hampered by sequential dependencies, as illustrated by Amdahl's law. Quantifying achievable parallelism in terms of provable mathematical results can help prevent futile programming efforts and guide innovation in computer architecture toward the most significant challenges. To complement Amdahl's law, we focus on stream processing and quantify performance losses due to stochastic runtimes. Using spectral theory of random matrices, we derive new analytical results and validate them by numerical simulations. These results allow us to explore unique benefits of stochasticity and show how and when they outweigh the costs for software streams.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2083782403",
    "type": "article"
  },
  {
    "title": "Analysis and minimization of power-transmission loss in locally daisy-chained systems by local energy buffering",
    "doi": "https://doi.org/10.1145/2491477.2491481",
    "publication_date": "2013-07-01",
    "publication_year": 2013,
    "authors": "Sehwan Kim; Pai H. Chou",
    "corresponding_authors": "",
    "abstract": "Power-transmission loss can be a severe problem for low-power embedded systems organized in a daisy-chain topology. The loss can be so high that it can result in failure to power the load in the first place. The first contribution of this article is a recursive algorithm for solving the transmission current on each segment of the daisy chain at a given supply voltage. It enables solving not only the transmission loss but also reports infeasible configurations if the voltage is too low. Using this core algorithm, our second contribution is to find energy-efficient configurations that use local energy buffers (LEBs) to eliminate peak load on the bus without relying on high voltage. Experimental results confirm that our proposed techniques significantly reduce the total energy consumption and enable the deployed system to operate for significantly longer.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2125389151",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2003695",
    "publication_date": "2011-10-01",
    "publication_year": 2011,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "In high-level synthesis for real-time embedded systems using heterogeneous functional units (FUs), it is critical to select the best FU type for each task. However, some tasks may not have fixed execution times. This article models each varied execution ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4231196895",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2558148",
    "publication_date": "2013-12-01",
    "publication_year": 2013,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "We introduce a Coordinated Management of Energy, Thermal, and Cooling (CoMETC) technique to minimize cooling and memory energy of server machines. State-of-the-art solutions decouple the optimization of cooling energy costs and energy consumption of CPU ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4233070601",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1929943",
    "publication_date": "2011-03-01",
    "publication_year": 2011,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "We define and study a new class of regular Boolean functions called D-reducible. A D-reducible function, depending on all its n input variables, can be studied and synthesized in a space of dimension strictly smaller than n. We show that the D-...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4233072241",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2491477",
    "publication_date": "2013-07-01",
    "publication_year": 2013,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Past improvements in clock frequencies have traditionally been obtained through technology scaling, but most recent technology nodes do not offer such benefits. Instead, parallelism has emerged as the key driver of chip-performance growth. Unfortunately,...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4244341871",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2442087",
    "publication_date": "2013-03-01",
    "publication_year": 2013,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Billion transistor systems-on-chip increasingly require dynamic management of their hardware components and careful coordination of the tasks that they carry out. Diverse real-time monitoring functions assist towards this objective through the ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4245029646",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1970353",
    "publication_date": "2011-06-01",
    "publication_year": 2011,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4245883233",
    "type": "paratext"
  },
  {
    "title": "Call for nominations for editor-in-chief",
    "doi": "https://doi.org/10.1145/2541012.2541672",
    "publication_date": "2013-10-01",
    "publication_year": 2013,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "invited-talk Share on Call for nominations for editor-in-chiefACM Transactions on Design Automation of Electronic SystemsVolume 18Issue 4October 2013 Article No.: 44pp 1https://doi.org/10.1145/2541012.2541672Published:25 October 2013Publication History 0citation65DownloadsMetricsTotal Citations0Total Downloads65Last 12 Months2Last 6 weeks2 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteGet Access",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4250233063",
    "type": "article"
  },
  {
    "title": "Performance-driven placement for dynamically reconfigurable FPGAs",
    "doi": "https://doi.org/10.1145/605440.605447",
    "publication_date": "2002-10-01",
    "publication_year": 2002,
    "authors": "Guangming Wu; Jai-Ming Lin; Yao‐Wen Chang",
    "corresponding_authors": "",
    "abstract": "In this article, we introduce a new placement problem motivated by the Dynamically Reconfigurable FPGA (DRFPGA) architectures. Unlike traditional placement, the problem for DRFPGAs must consider the precedence constraints among logic components. For the placement, we develop an effective metric that can consider wirelength, register requirement, and power consumption simultaneously. With the considerations of the new metric and the precedence constraints, we then present a three-stage scheme of partitioning, initial placement generation, and placement refinement to solve the new placement problem. Experimental results show that our placement scheme with the new metric achieves respective improvements of 17.2, 27.0, and 35.9% in wirelength, the number of registers, and power consumption requirements, compared with the list scheduling method.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W1988510914",
    "type": "article"
  },
  {
    "title": "Error Rate Estimation for Defective Circuits via Ones Counting",
    "doi": "https://doi.org/10.1145/2071356.2071364",
    "publication_date": "2012-01-01",
    "publication_year": 2012,
    "authors": "Zhaoliang Pan; Melvin A. Breuer",
    "corresponding_authors": "",
    "abstract": "With VLSI circuit feature size scaling down, it is becoming more difficult and expensive to achieve a desired level of yield. Error-tolerance employs defective chips that occasionally produce erroneous yet acceptable results in targeted applications, and has been proposed as one way to increase effective yield. These chips are characterized by criteria set by specific applications. Error rate, an upper-bound on how frequent errors occur at an output, is one such criterion. In this article we focus on the following problem: given a combinational logic circuit that is defective, and hence occasionally produces an erroneous output, how can we determine the error rate of each output line by using ones counting? The results of this work can also be used for runtime error estimation in aging systems and in environments where soft-errors are produced.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W1991951592",
    "type": "article"
  },
  {
    "title": "Variation-aware multimetric optimization during gate sizing",
    "doi": "https://doi.org/10.1145/1562514.1562522",
    "publication_date": "2009-08-01",
    "publication_year": 2009,
    "authors": "N. Ranganathan; Upavan Gupta; V. Mahalingam",
    "corresponding_authors": "",
    "abstract": "The aggressive scaling of technology has not only accentuated the effects of intradie parametric variations in devices, but it has also impacted the effects of optimizing a certain performance metric on the optimality of other metrics. Thus, there is a need for optimization methods that can perform the simultaneous optimization of multiple metrics considering the effects of process variations. In this article, a novel variation-aware gate sizing framework has been developed that can perform simultaneous optimization of multiple performance metrics. In this framework, the relationships between the optimization metrics (like dynamic power, leakage power, and crosstalk noise) are modeled as a function of the gate sizes in the objective function. The delay values obtained from unconstrained delay optimization and the noise margins derived from coupling capacitance information form the constraints for the multimetric optimization problem. As an abstract framework, it is independent of the type of mathematical programming approach as well as the metrics chosen to be optimized. The framework has been implemented using a mathematical programming approach and has been tested on ITC'99 benchmarks for different combinations of multimetric and single-metric optimizations of delay, dynamic power, leakage power, and crosstalk noise. The results indicate that the framework identifies good solution points, and is efficient for postlayout optimization via gate sizing.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2009334365",
    "type": "article"
  },
  {
    "title": "Minimizing leakage power of sequential circuits through mixed- <i> V <sub>t</sub> </i> flip-flops and multi- <i> V <sub>t</sub> </i> combinational gates",
    "doi": "https://doi.org/10.1145/1640457.1640461",
    "publication_date": "2009-12-01",
    "publication_year": 2009,
    "authors": "Jae Hyun Kim; Chungki Oh; Youngsoo Shin",
    "corresponding_authors": "",
    "abstract": "The current use of multi- V t to control leakage power targets combinational gates, even though sequential elements such as flip-flops and latches also contribute appreciable leakage. We can, nevertheless, apply multi- V t to flip-flops, but few can take advantage of high- V t , which causes abrupt changes in timing. We combine low- and high- V t at the transistor level to design mixed- V t flip-flops with reduced leakage, an unchanged footprint, and a small increase in either setup time or clock-to-Q delay, but not both. An allocation algorithm for two V t s determines the V t (mixed, high, or low) of each flip-flop and the V t of each combinational gate (high or low) in a sequential circuit. Experiments with 65-nm technology show an average leakage saving of 42% compared to conventional multi- V t approaches; the leakage of flip-flops alone is cut by 78%. This saving is largely unaffected by die-to-die or within-die process variations, which we show through simulations. Standard deviation of leakage caused by process variation is also reduced due to less use of low- V t devices. We also extend our approach to three V t s, and obtain a further 14% reduction in leakage.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2015762672",
    "type": "article"
  },
  {
    "title": "Introduction to special section on verification challenges in the concurrent world",
    "doi": "https://doi.org/10.1145/2209291.2209292",
    "publication_date": "2012-06-01",
    "publication_year": 2012,
    "authors": "Sandip Ray; Jayanta Bhadra; Magdy S. Abadir; Li-C. Wang; Aarti Gupta",
    "corresponding_authors": "",
    "abstract": "introduction Share on Introduction to special section on verification challenges in the concurrent world Authors: Sandip Ray University of Texas at Austin, TX University of Texas at Austin, TXView Profile , Jayanta Bhadra Freescale Semiconductor Inc., Austin, TX Freescale Semiconductor Inc., Austin, TXView Profile , Magdy S. Abadir Freescale Semiconductor Inc., Austin, TX Freescale Semiconductor Inc., Austin, TXView Profile , Li-C. Wang University of California at Santa Barbara, CA University of California at Santa Barbara, CAView Profile , Aarti Gupta NEC Laboratories America, Inc., Princeton, NJ NEC Laboratories America, Inc., Princeton, NJView Profile Authors Info & Claims ACM Transactions on Design Automation of Electronic SystemsVolume 17Issue 3June 2012 Article No.: 19pp 1–3https://doi.org/10.1145/2209291.2209292Published:05 July 2012Publication History 0citation172DownloadsMetricsTotal Citations0Total Downloads172Last 12 Months1Last 6 weeks1 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my Alerts New Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteGet Access",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2028292812",
    "type": "article"
  },
  {
    "title": "Using stuck-at tests to form scan-based tests for transition faults in standard-scan circuits",
    "doi": "https://doi.org/10.1145/1640457.1640464",
    "publication_date": "2009-12-01",
    "publication_year": 2009,
    "authors": "Irith Pomeranz; S.M. Reddy",
    "corresponding_authors": "",
    "abstract": "In enhanced-scan circuits, a two-pattern test &lt; t i , t j &gt; for a transition fault can be obtained by using a test t j that detects a stuck-at fault, and preceding it by a test t i that activates another stuck-at fault. Thus, test generation for transition faults can be done by combining pairs of stuck-at tests. This provides an alternative to deterministic test generation, as well as reduces the test storage requirements for transition fault tests. We study the possibility of generating scan-based tests for transition faults in standard-scan circuits in a similar way, by combining pairs of stuck-at tests. Since it is not always possible to obtain a standard-scan test that is equivalent to a two-pattern test &lt; t i , t j &gt; based on stuck-at tests t i and t j , it is not always possible to guarantee that the combination of t i and t j will detect a transition fault. To compensate for this, it is necessary to try combinations of different stuck-at test pairs, resulting in an increased simulation effort to compute effective standard-scan tests. Our focus in this work is on reducing this simulation effort by reducing the number of stuck-at test pairs that need to be considered.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2032515107",
    "type": "article"
  },
  {
    "title": "Targeted random test generation for power-aware multicore designs",
    "doi": "https://doi.org/10.1145/2209291.2209298",
    "publication_date": "2012-06-01",
    "publication_year": 2012,
    "authors": "Padmaraj Singh; Vijaykrishnan Narayanan; D.L. Landis",
    "corresponding_authors": "",
    "abstract": "Multicore Register Transfer Level (RTL) model simulations are indispensable in exposing subtle memory subsystem bugs. Validating memory consistency, coherency, and atomicity is a crucial design verification task. Random MultiProcessor (MP) test generators play critical roles in pre- and post-silicon validation. The Advanced Configuration and Power Interface (ACPI) standard supports dynamic frequency and voltage scaling by controlling performance states (P-States), yet multicore verification is generally conducted with cores operating at the P0-State. Independently varying core frequencies introduces new sets of intracore and intercore traffic latencies. The article introduces targeted random MP test generation techniques for multicore P-State functional verification. It develops a simple coverage metric to evaluate MP test effectiveness. The metric is demonstrated on MIP's instruction-set-based random MP tests. A novel technique is introduced to modulate the test address space by the spherical Bessel function. The technique delivers an order of magnitude coverage improvement over completely random tests. The article then outlines minimal P-State combinations to be exercised by MP tests. It also formulates two new methodologies to set up and apply MP tests for effective multicore P-State coverage. The methodologies are termed SimInit and SimTransition . First-level analyses indicate that these methods can deliver 97% to 100% improvement over random MP test coverage.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2032717504",
    "type": "article"
  },
  {
    "title": "Call for papers ACM transactions on design automation of electronic systems (TODAES) special section on low-power electronics and design",
    "doi": "https://doi.org/10.1145/1698759.1698770",
    "publication_date": "2010-02-01",
    "publication_year": 2010,
    "authors": "Naehyuck Chang; Jörg Henkel",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2046541815",
    "type": "paratext"
  },
  {
    "title": "An Algorithm for Jointly Optimizing Quantization and Multiple Constant Multiplication",
    "doi": "https://doi.org/10.1145/2348839.2348846",
    "publication_date": "2012-10-01",
    "publication_year": 2012,
    "authors": "Matthew B. Gately; Mark Yeary; Choon Yik Tang",
    "corresponding_authors": "",
    "abstract": "This article presents a joint framework for quantization and Multiple Constant Multiplication (MCM) optimization, which yields a computationally efficient implementation of multiplierless multiplication in hardware and software. Frameworks of this nature have been developed in the context of Finite Impulse Response (FIR) filters, where frequency response specifications are used to drive the design. In this work, we look at a general case, considering as given a vector of ideal, real constants, which may come from any application and do not necessarily represent FIR filter coefficients. We first formulate a joint optimization problem for finding a fixed-point vector and a shift-add network that are optimal in terms of quantization error and MCM complexity. We then describe ways to finitize and prune the search space, leading to an efficient algorithm called JOINT_SOLVE that solves the problem. Finally, via extensive randomized experiments, we show that our joint framework is notably more computationally efficient than a disjointed one, reducing the MCM cost by 15%--60% on moderate size problems.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2054158513",
    "type": "article"
  },
  {
    "title": "Energy- and Performance-Efficient Communication Framework for Embedded MPSoCs through Application-Driven Release Consistency",
    "doi": "https://doi.org/10.1145/1870109.1870117",
    "publication_date": "2010-11-01",
    "publication_year": 2010,
    "authors": "Chenjie Yu; П. П. Петров",
    "corresponding_authors": "",
    "abstract": "We present a framework for performance-, bandwidth-, and energy-efficient intercore communication in embedded MultiProcessor Systems-on-a-Chip (MPSoC). The methodology seamlessly integrates compiler, operating system, and hardware support to achieve a low-cost communication between synchronized producers and consumers. The technique is especially beneficial for data-streaming applications exploiting pipeline parallelism with computational phases mapped to separate cores. Code transformations utilizing a simple ISA support ensure that producer writes are propagated to consumers with a single interconnect transaction per cache block just prior to the producer exiting its synchronization region. Furthermore, in order to completely eliminate misses to shared data caused by interference with private data and also to minimize the cache energy, we integrate to the proposed framework a cache way partitioning policy based on a simple cache configurability support, which isolates the shared buffers from other cache traffic. This mechanism results in significant power savings since only a subset of the cache ways needs to be looked up for each cache access. The end result of the proposed framework is a single communication transaction per shared cache block between a producer and a consumer with no coherence misses on the consumer caches. Our experiments demonstrate significant reductions in interconnect traffic, cache misses, and energy for a set of multiprocessor benchmarks.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2072112849",
    "type": "article"
  },
  {
    "title": "A Hardware/Software Cooperative Custom Register Binding Approach for Register Spill Elimination in Application-Specific Instruction Set Processors",
    "doi": "https://doi.org/10.1145/2348839.2348844",
    "publication_date": "2012-10-01",
    "publication_year": 2012,
    "authors": "Hai Lin; Tiansi Hu; Yunsi Fei",
    "corresponding_authors": "",
    "abstract": "Application-Specific Instruction set Processor (ASIP) has become an important design choice for embedded systems. It can achieve both high flexibility offered by the base processor core and high performance and energy efficiency offered by the dedicated hardware extensions. Although a lot of efforts have been devoted to computation acceleration, for example, automatic custom instruction identification and synthesis, limited on-chip data storage elements including the register file and data cache have become a potential performance bottleneck. For custom instructions that have more inputs and/or outputs than the generic register file I/O ports, custom registers are added in ASIPs to satisfy the need of additional inputs and outputs, and traditionally they are used only by custom instructions. In this article, we propose a hardware/software cooperative approach with a linear scan register allocation algorithm, which allows base instructions to utilize the existing custom registers in ASIPs for eliminating register spills of the program. The data traffic between the base processor and off-chip memory can be replaced with energy-efficient on-chip communications between the processor core and custom hardware extensions. Our experimental results demonstrate that a significant performance gain can be achieved, orthogonal to improvements by other techniques in ASIP design.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2086097521",
    "type": "article"
  },
  {
    "title": "2009 ACM TODAES best paper award",
    "doi": "https://doi.org/10.1145/1562514.1562515",
    "publication_date": "2009-08-01",
    "publication_year": 2009,
    "authors": "Sivaram Gopalakrishnan; Priyank Kalla",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2092070413",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2209291",
    "publication_date": "2012-06-01",
    "publication_year": 2012,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Cache coherency is one of the major issues in multicore systems. Formal methods, in particular model-checking, have been successful at verifying high-level protocols, but, to the best of our knowledge, the verification of cache coherency at the ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4232482769",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1455229",
    "publication_date": "2009-01-01",
    "publication_year": 2009,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "With increasing design complexity, the gap from ESL (Electronic System Level) design to RTL synthesis becomes more and more crucial to many industrial projects. Although several behavioral synthesis tools exist to automatically generate synthesizable ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4235188404",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1754405",
    "publication_date": "2010-05-01",
    "publication_year": 2010,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "SystemC is a system-level modeling language that offers a wide range of features to describe concurrent systems at different levels of abstraction. The SystemC standard permits simulators to implement a deterministic scheduling policy, which often hides ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4238953937",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2390191",
    "publication_date": "2012-12-01",
    "publication_year": 2012,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4241564272",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2071356",
    "publication_date": "2012-01-01",
    "publication_year": 2012,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "This article presents a formal specification and validation environment to prove safety and liveness properties of parametric -- unbounded -- NoCs architectures described at a high-level of abstraction. The environment improves the GeNoC approach with ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4242079575",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1698759",
    "publication_date": "2010-02-01",
    "publication_year": 2010,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "With growing system complexity and ever-increasing software content, the development of embedded software for upcoming MPSoC architectures is a tremendous challenge. Traditional ISS-based validation becomes infeasible due to the large complexity.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4242701492",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1835420",
    "publication_date": "2010-09-01",
    "publication_year": 2010,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Power Gating has become one of the most widely used circuit design techniques for reducing leakage current. Its concept is very simple, but its application to standard-cell VLSI designs involves many careful considerations. The great complexity of ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4243098529",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2348839",
    "publication_date": "2012-10-01",
    "publication_year": 2012,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Developing software for heterogeneous multicore systems is particularly challenging even for experienced developers. While emulators have proven useful to application development, very few heterogeneous multicore emulators have been made available by ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4243947545",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1529255",
    "publication_date": "2009-05-01",
    "publication_year": 2009,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "SystemJ is a language based on the Globally Asynchronous Locally Synchronous (GALS) paradigm. A SystemJ program is a collection of GALS nodes, also called clock domains, and each clock domain is a synchronous program that extends the Java language. ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4245015441",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1870109",
    "publication_date": "2010-11-01",
    "publication_year": 2010,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Subthreshold operation of digital circuits enables minimum energy consumption. In this article, we observe that minimum energy Emin of subthreshold logic dramatically increases when reaching 45nm CMOS node. We demonstrate by circuit simulation and ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4245835235",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1562514",
    "publication_date": "2009-08-01",
    "publication_year": 2009,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4246481005",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1497561",
    "publication_date": "2009-03-01",
    "publication_year": 2009,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4249283872",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1640457",
    "publication_date": "2009-12-01",
    "publication_year": 2009,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "This article presents a new tool for automatic design of application-specific reconfigurable processor extensions based on UPaK (Abstract Unified Patterns Based Synthesis Kernel for Hardware and Software Systems). We introduce a complete design flow ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4253807332",
    "type": "paratext"
  },
  {
    "title": "Confidence analysis for defect-level estimation of VLSI random testing",
    "doi": "https://doi.org/10.1145/293625.293629",
    "publication_date": "1998-07-01",
    "publication_year": 1998,
    "authors": "Wen-Ben Jone; Kuan-Yao Tsai",
    "corresponding_authors": "",
    "abstract": "The defect level in circuit testing is the percentage of circuits such as chips, that are defective and shipped for use after testing. Our previously published results showed that the defect level of circuit fabrication and testing should be a probability distribution, rather than a single value, and the concept of confidence degree was proposed [Gondalia et al. 1993; Jone et al. 1995]. In this work, defect level is represented by a confidence interval which is more conventional and easier to interpret. The point estimate of defect level analysis and conditions to avoid meaningless confidence intervals are also investigated. Methods for adaptive random test length determination driven by different confidence intervals or interval length are proposed to meet both test requirements and test costs tradeoff. Finally, a complete test plan that can direct the test flow from fabrication infancy to maturity is suggested.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2075747453",
    "type": "article"
  },
  {
    "title": "Optimal routing algorithms for rectilinear pin clusters in high-density multichip modules",
    "doi": "https://doi.org/10.1145/1391962.1391976",
    "publication_date": "2008-09-01",
    "publication_year": 2008,
    "authors": "Muhammet Mustafa Özdal; Martin D. F. Wong; P. S. Honsinger",
    "corresponding_authors": "",
    "abstract": "As the circuit densities and transistor counts are increasing, the package routing problem is becoming more and more challenging. In this article, we study an important routing problem encountered in typical high-end MCM designs: routing within dense pin clusters. Pin clusters are often formed by pins that belong to the same functional unit or the same data bus, and can become bottlenecks in terms of overall routability. Typically, these clusters have irregular shapes, which can be approximated with rectilinear convex boundaries. Since such boundaries have often irregular shapes, a traditional escape routing algorithm may give unroutable solutions. In this article, we study how the positions of escape terminals on a convex boundary affect the overall routability. For this purpose, we propose a set of necessary and sufficient conditions to model routability outside a rectilinear convex boundary. Given an escape routing solution, we propose an optimal algorithm to select the maximal subset of nets that are routable outside the boundary. After that, we focus on an integrated approach to consider routability constraints (outside the boundary) during the actual escape routing algorithm. Here, we propose an optimal algorithm to find the best escape routing solution that satisfies all routability constraints. Our experiments demonstrate that we can reduce the number of layers by 17% on the average, by using this integrated methodology.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W1993820970",
    "type": "article"
  },
  {
    "title": "A note on “a mapping algorithm for computer-assisted exploration in the design of embedded systems”",
    "doi": "https://doi.org/10.1145/1278349.1278365",
    "publication_date": "2007-09-01",
    "publication_year": 2007,
    "authors": "Gang Chen; Xiaoyu Song; Feng Liu; Qingping Tan; Fei He",
    "corresponding_authors": "",
    "abstract": "article Share on A note on “a mapping algorithm for computer-assisted exploration in the design of embedded systems” Authors: Gang Chen Portland State University, Portland, OR Portland State University, Portland, ORView Profile , Xiaoyu Song Portland State University, Portland, OR Portland State University, Portland, ORView Profile , Feng Liu National Lab of Parallel Distributed Processing, Hunan, China National Lab of Parallel Distributed Processing, Hunan, ChinaView Profile , Qingping Tan National Lab of Parallel Distributed Processing, Hunan, China National Lab of Parallel Distributed Processing, Hunan, ChinaView Profile , Fei He Tsinghua University, Beijing, P.R. China Tsinghua University, Beijing, P.R. ChinaView Profile Authors Info & Claims ACM Transactions on Design Automation of Electronic SystemsVolume 12Issue 401 September 2007pp 52–eshttps://doi.org/10.1145/1278349.1278365Published:01 September 2007Publication History 0citation220DownloadsMetricsTotal Citations0Total Downloads220Last 12 Months3Last 6 weeks0 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteGet Access",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W1997956687",
    "type": "article"
  },
  {
    "title": "A noniterative equivalent waveform model for timing analysis in presence of crosstalk",
    "doi": "https://doi.org/10.1145/1344418.1344421",
    "publication_date": "2008-04-02",
    "publication_year": 2008,
    "authors": "K.K. Muchherla; Pinhong Chen; Dongsheng Ma; Janet Meiling Wang",
    "corresponding_authors": "",
    "abstract": "Due to the nonuniform interconnect scaling in the Deep Sub Micron (DSM) region, the coupling capacitance between wires becomes an increasingly dominant fraction of the total wire capacitance. This couple capacitance introduces server crosstalk which causes delay variations on signal lines and raises signal integrity problems. Therefore, including crosstalk in the timing analysis methods has become imperative for current technologies. And to correctly model the crosstalk, output loading effects, waveform shape and gate driving capability have to be considered. However, most existing crosstalk models have not yet included these factors and consequently suffer from the low accuracy problem. In this article, we propose a noniterative equivalent waveform model that addresses the above mentioned issues. Our experimental results have shown that the new model achieves 3 times speed up and 95% accuracy compared to the existing models.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2009255300",
    "type": "article"
  },
  {
    "title": "Simulation-based verification using Temporally Attributed Boolean Logic",
    "doi": "https://doi.org/10.1145/1391962.1391971",
    "publication_date": "2008-09-01",
    "publication_year": 2008,
    "authors": "S.K. Panda; Arnab Roy; P. P. Chakrabarti; Rajeev Kumar",
    "corresponding_authors": "",
    "abstract": "We propose a specification logic called Temporally Attributed Boolean (TAB) Logic for Assertion Based Verification, which allows us to: (i) represent assertions succinctly, (ii) incorporate data-orientation and (iii) associate timing to design intentions. TAB Logic allows us to write specifications functionally linking system variables from different temporal contexts. We present examples to show the motivation for this logic especially in the context of high level modeling of complex real time systems. We formally define TAB Logic, formulate the problem of verification on a simulation trace and present efficient algorithms to check TAB assertions, both offline and online. We present results of application of TAB Logic for Instruction Semantics and Bus Transaction Verification of a bus integrated pipelined processor core implementation. We also employ TAB Logic to validate the Interrupt mode behavior of the processor core implementation. Further, we show the utility of TAB Logic in fault detection. Finally, we demonstrate the applicability of TAB Logic in the domain of simulation based verification of analog circuits like Operational Amplifiers and DC-DC Converters. We finally discuss the limitations of TAB logic and conclude.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2018517638",
    "type": "article"
  },
  {
    "title": "Introduction to special section on high-level design, validation, and test",
    "doi": "https://doi.org/10.1145/1297666.1297668",
    "publication_date": "2008-01-01",
    "publication_year": 2008,
    "authors": "Michael S. Hsiao; Robert B. Jones",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2029860842",
    "type": "article"
  },
  {
    "title": "Introduction to the special section on demonstrable software systems and hardware platforms II",
    "doi": "https://doi.org/10.1145/1367045.1367047",
    "publication_date": "2008-07-01",
    "publication_year": 2008,
    "authors": "Alex K. Jones; Robert A. Walker",
    "corresponding_authors": "",
    "abstract": "introduction Share on Introduction to the special section on demonstrable software systems and hardware platforms II Authors: Alex K. Jones Pittsburgh, Pennsylvania Pittsburgh, PennsylvaniaView Profile , Robert Walker Kent, Ohio Kent, OhioView Profile Authors Info & Claims ACM Transactions on Design Automation of Electronic SystemsVolume 13Issue 3July 2008 Article No.: 38pp 1–3https://doi.org/10.1145/1367045.1367047Published:25 July 2008Publication History 1citation237DownloadsMetricsTotal Citations1Total Downloads237Last 12 Months3Last 6 weeks1 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my Alerts New Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteGet Access",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2065544860",
    "type": "article"
  },
  {
    "title": "Low-Power and testable circuit synthesis using Shannon decomposition",
    "doi": "https://doi.org/10.1145/1278349.1278360",
    "publication_date": "2007-09-01",
    "publication_year": 2007,
    "authors": "Swaroop Ghosh; Swarup Bhunia; Kaushik Roy",
    "corresponding_authors": "",
    "abstract": "Structural transformation of a design to enhance its testability while satisfying design constraints on power and performance can result in improved test cost and test confidence. In this article, we analyze the testability in a new style of logic design based on Shannon's decomposition and supply gating . We observe that the tree structure of a logic circuit due to Shannon's decomposition makes it intrinsically more testable than a conventionally synthesized circuit, while at the same time providing an improvement in active power. We have analyzed four different aspects of the testability of a circuit: a) IDDQ test sensitivity, b) test power during scan-based testing, c) test length (for both ATPG-generated deterministic and random patterns), and d) noise immunity. Simulation results on a set of MCNC benchmarks show promising results on all these aspects (an average improvement of 94% in IDDQ sensitivity, 50% in test power, 19% (21%) in test length for deterministic (random) patterns, and 50% in coupling noise immunity). We have also demonstrated that the new logic structure can improve parametric yield (6% on average) of a circuit under process variations when considering a bound on circuit leakage.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2116623634",
    "type": "article"
  },
  {
    "title": "Introduction to joint ACM JETC/TODAES special issue on new, emerging, and specialized technologies",
    "doi": "https://doi.org/10.1145/1344418.1344432",
    "publication_date": "2008-04-02",
    "publication_year": 2008,
    "authors": "R. Iris Bahar; Krishnendu Chakrabarty",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2130740378",
    "type": "article"
  },
  {
    "title": "Special Section",
    "doi": "https://doi.org/10.1145/3023455",
    "publication_date": "2017-02-09",
    "publication_year": 2017,
    "authors": "Twan Basten; Orlando Moreira; Robert de Groote",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2586501661",
    "type": "article"
  },
  {
    "title": "A Single-Tier Virtual Queuing Memory Controller Architecture for Heterogeneous MPSoCs",
    "doi": "https://doi.org/10.1145/3035481",
    "publication_date": "2017-04-27",
    "publication_year": 2017,
    "authors": "Yang Song; Kambiz Samadi; Bill Lin",
    "corresponding_authors": "",
    "abstract": "Heterogeneous MPSoCs typically integrate diverse cores, including application CPUs, GPUs, and HD coders. These cores commonly share an off-chip memory to save cost and energy, but their memory accesses often interfere with each other, leading to undesirable consequences like a slowdown of application performance or a failure to sustain real-time performance. The memory controller plays a central role in meeting the QoS needs of real-time cores while maximizing CPU performance. Previous QoS-aware memory controllers are based on a classic two-tier queuing architecture that buffers memory transactions at the first tier, followed by a second tier that buffers translated DRAM commands. In these designs, QoS-aware policies are used to schedule competing transactions at the first stage, but the translated DRAM commands are served in FIFO order at the second stage. Unfortunately, once the scheduled transactions have been forwarded to the command stage, newly arriving transactions that may be more critical cannot be served ahead of those translated commands that are already queued at the second stage. To address this, we propose a scalable memory controller architecture based on single-tier virtual queuing (STVQ) that maintains a single tier of request queues and employs an efficacious scheduler that considers both QoS requirements and DRAM bank states. In comparison with previous QoS-aware memory controllers, the proposed STVQ memory controller reduces CPU slowdown by up to 13.9% while satisfying all frame rate requirements. We propose further optimizations that can significantly increase row-buffer hits by up to 66.2% and reduce memory latency by up to 19.8%.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2608740005",
    "type": "article"
  },
  {
    "title": "Scalable Bandwidth Shaping Scheme via Adaptively Managed Parallel Heaps in Manycore-Based Network Processors",
    "doi": "https://doi.org/10.1145/3065926",
    "publication_date": "2017-05-20",
    "publication_year": 2017,
    "authors": "Taehyun Kim; Jongbum Lim; Jinku Kim; Woo-Cheol Cho; Eui-Young Chung; Hyuk‐Jun Lee",
    "corresponding_authors": "",
    "abstract": "Scalability of network processor-based routers heavily depends on limitations imposed by memory accesses and associated power consumption. Bandwidth shaping of a flow is a key function, which requires a token bucket per output queue and abuses memory bandwidth. As the number of output queues increases, managing token buckets becomes prohibitively expensive and limits scalability. In this work, we propose a scalable software-based token bucket management scheme that can reduce memory accesses and power consumption significantly. To satisfy real-time and low-cost constraints, we propose novel parallel heap data structures running on a manycore-based network processor. By using cache locking, the performance of heap processing is enhanced significantly and is more predictable. In addition, we quantitatively analyze the performance and memory footprint of the proposed software scheme using stochastic modeling and the Lyapunov central limit theorem. Finally, the proposed scheme provides an adaptive method to limit the size of heaps in the case of oversubscribed queues, which can successfully isolate the queues showing unideal behavior. The proposed scheme reduces memory accesses by up to three orders of magnitude for one million queues sharing a 100Gbps interface of the router while maintaining stability under stressful scenarios.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2617588517",
    "type": "article"
  },
  {
    "title": "Generating Current Constraints to Guarantee RLC Power Grid Safety",
    "doi": "https://doi.org/10.1145/3054746",
    "publication_date": "2017-06-15",
    "publication_year": 2017,
    "authors": "Zahi Moudallal; Farid N. Najm",
    "corresponding_authors": "",
    "abstract": "A critical task during early chip design is the efficient verification of the chip power distribution network. Vectorless verification, developed since the mid-2000s as an alternative to traditional simulation-based methods, requires the user to specify current constraints (budgets) for the underlying circuitry and checks if the corresponding voltage variations on all grid nodes are within a user-specified margin. This framework is extremely powerful, as it allows for efficient and early verification, but specifying/obtaining current constraints remains a burdensome task for users and a hurdle to adoption of this framework by the industry. Recently, the inverse problem has been introduced: Generate circuit current constraints that, if satisfied by the underlying logic circuitry, would guarantee grid safety from excessive voltage variations. This approach has many potential applications, including various grid quality metrics, as well as voltage drop-aware placement and floorplanning. So far, this framework has been developed assuming only resistive and capacitive (RC) elements in the power grid model. Inductive effects are becoming a significant component of the power supply noise and can no longer be ignored. In this article, we extend the constraints generation approach to allow for inductance. We give a rigorous problem definition and develop some key theoretical results related to maximality of the current space defined by the constraints. Based on this, we then develop three constraints generation algorithms that target the peak total chip power that is allowed by the grid, the uniformity of current distribution across the die area, and a combination of both metrics.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2627054467",
    "type": "article"
  },
  {
    "title": "A Fast Optimal Double-row Legalization Algorithm",
    "doi": "https://doi.org/10.1145/3579844",
    "publication_date": "2023-01-21",
    "publication_year": 2023,
    "authors": "Stefan Hougardy; Meike Neuwohner; Ulrike Schorr",
    "corresponding_authors": "",
    "abstract": "In Placement Legalization, it is often assumed that (almost) all standard cells possess the same height and can therefore be aligned in cell rows , which can then be treated independently. However, this is no longer true for recent technologies, where a substantial number of cells of double- or even arbitrary multiple-row height is to be expected. Due to interdependencies between the cell placements within several rows, the legalization task becomes considerably harder. In this article, we show how to optimize squared cell movement for pairs of adjacent rows comprising cells of single- as well as double-row height with a fixed left-to-right ordering in time 𝒪( n · log ( n )), where n denotes the number of cells involved. Opposed to prior works, we do not artificially bound the maximum cell movement and can guarantee to find an optimum solution. Our approach also allows us to include gridding and movebound constraints for the cells. Experimental results show an average percental decrease of over 26% in the total squared movement when compared to a legalization approach that fixes cells of more than single-row height after Global Placement.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3124019422",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1297666",
    "publication_date": "2008-01-01",
    "publication_year": 2008,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4229935655",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1188275",
    "publication_date": "2007-01-01",
    "publication_year": 2007,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4231489198",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1255456",
    "publication_date": "2007-08-01",
    "publication_year": 2007,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "System-level modeling, simulation, and synthesis using electronic design automation (EDA) tools are key steps in the design process for communication and signal processing systems, and the synchronous dataflow (SDF) model of computation is widely used ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4231697668",
    "type": "paratext"
  },
  {
    "title": "Editorial",
    "doi": "https://doi.org/10.1145/1391962.1391963",
    "publication_date": "2008-09-01",
    "publication_year": 2008,
    "authors": "Massoud Pedram",
    "corresponding_authors": "Massoud Pedram",
    "abstract": "editorial Free Access Share on Editorial Editor: Massoud Pedram View Profile Authors Info & Claims ACM Transactions on Design Automation of Electronic SystemsVolume 13Issue 4September 2008 Article No.: 55pp 1–3https://doi.org/10.1145/1391962.1391963Published:03 October 2008Publication History 0citation323DownloadsMetricsTotal Citations0Total Downloads323Last 12 Months17Last 6 weeks1 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my Alerts New Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4234585403",
    "type": "editorial"
  },
  {
    "title": "Editorial",
    "doi": "https://doi.org/10.1145/1367045.1367046",
    "publication_date": "2008-07-01",
    "publication_year": 2008,
    "authors": "Nikil Dutt",
    "corresponding_authors": "Nikil Dutt",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4238157491",
    "type": "editorial"
  },
  {
    "title": "Editorial",
    "doi": "https://doi.org/10.1145/1297666.1297667",
    "publication_date": "2008-01-01",
    "publication_year": 2008,
    "authors": "Nikil Dutt",
    "corresponding_authors": "Nikil Dutt",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4239131522",
    "type": "editorial"
  },
  {
    "title": "Hierarchical partitioning of VLSI floorplans by staircases",
    "doi": "https://doi.org/10.1145/1217088.1217095",
    "publication_date": "2007-01-01",
    "publication_year": 2007,
    "authors": "Subhashis Majumder; Susmita Sur‐Kolay; Bhargab B. Bhattacharya; Swarup Kumar Das",
    "corresponding_authors": "",
    "abstract": "This article addresses the problem of recursively bipartitioning a given floorplan F using monotone staircases. At each level of the hierarchy, a monotone staircase from one corner of F to its opposite corner is identified, such that (i) the two parts of the bipartition are nearly equal in area (or in the number of blocks), and (ii) the number of nets crossing the staircase is minimal. The problem of area-balanced bipartitioning is shown to be NP-hard, and a maxflow-based heuristic is proposed. Such a hierarchy may be useful to repeater placement in deep-submicron physical design, and also to global routing.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4240599084",
    "type": "article"
  },
  {
    "title": "A hierarchical modeling framework for on-chip communication architectures of multiprocessing SoCs",
    "doi": "https://doi.org/10.1145/1217088.1217094",
    "publication_date": "2007-01-01",
    "publication_year": 2007,
    "authors": "Zhu Xinping; Sharad Malik",
    "corresponding_authors": "",
    "abstract": "In multiprocessor-based SoCs, optimizing the communication architecture is often as important, if not more important, than optimizing the computation architecture. While there are mature platforms and techniques for the modeling and evaluation of architectures of processing elements, the same is not true for the communication architectures. This article presents an application-driven retargetable prototyping platform that fills this gap. This environment aims to facilitate the design exploration of the communication subsystem through application-level execution-driven simulations and quantitative analysis. Based on an analysis of a wide range of on-chip communication architectures, we describe how a specific hierarchical class library can be used to develop new on-chip communication architectures, or variants of existing ones with relatively little incremental effort. We demonstrate this through three case studies including two commercial on-chip bus systems and an on-chip packet switching network. Here we show that, through careful analysis and construction, it is possible for the modeling environment to support the common features of these architectures as part of the library and permit instantiation of the individual architectures as variants of the library design. Consequently, system-level design choices regarding the communication architecture can be made with high confidence in the early stages of design. In addition to improving design quality, this methodology also results in significantly shortening design-time.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4240648702",
    "type": "article"
  },
  {
    "title": "Scan-BIST based on cluster analysis and the encoding of repeating sequences",
    "doi": "https://doi.org/10.1145/1217088.1217092",
    "publication_date": "2007-01-01",
    "publication_year": 2007,
    "authors": "Lei Li; Zhong Lin Wang; Krishnendu Chakrabarty",
    "corresponding_authors": "",
    "abstract": "We present a built-in self-test (BIST) approach for full-scan designs that extracts the most frequently occurring sequences from deterministic test patterns. The extracted sequences are stored on-chip, and are used during test application. Three sets of test patterns are applied to the circuit under test during a BIST test session; these include pseudorandom patterns, semirandom patterns, and deterministic patterns. The semirandom patterns are generated based on the stored sequences and they are more likely to detect hard-to-detect faults than pseudorandom patterns. The deterministic patterns are encoded using either the stored sequences or the LFSR reseeding technique to reduce test data volume. We use the cluster analysis technique for sequence extraction to reduce the amount of data to be stored. Experimental results for the ISCAS-89 benchmark circuits show that the proposed approach often requires less on-chip storage and test data volume than other recent BIST methods.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4242445128",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1217088",
    "publication_date": "2007-01-01",
    "publication_year": 2007,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "VLIW processors have started gaining acceptance in the embedded systems domain. However, monolithic register file VLIW processors with a large number of functional units are not viable. This is because of the need for a large number of ports to support ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4243753107",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3062395",
    "publication_date": "2017-05-31",
    "publication_year": 2017,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Data compression plays a pivotal role in improving system performance and reducing energy consumption, because it increases the logical effective capacity of a compressed memory system without physically increasing the memory size. However, data ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4243839843",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1391962",
    "publication_date": "2008-09-01",
    "publication_year": 2008,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4244013110",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1230800",
    "publication_date": "2007-04-01",
    "publication_year": 2007,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Existing BDD-based symbolic algorithms designed for hardware designs do not perform well on software programs. We propose novel techniques based on unique characteristics of software programs. Our algorithm divides an image computation step into a ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4244083892",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3129756",
    "publication_date": "2017-10-17",
    "publication_year": 2017,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Random region covering is a global optimization technique that explores the landscape by introducing multiple random starting points to initiate the local optimization solvers. This study applies the random region covering technique to circuit design ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4247162271",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3097980",
    "publication_date": "2017-07-22",
    "publication_year": 2017,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Mobile devices are quickly becoming the most widely used processors in consumer devices. Since their major power supply is battery, energy-efficient computing is highly desired. In this article, we focus on energy-efficient cache design in emerging ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4247236031",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3029795",
    "publication_date": "2017-03-15",
    "publication_year": 2017,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Unpredictability is an important security property of Physically Unclonable Function (PUF) in the context of statistical attacks, where the correlation between challenge-response pairs is explicitly exploited. In the existing literature on PUFs, the ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4247601344",
    "type": "paratext"
  },
  {
    "title": "Editorial",
    "doi": "https://doi.org/10.1145/1344418.1344419",
    "publication_date": "2008-04-02",
    "publication_year": 2008,
    "authors": "Nikil Dutt",
    "corresponding_authors": "Nikil Dutt",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4247612777",
    "type": "editorial"
  },
  {
    "title": "Editorial",
    "doi": "https://doi.org/10.1145/1230800.1230801",
    "publication_date": "2007-04-01",
    "publication_year": 2007,
    "authors": "Nikil Dutt",
    "corresponding_authors": "Nikil Dutt",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4251270748",
    "type": "editorial"
  },
  {
    "title": "System-level performance/power analysis for platform-based design of multimedia applications",
    "doi": "https://doi.org/10.1145/1217088.1217090",
    "publication_date": "2007-01-01",
    "publication_year": 2007,
    "authors": "Nicholas H. Zamora; Xiao Hu; Radu Mărculescu",
    "corresponding_authors": "",
    "abstract": "The objective of this article is to introduce the use of Stochastic Automata Networks (SANs) as an effective formalism for application-architecture modeling in system-level average-case analysis for platform-based design. By platform, we mean a family of heterogeneous architectures that satisfy a set of architectural constraints imposed to allow re-use of hardware and software components. More precisely, we show how SANs can be used early in the design cycle to identify the best performance/power trade-offs among several application-architecture combinations. Having this information available not only helps avoid lengthy simulations for predicting power and performance figures, but also enables efficient mapping of different applications onto a chosen platform. We illustrate the benefits of our methodology by using the \"Picture-in-Picture\" video decoder as a driver application.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4254018648",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1344418",
    "publication_date": "2008-04-01",
    "publication_year": 2008,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4254276093",
    "type": "paratext"
  },
  {
    "title": "Analytical Placement with 3D Poisson’s Equation and ADMM-based Optimization for Large-scale 2.5D Heterogeneous FPGAs",
    "doi": "https://doi.org/10.1145/3582554",
    "publication_date": "2023-01-31",
    "publication_year": 2023,
    "authors": "Min Wei; Xingyu Tong; Wen Yuan; Jianli Chen; Jun Yu; Wenxing Zhu; Yao‐Wen Chang",
    "corresponding_authors": "",
    "abstract": "As design complexity keeps increasing, the 2.5D field-programmable gate array (FPGA) with large logic capacity has become popular in modern circuit applications. A 2.5D FPGA consists of multiple dies connected through super long lines (SLLs) on an interposer. Each die contains heterogeneous logic blocks and ASIC-like clocking architectures to achieve better skew and timing. Existing works consider these problems separately and thus may lead to serious timing issues or routing failure. This article presents an analytical placement algorithm for the 2.5D FPGA to simultaneously minimize the number of inter-die SLL signals and intra-die clocking violations. Using a lifting dimension technique, we first formulate the 2.5D global placement problem as a three-dimensional continuous and differential minimization problem, where the SLL-aware block distribution is modeled by 3D Poisson’s equation and directly solved to obtain an analytical solution. Then, we further reformulate the minimization problem as a separable optimization problem with linear constraints. Based on the proximal alternating direction method of multipliers optimization method, we efficiently optimize the separable subproblems one by one in an alternating fashion. Finally, clock-aware legalization and detailed placement are applied to legalize and improve our placement results. Compared with the state-of-the-art works, experimental results show that our algorithm can resolve all clocking constraints and reduce the number of SLL crossing signals by 36.9% with similar wirelength in a comparable running time.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4318618493",
    "type": "article"
  },
  {
    "title": "Routability Optimization of Extreme Aspect Ratio Design through Non-uniform Placement Utilization and Selective Flip-flop Stacking",
    "doi": "https://doi.org/10.1145/3573387",
    "publication_date": "2023-02-27",
    "publication_year": 2023,
    "authors": "Daijoon Hyun; Sunwha Koh; Younggwang Jung; Taeyoung Kim; Youngsoo Shin",
    "corresponding_authors": "",
    "abstract": "Circuits that are placed with very low (or high) aspect ratio are susceptible to routing overflows. Such designs are difficult to close and usually end up with larger area with low area utilization. In this article, we propose two routability optimization methods to implement designs even with very low (or high) aspect ratio and high area utilization. First, we find the best assignment of non-uniform placement utilization through convolutional neural network model, and cell placement is performed while respecting the placement utilization. This allows many cells to be spread out over the entire design rather than being centered. The experiments show that most overflows of 16.5% occurring in cell placement are removed with 23.1% reduction in wire length; this is the result of further improving overflow of 9.8% compared to a conventional method. In the second, some flip-flops are selectively stacked to reduce the routing resources used for clock routing. U-Net model is built with graph attention network to predict the congestion after clock-tree synthesis, and the flip-flops in highly congested areas are selected for stacking. The proposed method improves the overflows, which occurs after clock-tree synthesis, by 22.1%.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4322397556",
    "type": "article"
  },
  {
    "title": "Global Interconnect Optimization",
    "doi": "https://doi.org/10.1145/3587044",
    "publication_date": "2023-03-09",
    "publication_year": 2023,
    "authors": "Siad Daboul; Stephan Held; Bento Natura; Daniel Rotter",
    "corresponding_authors": "",
    "abstract": "We propose a new comprehensive solution to global interconnect optimization. Traditional buffering algorithms mostly insert repeaters on a net-by-net basis based on slacks and possibly guided by global wires. We show how to integrate routing congestion, placement congestion, global timing constraints, power consumption, and additional constraints into a single resource sharing formulation. The core of our algorithm is a new buffered routing subroutine. Given a net and Lagrangean resource prices for routing, timing, placement, and power, it computes a buffered Steiner tree. The resource sharing framework provides a special multiplicative price update for fast convergence. Our algorithm is fast enough for practical instances. We demonstrate experimentally on 7nm microprocessor units that it significantly improves timing while reducing netlength and power consumption in an industrial design flow. Our implementation scales well under parallelization with up to 128 threads.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4323663013",
    "type": "article"
  },
  {
    "title": "Introduction to the Special Issue on Machine Learning for CAD/EDA",
    "doi": "https://doi.org/10.1145/3586208",
    "publication_date": "2023-03-31",
    "publication_year": 2023,
    "authors": "Yibo Lin; Avi Ziv; Haoxing Ren",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4362474793",
    "type": "article"
  },
  {
    "title": "A Soft-Error Mitigation Approach Using Pulse Quenching Enhancement at Detailed Placement for Combinational Circuits",
    "doi": "https://doi.org/10.1145/3595637",
    "publication_date": "2023-05-05",
    "publication_year": 2023,
    "authors": "Xu He; Yao Wang; Chang Liu; Qiang Wu; Juan Luo; Yang Guo",
    "corresponding_authors": "",
    "abstract": "As technology continuously shrinks, radiation-induced soft errors have become a great threat to the circuit reliability. Among all the causes, the Single-Event Transient (SET) effect is the dominating one for the radiation-induced soft errors. SET-induced soft errors can be mitigated by multiple methods. In terms of area and power overhead, blocking SET propagation is considered to be the most efficient way for soft error reduction. It is found that the SET pulse width can be shrunk by a pulse quenching effect, which can be utilized to mitigate soft errors without introducing any area and power overhead. In this article, we present an effective detailed placer to exploit the pulse quenching effect for soft error reduction in combinational circuits. In our method, the quenching effect enhancement is globally optimized while the cell displacement is minimized. The experimental results demonstrate that our method reduces the soft error vulnerability of the circuits by 29.53% versus 18.38% of the state-of-the-art solution. Meanwhile, our method has a minimal effect on the displacement and half-perimeter wire length (HPWL) compared with the previous solutions, which means a minimum timing influence to the original design.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4372346669",
    "type": "article"
  },
  {
    "title": "ICP-RL: Identifying Critical Paths for Fault Diagnosis Using Reinforcement Learning",
    "doi": "https://doi.org/10.1145/3610294",
    "publication_date": "2023-07-21",
    "publication_year": 2023,
    "authors": "Jie Xiao; Yingying Ge; Wang Ru; Jungang Lou",
    "corresponding_authors": "",
    "abstract": "Identifying the critical paths is crucial to reducing the complexity of performance analysis and reliability calculation for logic circuits. In this article, we propose a method for identifying the critical path in a combination circuit using a reinforcement learning framework to enhance its applicability and compatibility. Initially, we configured the learning environment of the model based on circuit structure information to provide valuable information for decision-making on time. Subsequently, the upper confidence bound applied to trees (UCT) algorithm is employed to construct the behavior decision strategy of the model, which avoids invalid traversal and reduces computing costs. Then, a goal-oriented reward and punishment function is constructed based on the distance from the circuit primary outputs. Finally, based on the parallel computing strategy, we construct an adaptive training method to improve the model’s prediction accuracy by using finite sampling, which speeds up the convergence speed and enhances the quality of the model. Experimental results on benchmark circuits show that, with the functional timing analysis method as the reference, the average accuracy of the proposed method is as high as 99.39% and the single average calculation speed is 18.07 times faster than that of the reference method. Compared with the Monte Carlo model, the proposed method has a higher critical path hit rate, and the average calculation speed is 928.75 times faster.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4385071005",
    "type": "article"
  },
  {
    "title": "SoC Protocol Implementation Verification Using Instruction-Level Abstraction Specifications",
    "doi": "https://doi.org/10.1145/3610292",
    "publication_date": "2023-07-24",
    "publication_year": 2023,
    "authors": "Huaixi Lu; Yue Xing; Aarti Gupta; Sharad Malik",
    "corresponding_authors": "",
    "abstract": "In modern systems-on-chips, several hardware protocols are used for communication and interaction among different modules. These protocols are complex and need to be implemented correctly for correct operation of the system-on-chip. Therefore, protocol verification has received significant attention. However, this verification is often limited to checking high-level properties on a protocol specification or an implementation. Verifying these properties directly on an implementation faces scalability challenges due to its size and design complexity. Further, even after some high-level properties are verified, there is no guarantee that an implementation fully complies with a given specification, even if the same properties have also been checked on the specification. We address these challenges and gaps by adding a layer of component specifications, one for each component in the protocol implementation, and specifying and verifying the interactions at the interfaces between each pair of communicating components. We use the recently proposed formal model termed Instruction-Level Abstraction (ILA) as a component specification, which includes an interface specification for the interactions in composing different components. The use of ILA models as component specifications allows us to decompose the complete verification task into two sub-tasks: checking that the composition of ILAs is sequentially equivalent to a verified formal protocol specification, and checking that the protocol implementation is a refinement of the ILA composition. This check requires that each component implementation is a refinement of its ILA specification and includes interface checks guaranteeing that components interact with each other as specified. We have applied the proposed ILA-based methodology for protocol verification to several third-party design case studies. These include an AXI on-chip communication protocol, an off-chip communication protocol, and a cache coherence protocol. For each system, we successfully detected bugs in the implementation, and show that the full formal verification can be completed in reasonable time and effort.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4385221661",
    "type": "article"
  },
  {
    "title": "QuanDA: GPU Accelerated Quantitative Deep Neural Network Analysis",
    "doi": "https://doi.org/10.1145/3611671",
    "publication_date": "2023-08-01",
    "publication_year": 2023,
    "authors": "Mahum Naseer; Osman Hasan; Muhammad Shafique",
    "corresponding_authors": "",
    "abstract": "Over the past years, numerous studies demonstrated the vulnerability of deep neural networks (DNNs) to make correct classifications in the presence of small noise. This motivated the formal analysis of DNNs to ensure that they delineate acceptable behavior. However, in the case that the DNN’s behavior is unacceptable for the desired application, these qualitative approaches are ill equipped to determine the precise degree to which the DNN behaves unacceptably. We propose a novel quantitative DNN analysis framework, QuanDA, which not only checks whether the DNN delineates certain behavior but also provides the estimated probability of the DNN to delineate this particular behavior. Unlike the (few) available quantitative DNN analysis frameworks, QuanDA does not use any implicit assumptions on the probability distribution of the hidden nodes, which enables the framework to propagate close to real probability distributions of the hidden node values to each proceeding DNN layer. Furthermore, our framework leverages CUDA to parallelize the analysis, enabling high-speed GPU implementation for fast analysis. The applicability of the framework is demonstrated using the ACAS Xu benchmark, to provide reachability probability estimates for all network nodes. This paper also provides potential applications of QuanDA for the analysis of DNN safety properties.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4385456266",
    "type": "article"
  },
  {
    "title": "A High-performance Masking Design Approach for Saber against High-order Side-channel Attack",
    "doi": "https://doi.org/10.1145/3611670",
    "publication_date": "2023-08-03",
    "publication_year": 2023,
    "authors": "Yajing Chang; Yingjian Yan; Chunsheng Zhu; Yanjiang Liu",
    "corresponding_authors": "",
    "abstract": "Post-quantum cryptography (PQC) has become the most promising cryptographic scheme against the threat of quantum computing to conventional public-key cryptographic schemes. Saber, as the finalist in the third round of the PQC standardization procedure, presents an appealing option for embedded systems due to its high encryption efficiency and accessibility. However, side-channel attack (SCA) can easily reveal confidential information by analyzing the physical manifestations, and several works demonstrate that Saber is vulnerable to SCAs. In this work, a ciphertext comparison method for masking design based on the bitslicing technique and zerotest is proposed, which balances the tradeoff between the performance and security of comparing two arrays. The mathematical description of the proposed ciphertext comparison method is provided, and its correctness and security metrics are analyzed under the concept of PINI. Moreover, a high-order masking approach based on the state of the art, including the hash functions, centered binomial sampling, masking conversions, and proposed ciphertext comparison, is presented, using the bitslicing technique to improve throughput. As a proof of concept, the proposed implementation of Saber is on the ARM Cortex-M4. The performance results show that the runtime overhead factor of 1st-, 2nd-, and 3rd-order masking is 3.01×, 5.58×, and 8.68×, and the dynamic memory used for 1st-, 2nd-, and 3rd-order masking is 17.4kB, 24.0kB, and 30.2kB, respectively. The SCA-resilience evaluation results illustrate that the 1st-order Test Vectors Leakage Assessment (TVLA) result fails to reveal the secret key with 100,000 traces.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4385548363",
    "type": "article"
  },
  {
    "title": "Enhanced PATRON: Fault Injection and Power-aware FSM Encoding Through Linear Programming",
    "doi": "https://doi.org/10.1145/3611669",
    "publication_date": "2023-08-03",
    "publication_year": 2023,
    "authors": "Muhtadi Choudhury; Minyan Gao; Avinash L. Varna; Elad Peer; Domenic Forte",
    "corresponding_authors": "",
    "abstract": "Since finite state machines (FSMs) regulate the control flow in circuits, a computing system’s security might be breached by attacking the FSM. Physical attacks are especially worrisome because they can bypass software countermeasures. For example, an attacker can gain illegal access to the sensitive states of an FSM through fault injection, leading to privilege escalation and/or information leakage. Laser fault injection (LFI) provides one of the most effective attack vectors by enabling adversaries to precisely overturn single flip-flops states. Although conventional error correction/detection methodologies have been employed to improve FSM resiliency, their substantial overhead makes them unattractive to circuit designers. In our prior work, a novel decision diagram-based FSM encoding scheme called PATRON was proposed to resist LFI according to attack parameters, e.g., number of simultaneous faults. Although PATRON bested traditional encodings keeping overhead minimum, it provided numerous candidates for FSM designs requiring exhaustive and manual effort to select one optimum candidate. In this article, we automatically select an optimum candidate by enhancing PATRON using linear programming (LP). First, we exploit the proportionality between dynamic power dissipation and switching activity in digital CMOS circuits. Thus, our LP objective minimizes the number of FSM bit switches per transition, for comparatively lower switching activity and hence total power consumption. Second, additional LP constraints along with incorporating the original PATRON rules, systematically enforce bidirectionality to at least two state elements per FSM transition. This bestows protection against different types of fault injection, which we capture with a new unidirectional metric. Enhanced PATRON (EP) achieves superior security at lower power consumption in average compared to PATRON, error-coding, and traditional FSM encoding on five popular benchmarks.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4385553999",
    "type": "article"
  },
  {
    "title": "The Resistance Analysis Attack and Security Enhancement of the IMC LUT Based on the Complementary Resistive Switch Cells",
    "doi": "https://doi.org/10.1145/3616870",
    "publication_date": "2023-08-24",
    "publication_year": 2023,
    "authors": "Xiaole Cui; M. Yin; Hanqing Liu; Xiaoxin Cui",
    "corresponding_authors": "",
    "abstract": "The resistive random access memory (RRAM) based in-memory computing (IMC) is an emerging architecture to address the challenge of the “memory wall” problem. The complementary resistive switch (CRS) cell connects two bipolar RRAM elements anti-serially to reduce the sneak current in the crossbar array. The CRS array is a generic computing platform, for the arbitrary logic functions can be implemented in it. The IMC CRS LUT consumes fewer CRS cells than the static CRS LUT. The CRS array has built-in polymorphic characteristics because the correct logic function cannot be distinguished based on the circuit layout. However, the logic state of every CRS cell can be readout after each operation. It helps the attacker to recover the correct function of the IMC CRS LUT. This work discusses the resistance analysis attack of the IMC LUT based on the CRS array. The proposed resistance analysis attack method is able to be applied to different computation styles based on the CRS array, such as the CRS IMPLY, CRS NOR-OR/NAND-AND, and so on. The attacker can recover the logic function of the LUT by tracing the states of CRS cells. Furthermore, an improved IMC CRS LUT method is proposed and discussed to enhance security. The simulation and analysis results show that the improved IMC CRS LUT can resist various attacks, and it maintains the polymorphic characteristics of the IMC CRS LUT. And the N-bit full adder circuit based on the improved IMC CRS NOR-OR LUTs achieves the best performance compared with the previous counterparts.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4386142130",
    "type": "article"
  },
  {
    "title": "Programmable In-memory Computing Circuit of Fast Hartley Transform",
    "doi": "https://doi.org/10.1145/3618112",
    "publication_date": "2023-09-01",
    "publication_year": 2023,
    "authors": "Qinghui Hong; Richeng Huang; Pingdan Xiao; Jun Li; Jingru Sun; Jiliang Zhang",
    "corresponding_authors": "",
    "abstract": "Discrete Hartley transform is a core component of digital signal processing because of its advantages of fast computing speed and less power consumption. Traditional FPGA-based implementation methods have the disadvantage of high latency, which cannot meet the needs of energy-efficient computing in the Internet of Things era. Therefore, A programmable analog memory computing circuit is proposed to accelerate FHT and IFHT calculations for large-scale one-step matrix computation. By adjusting the weight of memristor, different scales of FHT calculation can be achieved. PSPICE simulation results show that the average accuracy of the proposed circuit can reach 99.9%, and the speed can also reach the level of 0.1 μs. The robustness analysis shows that the circuit can tolerate a certain degree of programming error and resistance tolerance. The designed analog circuit is applied to image compression processing, and the image compression accuracy can reach 99.9%.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4386370876",
    "type": "article"
  },
  {
    "title": "Multi-target Fluid Mixing in MEDA Biochips: Theory and an Attempt toward Waste Minimization",
    "doi": "https://doi.org/10.1145/3622785",
    "publication_date": "2023-09-06",
    "publication_year": 2023,
    "authors": "Debraj Kundu; Sudip Roy",
    "corresponding_authors": "",
    "abstract": "Sample preparation is an inherent procedure of many biochemical applications, and digital microfluidic biochips (DMBs) have proved to be very effective in performing such a procedure. In a single mixing step, conventional DMBs can mix two droplets in a 1:1 ratio only. Due to this limitation, DMBs suffer from heavy fluid wastage and often require a lot of mixing steps. However, the next-generation DMBs, i.e., micro-electrode-dot-array (MEDA) biochips, can realize multiple mixing ratios, which in general helps in minimizing the number of mixing operations. In this article, we present a heuristic-based sample preparation algorithm, specifically a mixing algorithm called Division by Factor Method for MEDA that exploits the mixing models of MEDA biochips. We propose another mixing algorithm for MEDA biochips called Single Target Waste Minimization ( STWM ), which minimizes the wastage of fluids and determines an efficient mixing graph. We also propose an advanced methodology for multiple target reagent mixing problems called Multi-target Waste Minimization ( MTWM ), which determines efficient mixing graphs for different target ratios by maximizing the sharing of fluids and minimizing the fluid wastage. Simulation results suggest that the proposed STWM and MTWM methods outperform the state-of-the-art methods in terms of minimizing the amount of fluid wastage, reducing the total usage of reagent fluids, and minimizing the number of mixing operations.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4386477399",
    "type": "article"
  },
  {
    "title": "Introduction to the Special Section on Advances in Physical Design Automation",
    "doi": "https://doi.org/10.1145/3604593",
    "publication_date": "2023-09-09",
    "publication_year": 2023,
    "authors": "Iris Hui-Ru Jiang; David Chinnery; Gracieli Posser; Jens Lienig",
    "corresponding_authors": "",
    "abstract": "introduction Share on Introduction to the Special Section on Advances in Physical Design Automation Authors: Iris Hui-Ru Jiang National Taiwan University National Taiwan University 0000-0002-4554-3442View Profile , David Chinnery Siemens Digital Industries Software Siemens Digital Industries Software 0000-0003-2693-439XView Profile , Gracieli Posser Cadence Design Systems Cadence Design Systems 0000-0003-4683-3676View Profile , Jens Lienig Dresden University of Technology Dresden University of Technology 0000-0002-2140-4587View Profile Authors Info & Claims ACM Transactions on Design Automation of Electronic SystemsVolume 28Issue 5Article No.: 68pp 1–3https://doi.org/10.1145/3604593Published:09 September 2023Publication History 0citation39DownloadsMetricsTotal Citations0Total Downloads39Last 12 Months39Last 6 weeks39 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteGet Access",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4386579030",
    "type": "article"
  },
  {
    "title": "GAN-Place: Advancing Open Source Placers to Commercial-quality Using Generative Adversarial Networks and Transfer Learning",
    "doi": "https://doi.org/10.1145/3636461",
    "publication_date": "2023-12-06",
    "publication_year": 2023,
    "authors": "Yi‐Chen Lu; Haoxing Ren; Hao-Hsiang Hsiao; Sung Kyu Lim",
    "corresponding_authors": "",
    "abstract": "Recently, GPU-accelerated placers such as DREAMPlace and Xplace have demonstrated their superiority over traditional CPU-reliant placers by achieving orders of magnitude speed up in placement runtime. However, due to their limited focus in placement objectives (e.g., wirelength and density), the placement quality achieved by DREAMPlace or Xplace is not comparable to that of commercial tools. In this article, to bridge the gap between open source and commercial placers, we present a novel placement optimization framework named GAN-Place that employs generative adversarial learning to transfer the placement quality of the industry-leading commercial placer, Synopsys ICC2, to existing open source GPU-accelerated placers (DREAMPlace and Xplace). Without the knowledge of the underlying proprietary algorithms or constraints used by the commercial tools, our framework facilitates transfer learning to directly enhance the open source placers by optimizing the proposed differentiable loss that denotes the “similarity” between DREAMPlace- or Xplace-generated placements and those in commercial databases. Experimental results on seven industrial designs not only show that our GAN-Place immediately improves the Power, Performance, and Area metrics at the placement stage but also demonstrates that these improvements last firmly to the post-route stage, where we observe improvements by up to 8.3% in wirelength, 7.4% in power, and 37.6% in Total Negative Slack on a commercial CPU benchmark.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4389386428",
    "type": "article"
  },
  {
    "title": "Introduction to the Special Issue on Design for Testability and Reliability of Security-aware Hardware",
    "doi": "https://doi.org/10.1145/3631476",
    "publication_date": "2023-12-18",
    "publication_year": 2023,
    "authors": "Tianming Ni; Xiaoqing Wen; Hussam Amrouch; Cheng Zhuo; Peilin Song",
    "corresponding_authors": "",
    "abstract": "The research on design for testability and reliability of security-aware hardware has been important in both academia and industry. With ever-growing globalization, commercial hardware design, manufacturing, transportation, and supply now involve many different countries, resulting in aggravated vulnerability from hardware design to manufacturing. Hardware with malicious purposes implanted from the third-party manufacturing process may control the operation of a circuit and tamper its functions, causing serious security issues. However, hardware includes not only devices and circuits but also systems. An important fact is that testability, reliability, and security technologies come from different design layers, but the impact evaluation is conducted at the system level. In other words, the testability, reliability, and security design of different layers can be carried out in a holistic manner to achieve optimization for the whole system. In addition, the testability, reliability, and security design technologies of each design layer can be collaboratively conducted to achieve better performance. The testability, reliability, and security tradeoff has garnered attention from academia and industry, particularly in the Post-Moore Era, due to the complexities and opportunities arising from new architectures and technologies.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4389892719",
    "type": "article"
  },
  {
    "title": "An algorithm for integrated pin assignment and buffer planning",
    "doi": "https://doi.org/10.1145/1080334.1080340",
    "publication_date": "2005-07-01",
    "publication_year": 2005,
    "authors": "Hua Xiang; Xiaoping Tang; Martin D. F. Wong",
    "corresponding_authors": "",
    "abstract": "The buffer block methodology has become increasingly popular as more and more buffers are needed in deep-submicron design, and it leads to many challenging problems in physical design. In this article, we present a polynomial-time exact algorithm for integrated pin assignment and buffer planning for all two-pin nets from one macro block (source block) to all other blocks of a given buffer block plan, while minimizing the total cost α ˙ W + β ˙ R for any positive α and β where W is the total wirelength, and R is the number of buffers. By applying this algorithm iteratively (each time, pick one block as the source block), it provides a polynomial-time algorithm for pin assignment and buffer planning for nets among multiple macro blocks. Experimental results demonstrate its efficiency and effectiveness.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W1966709241",
    "type": "article"
  },
  {
    "title": "Improving the energy behavior of block buffering using compiler optimizations",
    "doi": "https://doi.org/10.1145/1124713.1124727",
    "publication_date": "2006-01-01",
    "publication_year": 2006,
    "authors": "Mahmut Kandemir; J. Ramanujam; U. Sezer",
    "corresponding_authors": "",
    "abstract": "On-chip caches consume a significant fraction of the energy in current microprocessors. As a result, architectural/circuit-level techniques such as block buffering and sub-banking have been proposed and shown to be very effective in reducing the energy consumption of on-chip caches. While there has been some work on evaluating the energy and performance impact of different block buffering schemes, we are not aware of software solutions to take advantage of on-chip cache block buffers.This article presents a compiler-based approach that modifies code and variable layout to take better advantage of block buffering. The proposed technique is aimed at a class of embedded codes that make heavy use of scalar variables. Unlike previous work that uses only storage pattern optimization or only access pattern optimization, we propose an integrated approach that uses both code restructuring (which affects the access sequence) and storage pattern optimization (which determines the storage layout of variables). We use a graph-based formulation of the problem and present a solution for determining suitable variable placements and accompanying access pattern transformations. The proposed technique has been implemented using an experimental compiler and evaluated using a set of complete programs. The experimental results demonstrate that our approach leads to significant energy savings. Based on these results, we conclude that compiler support is complementary to architecture and circuit-based techniques to extract the best energy behavior from a cache subsystem that employs block buffering.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W1971171149",
    "type": "article"
  },
  {
    "title": "Introduction to special issue",
    "doi": "https://doi.org/10.1145/1142980.1142981",
    "publication_date": "2004-06-07",
    "publication_year": 2004,
    "authors": "Massoud Pedram",
    "corresponding_authors": "Massoud Pedram",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2006203262",
    "type": "article"
  },
  {
    "title": "Implicit grading of multiple path delay faults",
    "doi": "https://doi.org/10.1145/1142155.1142160",
    "publication_date": "2006-04-01",
    "publication_year": 2006,
    "authors": "Sanjeevikumar Padmanaban; Spyros Tragoudas",
    "corresponding_authors": "",
    "abstract": "The problem of fault grading for multiple path delay faults is introduced and a method of obtain exact coverage is presented. The faults are represented and manipulated as combinational sets using zero-suppressed binary decision diagrams. The presented methodology for fault grading uses only a polynomial number of zero-suppressed binary decision diagram operations. The efficiency of the proposed method is demonstrated by the experimental results on the ISCAS'85 and ISCAS'89 benchmarks.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2065850211",
    "type": "article"
  },
  {
    "title": "Using 2-domain partitioned OBDD data structure in an enhanced symbolic simulator",
    "doi": "https://doi.org/10.1145/1109118.1109122",
    "publication_date": "2005-10-01",
    "publication_year": 2005,
    "authors": "Tao Feng; Li-C. Wang; Kwang‐Ting Cheng; Chih-Chang Lin",
    "corresponding_authors": "",
    "abstract": "In this article, we propose a symbolic simulation method where Boolean functions can be efficiently manipulated through a 2-domain partitioned OBDD data structure. The functional partition is applied by automatically exploring the key decision points implicitly built inside a circuit. The partition can help to significantly reduce the OBDD sizes, solving problems that could not be solved with monolithic OBDD data structure. We demonstrate the performance of the approach through the symbolic simulation of several benchmark circuits with complex control logics and datapath. The symbolic simulation based on 2-domain partitioned OBDD can be also applied in equivalence checking. It can generate the signature of functions to identify the critical partition points in the optimized gate-level netlist.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2070450973",
    "type": "article"
  },
  {
    "title": "Test chip experimental results on high-level structural test",
    "doi": "https://doi.org/10.1145/1109118.1109125",
    "publication_date": "2005-10-01",
    "publication_year": 2005,
    "authors": "Ahmad A. Al-Yamani; E.J. McCluskey",
    "corresponding_authors": "",
    "abstract": "Using complex (high-level) gates, such as multiplexers, full adders, etc., for automatic test pattern generation (ATPG) has several advantages. It makes ATPG faster and potentially reduces the size of the test set that needs to be applied. A variety of other techniques are used to reduce the size of test sets for digital chips. They typically rely on preserving the single-stuck-fault coverage of the test set. This article presents data obtained from applying a variety of test sets on the ELF35 test chip and recording the test escapes. The data presented show the test quality effect of using complex gates as fault sites. The article also shows the impact of test compaction and reduced fault coverage on the test quality.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2091533492",
    "type": "article"
  },
  {
    "title": "Domino Cache",
    "doi": "https://doi.org/10.1145/3174848",
    "publication_date": "2018-02-01",
    "publication_year": 2018,
    "authors": "Mahmood Naderan-Tahan; Hamid Sarbazi‐Azad",
    "corresponding_authors": "",
    "abstract": "The energy consumption for processing modern workloads is challenging in data centers. Due to the large datasets of cloud workloads, the miss rate of the L1 data cache is high, and with respect to the energy efficiency concerns, such misses are costly for memory instructions because lower levels of memory hierarchy consume more energy per access than the L1. Moreover, large last-level caches are not performance effective, in contrast to traditional scientific workloads. The aim of this article is to propose a large L1 data cache, called Domino, to reduce the number of accesses to lower levels in order to improve the energy efficiency. In designing Domino, we focus on two components that use the on-chip area and are not energy efficient, which makes them good candidates to use their area for enlarging the L1 data cache. Domino is a highly associative cache that extends the conventional cache by borrowing the prefetcher and last-level-cache storage budget and using it as additional ways for data cache. In Domino, the additional ways are separated from the conventional cache ways; hence, the critical path of the first access is not altered. On a miss in the conventional part, it searches the added ways in a mix of parallel-sequential fashion to compromise the latency and energy consumption. Results on the Cloudsuite benchmark suite show that read and write misses are reduced by 30%, along with a 28% reduction in snoop messages. The overall energy consumption per access is then reduced by 20% on average (maximum 38%) as a result of filtering accesses to the lower levels.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2786820085",
    "type": "article"
  },
  {
    "title": "Dynamically Determined Preferred Values and a Design-for-Testability Approach for Multiplexer Select Inputs under Functional Test Sequences",
    "doi": "https://doi.org/10.1145/3219778",
    "publication_date": "2018-08-20",
    "publication_year": 2018,
    "authors": "Irith Pomeranz",
    "corresponding_authors": "Irith Pomeranz",
    "abstract": "Earlier works observed that certain primary inputs have preferred values, which help increase the gate-level fault coverage when they appear in a functional test sequence. This article observes that multiplexers present additional opportunities for increasing the fault coverage of a functional test sequence, which are not captured by preferred primary input values. Because multiplexers are prevalent, their effect on the fault coverage can be significant. A static analysis that is independent of any functional test sequence is performed in this article to identify preferred values for the outputs of multiplexers. This is followed by a dynamic analysis that adjusts the select inputs of the multiplexers for a given functional test sequence to ensure that the preferred values appear on the outputs of the multiplexers more often. The analysis yields design-for-testability logic for the select inputs of the multiplexers that have preferred values. The logic is independent of the functional test sequence, and it allows the fault coverage to be increased when the select inputs are not primary inputs, or when the same select inputs are used for different multiplexers. Experimental results are presented to demonstrate that this approach has a significant effect on the fault coverage of functional test sequences.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2888406770",
    "type": "article"
  },
  {
    "title": "Learning From Sleeping Experts",
    "doi": "https://doi.org/10.1145/3236617",
    "publication_date": "2018-11-06",
    "publication_year": 2018,
    "authors": "Anh Truong; S. Rasoul Etesami; Negar Kiyavash",
    "corresponding_authors": "",
    "abstract": "We consider a generalized model of learning from expert advice in which experts could abstain from participating at some rounds. Our proposed online algorithm falls into the class of weighted average predictors and uses a time-varying multiplicative weight update rule. This update rule changes the weight of an expert based on his or her relative performance compared to the average performance of available experts at the current round. This makes the algorithm suitable for recommendation systems in the presence of an adversary with many potential applications in the new emerging area of the Internet of Things. We prove the convergence of our algorithm to the best expert, defined in terms of both availability and accuracy, in the stochastic setting. In particular, we show the applicability of our definition of best expert through convergence analysis of another well-known algorithm in this setting. Finally, through simulation results on synthetic and real datasets, we justify the out-performance of our proposed algorithms compared to the existing ones in the literature.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2899762402",
    "type": "article"
  },
  {
    "title": "Harvesting Row-Buffer Hits via Orchestrated Last-Level Cache and DRAM Scheduling for Heterogeneous Multicore Systems",
    "doi": "https://doi.org/10.1145/3269982",
    "publication_date": "2018-12-21",
    "publication_year": 2018,
    "authors": "Yang Song; Olivier Alavoine; Bill Lin",
    "corresponding_authors": "",
    "abstract": "In heterogeneous multicore systems, the memory subsystem, including the last-level cache and DRAM, is widely shared among the CPU, the GPU, and the real-time cores. Due to their distinct memory traffic patterns, heterogeneous cores result in more frequent cache misses at the last-level cache. As cache misses travel through the memory subsystem, two schedulers are involved for the last-level cache and DRAM, respectively. Prior studies treated the scheduling of the last-level cache and DRAM as independent stages. However, with no orchestration and limited visibility of memory traffic, neither scheduling stage is able to ensure optimal scheduling decisions for memory efficiency. Unnecessary precharges and row activations happen in DRAM when the memory scheduler is ignorant of incoming cache misses, and DRAM row-buffer states are invisible to the last-level cache. In this article, we propose a unified memory controller for the the last-level cache and DRAM with orchestrated schedulers. The memory scheduler harvests row-buffer hit opportunities in cache request buffers during spare time without inducing significant implementation cost. We further introduce a dynamic orchestrated scheduling policy to improve memory efficiency while achieving target CPU IPC. Extensive evaluations show that the proposed controller improves the total memory bandwidth of DRAM by 16.8% on average and saves DRAM energy by up to 29.7% while achieving comparable CPU IPCs. With the dynamic scheduling policy, the unified controller achieves the same IPC as the conventional design and increases DRAM bandwidth by 9.2%. In addition, we explore the potential of the proposed memory controller to attain improvements on both memory bandwidth and CPU IPC.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2905904633",
    "type": "article"
  },
  {
    "title": "Efficiently Managing the Impact of Hardware Variability on GPUs’ Streaming Processors",
    "doi": "https://doi.org/10.1145/3287308",
    "publication_date": "2018-12-21",
    "publication_year": 2018,
    "authors": "Jingweijia Tan; Kaige Yan",
    "corresponding_authors": "",
    "abstract": "Graphics Processing Units (GPUs) are widely used in general-purpose high-performance computing fields due to their highly parallel architecture. In recent years, a new era with the nanometer scale integrated circuit manufacture process has come. As a consequence, GPUs’ computation capability gets even stronger. However, as process technology scales down, hardware variability, e.g., process variations (PVs) and negative bias temperature instability (NBTI), has a higher impact on the chip quality. The parallelism of GPU desires high consistency of hardware units on chip; otherwise, the worst unit will inevitably become the bottleneck. So the hardware variability becomes a pressing concern to further improve GPUs’ performance and lifetime, not only in integrated circuit fabrication, but more in GPU architecture design. Streaming Processors (SPs) are the key units in GPUs, which perform most of parallel computing operations. Therefore, in this work, we focus on mitigating the impact of hardware variability in GPU SPs. We first model and analyze SPs’ performance variations under hardware variability. Then, we observe that both PV and NBTI have a large impact on SPs’ performance. We further observe unbalanced SP utilization, e.g., some SPs are idle when others are active, during program execution. Leveraging this observation, we propose a Hardware Variability-aware SPs’ Management policy (HVSM), which dynamically dispatches computation in appropriate SPs to balance the utilizations. In addition, we find that a large portion of compute operations are duplicate. We also propose an Operation Compression (OC) technique to minimize the unnecessary computations to further mitigate the hardware variability effects. Our experimental results show the combined HVSM and OC technique effectively reduces the impact of hardware variability, which can translate to 37% performance improvement or 18.3% lifetime extension for a GPU chip.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2906453608",
    "type": "article"
  },
  {
    "title": "Probabilistic Evaluation of Hardware Security Vulnerabilities",
    "doi": "https://doi.org/10.1145/3290405",
    "publication_date": "2019-01-10",
    "publication_year": 2019,
    "authors": "Yanping Gong; Fengyu Qian; Lei Wang",
    "corresponding_authors": "",
    "abstract": "Various design techniques can be applied to implement the finite state machine (FSM) functions in order to optimize timing, performance, power, and to reduce overhead. Recently, malicious attacks to hardware systems have emerged as a critical problem. Fault injection attacks, in particular, alter the function or reveal the critical information of a hardware system through precisely controlled fault injection processes. Attackers can utilize the loopholes and vulnerabilities of FSM functions to access the states that are under protection. A probabilistic model is developed in this article to evaluate the potential vulnerabilities of FSM circuits at the design stage. Analysis based on the statistical behaviors of FSM also shows that the induced circuit errors can be exploited to access the protected states. An effective solution based on state re-encoding is proposed to minimize the risk of unauthorized transitions. Simulation results demonstrate that vulnerable transition paths can be protected with small hardware overheads.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2909259172",
    "type": "article"
  },
  {
    "title": "Editorial for TODAES Special Issue on Internet of Things System Performance, Reliability, and Security",
    "doi": "https://doi.org/10.1145/3276908",
    "publication_date": "2018-11-30",
    "publication_year": 2018,
    "authors": "Rasit Onur Topaloglu; Farinaz Koushanfar",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2911632397",
    "type": "article"
  },
  {
    "title": "DCW",
    "doi": "https://doi.org/10.1145/3317574",
    "publication_date": "2019-05-31",
    "publication_year": 2019,
    "authors": "Bo Wan; Xi Li; Bo Zhang; Caixu Zhao; Xianglan Chen; Chao Wang; Xuehai Zhou",
    "corresponding_authors": "",
    "abstract": "Real-time systems continuously interact with the physical environment and often have to satisfy stringent timing constraints imposed by their interactions. Those systems involve two main properties: reactivity and predictability. Reactivity allows the system to continuously react to a non-deterministic external environment, while predictability guarantees the deterministic execution of safety-critical parts of applications. However, with the increase in software complexity, traditional approaches to develop real-time systems make temporal behaviors difficult to infer, especially when the system is required to address non-deterministic aperiodic events from the physical environment. In this article, we propose a reactive and predictable programming framework, Distributed Clockwerk (DCW), for distributed real-time systems. DCW introduces the Servant, which is a non-preemptible execution entity, to implement periodic tasks based on the Logical Execution Time (LET) model. Furthermore, a joint schedule policy, based on the slack stealing algorithm, is proposed to efficiently address aperiodic events with no violated hard-time constraints. To further support predictable communication among distributed nodes, DCW implements the Time-Triggered Controller Area Network (TTCAN) to avoid collisions while accessing the shared communication medium. Moreover, a programming framework implements to provide a set of programming APIs for defining timing and functional behaviors of concurrent tasks. An example is further implemented to illustrate the DCW design flow. The evaluation results demonstrate that our proposal can improve both periodic and aperiodic reactivity compared with existing work, and the implemented DCW can also ensure the system predictability by achieving extremely low overheads.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2948031697",
    "type": "article"
  },
  {
    "title": "Stress-Induced Performance Shifts in 3D DRAMs",
    "doi": "https://doi.org/10.1145/3331527",
    "publication_date": "2019-06-26",
    "publication_year": 2019,
    "authors": "Tengtao Li; Sachin S. Sapatnekar",
    "corresponding_authors": "",
    "abstract": "3D-stacked DRAMs can significantly increase cell density and bandwidth while also lowering power consumption. However, 3D structures experience significant thermomechanical stress due to the differential rate of contraction of the constituent materials, which have different coefficients of thermal expansion. This impacts circuit performance. This article develops a procedure that performs a performance analysis of 3D DRAMs, capturing the impact of both layout-aware stress and layout-independent stress on parameters such as latency, leakage power, refresh power, area, and bus delay. The approach first proposes a semianalytical stress analysis method for the entire 3D DRAM structure, capturing the stress induced by through-silicon-vias (TSVs), micro bumps, package bumps, and warpage. Next, this stress is translated to variations in device mobility and threshold voltage, after which analytical models for latency, leakage power, and refresh power are derived. Finally, a complete analysis of performance variations is performed for various 3D DRAM layout configurations to assess the impact of layout-dependent stress. We explore the use of alternative flexible package substrate options to mitigate the performance impact of stress. Specifically, we explore the use of an alternative bendable package substrate made of polyimide to reduce warpage-induced stress, and show that it reduces stress-induced variations and improves the performance metrics for stacked 3D DRAMs.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2955326186",
    "type": "article"
  },
  {
    "title": "Cut Optimization for Redundant Via Insertion in Self-Aligned Double Patterning",
    "doi": "https://doi.org/10.1145/3355391",
    "publication_date": "2019-09-09",
    "publication_year": 2019,
    "authors": "Youngsoo Song; Daijoon Hyun; Jingon Lee; Jinwook Jung; Youngsoo Shin",
    "corresponding_authors": "",
    "abstract": "Redundant via (RV) insertion helps prevent via defects and hence leads to yield enhancement. However, RV insertion in self-aligned double patterning (SADP) processes is challenging since cut optimization has to be considered together. In SADP, parallel one-dimensional metal lines are divided into signal wires and dummy wires by line-end cuts. If an RV is inserted, signal wires need to be extended to connect to the RV. To this end, an additional cut, which we call RV cut, is introduced to make a space for the extension. Since RV cuts and line-end cuts are manufactured with the same mask set, design rules between those cuts have to be honored, which incurs proper distribution and mask assignment to individual cuts. In this article, we address a problem of integrated RV insertion and cut optimization. We show that the problem can be formulated as an integer linear programming (ILP). We also propose a heuristic algorithm is presented for practical application, in which potential locations of RVs are first identified and used to properly insert as many RVs as possible while minimizing the conflict between RV cuts. Our experimental results demonstrate that 75% of vias receive RVs with 8% increase in total wire length, which is only slightly worse than the optimal result obtained by ILP.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2972777651",
    "type": "article"
  },
  {
    "title": "Two-sided Net Untangling with Internal Detours for Single-layer Bus Routing",
    "doi": "https://doi.org/10.1145/3363184",
    "publication_date": "2019-10-17",
    "publication_year": 2019,
    "authors": "Jin-Tai Yan",
    "corresponding_authors": "Jin-Tai Yan",
    "abstract": "It is known that one-sided net untangling can be used to untangle the twisted nets inside a bus for single-layer bus routing. However, limited space behind one pin-row may make one-sided net untangling unsuccessful for single-layer bus routing. In this article, the concept of using internal detours on untangled nets can be introduced into two-sided net untangling. Given a set of 2-pin nets inside a bus, based on two one-sided untangling results with internal detours on untangled nets [8], an efficient algorithm first uses a minimal set of internal detours to guarantee that the crossing conditions of the given nets inside the bus can be eliminated in one initial two-sided untangling result with no capacity constraint behind two pin-rows and between two adjacent pins inside any pin-row. Furthermore, based on the maintenance of the non-crossing constraint on any pair of nets and the capacity constraint behind two pin-rows in one initial two-sided untangling result, an iterative rip-up-and-reassign algorithm can be proposed to eliminate the possible capacity violations between two adjacent pins inside two pin-rows to route a maximal set of nets in two-sided net untangling. Compared with Yan's one-sided net untangling [8] for 12 tested examples with different capacity constraints, the experimental results show that our proposed two-sided untangling algorithm can improve 3.5% of routability and use the benefit of more routing space behind two pin-rows to reduce 86.4% of the used internal detours on average in reasonable CPU time. Compared with Yan's two-sided net untangling [9] for 12 tested examples with different capacity constraints, the experimental results show that our proposed two-sided untangling algorithm can improve 2.8% of routability by introducing some internal detours and using iterative rip-up-and-reassign on the average in reasonable CPU time.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2980738596",
    "type": "article"
  },
  {
    "title": "Making Aging Useful by Recycling Aging-induced Clock Skew",
    "doi": "https://doi.org/10.1145/3363186",
    "publication_date": "2019-12-07",
    "publication_year": 2019,
    "authors": "Tien-Hung Tseng; Chung-Han Chou; Kai–Chiang Wu",
    "corresponding_authors": "",
    "abstract": "Device aging, which causes significant loss on circuit performance and lifetime, has been a primary factor in reliability degradation of nanoscale designs. In this article, we propose to take advantage of aging-induced clock skews (i.e., make them useful for aging tolerance) by manipulating and recycling these time-varying skews to compensate for the performance degradation of logic networks. The goal is to assign achievable/reasonable aging-induced clock skews in a circuit, such that its effective performance degradation due to aging can be tolerated. On average, 21.21% aging tolerance can be achieved with insignificant design overhead. Moreover, we employ V th assignment on clock buffers to further tolerate the aging-induced degradation of logic networks. When V th assignment is applied on top of aforementioned aging manipulation, the average aging tolerance can be enhanced to 29.15%.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2997367813",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3357467",
    "publication_date": "2019-11-14",
    "publication_year": 2019,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Approximate computing is a promising design paradigm that introduces a new dimension—error—into the original design space. By allowing the inexact computation in error-tolerance applications, approximate computing can gain both performance and energy ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4232011989",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3326461",
    "publication_date": "2019-07-24",
    "publication_year": 2019,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Fabless semiconductor companies design system-on-chips (SoC) by using third-party intellectual property (IP) cores and fabricate them in offshore, potentially untrustworthy foundries. Owing to the globally distributed electronics supply chain, security ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4232796770",
    "type": "paratext"
  },
  {
    "title": "Editorial",
    "doi": "https://doi.org/10.1145/1124713.1124714",
    "publication_date": "2006-01-01",
    "publication_year": 2006,
    "authors": "Nikil Dutt",
    "corresponding_authors": "Nikil Dutt",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4232992670",
    "type": "editorial"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3375457",
    "publication_date": "2019-12-19",
    "publication_year": 2019,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4234399200",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1142155",
    "publication_date": "2006-04-01",
    "publication_year": 2006,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4234752854",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3217208",
    "publication_date": "2018-07-20",
    "publication_year": 2018,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Modern field-programmable gate array (FPGA) devices contain complex clock architectures on top of configurable logics. Unlike application specific integrated circuits (ASICs), the physical structure of clock networks in an FPGA is pre-manufactured and ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4235789708",
    "type": "paratext"
  },
  {
    "title": "Editorial",
    "doi": "https://doi.org/10.1145/1044111.1044112",
    "publication_date": "2005-01-01",
    "publication_year": 2005,
    "authors": "Nikil Dutt",
    "corresponding_authors": "Nikil Dutt",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4235940997",
    "type": "editorial"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3319359",
    "publication_date": "2019-06-01",
    "publication_year": 2019,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Smart systems are characterized by the integration in a single device of multi-domain subsystems of different technological domains, namely, analog, digital, discrete and power devices, MEMS, and power sources. Such challenges, emerging from the ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4237385071",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3149546",
    "publication_date": "2018-01-24",
    "publication_year": 2018,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "In real-time mixed-critical systems, Worst-Case Execution Time (WCET) analysis is required to guarantee that timing constraints are respected—at least for high-criticality tasks. However, the WCET is pessimistic compared to the real execution time, ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4238404345",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1142980",
    "publication_date": "2006-07-01",
    "publication_year": 2006,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Embedded system level design must be based on paradigms that make formal foundations and unification a cornerstone of their construction. Platform-Based designs and communication synthesis are important components of the paradigm shift we ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4240420239",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3339837",
    "publication_date": "2019-10-19",
    "publication_year": 2019,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Packet Classification is the enabling function performed in commodity switches for providing various services such as access control, intrusion detection, load balancing, and so on. Ternary Content Addressable Memories (TCAMs) are the de facto standard ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4241160043",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3184476",
    "publication_date": "2018-04-18",
    "publication_year": 2018,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Conventional clock guardbanding to assure a circuit’s reliable operation under device aging due to NBTI/PBTI and process variations introduce significant performance loss in modern nanometer circuits. Dynamic Frequency Scaling (DFS) is a more efficient ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4241217712",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1124713",
    "publication_date": "2006-01-01",
    "publication_year": 2006,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "The increasing use of microprocessor cores in embedded systems as well as mobile and portable devices creates an opportunity for customizing the cache subsystem for improved performance. In traditional cache design, the index portion of the memory ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4245988359",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3306156",
    "publication_date": "2019-03-21",
    "publication_year": 2019,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Various design techniques can be applied to implement the finite state machine (FSM) functions in order to optimize timing, performance, power, and to reduce overhead. Recently, malicious attacks to hardware systems have emerged as a critical problem. ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4246559929",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3291062",
    "publication_date": "2018-12-21",
    "publication_year": 2018,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "We present a primal-dual approximation algorithm for minimizing the leakage power of an integrated circuit by assigning gate threshold voltages. While most existing techniques do not provide a performance guarantee, we prove an upper bound on the power ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4250485125",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3268934",
    "publication_date": "2018-10-18",
    "publication_year": 2018,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Real-time data analytics for smart-grid energy management is challenging with consideration of both occupant behavior profiles and energy profiles. This article proposes a distributed and networked machine-learning platform on smart-gateway-based smart-...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4251137250",
    "type": "paratext"
  },
  {
    "title": "Introduction",
    "doi": "https://doi.org/10.1145/1109118.1109119",
    "publication_date": "2005-10-01",
    "publication_year": 2005,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4252044101",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1179461",
    "publication_date": "2006-10-01",
    "publication_year": 2006,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Logic duplication, a commonly used synthesis technique to remove trapped inverters in reconvergent paths of Domino circuits, incurs high area and power penalties. In this article, we propose a synthesis scheme to reduce the duplication cost by allowing ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4252936070",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3293467",
    "publication_date": "2019-01-11",
    "publication_year": 2019,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "In the future, mobile systems will increasingly feature more advanced organic light-emitting diode (OLED) displays. The power consumption of these displays is highly dependent on the image content. However, existing OLED power-saving techniques either ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4255030078",
    "type": "paratext"
  },
  {
    "title": "LDE-aware Analog Layout Migration with OPC-inclusive Routing",
    "doi": "https://doi.org/10.1145/3398190",
    "publication_date": "2020-07-07",
    "publication_year": 2020,
    "authors": "Mohammad Torabi; Lihong Zhang",
    "corresponding_authors": "",
    "abstract": "Performance degradation in analog circuits due to layout dependent effects (LDEs) has become increasingly challenging in advanced technologies. To address this issue, LDEs have to be seriously considered as performance constraints in the physical design process. In this article, we have proposed an innovative LDE-aware retargeting methodology for analog layout migration from old technologies to new ones with LDEs optimized for performance preservation. The LDE constraints, which are first identified with the aid of a specialized sensitivity analysis scheme, are satisfied during the layout migration process. Moreover, optical proximity correction (OPC), as one of the most popular resolution enhancement techniques for subwavelength lithography in modern nanometer technology manufacturing, is also included in this study. We have developed an OPC-inclusive ILP-based analog router to route electrical nets for improving image fidelity of the final layout while the routability and other analog constraints are respected in the meantime. The experimental results show our proposed layout migration methodology along with the routing scheme is able to retarget analog layouts with better circuit performance and finer image quality compared to the previous works.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3051664773",
    "type": "article"
  },
  {
    "title": "Interval Arithmetic and Self-Similarity Based RTL Input Vector Control for Datapath Leakage Minimization",
    "doi": "https://doi.org/10.1145/3408061",
    "publication_date": "2020-09-16",
    "publication_year": 2020,
    "authors": "Shilpa Pendyala; Sheikh Ariful Islam; Srinivas Katkoori",
    "corresponding_authors": "",
    "abstract": "With technology scaling, subthreshold leakage has dominated the overall power consumption in a design. Input vector control is an effective technique to minimize subthreshold leakage. Low leakage input vector determination is not often possible due to large design space and simulation time. Similarly, applying an appropriate minimum leakage vector (MLV) to each Register Transfer Level (RTL) module instance in a design often results in a low leakage state with significant area overhead. In this work, we propose a top-down and bottom-up approach for propagating the input vector interval to identify low leakage input vector at primary inputs of an RTL datapath. For each module, via Monte Carlo simulation, we identify a set of MLV intervals such that maximum leakage is within (say) 10% of the lowest leakage points. As the module bit width increases, exhaustive simulation to find the low leakage vector is not feasible. Further, we need to uniformly search the entire input space to obtain as many low leakage intervals as possible. Based on empirical observations, we observe self-similarity in the subthreshold leakage distribution of adder/multiplier modules with highly regular bit-slice architectures when input space is partitioned into smaller cells. This property enables the uniform search of low leakage vectors in the entire input space where the time taken for characterization increases linearly with the module size. We further process the reduced interval set with simulated annealing to arrive at the best low-leakage vector at the primary inputs. We also propose to reduce area overhead (in some cases to 0%) by choosing Primary Input (PI) MLVs such that resultant inputs to internal nodes are also MLVs. Compared to existing work, experimental results for DSP filters simulated in 16nm technology demonstrated leakage savings of 93.6% and 89.2% for top-down and bottom-up approaches with no area overhead.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3087107980",
    "type": "article"
  },
  {
    "title": "Introduction to the Special Issue on Machine Learning for CAD",
    "doi": "https://doi.org/10.1145/3410864",
    "publication_date": "2020-09-30",
    "publication_year": 2020,
    "authors": "Henkel Jorg; Xiaobo Sharon Hu; Wolf Marilyn",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3089860970",
    "type": "article"
  },
  {
    "title": "Editorial",
    "doi": "https://doi.org/10.1145/3419376",
    "publication_date": "2020-09-10",
    "publication_year": 2020,
    "authors": "Xiaobo Sharon Hu",
    "corresponding_authors": "Xiaobo Sharon Hu",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3107047064",
    "type": "editorial"
  },
  {
    "title": "Co-synthesis of pipelined structures and instruction reordering constraints for instruction set processors",
    "doi": "https://doi.org/10.1145/371254.371268",
    "publication_date": "2001-01-01",
    "publication_year": 2001,
    "authors": "Ing-Jer Huang",
    "corresponding_authors": "Ing-Jer Huang",
    "abstract": "This paper presents a hardware/software co-synthesis approach to pipelined ISP (instruction set processor) design. The approach synthesizes the pipeline structure from a given instruction set architecture (behavioral) specification. In addition, it generates a set of reordering constraints that guides the compiler back-end (reorderer) to properly schedule instructions so that possible pipeline hazards are avoided and throughput is improved. Co-synthesis takes place while resolving pipeline hazards, which can be attributed to interin-struction dependencies (IIDs). An extended taxonomy of IIDs have been proposed for the systematic analysis of pipeline hazards. Hardware/software methods are developed to resolve IIDs. Algorithms based on taxonomy and resolutions are constructed and integrated into the pipeline synthesis process to explore hardware and software design space. Application benchmarks are used to evaluate possible designs and guide the design decision. The power of the co-synthesis tool PIPER is demonstrated through pipeline synthesis of one illustrative example and two ISPs, including an industrial one (TDY-43). In comparison with other related approaches, our approach achieves higher throughput and provides a systematic way to explore the hardware/software trade-off.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W1989251639",
    "type": "article"
  },
  {
    "title": "Minimum delay optimization for domino logic circuits---a coupling-aware approach",
    "doi": "https://doi.org/10.1145/762488.762491",
    "publication_date": "2003-04-01",
    "publication_year": 2003,
    "authors": "K. W. Kim; Seong‐Ook Jung; Taewhan Kim; Sung-Mo Kang",
    "corresponding_authors": "",
    "abstract": "Minimum delay associated with the hold time requirement is of concern to circuit designers, since race-through hazards are inherent in any multiple clock organization or clock distribution tree irrespective of clock frequency. The monotonic property of domino logic aggravates the min-delay path failure through coupling-induced speedup. To tackle the min-delay problem for domino logic, we propose a min-delay optimization algorithm considering coupling effects. Experimental results indicate that our algorithm yields a significant increase of min-delay without incurring max-delay violation.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2026387462",
    "type": "article"
  },
  {
    "title": "Intrinsic response for analog module testing using an analog testability bus",
    "doi": "https://doi.org/10.1145/375977.375981",
    "publication_date": "2001-04-01",
    "publication_year": 2001,
    "authors": "Chauchin Su; Yue-Tsang Chen; Shyh‐Jye Jou",
    "corresponding_authors": "",
    "abstract": "A parasitic effect removal methodology is proposed to handle the large parasitic effects in analog testability buses. The removal is done by an on-chip test generation technique and an intrinsic response extraction algorithm. On-chip test generation creates test signals on-chip to avoid the parasitic effects of the test application bus. The intrinsic response extraction cross-checks and cancels the parasitic effects of both test application and response observation paths. The tests using both SPICE simulation and MNABST-1 P1149.4 test chip reveal that the proposed algorthm can not only remove the parasitic effects of the test buses but also tolerate test signal variations. Furthermore, it is robust enough to handle loud environmental noise and the nonlinearity of the switching devices.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2081949261",
    "type": "article"
  },
  {
    "title": "Introduction",
    "doi": "https://doi.org/10.1145/944027.944028",
    "publication_date": "2003-10-01",
    "publication_year": 2003,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4247392850",
    "type": "article"
  },
  {
    "title": "DANCE: DAta-Network Co-optimization for Efficient Segmentation Model Training and Inference",
    "doi": "https://doi.org/10.1145/3510835",
    "publication_date": "2022-05-05",
    "publication_year": 2022,
    "authors": "Chaojian Li; Wuyang Chen; Yuchen Gu; Tianlong Chen; Yonggan Fu; Zhangyang Wang; Yingyan Lin",
    "corresponding_authors": "",
    "abstract": "Semantic segmentation for scene understanding is nowadays widely demanded, raising significant challenges for the algorithm efficiency, especially its applications on resource-limited platforms. Current segmentation models are trained and evaluated on massive high-resolution scene images (“data-level”) and suffer from the expensive computation arising from the required multi-scale aggregation (“network level”). In both folds, the computational and energy costs in training and inference are notable due to the often desired large input resolutions and heavy computational burden of segmentation models. To this end, we propose DANCE, general automated DA ta- N etwork C o-optimization for E fficient segmentation model training and inference . Distinct from existing efficient segmentation approaches that focus merely on light-weight network design, DANCE distinguishes itself as an automated simultaneous data-network co-optimization via both input data manipulation and network architecture slimming. Specifically, DANCE integrates automated data slimming which adaptively downsamples/drops input images and controls their corresponding contribution to the training loss guided by the images’ spatial complexity. Such a downsampling operation, in addition to slimming down the cost associated with the input size directly, also shrinks the dynamic range of input object and context scales, therefore motivating us to also adaptively slim the network to match the downsampled data. Extensive experiments and ablating studies (on four SOTA segmentation models with three popular segmentation datasets under two training settings) demonstrate that DANCE can achieve “all-win” towards efficient segmentation (reduced training cost, less expensive inference, and better mean Intersection-over-Union (mIoU)). Specifically, DANCE can reduce ↓25%–↓77% energy consumption in training, ↓31%–↓56% in inference, while boosting the mIoU by ↓0.71%–↑ 13.34%.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3183813924",
    "type": "article"
  },
  {
    "title": "Introduction to the Special Issue on Approximate Systems",
    "doi": "https://doi.org/10.1145/3488726",
    "publication_date": "2022-02-11",
    "publication_year": 2022,
    "authors": "Armin Alaghi; Eva Darulová; Andreas Gerstlauer; Phillip Stanley‐Marbell",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4211165007",
    "type": "article"
  },
  {
    "title": "Increasing the Fault Coverage of a Truncated Test Set",
    "doi": "https://doi.org/10.1145/3508459",
    "publication_date": "2022-02-18",
    "publication_year": 2022,
    "authors": "Irith Pomeranz",
    "corresponding_authors": "Irith Pomeranz",
    "abstract": "Defect-aware, cell-aware, and gate-exhaustive faults are described by input patterns of subcircuits or cells that are expected to activate defects. Even with single-cycle faults, an \\( n \\) -input subcircuit can have up to \\( 2^n \\) faults with unique fault detection conditions, resulting in a large test set. Such a test set may have to be truncated to fit in the tester memory or satisfy constraints on test application time. In this case, a loss of fault coverage is inevitable. This article considers the test set denoted by \\( T_1 \\) obtained after truncating a larger test set denoted by \\( T_0 \\) . Suppose that the truncation reduces the set of detected faults from the set denoted by \\( D_0 \\) to the set denoted by \\( D_1 \\) . The procedure described in this article modifies the tests in \\( T_1 \\) to gain the detection of faults from \\( D_0 \\) \\( \\setminus \\) \\( D_1 \\) , even at the cost of losing the detection of faults from \\( D_1 \\) . The goal is to reduce the fault coverage loss by computing a test set denoted by \\( T_2 \\) that detects a set of faults denoted by \\( D_2 \\) such that \\( |T_2| = |T_1| \\) and \\( |D_2| \\gt |D_1| \\) . Experimental results for benchmark circuits demonstrate the ability of the procedure to increase the coverage of gate-exhaustive faults over several iterations.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4212800822",
    "type": "article"
  },
  {
    "title": "Design Automation Algorithms for the NP-Separate VLSI Design Methodology",
    "doi": "https://doi.org/10.1145/3508375",
    "publication_date": "2022-02-18",
    "publication_year": 2022,
    "authors": "Monzurul Islam Dewan; Dae Hyun Kim",
    "corresponding_authors": "",
    "abstract": "The NP-Separate design methodology for very-large-scale integration (VLSI) design fine-controls the sizes of transistors, thereby achieving significant power, performance, and area improvement compared to the conventional standard-cell-based design methodology. NP-Separate uses NP cells formed by merging and routing N and P cells having only NFETs and PFETs, respectively. The NP cell formation, however, should be automated to design large circuits using the NP-Separate design methodology. In this paper, we propose design automation algorithms to create NP cells automatically. Simulation results show that the automated NP-Separate reduces the design time significantly, decreases the coupling capacitance by 13%, the critical path delay by 6%, and the power consumption by 10% on average compared to the manual NP-Separate designs. We also propose a detailed placement algorithm to generate more compact VLSI layouts with a little wirelength overhead. The combined effect reduces the coupling capacitance by 10%, the critical path delay by 5%, and the power consumption by 10% on average compared to the manual NP-Separate designs.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4213207057",
    "type": "article"
  },
  {
    "title": "Synthesis of Clock Networks with a Mode-Reconfigurable Topology",
    "doi": "https://doi.org/10.1145/3503538",
    "publication_date": "2022-03-08",
    "publication_year": 2022,
    "authors": "Necati Uysal; Rickard Ewetz",
    "corresponding_authors": "",
    "abstract": "Modern digital circuits are often required to operate in multiple modes to cater to variable frequency and power requirements. Consequently, the clock networks for such circuits must be synthesized, meeting different timing constraints in different operational modes. The overall power consumption and robustness to variations of a clock network are determined by the topology. However, state-of-the-art clock networks use the same topology in every mode, despite that timing constraints in low- and high-performance modes can be very different. In this article, we propose a clock network with a mode-reconfigurable topology (MRT) for circuits with positive-edge-triggered sequential elements. In high-performance modes, the MRT structure is reconfigured into a near-tree to provide the required robustness to variations. In low-performance modes, the MRT structure is reconfigured into a tree to save power. Non-tree (or near-tree) structures provide robustness to variations by appropriately constructing multiple alternative paths from the clock source to the clock sinks, which neutralizes the negative impact of variations. In MRT structures, OR-gates are used to join multiple alternative paths into a single path. Hence, the MRT structures consume no short-circuit power because there is only one gate driving each net. Moreover, it is straightforward to reconfigure an MRT structure into a tree topology using a single clock gate. In high-performance modes, the experimental results demonstrate that MRT structures have \\( 25\\% \\) lower power consumption than state-of-the-art near-tree structures. In low-performance modes, the power consumption of the MRT structure is similar to the power consumption of a clock tree.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4220762908",
    "type": "article"
  },
  {
    "title": "A Case for Precise, Fine-Grained Pointer Synthesis in High-Level Synthesis",
    "doi": "https://doi.org/10.1145/3491430",
    "publication_date": "2022-03-08",
    "publication_year": 2022,
    "authors": "Nadesh Ramanathan; George A. Constantinides; John Wickerson",
    "corresponding_authors": "",
    "abstract": "This article combines two practical approaches to improve pointer synthesis within HLS tools. Both approaches focus on inefficiencies in how HLS tools treat the points-to graph— a mapping that connects each instruction to the memory locations that it might access at runtime. HLS pointer synthesis first computes the points-to graph via pointer analysis and then implements its connections in hardware, which gives rise to two inefficiencies. First, HLS tools typically favour pointer analysis that is fast, sacrificing precision. Second, they also favour centralising memory connections in hardware for instructions that can point to more than one location. In this article, we demonstrate that a more precise pointer analysis coupled with decentralised memory connections in hardware can substantially reduce the unnecessary sharing of memory resources. We implement both flow- and context-sensitive pointer analysis and fine-grained memory connections in two modern HLS tools, LegUp and Vitis HLS. An evaluation on three benchmark suites, ranging from non-trivial pointer use to standard HLS benchmarks, indicates that when we improve both precision and granularity of pointer synthesis, on average, we can reduce area and latency by around 42% and 37%, respectively.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4220923401",
    "type": "article"
  },
  {
    "title": "Achieving High In Situ Training Accuracy and Energy Efficiency with Analog Non-Volatile Synaptic Devices",
    "doi": "https://doi.org/10.1145/3500929",
    "publication_date": "2022-03-08",
    "publication_year": 2022,
    "authors": "Shanshi Huang; Xiaoyu Sun; Xiaochen Peng; Hongwu Jiang; Shimeng Yu",
    "corresponding_authors": "",
    "abstract": "On-device embedded artificial intelligence prefers the adaptive learning capability when deployed in the field, and thus in situ training is required. The compute-in-memory approach, which exploits the analog computation within the memory array, is a promising solution for deep neural network (DNN) on-chip acceleration. Emerging non-volatile memories are of great interest, serving as analog synapses due to their multilevel programmability. However, the asymmetry and nonlinearity in the conductance tuning remain grand challenges for achieving high in situ training accuracy. In addition, analog-to-digital converters at the edge of the memory array introduce quantization errors. In this work, we present an algorithm-hardware co-optimization to overcome these challenges. We incorporate the device/circuit non-ideal effects into the DNN propagation and weight update steps. By introducing the adaptive “momentum” in the weight update rule, in situ training accuracy on CIFAR-10 could approach its software baseline even under severe asymmetry/nonlinearity and analog-to-digital converter quantization error. The hardware performance of the on-chip training architecture and the overhead for adding “momentum” are also evaluated. By optimizing the backpropagation dataflow, 23.59 TOPS/W training energy efficiency (12× improvement compared to naïve dataflow) is achieved. The circuits that handle “momentum” introduce only 4.2% energy overhead. Our results show great potential and more relaxed requirements that enable emerging non-volatile memories for DNN acceleration on the embedded artificial intelligence platforms.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4220969256",
    "type": "article"
  },
  {
    "title": "Introduction to the Special Section on High-level Synthesis for FPGA: Next-generation Technologies and Applications",
    "doi": "https://doi.org/10.1145/3519279",
    "publication_date": "2022-03-08",
    "publication_year": 2022,
    "authors": "Christian Pilato; Zhenman Fang; Yuko Hara–Azumi; Jihyeon Hwang",
    "corresponding_authors": "Christian Pilato",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4220978688",
    "type": "article"
  },
  {
    "title": "Guest Editorial",
    "doi": "https://doi.org/10.1145/362652.362654",
    "publication_date": "2000-10-01",
    "publication_year": 2000,
    "authors": "Peter Marwedel",
    "corresponding_authors": "Peter Marwedel",
    "abstract": "editorial Free Access Share on Guest Editorial Author: Peter Marwedel Univ. of Dortnund, Dortmund, Germany Univ. of Dortnund, Dortmund, GermanyView Profile Authors Info & Claims ACM Transactions on Design Automation of Electronic SystemsVolume 5Issue 4Oct. 2000 pp 749–751https://doi.org/10.1145/362652.362654Published:01 October 2000Publication History 0citation192DownloadsMetricsTotal Citations0Total Downloads192Last 12 Months5Last 6 weeks1 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my Alerts New Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4240170711",
    "type": "editorial"
  },
  {
    "title": "Editorial",
    "doi": "https://doi.org/10.1145/348019.348027",
    "publication_date": "2000-07-01",
    "publication_year": 2000,
    "authors": "Mary Jane Irwin",
    "corresponding_authors": "Mary Jane Irwin",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4245874140",
    "type": "editorial"
  },
  {
    "title": "E <sup>2</sup> -VOR: An End-to-End En/Decoder Architecture for Efficient Video Object Recognition",
    "doi": "https://doi.org/10.1145/3543852",
    "publication_date": "2022-06-17",
    "publication_year": 2022,
    "authors": "Zhuoran Song; Naifeng Jing; Xiaoyao Liang",
    "corresponding_authors": "",
    "abstract": "High-resolution video object recognition (VOR) evolves so fast but is very compute-intensive. This is because VOR leverages compute-intensive deep neural network (DNN) for better accuracy. Although many works have been proposed for speedup, they mostly focus on DNN algorithm and hardware acceleration on the edge side. We observe that most video streams need to be losslessly compressed before going online and an encoder should have all the video information. Moreover, as the cloud should have abundant computing power to handle sophisticated VOR algorithms, we propose to take a one-shot effort for a modified VOR algorithm at the encoding stage in cloud and integrate the full VOR regeneration into a slightly extended decoder on the device. The scheme can enable lightweight VOR with server-class accuracy by simply leveraging the classic and economic video decoder universal to any mobile device. Meanwhile, the scheme can save massive computing power for not repetitively processing the same video on different user devices that makes it extremely sustainable for green computing across the whole network. We propose E 2 -VOR, an end-to-end encoder and decoder architecture for efficient VOR. We carefully design the scheme to have minimum impact on the video bitstream transmitted. In the cloud, the VOR extended video encoder tracks on a macro-block basis and packs intelligent information into the video stream for increased VOR accuracy and fast regenerating process. On the edge device, we extend the traditional video decoder with a small piece of dedicated hardware to enable the efficient VOR regeneration. Our experiment shows that E 2 -VOR can achieve 5.0× performance improvement with less than 0.4% VOR accuracy loss compared to the state-of-the-art FAVOS scheme. On average, E 2 -VOR can run over 54 frames-per-second (FPS) for 480P videos on an edge device.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4283008733",
    "type": "article"
  },
  {
    "title": "Training PPA Models for Embedded Memories on a Low-data Diet",
    "doi": "https://doi.org/10.1145/3556539",
    "publication_date": "2022-08-12",
    "publication_year": 2022,
    "authors": "Felix Last; Ulf Schlichtmann",
    "corresponding_authors": "",
    "abstract": "Supervised machine learning requires large amounts of labeled data for training. In power, performance, and area (PPA) estimation of embedded memories, every new memory compiler version is considered independently of previous compiler versions. Since the data of different memory compilers originate from similar domains, transfer learning may reduce the amount of supervised data required by pre-training PPA estimation neural networks on related domains. We show that provisioning times of PPA models for new compiler versions can be reduced significantly by exploiting similarities among different compilers, versions, and technology nodes. Through transfer learning, we shorten the time to provision PPA models for new compiler versions, which speeds up time-critical periods of the design cycle. Using only 901 training samples (10%) is sufficient to achieve an almost worst-case (98th percentile) estimation error of 2.67% and allows us to shorten model provisioning times from 40 days to less than one week without sacrificing accuracy. To enable a diverse set of source domains for transfer learning, we devise a new, application-independent method for overcoming structural domain differences through domain equalization that attains competitive results when compared to domain-free transfer. A high degree of automation necessitates the efficient assessment of the best source domains. We propose using various metrics to accurately identify four of the five best among 45 datasets with low computational effort.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4291145422",
    "type": "article"
  },
  {
    "title": "Efficient Test Chip Design via Smart Computation",
    "doi": "https://doi.org/10.1145/3558393",
    "publication_date": "2022-09-12",
    "publication_year": 2022,
    "authors": "Chenlei Fang; Qicheng Huang; Zeye Liu; Ruizhou Ding; R. D. Blanton",
    "corresponding_authors": "",
    "abstract": "Submitted to the Special Issue on Machine Learning for CAD (ML-CAD). Competitive strength in semiconductor field depends on yield. The challenges associated with designing and manufacturing of leading-edge integrated circuits (ICs) have increased that reduce yield. Test chips, especially full-flow logic test chips, are increasingly employed to investigate the complex interaction between layout features and the process that improves the total process quality before and during initial mass production. However, designing a high-quality full-flow logic test chip can be time-consuming due to the huge design space and complex process to search for optimal result. This work describes a new design flow that significantly accelerates the logic test chip design process. First, we deploy random forest classification technique to predict potential synthesis outcome for test chip design exploration. Next, a new method is described to efficiently solve the integer programming problem involved in the design process. Various experiments with industrial design have demonstrated that the proposed two methods greatly improve the design efficiency.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4295290224",
    "type": "article"
  },
  {
    "title": "Design of Synthesis-time Vectorized Arithmetic Hardware for Tapered Floating-point Addition and Subtraction",
    "doi": "https://doi.org/10.1145/3567423",
    "publication_date": "2022-10-08",
    "publication_year": 2022,
    "authors": "Ashish Reddy Bommana; Susheel Ujwal Siddamshetty; Dhilleswararao Pudi; T.K.R Arvind; Srinivas Boppu; M. Sabarimalai Manikandan; Linga Reddy Cenkeramaddi",
    "corresponding_authors": "",
    "abstract": "Energy efficiency has become the new performance criterion in this era of pervasive embedded computing; thus, accelerator-rich multi-processor system-on-chips are commonly used in embedded computing hardware. Once computationally intensive machine learning applications gained much traction, they are now deployed in many application domains due to abundant and cheaply available computational capacity. In addition, there is a growing trend toward developing hardware accelerators for machine learning applications for embedded edge devices where performance and energy efficiency are critical. Although these hardware accelerators frequently use floating-point operations for accuracy, reduced-width floating-point formats are also used to reduce hardware complexity; thus, power consumption while maintaining accuracy. Vectorization concepts can also be used to improve performance, energy efficiency, and memory bandwidth. We propose the design of a vectorized floating-point adder/subtractor that supports arbitrary length floating-point formats with varying exponent and mantissa widths in this article. In comparison to existing designs in the literature, the proposed design is 2.57× area- and 1.56× power-efficient, and it supports true vectorization with no restrictions on exponent and mantissa widths.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4303647553",
    "type": "article"
  },
  {
    "title": "CmpCNN: CMP Modeling with Transfer Learning CNN Architecture",
    "doi": "https://doi.org/10.1145/3569941",
    "publication_date": "2022-10-27",
    "publication_year": 2022,
    "authors": "Qing Zhang; Huajie Huang; Jizuo Li; Yuhang Zhang; Yongfu Li",
    "corresponding_authors": "",
    "abstract": "Performing chemical mechanical polishing (CMP) modeling for physical verification on an integrated circuit (IC) chip is vital to minimize its manufacturing yield loss. Traditional CMP models calculate post-CMP topography height of the IC’s layout based on physical principles and empirical experiments, which is computationally costly and time-consuming. In this work, we propose a CmpCNN framework based on convolutional neural networks (CNNs) with a transfer learning method to accelerate the CMP modeling process. It utilizes a multi-input strategy by feeding the binary image of layout and its density into our CNN-based model to extract features more efficiently. The transfer learning method is adopted to different CMP process parameters and different categories of circuits to further improve its prediction accuracy and convergence speed. Experimental results show that our CmpCNN framework achieves a competitive root mean square error ( RMSE ) of 2.7733Å with 1.89× reduction compared to the prior work, and a 57× speedup compared to the commercial CMP simulation tool.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4307366305",
    "type": "article"
  },
  {
    "title": "Polling-Based Memory Interface",
    "doi": "https://doi.org/10.1145/3572919",
    "publication_date": "2022-12-02",
    "publication_year": 2022,
    "authors": "Trung Thanh Le; Zhao Zhang; Zhichun Zhu",
    "corresponding_authors": "",
    "abstract": "Non-volatile memory has been extensively researched as the alternative for a DRAM-based system; however, the traditional memory controller cannot efficiently track and schedule operations for all the memory devices in heterogeneous systems due to different timing requirements and complex architecture supports of various memory technologies. To address this issue, we propose a hybrid memory architecture framework called POMI (POlling-based Memory Interface). It uses a small buffer chip inserted on each DIMM (Dual In-line Memory Module) to decouple operation scheduling from the controller to enable the support for diverse memory technologies in the system. Unlike the conventional DRAM-based system, POMI uses a polling-based memory bus protocol for communication and to resolve any bus conflicts between memory modules. The buffer chip on each DIMM will provide feedback information to the main memory controller so that the polling overhead is trivial. We propose two unique designs. The first one adds additional bus lines for sending the feedback information, and the second one utilizes the Command/Address bus. The framework provides several benefits: a technology-independent memory system, higher parallelism, and better scalability. Our experimental results show that POMI can efficiently support both homogeneous and heterogeneous systems. Compared with the conventional DDR4-2400 implementation, our scheme improves the performance of memory-intensive workloads by 3.7% on average. Compared with an existing interface for hybrid memory systems, Twin-Load, it also improves performance by 22.0% on average for memory-intensive workloads.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4311119096",
    "type": "article"
  },
  {
    "title": "General technology mapping for field-programmable gate arrays based on lookup tables",
    "doi": "https://doi.org/10.1145/504914.504915",
    "publication_date": "2002-01-01",
    "publication_year": 2002,
    "authors": "Amit Chowdhary; John P. Hayes",
    "corresponding_authors": "",
    "abstract": "We present a general technology-mapping methodology (TULIP) for field-programmable gate arrays (FPGAs) that can yield optimal results, and is applicable to any FPGA with a logic block composed of lookup tables (LUTs). We introduce the concept of a virtual switch to model the internal connections of a logic block with multiple LUTs; each configuration of virtual switches is called a multiple-LUT block (MLB). A logic block can be precisely defined by a small but complete set of representative configurations called an MLB basis. The MLB bases for various commercial FPGA families are demonstrated. Given a logic block represented by its MLB basis, technology mapping is precisely formulated as a graph-covering problem, which is transformed into a mixed integer-linear programming (MILP) optimization problem in order to achieve our optimality and generality objectives. The MILP model is solved using a general-purpose MILP solver tool. The results of using TULIP for mapping some ISCAS-85 benchmark circuits to a variety of logic blocks are presented. Circuits of a few hundred gates can be mapped directly in a few minutes. To map larger circuits to complex logic blocks, some approximation techniques are proposed based on partitioning the input circuit and simplifying the MLB basis. We show that these approximations result in close-to-optimal mappings of the benchmark circuits.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2119770138",
    "type": "article"
  },
  {
    "title": "Guest editorial",
    "doi": "https://doi.org/10.1145/605440.605441",
    "publication_date": "2002-10-01",
    "publication_year": 2002,
    "authors": "Majid Sarrafzadeh; Rajeev Jayaraman",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4248188977",
    "type": "editorial"
  },
  {
    "title": "Estimating the storage requirements of the rectangular and L-shaped corner stitching data structures",
    "doi": "https://doi.org/10.1145/290833.290850",
    "publication_date": "1998-04-01",
    "publication_year": 1998,
    "authors": "Dinesh P. Mehta",
    "corresponding_authors": "Dinesh P. Mehta",
    "abstract": "This paper proposes a technique for estimating the storage requirements of the Rectangular Corner Stitching (RCS) data structure [Ousterhout 1984] and the L-shaped Corner Stitching (LCS) data structure [Mehta and Blust 1997] on a given circuit by studying its (the circuit's) geometric properties. This provides a method for estimating the storage requirements of a circuit without having to implement the corner stitching data structure, which is a tedious and time-consuming task. This technique can also be used to estimate the amount of space saved by employing the LCS data structure over the RCS data structure on a given circuit.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2041071428",
    "type": "article"
  },
  {
    "title": "Covering Test Holes of Functional Broadside Tests",
    "doi": "https://doi.org/10.1145/3441282",
    "publication_date": "2021-01-06",
    "publication_year": 2021,
    "authors": "Irith Pomeranz",
    "corresponding_authors": "Irith Pomeranz",
    "abstract": "Functional broadside tests were developed to avoid overtesting of delay faults. The tests achieve this goal by creating functional operation conditions during their functional capture cycles. To increase the achievable fault coverage, close-to-functional scan-based tests are allowed to deviate from functional operation conditions. This article suggests that a more comprehensive functional broadside test set can be obtained by replacing target faults that cannot be detected with faults that have similar (but not identical) detection conditions. A more comprehensive functional broadside test set has the advantage that it still maintains functional operation conditions. It covers the test holes created when target faults cannot be detected by detecting similar faults. The article considers the case where the target faults are transition faults. When a standard transition fault, with an extra delay of a single clock cycle, cannot be detected, an unspecified transition fault is used instead. An unspecified transition fault captures the behaviors of transition faults with different extra delays. When this fault cannot be detected, a stuck-at fault is used instead. A stuck-at fault has some of the detection conditions of a transition fault. Multicycle functional broadside tests are used to allow unspecified transition faults to be detected. As a by-product, test compaction also occurs. The structure of the test generation procedure accommodates the complexity of producing functional broadside tests by considering the target as well as replacement faults together. Experimental results for benchmark circuits demonstrate the fault coverage improvements achieved, and the effect on the number of tests.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3119880501",
    "type": "article"
  },
  {
    "title": "Equivalent Faults under Launch-on-Shift (LOS) Tests with Equal Primary Input Vectors",
    "doi": "https://doi.org/10.1145/3440013",
    "publication_date": "2021-01-15",
    "publication_year": 2021,
    "authors": "Irith Pomeranz",
    "corresponding_authors": "Irith Pomeranz",
    "abstract": "A recent work showed that it is possible to transform a single-cycle test for stuck-at faults into a launch-on-shift (LOS) test that is guaranteed to detect the same stuck-at faults without any logic or fault simulation. The LOS test also detects transition faults. This was used for obtaining a compact LOS test set that detects both types of faults. In the scenario where LOS tests are used for both stuck-at and transition faults, this article observes that, under certain conditions, the detection of a stuck-at fault guarantees the detection of a corresponding transition fault. This implies that the two faults are equivalent under LOS tests. Equivalence can be used for reducing the set of target faults for test generation and test compaction. The article develops this notion of equivalence under LOS tests with equal primary input vectors and provides an efficient procedure for identifying it. It presents experimental results to demonstrate that such equivalences exist in benchmark circuits, and shows an unexpected effect on a test compaction procedure.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3124384683",
    "type": "article"
  },
  {
    "title": "A Variation-aware Hold Time Fixing Methodology for Single Flux Quantum Logic Circuits",
    "doi": "https://doi.org/10.1145/3460289",
    "publication_date": "2021-08-01",
    "publication_year": 2021,
    "authors": "Xi Li; Soheil Nazar Shahsavani; Xuan Zhou; Massoud Pedram; Peter A. Beerel",
    "corresponding_authors": "",
    "abstract": "Single flux quantum (SFQ) logic is a promising technology to replace complementary metal-oxide-semiconductor logic for future exa-scale supercomputing but requires the development of reliable EDA tools that are tailored to the unique characteristics of SFQ circuits, including the need for active splitters to support fanout and clocked logic gates. This article is the first work to present a physical design methodology for inserting hold buffers in SFQ circuits. Our approach is variation-aware, uses common path pessimism removal and incremental placement to minimize the overhead of timing fixes, and can trade off layout area and timing yield. Compared to a previously proposed approach using fixed hold time margins, Monte Carlo simulations show that, averaging across 10 ISCAS’85 benchmark circuits, our proposed method can reduce the number of inserted hold buffers by 8.4% with a 6.2% improvement in timing yield and by 21.9% with a 1.7% improvement in timing yield.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3187101752",
    "type": "article"
  },
  {
    "title": "An Efficient Execution Framework of Two-Part Execution Scenario Analysis",
    "doi": "https://doi.org/10.1145/3465474",
    "publication_date": "2021-09-13",
    "publication_year": 2021,
    "authors": "Han Ding; Guohui Li; Quan Zhou; Jianjun Li; Yong Yang; Xiaofei Hu",
    "corresponding_authors": "",
    "abstract": "Response Time Analysis ( RTA ) is an important and promising technique for analyzing the schedulability of real-time tasks under both Global Fixed-Priority ( G-FP ) scheduling and Global Earliest Deadline First ( G-EDF ) scheduling. Most existing RTA methods for tasks under global scheduling are dominated by partitioned scheduling, due to the pessimism of the <?TeX $1/m$?> -based interference calculation where <?TeX $m$?> is the number of processors. Two-part execution scenario is an effective technique that addresses this pessimism at the cost of efficiency. The major idea of two-part execution scenario is to calculate a more accurate upper bound of the interference by dividing the execution of the target job into two parts and calculating the interference on the target job in each part. This article proposes a novel RTA execution framework that improves two-part execution scenario by reducing some unnecessary calculation, without sacrificing accuracy of the schedulability test. The key observation is that, after the division of the execution of the target job, two-part execution scenario enumerates all possible execution time of the target job in the first part for calculating the final Worst-Case Response Time ( WCRT ). However, only some special execution time can cause the final result. A set of experiments is conducted to test the performance of the proposed execution framework and the result shows that the proposed execution framework can improve the efficiency of two-part execution scenario analysis by up to <?TeX $96\\%$?> in terms of the execution time.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3198992024",
    "type": "article"
  },
  {
    "title": "Double-Shift: A Low-Power DNN Weights Storage and Access Framework based on Approximate Decomposition and Quantization",
    "doi": "https://doi.org/10.1145/3477047",
    "publication_date": "2021-11-02",
    "publication_year": 2021,
    "authors": "Ming Han; Ye Wang; Jian Dong; Gang Qu",
    "corresponding_authors": "",
    "abstract": "One major challenge in deploying Deep Neural Network (DNN) in resource-constrained applications, such as edge nodes, mobile embedded systems, and IoT devices, is its high energy cost. The emerging approximate computing methodology can effectively reduce the energy consumption during the computing process in DNN. However, a recent study shows that the weight storage and access operations can dominate DNN's energy consumption due to the fact that the huge size of DNN weights must be stored in the high-energy-cost DRAM. In this paper, we propose Double-Shift, a low-power DNN weight storage and access framework, to solve this problem. Enabled by approximate decomposition and quantization, Double-Shift can reduce the data size of the weights effectively. By designing a novel weight storage allocation strategy, Double-Shift can boost the energy efficiency by trading the energy consuming weight storage and access operations for low-energy-cost computations. Our experimental results show that Double-Shift can reduce DNN weights to 3.96%–6.38% of the original size and achieve an energy saving of 86.47%–93.62%, while introducing a DNN classification error within 2%.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3207985551",
    "type": "article"
  },
  {
    "title": "Towards Fine-Grained Online Adaptive Approximation Control for Dense SLAM on Embedded GPUs",
    "doi": "https://doi.org/10.1145/3486612",
    "publication_date": "2021-11-02",
    "publication_year": 2021,
    "authors": "T. Bu; Kaige Yan; Jingweijia Tan",
    "corresponding_authors": "",
    "abstract": "Dense SLAM is an important application on an embedded environment. However, embedded platforms usually fail to provide enough computation resources for high-accuracy real-time dense SLAM, even with high-parallelism architecture such as GPUs. To tackle this problem, one solution is to design proper approximation techniques for dense SLAM on embedded GPUs. In this work, we propose two novel approximation techniques, critical data identification and redundant branch elimination. We also analyze the error characteristics of the other two techniques—loop skipping and thread approximation. Then, we propose SLaPP, an online adaptive approximation controller, which aims to control the error to be under an acceptable threshold. The evaluation shows SLaPP can achieve 2.0× performance speedup and 30% energy saving on average compared to the case without approximation.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3209681167",
    "type": "article"
  },
  {
    "title": "Hierarchical Scheduling of an SDF/L Graph onto Multiple Processors",
    "doi": "https://doi.org/10.1145/3489469",
    "publication_date": "2021-11-22",
    "publication_year": 2021,
    "authors": "Mari-Liis Oldja; Jangryul Kim; Dowhan Jeong; Soonhoi Ha",
    "corresponding_authors": "",
    "abstract": "Although dataflow models are known to thrive at exploiting task-level parallelism of an application, it is difficult to exploit the parallelism of data, represented well with loop structures, since these structures are not explicitly specified in existing dataflow models. SDF/L model overcomes this shortcoming by specifying the loop structures explicitly in a hierarchical fashion. We introduce a scheduling technique of an application represented by the SDF/L model onto heterogeneous processors. In the proposed method, we explore the mapping of tasks using an evolutionary meta-heuristic and schedule hierarchically in a bottom-up fashion, creating parallel loop schedules at lower levels first and then re-using them when constructing the schedule at a higher level. The efficiency of the proposed scheduling methodology is verified with benchmark examples and randomly generated SDF/L graphs.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3217660409",
    "type": "article"
  },
  {
    "title": "A fast algorithm for minimizing FPGA combinational and sequential modules",
    "doi": "https://doi.org/10.1145/234860.234863",
    "publication_date": "1996-07-01",
    "publication_year": 1996,
    "authors": "Dimitrios Kagaris; Spyros Tragoudas",
    "corresponding_authors": "",
    "abstract": "We present a quadratic-time algorithm for minimizing the number of modules in an FPGA with combinational and sequential modules (like the C-modules and S-modules of the ACT2 and ACT3 architectures). The constraint is that a combinational module can be combined with one flip-flop in a single sequential module, only if the combinational module drives no other combinational modules. Our algorithm uses a minimum-cost flow formulation to solve the problem with a significant time improvement over a previous approach that used a general linear program.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2047202406",
    "type": "article"
  }
]
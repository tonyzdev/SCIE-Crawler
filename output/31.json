[
  {
    "title": "The DLV system for knowledge representation and reasoning",
    "doi": "https://doi.org/10.1145/1149114.1149117",
    "publication_date": "2006-07-01",
    "publication_year": 2006,
    "authors": "Nicola Leone; Gerald Pfeifer; Wolfgang Faber; Thomas Eiter; Georg Gottlob; Simona Perri; Francesco Scarcello",
    "corresponding_authors": "",
    "abstract": "Disjunctive Logic Programming (DLP) is an advanced formalism for knowledge representation and reasoning, which is very expressive in a precise mathematical sense: it allows one to express every property of finite structures that is decidable in the complexity class Σ P 2 (NP NP ). Thus, under widely believed assumptions, DLP is strictly more expressive than normal ( disjunction-free ) logic programming, whose expressiveness is limited to properties decidable in NP. Importantly, apart from enlarging the class of applications which can be encoded in the language, disjunction often allows for representing problems of lower complexity in a simpler and more natural fashion.This article presents the DLV system, which is widely considered the state-of-the-art implementation of disjunctive logic programming, and addresses several aspects. As for problem solving, we provide a formal definition of its kernel language, function-free disjunctive logic programs (also known as disjunctive datalog ), extended by weak constraints, which are a powerful tool to express optimization problems. We then illustrate the usage of DLV as a tool for knowledge representation and reasoning, describing a new declarative programming methodology which allows one to encode complex problems (up to Δ P 3 -complete problems) in a declarative fashion. On the foundational side, we provide a detailed analysis of the computational complexity of the language of DLV, and by deriving new complexity results we chart a complete picture of the complexity of this language and important fragments thereof.Furthermore, we illustrate the general architecture of the DLV system, which has been influenced by these results. As for applications, we overview application front-ends which have been developed on top of DLV to solve specific knowledge representation tasks, and we briefly describe the main international projects investigating the potential of the system for industrial exploitation. Finally, we report about thorough experimentation and benchmarking, which has been carried out to assess the efficiency of the system. The experimental results confirm the solidity of DLV and highlight its potential for emerging application areas like knowledge management and information integration.",
    "cited_by_count": 1187,
    "openalex_id": "https://openalex.org/W1976055110",
    "type": "article"
  },
  {
    "title": "Strongly equivalent logic programs",
    "doi": "https://doi.org/10.1145/383779.383783",
    "publication_date": "2001-10-01",
    "publication_year": 2001,
    "authors": "Vladimir Lifschitz; David Pearce; Agustín Valverde",
    "corresponding_authors": "",
    "abstract": "A logic program Π 1 is said to be equivalent to a logic program Π 2 in the sense of the answer set semantics if Π 1 and Π 2 have the same answer sets. We are interested in the following stronger condition: for every logic program, Π, Π 1 , ∪ Π has the same answer sets as Π 2 ∪ Π. The study of strong equivalence is important, because we learn from it how one can simplify a part of a logic program without looking at the rest of it. The main theorem shows that the verification of strong equivalence can be accomplished by cheching the equivalence of formulas in a monotonic logic, called the logic of here-and-there, which is intermediate between classical logic and intuitionistic logic.",
    "cited_by_count": 543,
    "openalex_id": "https://openalex.org/W1985274317",
    "type": "article"
  },
  {
    "title": "Sequential abstract-state machines capture sequential algorithms",
    "doi": "https://doi.org/10.1145/343369.343384",
    "publication_date": "2000-07-01",
    "publication_year": 2000,
    "authors": "Yuri Gurevich",
    "corresponding_authors": "Yuri Gurevich",
    "abstract": "We examine sequential algorithms and formulate a sequential-time postulate, an abstract-state postulate, and a bounded-exploration postulate . Analysis of the postulates leads us to the notion of sequential abstract-state machine and to the theorem in the title. First we treat sequential algorithms that are deterministic and noninteractive. Then we consider sequential algorithms that may be nondeterministic and that may interact with their environments.",
    "cited_by_count": 463,
    "openalex_id": "https://openalex.org/W1998333922",
    "type": "article"
  },
  {
    "title": "Model-checking continuous-time Markov chains",
    "doi": "https://doi.org/10.1145/343369.343402",
    "publication_date": "2000-07-01",
    "publication_year": 2000,
    "authors": "Adnan Aziz; Kumud Sanwal; Vigyan Singhal; Robert K. Brayton",
    "corresponding_authors": "",
    "abstract": "We present a logical formalism for expressing properties of continuous-time Markov chains. The semantics for such properties arise as a natural extension of previous work on discrete-time Markov chains to continuous time. The major result is that the verification problem is decidable; this is shown using results in algebraic and transcendental number theory.",
    "cited_by_count": 422,
    "openalex_id": "https://openalex.org/W2041226400",
    "type": "article"
  },
  {
    "title": "Representation results for defeasible logic",
    "doi": "https://doi.org/10.1145/371316.371517",
    "publication_date": "2001-04-01",
    "publication_year": 2001,
    "authors": "Grigoris Antoniou; David P. Billington; Guido Governatori; Michael J. Maher",
    "corresponding_authors": "",
    "abstract": "The importance of transformations and normal forms in logic programming, and generally in computer science, is well documented. This paper investigates transformations and normal forms in the context of Defeasible Logic, a simple but efficient formalism for nonmonotonic reasoning based on rules and priorities. The transformations described in this paper have two main benefits: on one hand they can be used as a theoretical tool that leads to a deeper understanding of the formalism, and on the other hand they have been used in the development of an efficient implementation of defeasible logic.",
    "cited_by_count": 374,
    "openalex_id": "https://openalex.org/W2098791425",
    "type": "article"
  },
  {
    "title": "Finite state machines for strings over infinite alphabets",
    "doi": "https://doi.org/10.1145/1013560.1013562",
    "publication_date": "2004-07-01",
    "publication_year": 2004,
    "authors": "Frank Neven; Thomas Schwentick; Victor Vianu",
    "corresponding_authors": "",
    "abstract": "Motivated by formal models recently proposed in the context of XML, we study automata and logics on strings over infinite alphabets. These are conservative extensions of classical automata and logics defining the regular languages on finite alphabets. Specifically, we consider register and pebble automata, and extensions of first-order logic and monadic second-order logic. For each type of automaton we consider one-way and two-way variants, as well as deterministic, nondeterministic, and alternating control. We investigate the expressiveness and complexity of the automata and their connection to the logics, as well as standard decision problems. Some of our results answer open questions of Kaminski and Francez on register automata.",
    "cited_by_count": 270,
    "openalex_id": "https://openalex.org/W2056665285",
    "type": "article"
  },
  {
    "title": "LTL with the freeze quantifier and register automata",
    "doi": "https://doi.org/10.1145/1507244.1507246",
    "publication_date": "2009-04-01",
    "publication_year": 2009,
    "authors": "Stéphane Demri; Ranko Lazić",
    "corresponding_authors": "",
    "abstract": "A data word is a sequence of pairs of a letter from a finite alphabet and an element from an infinite set, where the latter can only be compared for equality. To reason about data words, linear temporal logic is extended by the freeze quantifier, which stores the element at the current word position into a register, for equality comparisons deeper in the formula. By translations from the logic to alternating automata with registers and then to faulty counter automata whose counters may erroneously increase at any time, and from faulty and error-free counter automata to the logic, we obtain a complete complexity table for logical fragments defined by varying the set of temporal operators and the number of registers. In particular, the logic with future-time operators and 1 register is decidable but not primitive recursive over finite data words. Adding past-time operators or 1 more register, or switching to infinite data words, causes undecidability.",
    "cited_by_count": 257,
    "openalex_id": "https://openalex.org/W2177814128",
    "type": "article"
  },
  {
    "title": "Contextual modal type theory",
    "doi": "https://doi.org/10.1145/1352582.1352591",
    "publication_date": "2008-06-01",
    "publication_year": 2008,
    "authors": "Aleksandar Nanevski; Frank Pfenning; Brigitte Pientka",
    "corresponding_authors": "",
    "abstract": "The intuitionistic modal logic of necessity is based on the judgmental notion of categorical truth. In this article we investigate the consequences of relativizing these concepts to explicitly specified contexts. We obtain contextual modal logic and its type-theoretic analogue. Contextual modal type theory provides an elegant, uniform foundation for understanding metavariables and explicit substitutions. We sketch some applications in functional programming and logical frameworks.",
    "cited_by_count": 255,
    "openalex_id": "https://openalex.org/W1990204174",
    "type": "article"
  },
  {
    "title": "Description logics of minimal knowledge and negation as failure",
    "doi": "https://doi.org/10.1145/505372.505373",
    "publication_date": "2002-04-01",
    "publication_year": 2002,
    "authors": "Francesco M. Donini; Daniele Nardi; Riccardo Rosati",
    "corresponding_authors": "",
    "abstract": "We present description logics of minimal knowledge and negation as failure (MKNF-DLs), which augment description logics with modal operators interpreted according to Lifschitz's nonmonotonic logic MKNF. We show the usefulness of MKNF-DLs for a formal characterization of a wide variety of nonmonotonic features that are both commonly available inframe-based systems, and needed in the development of practical knowledge-based applications: defaults, integrity constraints, role, and concept closure. In addition, we provide a correct and terminating calculus for query answering in a very expressive MKNF-DL.",
    "cited_by_count": 255,
    "openalex_id": "https://openalex.org/W2059360847",
    "type": "article"
  },
  {
    "title": "Weak alternating automata are not that weak",
    "doi": "https://doi.org/10.1145/377978.377993",
    "publication_date": "2001-07-01",
    "publication_year": 2001,
    "authors": "Orna Kupferman; Moshe Y. Vardi",
    "corresponding_authors": "",
    "abstract": "Automata on infinite words are used for specification and verification of nonterminating programs. Different types of automata induce different levels of expressive power, of succinctness, and of complexity. Alternating automata have both existential and universal branching modes and are particularly suitable for specification of programs. In a weak alternating automata the state space is partitioned into partially ordered sets, and the automaton can proceed from a certain set only to smaller sets. Reasoning about weak alternating automata is easier than reasoning about alternating automata with no restricted structure. Known translations of alternating automata to weak alternating automata involve determinization, and therefore involve a double-exponential blow-up. In this paper we describe a quadratic translation, which circumvents the need for determinization, of Büchi and co-Büchi alternating automata to weak alternating automata. Beyond the independent interest of such a translation, it gives rise to a simple complementation algorithm for nondeterministic Büchi automata.",
    "cited_by_count": 224,
    "openalex_id": "https://openalex.org/W2059045337",
    "type": "article"
  },
  {
    "title": "Specifying norm-governed computational societies",
    "doi": "https://doi.org/10.1145/1459010.1459011",
    "publication_date": "2009-01-01",
    "publication_year": 2009,
    "authors": "Alexander Artikis; Marek Sergot; Jeremy Pitt",
    "corresponding_authors": "",
    "abstract": "Electronic markets, dispute resolution and negotiation protocols are three types of application domains that can be viewed as open agent societies. Key characteristics of such societies are agent heterogeneity, conflicting individual goals and unpredictable behavior. Members of such societies may fail to, or even choose not to, conform to the norms governing their interactions. It has been argued that systems of this type should have a formal, declarative, verifiable, and meaningful semantics. We present a theoretical and computational framework being developed for the executable specification of open agent societies. We adopt an external perspective and view societies as instances of normative systems. In this article, we demonstrate how the framework can be applied to specifying and executing a contract-net protocol. The specification is formalized in two action languages, the C + language and the Event Calculus, and executed using respective software implementations, the Causal Calculator and the Society Visualizer. We evaluate our executable specification in the light of the presented case study, discussing the strengths and weaknesses of the employed action languages for the specification of open agent societies.",
    "cited_by_count": 219,
    "openalex_id": "https://openalex.org/W2171687149",
    "type": "article"
  },
  {
    "title": "A system of interaction and structure",
    "doi": "https://doi.org/10.1145/1182613.1182614",
    "publication_date": "2007-01-01",
    "publication_year": 2007,
    "authors": "Alessio Guglielmi",
    "corresponding_authors": "Alessio Guglielmi",
    "abstract": "This article introduces a logical system, called BV, which extends multiplicative linear logic by a noncommutative self-dual logical operator. This extension is particularly challenging for the sequent calculus, and so far, it is not achieved therein. It becomes very natural in a new formalism, called the calculus of structures , which is the main contribution of this work. Structures are formulas subject to certain equational laws typical of sequents. The calculus of structures is obtained by generalizing the sequent calculus in such a way that a new top-down symmetry of derivations is observed, and it employs inference rules that rewrite inside structures at any depth. These properties, in addition to allowing the design of BV, yield a modular proof of cut elimination.",
    "cited_by_count": 218,
    "openalex_id": "https://openalex.org/W2102625227",
    "type": "article"
  },
  {
    "title": "Reasoning About Strategies",
    "doi": "https://doi.org/10.1145/2631917",
    "publication_date": "2014-08-01",
    "publication_year": 2014,
    "authors": "Fabio Mogavero; Aniello Murano; Giuseppe Perelli; Moshe Y. Vardi",
    "corresponding_authors": "",
    "abstract": "In open systems verification, to formally check for reliability, one needs an appropriate formalism to model the interaction between agents and express the correctness of the system no matter how the environment behaves. An important contribution in this context is given by modal logics for strategic ability, in the setting of multiagent games, such as A tl , A tl *, and the like. Recently, Chatterjee, Henzinger, and Piterman introduced Strategy Logic , which we denote here by CHP-S l , with the aim of getting a powerful framework for reasoning explicitly about strategies. CHP-S l is obtained by using first-order quantifications over strategies and has been investigated in the very specific setting of two-agents turned-based games, where a nonelementary model-checking algorithm has been provided. While CHP-S l is a very expressive logic, we claim that it does not fully capture the strategic aspects of multiagent systems. In this article, we introduce and study a more general strategy logic, denoted S l , for reasoning about strategies in multiagent concurrent games. As a key aspect, strategies in S l are not intrinsically glued to a specific agent, but an explicit binding operator allows an agent to bind to a strategy variable. This allows agents to share strategies or reuse one previously adopted. We prove that S l strictly includes CHP-S l , while maintaining a decidable model-checking problem. In particular, the algorithm we propose is computationally not harder than the best one known for CHP-S l . Moreover, we prove that such a problem for S l is N on E lementary . This negative result has spurred us to investigate syntactic fragments of S l , strictly subsuming A tl *, with the hope of obtaining an elementary model-checking problem. Among others, we introduce and study the sublogics S l [ ng ], S l [ bg ], and S l [1 g ]. They encompass formulas in a special prenex normal form having, respectively, nested temporal goals, Boolean combinations of goals, and, a single goal at a time. Intuitively, for a goal, we mean a sequence of bindings, one for each agent, followed by an L tl formula. We prove that the model-checking problem for S l [1 g ] is 2E xp T ime - complete , thus not harder than the one for A tl *. In contrast, S l [ ng ] turns out to be N on E lementary -hard, strengthening the corresponding result for S l . Regarding S l [ bg ], we show that it includes CHP-S l and its model-checking is decidable with a 2E xp T ime lower-bound. It is worth enlightening that to achieve the positive results about S l [1 g ], we introduce a fundamental property of the semantics of this logic, called behavioral , which allows to strongly simplify the reasoning about strategies. Indeed, in a nonbehavioral logic such as S l [ bg ] and the subsuming ones, to satisfy a formula, one has to take into account that a move of an agent, at a given moment of a play, may depend on the moves taken by any agent in another counterfactual play.",
    "cited_by_count": 192,
    "openalex_id": "https://openalex.org/W2108947407",
    "type": "article"
  },
  {
    "title": "Kleene algebra with domain",
    "doi": "https://doi.org/10.1145/1183278.1183285",
    "publication_date": "2006-10-01",
    "publication_year": 2006,
    "authors": "Jules Desharnais; Bernhard Möller; Georg Struth",
    "corresponding_authors": "",
    "abstract": "We propose Kleene algebra with domain (KAD), an extension of Kleene algebra by simple equational axioms for a domain and a codomain operation. KAD considerably augments the expressiveness of Kleene algebra, in particular for the specification and analysis of programs and state transition systems. We develop the basic calculus, present the most interesting models and discuss some related theories. We demonstrate applicability by two examples: algebraic reconstructions of Noethericity and propositional Hoare logic based on equational reasoning.",
    "cited_by_count": 172,
    "openalex_id": "https://openalex.org/W2068047345",
    "type": "article"
  },
  {
    "title": "Quantitative languages",
    "doi": "https://doi.org/10.1145/1805950.1805953",
    "publication_date": "2010-07-01",
    "publication_year": 2010,
    "authors": "Krishnendu Chatterjee; Laurent Doyen; Thomas A. Henzinger",
    "corresponding_authors": "",
    "abstract": "Quantitative generalizations of classical languages, which assign to each word a real number instead of a Boolean value, have applications in modeling resource-constrained computation. We use weighted automata (finite automata with transition weights) to define several natural classes of quantitative languages over finite and infinite words; in particular, the real value of an infinite run is computed as the maximum, limsup, liminf, limit average, or discounted sum of the transition weights. We define the classical decision problems of automata theory (emptiness, universality, language inclusion, and language equivalence) in the quantitative setting and study their computational complexity. As the decidability of the language-inclusion problem remains open for some classes of weighted automata, we introduce a notion of quantitative simulation that is decidable and implies language inclusion. We also give a complete characterization of the expressive power of the various classes of weighted automata. In particular, we show that most classes of weighted automata cannot be determinized.",
    "cited_by_count": 169,
    "openalex_id": "https://openalex.org/W2294334272",
    "type": "article"
  },
  {
    "title": "Complexity of conservative constraint satisfaction problems",
    "doi": "https://doi.org/10.1145/1970398.1970400",
    "publication_date": "2011-07-01",
    "publication_year": 2011,
    "authors": "Andreĭ A. Bulatov",
    "corresponding_authors": "Andreĭ A. Bulatov",
    "abstract": "In a constraint satisfaction problem (CSP), the aim is to find an assignment of values to a given set of variables, subject to specified constraints. The CSP is known to be NP-complete in general. However, certain restrictions on the form of the allowed constraints can lead to problems solvable in polynomial time. Such restrictions are usually imposed by specifying a constraint language, that is, a set of relations that are allowed to be used as constraints. A principal research direction aims to distinguish those constraint languages that give rise to tractable CSPs from those that do not. We achieve this goal for the important version of the CSP, in which the set of values for each individual variable can be restricted arbitrarily. Restrictions of this type can be studied by considering those constraint languages which contain all possible unary constraints; we call such languages conservative . We completely characterize conservative constraint languages that give rise to polynomial time solvable CSP classes. In particular, this result allows us to obtain a complete description of those (directed) graphs H for which the List H -Coloring problem is solvable in polynomial time. The result, the solving algorithm, and the proofs heavily use the algebraic approach to CSP developed in Jeavons et al. [1997], Jeavons [1998], Bulatov et al. [2005], and Bulatov and Jeavons [2001b, 2003].",
    "cited_by_count": 166,
    "openalex_id": "https://openalex.org/W2032487621",
    "type": "article"
  },
  {
    "title": "Verifiable agent interaction in abductive logic programming",
    "doi": "https://doi.org/10.1145/1380572.1380578",
    "publication_date": "2008-08-01",
    "publication_year": 2008,
    "authors": "Marco Alberti; Federico Chesani; Marco Gavanelli; Evelina Lamma; Paola Mello; Paolo Torroni",
    "corresponding_authors": "",
    "abstract": "SCIFF is a framework thought to specify and verify interaction in open agent societies. The SCIFF language is equipped with a semantics based on abductive logic programming; SCIFF's operational component is a new abductive logic programming proof procedure, also named SCIFF, for reasoning with expectations in dynamic environments. In this article we present the declarative and operational semantics of the SCIFF language, and the termination, soundness, and completeness results of the SCIFF proof procedure, and we demonstrate SCIFF's possible application in the multiagent domain.",
    "cited_by_count": 156,
    "openalex_id": "https://openalex.org/W2162176451",
    "type": "article"
  },
  {
    "title": "Collapsible Pushdown Automata and Recursion Schemes",
    "doi": "https://doi.org/10.1109/lics.2008.34",
    "publication_date": "2008-06-01",
    "publication_year": 2008,
    "authors": "Matthew Hague; Andrzej S. Murawski; C.-H. Luke Ong; Olivier Serre",
    "corresponding_authors": "",
    "abstract": "Collapsible pushdown automata (CPDA) are a new kind of higher-order pushdown automata in which every symbol in the stack has a link to a stack situated somewhere below it. In addition to the higher-order push and pop operations, CPDA have an important operation called collapse, whose effect is to \"collapse\" a stack s to the prefix as indicated by the link from the topmost symbol of s. Our first result is that CPDA are equi-expressive with recursion schemes as generators of (possibly infinite) ranked trees. In one direction, we give a simple algorithm that transforms an order-n CPDA to an order-n recursion scheme that generates the same tree, uniformly for all n Gt= 0. In the other direction, using ideas from game semantics, we give an effective transformation of order-n recursion schemes (not assumed to be homogeneously typed, and hence not necessarily safe) to order-n CPDA that compute traversals over an abstract syntax graph of the scheme, and hence paths in the tree generated by the scheme. Our equi-expressivity result is the first automata-theoretic characterization of higher-order recursion schemes. Thus CPDA are also a characterization of the simply-typed lambda calculus with recursion (generated from uninterpreted 1st-order symbols) and of (pure) innocent strategies. An important consequence of the equi-expressivity result is that it allows us to reduce decision problems on trees generated by recursion schemes to equivalent problems on CPDA and vice versa. Thus we show, as a consequence of a recent result by Ong (modal mu-calculus model-checking of trees generated by recursion schemes is n-EXPTIME complete), that the problem of solving parity games over the configuration graphs of order-n CPDA is n-EXPTIME complete, subsuming several well-known results about the solvability of games over higher-order pushdown graphs by (respectively) Walukiewicz, Cachat, and Knapik et al. Another contribution of our work is a self-contained proof of the same solvability result by generalizing standard techniques in the field. By appealing to our equi-expressivity result, we obtain a new proof of Ong's result. In contrast to higher-order pushdown graphs, we show that the monadic second-order theories of the configuration graphs of CPDA are undecidable. It follows that -- as generators of graphs -- CPDA are strictly more expressive than higher-order pushdown automata.",
    "cited_by_count": 152,
    "openalex_id": "https://openalex.org/W2102644483",
    "type": "article"
  },
  {
    "title": "Two-variable logic on data words",
    "doi": "https://doi.org/10.1145/1970398.1970403",
    "publication_date": "2011-07-01",
    "publication_year": 2011,
    "authors": "Mikołaj Bojańczyk; Claire David; Anca Muscholl; Thomas Schwentick; Luc Segoufin",
    "corresponding_authors": "",
    "abstract": "In a data word each position carries a label from a finite alphabet and a data value from some infinite domain. This model has been already considered in the realm of semistructured data, timed automata, and extended temporal logics. This article shows that satisfiability for the two-variable fragment FO 2 (∼,&lt;,+1) of first-order logic with data equality test ∼ is decidable over finite and infinite data words. Here +1 and &lt; are the usual successor and order predicates, respectively. The satisfiability problem is shown to be at least as hard as reachability in Petri nets. Several extensions of the logic are considered; some remain decidable while some are undecidable.",
    "cited_by_count": 147,
    "openalex_id": "https://openalex.org/W2073614038",
    "type": "article"
  },
  {
    "title": "Clausal temporal resolution",
    "doi": "https://doi.org/10.1145/371282.371311",
    "publication_date": "2001-01-01",
    "publication_year": 2001,
    "authors": "Michael Fisher; Clare Dixon; Martin Peim",
    "corresponding_authors": "",
    "abstract": "In this article, we examine how clausal resolution can be applied to a specific, but widely used, nonclassical logic, namely discrete linear temporal logic. Thus, we first define a normal form for temporal formulae and show how arbitrary temporal formulae can be translated into the normal form, while preserving satisfiability. We then introduce novel resolution rules that can be applied to formulae in this normal form, provide a range of examples, and examine the correctness and complexity of this approach. Finally, we describe related work and future developments concerning this work.",
    "cited_by_count": 177,
    "openalex_id": "https://openalex.org/W2131225255",
    "type": "article"
  },
  {
    "title": "Abstract state machines capture parallel algorithms",
    "doi": "https://doi.org/10.1145/937555.937561",
    "publication_date": "2003-10-01",
    "publication_year": 2003,
    "authors": "Andreas Blass; Yuri Gurevich",
    "corresponding_authors": "",
    "abstract": "We give an axiomatic description of parallel, synchronous algorithms. Our main result is that every such algorithm can be simulated, step for step, by an abstract state machine with a background that provides for multisets.",
    "cited_by_count": 167,
    "openalex_id": "https://openalex.org/W2125522861",
    "type": "article"
  },
  {
    "title": "A proof theory for generic judgments",
    "doi": "https://doi.org/10.1145/1094622.1094628",
    "publication_date": "2005-10-01",
    "publication_year": 2005,
    "authors": "Dale Miller; Alwen Tiu",
    "corresponding_authors": "",
    "abstract": "The operational semantics of a computation system is often presented as inference rules or, equivalently, as logical theories. Specifications can be made more declarative and high level if syntactic details concerning bound variables and substitutions are encoded directly into the logic using term-level abstractions (λ-abstraction) and proof-level abstractions (eigenvariables). When one wishes to use such logical theories to support reasoning about properties of computation, the usual quantifiers and proof-level abstractions do not seem adequate: proof-level abstraction of variables with scope over sequents ( global scope) as well as over only formulas ( local scope) seem required for many examples. We will present a sequent calculus that provides this local notion of proof-level abstraction via generic judgment and a new quantifier, ∇, which explicitly manipulates such local scope. Intuitionistic logic extended with ∇ satisfies cut-elimination even when the logic is additionally strengthened with a proof theoretic notion of definitions. The resulting logic can be used to encode naturally a number of examples involving abstractions, and we illustrate the uses of ∇ with the π-calculus and an encoding of provability of an object-logic.",
    "cited_by_count": 160,
    "openalex_id": "https://openalex.org/W2032234226",
    "type": "article"
  },
  {
    "title": "MSO definable string transductions and two-way finite-state transducers",
    "doi": "https://doi.org/10.1145/371316.371512",
    "publication_date": "2001-04-01",
    "publication_year": 2001,
    "authors": "Joost Engelfriet; Hendrik Jan Hoogeboom",
    "corresponding_authors": "",
    "abstract": "We extend a classic result of Büchi, Elgot, and Trakhtenbrot: MSO definable string transductions i.e., string-to-string functions that are definable by an interpretation using monadic second-order (MSO) logic, are exactly those realized by deterministic two-way finite-state transducers, i.e., finite-state automata with a two-way input tape and a one-way output tape. Consequently, the equivalence of two mso definable string transductions is decidable. In the nondeterministic case however, MSO definable string tranductions, i.e., binary relations on strings that are mso definable by an interpretation with parameters, are incomparable to those realized by nondeterministic two-way finite-state transducers. This is a motivation to look for another machine model, and we show that both classes of MSO definable string transductions are characterized in terms of Hennie machines, i.e., two-way finite-state transducers that are allowed to rewrite their input tape, but may visit each position of their input only a bounded number of times.",
    "cited_by_count": 157,
    "openalex_id": "https://openalex.org/W2106181999",
    "type": "article"
  },
  {
    "title": "On Hoare logic and Kleene algebra with tests",
    "doi": "https://doi.org/10.1145/343369.343378",
    "publication_date": "2000-07-01",
    "publication_year": 2000,
    "authors": "Dexter Kozen",
    "corresponding_authors": "Dexter Kozen",
    "abstract": "We show that Kleene algebra with tests (KAT) subsumes propositional Hoare logic (PHL). Thus the specialized syntax and deductive apparatus of Hoare logic are inessential and can be replaced by simple equational reasoning. In addition, we show that all relationally valid inference rules are derivable in KAT and that deciding the relational validity of such rules is PSPACE -complete.",
    "cited_by_count": 156,
    "openalex_id": "https://openalex.org/W2010626618",
    "type": "article"
  },
  {
    "title": "Processor verification using efficient reductions of the logic of uninterpreted functions to propositional logic",
    "doi": "https://doi.org/10.1145/371282.371364",
    "publication_date": "2001-01-01",
    "publication_year": 2001,
    "authors": "Randal E. Bryant; Steven M. German; Miroslav N. Velev",
    "corresponding_authors": "",
    "abstract": "The logic of Equality with Uninterpreted Functions (EUF) provides a means of abstracting the manipulation of data by a processor when verifying the correctness of its control logic. By reducing formulas in this logic to propositional formulas, we can apply Boolean methods such as ordered Binary Decision Diagrams (BDDs) and Boolean satisfiability checkers to perform the verification. We can exploit characteristics of the formulas describing the verification conditions to greatly simplfy the propostional formulas generated. We identify a class of terms we call “p-terms” for which equality comparisons can only be used in monotonically positive formulas. By applying suitable abstractions to the hardware model, we can express the functionality of data values and instruction addresses flowing through an instruction pipeline with p-terms. A decision procedure can exploit the restricted uses of p-terms by considering only “maximally diverse” interpretations of the associated function symbols, where every function application yields a different value execept when constrainted by functional consistency. We present two methods to translate formulas in EUF into propositional logic. The first interprets the formula over a domain of fixed-length bit vectors and uses vectors of propositional variables to encode domain variables. The second generates formulas encoding the conditions under which pairs of terms have equal valuations, introducing propostional variables to encode the equality relations between pairs of terms. Both of these approaches can exploit maximal diversity to greatly reduce the number of propositional variables that need to be introduced and to reduce the overall formula sizes. We present experimental results demonstrating the efficiency of this approach when verifying pipelined processors using the method proposed by Burch and Dill. Exploiting positive equality allows us to overcome the experimental blow-up experienced previously when verifying microprocessors with load, store, and branch instructions.",
    "cited_by_count": 156,
    "openalex_id": "https://openalex.org/W2118154221",
    "type": "article"
  },
  {
    "title": "Unfolding partiality and disjunctions in stable model semantics",
    "doi": "https://doi.org/10.1145/1119439.1119440",
    "publication_date": "2006-01-01",
    "publication_year": 2006,
    "authors": "Tomi Janhunen; Ilkka Niemelä; Dietmar Seipel; Patrik Simons; Jia-Huai You",
    "corresponding_authors": "",
    "abstract": "This article studies an implementation methodology for partial and disjunctive stable models where partiality and disjunctions are unfolded from a logic program so that an implementation of stable models for normal (disjunction-free) programs can be used as the core inference engine. The unfolding is done in two separate steps. First, it is shown that partial stable models can be captured by total stable models using a simple linear and modular program transformation. Hence, reasoning tasks concerning partial stable models can be solved using an implementation of total stable models. Disjunctive partial stable models have been lacking implementations which now become available as the translation handles also the disjunctive case. Second, it is shown how total stable models of disjunctive programs can be determined by computing stable models for normal programs. Thus an implementation of stable models of normal programs can be used as a core engine for implementing disjunctive programs. The feasibility of the approach is demonstrated by constructing a system for computing stable models of disjunctive programs using the SMODELS system as the core engine. The performance of the resulting system is compared to that of DLV, which is a state-of-the-art system for disjunctive programs.",
    "cited_by_count": 140,
    "openalex_id": "https://openalex.org/W2056850725",
    "type": "article"
  },
  {
    "title": "Why are there so many loop formulas?",
    "doi": "https://doi.org/10.1145/1131313.1131316",
    "publication_date": "2006-04-01",
    "publication_year": 2006,
    "authors": "Vladimir Lifschitz; Alexander Razborov",
    "corresponding_authors": "",
    "abstract": "A theorem by Lin and Zhao shows how to turn any nondisjunctive logic program, understood in accordance with the answer set semantics, into an equivalent set of propositional formulas. The set of formulas generated by this process can be significantly larger than the original program. In this article we show (assuming P ⊈ NC 1 / poly , a conjecture from the theory of computational complexity that is widely believed to be true) that this is inevitable: any equivalent translation from logic programs to propositional formulas involves a significant increase in size.",
    "cited_by_count": 140,
    "openalex_id": "https://openalex.org/W2079430756",
    "type": "article"
  },
  {
    "title": "Deterministic generators and games for Ltl fragments",
    "doi": "https://doi.org/10.1145/963927.963928",
    "publication_date": "2004-01-01",
    "publication_year": 2004,
    "authors": "Rajeev Alur; Salvatore La Torre",
    "corresponding_authors": "",
    "abstract": "Deciding infinite two-player games on finite graphs with the winning condition specified by a linear temporal logic (Ltl) formula, is known to be 2Exptime-complete. In this paper, we identify Ltl fragments of lower complexity. Solving Ltl games typically involves a doubly exponential translation from Ltl formulas to deterministic ω-automata. First, we show that the longest distance (length of the longest simple path) of the generator is also an important parameter, by giving an O ( d log n )-space procedure to solve a Büchi game on a graph with n vertices and longest distance d . Then, for the Ltl fragment of the Boolean combinations of formulas obtained only by eventualities and conjunctions, we provide a translation to deterministic generators of exponential size and linear longest distance, show both of these bounds to be optimal, and prove the corresponding games to be Pspace-complete. Introducing next modalities in this fragment, we give a translation to deterministic generators still of exponential size but also with exponential longest distance, show both of these bounds to be optimal, and prove the corresponding games to be Exptime-complete. For the fragment resulting by further adding disjunctions, we provide a translation to deterministic generators of doubly exponential size and exponential longest distance, show both of these bounds to be optimal, and prove the corresponding games to be Expspace. We also show tightness of the double exponential bound on the size as well as the longest distance for deterministic generators of Ltl formulas without next and until modalities. Finally, we identify a class of deterministic Büchi automata corresponding to a fragment of Ltl with restricted use of always and until modalities, for which deciding games is Pspace-complete.",
    "cited_by_count": 136,
    "openalex_id": "https://openalex.org/W2178626170",
    "type": "article"
  },
  {
    "title": "A game-based framework for CTL counterexamples and 3-valued abstraction-refinement",
    "doi": "https://doi.org/10.1145/1297658.1297659",
    "publication_date": "2007-12-01",
    "publication_year": 2007,
    "authors": "Sharon Shoham; Orna Grümberg",
    "corresponding_authors": "",
    "abstract": "This work exploits and extends the game-based framework of CTL model checking for counterexample and incremental abstraction-refinement. We define a game-based CTL model checking for abstract models over the 3-valued semantics, which can be used for verification as well as refutation. The model checking process of an abstract model may end with an indefinite result, in which case we suggest a new notion of refinement, which eliminates indefinite results of the model checking. This provides an iterative abstraction-refinement framework. This framework is enhanced by an incremental algorithm, where refinement is applied only where indefinite results exist and definite results from prior iterations are used within the model checking algorithm. We also define the notion of annotated counterexamples , which are sufficient and minimal counterexamples for full CTL. We present an algorithm that uses the game board of the model checking game to derive an annotated counterexample in case the examined system model refutes the checked formula.",
    "cited_by_count": 135,
    "openalex_id": "https://openalex.org/W1998779352",
    "type": "article"
  },
  {
    "title": "A logic of nonmonotone inductive definitions",
    "doi": "https://doi.org/10.1145/1342991.1342998",
    "publication_date": "2008-03-01",
    "publication_year": 2008,
    "authors": "Marc Denecker; Eugenia Ternovska",
    "corresponding_authors": "",
    "abstract": "Well-known principles of induction include monotone induction and different sorts of nonmonotone induction such as inflationary induction, induction over well-founded sets and iterated induction. In this work, we define a logic formalizing induction over well-founded sets and monotone and iterated induction. Just as the principle of positive induction has been formalized in FO(LFP), and the principle of inflationary induction has been formalized in FO(IFP), this article formalizes the principle of iterated induction in a new logic for Nonmonotone Inductive Definitions (ID-logic). The semantics of the logic is strongly influenced by the well-founded semantics of logic programming. This article discusses the formalisation of different forms of (non-)monotone induction by the well-founded semantics and illustrates the use of the logic for formalizing mathematical and common-sense knowledge. To model different types of induction found in mathematics, we define several subclasses of definitions, and show that they are correctly formalized by the well-founded semantics. We also present translations into classical first or second order logic. We develop modularity and totality results and demonstrate their use to analyze and simplify complex definitions. We illustrate the use of the logic for temporal reasoning. The logic formally extends Logic Programming, Abductive Logic Programming and Datalog, and thus formalizes the view on these formalisms as logics of (generalized) inductive definitions.",
    "cited_by_count": 112,
    "openalex_id": "https://openalex.org/W2042629502",
    "type": "article"
  },
  {
    "title": "Finitary winning in ω-regular games",
    "doi": "https://doi.org/10.1145/1614431.1614432",
    "publication_date": "2009-10-01",
    "publication_year": 2009,
    "authors": "Krishnendu Chatterjee; Thomas A. Henzinger; Florian Horn",
    "corresponding_authors": "",
    "abstract": "Games on graphs with ω-regular objectives provide a model for the control and synthesis of reactive systems. Every ω-regular objective can be decomposed into a safety part and a liveness part. The liveness part ensures that something good happens “eventually.” Two main strengths of the classical, infinite-limit formulation of liveness are robustness (independence from the granularity of transitions) and simplicity (abstraction of complicated time bounds). However, the classical liveness formulation suffers from the drawback that the time until something good happens may be unbounded. A stronger formulation of liveness, so-called finitary liveness, overcomes this drawback, while still retaining robustness and simplicity. Finitary liveness requires that there exists an unknown, fixed bound b such that something good happens within b transitions. While for one-shot liveness (reachability) objectives, classical and finitary liveness coincide, for repeated liveness (Büchi) objectives, the finitary formulation is strictly stronger. In this work we study games with finitary parity and Streett objectives. We prove the determinacy of these games, present algorithms for solving these games, and characterize the memory requirements of winning strategies. We show that finitary parity games can be solved in polynomial time, which is not known for infinitary parity games. For finitary Streett games, we give an EXPTIME algorithm and show that the problem is NP-hard. Our algorithms can be used, for example, for synthesizing controllers that do not let the response time of a system increase without bound.",
    "cited_by_count": 104,
    "openalex_id": "https://openalex.org/W2015287249",
    "type": "article"
  },
  {
    "title": "Conjunctive query containment and answering under description logic constraints",
    "doi": "https://doi.org/10.1145/1352582.1352590",
    "publication_date": "2008-06-01",
    "publication_year": 2008,
    "authors": "Diego Calvanese; Giuseppe De Giacomo; Maurizio Lenzerini",
    "corresponding_authors": "",
    "abstract": "Query containment and query answering are two important computational tasks in databases. While query answering amounts to computing the result of a query over a database, query containment is the problem of checking whether, for every database, the result of one query is a subset of the result of another query. In this article, we deal with unions of conjunctive queries, and we address query containment and query answering under description logic constraints. Every such constraint is essentially an inclusion dependency between concepts and relations, and their expressive power is due to the possibility of using complex expressions in the specification of the dependencies, for example, intersection and difference of relations, special forms of quantification, regular expressions over binary relations. These types of constraints capture a great variety of data models, including the relational, the entity-relationship, and the object-oriented model, all extended with various forms of constraints. They also capture the basic features of the ontology languages used in the context of the Semantic Web. We present the following results on both query containment and query answering. We provide a method for query containment under description logic constraints, thus showing that the problem is decidable, and analyze its computational complexity. We prove that query containment is undecidable in the case where we allow inequalities in the right-hand-side query, even for very simple constraints and queries. We show that query answering under description logic constraints can be reduced to query containment, and illustrate how such a reduction provides upper-bound results with respect to both combined and data complexity.",
    "cited_by_count": 101,
    "openalex_id": "https://openalex.org/W2141591281",
    "type": "article"
  },
  {
    "title": "Annotated RDF",
    "doi": "https://doi.org/10.1145/1656242.1656245",
    "publication_date": "2010-01-01",
    "publication_year": 2010,
    "authors": "Octavian Udrea; Diego Reforgiato Recupero; V. S. Subrahmanian",
    "corresponding_authors": "",
    "abstract": "Real-world use of RDF requires the ability to transparently represent and explain metadata associated with RDF triples. For example, when RDF triples are extracted automatically by information extraction programs, there is a need to represent where the triples came from, what their temporal validity is, and how certain we are that the triple is correct. Today, there is no theoretically clean and practically scalable mechanism that spans these different needs - reification is the only solution propose to date, and its implementations have been ugly. In this paper, we present Annotated RDF (or aRDF for short) in which RDF triples are annotated by members of a partially ordered set (with bottom element) that can be selected in any way desired by the user. We present a formal declarative semantics (model theory) for annotated RDF and develop algorithms to check consistency of aRDF theories and to answer queries to aRDF theories. We show that annotated RDF supports users who need to think about the uncertainty, temporal aspects, and provenance of the RDF triples in an RDF database. We develop a prototype aRDF implementation and show that our algorithms work efficiently even on real world data sets containing over 10 million triples.",
    "cited_by_count": 99,
    "openalex_id": "https://openalex.org/W2295437155",
    "type": "article"
  },
  {
    "title": "A counterexample-guided abstraction-refinement framework for markov decision processes",
    "doi": "https://doi.org/10.1145/1838552.1838553",
    "publication_date": "2010-10-01",
    "publication_year": 2010,
    "authors": "Rohit Chadha; Mahesh Viswanathan",
    "corresponding_authors": "",
    "abstract": "The main challenge in using abstractions effectively is to construct a suitable abstraction for the system being verified. One approach that tries to address this problem is that of counterexample guided abstraction refinement (CEGAR) , wherein one starts with a coarse abstraction of the system, and progressively refines it, based on invalid counterexamples seen in prior model checking runs, until either an abstraction proves the correctness of the system or a valid counterexample is generated. While CEGAR has been successfully used in verifying nonprobabilistic systems automatically, CEGAR has only recently been investigated in the context of probabilistic systems. The main issues that need to be tackled in order to extend the approach to probabilistic systems is a suitable notion of “counterexample”, algorithms to generate counterexamples, check their validity, and then automatically refine an abstraction based on an invalid counterexample. In this article, we address these issues, and present a CEGAR framework for Markov decision processes.",
    "cited_by_count": 94,
    "openalex_id": "https://openalex.org/W2088501121",
    "type": "article"
  },
  {
    "title": "LTL over description logic axioms",
    "doi": "https://doi.org/10.1145/2287718.2287721",
    "publication_date": "2012-08-01",
    "publication_year": 2012,
    "authors": "Franz Baader; Silvio Ghilardi; Carsten Lutz",
    "corresponding_authors": "",
    "abstract": "Most of the research on temporalized Description Logics (DLs) has concentrated on the case where temporal operators can be applied to concepts, and sometimes additionally to TBox axioms and ABox assertions. The aim of this article is to study temporalized DLs where temporal operators on TBox axioms and ABox assertions are available, but temporal operators on concepts are not. While the main application of existing temporalized DLs is the representation of conceptual models that explicitly incorporate temporal aspects, the family of DLs studied in this article addresses applications that focus on the temporal evolution of data and of ontologies. Our results show that disallowing temporal operators on concepts can significantly decrease the complexity of reasoning. In particular, reasoning with rigid roles (whose interpretation does not change over time) is typically undecidable without such a syntactic restriction, whereas our logics are decidable in elementary time even in the presence of rigid roles. We analyze the effects on computational complexity of dropping rigid roles, dropping rigid concepts, replacing temporal TBoxes with global ones, and restricting the set of available temporal operators. In this way, we obtain a novel family of temporalized DLs whose complexity ranges from 2- ExpTime-complete via NExpTime-complete to ExpTime-complete.",
    "cited_by_count": 90,
    "openalex_id": "https://openalex.org/W2026807253",
    "type": "article"
  },
  {
    "title": "Least and Greatest Fixed Points in Linear Logic",
    "doi": "https://doi.org/10.1145/2071368.2071370",
    "publication_date": "2012-01-01",
    "publication_year": 2012,
    "authors": "David Baelde",
    "corresponding_authors": "David Baelde",
    "abstract": "The first-order theory of MALL (multiplicative, additive linear logic) over only equalities is a well-structured but weak logic since it cannot capture unbounded (infinite) behavior. Instead of accounting for unbounded behavior via the addition of the exponentials (! and ?), we add least and greatest fixed point operators. The resulting logic, which we call μ MALL, satisfies two fundamental proof theoretic properties: we establish weak normalization for it, and we design a focused proof system that we prove complete with respect to the initial system. That second result provides a strong normal form for cut-free proof structures that can be used, for example, to help automate proof search. We show how these foundations can be applied to intuitionistic logic.",
    "cited_by_count": 82,
    "openalex_id": "https://openalex.org/W2088881461",
    "type": "article"
  },
  {
    "title": "Topological and Simplicial Models of Identity Types",
    "doi": "https://doi.org/10.1145/2071368.2071371",
    "publication_date": "2012-01-01",
    "publication_year": 2012,
    "authors": "Benno van den Berg; Richard Garner",
    "corresponding_authors": "",
    "abstract": "In this paper we construct new categorical models for the identity types of Martin-Löf type theory, in the categories Top of topological spaces and SSet of simplicial sets. We do so building on earlier work of Awodey and Warren [2009], which has suggested that a suitable environment for the interpretation of identity types should be a category equipped with a weak factorization system in the sense of Bousfield--Quillen. It turns out that this is not quite enough for a sound model, due to some subtle coherence issues concerned with stability under substitution; and so our first task is to introduce a slightly richer structure, which we call a homotopy-theoretic model of identity types , and to prove that this is sufficient for a sound interpretation. Now, although both Top and SSet are categories endowed with a weak factorization system---and indeed, an entire Quillen model structure---exhibiting the additional structure required for a homotopy-theoretic model is quite hard to do. However, the categories we are interested in share a number of common features, and abstracting these leads us to introduce the notion of a path object category . This is a relatively simple axiomatic framework, which is nonetheless sufficiently strong to allow the construction of homotopy-theoretic models. Now by exhibiting suitable path object structures on Top and SSet , we endow those categories with the structure of a homotopy-theoretic model and, in this way, obtain the desired topological and simplicial models of identity types.",
    "cited_by_count": 81,
    "openalex_id": "https://openalex.org/W1997582403",
    "type": "article"
  },
  {
    "title": "Succinctness of the Complement and Intersection of Regular Expressions",
    "doi": "https://doi.org/10.1145/2071368.2071372",
    "publication_date": "2012-01-01",
    "publication_year": 2012,
    "authors": "Wouter Gelade; Frank Neven",
    "corresponding_authors": "",
    "abstract": "We study the succinctness of the complement and intersection of regular expressions. In particular, we show that when constructing a regular expression defining the complement of a given regular expression, a double exponential size increase cannot be avoided. Similarly, when constructing a regular expression defining the intersection of a fixed and an arbitrary number of regular expressions, an exponential and double exponential size increase, respectively, cannot be avoided. All mentioned lower bounds improve the existing ones by one exponential and are tight in the sense that the target expression can be constructed in the corresponding time class, that is, exponential or double exponential time. As a by-product, we generalize a theorem by Ehrenfeucht and Zeiger stating that there is a class of DFAs which are exponentially more succinct than regular expressions, to a fixed alphabet. When the given regular expressions are one-unambiguous, as for instance required by the XML Schema specification, the complement can be computed in polynomial time whereas the bounds concerning intersection continue to hold. For the subclass of single-occurrence regular expressions, we prove a tight exponential lower bound for intersection.",
    "cited_by_count": 78,
    "openalex_id": "https://openalex.org/W2082135413",
    "type": "article"
  },
  {
    "title": "Optimization Modulo Theories with Linear Rational Costs",
    "doi": "https://doi.org/10.1145/2699915",
    "publication_date": "2015-02-17",
    "publication_year": 2015,
    "authors": "Roberto Sebastiani; Silvia Tomasi",
    "corresponding_authors": "",
    "abstract": "In the contexts of automated reasoning (AR) and formal verification (FV), important decision problems are effectively encoded into Satisfiability Modulo Theories (SMT). In the last decade, efficient SMT solvers have been developed for several theories of practical interest (e.g., linear arithmetic, arrays, and bit vectors). Surprisingly, little work has been done to extend SMT to deal with optimization problems; in particular, we are not aware of any previous work on SMT solvers able to produce solutions that minimize cost functions over arithmetical variables. This is unfortunate, since some problems of interest require this functionality. In the work described in this article we start filling this gap. We present and discuss two general procedures for leveraging SMT to handle the minimization of linear rational cost functions, combining SMT with standard minimization techniques. We have implemented the procedures within the MathSAT SMT solver. Due to the absence of competitors in the AR, FV, and SMT domains, we have experimentally evaluated our implementation against state-of-the-art tools for the domain of Linear Generalized Disjunctive Programming (LGDP) , which is closest in spirit to our domain, on sets of problems that have been previously proposed as benchmarks for the latter tools. The results show that our tool is very competitive with, and often outperforms, these tools on these problems, clearly demonstrating the potential of the approach.",
    "cited_by_count": 77,
    "openalex_id": "https://openalex.org/W2090777457",
    "type": "article"
  },
  {
    "title": "Complexities of Horn Description Logics",
    "doi": "https://doi.org/10.1145/2422085.2422087",
    "publication_date": "2013-02-01",
    "publication_year": 2013,
    "authors": "Markus Krötzsch; Sebastian Rudolph; Pascal Hitzler",
    "corresponding_authors": "",
    "abstract": "Description logics (DLs) have become a prominent paradigm for representing knowledge in a variety of application areas, partly due to their ability to achieve a favourable balance between expressivity of the logic and performance of reasoning. Horn description logics are obtained, roughly speaking, by disallowing all forms of disjunctions. They have attracted attention since their (worst-case) data complexities are in general lower than those of their non-Horn counterparts, which makes them attractive for reasoning with large sets of instance data (ABoxes). It is therefore natural to ask whether Horn DLs also provide advantages for schema (TBox) reasoning, that is, whether they also feature lower combined complexities. This article settles this question for a variety of Horn DLs. An example of a tractable Horn logic is the DL underlying the ontology language OWL RL, which we characterize as the Horn fragment of the description logic SROIQ without existential quantifiers. If existential quantifiers are allowed, however, many Horn DLs become intractable. We find that Horn- ALC already has the same worst-case complexity as ALC , that is, ExpTime , but we also identify various DLs for which reasoning is PSpace -complete. As a side effect, we derive simplified syntactic definitions of Horn DLs for which we exploit suitable normal form transformations.",
    "cited_by_count": 75,
    "openalex_id": "https://openalex.org/W2064593774",
    "type": "article"
  },
  {
    "title": "On the Complexity of Probabilistic Abstract Argumentation Frameworks",
    "doi": "https://doi.org/10.1145/2749463",
    "publication_date": "2015-06-02",
    "publication_year": 2015,
    "authors": "Bettina Fazzinga; Sergio Flesca; Francesco Parisi",
    "corresponding_authors": "",
    "abstract": "Probabilistic abstract argumentation combines Dung’s abstract argumentation framework with probability theory in order to model uncertainty in argumentation. In this setting, we address the fundamental problem of computing the probability that a set of arguments is an extension according to a given semantics. We focus on the most popular semantics (i.e., admissible , stable , complete , grounded , preferred , ideal-set , ideal , stage , and semistable ) and show the following dichotomy result: computing the probability that a set of arguments is an extension is either FP or FP # P -complete depending on the semantics adopted. Our polynomial-time results are particularly interesting, as they hold for some semantics for which no polynomial-time technique was known so far.",
    "cited_by_count": 71,
    "openalex_id": "https://openalex.org/W2207251955",
    "type": "article"
  },
  {
    "title": "A Higher-Order Calculus of Computational Fields",
    "doi": "https://doi.org/10.1145/3285956",
    "publication_date": "2019-01-04",
    "publication_year": 2019,
    "authors": "Giorgio Audrito; Mirko Viroli; Ferruccio Damiani; Danilo Pianini; Jacob Beal",
    "corresponding_authors": "",
    "abstract": "The complexity of large-scale distributed systems, particularly when deployed in physical space, calls for new mechanisms to address composability and reusability of collective adaptive behaviour. Computational fields have been proposed as an effective abstraction to fill the gap between the macro-level of such systems (specifying a system’s collective behaviour) and the micro-level (individual devices’ actions of computation and interaction to implement that collective specification), thereby providing a basis to better facilitate the engineering of collective APIs and complex systems at higher levels of abstraction. This article proposes a full formal foundation for field computations, in terms of a core (higher-order) calculus of computational fields containing a few key syntactic constructs, and equipped with typing, denotational and operational semantics. Critically, this allows formal establishment of a link between the micro- and macro-levels of collective adaptive systems by a result of computational adequacy and abstraction for the (aggregate) denotational semantics with respect to the (per-device) operational semantics.",
    "cited_by_count": 69,
    "openalex_id": "https://openalex.org/W2541133209",
    "type": "article"
  },
  {
    "title": "Automated Verification of Equivalence Properties of Cryptographic Protocols",
    "doi": "https://doi.org/10.1145/2926715",
    "publication_date": "2016-09-20",
    "publication_year": 2016,
    "authors": "Rohit Chadha; Vincent Cheval; Ştefan Ciobâcă; Steve Kremer",
    "corresponding_authors": "",
    "abstract": "Indistinguishability properties are essential in formal verification of cryptographic protocols. They are needed to model anonymity properties, strong versions of confidentiality, and resistance against offline guessing attacks. Indistinguishability properties can be conveniently modeled as equivalence properties. We present a novel procedure to verify equivalence properties for a bounded number of sessions of cryptographic protocols. As in the applied pi calculus, our protocol specification language is parametrized by a first-order sorted term signature and an equational theory that allows formalization of algebraic properties of cryptographic primitives. Our procedure is able to verify trace equivalence for determinate cryptographic protocols. On determinate protocols, trace equivalence coincides with observational equivalence, which can therefore be automatically verified for such processes. When protocols are not determinate, our procedure can be used for both under- and over-approximations of trace equivalence, which proved successful on examples. The procedure can handle a large set of cryptographic primitives, namely those whose equational theory is generated by an optimally reducing convergent rewrite system. The procedure is based on a fully abstract modelling of the traces of a bounded number of sessions of the protocols into first-order Horn clauses on which a dedicated resolution procedure is used to decide equivalence properties. We have shown that our procedure terminates for the class of subterm convergent equational theories. Moreover, the procedure has been implemented in a prototype tool Active Knowledge in Security Protocols and has been effectively tested on examples. Some of the examples were outside the scope of existing tools, including checking anonymity of an electronic voting protocol due to Okamoto.",
    "cited_by_count": 67,
    "openalex_id": "https://openalex.org/W2521663436",
    "type": "article"
  },
  {
    "title": "A computational theory of normative positions",
    "doi": "https://doi.org/10.1145/383779.383786",
    "publication_date": "2001-10-01",
    "publication_year": 2001,
    "authors": "Marek Sergot",
    "corresponding_authors": "Marek Sergot",
    "abstract": "The Kanger-Lindahl theory of normative positions attempts to use a combination of deontic logic (the logic of obligation and permission) and a logic of action/agency to give a formal account of obligations, duties, rights, and other complex normative concepts. This paper presents a generalization and further development of this theory, together with methods for its automation and application to practical examples. The resulting theory is intended to be applied in the representation and analysis of laws, regulations, and contracts, in the specification of aspects of computer systems, in multiagent systems, and as a contribution to the formal theory of organizations. Particular attention is paid to representations at varying levels of detail and the relationships that hold between them. The last part presents Norman-G, an automated support system intended to facilitate application of the theory to the analysis of practical problems, with a small example to illustrate its use.",
    "cited_by_count": 118,
    "openalex_id": "https://openalex.org/W2089147999",
    "type": "article"
  },
  {
    "title": "The marriage of effects and monads",
    "doi": "https://doi.org/10.1145/601775.601776",
    "publication_date": "2003-01-01",
    "publication_year": 2003,
    "authors": "Philip Wadler; Peter Thiemann",
    "corresponding_authors": "",
    "abstract": "Gifford and others proposed an effect typing discipline to delimit the scope of computational effects within a program, while Moggi and others proposed monads for much the same purpose. Here we marry effects to monads, uniting two previously separate lines of research. In particular, we show that the type, region, and effect system of Talpin and Jouvelot carries over directly to an analogous system for monads, including a type and effect reconstruction algorithm. The same technique should allow one to transpose any effect system into a corresponding monad system.",
    "cited_by_count": 111,
    "openalex_id": "https://openalex.org/W2022518532",
    "type": "article"
  },
  {
    "title": "Probabilistic logic programming with conditional constraints",
    "doi": "https://doi.org/10.1145/377978.377983",
    "publication_date": "2001-07-01",
    "publication_year": 2001,
    "authors": "Thomas Lukasiewicz",
    "corresponding_authors": "Thomas Lukasiewicz",
    "abstract": "We introduce a new approach to probabilistic logic programming in which probabilities are defined over a set of possible worlds. More precisely, classical program clauses are extended by a subinterval of [0,1] that describes a range for the conditional probability of the head of a clause given its body. We then analyze the complexity of selected probabilistic logic programming tasks. It turns out that probabilistic logic programming is computationally more complex than classical logic programming, More precisely, the tractability of special cases of classical logic programming generally does not carry over to the corresponding special cases of probabilistic logic programming. Moreover, we also draw a precise picture of the complexity of deciding and computing tight logical consequences in probabilistic reasoning with conditional constraints in general. We then present linear optimization techniques for deciding satisfiability and computing tight logical consequencesof probabilistic logic programs. These techniques are efficient in the special case in which we have little relevant purely probabilistic knowledge. We finally show that probabilistic logic programming under certain syntactic and semantic restrictions is closely related to van Emden's quantitative deduction, and thus has computational properties similar to calssical logic programming. Based on this result, we present an efficient approximation technique for probabilistic logic programming.",
    "cited_by_count": 104,
    "openalex_id": "https://openalex.org/W2005277728",
    "type": "article"
  },
  {
    "title": "Intuitionistic Light Affine Logic",
    "doi": "https://doi.org/10.1145/504077.504081",
    "publication_date": "2002-01-01",
    "publication_year": 2002,
    "authors": "Andrea Asperti; Luca Roversi",
    "corresponding_authors": "",
    "abstract": "This article is a structured introduction to Intuitionistic Light Affine Logic ( ILAL ). ILAL has a polynomially costing normalization, and it is expressive enough to encode, and simulate, all PolyTime Turing machines. The bound on the normalization cost is proved by introducing the proof-nets for ILAL . The bound follows from a suitable normalization strategy that exploits structural properties of the proof-nets. This allows us to have a good understanding of the meaning of the § modality, which is a peculiarity of light logics. The expressive power of ILAL is demonstrated in full detail. Such a proof gives a hint of the nontrivial task of programming with resource limitations, using ILAL derivations as programs.",
    "cited_by_count": 104,
    "openalex_id": "https://openalex.org/W2133538984",
    "type": "article"
  },
  {
    "title": "A logic programming approach to knowledge-state planning",
    "doi": "https://doi.org/10.1145/976706.976708",
    "publication_date": "2004-04-01",
    "publication_year": 2004,
    "authors": "Thomas Eiter; Wolfgang Faber; Nicola Leone; Gerald Pfeifer; Axel Polleres",
    "corresponding_authors": "",
    "abstract": "We propose a new declarative planning language, called K, which is based on principles and methods of logic programming. In this language, transitions between states of knowledge can be described, rather than transitions between completely described states of the world, which makes the language well suited for planning under incomplete knowledge. Furthermore, our formalism enables the use of default principles in the planning process by supporting negation as failure. Nonetheless, K also supports the representation of transitions between states of the world (i.e., states of complete knowledge) as a special case, which shows that the language is very flexible. As we demonstrate on particular examples, the use of knowledge states may allow for a natural and compact problem representation. We then provide a thorough analysis of the computational complexity of K, and consider different planning problems, including standard planning and secure planning (also known as conformant planning ) problems. We show that these problems have different complexities under various restrictions, ranging from NP to NEXPTIME in the propositional case. Our results form the theoretical basis for the DLV k system, which implements the language K on top of the DLV logic programming system.",
    "cited_by_count": 101,
    "openalex_id": "https://openalex.org/W2105197521",
    "type": "article"
  },
  {
    "title": "On equivalence and canonical forms in the LF type theory",
    "doi": "https://doi.org/10.1145/1042038.1042041",
    "publication_date": "2005-01-01",
    "publication_year": 2005,
    "authors": "Robert Harper; Frank Pfenning",
    "corresponding_authors": "",
    "abstract": "Decidability of definitional equality and conversion of terms into canonical form play a central role in the meta-theory of a type-theoretic logical framework. Most studies of definitional equality are based on a confluent, strongly normalizing notion of reduction. Coquand has considered a different approach, directly proving the correctness of a practical equivalance algorithm based on the shape of terms. Neither approach appears to scale well to richer languages with, for example, unit types or subtyping, and neither provides a notion of canonical form suitable for proving adequacy of encodings.In this article, we present a new, type-directed equivalence algorithm for the LF type theory that overcomes the weaknesses of previous approaches. The algorithm is practical, scales to richer languages, and yields a new notion of canonical form sufficient for adequate encodings of logical systems. The algorithm is proved complete by a Kripke-style logical relations argument similar to that suggested by Coquand. Crucially, both the algorithm itself and the logical relations rely only on the shapes of types, ignoring dependencies on terms.",
    "cited_by_count": 96,
    "openalex_id": "https://openalex.org/W2043740265",
    "type": "article"
  },
  {
    "title": "New results on rewrite-based satisfiability procedures",
    "doi": "https://doi.org/10.1145/1459010.1459014",
    "publication_date": "2009-01-01",
    "publication_year": 2009,
    "authors": "Alessandro Armando; Maria Paola Bonacina; Silvio Ranise; Stephan Schulz",
    "corresponding_authors": "",
    "abstract": "Program analysis and verification require decision procedures to reason on theories of data structures. Many problems can be reduced to the satisfiability of sets of ground literals in theory T. If a sound and complete inference system for first-order logic is guaranteed to terminate on T-satisfiability problems, any theorem-proving strategy with that system and a fair search plan is a T-satisfiability procedure. We prove termination of a rewrite-based first-order engine on the theories of records, integer offsets, integer offsets modulo and lists. We give a modularity theorem stating sufficient conditions for termination on a combinations of theories, given termination on each. The above theories, as well as others, satisfy these conditions. We introduce several sets of benchmarks on these theories and their combinations, including both parametric synthetic benchmarks to test scalability, and real-world problems to test performances on huge sets of literals. We compare the rewrite-based theorem prover E with the validity checkers CVC and CVC Lite. Contrary to the folklore that a general-purpose prover cannot compete with reasoners with built-in theories, the experiments are overall favorable to the theorem prover, showing that not only the rewriting approach is elegant and conceptually simple, but has important practical implications.",
    "cited_by_count": 91,
    "openalex_id": "https://openalex.org/W2084417024",
    "type": "article"
  },
  {
    "title": "Semantical characterizations and complexity of equivalences in answer set programming",
    "doi": "https://doi.org/10.1145/1243996.1244000",
    "publication_date": "2007-07-01",
    "publication_year": 2007,
    "authors": "Thomas Eiter; Michael Fink; Stefan Woltran",
    "corresponding_authors": "",
    "abstract": "In recent research on nonmonotonic logic programming, repeatedly strong equivalence of logic programs P and Q has been considered, which holds if the programs P ∪ R and Q ∪ R have the same answer sets for any other program R . This property strengthens the equivalence of P and Q with respect to answer sets (which is the particular case for R =∅), and has its applications in program optimization, verification, and modular logic programming. In this article, we consider more liberal notions of strong equivalence, in which the actual form of R may be syntactically restricted. On the one hand, we consider uniform equivalence where R is a set of facts, rather than a set of rules. This notion, which is well-known in the area of deductive databases, is particularly useful for assessing whether programs P and Q are equivalent as components of a logic program which is modularly structured. On the other hand, we consider relativized notions of equivalence where R ranges over rules over a fixed alphabet, and thus generalize our results to relativized notions of strong and uniform equivalence. For all these notions, we consider disjunctive logic programs in the propositional (ground) case as well as some restricted classes, providing semantical characterizations and analyzing the computational complexity. Our results, which naturally extend to answer set semantics for programs with strong negation, complement the results on strong equivalence of logic programs and pave the way for optimizations in answer set solvers as a tool for input-based problem solving.",
    "cited_by_count": 90,
    "openalex_id": "https://openalex.org/W1971626643",
    "type": "article"
  },
  {
    "title": "Efficient solving of quantified inequality constraints over the real numbers",
    "doi": "https://doi.org/10.1145/1183278.1183282",
    "publication_date": "2006-10-01",
    "publication_year": 2006,
    "authors": "Stefan Ratschan",
    "corresponding_authors": "Stefan Ratschan",
    "abstract": "Let a quantified inequality constraint over the reals be a formula in the first-order predicate language over the structure of the real numbers, where the allowed predicate symbols are ≤ and &lt;. Solving such constraints is an undecidable problem when allowing function symbols such sin or cos. In this article, we give an algorithm that terminates with a solution for all, except for very special, pathological inputs. We ensure the practical efficiency of this algorithm by employing constraint programming techniques.",
    "cited_by_count": 89,
    "openalex_id": "https://openalex.org/W2092007705",
    "type": "article"
  },
  {
    "title": "First-order queries on structures of bounded degree are computable with constant delay",
    "doi": "https://doi.org/10.1145/1276920.1276923",
    "publication_date": "2007-08-01",
    "publication_year": 2007,
    "authors": "Arnaud Durand; Étienne Grandjean",
    "corresponding_authors": "",
    "abstract": "A relational structure is d -degree-bounded, for some integer d , if each element of the domain belongs to at most d tuples. In this paper, we revisit the complexity of the evaluation problem of not necessarily Boolean first-order ( FO ) queries over d -degree-bounded structures. Query evaluation is considered here as a dynamical process. We prove that any FO query on d -degree-bounded structures belongs to the complexity class constant-Delay lin , that is, can be computed by an algorithm that has two separate parts: it has a precomputation step of time linear in the size of the structure and then, it outputs all solutions (i.e., tuples that satisfy the formula) one by one with a constant delay (i.e., depending on the size of the formula only) between each. Seen as a global process, this implies that queries on d -degree-bounded structures can be evaluated in total time f (|φ|).(| S | + |φ( S )|) and space g (|φ|).| S | where S is the structure, φ is the formula, φ( S ) is the result of the query and f , g are some fixed functions. Among other things, our results generalize a result of Seese on the data complexity of the model-checking problem for d -degree-bounded structures. Besides, the originality of our approach compared to related results is that it does not rely on the Hanf's model-theoretic technique and is simple and informative since it essentially rests on a quantifier elimination method.",
    "cited_by_count": 81,
    "openalex_id": "https://openalex.org/W2030076354",
    "type": "article"
  },
  {
    "title": "An algebra of quantum processes",
    "doi": "https://doi.org/10.1145/1507244.1507249",
    "publication_date": "2009-04-01",
    "publication_year": 2009,
    "authors": "Mingsheng Ying; Yuan Feng; Runyao Duan; Zhengfeng Ji",
    "corresponding_authors": "",
    "abstract": "We introduce an algebra qCCS of pure quantum processes in which communications by moving quantum states physically are allowed and computations are modeled by super-operators, but no classical data is explicitly involved. An operational semantics of qCCS is presented in terms of (nonprobabilistic) labeled transition systems. Strong bisimulation between processes modeled in qCCS is defined, and its fundamental algebraic properties are established, including uniqueness of the solutions of recursive equations. To model sequential computation in qCCS, a reduction relation between processes is defined. By combining reduction relation and strong bisimulation we introduce the notion of strong reduction-bisimulation, which is a device for observing interaction of computation and communication in quantum systems. Finally, a notion of strong approximate bisimulation (equivalently, strong bisimulation distance) and its reduction counterpart are introduced. It is proved that both approximate bisimilarity and approximate reduction-bisimilarity are preserved by various constructors of quantum processes. This provides us with a formal tool for observing robustness of quantum processes against inaccuracy in the implementation of its elementary gates.",
    "cited_by_count": 79,
    "openalex_id": "https://openalex.org/W2112989388",
    "type": "article"
  },
  {
    "title": "Well-founded semantics for description logic programs in the semantic web",
    "doi": "https://doi.org/10.1145/1877714.1877717",
    "publication_date": "2011-01-01",
    "publication_year": 2011,
    "authors": "Thomas Eiter; Giovambattista Ianni; Thomas Lukasiewicz; Roman Schindlauer",
    "corresponding_authors": "",
    "abstract": "The realization of the Semantic Web vision, in which computational logic has a prominent role, has stimulated a lot of research on combining rules and ontologies, which are formulated in different formalisms. In particular, combining logic programming with the Web Ontology Language (OWL), which is a standard based on description logics, emerged as an important issue for linking the Rules and Ontology Layers of the Semantic Web. Nonmonotonic description logic programs ( dl-programs ) were introduced for such a combination, in which a pair (L,P) of a description logic knowledge base L and a set of rules P with negation as failure is given a model-based semantics that generalizes the answer set semantics of logic programs. In this article, we reconsider dl-programs and present a well-founded semantics for them as an analog for the other main semantics of logic programs. It generalizes the canonical definition of the well-founded semantics based on unfounded sets, and, as we show, lifts many of the well-known properties from ordinary logic programs to dl-programs. Among these properties, our semantics amounts to a partial model approximating the answer set semantics, which yields for positive and stratified dl-programs, a total model coinciding with the answer set semantics; it has polynomial data complexity provided the access to the description logic knowledge base is polynomial; under suitable restrictions, it has lower complexity and even first-order rewritability is achievable. The results add to previous evidence that dl-programs are a versatile and robust combination approach, which moreover is implementable using legacy engines.",
    "cited_by_count": 77,
    "openalex_id": "https://openalex.org/W2115303419",
    "type": "article"
  },
  {
    "title": "Alternating timed automata",
    "doi": "https://doi.org/10.1145/1342991.1342994",
    "publication_date": "2008-03-01",
    "publication_year": 2008,
    "authors": "Sławomir Lasota; Igor Walukiewicz",
    "corresponding_authors": "",
    "abstract": "A notion of alternating timed automata is proposed. It is shown that such automata with only one clock have decidable emptiness problem over finite words. This gives a new class of timed languages that is closed under boolean operations and which has an effective presentation. We prove that the complexity of the emptiness problem for alternating timed automata with one clock is nonprimitive recursive. The proof gives also the same lower bound for the universality problem for nondeterministic timed automata with one clock. We investigate extension of the model with epsilon-transitions and prove that emptiness is undecidable. Over infinite words, we show undecidability of the universality problem.",
    "cited_by_count": 76,
    "openalex_id": "https://openalex.org/W1964297656",
    "type": "article"
  },
  {
    "title": "A Cookbook for Temporal Conceptual Data Modelling with Description Logics",
    "doi": "https://doi.org/10.1145/2629565",
    "publication_date": "2014-07-08",
    "publication_year": 2014,
    "authors": "Alessandro Artale; Roman Kontchakov; Vladislav Ryzhikov; Michael Zakharyaschev",
    "corresponding_authors": "",
    "abstract": "We design temporal description logics (TDLs) suitable for reasoning about temporal conceptual data models and investigate their computational complexity. Our formalisms are based on DL-Lite logics with three types of concept inclusions (ranging from atomic concept inclusions and disjointness to the full Booleans), as well as cardinality constraints and role inclusions. The logics are interpreted over the Cartesian products of object domains and the flow of time (ℤ, &lt;), satisfying the constant domain assumption. Concept and role inclusions of the TBox hold at all moments of time (globally), and data assertions of the ABox hold at specified moments of time. To express temporal constraints of conceptual data models, the languages are equipped with flexible and rigid roles, standard future and past temporal operators on concepts, and operators “always” and “sometime” on roles. The most expressive of our TDLs (which can capture lifespan cardinalities and either qualitative or quantitative evolution constraints) turns out to be undecidable. However, by omitting some of the temporal operators on concepts/roles or by restricting the form of concept inclusions, we construct logics whose complexity ranges between NL og S pace and PS pace . These positive results are obtained by reduction to various clausal fragments of propositional temporal logic, which opens a way to employ propositional or first-order temporal provers for reasoning about temporal data models.",
    "cited_by_count": 68,
    "openalex_id": "https://openalex.org/W1980167179",
    "type": "article"
  },
  {
    "title": "Logic programs with propositional connectives and aggregates",
    "doi": "https://doi.org/10.1145/1970398.1970401",
    "publication_date": "2011-07-01",
    "publication_year": 2011,
    "authors": "Paolo Ferraris",
    "corresponding_authors": "Paolo Ferraris",
    "abstract": "Answer set programming (ASP) is a logic programming paradigm that can be used to solve complex combinatorial search problems. Aggregates are an ASP construct that plays an important role in many applications. Defining a satisfactory semantics of aggregates turned out to be a difficult problem, and in this article we propose a new approach, based on an analogy between aggregates and propositional connectives. First we extend the definition of an answer set/stable model to cover arbitrary propositional theories; then we define aggregates on top of them both as primitive constructs and as abbreviations for formulas. Our definition of an aggregate combines expressiveness and simplicity, and it inherits many theorems about programs with nested expressions, such as theorems about strong equivalence and splitting.",
    "cited_by_count": 68,
    "openalex_id": "https://openalex.org/W2029702617",
    "type": "article"
  },
  {
    "title": "Incremental Linearization for Satisfiability and Verification Modulo Nonlinear Arithmetic and Transcendental Functions",
    "doi": "https://doi.org/10.1145/3230639",
    "publication_date": "2018-07-31",
    "publication_year": 2018,
    "authors": "Alessandro Cimatti; Alberto Griggio; Ahmed Irfan; Marco Roveri; Roberto Sebastiani",
    "corresponding_authors": "",
    "abstract": "Satisfiability Modulo Theories (SMT) is the problem of deciding the satisfiability of a first-order formula with respect to some theory or combination of theories; Verification Modulo Theories (VMT) is the problem of analyzing the reachability for transition systems represented in terms of SMT formulae. In this article, we tackle the problems of SMT and VMT over the theories of nonlinear arithmetic over the reals (NRA) and of NRA augmented with transcendental (exponential and trigonometric) functions (NTA). We propose a new abstraction-refinement approach for SMT and VMT on NRA or NTA, called Incremental Linearization . The idea is to abstract nonlinear multiplication and transcendental functions as uninterpreted functions in an abstract space limited to linear arithmetic on the rationals with uninterpreted functions. The uninterpreted functions are incrementally axiomatized by means of upper- and lower-bounding piecewise-linear constraints. In the case of transcendental functions, particular care is required to ensure the soundness of the abstraction. The method has been implemented in the M ath SAT SMT solver and in the nu X mv model checker. An extensive experimental evaluation on a wide set of benchmarks from verification and mathematics demonstrates the generality and the effectiveness of our approach.",
    "cited_by_count": 60,
    "openalex_id": "https://openalex.org/W2889414920",
    "type": "article"
  },
  {
    "title": "Algebra-coalgebra duality in brzozowski's minimization algorithm",
    "doi": "https://doi.org/10.1145/2490818",
    "publication_date": "2014-02-01",
    "publication_year": 2014,
    "authors": "Filippo Bonchi; Marcello Bonsangue; Helle Hvid Hansen; Prakash Panangaden; Jan Rutten; Alexandra Silva",
    "corresponding_authors": "",
    "abstract": "We give a new presentation of Brzozowski's algorithm to minimize finite automata using elementary facts from universal algebra and coalgebra and building on earlier work by Arbib and Manes on a categorical presentation of Kalman duality between reachability and observability. This leads to a simple proof of its correctness and opens the door to further generalizations. Notably, we derive algorithms to obtain minimal language equivalent automata from Moore nondeterministic and weighted automata.",
    "cited_by_count": 55,
    "openalex_id": "https://openalex.org/W2138769606",
    "type": "article"
  },
  {
    "title": "Narrow Proofs May Be Maximally Long",
    "doi": "https://doi.org/10.1145/2898435",
    "publication_date": "2016-05-18",
    "publication_year": 2016,
    "authors": "Albert Atserias; Massimo Lauria; Jakob Nordström",
    "corresponding_authors": "",
    "abstract": "We prove that there are 3-CNF formulas over n variables that can be refuted in resolution in width w but require resolution proofs of size n Ω( w ) . This shows that the simple counting argument that any formula refutable in width w must have a proof in size n O( w ) is essentially tight. Moreover, our lower bound generalizes to polynomial calculus resolution and Sherali-Adams, implying that the corresponding size upper bounds in terms of degree and rank are tight as well. The lower bound does not extend all the way to Lasserre, however, since we show that there the formulas we study have proofs of constant rank and size polynomial in both n and w .",
    "cited_by_count": 55,
    "openalex_id": "https://openalex.org/W2396393208",
    "type": "article"
  },
  {
    "title": "Probabilistic Event Calculus for Event Recognition",
    "doi": "https://doi.org/10.1145/2699916",
    "publication_date": "2015-02-17",
    "publication_year": 2015,
    "authors": "Anastasios Skarlatidis; Γεώργιος Παλιούρας; Alexander Artikis; George A. Vouros",
    "corresponding_authors": "",
    "abstract": "Symbolic event recognition systems have been successfully applied to a variety of application domains, extracting useful information in the form of events, allowing experts or other systems to monitor and respond when significant events are recognised. In a typical event recognition application, however, these systems often have to deal with a significant amount of uncertainty. In this article, we address the issue of uncertainty in logic-based event recognition by extending the Event Calculus with probabilistic reasoning. Markov logic networks are a natural candidate for our logic-based formalism. However, the temporal semantics of the Event Calculus introduce a number of challenges for the proposed model. We show how and under what assumptions we can overcome these problems. Additionally, we study how probabilistic modelling changes the behaviour of the formalism, affecting its key property—the inertia of fluents. Furthermore, we demonstrate the advantages of the probabilistic Event Calculus through examples and experiments in the domain of activity recognition, using a publicly available dataset for video surveillance.",
    "cited_by_count": 54,
    "openalex_id": "https://openalex.org/W2037189708",
    "type": "article"
  },
  {
    "title": "Algebraic Proof Theory for LE-logics",
    "doi": "https://doi.org/10.1145/3632526",
    "publication_date": "2023-11-17",
    "publication_year": 2023,
    "authors": "Giuseppe Greco; Peter Jipsen; Fei Liang; Alessandra Palmigiano; Apostolos Tzimoulis",
    "corresponding_authors": "",
    "abstract": "In this article, we extend the research programme in algebraic proof theory from axiomatic extensions of the full Lambek calculus to logics algebraically captured by certain varieties of normal lattice expansions (normal LE-logics). Specifically, we generalize the residuated frames in Reference [ 34 ] to arbitrary signatures of normal lattice expansions (LE). Such a generalization provides a valuable tool for proving important properties of LE-logics in full uniformity. We prove semantic cut elimination for the display calculi \\(\\mathrm{D.LE}\\) associated with the basic normal LE-logics and their axiomatic extensions with analytic inductive axioms. We also prove the finite model property (FMP) for each such calculus \\(\\mathrm{D.LE}\\) , as well as for its extensions with analytic structural rules satisfying certain additional properties.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W2887483904",
    "type": "article"
  },
  {
    "title": "Parametric temporal logic for “model measuring”",
    "doi": "https://doi.org/10.1145/377978.377990",
    "publication_date": "2001-07-01",
    "publication_year": 2001,
    "authors": "Rajeev Alur; Kousha Etessami; Salvatore La Torre; Doron Peled",
    "corresponding_authors": "",
    "abstract": "We extend the standard model checking paradigm of linear temporal logic, LTL, to a “model measuring” paradigm where one can obtain more quantitative information beyond a “Yes/No” answer. For this purpose, we define a parametric temporal logic , PLTL, which allows statements such as “a request p is followed in at most x steps by a response q ,” where x is a free variable. We show how one can, given a formula ***( x 1 ...,x k ) of PLTL and a system model K satisfies the property ***, but if so find valuations which satisfy various optimality criteria. In particular, we present algorithms for finding valuations which minimize (or maximize) the maximum (or minimum) of all parameters. Theses algorithms exhibit the same PSPACE complexity as LTL model checking. We show that our choice of syntax for PLTL lies at the threshold of decidability for parametric temporal logics, in that several natural extensions have undecidable “model measuring” problems.",
    "cited_by_count": 99,
    "openalex_id": "https://openalex.org/W2048780543",
    "type": "article"
  },
  {
    "title": "Reasoning with higher-order abstract syntax in a logical framework",
    "doi": "https://doi.org/10.1145/504077.504080",
    "publication_date": "2002-01-01",
    "publication_year": 2002,
    "authors": "Raymond McDowell; Dale Miller",
    "corresponding_authors": "",
    "abstract": "Logical frameworks based on intuitionistic or linear logics with higher-type quantification have been successfully used to give high-level, modular, and formal specifications of many important judgments in the area of programming languages and inference systems. Given such specifications, it is natural to consider proving properties about the specified systems in the framework: for example, given the specification of evaluation for a functional programming language, prove that the language is deterministic or that evaluation preserves types. One challenge in developing a framework for such reasoning is that higher-order abstract syntax (HOAS), an elegant and declarative treatment of object-level abstraction and substitution, is difficult to treat in proofs involving induction. In this article, we present a meta-logic that can be used to reason about judgments coded using HOAS; this meta-logic is an extension of a simple intuitionistic logic that admits higher-order quantification over simply typed λ-terms (key ingredients for HOAS) as well as induction and a notion of definition . The latter concept of definition is a proof-theoretic device that allows certain theories to be treated as \"closed\" or as defining fixed points. We explore the difficulties of formal meta-theoretic analysis of HOAS encodings by considering encodings of intuitionistic and linear logics, and formally derive the admissibility of cut for important subsets of these logics. We then propose an approach to avoid the apparent trade-off between the benefits of higher-order abstract syntax and the ability to analyze the resulting encodings. We illustrate this approach through examples involving the simple functional and imperative programming languages PCF and PCF := . We formally derive such properties as unicity of typing, subject reduction, determinacy of evaluation, and the equivalence of transition semantics and natural semantics presentations of evaluation.",
    "cited_by_count": 98,
    "openalex_id": "https://openalex.org/W2099521332",
    "type": "article"
  },
  {
    "title": "Simulation-based minimization",
    "doi": "https://doi.org/10.1145/635499.635502",
    "publication_date": "2003-04-01",
    "publication_year": 2003,
    "authors": "Doron Bustan; Orna Grümberg",
    "corresponding_authors": "",
    "abstract": "We present a minimization algorithm that receives a Kripke structure M and returns the smallest structure that is simulation equivalent to M . The simulation equivalence relation is weaker than bisimulation but stronger than the simulation preorder. It strongly preserves ACTL and LTL (as sublogics of ACTL*).We show that every structure M has a unique-up-to-isomorphism reduced structure that is simulation equivalent to M and smallest in size. Our Minimizing Algorithm constructs this reduced structure. It first constructs the quotient structure for M , then eliminates transitions to little brothers, and finally deletes unreachable states.Since the first step of the algorithm is based on the simulation preorder over M , it has maximal space requirements. To reduce them, we present the Partitioning Algorithm, which constructs the quotient structure for M without ever building the simulation preorder. The Partitioning Algorithm has improved space complexity, but its time complexity might have worse.",
    "cited_by_count": 94,
    "openalex_id": "https://openalex.org/W2076334860",
    "type": "article"
  },
  {
    "title": "On knowledge-based programming with sensing in the situation calculus",
    "doi": "https://doi.org/10.1145/383779.383780",
    "publication_date": "2001-10-01",
    "publication_year": 2001,
    "authors": "Ray Reiter",
    "corresponding_authors": "Ray Reiter",
    "abstract": "We consider a class of knowledge-based Golog programs with sense actions. These programs refer explicitly to an agent's knowledge, and are designed to execute on-line, and under a dynamic closed-world assumption on knowledge. On-line execution of sense actions dynamically updates the background axioms with sentences asserting knowledge of the sense actions' outcomes. We formalize what all this might mean, and show that under suitable assumptions the knowledge modality in such programs can be implemented by provability. This leads to an on-line Golog interpreter for such programs, which we demonstrate on a knowledge-based program with sensing for the blocks world.",
    "cited_by_count": 91,
    "openalex_id": "https://openalex.org/W1977208552",
    "type": "article"
  },
  {
    "title": "An extended transformation approach to inductive logic programming",
    "doi": "https://doi.org/10.1145/383779.383781",
    "publication_date": "2001-10-01",
    "publication_year": 2001,
    "authors": "Nada Lavrač; Peter Flach",
    "corresponding_authors": "",
    "abstract": "Inductive logic programming (ILP) is concerned with learning relational descriptions that typically have the form of logic programs. In a transformation approach, an ILP task is transformed into an equivalent learning task in a different representation formalism. Propositionalization is a particular transformation method, in which the ILP task is compiled to an attribute-value learning task. The main restriction of propositionalization methods such as LINUS is that they are unable to deal with nondeterminate local variables in the body of hypothesis clauses. In this paper we show how this limitation can be overcome., by systematic first-order feature construction using a particular individual-centered feature bias. The approach can be applied in any domain where there is a clear notion of individual. We also show how to improve upon exhaustive first-order feature construction by using a relevancy filter. The proposed approach is illustrated on the “trains” and “mutagenesis” ILP domains.",
    "cited_by_count": 88,
    "openalex_id": "https://openalex.org/W2141244067",
    "type": "article"
  },
  {
    "title": "Probabilistic game semantics",
    "doi": "https://doi.org/10.1145/507382.507385",
    "publication_date": "2002-07-01",
    "publication_year": 2002,
    "authors": "Vincent Danos; Russell Harmer",
    "corresponding_authors": "",
    "abstract": "A category of HO/N-style games and probabilistic strategies is developed where the possible choices of a strategy are quantified so as to give a measure of the likelihood of seeing a given play. A two-sided die is shown to be universal in this category, in the sense that any strategy breaks down into a composition between some deterministic strategy and that die. The interpretative power of the category is then demonstrated by delineating a Cartesian closed subcategory that provides a fully abstract model of a probabilistic extension of Idealized Algol.",
    "cited_by_count": 88,
    "openalex_id": "https://openalex.org/W2178993149",
    "type": "article"
  },
  {
    "title": "Proof nets for unit-free multiplicative-additive linear logic",
    "doi": "https://doi.org/10.1145/1094622.1094629",
    "publication_date": "2005-10-01",
    "publication_year": 2005,
    "authors": "Dominic J. D. Hughes; Rob J. van Glabbeek",
    "corresponding_authors": "",
    "abstract": "A cornerstone of the theory of proof nets for unit-free multiplicative linear logic (MLL) is the abstract representation of cut-free proofs modulo inessential rule commutation. The only known extension to additives, based on monomial weights, fails to preserve this key feature: a host of cut-free monomial proof nets can correspond to the same cut-free proof. Thus, the problem of finding a satisfactory notion of proof net for unit-free multiplicative-additive linear logic (MALL) has remained open since the inception of linear logic in 1986. We present a new definition of MALL proof net which remains faithful to the cornerstone of the MLL theory.",
    "cited_by_count": 84,
    "openalex_id": "https://openalex.org/W1964454590",
    "type": "article"
  },
  {
    "title": "Soft concurrent constraint programming",
    "doi": "https://doi.org/10.1145/1149114.1149118",
    "publication_date": "2006-07-01",
    "publication_year": 2006,
    "authors": "Stefano Bistarelli; Ugo Montanari; Francesca Rossi",
    "corresponding_authors": "",
    "abstract": "Soft constraints extend classical constraints to represent multiple consistency levels, and thus provide a way to express preferences, fuzziness, and uncertainty. While there are many soft constraint solving formalisms, even distributed ones, as yet there seems to be no concurrent programming framework where soft constraints can be handled. In this article we show how the classical concurrent constraint (cc) programming framework can work with soft constraints, and we also propose an extension of cc languages which can use soft constraints to prune and direct the search for a solution. We believe that this new programming paradigm, called soft cc (scc), can be also very useful in many Web-related scenarios. In fact, the language level allows Web agents to express their interaction and negotiation protocols, and also to post their requests in terms of preferences, and the underlying soft constraint solver can find an agreement among the agents even if their requests are incompatible.",
    "cited_by_count": 79,
    "openalex_id": "https://openalex.org/W3122941067",
    "type": "article"
  },
  {
    "title": "Automatic linear orders and trees",
    "doi": "https://doi.org/10.1145/1094622.1094625",
    "publication_date": "2005-10-01",
    "publication_year": 2005,
    "authors": "Bakhadyr Khoussainov; Sasha Rubin; Frank Stephan",
    "corresponding_authors": "",
    "abstract": "We investigate partial orders that are computable, in a precise sense, by finite automata. Our emphasis is on trees and linear orders. We study the relationship between automatic linear orders and trees in terms of rank functions that are related to Cantor--Bendixson rank. We prove that automatic linear orders and automatic trees have finite rank. As an application we provide a procedure for deciding the isomorphism problem for automatic ordinals. We also investigate the complexity and definability of infinite paths in automatic trees. In particular, we show that every infinite path in an automatic tree with countably many infinite paths is a regular language.",
    "cited_by_count": 74,
    "openalex_id": "https://openalex.org/W2033186040",
    "type": "article"
  },
  {
    "title": "A concrete framework for environment machines",
    "doi": "https://doi.org/10.1145/1297658.1297664",
    "publication_date": "2007-12-01",
    "publication_year": 2007,
    "authors": "Małgorzata Biernacka; Olivier Danvy",
    "corresponding_authors": "",
    "abstract": "We materialize the common understanding that calculi with explicit substitutions provide an intermediate step between an abstract specification of substitution in the lambda-calculus and its concrete implementations. To this end, we go back to Curien's original calculus of closures (an early calculus with explicit substitutions), we extend it minimally so that it can also express one-step reduction strategies, and we methodically derive a series of environment machines from the specification of two one-step reduction strategies for the lambda-calculus: normal order and applicative order. The derivation extends Danvy and Nielsen's refocusing-based construction of abstract machines with two new steps: one for coalescing two successive transitions into one, and the other for unfolding a closure into a term and an environment in the resulting abstract machine. The resulting environment machines include both the Krivine machine and the original version of Krivine's machine, Felleisen et al.'s CEK machine, and Leroy's Zinc abstract machine.",
    "cited_by_count": 72,
    "openalex_id": "https://openalex.org/W2163285555",
    "type": "article"
  },
  {
    "title": "What causes a system to satisfy a specification?",
    "doi": "https://doi.org/10.1145/1352582.1352588",
    "publication_date": "2008-06-01",
    "publication_year": 2008,
    "authors": "Hana Chockler; Joseph Y. Halpern; Orna Kupferman",
    "corresponding_authors": "",
    "abstract": "Even when a system is proven to be correct with respect to a specification, there is still a question of how complete the specification is, and whether it really covers all the behaviors of the system. Coverage metrics attempt to check which parts of a system are actually relevant for the verification process to succeed. Recent work on coverage in model checking suggests several coverage metrics and algorithms for finding parts of the system that are not covered by the specification. The work has already proven to be effective in practice, detecting design errors that escape early verification efforts in industrial settings. In this article, we relate a formal definition of causality given by Halpern and Pearl to coverage. We show that it gives significant insight into unresolved issues regarding the definition of coverage and leads to potentially useful extensions of coverage. In particular, we introduce the notion of responsibility , which assigns to components of a system a quantitative measure of their relevance to the satisfaction of the specification.",
    "cited_by_count": 70,
    "openalex_id": "https://openalex.org/W2130780163",
    "type": "article"
  },
  {
    "title": "A formally verified proof of the prime number theorem",
    "doi": "https://doi.org/10.1145/1297658.1297660",
    "publication_date": "2007-12-01",
    "publication_year": 2007,
    "authors": "Jeremy Avigad; K. Donnelly; David Gray; Paul Raff",
    "corresponding_authors": "",
    "abstract": "The prime number theorem, established by Hadamard and de la Vallée Poussin independently in 1896, asserts that the density of primes in the positive integers is asymptotic to 1/ln x . Whereas their proofs made serious use of the methods of complex analysis, elementary proofs were provided by Selberg and Erdös in 1948. We describe a formally verified version of Selberg's proof, obtained using the Isabelle proof assistant.",
    "cited_by_count": 68,
    "openalex_id": "https://openalex.org/W2000062667",
    "type": "article"
  },
  {
    "title": "Efficient generation of craig interpolants in satisfiability modulo theories",
    "doi": "https://doi.org/10.1145/1838552.1838559",
    "publication_date": "2010-10-01",
    "publication_year": 2010,
    "authors": "Alessandro Cimatti; Alberto Griggio; Roberto Sebastiani",
    "corresponding_authors": "",
    "abstract": "The problem of computing Craig interpolants has recently received a lot of interest. In this article, we address the problem of efficient generation of interpolants for some important fragments of first-order logic, which are amenable for effective decision procedures, called satisfiability modulo theory (SMT) solvers. We make the following contributions. First, we provide interpolation procedures for several basic theories of interest: the theories of linear arithmetic over the rationals, difference logic over rationals and integers, and UTVPI over rationals and integers. Second, we define a novel approach to interpolate combinations of theories that applies to the delayed theory combination approach. Efficiency is ensured by the fact that the proposed interpolation algorithms extend state-of-the-art algorithms for satisfiability modulo theories. Our experimental evaluation shows that the MathSAT SMT solver can produce interpolants with minor overhead in search, and much more efficiently than other competitor solvers.",
    "cited_by_count": 65,
    "openalex_id": "https://openalex.org/W2003690673",
    "type": "article"
  },
  {
    "title": "PSPACE bounds for rank-1 modal logics",
    "doi": "https://doi.org/10.1145/1462179.1462185",
    "publication_date": "2009-02-01",
    "publication_year": 2009,
    "authors": "Lutz Schröder; Dirk Pattinson",
    "corresponding_authors": "",
    "abstract": "For lack of general algorithmic methods that apply to wide classes of logics, establishing a complexity bound for a given modal logic is often a laborious task. The present work is a step towards a general theory of the complexity of modal logics. Our main result is that all rank-1 logics enjoy a shallow model property and thus are, under mild assumptions on the format of their axiomatisation, in PSPACE. This leads to a unified derivation of tight PSPACE-bounds for a number of logics including K, KD, coalition logic, graded modal logic, majority logic, and probabilistic modal logic. Our generic algorithm moreover finds tableau proofs that witness pleasant proof-theoretic properties including a weak subformula property. This generality is made possible by a coalgebraic semantics, which conveniently abstracts from the details of a given model class and thus allows covering a broad range of logics in a uniform way.",
    "cited_by_count": 62,
    "openalex_id": "https://openalex.org/W2250074872",
    "type": "article"
  },
  {
    "title": "On the proof complexity of deep inference",
    "doi": "https://doi.org/10.1145/1462179.1462186",
    "publication_date": "2009-02-01",
    "publication_year": 2009,
    "authors": "Paola Bruscoli; Alessio Guglielmi",
    "corresponding_authors": "",
    "abstract": "We obtain two results about the proof complexity of deep inference: (1) Deep-inference proof systems are as powerful as Frege ones, even when both are extended with the Tseitin extension rule or with the substitution rule; (2) there are analytic deep-inference proof systems that exhibit an exponential speedup over analytic Gentzen proof systems that they polynomially simulate.",
    "cited_by_count": 62,
    "openalex_id": "https://openalex.org/W3123028025",
    "type": "article"
  },
  {
    "title": "Deciding security properties for cryptographic protocols. application to key cycles",
    "doi": "https://doi.org/10.1145/1656242.1656244",
    "publication_date": "2010-01-01",
    "publication_year": 2010,
    "authors": "Hubert Comon-Lundh; Véronique Cortier; Eugen Zălinescu",
    "corresponding_authors": "",
    "abstract": "There is a large amount of work dedicated to the formal verification of security protocols. In this article, we revisit and extend the NP-complete decision procedure for a bounded number of sessions. We use a, now standard, deducibility constraint formalism for modeling security protocols. Our first contribution is to give a simple set of constraint simplification rules, that allows to reduce any deducibility constraint to a set of solved forms , representing all solutions (within the bound on sessions). As a consequence, we prove that deciding the existence of key cycles is NP-complete for a bounded number of sessions. The problem of key-cycles has been put forward by recent works relating computational and symbolic models. The so-called soundness of the symbolic model requires indeed that no key cycle (e.g., enc(k, k)) ever occurs in the execution of the protocol. Otherwise, stronger security assumptions (such as KDM-security) are required. We show that our decision procedure can also be applied to prove again the decidability of authentication-like properties and the decidability of a significant fragment of protocols with timestamps.",
    "cited_by_count": 55,
    "openalex_id": "https://openalex.org/W2155993098",
    "type": "article"
  },
  {
    "title": "Sound and Complete Axiomatizations of Coalgebraic Language Equivalence",
    "doi": "https://doi.org/10.1145/2422085.2422092",
    "publication_date": "2013-02-01",
    "publication_year": 2013,
    "authors": "Marcello Bonsangue; Stefan Milius; Alexandra Silva",
    "corresponding_authors": "",
    "abstract": "Coalgebras provide a uniform framework to study dynamical systems, including several types of automata. In this paper, we make use of the coalgebraic view on systems to investigate, in a uniform way, under which conditions calculi that are sound and complete with respect to behavioral equivalence can be extended to a coarser coalgebraic language equivalence, which arises from a generalised powerset construction that determinises coalgebras. We show that soundness and completeness are established by proving that expressions modulo axioms of a calculus form the rational fixpoint of the given type functor. Our main result is that the rational fixpoint of the functor $FT$, where $T$ is a monad describing the branching of the systems (e.g. non-determinism, weights, probability etc.), has as a quotient the rational fixpoint of the \"determinised\" type functor $\\bar F$, a lifting of $F$ to the category of $T$-algebras. We apply our framework to the concrete example of weighted automata, for which we present a new sound and complete calculus for weighted language equivalence. As a special case, we obtain non-deterministic automata, where we recover Rabinovich's sound and complete calculus for language equivalence.",
    "cited_by_count": 49,
    "openalex_id": "https://openalex.org/W3121572647",
    "type": "article"
  },
  {
    "title": "A Model-Theoretic Approach to Belief Change in Answer Set Programming",
    "doi": "https://doi.org/10.1145/2480759.2480766",
    "publication_date": "2013-06-01",
    "publication_year": 2013,
    "authors": "James P. Delgrande; Torsten Schaub; Hans Tompits; Stefan Woltran",
    "corresponding_authors": "",
    "abstract": "We address the problem of belief change in (nonmonotonic) logic programming under answer set semantics. Our formal techniques are analogous to those of distance-based belief revision in propositional logic. In particular, we build upon the model theory of logic programs furnished by SE interpretations, where an SE interpretation is a model of a logic program in the same way that a classical interpretation is a model of a propositional formula. Hence we extend techniques from the area of belief revision based on distance between models to belief change in logic programs. We first consider belief revision: for logic programs P and Q , the goal is to determine a program R that corresponds to the revision of P by Q , denoted P * Q . We investigate several operators, including (logic program) expansion and two revision operators based on the distance between the SE models of logic programs. It proves to be the case that expansion is an interesting operator in its own right, unlike in classical belief revision where it is relatively uninteresting. Expansion and revision are shown to satisfy a suite of interesting properties; in particular, our revision operators satisfy all or nearly all of the AGM postulates for revision. We next consider approaches for merging a set of logic programs, P 1 , ..., P n . Again, our formal techniques are based on notions of relative distance between the SE models of the logic programs. Two approaches are examined. The first informally selects for each program P i those models of P i that vary the least from models of the other programs. The second approach informally selects those models of a program P 0 that are closest to the models of programs P 1 , ..., P n . In this case, P 0 can be thought of as a set of database integrity constraints. We examine these operators with regards to how they satisfy relevant postulate sets. Last, we present encodings for computing the revision as well as the merging of logic programs within the same logic programming framework. This gives rise to a direct implementation of our approach in terms of off-the-shelf answer set solvers. These encodings also reflect the fact that our change operators do not increase the complexity of the base formalism.",
    "cited_by_count": 46,
    "openalex_id": "https://openalex.org/W2001560360",
    "type": "article"
  },
  {
    "title": "Improved witnessing and local improvement principles for second-order bounded arithmetic",
    "doi": "https://doi.org/10.1145/2559950",
    "publication_date": "2014-02-01",
    "publication_year": 2014,
    "authors": "Arnold Beckmann; Samuel R. Buss",
    "corresponding_authors": "",
    "abstract": "This article concerns the second-order systems U 1 2 and V 1 2 of bounded arithmetic, which have proof-theoretic strengths corresponding to polynomial-space and exponential-time computation. We formulate improved witnessing theorems for these two theories by using S 1 2 as a base theory for proving the correctness of the polynomial-space or exponential-time witnessing functions. We develop the theory of nondeterministic polynomial-space computation, including Savitch's theorem, in U 1 2 . Kołodziejczyk et al. [2011] have introduced local improvement properties to characterize the provably total NP functions of these second-order theories. We show that the strengths of their local improvement principles over U 1 2 and V 1 2 depend primarily on the topology of the underlying graph, not the number of rounds in the local improvement games. The theory U 1 2 proves the local improvement principle for linear graphs even without restricting to logarithmically many rounds. The local improvement principle for grid graphs with only logarithmically-many rounds is complete for the provably total NP search problems of V 1 2 . Related results are obtained for local improvement principles with one improvement round and for local improvement over rectangular grids.",
    "cited_by_count": 45,
    "openalex_id": "https://openalex.org/W2040502162",
    "type": "article"
  },
  {
    "title": "A Sound and Complete Proof Technique for Linearizability of Concurrent Data Structures",
    "doi": "https://doi.org/10.1145/2629496",
    "publication_date": "2014-08-01",
    "publication_year": 2014,
    "authors": "Gerhard Schellhorn; John Derrick; Heike Wehrheim",
    "corresponding_authors": "",
    "abstract": "Efficient implementations of data structures such as queues, stacks or hash-tables allow for concurrent access by many processes at the same time. To increase concurrency, these algorithms often completely dispose with locking, or only lock small parts of the structure. Linearizability is the standard correctness criterion for such a scenario—where a concurrent object is linearizable if all of its operations appear to take effect instantaneously some time between their invocation and return. The potential concurrent access to the shared data structure tremendously increases the complexity of the verification problem, and thus current proof techniques for showing linearizability are all tailored to specific types of data structures. In previous work, we have shown how simulation-based proof conditions for linearizability can be used to verify a number of subtle concurrent algorithms. In this article, we now show that conditions based on backward simulation can be used to show linearizability of every linearizable algorithm, that is, we show that our proof technique is both sound and complete. We exemplify our approach by a linearizability proof of a concurrent queue, introduced in Herlihy and Wing's landmark paper on linearizability. Except for their manual proof, none of the numerous other approaches have successfully treated this queue. Our approach is supported by a full mechanisation: both the linearizability proofs for case studies like the queue, and the proofs of soundness and completeness have been carried out with an interactive prover, which is KIV.",
    "cited_by_count": 44,
    "openalex_id": "https://openalex.org/W2017559473",
    "type": "article"
  },
  {
    "title": "An <i>O</i> ( <i>m</i> log <i>n</i> ) Algorithm for Computing Stuttering Equivalence and Branching Bisimulation",
    "doi": "https://doi.org/10.1145/3060140",
    "publication_date": "2017-04-30",
    "publication_year": 2017,
    "authors": "Jan Friso Groote; David N. Jansen; Jeroen J. A. Keiren; Anton Wijs",
    "corresponding_authors": "",
    "abstract": "We provide a new algorithm to determine stuttering equivalence with time complexity O ( m log n ), where n is the number of states and m is the number of transitions of a Kripke structure. This algorithm can also be used to determine branching bisimulation in O ( m (log | Act | + log n )) time, where Act is the set of actions in a labeled transition system. Theoretically, our algorithm substantially improves upon existing algorithms, which all have time complexity of the form O ( mn ) at best. Moreover, it has better or equal space complexity. Practical results confirm these findings: they show that our algorithm can outperform existing algorithms by several orders of magnitude, especially when the Kripke structures are large. The importance of our algorithm stretches far beyond stuttering equivalence and branching bisimulation. The known O ( mn ) algorithms were already far more efficient (both in space and time) than most other algorithms to determine behavioral equivalences (including weak bisimulation), and therefore they were often used as an essential preprocessing step. This new algorithm makes this use of stuttering equivalence and branching bisimulation even more attractive.",
    "cited_by_count": 42,
    "openalex_id": "https://openalex.org/W2663462053",
    "type": "article"
  },
  {
    "title": "Search and strategies in OPL",
    "doi": "https://doi.org/10.1145/359496.359529",
    "publication_date": "2000-10-01",
    "publication_year": 2000,
    "authors": "Pascal Van Hentenryck; Laurent Perron; Jean‐François Puget",
    "corresponding_authors": "",
    "abstract": "OPL is a modeling language for mathematical programming and combinatorial optimization. It is the first language to combine high-level algebraic and set notations from mathematical modeling languages with a rich constraint language and the ability to specify search procedures and strategies that are the essence of constraint programming. This paper describes the facilities available in OPL to specify search procedures. It describes the abstractions of OPL to specify both the search tree (search) and how to explore it (strategies). The paper also illustrates how to use these high-level constructs to implement traditional search procedures in constraint programming and scheduling.",
    "cited_by_count": 78,
    "openalex_id": "https://openalex.org/W2090338624",
    "type": "article"
  },
  {
    "title": "Datalog LITE",
    "doi": "https://doi.org/10.1145/504077.504079",
    "publication_date": "2002-01-01",
    "publication_year": 2002,
    "authors": "Georg Gottlob; Erich Grädel; Helmut Veith",
    "corresponding_authors": "",
    "abstract": "We present Datalog LITE, a new deductive query language with a linear-time model-checking algorithm, that is, linear time data complexity and program complexity. Datalog LITE is a variant of Datalog that uses stratified negation, restricted variable occurrences and a limited form of universal quantification in rule bodies.Despite linear-time evaluation, Datalog LITE is highly expressive: It encompasses popular modal and temporal logics such as CTL or the alternation-free μ-calculus. In fact, these formalisms have natural presentations as fragments of Datalog LITE. Further, Datalog LITE is equivalent to the alternation-free portion of guarded fixed-point logic. Consequently, linear-time model checking algorithms for all mentioned logics are obtained in a unified way.The results are complemented by inexpressibility proofs to the effect that linear-time fragments of stratified Datalog have too limited expressive power.",
    "cited_by_count": 76,
    "openalex_id": "https://openalex.org/W2008029457",
    "type": "article"
  },
  {
    "title": "Verifying security protocols as planning in logic programming",
    "doi": "https://doi.org/10.1145/383779.383785",
    "publication_date": "2001-10-01",
    "publication_year": 2001,
    "authors": "Luigia Carlucci Aiello; Fabio Massacci",
    "corresponding_authors": "",
    "abstract": "We illustrate AL SP (Action Language for Security Protocol), a declarative executable specification language for planning attacks to security protocols. AL SP is based on logic programming with negation as failure, and with stable model semantics. In AL SP we can give a declarative specification of a protocol with the natural semantics of send and receive actions which can be performed in parallel. By viewing a protocol trace as a plan to achieve a goal, attacks are (possibly parallel) plans achieving goals that correspond to security violations. Building on results from logic programming and planning, we map the existence of an attack into the existence of a model for the protocol that satisfies the specification of an attack. We show that our liberal model of parallel actions can adequately represent the traditional Dolev-Yao trace-based model used in the formal analysis of security protocols. Specifications in AL SP are executable, as we can automatically search for attacks via an efficient model generator (smodels), implementing the stable model semantics of normal logic programs.",
    "cited_by_count": 74,
    "openalex_id": "https://openalex.org/W2049129243",
    "type": "article"
  },
  {
    "title": "Back and forth between guarded and modal logics",
    "doi": "https://doi.org/10.1145/507382.507388",
    "publication_date": "2002-07-01",
    "publication_year": 2002,
    "authors": "Erich Grädel; Colin Hirsch; Martin Otto",
    "corresponding_authors": "",
    "abstract": "Guarded fixed-point logic μGF extends the guarded fragment by means of least and greatest fixed points, and thus plays the same role within the domain of guarded logics as the modal μ-calculus plays within the modal domain. We provide a semantic characterization of μGF within an appropriate fragment of second-order logic, in terms of invariance under guarded bisimulation. The corresponding characterization of the modal μ-calculus, due to Janin and Walukiewicz, is lifted from the modal to the guarded domain by means of model theoretic translations. Guarded second-order logic, the fragment of second-order logic which is introduced in the context of our characterization theorem, captures a natural and robust level of expressiveness with several equivalent characterizations. For a wide range of issues in guarded logics it may take up a role similar to that of monadic second-order in relation to modal logics. At the more general methodological level, the translations between the guarded and modal domains make the intuitive analogy between guarded and modal logics available as a tool in the further analysis of the model theory of guarded logics.",
    "cited_by_count": 74,
    "openalex_id": "https://openalex.org/W2179506702",
    "type": "article"
  },
  {
    "title": "An effective decision procedure for linear arithmetic over the integers and reals",
    "doi": "https://doi.org/10.1145/1071596.1071601",
    "publication_date": "2005-07-01",
    "publication_year": 2005,
    "authors": "Bernard Boigelot; Sébastien Jodogne; Pierre Wolper",
    "corresponding_authors": "",
    "abstract": "This article considers finite-automata-based algorithms for handling linear arithmetic with both real and integer variables. Previous work has shown that this theory can be dealt with by using finite automata on infinite words, but this involves some difficult and delicate to implement algorithms. The contribution of this article is to show, using topological arguments, that only a restricted class of automata on infinite words are necessary for handling real and integer linear arithmetic. This allows the use of substantially simpler algorithms, which have been successfully implemented.",
    "cited_by_count": 72,
    "openalex_id": "https://openalex.org/W1966686249",
    "type": "article"
  },
  {
    "title": "A classification of symbolic transition systems",
    "doi": "https://doi.org/10.1145/1042038.1042039",
    "publication_date": "2005-01-01",
    "publication_year": 2005,
    "authors": "Thomas A. Henzinger; Rupak Majumdar; Jean-François Raskin",
    "corresponding_authors": "",
    "abstract": "We define five increasingly comprehensive classes of infinite-state systems, called STS1--STS5, whose state spaces have finitary structure. For four of these classes, we provide examples from hybrid systems.STS1 These are the systems with finite bisimilarity quotients. They can be analyzed symbolically by iteratively applying predecessor and Boolean operations on state sets, starting from a finite number of observable state sets. Any such iteration is guaranteed to terminate in that only a finite number of state sets can be generated. This enables model checking of the μ-calculus.STS2 These are the systems with finite similarity quotients. They can be analyzed symbolically by iterating the predecessor and positive Boolean operations. This enables model checking of the existential and universal fragments of the μ-calculus.STS3 These are the systems with finite trace-equivalence quotients. They can be analyzed symbolically by iterating the predecessor operation and a restricted form of positive Boolean operations (intersection is restricted to intersection with observables). This enables model checking of all ω-regular properties, including linear temporal logic.STS4 These are the systems with finite distance-equivalence quotients (two states are equivalent if for every distance d , the same observables can be reached in d transitions). The systems in this class can be analyzed symbolically by iterating the predecessor operation and terminating when no new state sets are generated. This enables model checking of the existential conjunction-free and universal disjunction-free fragments of the μ-calculus.STS5 These are the systems with finite bounded-reachability quotients (two states are equivalent if for every distance d , the same observables can be reached in d or fewer transitions). The systems in this class can be analyzed symbolically by iterating the predecessor operation and terminating when no new states are encountered (this is a weaker termination condition than above). This enables model checking of reachability properties.",
    "cited_by_count": 71,
    "openalex_id": "https://openalex.org/W1977116278",
    "type": "article"
  },
  {
    "title": "Logic programming revisited",
    "doi": "https://doi.org/10.1145/383779.383789",
    "publication_date": "2001-10-01",
    "publication_year": 2001,
    "authors": "Maurice Bruynooghe; Victor W. Marek",
    "corresponding_authors": "",
    "abstract": "Logic programming has been introduced as programming in the Horn clause subset of first-order logic. This view breaks down for the negation as failure inference rule. To overcome the problem, one line of research has been to view a logic program as a set of iff-definitions. A second approach was to identify a unique canonical, preferred , or intended model among the models of the program and to appeal to common sense to validate the choice of such model. Another line of research developed the view of logic programming as a nonmonotonic reasoning formalism strongly related to Default Logic and Autoepistemic Logic. These competing approaches have resulted in some confusion about the declarative meaning of logic programming. This paper investigates the problem and proposes an alternative epistemological foundation for the canonical model approach, which is not based on common sense but on a solid mathematical information principle. The thesis is developed that logic programming can be understood as a natural and general logic of inductive definitions . In particular, logic programs with negation represent nonmonotone inductive definitions . It is argued that this thesis results in an alternative justification of the well-founded model as the unique intended model of the logic program. In addition, it equips logic programs with an easy-to-comprehend meaning that corresponds very well with the intuitions of programmers.",
    "cited_by_count": 71,
    "openalex_id": "https://openalex.org/W2076652224",
    "type": "article"
  },
  {
    "title": "Abstract versus concrete computation on metric partial algebras",
    "doi": "https://doi.org/10.1145/1024922.1024924",
    "publication_date": "2004-10-01",
    "publication_year": 2004,
    "authors": "John V. Tucker; J. I. Zucker",
    "corresponding_authors": "",
    "abstract": "In the theory of computation on topological algebras there is a considerable gap between so-called abstract and concrete models of computation. In concrete models, unlike abstract models, the computations depend on the representation of the algebra. First, we show that with abstract models, one needs algebras with &lt;i&gt;partial operations&lt;/i&gt;, and computable functions that are both &lt;i&gt;continuous&lt;/i&gt; and &lt;i&gt;many-valued&lt;/i&gt;. This many-valuedness is needed even to compute single-valued functions, and so &lt;i&gt;abstract models must be nondeterministic even to compute deterministic problems&lt;/i&gt;. As an abstract model, we choose the \"while\"-array programming language, extended with a nondeterministic \"countable choice\" assignment, called the &lt;i&gt;&lt;b&gt;WhileCC*&lt;/b&gt;&lt;/i&gt; model. Using this, we introduce the concept of &lt;i&gt;approximable many-valued computation&lt;/i&gt; on metric algebras. For our concrete model, we choose metric algebras with &lt;i&gt;effective representations&lt;/i&gt;. We prove:(1) for any metric algebra &lt;i&gt;A&lt;/i&gt; with an effective representation α, &lt;i&gt;&lt;b&gt;WhileCC*&lt;/b&gt;&lt;/i&gt; approximability implies computability in α, and (2) also the converse, under certain reasonable conditions on &lt;i&gt;A&lt;/i&gt;. From (1) and (2) we derive an equivalence theorem between abstract and concrete computation on metric partial algebras. We give examples of algebras where this equivalence holds.",
    "cited_by_count": 71,
    "openalex_id": "https://openalex.org/W2094663018",
    "type": "article"
  },
  {
    "title": "NEXP TIME-complete description logics with concrete domains",
    "doi": "https://doi.org/10.1145/1024922.1024925",
    "publication_date": "2004-10-01",
    "publication_year": 2004,
    "authors": "Carsten Lutz",
    "corresponding_authors": "Carsten Lutz",
    "abstract": "Concrete domains are an extension of Description Logics (DLs) that allow one to integrate reasoning about conceptual knowledge with reasoning about \"concrete qualities\" of real-world entities such as their sizes, weights, and durations. In this article, we are concerned with the complexity of Description Logics providing for concrete domains: starting from the complexity result established in Lutz [2002b], which states that reasoning with the basic propositionally closed DL with concrete domains &lt;i&gt;ALC(D)&lt;/i&gt; is PSpace-complete (provided that some weak conditions are satisfied), we perform an in-depth analysis of the complexity of extensions of this logic. More precisely, we consider five natural and seemingly \"harmless\" extensions of &lt;i&gt;ALC(D)&lt;/i&gt; and prove that, for all five extensions, reasoning is NExpTime-complete (again if some weak conditions are satisfied). Thus, we show that the PSpace upper bound for reasoning with &lt;i&gt;ALC(D)&lt;/i&gt; cannot be considered robust with respect to extensions of the language.",
    "cited_by_count": 70,
    "openalex_id": "https://openalex.org/W1978002064",
    "type": "article"
  },
  {
    "title": "Sequent and hypersequent calculi for abelian and łukasiewicz logics",
    "doi": "https://doi.org/10.1145/1071596.1071600",
    "publication_date": "2005-07-01",
    "publication_year": 2005,
    "authors": "George Metcalfe; Nicola Olivetti; Dov M. Gabbay",
    "corresponding_authors": "",
    "abstract": "We present two embeddings of Łukasiewicz logic Ł into Meyer and Slaney's Abelian logic A , the logic of lattice-ordered Abelian groups. We give new analytic proof systems for A and use the embeddings to derive corresponding systems for Ł . These include hypersequent calculi, terminating hypersequent calculi, co-NP labeled sequent calculi, and unlabeled sequent calculi.",
    "cited_by_count": 69,
    "openalex_id": "https://openalex.org/W2088476380",
    "type": "article"
  },
  {
    "title": "Precongruence formats for decorated trace semantics",
    "doi": "https://doi.org/10.1145/963927.963929",
    "publication_date": "2004-01-01",
    "publication_year": 2004,
    "authors": "Bard Bloom; Wan Fokkink; Rob J. van Glabbeek",
    "corresponding_authors": "",
    "abstract": "This paper explores the connection between semantic equivalences and preorders for concrete sequential processes, represented by means of labeled transition systems, and formats of transition system specifications using Plotkin's structural approach. For several preorders in the linear time---branching time spectrum a format is given, as general as possible, such that this preorder is a precongruence for all operators specifiable in that format. The formats are derived using the modal characterizations of the corresponding preorders.",
    "cited_by_count": 69,
    "openalex_id": "https://openalex.org/W2154695063",
    "type": "article"
  },
  {
    "title": "Domain-dependent knowledge in answer set planning",
    "doi": "https://doi.org/10.1145/1183278.1183279",
    "publication_date": "2006-10-01",
    "publication_year": 2006,
    "authors": "Tran Cao Son; Chitta Baral; Nam Tran; Sheila A. McIlraith",
    "corresponding_authors": "",
    "abstract": "In this article we consider three different kinds of domain-dependent control knowledge (temporal, procedural and HTN-based) that are useful in planning. Our approach is declarative and relies on the language of logic programming with answer set semantics (AnsProlog*). AnsProlog* is designed to plan without control knowledge. We show how temporal, procedural and HTN-based control knowledge can be incorporated into AnsProlog* by the modular addition of a small number of domain-dependent rules, without the need to modify the planner. We formally prove the correctness of our planner, both in the absence and presence of the control knowledge. Finally, we perform some initial experimentation that demonstrates the potential reduction in planning time that can be achieved when procedural domain knowledge is used to solve planning problems with large plan length.",
    "cited_by_count": 62,
    "openalex_id": "https://openalex.org/W2154595228",
    "type": "article"
  },
  {
    "title": "Arithmetic, first-order logic, and counting quantifiers",
    "doi": "https://doi.org/10.1145/1071596.1071602",
    "publication_date": "2005-07-01",
    "publication_year": 2005,
    "authors": "Nicole Schweikardt",
    "corresponding_authors": "Nicole Schweikardt",
    "abstract": "This article gives a thorough overview of what is known about first-order logic with counting quantifiers and with arithmetic predicates. As a main theorem we show that Presburger arithmetic is closed under unary counting quantifiers. Precisely, this means that for every first-order formula φ( y , z ) over the signature {&lt;,+} there is a first-order formula ψ( x , z ) which expresses over the structure 〈ℕ,&lt;,+〉 (respectively, over initial segments of this structure) that the variable x is interpreted exactly by the number of possible interpretations of the variable y for which the formula φ( y , z ) is satisfied. Applying this theorem, we obtain an easy proof of Ruhl's result that reachability (and similarly, connectivity) in finite graphs is not expressible in first-order logic with unary counting quantifiers and addition. Furthermore, the above result on Presburger arithmetic helps to show the failure of a particular version of the Crane Beach conjecture.",
    "cited_by_count": 61,
    "openalex_id": "https://openalex.org/W1988899858",
    "type": "article"
  },
  {
    "title": "Results on the quantitative μ-calculus <i>qM</i> μ",
    "doi": "https://doi.org/10.1145/1182613.1182616",
    "publication_date": "2007-01-01",
    "publication_year": 2007,
    "authors": "Annabelle McIver; Carroll Morgan",
    "corresponding_authors": "",
    "abstract": "The μ-calculus is a powerful tool for specifying and verifying transition systems, including those with both demonic (universal) and angelic (existential) choice; its quantitative generalization qM μ extends to include probabilistic choice.We make two major contributions to the theory of such systems. The first is to show that for a finite-state system, the logical interpretation of qM μ, via fixed points in a domain of real-valued functions into [0, 1], is equivalent to an operational interpretation given as a turn-based gambling game between two players.The second contribution is to show that each player in the gambling game has an optimal memoryless strategy---that is, a strategy which is independent of the game's history, and with which a player can achieve his optimal expected reward however his opponent chooses to play. Moreover, since qM μ is expressive enough to encode stochastic parity games , our result implies the existence of memoryless strategies in that framework, as well.As an additional feature, we include an extensive case study demonstrating the aforementioned duality between games and logic. Among other things, it shows that the use of algorithmic verification techniques is mathematically justified in the practical computation of probabilistic system properties.",
    "cited_by_count": 61,
    "openalex_id": "https://openalex.org/W2091027967",
    "type": "article"
  },
  {
    "title": "Predicate abstraction with indexed predicates",
    "doi": "https://doi.org/10.1145/1297658.1297662",
    "publication_date": "2007-12-01",
    "publication_year": 2007,
    "authors": "Shuvendu K. Lahiri; Randal E. Bryant",
    "corresponding_authors": "",
    "abstract": "Predicate abstraction provides a powerful tool for verifying properties of infinite-state systems using a combination of a decision procedure for a subset of first-order logic and symbolic methods originally developed for finite-state model checking. We consider models containing first-order state variables, where the system state includes mutable functions and predicates. Such a model can describe systems containing arbitrarily large memories, buffers, and arrays of identical processes. We describe a form of predicate abstraction that constructs a formula over a set of universally quantified variables to describe invariant properties of the first-order state variables. We provide a formal justification of the soundness of our approach and describe how it has been used to verify several hardware and software designs, including a directory-based cache coherence protocol.",
    "cited_by_count": 61,
    "openalex_id": "https://openalex.org/W2151643528",
    "type": "article"
  },
  {
    "title": "A sequent calculus and a theorem prover for standard conditional logics",
    "doi": "https://doi.org/10.1145/1276920.1276924",
    "publication_date": "2007-08-01",
    "publication_year": 2007,
    "authors": "Nicola Olivetti; Gian Luca Pozzato; Camilla Schwind",
    "corresponding_authors": "",
    "abstract": "In this paper we present a cut-free sequent calculus, called SeqS, for some standard conditional logics. The calculus uses labels and transition formulas and can be used to prove decidability and space complexity bounds for the respective logics. We also show that these calculi can be the base for uniform proof systems. Moreover, we present CondLean, a theorem prover in Prolog for these calculi.",
    "cited_by_count": 60,
    "openalex_id": "https://openalex.org/W2097313873",
    "type": "article"
  },
  {
    "title": "Ordinary interactive small-step algorithms, I",
    "doi": "https://doi.org/10.1145/1131313.1131320",
    "publication_date": "2006-04-01",
    "publication_year": 2006,
    "authors": "Andreas Blass; Yuri Gurevich",
    "corresponding_authors": "",
    "abstract": "This is the first in a series of articles extending the abstract state machine thesis---that arbitrary algorithms are behaviorally equivalent to abstract state machines---to algorithms that can interact with their environments during a step rather than only between steps. In the present work, we describe, by means of suitable postulates, those interactive algorithms that (1) proceed in discrete, global steps; (2) perform only a bounded amount of work in each step; (3) use only such information from the environment as can be regarded as answers to queries; and (4) never complete a step until all queries from that step have been answered.We indicate how a great many sorts of interaction meet these requirements. We also discuss in detail the structure of queries and replies and the appropriate definition of equivalence of algorithms.Finally, motivated by our considerations concerning queries, we discuss a generalization of first-order logic in which the arguments of function and relation symbols are not merely tuples of elements but orbits of such tuples under groups of permutations of the argument places.",
    "cited_by_count": 58,
    "openalex_id": "https://openalex.org/W2142611800",
    "type": "article"
  },
  {
    "title": "Automated termination proofs for logic programs by term rewriting",
    "doi": "https://doi.org/10.1145/1614431.1614433",
    "publication_date": "2009-10-01",
    "publication_year": 2009,
    "authors": "Peter Schneider–Kamp; Jürgen Giesl; Alexander Serebrenik; René Thiemann",
    "corresponding_authors": "",
    "abstract": "There are two kinds of approaches for termination analysis of logic programs: “transformational” and “direct” ones. Direct approaches prove termination directly on the basis of the logic program. Transformational approaches transform a logic program into a Term Rewrite System (TRS) and then analyze termination of the resulting TRS instead. Thus, transformational approaches make all methods previously developed for TRSs available for logic programs as well. However, the applicability of most existing transformations is quite restricted, as they can only be used for certain subclasses of logic programs. (Most of them are restricted to well-moded programs.) In this article we improve these transformations such that they become applicable for any definite logic program. To simulate the behavior of logic programs by TRSs, we slightly modify the notion of rewriting by permitting infinite terms. We show that our transformation results in TRSs which are indeed suitable for automated termination analysis. In contrast to most other methods for termination of logic programs, our technique is also sound for logic programming without occur check , which is typically used in practice. We implemented our approach in the termination prover AProVE and successfully evaluated it on a large collection of examples.",
    "cited_by_count": 49,
    "openalex_id": "https://openalex.org/W2137327104",
    "type": "article"
  },
  {
    "title": "FDNC",
    "doi": "https://doi.org/10.1145/1656242.1656249",
    "publication_date": "2010-01-01",
    "publication_year": 2010,
    "authors": "Thomas Eiter; Mantas Šimkus",
    "corresponding_authors": "",
    "abstract": "We present the class FDNC of logic programs that allows for function symbols (F), disjunction (D), nonmonotonic negation under the answer set semantics (N), and constraints (C), while still retaining the decidability of the standard reasoning tasks. Thanks to these features, FDNC programs are a powerful formalism for rule-based modeling of applications with potentially infinite processes and objects, and which allows also for common-sense reasoning in this context. This is evidenced, for instance, by tasks in reasoning about actions and planning: brave and open queries over FDNC programs capture the well-known problems of plan existence and secure (conformant) plan existence, respectively, in transition-based actions domains. As for reasoning from FDNC programs, we show that consistency checking and brave/cautious reasoning tasks are ExpTime-complete in general, but have lower complexity under syntactic restrictions that give rise to a family of program classes. Furthermore, we also determine the complexity of open queries (i.e., with answer variables), for which deciding non-empty answers is shown to be ExpSpace -complete under cautious entailment. Furthermore, we present algorithms for all reasoning tasks that are worst-case optimal. The majority of them resorts to a finite representation of the stable models of an FDNC program that employs maximal founded sets of knots, which are labeled trees of depth at most 1 from which each stable model can be reconstructed. Due to this property, reasoning over FDNC programs can in many cases be reduced to reasoning from knots. Once the knot-representation for a program is derived (which can be done off-line), several reasoning tasks are not more expensive than in the function-free case, and some are even feasible in polynomial time. This knowledge compilation technique paves the way to potentially more efficient online reasoning methods not only for FDNC, but also for other formalisms.",
    "cited_by_count": 48,
    "openalex_id": "https://openalex.org/W2051741066",
    "type": "article"
  },
  {
    "title": "An inclusion theorem for defeasible logics",
    "doi": "https://doi.org/10.1145/1838552.1838558",
    "publication_date": "2010-10-01",
    "publication_year": 2010,
    "authors": "David P. Billington; Grigoris Antoniou; Guido Governatori; Michael J. Maher",
    "corresponding_authors": "",
    "abstract": "Defeasible reasoning is a computationally simple nonmonotonic reasoning approach that has attracted significant theoretical and practical attention. It comprises a family of logics that capture different intuitions, among them ambiguity propagation versus ambiguity blocking, and the adoption or rejection of team defeat. This article provides a compact presentation of the defeasible logic variants, and derives an inclusion theorem which shows that different notions of provability in defeasible logic form a chain of levels of proof.",
    "cited_by_count": 45,
    "openalex_id": "https://openalex.org/W2094817192",
    "type": "article"
  },
  {
    "title": "On the Inference of Resource Usage Upper and Lower Bounds",
    "doi": "https://doi.org/10.1145/2499937.2499943",
    "publication_date": "2013-08-01",
    "publication_year": 2013,
    "authors": "Elvira Albert; Samir Genaim; Abu Naser Masud",
    "corresponding_authors": "",
    "abstract": "Cost analysis aims at determining the amount of resources required to run a program in terms of its input data sizes. The most challenging step is to infer the cost of executing the loops in the program. This requires bounding the number of iterations of each loop and finding tight bounds for the cost of each of its iterations. This article presents a novel approach to infer upper and lower bounds from cost relations . These relations are an extended form of standard recurrence equations that can be nondeterministic, contain inexact size constraints and have multiple arguments that increase and/or decrease. We propose novel techniques to automatically transform cost relations into worst-case and best-case deterministic one-argument recurrence relations. The solution of each recursive relation provides a precise upper-bound and lower-bound for executing a corresponding loop in the program. Importantly, since the approach is developed at the level of the cost equations, our techniques are programming language independent.",
    "cited_by_count": 42,
    "openalex_id": "https://openalex.org/W1992296379",
    "type": "article"
  },
  {
    "title": "Parity Games and Propositional Proofs",
    "doi": "https://doi.org/10.1145/2579822",
    "publication_date": "2014-04-01",
    "publication_year": 2014,
    "authors": "Arnold Beckmann; Pavel Pudlák; Neil Thapen",
    "corresponding_authors": "",
    "abstract": "A propositional proof system is weakly automatizable if there is a polynomial time algorithm that separates satisfiable formulas from formulas that have a short refutation in the system, with respect to a given length bound. We show that if the resolution proof system is weakly automatizable, then parity games can be decided in polynomial time. We give simple proofs that the same holds for depth-1 propositional calculus (where resolution has depth 0) with respect to mean payoff and simple stochastic games. We define a new type of combinatorial game and prove that resolution is weakly automatizable if and only if one can separate, by a set decidable in polynomial time, the games in which the first player has a positional winning strategy from the games in which the second player has a positional winning strategy. Our main technique is to show that a suitable weak bounded arithmetic theory proves that both players in a game cannot simultaneously have a winning strategy, and then to translate this proof into propositional form.",
    "cited_by_count": 41,
    "openalex_id": "https://openalex.org/W1966303481",
    "type": "article"
  },
  {
    "title": "Hierarchies in Dependence Logic",
    "doi": "https://doi.org/10.1145/2362355.2362359",
    "publication_date": "2012-10-01",
    "publication_year": 2012,
    "authors": "Arnaud Durand; Juha Kontinen",
    "corresponding_authors": "",
    "abstract": "We study fragments D ( k ∀) and D ( k -dep) of dependence logic defined either by restricting the number k of universal quantifiers or the width of dependence atoms in formulas. We find the sublogics of existential second-order logic corresponding to these fragments of dependence logic. We also show that, for any fixed signature, the fragments D ( k ∀) give rise to an infinite hierarchy with respect to expressive power. On the other hand, for the fragments D ( k -dep), a hierarchy theorem is otained only in the case the signature is also allowed to vary. For any fixed signature, this question is open and is related to the so-called Spectrum Arity Hierarchy Conjecture.",
    "cited_by_count": 40,
    "openalex_id": "https://openalex.org/W2079986269",
    "type": "article"
  },
  {
    "title": "Partial-Observation Stochastic Games",
    "doi": "https://doi.org/10.1145/2579821",
    "publication_date": "2014-04-01",
    "publication_year": 2014,
    "authors": "Krishnendu Chatterjee; Laurent Doyen",
    "corresponding_authors": "",
    "abstract": "In two-player finite-state stochastic games of partial observation on graphs, in every state of the graph, the players simultaneously choose an action, and their joint actions determine a probability distribution over the successor states. The game is played for infinitely many rounds and thus the players construct an infinite path in the graph. We consider reachability objectives where the first player tries to ensure a target state to be visited almost-surely (i.e., with probability 1) or positively (i.e., with positive probability), no matter the strategy of the second player. We classify such games according to the information and to the power of randomization available to the players. On the basis of information, the game can be one-sided with either ( a ) player 1, or ( b ) player 2 having partial observation (and the other player has perfect observation), or two-sided with ( c ) both players having partial observation. On the basis of randomization, ( a ) the players may not be allowed to use randomization (pure strategies), or ( b ) they may choose a probability distribution over actions but the actual random choice is external and not visible to the player (actions invisible), or ( c ) they may use full randomization. Our main results for pure strategies are as follows: (1) For one-sided games with player 2 having perfect observation we show that (in contrast to full randomized strategies) belief-based (subset-construction based) strategies are not sufficient, and we present an exponential upper bound on memory both for almost-sure and positive winning strategies; we show that the problem of deciding the existence of almost-sure and positive winning strategies for player 1 is EXPTIME-complete and present symbolic algorithms that avoid the explicit exponential construction. (2) For one-sided games with player 1 having perfect observation we show that nonelementary memory is both necessary and sufficient for both almost-sure and positive winning strategies. (3) We show that for the general (two-sided) case finite-memory strategies are sufficient for both positive and almost-sure winning, and at least nonelementary memory is required. We establish the equivalence of the almost-sure winning problems for pure strategies and for randomized strategies with actions invisible. Our equivalence result exhibit serious flaws in previous results of the literature: we show a nonelementary memory lower bound for almost-sure winning whereas an exponential upper bound was previously claimed.",
    "cited_by_count": 38,
    "openalex_id": "https://openalex.org/W2048183302",
    "type": "article"
  },
  {
    "title": "Linear-Logic Based Analysis of Constraint Handling Rules with Disjunction",
    "doi": "https://doi.org/10.1145/2422085.2422086",
    "publication_date": "2013-02-01",
    "publication_year": 2013,
    "authors": "Hariolf Betz; Thom Frühwirth",
    "corresponding_authors": "",
    "abstract": "Constraint Handling Rules (CHR) is a declarative rule-based programming language that has cut out its niche over the course of the last 20 years. It generalizes concurrent constraint logic programming to multiple heads, thus closing the gap to multiset transformation systems. Its popular extension CHR with Disjunction (CHR∨) is a multiparadigm declarative programming language that allows embedding of Horn programs with SLD resolution. We analyze the assets and the limitations of the classical declarative semantics of CHR∨ and highlight its natural relationship with linear-logic. We furthermore develop two linear-logic semantics for CHR∨ that differ in the reasoning domain for which they are instrumental. We show their idempotence and their soundness and completeness with respect to the operational semantics. We show how to apply the linear-logic semantics to decide program properties and to reason about operational equivalence of CHR∨ programs.",
    "cited_by_count": 38,
    "openalex_id": "https://openalex.org/W2149254449",
    "type": "article"
  },
  {
    "title": "Temporal Specifications with Accumulative Values",
    "doi": "https://doi.org/10.1145/2629686",
    "publication_date": "2014-07-29",
    "publication_year": 2014,
    "authors": "Udi Boker; Krishnendu Chatterjee; Thomas A. Henzinger; Orna Kupferman",
    "corresponding_authors": "",
    "abstract": "Recently, there has been an effort to add quantitative objectives to formal verification and synthesis. We introduce and investigate the extension of temporal logics with quantitative atomic assertions. At the heart of quantitative objectives lies the accumulation of values along a computation. It is often the accumulated sum, as with energy objectives, or the accumulated average, as with mean-payoff objectives. We investigate the extension of temporal logics with the prefix-accumulation assertions Sum( v ) ≥ c and Avg( v ) ≥ c , where v is a numeric (or Boolean) variable of the system, c is a constant rational number, and Sum( v ) and Avg( v ) denote the accumulated sum and average of the values of v from the beginning of the computation up to the current point in time. We also allow the path-accumulation assertions LimInfAvg( v )≥ c and LimSupAvg( v )≥ c , referring to the average value along an entire infinite computation. We study the border of decidability for such quantitative extensions of various temporal logics. In particular, we show that extending the fragment of CTL that has only the EX, EF, AX, and AG temporal modalities with both prefix-accumulation assertions, or extending LTL with both path-accumulation assertions, results in temporal logics whose model-checking problem is decidable. Moreover, the prefix-accumulation assertions may be generalized with “controlled accumulation,” allowing, for example, to specify constraints on the average waiting time between a request and a grant. On the negative side, we show that this branching-time logic is, in a sense, the maximal logic with one or both of the prefix-accumulation assertions that permits a decidable model-checking procedure. Extending a temporal logic that has the EG or EU modalities, such as CTL or LTL, makes the problem undecidable.",
    "cited_by_count": 38,
    "openalex_id": "https://openalex.org/W2160029445",
    "type": "article"
  },
  {
    "title": "Symbolic Bisimulation for Quantum Processes",
    "doi": "https://doi.org/10.1145/2579818",
    "publication_date": "2014-04-01",
    "publication_year": 2014,
    "authors": "Yuan Feng; Yuxin Deng; Mingsheng Ying",
    "corresponding_authors": "",
    "abstract": "With the previous notions of bisimulation presented in the literature, to check if two quantum processes are bisimilar, we have to instantiate their free quantum variables with arbitrary quantum states, and verify the bisimilarity of the resulting configurations. This makes checking bisimilarity infeasible from an algorithmic point of view, because quantum states constitute a continuum. In this article, we introduce a symbolic operational semantics for quantum processes directly at the quantum operation level, which allows us to describe the bisimulation between quantum processes without resorting to quantum states. We show that the symbolic bisimulation defined here is equivalent to the open bisimulation for quantum processes in previous work, when strong bisimulations are considered. An algorithm for checking symbolic ground bisimilarity is presented. We also give a modal characterisation for quantum bisimilarity based on an extension of Hennessy-Milner logic to quantum processes.",
    "cited_by_count": 37,
    "openalex_id": "https://openalex.org/W2044210134",
    "type": "article"
  },
  {
    "title": "Model-Checking Linear-Time Properties of Quantum Systems",
    "doi": "https://doi.org/10.1145/2629680",
    "publication_date": "2014-07-08",
    "publication_year": 2014,
    "authors": "Mingsheng Ying; Yangjia Li; Nengkun Yu; Yuan Feng",
    "corresponding_authors": "",
    "abstract": "We define a formal framework for reasoning about linear-time properties of quantum systems in which quantum automata are employed in the modeling of systems and certain (closed) subspaces of state Hilbert spaces are used as the atomic propositions about the behavior of systems. We provide an algorithm for verifying invariants of quantum automata. Then, an automata-based model-checking technique is generalized for the verification of safety properties recognizable by reversible automata and ω--properties recognizable by reversible Büchi automata.",
    "cited_by_count": 36,
    "openalex_id": "https://openalex.org/W1988413534",
    "type": "article"
  },
  {
    "title": "Verifying Procedural Programs via Constrained Rewriting Induction",
    "doi": "https://doi.org/10.1145/3060143",
    "publication_date": "2017-04-30",
    "publication_year": 2017,
    "authors": "Carsten Fuhs; Cynthia Kop; Naoki Nishida",
    "corresponding_authors": "",
    "abstract": "This article aims to develop a verification method for procedural programs via a transformation into logically constrained term rewriting systems (LCTRSs). To this end, we extend transformation methods based on integer term rewriting systems to handle arbitrary data types, global variables, function calls, and arrays, and to encode safety checks. Then we adapt existing rewriting induction methods to LCTRSs and propose a simple yet effective method to generalize equations. We show that we can automatically verify memory safety and prove correctness of realistic functions. Our approach proves equivalence between two implementations; thus, in contrast to other works, we do not require an explicit specification in a separate specification language.",
    "cited_by_count": 36,
    "openalex_id": "https://openalex.org/W2964206513",
    "type": "article"
  },
  {
    "title": "From Small Space to Small Width in Resolution",
    "doi": "https://doi.org/10.1145/2746339",
    "publication_date": "2015-07-14",
    "publication_year": 2015,
    "authors": "Yuval Filmus; Massimo Lauria; Mladen Mikša; Jakob Nordström; Marc Vinyals",
    "corresponding_authors": "",
    "abstract": "In 2003, Atserias and Dalmau resolved a major open question about the resolution proof system by establishing that the space complexity of a Conjunctive Normal Form (CNF) formula is always an upper bound on the width needed to refute the formula. Their proof is beautiful but uses a nonconstructive argument based on Ehrenfeucht-Fraïssé games. We give an alternative, more explicit, proof that works by simple syntactic manipulations of resolution refutations. As a by-product, we develop a “black-box” technique for proving space lower bounds via a “static” complexity measure that works against any resolution refutation—previous techniques have been inherently adaptive. We conclude by showing that the related question for polynomial calculus (i.e., whether space is an upper bound on degree) seems unlikely to be resolvable by similar methods.",
    "cited_by_count": 35,
    "openalex_id": "https://openalex.org/W2150406686",
    "type": "article"
  },
  {
    "title": "Linear Logic Properly Displayed",
    "doi": "https://doi.org/10.1145/3570919",
    "publication_date": "2022-11-07",
    "publication_year": 2022,
    "authors": "Giuseppe Greco; Alessandra Palmigiano",
    "corresponding_authors": "",
    "abstract": "We introduce proper display calculi for intuitionistic, bi-intuitionistic and classical linear logics with exponentials, which are sound, complete, conservative, and enjoy cut elimination and subformula property. Based on the same design, we introduce a variant of Lambek calculus with exponentials, aimed at capturing the controlled application of exchange and associativity. Properness (i.e., closure under uniform substitution of all parametric parts in rules) is the main technical novelty of the present proposal, allowing both for the smoothest proof of cut elimination and for the development of an overarching and modular treatment for a vast class of axiomatic extensions and expansions of intuitionistic, bi-intuitionistic, and classical linear logics with exponentials. Our proposal builds on an algebraic and order-theoretic analysis of linear logic and applies the guidelines of the multi-type methodology in the design of display calculi.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W2565548059",
    "type": "article"
  },
  {
    "title": "An Axiomatic Theory for Reversible Computation",
    "doi": "https://doi.org/10.1145/3648474",
    "publication_date": "2024-02-19",
    "publication_year": 2024,
    "authors": "Ivan Lanese; Iain Phillips; Irek Ulidowski",
    "corresponding_authors": "",
    "abstract": "Undoing computations of a concurrent system is beneficial in many situations, such as in reversible debugging of multi-threaded programs and in recovery from errors due to optimistic execution in parallel discrete event simulation. A number of approaches have been proposed for how to reverse formal models of concurrent computation, including process calculi such as CCS, languages like Erlang, and abstract models such as prime event structures and occurrence nets. However, it has not been settled as to what properties a reversible system should enjoy, nor how the various properties that have been suggested, such as the parabolic lemma and the causal-consistency property, are related. We contribute to a solution to these issues by using a generic labelled transition system equipped with a relation capturing whether transitions are independent to explore the implications between various reversibility properties. In particular, we show how all properties we consider are derivable from a set of axioms. Our intention is that when establishing properties of some formalism, it will be easier to verify the axioms rather than proving properties such as the parabolic lemma directly. We also introduce two new properties related to causal-consistent reversibility, namely causal liveness and causal safety, stating, respectively, that an action can be undone if (causal liveness) and only if (causal safety) it is independent from all of the following actions. These properties come in three flavours: defined in terms of independent transitions, independent events, or via an ordering on events. Both causal liveness and causal safety are derivable from our axioms.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4391941157",
    "type": "article"
  },
  {
    "title": "Probabilistic Temporal Reasoning using Superposition Semantics",
    "doi": "https://doi.org/10.1145/3714427",
    "publication_date": "2025-01-21",
    "publication_year": 2025,
    "authors": "Fabrizio Maria Maggi; Marco Montali; Rafael Peñaloza",
    "corresponding_authors": "",
    "abstract": "Temporal logics over finite traces have recently seen wide application in a number of areas, from business process modelling, monitoring, and mining to planning and decision making. However, real-life dynamic systems contain a degree of uncertainty which cannot be handled with classical logics. We thus propose a new probabilistic temporal logic over finite traces using superposition semantics, where all possible evolutions are possible, until observed. We study the properties of the logic and provide automata-based mechanisms for deriving probabilistic inferences from its formulas. We then study a fragment of the logic with better computational properties. Notably, formulas in this fragment can be discovered from event log data using off-the-shelf existing declarative process discovery techniques.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4406671867",
    "type": "article"
  },
  {
    "title": "Hypersequent calculi for propositional default logics",
    "doi": "https://doi.org/10.1145/3725849",
    "publication_date": "2025-03-25",
    "publication_year": 2025,
    "authors": "Mario Piazza; Andrea Sabatini",
    "corresponding_authors": "",
    "abstract": "In this paper, we investigate default reasoning from a structural proof-theoretic perspective. We introduce hybrid hypersequent calculi for propositional default logics, where extra-logical rules directly capture default rules, while parallel composition of sequents and antisequents formalizes contrary updating on the conclusions of extra-logical rules. We establish the admissibility of structural rules and the invertibility of logical rules, showing that cut-free proofs exhibit a weakened form of analyticity. Next, we prove that specific hybrid hypersequent calculi are sound and weakly complete with respect to credulous consequence based on Łukaszewicz extensions. Lastly, we propose a hypersequent-based decision method for skeptical consequence which circumvents the need for early computation of all extensions.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4408807496",
    "type": "article"
  },
  {
    "title": "Closing star-free closure",
    "doi": "https://doi.org/10.1145/3733831",
    "publication_date": "2025-05-06",
    "publication_year": 2025,
    "authors": "Thomas Place; Marc Zeitoun",
    "corresponding_authors": "",
    "abstract": "We introduce an operator on classes of regular languages, the star-free closure. Our motivation is to generalize standard results of automata theory within a unified framework. Given an arbitrary input class \\(\\mathscr{C}\\) , the star-free closure operator outputs the least class closed under Boolean operations and language concatenation, and containing all languages of \\(\\mathscr{C}\\) as well as all finite languages. We establish several equivalent characterizations of star-free closure: in terms of regular expressions, first-order logic, pure future and future-past temporal logic, and recognition by finite monoids. A key ingredient is that star-free closure coincides with another closure operator, defined in terms of regular operations where Kleene stars are allowed in restricted contexts. A consequence of this first result is that we can decide membership of a regular language in the star-free closure of a class whose separation problem is decidable. Moreover, we prove that separation itself is decidable for the star-free closure of any finite class, and of any class of group languages having itself decidable separation (plus mild additional properties). We actually show decidability of a stronger property, called covering.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4410119689",
    "type": "article"
  },
  {
    "title": "Centralized vs Decentralized Monitors for Hyperproperties",
    "doi": "https://doi.org/10.1145/3767738",
    "publication_date": "2025-09-16",
    "publication_year": 2025,
    "authors": "Luca Aceto; Antonis Achilleos; Elli Anastasiadi; Adrian Francalanza; Daniele Gorla; Jana Wagemaker",
    "corresponding_authors": "",
    "abstract": "This paper focuses on the runtime verification of hyperproperties expressed in Hyper-recHML, an expressive yet simple logic for describing properties of sets of traces. To this end, we consider a simple language of monitors that observe sets of system executions and report verdicts w.r.t. a given Hyper-recHML formula. We first employ a unique omniscient monitor that centrally observes all system traces. Since centralised monitors are not ideal for distributed settings, we also provide a language for decentralized monitors, where each trace has a dedicated monitor; these monitors yield a unique verdict by communicating their observations to one another. For both the centralized and the decentralized settings, we provide a synthesis procedure that, given a formula, yields a monitor that is correct (i.e., sound and violation complete). A key step in proving the correctness of the synthesis for decentralized monitors is a result showing that, for each formula, the synthesized centralized monitor and its corresponding decentralized one are weakly bisimilar for a suitable notion of weak bisimulation.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4414266735",
    "type": "article"
  },
  {
    "title": "Boolean satisfiability with transitivity constraints",
    "doi": "https://doi.org/10.1145/566385.566390",
    "publication_date": "2002-10-01",
    "publication_year": 2002,
    "authors": "Randal E. Bryant; Miroslav N. Velev",
    "corresponding_authors": "",
    "abstract": "We consider a variant of the Boolean satisfiability problem where a subset ε of the propositional variables appearing in formula F sat encode a symmetric, transitive, binary relation over N elements. Each of these relational variables, e i,j , for 1 ≤ i &lt; j ≤ N , expresses whether or not the relation holds between elements i and j . The task is to either find a satisfying assignment to F sat that also satisfies all transitivity constraints over the relational variables (e.g., e 1,2 ∧ e 2,3 ⇒ e 1,3 ), or to prove that no such assignment exists. Solving this satisfiability problem is the final and most difficult step in our decision procedure for a logic of equality with uninterpreted functions. This procedure forms the core of our tool for verifying pipelined microprocessors.To use a conventional Boolean satisfiability checker, we augment the set of clauses expressing F sat with clauses expressing the transitivity constraints. We consider methods to reduce the number of such clauses based on the sparse structure of the relational variables.To use Ordered Binary Decision Diagrams (OBDDs), we show that for some sets ε, the OBDD representation of the transitivity constraints has exponential size for all possible variable orderings. By considering only those relational variables that occur in the OBDD representation of F sat , our experiments show that we can readily construct an OBDD representation of the relevant transitivity constraints and thus solve the constrained satisfiability problem.",
    "cited_by_count": 65,
    "openalex_id": "https://openalex.org/W2104115705",
    "type": "article"
  },
  {
    "title": "Induction from answer sets in nonmonotonic logic programs",
    "doi": "https://doi.org/10.1145/1055686.1055687",
    "publication_date": "2005-04-01",
    "publication_year": 2005,
    "authors": "Chiaki Sakama",
    "corresponding_authors": "Chiaki Sakama",
    "abstract": "Inductive logic programming (ILP) realizes inductive machine learning in computational logic. However, the present ILP mostly handles classical clausal programs, especially Horn logic programs, and has limited applications to learning nonmonotonic logic programs . This article studies a method for realizing induction in nonmonotonic logic programs. We consider an extended logic program as a background theory, and introduce techniques for inducing new rules using answer sets of the program. The produced new rules explain positive/negative examples in the context of inductive logic programming. The proposed methods extend the present ILP techniques to a syntactically and semantically richer framework, and contribute to a theory of nonmonotonic ILP.",
    "cited_by_count": 60,
    "openalex_id": "https://openalex.org/W2149404336",
    "type": "article"
  },
  {
    "title": "Logics of metric spaces",
    "doi": "https://doi.org/10.1145/635499.635504",
    "publication_date": "2003-04-01",
    "publication_year": 2003,
    "authors": "Oliver Kutz; Frank Wolter; Holger Sturm; Norihiro Suzuki; Michael Zakharyaschev",
    "corresponding_authors": "",
    "abstract": "We investigate the expressive power and computational properties of two different types of languages intended for speaking about distances. First, we consider a first-order language FM the two-variable fragment of which turns out to be undecidable in the class of distance spaces validating the triangular inequality as well as in the class of all metric spaces. Yet, this two-variable fragment is decidable in various weaker classes of distance spaces. Second, we introduce a variable-free modal language MS that, when interpreted in metric spaces, has the same expressive power as the two-variable fragment of FM. We determine natural and expressive fragments of MS which are decidable in various classes of distance spaces validating the triangular inequality, in particular, the class of all metric spaces.",
    "cited_by_count": 57,
    "openalex_id": "https://openalex.org/W2055256635",
    "type": "article"
  },
  {
    "title": "Monodic temporal resolution",
    "doi": "https://doi.org/10.1145/1119439.1119443",
    "publication_date": "2006-01-01",
    "publication_year": 2006,
    "authors": "Alexander Degtyarev; Michael Fisher; Boris Konev",
    "corresponding_authors": "",
    "abstract": "Until recently, First-Order Temporal Logic (FOTL) has been only partially understood. While it is well known that the full logic has no finite axiomatisation, a more detailed analysis of fragments of the logic was not previously available. However, a breakthrough by Hodkinson et al., identifying a finitely axiomatisable fragment, termed the monodic fragment, has led to improved understanding of FOTL. Yet, in order to utilise these theoretical advances, it is important to have appropriate proof techniques for this monodic fragment.In this paper, we modify and extend the clausal temporal resolution technique, originally developed for propositional temporal logics, to enable its use in such monodic fragments. We develop a specific normal form for monodic formulae in FOTL, and provide a complete resolution calculus for formulae in this form. Not only is this clausal resolution technique useful as a practical proof technique for certain monodic classes, but the use of this approach provides us with increased understanding of the monodic fragment. In particular, we here show how several features of monodic FOTL can be established as corollaries of the completeness result for the clausal temporal resolution method. These include definitions of new decidable monodic classes, simplification of existing monodic classes by reductions, and completeness of clausal temporal resolution in the case of monodic logics with expanding domains, a case with much significance in both theory and practice.",
    "cited_by_count": 49,
    "openalex_id": "https://openalex.org/W2111581283",
    "type": "article"
  },
  {
    "title": "Abstract state machines capture parallel algorithms",
    "doi": "https://doi.org/10.1145/1352582.1352587",
    "publication_date": "2008-06-01",
    "publication_year": 2008,
    "authors": "Andreas Blass; Yuri Gurevich",
    "corresponding_authors": "",
    "abstract": "We consider parallel algorithms working in sequential global time, for example, circuits or parallel random access machines (PRAMs). Parallel abstract state machines (parallel ASMs) are such parallel algorithms, and the parallel ASM thesis asserts that every parallel algorithm is behaviorally equivalent to a parallel ASM. In an earlier article, we axiomatized parallel algorithms, proved the ASM thesis, and proved that every parallel ASM satisfies the axioms. It turned out that we were too timid in formulating the axioms; they did not allow a parallel algorithm to create components on the fly. This restriction did not hinder us from proving that the usual parallel models, like circuits or PRAMs or even alternating Turing machines, satisfy the postulates. But it resulted in an error in our attempt to prove that parallel ASMs always satisfy the postulates. To correct the error, we liberalize our axioms and allow on-the-fly creation of new parallel components. We believe that the improved axioms accurately express what parallel algorithms ought to be. We prove the parallel thesis for the new, corrected notion of parallel algorithms, and we check that parallel ASMs satisfy the new axioms.",
    "cited_by_count": 49,
    "openalex_id": "https://openalex.org/W2139801570",
    "type": "article"
  },
  {
    "title": "Undecidability of the unification and admissibility problems for modal and description logics",
    "doi": "https://doi.org/10.1145/1380572.1380574",
    "publication_date": "2008-08-01",
    "publication_year": 2008,
    "authors": "Frank Wolter; Michael Zakharyaschev",
    "corresponding_authors": "",
    "abstract": "We show that the unification problem “is there a substitution instance of a given formula that is provable in a given logic?” is undecidable for basic modal logics K and K4 extended with the universal modality. It follows that the admissibility problem for inference rules is undecidable for these logics as well. These are the first examples of standard decidable modal logics for which the unification and admissibility problems are undecidable. We also prove undecidability of the unification and admissibility problems for K and K4 with at least two modal operators and nominals (instead of the universal modality), thereby showing that these problems are undecidable for basic hybrid logics. Recently, unification has been introduced as an important reasoning service for description logics. The undecidability proof for K with nominals can be used to show the undecidability of unification for Boolean description logics with nominals (such as ALCO and SHIQO). The undecidability proof for K with the universal modality can be used to show that the unification problem relative to role boxes is undecidable for Boolean description logics with transitive roles, inverse roles, and role hierarchies (such as SHI and SHIQ).",
    "cited_by_count": 48,
    "openalex_id": "https://openalex.org/W2021587896",
    "type": "article"
  },
  {
    "title": "Regular tree languages definable in FO and in FO <sub> <i>mod</i> </sub>",
    "doi": "https://doi.org/10.1145/1614431.1614435",
    "publication_date": "2009-10-01",
    "publication_year": 2009,
    "authors": "Michael Benedikt; Luc Segoufin",
    "corresponding_authors": "",
    "abstract": "We consider regular languages of labeled trees. We give an effective characterization of the regular languages over such trees that are definable in first-order logic in the language of labeled graphs. These languages are the analog on trees of the “locally threshold testable” languages on strings. We show that this characterization yields a decision procedure for determining whether a regular tree language is first-order definable: The procedure is polynomial time in the minimal automaton presenting the regular language. We also provide an algorithm for deciding whether a regular language is definable in first-order logic supplemented with modular quantifiers.",
    "cited_by_count": 44,
    "openalex_id": "https://openalex.org/W2012552318",
    "type": "article"
  },
  {
    "title": "Tableau-based decision procedures for logics of strategic ability in multiagent systems",
    "doi": "https://doi.org/10.1145/1614431.1614434",
    "publication_date": "2009-10-01",
    "publication_year": 2009,
    "authors": "Valentin Goranko; Dmitry Shkatov",
    "corresponding_authors": "",
    "abstract": "We develop an incremental tableau-based decision procedure for the alternating-time temporal logic ATL and some of its variants. While running within the theoretically established complexity upper bound, we believe that our tableaux are practically more efficient in the average case than other decision procedures for ATL known so far. Besides, the ease of its adaptation to variants of ATL demonstrates the flexibility of the proposed procedure.",
    "cited_by_count": 43,
    "openalex_id": "https://openalex.org/W2139978539",
    "type": "article"
  },
  {
    "title": "Checking timed Büchi automata emptiness on simulation graphs",
    "doi": "https://doi.org/10.1145/1507244.1507245",
    "publication_date": "2009-04-01",
    "publication_year": 2009,
    "authors": "Stavros Tripakis",
    "corresponding_authors": "Stavros Tripakis",
    "abstract": "Timed automata [Alur and Dill 1994] comprise a popular model for describing real-time and embedded systems and reasoning formally about them. Efficient model-checking algorithms have been developed and implemented in tools such as Kronos [Daws et al. 1996] or Uppaal [Larsen et al. 1997] for checking safety properties on this model, which amounts to reachability. These algorithms use the so-called zone-closed simulation graph, a finite graph that admits efficient representation and has been recently shown to preserve reachability [Bouyer 2004]. Building upon Bouyer [2004] and our previous work [Bouajjani et al. 1997; Tripakis et al. 2005], we show that this graph can also be used for checking liveness properties, in particular, emptiness of timed Büchi automata.",
    "cited_by_count": 43,
    "openalex_id": "https://openalex.org/W2162181585",
    "type": "article"
  },
  {
    "title": "Annotated probabilistic temporal logic",
    "doi": "https://doi.org/10.1145/1877714.1877720",
    "publication_date": "2011-01-01",
    "publication_year": 2011,
    "authors": "Paulo Shakarian; Austin Parker; Gerardo I. Simari; Venkatramana V. S. Subrahmanian",
    "corresponding_authors": "",
    "abstract": "The semantics of most logics of time and probability is given via a probability distribution over threads , where a thread is a structure specifying what will be true at different points in time (in the future). When assessing the probabilities of statements such as “Event a will occur within 5 units of time of event b ,” there are many different semantics possible, even when assessing the truth of this statement within a single thread. We introduce the syntax of annotated probabilistic temporal (APT) logic programs and axiomatically introduce the key notion of a frequency function (for the first time) to capture different types of intrathread reasoning, and then provide a semantics for intrathread and interthread reasoning in APT logic programs parameterized by such frequency functions. We develop a comprehensive set of complexity results for consistency checking and entailment in APT logic programs, together with sound and complete algorithms to check consistency and entailment. The basic algorithms use linear programming, but we then show how to substantially and correctly reduce the sizes of these linear programs to yield better computational properties. We describe a real world application we are developing using APT logic programs.",
    "cited_by_count": 38,
    "openalex_id": "https://openalex.org/W2045914854",
    "type": "article"
  },
  {
    "title": "Enumeration of monadic second-order queries on trees",
    "doi": "https://doi.org/10.1145/2528928",
    "publication_date": "2013-11-01",
    "publication_year": 2013,
    "authors": "Wojciech Kazana; Luc Segoufin",
    "corresponding_authors": "",
    "abstract": "We consider the enumeration problem of Monadic Second-Order (MSO) queries with first-order free variables over trees. In Bagan [2006] it was shown that this problem is in CONSTANT-DELAY lin . An enumeration problem belongs to CONSTANT-DELAY lin if for an input structure of size n it can be solved by: —an O ( n ) precomputation phase building an index structure, —followed by a phase enumerating the answers with no repetition and a constant delay between two consecutive outputs. In this article we give a different proof of this result based on the deterministic factorization forest decomposition theorem of Colcombet [2007].",
    "cited_by_count": 35,
    "openalex_id": "https://openalex.org/W2014984050",
    "type": "article"
  },
  {
    "title": "The NP Search Problems of Frege and Extended Frege Proofs",
    "doi": "https://doi.org/10.1145/3060145",
    "publication_date": "2017-04-30",
    "publication_year": 2017,
    "authors": "Arnold Beckmann; Sam Buss",
    "corresponding_authors": "",
    "abstract": "We study consistency search problems for Frege and extended Frege proofs—namely the NP search problems of finding syntactic errors in Frege and extended Frege proofs of contradictions. The input is a polynomial time function, or an oracle, describing a proof of a contradiction; the output is the location of a syntactic error in the proof. The consistency search problems for Frege and extended Frege systems are shown to be many-one complete for the provably total NP search problems of the second-order bounded arithmetic theories U 1 2 and V 1 2 , respectively.",
    "cited_by_count": 33,
    "openalex_id": "https://openalex.org/W2604582573",
    "type": "article"
  },
  {
    "title": "Structural Focalization",
    "doi": "https://doi.org/10.1145/2629678",
    "publication_date": "2014-07-08",
    "publication_year": 2014,
    "authors": "Robert J. Simmons",
    "corresponding_authors": "Robert J. Simmons",
    "abstract": "Focusing, introduced by Jean-Marc Andreoli in the context of classical linear logic [Andreoli 1992], defines a normal form for sequent calculus derivations that cuts down on the number of possible derivations by eagerly applying invertible rules and grouping sequences of non-invertible rules. A focused sequent calculus is defined relative to some nonfocused sequent calculus; focalization is the property that every nonfocused derivation can be transformed into a focused derivation. In this article, we present a focused sequent calculus for propositional intuitionistic logic and prove the focalization property relative to a standard presentation of propositional intuitionistic logic. Compared to existing approaches, the proof is quite concise, depending only on the internal soundness and completeness of the focused logic. In turn, both of these properties can be established (and mechanically verified) by structural induction in the style of Pfenning's structural cut elimination without the need for any tedious and repetitious invertibility lemmas. The proof of cut admissibility for the focused system, which establishes internal soundness, is not particularly novel. The proof of identity expansion, which establishes internal completeness, is a major contribution of this work.",
    "cited_by_count": 31,
    "openalex_id": "https://openalex.org/W2293455754",
    "type": "article"
  },
  {
    "title": "Faster Statistical Model Checking for Unbounded Temporal Properties",
    "doi": "https://doi.org/10.1145/3060139",
    "publication_date": "2017-04-30",
    "publication_year": 2017,
    "authors": "Przemysław Daca; Thomas A. Henzinger; Jan Křetínský; Tatjana Petrov",
    "corresponding_authors": "",
    "abstract": "We present a new algorithm for the statistical model checking of Markov chains with respect to unbounded temporal properties, including full linear temporal logic. The main idea is that we monitor each simulation run on the fly, in order to detect quickly if a bottom strongly connected component is entered with high probability, in which case the simulation run can be terminated early. As a result, our simulation runs are often much shorter than required by termination bounds that are computed a priori for a desired level of confidence on a large state space. In comparison to previous algorithms for statistical model checking our method is not only faster in many cases but also requires less information about the system, namely, only the minimum transition probability that occurs in the Markov chain. In addition, our method can be generalised to unbounded quantitative properties such as mean-payoff bounds.",
    "cited_by_count": 30,
    "openalex_id": "https://openalex.org/W1748853391",
    "type": "article"
  },
  {
    "title": "Fuzzy Time in Linear Temporal Logic",
    "doi": "https://doi.org/10.1145/2629606",
    "publication_date": "2014-08-01",
    "publication_year": 2014,
    "authors": "Achille Frigeri; Liliana Pasquale; Paola Spoletini",
    "corresponding_authors": "",
    "abstract": "In the past years, the adoption of adaptive systems has increased in many fields of computer science, such as databases and software engineering. These systems are able to automatically react to events by collecting information from the external environment and generating new events. However, the collection of data is often hampered by uncertainty and vagueness. The decision-making mechanism used to produce a reaction is also imprecise and cannot be evaluated in a crisp way, as it depends on vague temporal constraints expressed by humans. Logic has been extensively used as an abstraction to express vagueness in the satisfaction of system properties, as well as to enrich existing modeling formalisms. However, existing attempts to fuzzify the temporal modalities still have some limitations. Existing fuzzy temporal languages are generally obtained from classical temporal logic by replacing classical connectives or propositions with their fuzzy counterparts. Hence, these languages do not allow us to represent temporal properties, such as “almost always” and “soon,” in which the notion of time is inherently fuzzy. To overcome these limitations, we propose a temporal framework, fuzzy-time temporal logic (FTL), to express vagueness on time. This framework formally defines a set of fuzzy temporal modalities that can be customized by choosing a specific semantics for the connectives. The semantics of the language is sound, and the introduced modalities respect a set of mutual relations. We also prove that under the assumption that all events are crisp, FTL reduces to linear temporal logic (LTL). Moreover, for some of the possible fuzzy interpretations of the connectives, we identify adequate sets of temporal operators, from which it is possible to derive all of the other ones.",
    "cited_by_count": 30,
    "openalex_id": "https://openalex.org/W2056186669",
    "type": "article"
  },
  {
    "title": "Horn Fragments of the Halpern-Shoham Interval Temporal Logic",
    "doi": "https://doi.org/10.1145/3105909",
    "publication_date": "2017-07-31",
    "publication_year": 2017,
    "authors": "Davide Bresolin; Agi Kurucz; Emilio Muñoz‐Velasco; Vladislav Ryzhikov; Guido Sciavicco; Michael Zakharyaschev",
    "corresponding_authors": "",
    "abstract": "We investigate the satisfiability problem for Horn fragments of the Halpern-Shoham interval temporal logic depending on the type (box or diamond) of the interval modal operators, the type of the underlying linear order (discrete or dense), and the type of semantics for the interval relations (reflexive or irreflexive). For example, we show that satisfiability of Horn formulas with diamonds is undecidable for any type of linear orders and semantics. On the contrary, satisfiability of Horn formulas with boxes is tractable over both discrete and dense orders under the reflexive semantics and over dense orders under the irreflexive semantics but becomes undecidable over discrete orders under the irreflexive semantics. Satisfiability of binary Horn formulas with both boxes and diamonds is always undecidable under the irreflexive semantics.",
    "cited_by_count": 30,
    "openalex_id": "https://openalex.org/W3124696891",
    "type": "article"
  },
  {
    "title": "Two-Variable Logic with Counting and Trees",
    "doi": "https://doi.org/10.1145/2983622",
    "publication_date": "2016-11-03",
    "publication_year": 2016,
    "authors": "Witold Charatonik; Piotr Witkowski",
    "corresponding_authors": "",
    "abstract": "We consider the two-variable logic with counting quantifiers (C 2 ) interpreted over finite structures that contain two forests of ranked trees. This logic is strictly more expressive than standard C 2 and it is no longer a fragment of first-order logic. In particular, it can express that a structure is a ranked tree, a cycle, or a connected graph of bounded degree. It is also strictly more expressive than first-order logic with two variables and two successor relations of two finite linear orders. We present a decision procedure for the satisfiability problem for this logic. The procedure runs in NE xp T ime , which is optimal since the satisfiability problem for plain C 2 is NE xp T ime -complete.",
    "cited_by_count": 29,
    "openalex_id": "https://openalex.org/W2549023517",
    "type": "article"
  },
  {
    "title": "Complexity of Propositional Logics in Team Semantic",
    "doi": "https://doi.org/10.1145/3157054",
    "publication_date": "2018-01-06",
    "publication_year": 2018,
    "authors": "Miika Hannula; Juha Kontinen; Jonni Virtema; Heribert Vollmer",
    "corresponding_authors": "",
    "abstract": "We classify the computational complexity of the satisfiability, validity, and model-checking problems for propositional independence, inclusion, and team logic. Our main result shows that the satisfiability and validity problems for propositional team logic are complete for alternating exponential-time with polynomially many alternations.",
    "cited_by_count": 29,
    "openalex_id": "https://openalex.org/W2964051209",
    "type": "article"
  },
  {
    "title": "Modularisation of Sequent Calculi for Normal and Non-normal Modalities",
    "doi": "https://doi.org/10.1145/3288757",
    "publication_date": "2019-02-22",
    "publication_year": 2019,
    "authors": "Björn Lellmann; Elaine Pimentel",
    "corresponding_authors": "",
    "abstract": "In this work, we explore the connections between (linear) nested sequent calculi and ordinary sequent calculi for normal and non-normal modal logics. By proposing local versions to ordinary sequent rules, we obtain linear nested sequent calculi for a number of logics, including, to our knowledge, the first nested sequent calculi for a large class of simply dependent multimodal logics and for many standard non-normal modal logics. The resulting systems are modular and have separate left and right introduction rules for the modalities, which makes them amenable to specification as bipole clauses. While this granulation of the sequent rules introduces more choices for proof search, we show how linear nested sequent calculi can be restricted to blocked derivations, which directly correspond to ordinary sequent derivations.",
    "cited_by_count": 29,
    "openalex_id": "https://openalex.org/W2964142950",
    "type": "article"
  },
  {
    "title": "First-Order Interpretations of Bounded Expansion Classes",
    "doi": "https://doi.org/10.1145/3382093",
    "publication_date": "2020-07-05",
    "publication_year": 2020,
    "authors": "Jakub Gajarský; Stephan Kreutzer; Jaroslav Nešetřil; Patrice Ossona de Mendez; Michał Pilipczuk; Sebastian Siebertz; Szymon Toruńczyk",
    "corresponding_authors": "",
    "abstract": "The notion of bounded expansion captures uniform sparsity of graph classes and renders various algorithmic problems that are hard in general tractable. In particular, the model-checking problem for first-order logic is fixed-parameter tractable over such graph classes. With the aim of generalizing such results to dense graphs, we introduce classes of graphs with structurally bounded expansion , defined as first-order transductions of classes of bounded expansion. As a first step towards their algorithmic treatment, we provide their characterization analogous to the characterization of classes of bounded expansion via low treedepth covers (or colorings), replacing treedepth by its dense analogue called shrubdepth.",
    "cited_by_count": 28,
    "openalex_id": "https://openalex.org/W3040059890",
    "type": "article"
  },
  {
    "title": "Principles of KLM-style Defeasible Description Logics",
    "doi": "https://doi.org/10.1145/3420258",
    "publication_date": "2020-11-15",
    "publication_year": 2020,
    "authors": "Katarina Britz; Giovanni Casini; Thomas Meyer; Kody Moodley; Ulrike Sattler; Ivan Varzinczak",
    "corresponding_authors": "",
    "abstract": "The past 25 years have seen many attempts to introduce defeasible-reasoning capabilities into a description logic setting. Many, if not most, of these attempts are based on preferential extensions of description logics, with a significant number of these, in turn, following the so-called KLM approach to defeasible reasoning initially advocated for propositional logic by Kraus, Lehmann, and Magidor. Each of these attempts has its own aim of investigating particular constructions and variants of the (KLM-style) preferential approach. Here our aim is to provide a comprehensive study of the formal foundations of preferential defeasible reasoning for description logics in the KLM tradition. We start by investigating a notion of defeasible subsumption in the spirit of defeasible conditionals as studied by Kraus, Lehmann, and Magidor in the propositional case. In particular, we consider a natural and intuitive semantics for defeasible subsumption, and we investigate KLM-style syntactic properties for both preferential and rational subsumption. Our contribution includes two representation results linking our semantic constructions to the set of preferential and rational properties considered. Besides showing that our semantics is appropriate, these results pave the way for more effective decision procedures for defeasible reasoning in description logics. Indeed, we also analyse the problem of non-monotonic reasoning in description logics at the level of entailment and present an algorithm for the computation of rational closure of a defeasible knowledge base. Importantly, our algorithm relies completely on classical entailment and shows that the computational complexity of reasoning over defeasible knowledge bases is no worse than that of reasoning in the underlying classical DL ALC .",
    "cited_by_count": 28,
    "openalex_id": "https://openalex.org/W3082661735",
    "type": "article"
  },
  {
    "title": "Being Correct Is Not Enough: Efficient Verification Using Robust Linear Temporal Logic",
    "doi": "https://doi.org/10.1145/3491216",
    "publication_date": "2022-01-14",
    "publication_year": 2022,
    "authors": "Tzanis Anevlavis; Matthew Philippe; Daniel Neider; Paulo Tabuada",
    "corresponding_authors": "",
    "abstract": "While most approaches in formal methods address system correctness, ensuring robustness has remained a challenge. In this article, we present and study the logic rLTL, which provides a means to formally reason about both correctness and robustness in system design. Furthermore, we identify a large fragment of rLTL for which the verification problem can be efficiently solved, i.e., verification can be done by using an automaton, recognizing the behaviors described by the rLTL formula φ, of size at most O(3 |φ |), where |φ | is the length of φ. This result improves upon the previously known bound of O(5|φ |) for rLTL verification and is closer to the LTL bound of O(2|φ |). The usefulness of this fragment is demonstrated by a number of case studies showing its practical significance in terms of expressiveness, the ability to describe robustness, and the fine-grained information that rLTL brings to the process of system verification. Moreover, these advantages come at a low computational overhead with respect to LTL verification.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W3133387630",
    "type": "article"
  },
  {
    "title": "Interpolation in Linear Logic and Related Systems",
    "doi": "https://doi.org/10.1145/3680284",
    "publication_date": "2024-07-25",
    "publication_year": 2024,
    "authors": "Wesley Fussner; Simon Santschi",
    "corresponding_authors": "",
    "abstract": "We prove that there are continuum-many axiomatic extensions of the full Lambek calculus with exchange that have the deductive interpolation property. Further, we extend this result to both classical and intuitionistic linear logic as well as their multiplicative-additive fragments. None of the logics we exhibit have the Craig interpolation property, but we show that the exhibited extensions of classical and intuitionistic linear logic all enjoy a guarded form of Craig interpolation. We also give continuum-many axiomatic extensions of classical linear logic without the deductive interpolation property.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4400977938",
    "type": "article"
  },
  {
    "title": "Sequent calculi for propositional nonmonotonic logics",
    "doi": "https://doi.org/10.1145/505372.505374",
    "publication_date": "2002-04-01",
    "publication_year": 2002,
    "authors": "Piero A. Bonatti; Nicola Olivetti",
    "corresponding_authors": "",
    "abstract": "A uniform proof-theoretic reconstruction of the major nonmonotonic logics is introduced. It consists of analytic sequent calculi where the details of nonmonotonic assumption making are modelled by an axiomatic rejection method. Another distinctive feature of the calculi is the use of provability constraints that make reasoning largely independent of any specific derivation strategy. The resulting account of nonmonotonic inference is simple and flexible enough to be a promising playground for investigating and comparing proof strategies, and for describing the behavior of automated reasoning systems. We provide some preliminary evidence for this claim by introducing optimized calculi, and by simulating an existing tableaux-based method for circumscription. The calculi for skeptical reasoning support concise proofs that may depend on a strict subset of the given theory. This is a difficult task, given the nonmonotonic behavior of the logics.",
    "cited_by_count": 55,
    "openalex_id": "https://openalex.org/W2019738341",
    "type": "article"
  },
  {
    "title": "An <i>n</i> ! lower bound on formula size",
    "doi": "https://doi.org/10.1145/772062.772064",
    "publication_date": "2003-07-01",
    "publication_year": 2003,
    "authors": "Micah Adler; Neil Immerman",
    "corresponding_authors": "",
    "abstract": "We introduce a new Ehrenfeucht--Fraïssé game for proving lower bounds on the size of first-order formulas. Up until now, such games have only been used to prove bounds on the operator depth of formulas, not their size. We use this game to prove that the CTL + formula, Occur n ≡ E[F p 1 ∧ F p 2 ∧ … ∧ F p n ], which says that there is a path along which the predicates p 1 through p n all occur, requires size n ! to express in CTL. Our lower bound is optimal. It follows that the succinctness of CTL + with respect to CTL is exactly Θ( n )!. Wilke had shown that the succinctness was at least exponential [Wilke 1999].We also use our games to prove an optimal Ω( n ) lower bound on the number of boolean variables needed for forward reachability logic (RL f ) to polynomially embed the language CTL + . The number of booleans needed for full reachability logic RL and the transitive closure logic FO 2 (TC) remain open [Immerman and Vardi 1997; Alechina and Immerman 2000].",
    "cited_by_count": 54,
    "openalex_id": "https://openalex.org/W2175748456",
    "type": "article"
  },
  {
    "title": "Minimum model semantics for logic programs with negation-as-failure",
    "doi": "https://doi.org/10.1145/1055686.1055694",
    "publication_date": "2005-04-01",
    "publication_year": 2005,
    "authors": "Panos Rondogiannis; William W. Wadge",
    "corresponding_authors": "",
    "abstract": "We give a purely model-theoretic characterization of the semantics of logic programs with negation-as-failure allowed in clause bodies. In our semantics, the meaning of a program is, as in the classical case, the unique minimum model in a program-independent ordering. We use an expanded truth domain that has an uncountable linearly ordered set of truth values between False (the minimum element) and True (the maximum), with a Zero element in the middle. The truth values below Zero are ordered like the countable ordinals. The values above Zero have exactly the reverse order. Negation is interpreted as reflection about Zero followed by a step towards Zero ; the only truth value that remains unaffected by negation is Zero . We show that every program has a unique minimum model M P , and that this model can be constructed with a T P iteration which proceeds through the countable ordinals. Furthermore, we demonstrate that M P can alternatively be obtained through a construction that generalizes the well-known model intersection theorem for classical logic programming. Finally, we show that by collapsing the true and false values of the infinite-valued model M P to (the classical) True and False , we obtain a three-valued model identical to the well-founded one.",
    "cited_by_count": 47,
    "openalex_id": "https://openalex.org/W2071118378",
    "type": "article"
  },
  {
    "title": "The strength of replacement in weak arithmetic",
    "doi": "https://doi.org/10.1145/1183278.1183283",
    "publication_date": "2006-10-01",
    "publication_year": 2006,
    "authors": "Stephen Cook; Neil Thapen",
    "corresponding_authors": "",
    "abstract": "The replacement (or collection or choice ) axiom scheme BB(Γ) asserts bounded quantifier exchange as follows: ∀ i &lt; | a | ∃ x &lt; a ϕ( i , x ) → ∃ w ∀ i &lt; | a |ϕ( i ,[ w ] i ), for ϕ in the class Γ of formulas. The theory S 1 2 proves the scheme BB(Σ b 1 ), and thus in S 1 2 every Σ b 1 formula is equivalent to a strict Σ b 1 formula (in which all non-sharply-bounded quantifiers are in front). Here we prove (sometimes subject to an assumption) that certain theories weaker than S 1 2 do not prove either BB(Σ b 1 ) or BB(Σ b 0 ). We show (unconditionally) that V 0 does not prove BB(Σ b 0 ), where V 0 (essentially IΣ 1, b 0 ) is the two-sorted theory associated with the complexity class AC 0 . We show that PV does not prove BB(Σ b 0 ), assuming that integer factoring is not possible in probabilistic polynomial time. Johannsen and Pollett introduced the theory C 0 2 associated with the complexity class TC 0 , and later introduced an apparently weaker theory Δ b 1 − CR for the same class. We use our methods to show that Δ b 1 − CR is indeed weaker than C 0 2 , assuming that RSA is secure against probabilistic polynomial time attack.Our main tool is the KPT witnessing theorem.",
    "cited_by_count": 47,
    "openalex_id": "https://openalex.org/W2112512535",
    "type": "article"
  },
  {
    "title": "Extensional equivalence and singleton types",
    "doi": "https://doi.org/10.1145/1183278.1183281",
    "publication_date": "2006-10-01",
    "publication_year": 2006,
    "authors": "C. Addison Stone; Robert Harper",
    "corresponding_authors": "",
    "abstract": "We study the λ ΠΣ S ≤ calculus, which contains singleton types S ( M ) classifying terms of base type provably equivalent to the term M . The system includes dependent types for pairs and functions (Σ and Π) and a subtyping relation induced by regarding singletons as subtypes of the base type. The decidability of type checking for this language is non-obvious, since to type check we must be able to determine equivalence of well-formed terms. But in the presence of singleton types, the provability of an equivalence judgment Γ ⊢ M 1 ≡ M 2 : A can depend both on the typing context Γ and on the particular type A at which M 1 and M 2 are compared.We show how to prove decidability of term equivalence, hence of type checking, in λ ΠΣ S ≤ by exhibiting a type-directed algorithm for directly computing normal forms. The correctness of normalization is shown using an unusual variant of Kripke logical relations organized around sets; rather than defining a logical equivalence relation, we work directly with (subsets of) the corresponding equivalence classes.We then provide a more efficient algorithm for checking type equivalence without constructing normal forms. We also show that type checking, subtyping, and all other judgments of the system are decidable.The λ ΠΣ S ≤ calculus models type constructors and kinds in the intermediate language used by the TILT compiler for Standard ML to implement the SML module system. The decidability of λ ΠΣ S ≤ term equivalence allows us to show decidability of type checking for TILT's intermediate language. We also obtain a consistency result that allows us to prove type safety for the intermediate language. The algorithms derived here form the core of the type checker used for internal type checking in TILT.",
    "cited_by_count": 47,
    "openalex_id": "https://openalex.org/W2161017670",
    "type": "article"
  },
  {
    "title": "Splitting an operator",
    "doi": "https://doi.org/10.1145/1183278.1183284",
    "publication_date": "2006-10-01",
    "publication_year": 2006,
    "authors": "Joost Vennekens; David Gilis; Marc Denecker",
    "corresponding_authors": "",
    "abstract": "It is well known that, under certain conditions, it is possible to split logic programs under stable model semantics, that is, to divide such a program into a number of different “levels”, such that the models of the entire program can be constructed by incrementally constructing models for each level. Similar results exist for other nonmonotonic formalisms, such as auto-epistemic logic and default logic. In this work, we present a general, algebraic splitting theory for logics with a fixpoint semantics. Together with the framework of approximation theory , a general fixpoint theory for arbitrary operators, this gives us a uniform and powerful way of deriving splitting results for each logic with a fixpoint semantics. We demonstrate the usefulness of these results, by generalizing existing results for logic programming, auto-epistemic logic and default logic.",
    "cited_by_count": 45,
    "openalex_id": "https://openalex.org/W2080633262",
    "type": "article"
  },
  {
    "title": "Propositional computability logic I",
    "doi": "https://doi.org/10.1145/1131313.1131318",
    "publication_date": "2006-04-01",
    "publication_year": 2006,
    "authors": "Giorgi Japaridze",
    "corresponding_authors": "Giorgi Japaridze",
    "abstract": "In the same sense as classical logic is a formal theory of truth, the recently initiated approach called computability logic is a formal theory of computability. It understands (interactive) computational problems as games played by a machine against the environment, their computability as existence of a machine that always wins the game, logical operators as operations on computational problems, and validity of a logical formula as being a scheme of \"always computable\" problems. The present contribution gives a detailed exposition of a soundness and completeness proof for an axiomatization of one of the most basic fragments of computability logic. The logical vocabulary of this fragment contains operators for the so called parallel and choice operations, and its atoms represent elementary problems, i.e. predicates in the standard sense. This article is self-contained as it explains all relevant concepts. While not technically necessary, however, familiarity with the foundational paper \"Introduction to computability logic\" [Annals of Pure and Applied Logic 123 (2003), pp.1-99] would greatly help the reader in understanding the philosophy, underlying motivations, potential and utility of computability logic, -- the context that determines the value of the present results. Online introduction to the subject is available at http://www.cis.upenn.edu/~giorgi/cl.html and http://www.csc.villanova.edu/~japaridz/CL/gsoll.html .",
    "cited_by_count": 43,
    "openalex_id": "https://openalex.org/W2121000477",
    "type": "article"
  },
  {
    "title": "Analytic tableaux calculi for KLM logics of nonmonotonic reasoning",
    "doi": "https://doi.org/10.1145/1507244.1507248",
    "publication_date": "2009-04-01",
    "publication_year": 2009,
    "authors": "Laura Giordano; Valentina Gliozzi; Nicola Olivetti; Gian Luca Pozzato",
    "corresponding_authors": "",
    "abstract": "We present tableau calculi for the logics of nonmonotonic reasoning defined by Kraus, Lehmann and Magidor (KLM). We give a tableau proof procedure for all KLM logics, namely preferential, loop-cumulative, cumulative, and rational logics. Our calculi are obtained by introducing suitable modalities to interpret conditional assertions. We provide a decision procedure for the logics considered and we study their complexity.",
    "cited_by_count": 37,
    "openalex_id": "https://openalex.org/W2132059708",
    "type": "article"
  },
  {
    "title": "Optimality of size-degree tradeoffs for polynomial calculus",
    "doi": "https://doi.org/10.1145/1838552.1838556",
    "publication_date": "2010-10-01",
    "publication_year": 2010,
    "authors": "Nicola Galesi; Massimo Lauria",
    "corresponding_authors": "",
    "abstract": "There are methods to turn short refutations in polynomial calculus (Pc) and polynomial calculus with resolution (Pcr) into refutations of low degree. Bonet and Galesi [1999, 2003] asked if such size-degree tradeoffs for Pc [Clegg et al. 1996; Impagliazzo et al. 1999] and Pcr [Alekhnovich et al. 2004] are optimal. We answer this question by showing a polynomial encoding of the graph ordering principle on m variables which requires Pc and Pcr refutations of degree Ω(√ m ). Tradeoff optimality follows from our result and from the short refutations of the graph ordering principle in Bonet and Galesi [1999, 2001]. We then introduce the algebraic proof system Pcr k which combines together polynomial calculus and k-DNF resolution (Res k ). We show a size hierarchy theorem for Pcr k : Pcr k is exponentially separated from Pcr k+1 . This follows from the previous degree lower bound and from techniques developed for Res k . Finally we show that random formulas in conjunctive normal form (3-CNF) are hard to refute in Pcr k .",
    "cited_by_count": 33,
    "openalex_id": "https://openalex.org/W2076972272",
    "type": "article"
  },
  {
    "title": "Reasoning about actions with sensing under qualitative and probabilistic uncertainty",
    "doi": "https://doi.org/10.1145/1459010.1459015",
    "publication_date": "2009-01-01",
    "publication_year": 2009,
    "authors": "Luca Iocchi; Thomas Lukasiewicz; Daniele Nardi; Riccardo Rosati",
    "corresponding_authors": "",
    "abstract": "We focus on the aspect of sensing in reasoning about actions under qualitative and probabilistic uncertainty. We first define the action language E for reasoning about actions with sensing, which has a semantics based on the autoepistemic description logic ALCK NF , and which is given a formal semantics via a system of deterministic transitions between epistemic states. As an important feature, the main computational tasks in E can be done in linear and quadratic time. We then introduce the action language E + for reasoning about actions with sensing under qualitative and probabilistic uncertainty, which is an extension of E by actions with nondeterministic and probabilistic effects, and which is given a formal semantics in a system of deterministic, nondeterministic, and probabilistic transitions between epistemic states. We also define the notion of a belief graph, which represents the belief state of an agent after a sequence of deterministic, nondeterministic, and probabilistic actions, and which compactly represents a set of unnormalized probability distributions. Using belief graphs, we then introduce the notion of a conditional plan and its goodness for reasoning about actions under qualitative and probabilistic uncertainty. We formulate the problems of optimal and threshold conditional planning under qualitative and probabilistic uncertainty, and show that they are both uncomputable in general. We then give two algorithms for conditional planning in our framework. The first one is always sound, and it is also complete for the special case in which the relevant transitions between epistemic states are cycle-free. The second algorithm is a sound and complete solution to the problem of finite-horizon conditional planning in our framework. Under suitable assumptions, it computes every optimal finite-horizon conditional plan in polynomial time. We also describe an application of our formalism in a robotic-soccer scenario, which underlines its usefulness in realistic applications.",
    "cited_by_count": 33,
    "openalex_id": "https://openalex.org/W2120848913",
    "type": "article"
  },
  {
    "title": "Logic of infons",
    "doi": "https://doi.org/10.1145/1877714.1877715",
    "publication_date": "2011-01-01",
    "publication_year": 2011,
    "authors": "Yuri Gurevich; Itay Neeman",
    "corresponding_authors": "",
    "abstract": "Infons are statements viewed as containers of information (rather then representations of truth values). The logic of infons turns out to be a conservative extension of logic known as constructive or intuitionistic. Distributed Knowledge Authorization Language uses additional unary connectives “ p said” and “ p implied” where p ranges over principals. Here we investigate infon logic and a narrow but useful primal fragment of it. In both cases, we develop model theory and analyze the derivability problem: Does the given query follow from the given hypotheses? Our more involved technical results are on primal infon logic. We construct an algorithm for the multiple derivability problem: Which of the given queries follow from the given hypotheses? Given a bound on the quotation depth of the hypotheses, the algorithm runs in linear time. We quickly discuss the significance of this result for access control.",
    "cited_by_count": 33,
    "openalex_id": "https://openalex.org/W2159914860",
    "type": "article"
  },
  {
    "title": "On the Relative Strength of Pebbling and Resolution",
    "doi": "https://doi.org/10.1145/2159531.2159538",
    "publication_date": "2012-04-01",
    "publication_year": 2012,
    "authors": "Jakob Nordström",
    "corresponding_authors": "Jakob Nordström",
    "abstract": "The last decade has seen a revival of interest in pebble games in the context of proof complexity. Pebbling has proven to be a useful tool for studying resolution-based proof systems when comparing the strength of different subsystems, showing bounds on proof space, and establishing size-space trade-offs. The typical approach has been to encode the pebble game played on a graph as a CNF formula and then argue that proofs of this formula must inherit (various aspects of) the pebbling properties of the underlying graph. Unfortunately, the reductions used here are not tight. To simulate resolution proofs by pebblings, the full strength of nondeterministic black-white pebbling is needed, whereas resolution is only known to be able to simulate deterministic black pebbling. To obtain strong results, one therefore needs to find specific graph families which either have essentially the same properties for black and black-white pebbling (not at all true in general) or which admit simulations of black-white pebblings in resolution. This article contributes to both these approaches. First, we design a restricted form of black-white pebbling that can be simulated in resolution and show that there are graph families for which such restricted pebblings can be asymptotically better than black pebblings. This proves that, perhaps somewhat unexpectedly, resolution can strictly beat black-only pebbling, and in particular that the space lower bounds on pebbling formulas in Ben-Sasson and Nordström [2008] are tight. Second, we present a versatile parametrized graph family with essentially the same properties for black and black-white pebbling, which gives sharp simultaneous trade-offs for black and black-white pebbling for various parameter settings. Both of our contributions have been instrumental in obtaining the time-space trade-off results for resolution-based proof systems in Ben-Sasson and Nordström [2011].",
    "cited_by_count": 32,
    "openalex_id": "https://openalex.org/W1985970833",
    "type": "article"
  },
  {
    "title": "Parameterized Complexity of DPLL Search Procedures",
    "doi": "https://doi.org/10.1145/2499937.2499941",
    "publication_date": "2013-08-01",
    "publication_year": 2013,
    "authors": "Olaf Beyersdorff; Nicola Galesi; Massimo Lauria",
    "corresponding_authors": "",
    "abstract": "We study the performance of DPLL algorithms on parameterized problems. In particular, we investigate how difficult it is to decide whether small solutions exist for satisfiability and other combinatorial problems. For this purpose we develop a Prover-Delayer game that models the running time of DPLL procedures and we establish an information-theoretic method to obtain lower bounds to the running time of parameterized DPLL procedures. We illustrate this technique by showing lower bounds to the parameterized pigeonhole principle and to the ordering principle. As our main application we study the DPLL procedure for the problem of deciding whether a graph has a small clique. We show that proving the absence of a k -clique requires n Ω(k) steps for a nontrivial distribution of graphs close to the critical threshold. For the restricted case of tree-like Parameterized Resolution, this result answers a question asked by Beyersdorff et al. [2012] of understanding the Resolution complexity of this family of formulas.",
    "cited_by_count": 29,
    "openalex_id": "https://openalex.org/W2045690379",
    "type": "article"
  },
  {
    "title": "The Complexity of Phylogeny Constraint Satisfaction Problems",
    "doi": "https://doi.org/10.1145/3105907",
    "publication_date": "2017-07-31",
    "publication_year": 2017,
    "authors": "Manuel Bodirsky; Peter Jönsson; Trung Van Pham",
    "corresponding_authors": "",
    "abstract": "We systematically study the computational complexity of a broad class of computational problems in phylogenetic reconstruction. The class contains, for example, the rooted triple consistency problem, forbidden subtree problems, the quartet consistency problem, and many other problems studied in the bioinformatics literature. The studied problems can be described as constraint satisfaction problems , where the constraints have a first-order definition over the rooted triple relation. We show that every such phylogeny problem can be solved in polynomial time or is NP-complete. On the algorithmic side, we generalize a well-known polynomial-time algorithm of Aho, Sagiv, Szymanski, and Ullman for the rooted triple consistency problem. Our algorithm repeatedly solves linear equation systems to construct a solution in polynomial time. We then show that every phylogeny problem that cannot be solved by our algorithm is NP-complete. Our classification establishes a dichotomy for a large class of infinite structures that we believe is of independent interest in universal algebra, model theory, and topology. The proof of our main result combines results and techniques from various research areas: a recent classification of the model-complete cores of the reducts of the homogeneous binary branching C-relation, Leeb’s Ramsey theorem for rooted trees, and universal algebra.",
    "cited_by_count": 29,
    "openalex_id": "https://openalex.org/W2740483412",
    "type": "article"
  },
  {
    "title": "Differential Game Logic",
    "doi": "https://doi.org/10.1145/2817824",
    "publication_date": "2015-11-14",
    "publication_year": 2015,
    "authors": "André Platzer",
    "corresponding_authors": "André Platzer",
    "abstract": "Differential game logic (dGL) is a logic for specifying and verifying properties of hybrid games, i.e. games that combine discrete, continuous, and adversarial dynamics. Unlike hybrid systems, hybrid games allow choices in the system dynamics to be resolved adversarially by different players with different objectives. The logic dGL can be used to study the existence of winning strategies for such hybrid games, i.e. ways of resolving the player's choices in some way so that he wins by achieving his objective for all choices of the opponent. Hybrid games are determined, i.e. from each state, one player has a winning strategy, yet computing their winning regions may take transfinitely many steps. The logic dGL, nevertheless, has a sound and complete axiomatization relative to any expressive logic. Separating axioms are identified that distinguish hybrid games from hybrid systems. Finally, dGL is proved to be strictly more expressive than the corresponding logic of hybrid systems by characterizing the expressiveness of both.",
    "cited_by_count": 29,
    "openalex_id": "https://openalex.org/W3125808851",
    "type": "article"
  },
  {
    "title": "A unified semantic framework for fully structural propositional sequent systems",
    "doi": "https://doi.org/10.1145/2528930",
    "publication_date": "2013-11-01",
    "publication_year": 2013,
    "authors": "Ori Lahav; Arnon Avron",
    "corresponding_authors": "",
    "abstract": "We identify a large family of fully structural propositional sequent systems, which we call basic systems . We present a general uniform method for providing (potentially, nondeterministic) strongly sound and complete Kripke-style semantics, which is applicable for every system of this family. In addition, this method can also be applied when: (i) some formulas are not allowed to appear in derivations, (ii) some formulas are not allowed to serve as cut formulas, and (iii) some instances of the identity axiom are not allowed to be used. This naturally leads to new semantic characterizations of analyticity (global subformula property), cut admissibility and axiom expansion in basic systems. We provide a large variety of examples showing that many soundness and completeness theorems for different sequent systems, as well as analyticity, cut admissibility, and axiom expansion results, easily follow using the general method of this article.",
    "cited_by_count": 28,
    "openalex_id": "https://openalex.org/W1990123412",
    "type": "article"
  },
  {
    "title": "The dynamic complexity of formal languages",
    "doi": "https://doi.org/10.1145/2287718.2287719",
    "publication_date": "2012-08-01",
    "publication_year": 2012,
    "authors": "Wouter Gelade; Marcel Marquardt; Thomas Schwentick",
    "corresponding_authors": "",
    "abstract": "The article investigates the power of the dynamic complexity classes D yn FO, D yn QF, and D yn PROP over string languages. The latter two classes contain problems that can be maintained using quantifier-free first-order updates, with and without auxiliary functions, respectively. It is shown that the languages maintainable in D yn PROP are exactly the regular languages, even when allowing arbitrary precomputation. This enables lower bounds for D yn PROP and separates D yn PROP from D yn QF and D yn FO. Further, it is shown that any context-free language can be maintained in D yn FO and a number of specific context-free languages, for example all Dyck-languages, are maintainable in D yn QF. Furthermore, the dynamic complexity of regular tree languages is investigated and some results concerning arbitrary structures are obtained: There exist first-order definable properties which are not maintainable in D yn PROP. On the other hand, any existential first-order property can be maintained in D yn QF when allowing precomputation.",
    "cited_by_count": 28,
    "openalex_id": "https://openalex.org/W2024823088",
    "type": "article"
  },
  {
    "title": "The Logical View on Continuous Petri Nets",
    "doi": "https://doi.org/10.1145/3105908",
    "publication_date": "2017-07-31",
    "publication_year": 2017,
    "authors": "Michael Blondin; Alain Finkel; Christoph Haase; Serge Haddad",
    "corresponding_authors": "",
    "abstract": "Continuous Petri nets are a relaxation of classical discrete Petri nets in which transitions can be fired a fractional number of times, and consequently places may contain a fractional number of tokens. Such continuous Petri nets are an appealing object to study, since they over-approximate the set of reachable configurations of their discrete counterparts, and their reachability problem is known to be decidable in polynomial time. The starting point of this article is to show that the reachability relation for continuous Petri nets is definable by a sentence of linear size in the existential theory of the rationals with addition and order. Using this characterization, we obtain decidability and complexity results for a number of classical decision problems for continuous Petri nets. In particular, we settle the open problem about the precise complexity of reachability set inclusion. Finally, we show how continuous Petri nets can be incorporated inside the classical backward coverability algorithm for discrete Petri nets as a pruning heuristic to tackle the symbolic state explosion problem. The cornerstone of the approach we present is that our logical characterization enables us to leverage the power of modern SMT-solvers to yield a highly performant and robust decision procedure for coverability in Petri nets. We demonstrate the applicability of our approach on a set of standard benchmarks from the literature.",
    "cited_by_count": 28,
    "openalex_id": "https://openalex.org/W2745248131",
    "type": "article"
  },
  {
    "title": "Quantifier-free interpolation in combinations of equality interpolating theories",
    "doi": "https://doi.org/10.1145/2490253",
    "publication_date": "2014-02-01",
    "publication_year": 2014,
    "authors": "Roberto Bruttomesso; Silvio Ghilardi; Silvio Ranise",
    "corresponding_authors": "",
    "abstract": "The use of interpolants in verification is gaining more and more importance. Since theories used in applications are usually obtained as (disjoint) combinations of simpler theories, it is important to modularly reuse interpolation algorithms for the component theories. We show that a sufficient and necessary condition to do this for quantifier-free interpolation is that the component theories have the strong ( sub -) amalgamation property. Then, we provide an equivalent syntactic characterization and show that such characterization covers most theories commonly employed in verification. Finally, we design a combined quantifier-free interpolation algorithm capable of handling both convex and nonconvex theories; this algorithm subsumes and extends most existing work on combined interpolation.",
    "cited_by_count": 27,
    "openalex_id": "https://openalex.org/W2026276439",
    "type": "article"
  },
  {
    "title": "Differential Hybrid Games",
    "doi": "https://doi.org/10.1145/3091123",
    "publication_date": "2017-07-31",
    "publication_year": 2017,
    "authors": "André Platzer",
    "corresponding_authors": "André Platzer",
    "abstract": "This article introduces differential hybrid games, which combine differential games with hybrid games. In both kinds of games, two players interact with continuous dynamics. The difference is that hybrid games also provide all the features of hybrid systems and discrete games, but only deterministic differential equations. Differential games, instead, provide differential equations with continuous-time game input by both players, but not the luxury of hybrid games, such as mode switches and discrete-time or alternating adversarial interaction. This article augments differential game logic with modalities for the combined dynamics of differential hybrid games. It shows how hybrid games subsume differential games and introduces differential game invariants and differential game variants for proving properties of differential games inductively.",
    "cited_by_count": 27,
    "openalex_id": "https://openalex.org/W3125479578",
    "type": "article"
  },
  {
    "title": "A SAT Approach to Clique-Width",
    "doi": "https://doi.org/10.1145/2736696",
    "publication_date": "2015-06-02",
    "publication_year": 2015,
    "authors": "Marijn J. H. Heule; Stefan Szeider",
    "corresponding_authors": "",
    "abstract": "Clique-width is a graph invariant that has been widely studied in combinatorics and computational logic. Computing the clique-width of a graph is an intricate problem, because the exact clique-width is not known even for very small graphs. We present a new method for computing clique-width via an encoding to propositional satisfiability (SAT), which is then evaluated by a SAT solver. Our encoding is based on a reformulation of clique-width in terms of partitions that utilizes an efficient encoding of cardinality constraints. Our SAT-based method is the first to discover the exact clique-width of various small graphs, including famous named graphs from the literature as well as random graphs of various density. With our method, we determined the smallest graphs that require a small predescribed clique-width. We further show how our method can be modified to compute the linear clique-width of graphs, a variant of clique-width that has recently received considerable attention. In an appendix, we provide certificates for tight upper bounds for the clique-width and linear clique-width of famous named graphs.",
    "cited_by_count": 26,
    "openalex_id": "https://openalex.org/W1906408003",
    "type": "article"
  },
  {
    "title": "A PSPACE-complete first-order fragment of computability logic",
    "doi": "https://doi.org/10.1145/2559949",
    "publication_date": "2014-02-01",
    "publication_year": 2014,
    "authors": "Matthew S. Bauer",
    "corresponding_authors": "Matthew S. Bauer",
    "abstract": "In a recently launched research program for developing logic as a formal theory of (interactive) computability, several very interesting logics have been introduced and axiomatized. These fragments of the larger Computability Logic aim not only to describe what can be computed, but also provide a mechanism for extracting computational algorithms from proofs. Among the most expressive and fundamental of these is CL4, known to be (constructively) sound and complete with respect to the underlying computational semantics. Furthermore, the ∀, ∃-free fragment of CL4 was shown to be decidable in polynomial space. The present work extends this result and proves that this fragment is, in fact, PSPACE-complete.",
    "cited_by_count": 26,
    "openalex_id": "https://openalex.org/W2105830064",
    "type": "article"
  },
  {
    "title": "On the complexity of existential positive queries",
    "doi": "https://doi.org/10.1145/2559946",
    "publication_date": "2014-02-01",
    "publication_year": 2014,
    "authors": "Hubie Chen",
    "corresponding_authors": "Hubie Chen",
    "abstract": "We systematically investigate the complexity of model checking the existential positive fragment of first-order logic. In particular, for a set of existential positive sentences, we consider model checking where the sentence is restricted to fall into the set; a natural question is then to classify which sentence sets are tractable and which are intractable. With respect to fixed-parameter tractability, we give a general theorem that reduces this classification question to the corresponding question for primitive positive logic, for a variety of representations of structures. This general theorem allows us to deduce that an existential positive sentence set having bounded arity is fixed-parameter tractable if and only if each sentence is equivalent to one in bounded-variable logic. We then use the lens of classical complexity to study these fixed-parameter tractable sentence sets. We show that such a set can be NP-complete, and consider the length needed by a translation from sentences in such a set to bounded-variable logic; we prove superpolynomial lower bounds on this length using the theory of compilability, obtaining an interesting type of formula size lower bound. Overall, the tools, concepts, and results of this article set the stage for the future consideration of the complexity of model checking on more expressive logics.",
    "cited_by_count": 26,
    "openalex_id": "https://openalex.org/W2118076394",
    "type": "article"
  },
  {
    "title": "Strategy Logic with Imperfect Information",
    "doi": "https://doi.org/10.1145/3427955",
    "publication_date": "2021-01-05",
    "publication_year": 2021,
    "authors": "Raphaël Berthon; Bastien Maubert; Aniello Murano; Sasha Rubin; Moshe Y. Vardi",
    "corresponding_authors": "",
    "abstract": "We introduce an extension of Strategy Logic for the imperfect-information setting, called SL ii and study its model-checking problem. As this logic naturally captures multi-player games with imperfect information, this problem is undecidable; but we introduce a syntactical class of “hierarchical instances” for which, intuitively, as one goes down the syntactic tree of the formula, strategy quantifications are concerned with finer observations of the model, and we prove that model-checking SL ii restricted to hierarchical instances is decidable. This result, because it allows for complex patterns of existential and universal quantification on strategies, greatly generalises the decidability of distributed synthesis for systems with hierarchical information. It allows us to easily derive new decidability results concerning strategic problems under imperfect information such as the existence of Nash equilibria or rational synthesis. To establish this result, we go through an intermediary, “low-level” logic much more adapted to automata techniques. QCTL * is an extension of CTL * with second-order quantification over atomic propositions that has been used to study strategic logics with perfect information. We extend it to the imperfect information setting by parameterising second-order quantifiers with observations. The simple syntax of the resulting logic, QCTL * ii , allows us to provide a conceptually neat reduction of SL ii to QCTL * ii that separates concerns, allowing one to forget about strategies and players and focus solely on second-order quantification. While the model-checking problem of QCTL * ii is, in general, undecidable, we identify a syntactic fragment of hierarchical formulas and prove, using an automata-theoretic approach, that it is decidable.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W3119811314",
    "type": "article"
  },
  {
    "title": "A decision procedure for term algebras with queues",
    "doi": "https://doi.org/10.1145/371316.371494",
    "publication_date": "2001-04-01",
    "publication_year": 2001,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "In software verification it is often required to prove statements about heterogeneous domains containing elements of various sorts, such as counters, stacks, lists, trees and queues. Any domain with counters, stacks, lists, and trees (but not queues) can be easily seen a special case of the term algebra, and hence a decision procedure for term algebras can be applied to decide the first-order theory of such a domain. We present a quantifier-elimination procedure for the first-order theory of term algebra extended with queues. The complete axiomatization and decidability of this theory can be immediately derived from the procedure.",
    "cited_by_count": 47,
    "openalex_id": "https://openalex.org/W2181289644",
    "type": "article"
  },
  {
    "title": "Inadequacy of computable loop invariants",
    "doi": "https://doi.org/10.1145/371282.371285",
    "publication_date": "2001-01-01",
    "publication_year": 2001,
    "authors": "Andreas Blass; Yuri Gurevich",
    "corresponding_authors": "",
    "abstract": "Hoare logic is a widely recommended verification tool. There is, however, a problem of finding easily checkable loop invariants; it is known that decidable assertions do not suffice to verify while programs, even when the pre- and postconditions are decidable. We show here a stronger result: decidable invariants do not suffice to verify single-loop programs. We also show that this problem arises even in extremely simple contexts. Let N be the structure consisting of the set of natural numbers together with the functions S(x) = x +1, D(x) =2 (x) =*** x /2***. There is a single-loop program *** using only three variables x,y,z such that the asserted program x = y = z =0 *** false is partially correct on N but any loop invariant I(x,y,z) for this asserted program is undecidable.",
    "cited_by_count": 44,
    "openalex_id": "https://openalex.org/W2092019763",
    "type": "article"
  },
  {
    "title": "From linear time to branching time",
    "doi": "https://doi.org/10.1145/1055686.1055689",
    "publication_date": "2005-04-01",
    "publication_year": 2005,
    "authors": "Orna Kupferman; Moshe Y. Vardi",
    "corresponding_authors": "",
    "abstract": "Model checking is a method for the verification of systems with respect to their specifications. Symbolic model-checking, which enables the verification of large systems, proceeds by calculating fixed-point expressions over the system's set of states. The μ-calculus is a branching-time temporal logic with fixed-point operators. As such, it is a convenient logic for symbolic model-checking tools. In particular, the alternation-free fragment of μ-calculus has a restricted syntax, making the symbolic evaluation of its formulas computationally easy. Formally, it takes time that is linear in the size of the system. On the other hand, specifiers find the μ-calculus inconvenient. In addition, specifiers often prefer to use linear-time formalisms. Such formalisms, however, cannot in general be translated to the alternation-free μ-calculus, and their symbolic evaluation involves nesting of fixed-points, resulting in time complexity that is quadratic in the size of the system. In this article, we characterize linear-time properties that can be specified in the alternation-free μ-calculus. We show that a linear-time property can be specified in the alternation-free μ-calculus iff it can be recognized by a deterministic Büchi automaton. We study the problem of deciding whether a linear-time property, specified by either an automaton or an LTL formula, can be translated to an alternation-free μ-calculus formula, and describe the translation, when possible.",
    "cited_by_count": 42,
    "openalex_id": "https://openalex.org/W2020617153",
    "type": "article"
  },
  {
    "title": "Comparisons and computation of well-founded semantics for disjunctive logic programs",
    "doi": "https://doi.org/10.1145/1055686.1055690",
    "publication_date": "2005-04-01",
    "publication_year": 2005,
    "authors": "Kewen Wang; Lizhu Zhou",
    "corresponding_authors": "",
    "abstract": "Much work has been done on extending the well-founded semantics to general disjunctive logic programs and various approaches have been proposed. However, these semantics are different from each other and no consensus is reached about which semantics is the most intended. In this article, we look at disjunctive well-founded reasoning from different angles. We show that there is an intuitive form of the well-founded reasoning in disjunctive logic programming which can be characterized by slightly modifying some existing approaches to defining disjunctive well-founded semantics, including program transformations, argumentation, unfounded sets (and resolution-like procedure). By employing the techniques developed by Brass and Dix in their transformation-based approach, we also provide a bottom-up procedure for this semantics. The significance of our work is not only in clarifying the relationship among different approaches, but also shed some light on what is an intended well-founded semantics for disjunctive logic programs.",
    "cited_by_count": 41,
    "openalex_id": "https://openalex.org/W2011438231",
    "type": "article"
  },
  {
    "title": "Logical characterizations of heap abstractions",
    "doi": "https://doi.org/10.1145/1182613.1182618",
    "publication_date": "2007-01-01",
    "publication_year": 2007,
    "authors": "Greta Yorsh; Thomas Reps; Mooly Sagiv; Reinhard Wilhelm",
    "corresponding_authors": "",
    "abstract": "Shape analysis concerns the problem of determining “shape invariants” for programs that perform destructive updating on dynamically allocated storage. In recent work, we have shown how shape analysis can be performed using an abstract interpretation based on three-valued first-order logic. In that work, concrete stores are finite two-valued logical structures, and the sets of stores that can possibly arise during execution are represented (conservatively) using a certain family of finite three-valued logical structures. In this article, we show how three-valued structures that arise in shape analysis can be characterized using formulas in first-order logic with transitive closure. We also define a nonstandard (“supervaluational”) semantics for three-valued first-order logic that is more precise than a conventional three-valued semantics, and demonstrate that the supervaluational semantics can be implemented using existing theorem provers.",
    "cited_by_count": 33,
    "openalex_id": "https://openalex.org/W2069969904",
    "type": "article"
  },
  {
    "title": "Probabilistic interval XML",
    "doi": "https://doi.org/10.1145/1276920.1276926",
    "publication_date": "2007-08-01",
    "publication_year": 2007,
    "authors": "Edward Hung; Lise Getoor; V. S. Subrahmanian",
    "corresponding_authors": "",
    "abstract": "Interest in XML databases has been expanding rapidly over the last few years. In this paper, we study the problem of incorporating probabilistic information into XML databases. We propose the Probabilistic Interval XML ( PIXML for short) data model in this paper. Using this data model, users can express probabilistic information within XML markups. In addition, we provide two alternative formal model-theoretic semantics for PIXML data. The first semantics is a “global” semantics which is relatively intuitive, but is not directly amenable to computation. The second semantics is a “local” semantics which supports efficient computation. We prove several correspondence results between the two semantics. To our knowledge, this is the first formal model theoretic semantics for probabilistic interval XML. We then provide an operational semantics that may be used to compute answers to queries and that is correct for a large class of probabilistic instances.",
    "cited_by_count": 32,
    "openalex_id": "https://openalex.org/W1964634346",
    "type": "article"
  },
  {
    "title": "A finite equational base for CCS with left merge and communication merge",
    "doi": "https://doi.org/10.1145/1459010.1459016",
    "publication_date": "2009-01-01",
    "publication_year": 2009,
    "authors": "Luca Aceto; Wan Fokkink; Anna Ingólfsdóttir; Bas Luttik",
    "corresponding_authors": "",
    "abstract": "Using the left merge and the communication merge from ACP, we present an equational base (i.e., a ground-complete and ω-complete set of valid equations) for the fragment of CCS without recursion, restriction and relabeling modulo (strong) bisimilarity. Our equational base is finite if the set of actions is finite.",
    "cited_by_count": 32,
    "openalex_id": "https://openalex.org/W2164504930",
    "type": "article"
  },
  {
    "title": "Context semantics, linear logic, and computational complexity",
    "doi": "https://doi.org/10.1145/1555746.1555749",
    "publication_date": "2009-08-01",
    "publication_year": 2009,
    "authors": "Ugo Dal Lago",
    "corresponding_authors": "Ugo Dal Lago",
    "abstract": "We show that context semantics can be fruitfully applied to the quantitative analysis of proof normalization in linear logic. In particular, context semantics lets us define the weight of a proof-net as a measure of its inherent complexity: it is both an upper bound to normalization time (modulo a polynomial overhead, independently on the reduction strategy) and a lower bound to the amount of resources needed to compute the normal form. Weights are then exploited in proving strong soundness theorems for various subsystems of linear logic, namely elementary linear logic, soft linear logic, and light linear logic.",
    "cited_by_count": 32,
    "openalex_id": "https://openalex.org/W2169724594",
    "type": "article"
  },
  {
    "title": "Program termination and well partial orderings",
    "doi": "https://doi.org/10.1145/1352582.1352586",
    "publication_date": "2008-06-01",
    "publication_year": 2008,
    "authors": "Andreas Blass; Yuri Gurevich",
    "corresponding_authors": "",
    "abstract": "The following known observation is useful in establishing program termination: if a transitive relation R is covered by finitely many well-founded relations U 1 ,…, U n then R is well-founded. A question arises how to bound the ordinal height | R | of the relation R in terms of the ordinals α i = | U i |. We introduce the notion of the stature ∥ P ∥ of a well partial ordering P and show that | R | ≤ ∥α 1 × … × α n ∥ and that this bound is tight. The notion of stature is of considerable independent interest. We define ∥ P ∥ as the ordinal height of the forest of nonempty bad sequences of P , but it has many other natural and equivalent definitions. In particular, ∥ P ∥ is the supremum, and in fact the maximum, of the lengths of linearizations of P . And ∥α 1 × … × α n ∥ is equal to the natural product α 1 ⊗ … ⊗ α n .",
    "cited_by_count": 31,
    "openalex_id": "https://openalex.org/W1967109918",
    "type": "article"
  },
  {
    "title": "Lower bounds for bounded depth Frege proofs via Pudlák-Buss games",
    "doi": "https://doi.org/10.1145/1740582.1740587",
    "publication_date": "2010-05-01",
    "publication_year": 2010,
    "authors": "Eli Ben‐Sasson; Prahladh Harsha",
    "corresponding_authors": "",
    "abstract": "We present a simple proof of the bounded-depth Frege proof lower bounds of Pitassi et al. [1993] and Krajíček et al. [1995] for the pigeonhole principle. Our method uses the interpretation of proofs as two player games given by Pudlák and Buss. Our lower bound is conceptually simpler than previous ones, and relies on tools and intuition that are well known in the context of computational complexity. This makes the lower bound of Pitassi et al. [1993] and Krajíček et al. [1995] accessible to the general computational complexity audience. We hope this new view will open new directions for research in proof complexity.",
    "cited_by_count": 31,
    "openalex_id": "https://openalex.org/W1990362734",
    "type": "article"
  },
  {
    "title": "A flow calculus of <i>mwp</i> -bounds for complexity analysis",
    "doi": "https://doi.org/10.1145/1555746.1555752",
    "publication_date": "2009-08-01",
    "publication_year": 2009,
    "authors": "Neil D. Jones; Lars Kristiansen",
    "corresponding_authors": "",
    "abstract": "We present a method for certifying that the values computed by an imperative program will be bounded by polynomials in the program's inputs. To this end, we introduce mwp -matrices and define a semantic relation ⊧ C : M , where C is a program and M is an mwp -matrix. It follows straightforwardly from our definitions that there exists M such that ⊧ C : M holds iff every value computed by C is bounded by a polynomial in the inputs. Furthermore, we provide a syntactical proof calculus and define the relation ⊢ C : M to hold iff there exists a derivation in the calculus where C : M is the bottom line. We prove that ⊢ C : M implies ⊧ C : M . By means of exhaustive proof search, an algorithm can decide if there exists M such that the relation ⊢ C : M holds, and thus, our results yield a computational method.",
    "cited_by_count": 30,
    "openalex_id": "https://openalex.org/W2115581182",
    "type": "article"
  },
  {
    "title": "Termination of rewriting under strategies",
    "doi": "https://doi.org/10.1145/1462179.1462182",
    "publication_date": "2009-02-01",
    "publication_year": 2009,
    "authors": "Isabelle Gnaedig; Claude Kirchner",
    "corresponding_authors": "",
    "abstract": "A termination proof method for rewriting under strategies, based on an explicit induction on the termination property, is presented and instantiated for the innermost, outermost, and local strategies. Rewriting trees are simulated by proof trees generated with an abstraction mechanism, narrowing and constraints representing sets of ground terms. Abstraction introduces variables to represent normal forms without computing them and to control the narrowing mechanism, well known to easily diverge. The induction ordering is not given a priori, but defined with ordering constraints, incrementally set during the proof. It is established that termination under strategy is equivalent to the construction of finite proof trees schematizing terminating rewriting trees. Sufficient effective conditions to ensure finiteness are studied and the method is illustrated on several examples for each specific strategy.",
    "cited_by_count": 29,
    "openalex_id": "https://openalex.org/W2090652385",
    "type": "article"
  },
  {
    "title": "Proof search specifications of bisimulation and modal logics for the π-calculus",
    "doi": "https://doi.org/10.1145/1656242.1656248",
    "publication_date": "2010-01-01",
    "publication_year": 2010,
    "authors": "Alwen Tiu; Dale Miller",
    "corresponding_authors": "",
    "abstract": "We specify the operational semantics and bisimulation relations for the finite φ-calculus within a logic that contains the ∇ quantifier for encoding generic judgments and definitions for encoding fixed points. Since we restrict to the finite case, the ability of the logic to unfold fixed points allows this logic to be complete for both the inductive nature of operational semantics and the coinductive nature of bisimulation. The ∇ quantifier helps with the delicate issues surrounding the scope of variables within φ-calculus expressions and their executions (proofs). We illustrate several merits of the logical specifications permitted by this logic: they are natural and declarative; they contain no side-conditions concerning names of variables while maintaining a completely formal treatment of such variables; differences between late and open bisimulation relations arise from familar logic distinctions; the interplay between the three quantifiers (∀, ∃, and ∇) and their scopes can explain the differences between early and late bisimulation and between various modal operators based on bound input and output actions; and proof search involving the application of inference rules, unification, and backtracking can provide complete proof systems for one-step transitions, bisimulation, and satisfaction in modal logic. We also illustrate how one can encode the φ-calculus with replications, in an extended logic with induction and co-induction.",
    "cited_by_count": 29,
    "openalex_id": "https://openalex.org/W2104680392",
    "type": "article"
  },
  {
    "title": "A fast algorithm and datalog inexpressibility for temporal reasoning",
    "doi": "https://doi.org/10.1145/1740582.1740583",
    "publication_date": "2010-05-01",
    "publication_year": 2010,
    "authors": "Manuel Bodirsky; Jan Kára",
    "corresponding_authors": "",
    "abstract": "We introduce a new tractable temporal constraint language, which strictly contains the Ord-Horn language of Bürkert and Nebel and the class of AND/OR precedence constraints. The algorithm we present for this language decides whether a given set of constraints is consistent in time that is quadratic in the input size. We also prove that (unlike Ord-Horn) the constraint satisfaction problem of this language cannot be solved by Datalog or by establishing local consistency.",
    "cited_by_count": 28,
    "openalex_id": "https://openalex.org/W2123815839",
    "type": "article"
  },
  {
    "title": "Alternating automata on data trees and XPath satisfiability",
    "doi": "https://doi.org/10.1145/1929954.1929956",
    "publication_date": "2011-05-01",
    "publication_year": 2011,
    "authors": "Marcin Jurdziński; Ranko Lazić",
    "corresponding_authors": "",
    "abstract": "A data tree is an unranked ordered tree whose every node is labeled by a letter from a finite alphabet and an element (“datum”) from an infinite set, where the latter can only be compared for equality. The article considers alternating automata on data trees that can move downward and rightward, and have one register for storing data. The main results are that nonemptiness over finite data trees is decidable but not primitive recursive, and that nonemptiness of safety automata is decidable but not elementary. The proofs use nondeterministic tree automata with faulty counters. Allowing upward moves, leftward moves, or two registers, each causes undecidability. As corollaries, decidability is obtained for two data-sensitive fragments of the XPath query language.",
    "cited_by_count": 27,
    "openalex_id": "https://openalex.org/W2056864188",
    "type": "article"
  },
  {
    "title": "Model Checking of Recursive Probabilistic Systems",
    "doi": "https://doi.org/10.1145/2159531.2159534",
    "publication_date": "2012-04-01",
    "publication_year": 2012,
    "authors": "Kousha Etessami; Mihalis Yannakakis",
    "corresponding_authors": "",
    "abstract": "Recursive Markov Chains (RMCs) are a natural abstract model of procedural probabilistic programs and related systems involving recursion and probability. They succinctly define a class of denumerable Markov chains that generalize several other stochastic models, and they are equivalent in a precise sense to probabilistic Pushdown Systems. In this article, we study the problem of model checking an RMC against an ω -regular specification, given in terms of a Büchi automaton or a Linear Temporal Logic (LTL) formula. Namely, given an RMC A and a property, we wish to know the probability that an execution of A satisfies the property. We establish a number of strong upper bounds, as well as lower bounds, both for qualitative problems (is the probability = 1, or = 0?), and for quantitative problems (is the probability ≥ p ?, or, approximate the probability to within a desired precision). The complexity upper bounds we obtain for automata and LTL properties are similar, although the algorithms are different. We present algorithms for the qualitative model checking problem that run in polynomial space in the size | A | of the RMC and exponential time in the size of the property (the automaton or the LTL formula). For several classes of RMCs, including single-exit RMCs (a class that encompasses some well-studied stochastic models, for instance, stochastic context-free grammars) the algorithm runs in polynomial time in | A |. For the quantitative model checking problem, we present algorithms that run in polynomial space in the RMC and exponential space in the property. For the class of linearly recursive RMCs we can compute the exact probability in time polynomial in the RMC and exponential in the property. For deterministic automata specifications, all our complexities in the specification come down by one exponential. For lower bounds, we show that the qualitative model checking problem, even for a fixed RMC, is already EXPTIME-complete. On the other hand, even for simple reachability analysis, we know from our prior work that our PSPACE upper bounds in A can not be improved substantially without a breakthrough on a well-known open problem in the complexity of numerical computation.",
    "cited_by_count": 27,
    "openalex_id": "https://openalex.org/W2142921329",
    "type": "article"
  },
  {
    "title": "Extensional Higher-Order Logic Programming",
    "doi": "https://doi.org/10.1145/2499937.2499942",
    "publication_date": "2013-08-01",
    "publication_year": 2013,
    "authors": "Angelos Charalambidis; Konstantinos Handjopoulos; Panagiotis Rondogiannis; William W. Wadge",
    "corresponding_authors": "",
    "abstract": "We propose a purely extensional semantics for higher-order logic programming. In this semantics program predicates denote sets of ordered tuples, and two predicates are equal iff they are equal as sets. Moreover, every program has a unique minimum Herbrand model which is the greatest lower bound of all Herbrand models of the program and the least fixed-point of an immediate consequence operator. We also propose an SLD-resolution proof system which is proven sound and complete with respect to the minimum Herbrand model semantics. In other words, we provide a purely extensional theoretical framework for higher-order logic programming which generalizes the familiar theory of classical (first-order) logic programming.",
    "cited_by_count": 26,
    "openalex_id": "https://openalex.org/W1591526886",
    "type": "article"
  },
  {
    "title": "A system of interaction and structure IV",
    "doi": "https://doi.org/10.1145/1970398.1970399",
    "publication_date": "2011-07-01",
    "publication_year": 2011,
    "authors": "Lutz Straß Burger; Alessio Guglielmi",
    "corresponding_authors": "",
    "abstract": "We study a system, called NEL, which is the mixed commutative/noncommutative linear logic BV augmented with linear logic's exponentials. Equivalently, NEL is MELL augmented with the noncommutative self-dual connective seq. In this article, we show a basic compositionality property of NEL, which we call decomposition . This result leads to a cut-elimination theorem, which is proved in the next article of this series. To control the induction measure for the theorem, we rely on a novel technique that extracts from NEL proofs the structure of exponentials, into what we call !-?-Flow-Graphs.",
    "cited_by_count": 26,
    "openalex_id": "https://openalex.org/W2006792923",
    "type": "article"
  },
  {
    "title": "Robust Vacuity for Branching Temporal Logic",
    "doi": "https://doi.org/10.1145/2071368.2071369",
    "publication_date": "2012-01-01",
    "publication_year": 2012,
    "authors": "Arie Gurfinkel; Marsha Chećhik",
    "corresponding_authors": "",
    "abstract": "There is a growing interest in techniques for detecting whether a logic specification is satisfied too easily, or vacuously . For example, the specification “every request is eventually followed by an acknowledgment” is satisfied vacuously by a system that never generates any requests. Vacuous satisfaction misleads users of model-checking into thinking that a system is correct. It is a serious problem in practice. There are several existing definitions of vacuity. Originally, Beer et al. [1997] formalized vacuity as insensitivity to syntactic perturbation ( syntactic vacuity ). This formulation captures the intuition of “vacuity” when applied to a single occurrence of a subformula. Armoni et al. argued that vacuity must be robust ; not affected by semantically invariant changes, such as extending a model with additional atomic propositions. They show that syntactic vacuity is not robust for subformulas of linear temporal logic, and propose an alternative definition; trace vacuity . In this article, we continue this line of research. We show that trace vacuity is not robust for branching time logic. We further refine the notion of vacuity so that it applies uniformly to linear and branching time logic and does not suffer from the common pitfalls of prior definitions. Our new definition, bisimulation vacuity , is a proper and nontrivial extension of both syntactic and trace vacuity. We discuss the complexity of detecting bisimulation vacuity, and identify several practically-relevant subsets of CTL* for which vacuity detection problem is reducible to model-checking. We believe that in most practical applications, bisimulation vacuity provides both the desired theoretical properties and is tractable computationally.",
    "cited_by_count": 26,
    "openalex_id": "https://openalex.org/W2101814946",
    "type": "article"
  },
  {
    "title": "Monadic second order logic on graphs with local cardinality constraints",
    "doi": "https://doi.org/10.1145/1877714.1877718",
    "publication_date": "2011-01-01",
    "publication_year": 2011,
    "authors": "Stefan Szeider",
    "corresponding_authors": "Stefan Szeider",
    "abstract": "We introduce the class of MSO-LCC problems, which are problems of the following form. Given a graph G and for each vertex v of G a set α( v ) of non-negative integers. Is there a set S of vertices or edges of G such that, (1) S satisfies a fixed property expressible in monadic second order logic, and (2) for each vertex v of G the number of vertices/edges in S adjacent/incident with v belongs to the set α( v )? We demonstrate that several hard combinatorial problems such as Lovász's General Factor Problem can be naturally formulated as MSO-LCC problems. Our main result is the polynomial-time tractability of MSO-LCC problems for graphs of bounded treewidth. We obtain this result by means of a tree-automata approach. By way of contrast we show that a more general class of MSO-LCC problems, where cardinality constraints are applied to second-order variables that are arbitrarily quantified, does not admit polynomial-time tractability for graphs of bounded treewidth unless P=NP.",
    "cited_by_count": 25,
    "openalex_id": "https://openalex.org/W2026493143",
    "type": "article"
  },
  {
    "title": "The tractability of model checking for LTL",
    "doi": "https://doi.org/10.1145/1877714.1877719",
    "publication_date": "2011-01-01",
    "publication_year": 2011,
    "authors": "Michael Bauland; Martin Mundhenk; Thomas Schneider; Henning Schnoor; Ilka Schnoor; Heribert Vollmer",
    "corresponding_authors": "",
    "abstract": "In a seminal paper from 1985, Sistla and Clarke showed that the model-checking problem for Linear Temporal Logic (LTL) is either NP-complete or PSPACE-complete, depending on the set of temporal operators used. If in contrast, the set of propositional operators is restricted, the complexity may decrease. This article systematically studies the model-checking problem for LTL formulae over restricted sets of propositional and temporal operators. For almost all combinations of temporal and propositional operators, we determine whether the model-checking problem is tractable (in PTIME) or intractable (NP-hard). We then focus on the tractable cases, showing that they all are NL-complete or even logspace solvable. This leads to a surprising gap in complexity between tractable and intractable cases. It is worth noting that our analysis covers an infinite set of problems, since there are infinitely many sets of propositional operators.",
    "cited_by_count": 25,
    "openalex_id": "https://openalex.org/W2058566227",
    "type": "article"
  },
  {
    "title": "Nominal Unification from a Higher-Order Perspective",
    "doi": "https://doi.org/10.1145/2159531.2159532",
    "publication_date": "2012-04-01",
    "publication_year": 2012,
    "authors": "Jordi Levy; Mateu Villaret",
    "corresponding_authors": "",
    "abstract": "Nominal logic is an extension of first-order logic with equality, name-binding, renaming via name-swapping and freshness of names. Contrarily to lambda-terms, in nominal terms, bindable names, called atoms, and instantiable variables are considered as distinct entities. Moreover, atoms are capturable by instantiations, breaking a fundamental principle of the lambda-calculus. Despite these differences, nominal unification can be seen from a higher-order perspective. From this view, we show that nominal unification can be quadratically reduced to a particular fragment of higher-order unification problems: higher-order pattern unification. We also prove that the translation preserves most generality of unifiers.",
    "cited_by_count": 25,
    "openalex_id": "https://openalex.org/W2141669458",
    "type": "article"
  },
  {
    "title": "Nonelementary Complexities for Branching VASS, MELL, and Extensions",
    "doi": "https://doi.org/10.1145/2733375",
    "publication_date": "2015-06-02",
    "publication_year": 2015,
    "authors": "Ranko Lazić; Sylvain Schmitz",
    "corresponding_authors": "",
    "abstract": "We study the complexity of reachability problems on branching extensions of vector addition systems, which allows us to derive new non-elementary complexity bounds for fragments and variants of propositional linear logic. We show that provability in the multiplicative exponential fragment is T ower -hard already in the affine case—and hence non-elementary. We match this lower bound for the full propositional affine linear logic, proving its T ower -completeness. We also show that provability in propositional contractive linear logic is A ckermann -complete.",
    "cited_by_count": 24,
    "openalex_id": "https://openalex.org/W2568513581",
    "type": "article"
  },
  {
    "title": "Power and Limits of Structural Display Rules",
    "doi": "https://doi.org/10.1145/2874775",
    "publication_date": "2016-02-17",
    "publication_year": 2016,
    "authors": "Agata Ciabattoni; Revantha Ramanayake",
    "corresponding_authors": "",
    "abstract": "What can (and cannot) be expressed by structural display rules? Given a display calculus, we present a systematic procedure for transforming axioms into structural rules. The conditions for the procedure are given in terms of (purely syntactic) abstract properties of the base calculus; thus, the method applies to large classes of calculi and logics. If the calculus satisfies certain additional properties, we prove the converse direction, thus characterising the class of axioms that can be captured by structural display rules. Determining if an axiom belongs to this class or not is shown to be decidable. Applied to the display calculus for tense logic, we obtain a new proof of Kracht’s Display Theorem I.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W2281452765",
    "type": "article"
  },
  {
    "title": "Intuitionistic Linear Temporal Logics",
    "doi": "https://doi.org/10.1145/3365833",
    "publication_date": "2019-12-20",
    "publication_year": 2019,
    "authors": "Philippe Balbiani; Joseph Boudou; Martín Diéguez; David Fernández–Duque",
    "corresponding_authors": "",
    "abstract": "We consider intuitionistic variants of linear temporal logic with “next,” “until,” and “release” based on expanding posets : partial orders equipped with an order-preserving transition function. This class of structures gives rise to a logic that we denote ITL e , and by imposing additional constraints, we obtain the logics ITL p of persistent posets and ITL ht of here-and-there temporal logic, both of which have been considered in the literature. We prove that ITL e has the effective finite model property and hence is decidable, while ITL p does not have the finite model property. We also introduce notions of bounded bisimulations for these logics and use them to show that the “until” and “release” operators are not definable in terms of each other, even over the class of persistent posets.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W2994676117",
    "type": "article"
  },
  {
    "title": "The Local Universes Model",
    "doi": "https://doi.org/10.1145/2754931",
    "publication_date": "2015-07-04",
    "publication_year": 2015,
    "authors": "Peter LeFanu Lumsdaine; Michael A. Warren",
    "corresponding_authors": "",
    "abstract": "We present a new coherence theorem for comprehension categories, providing strict models of dependent type theory with all standard constructors, including dependent products, dependent sums, identity types, and other inductive types. Precisely, we take as input a “weak model”: a comprehension category, equipped with structure corresponding to the desired logical constructions. We assume throughout that the base category is close to locally Cartesian closed: specifically, that products and certain exponentials exist. Beyond this, we require only that the logical structure should be weakly stable —a pure existence statement, not involving any specific choice of structure, weaker than standard categorical Beck--Chevalley conditions, and holding in the now standard homotopy-theoretic models of type theory. Given such a comprehension category, we construct an equivalent split one whose logical structure is strictly stable under reindexing. This yields an interpretation of type theory with the chosen constructors. The model is adapted from Voevodsky's use of universes for coherence, and at the level of fibrations is a classical construction of Giraud. It may be viewed in terms of local universes or delayed substitutions.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W4293252599",
    "type": "article"
  },
  {
    "title": "Fast Query Answering over Existential Rules",
    "doi": "https://doi.org/10.1145/3308448",
    "publication_date": "2019-03-27",
    "publication_year": 2019,
    "authors": "Nicola Leone; Marco Manna; Giorgio Terracina; Pierfrancesco Veltri",
    "corresponding_authors": "",
    "abstract": "Enhancing Datalog with existential quantification gives rise to Datalog ∃ , a powerful knowledge representation language widely used in ontology-based query answering. In this setting, a conjunctive query is evaluated over a Datalog ∃ program consisting of extensional data paired with so-called “existential” rules. Owing to their high expressiveness, such rules make the evaluation of queries undecidable, even when the latter are atomic. Decidable generalizations of Datalog by existential rules have been proposed in the literature (such as weakly acyclic and weakly guarded); but they pay the price of higher computational complexity, hindering the implementation of effective systems. Conversely, the results in this article demonstrate that it is definitely possible to enable fast yet powerful query answering over existential rules that strictly generalize Datalog by ensuring decidability without any complexity overhead. On the theoretical side, we define the class of parsimonious programs that guarantees decidability of atomic queries. We then strengthen this class to strongly parsimonious programs ensuring decidability also for conjunctive queries. Since parsimony is an undecidable property, we single out Shy, an easily recognizable class of strongly parsimonious programs that generalizes Datalog while preserving its complexity even under conjunctive queries. Shy also generalizes the class of linear existential programs, while it is uncomparable to the other main classes ensuring decidability. On the practical side, we exploit our results to implement DLV ∃ , an effective system for query answering over parsimonious existential rules. To assess its efficiency, we carry out an experimental analysis, evaluating DLV ∃ performances for ontology-based query answering on both real-world and synthetic ontologies.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W2926816154",
    "type": "article"
  },
  {
    "title": "Using tableau to decide description logics with full role negation and identity",
    "doi": "https://doi.org/10.1145/2559947",
    "publication_date": "2014-02-01",
    "publication_year": 2014,
    "authors": "Renate A. Schmidt; Dmitry Tishkovsky",
    "corresponding_authors": "",
    "abstract": "This article presents a tableau approach for deciding expressive description logics with full role negation and role identity. We consider the description logic ALBO id , which is ALC extended with the Boolean role operators, inverse of roles, the identity role, and includes full support for individuals and singleton concepts. ALBO id is expressively equivalent to the two-variable fragment of first-order logic with equality and subsumes Boolean modal logic. In this article, we define a sound, complete, and terminating tableau calculus for ALBO id that provides the basis for decision procedures for this logic and all its sublogics. An important novelty of our approach is the use of a generic unrestricted blocking mechanism. Unrestricted blocking is based on equality reasoning and a conceptually simple rule, which performs case distinctions over the identity of individuals. The blocking mechanism ties the proof of termination of tableau derivations to the finite model property of ALBO id .",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W3122242939",
    "type": "article"
  },
  {
    "title": "A Complete Finite Axiomatisation of the Equational Theory of Common Meadows",
    "doi": "https://doi.org/10.1145/3689211",
    "publication_date": "2024-08-17",
    "publication_year": 2024,
    "authors": "J.A. Bergstra; John V. Tucker",
    "corresponding_authors": "",
    "abstract": "We analyse abstract data types that model numerical structures with a concept of error. Specifically, we focus on arithmetic data types that contain an error value \\(\\bot\\) whose main purpose is to always return a value for division. To rings and fields, we add a division operator \\(x/y\\) and study a class of algebras called common meadows wherein \\(x/0=\\bot\\) . The set of equations true in all common meadows is named the equational theory of common meadows . We give a finite equational axiomatisation of the equational theory of common meadows and prove that it is complete and that the equational theory is decidable.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4401665823",
    "type": "article"
  },
  {
    "title": "Logics with counting and local properties",
    "doi": "https://doi.org/10.1145/343369.343376",
    "publication_date": "2000-07-01",
    "publication_year": 2000,
    "authors": "Leonid Libkin",
    "corresponding_authors": "Leonid Libkin",
    "abstract": "The expressive power of first-order logic over finite structures is limited in two ways: it lacks a recursion mechanism, and it cannot count. Overcoming the first limitation has been a subject of extensive study. A number of fixpoint logics have been introduced. and shown to be subsumed by an infinitary logic L ω ∞ω . This logic is easier to analyze than fixpoint logics, and it still lacks counting power, as it has a 0-1 law. On the counting side, there is no analog of L ω ∞ω . There are a number of logics with counting power, usually introduced via generalized quantifiers. Most known expressivityy bounds are based on the fact that counting extensions of first-order logic preserve the locality properties. This article has three main goals. First, we introduce a new logic L * ∞ω ( C ) that plays the same role for counting as L ω ∞ω does for recursion—it subsumes a number of extensions of first-order logic with counting, and has nice properties that make it easy to study. Second, we give simple direct proof that L ω ∞ω ( C ) expresses only local properties: those that depend on the properties of small neighborhoods, but cannot grasp a structure as a whole. This is a general way of saying that a logic lacks a recursion mechanism. Third, we consider a finer analysis of locality of counting logics. In particular, we address the question of how local a logic is, that is, how big are those neighborhoods that local properties depend on. We get a uniform answer for a variety of logics between first-order and L * ∞ω ( C ). This is done by introducing a new form of locality that captures the tightest condition that the duplicator needs to maintain in order to win a game. We also use this technique to give bounds on outputs of L * ∞ω (C)-definable queries.",
    "cited_by_count": 42,
    "openalex_id": "https://openalex.org/W2013208146",
    "type": "article"
  },
  {
    "title": "Locality of order-invariant first-order formulas",
    "doi": "https://doi.org/10.1145/343369.343386",
    "publication_date": "2000-07-01",
    "publication_year": 2000,
    "authors": "Martin Grohe; Thomas Schwentick",
    "corresponding_authors": "",
    "abstract": "A query is local if the decision of whether a tuple in a structure satisfies this query only depends on a small neighborhood of the tuple. We prove that all queries expressible by order-invariant first-order formulas are local.",
    "cited_by_count": 40,
    "openalex_id": "https://openalex.org/W2100006909",
    "type": "article"
  },
  {
    "title": "The intuitionism behind Statecharts steps",
    "doi": "https://doi.org/10.1145/504077.504078",
    "publication_date": "2002-01-01",
    "publication_year": 2002,
    "authors": "Gerald Lüttgen; Michael Mendler",
    "corresponding_authors": "",
    "abstract": "The semantics of Statecharts macro steps, as introduced by Pnueli and Shalev [1991], lacks compositionality. This article first analyzes the compositionality problem and traces it back to the invalidity of the Law of the Excluded Middle. It then characterizes the semantics via a particular class of linear intuitionistic Kripke models. This yields, for the first time in the literature, a simple fully abstract semantics that interprets Pnueli and Shalev's concept of failure naturally. The results not only give insight into the semantic subtleties of Statecharts, but also provide a basis for an implementation, for developing algebraic theories for macro steps, and for comparing different Statecharts variants.",
    "cited_by_count": 40,
    "openalex_id": "https://openalex.org/W2119997500",
    "type": "article"
  },
  {
    "title": "First-order conditional logic for default reasoning revisited",
    "doi": "https://doi.org/10.1145/359496.359500",
    "publication_date": "2000-10-01",
    "publication_year": 2000,
    "authors": "Nir Friedman; Joseph Y. Halpern; Daphne Koller",
    "corresponding_authors": "",
    "abstract": "Conditional logics play an important role in recent attempts to formulate theories of default reasoning. This paper investigates first-order conditional logic. We show that, as for first-order probabilistic logic, it is important not to confound statistical conditionals over the domain (such as “most birds fly”), and subjective conditionals over possible worlds (such as “I believe that Tweety is unlikely to fly”). We then address the issue of ascribing semantics to first-order conditional logic. As in the propositional case, there are many possible semantics. To study the problem in a coherent way, we use plausibility structures . These provide us with a general framework in which many of the standard approaches can be embedded. We show that while these standard approaches are all the same at the propositional level, they are significantly different in the context of a first-order language. Furthermore, we show that plausibilities provide the most natural extension of conditional logic to the first-order case:we provide a sound and complete axiomatization that contains only the KLM properties and standard axioms of first-order modal logic. We show that most of the other approaches have additional properties, which result in an inappropriate treatment of an infinitary version of the lottery paradox .",
    "cited_by_count": 38,
    "openalex_id": "https://openalex.org/W2044081892",
    "type": "article"
  },
  {
    "title": "Termination proofs for logic programs with tabling",
    "doi": "https://doi.org/10.1145/371282.371357",
    "publication_date": "2001-01-01",
    "publication_year": 2001,
    "authors": "Sofie Verbaeten; Danny De Schreye; Konstantinos Sagonas",
    "corresponding_authors": "",
    "abstract": "Tabled evaluation is receiving increasing attention in the logic programming community. It avoids many of the shortcomings of SLD execution and provides a more flexible and often considerably more efficient execution mechanism for logic programs. In particular, tabled execution terminates more often than execution based on SLD-resolution. In this article, we introduce two notions of universal termination of logic programming with tabling: quasi-termination and (the stronger notion of) LG-termination. We present sufficient conditions for these two notions of termination, namely quasi-acceptability and LG-acceptability, and we show that these conditions are also necessary in case the selection of tabled predicates meets certain natural criteria. Starting from these conditions, we develop modular termination proofs, i.e., proofs capable of combining termination proofs of separate programs to obtain termination proofs of combined programs. Finally, in the presence of mode information, we state sufficient conditions which form the basis for automatically proving termination in a constraint-based way.",
    "cited_by_count": 38,
    "openalex_id": "https://openalex.org/W2129825950",
    "type": "article"
  },
  {
    "title": "Interval constraint solving for camera control and motion planning",
    "doi": "https://doi.org/10.1145/1024922.1024927",
    "publication_date": "2004-10-01",
    "publication_year": 2004,
    "authors": "Frédéric Benhamou; Frédéric Goualard; Éric Languénou; Marc Christie",
    "corresponding_authors": "",
    "abstract": "Many problems in robust control and motion planning can be reduced to either finding a sound approximation of the solution space determined by a set of nonlinear inequalities, or to the \"guaranteed tuning problem\" as defined by Jaulin and Walter, which amounts to finding a value for some tuning parameter such that a set of inequalities be verified for all the possible values of some perturbation vector. A classical approach to solving these problems, which satisfies the strong soundness requirement, involves some quantifier elimination procedure such as Collins' Cylindrical Algebraic Decomposition symbolic method. Sound numerical methods using interval arithmetic and local consistency enforcement to prune the search space are presented in this article as much faster alternatives for both soundly solving systems of nonlinear inequalities, and addressing the guaranteed tuning problem whenever the perturbation vector has dimension 1. The use of these methods in camera control is investigated, and experiments with the prototype of a declarative modeler to express camera motion using a cinematic language are reported and commented upon.",
    "cited_by_count": 38,
    "openalex_id": "https://openalex.org/W2135202456",
    "type": "article"
  },
  {
    "title": "Topological incompleteness and order incompleteness of the lambda calculus",
    "doi": "https://doi.org/10.1145/772062.772067",
    "publication_date": "2003-07-01",
    "publication_year": 2003,
    "authors": "Antonino Salibra",
    "corresponding_authors": "Antonino Salibra",
    "abstract": "A model of the untyped lambda calculus univocally induces a lambda theory (i.e., a congruence relation on λ-terms closed under α- and β-conversion) through the kernel congruence relation of the interpretation function. A semantics of lambda calculus is (equationally) incomplete if there exists a lambda theory that is not induced by any model in the semantics. In this article, we introduce a new technique to prove in a uniform way the incompleteness of all denotational semantics of lambda calculus that have been proposed so far, including the strongly stable one, whose incompleteness had been conjectured by Bastonero, Gouy and Berline. We apply this technique to prove the incompleteness of any semantics of lambda calculus given in terms of partially ordered models with a bottom element. This incompleteness removes the belief that partial orderings with a bottom element are intrinsic to models of the lambda calculus, and that the incompleteness of a semantics is only due to the richness of the structure of representable functions. Instead, the incompleteness is also due to the richness of the structure of lambda theories. Further results of the article are: (i) an incompleteness theorem for partially ordered models with finitely many connected components (= minimal upward and downward closed sets); (ii) an incompleteness theorem for topological models whose topology satisfies a suitable property of connectedness; (iii) a completeness theorem for topological models whose topology is non-trivial and metrizable.",
    "cited_by_count": 36,
    "openalex_id": "https://openalex.org/W1991093042",
    "type": "article"
  },
  {
    "title": "On proving left termination of constraint logic programs",
    "doi": "https://doi.org/10.1145/635499.635503",
    "publication_date": "2003-04-01",
    "publication_year": 2003,
    "authors": "Fred Mesnard; Salvatore Ruggieri",
    "corresponding_authors": "",
    "abstract": "The Constraint Logic Programming (CLP) Scheme merges logic programming with constraint solving over predefined domains. In this article, we study proof methods for universal left termination of constraint logic programs. We provide a sound and complete characterization of left termination for ideal CLP languages which generalizes acceptability of logic programs. The characterization is then refined to the notion of partial acceptability , which is well suited for automatic modular inference. We describe a theoretical framework for automation of the approach, which is implemented. For nonideal CLP languages and without any assumption on their incomplete constraint solvers, even the most basic sound termination criterion from logic programming does not lift. We focus on a specific system, namely CLP(R), by proposing some additional conditions that make (partial) acceptability sound.",
    "cited_by_count": 36,
    "openalex_id": "https://openalex.org/W1999783590",
    "type": "article"
  },
  {
    "title": "A modal logic for mobile agents",
    "doi": "https://doi.org/10.1145/963927.963930",
    "publication_date": "2004-01-01",
    "publication_year": 2004,
    "authors": "Rocco De Nicola; Michele Loreti",
    "corresponding_authors": "",
    "abstract": "Klaim is an experimental programming language that supports a programming paradigm where both processes and data can be moved across different computing environments. The language relies on the use of explicit localities. This paper presents a temporal logic for specifying properties of Klaim programs. The logic is inspired by Hennessy-Milner Logic (HML) and the μ-calculus, but has novel features that permit dealing with state properties and impact of actions and movements over the different sites. The logic is equipped with a complete proof system that enables one to prove properties of mobile systems.",
    "cited_by_count": 36,
    "openalex_id": "https://openalex.org/W2026960406",
    "type": "article"
  },
  {
    "title": "Inflationary fixed points in modal logic",
    "doi": "https://doi.org/10.1145/976706.976710",
    "publication_date": "2004-04-01",
    "publication_year": 2004,
    "authors": "Anuj Dawar; Erich Grädel; Stephan Kreutzer",
    "corresponding_authors": "",
    "abstract": "We consider an extension of modal logic with an operator for constructing inflationary fixed points, just as the modal μ-calculus extends basic modal logic with an operator for least fixed points. Least and inflationary fixed-point operators have been studied and compared in other contexts, particularly in finite model theory, where it is known that the logics IFP and LFP that result from adding such fixed-point operators to first-order logic have equal expressive power. As we show, the situation in modal logic is quite different, as the modal iteration calculus (MIC), we introduce has much greater expressive power than the μ-calculus. Greater expressive power comes at a cost: the calculus is algorithmically much less manageable.",
    "cited_by_count": 36,
    "openalex_id": "https://openalex.org/W2045916861",
    "type": "article"
  },
  {
    "title": "Predicate-calculus-based logics for modeling and solving search problems",
    "doi": "https://doi.org/10.1145/1119439.1119441",
    "publication_date": "2006-01-01",
    "publication_year": 2006,
    "authors": "Deborah East; Mirosław Truszczyński",
    "corresponding_authors": "",
    "abstract": "The answer-set programming (ASP) paradigm is a way of using logic to solve search problems. Given a search problem, to solve it one designs a logic theory so that models of this theory represent problem solutions. To compute a solution to the problem, one computes a model of the theory. Several answer-set programming formalisms have been developed on the basis of logic programming with the semantics of answer sets. In this article we show that predicate logic also gives rise to effective implementations of the ASP paradigm, similar in spirit to logic programming with the answer-set semantics and with a similar scope of applicability. Specifically, we propose two logics based on predicate calculus as formalisms for encoding search problems. We show that the expressive power of these logics is given by the class NPMV. We demonstrate their use in programming and discuss computational approaches to model finding. To address this latter issue, we follow a two-pronged approach. On the one hand, we show that the problem can be reduced to that of computing models of propositional theories and, more generally, of collections of pseudo-Boolean constraints. Consequently, programs (solvers) developed in the areas of propositional and pseudo-Boolean satisfiability can be used to compute models of theories in our logics. On the other hand, we develop native solvers designed specifically to exploit features of our formalisms. We present experimental results demonstrating the computational effectiveness of the overall approach.",
    "cited_by_count": 35,
    "openalex_id": "https://openalex.org/W2041526687",
    "type": "article"
  },
  {
    "title": "Constant-depth Frege systems with counting axioms polynomially simulate Nullstellensatz refutations",
    "doi": "https://doi.org/10.1145/1131313.1131314",
    "publication_date": "2006-04-01",
    "publication_year": 2006,
    "authors": "Russell Impagliazzo; Nathan Segerlind",
    "corresponding_authors": "",
    "abstract": "We show that constant-depth Frege systems with counting axioms modulo m polynomially simulate Nullstellensatz refutations modulo m . Central to this is a new definition of reducibility from propositional formulas to systems of polynomials. Using our definition of reducibility, most previously studied propositional formulas reduce to their polynomial translations. When combined with a previous result of the authors, this establishes the first size separation between Nullstellensatz and polynomial calculus refutations. We also obtain new upper bounds on refutation sizes for certain CNFs in constant-depth Frege with counting axioms systems.",
    "cited_by_count": 33,
    "openalex_id": "https://openalex.org/W1975857059",
    "type": "article"
  },
  {
    "title": "Abstract canonical inference",
    "doi": "https://doi.org/10.1145/1182613.1182619",
    "publication_date": "2007-01-01",
    "publication_year": 2007,
    "authors": "Maria Paola Bonacina; Nachum Dershowitz",
    "corresponding_authors": "",
    "abstract": "An abstract framework of canonical inference is used to explore how different proof orderings induce different variants of saturation and completeness. Notions like completion, paramodulation, saturation, redundancy elimination, and rewrite-system reduction are connected to proof orderings. Fairness of deductive mechanisms is defined in terms of proof orderings, distinguishing between (ordinary) \"fairness,\" which yields completeness, and \"uniform fairness,\" which yields saturation.",
    "cited_by_count": 29,
    "openalex_id": "https://openalex.org/W3104411811",
    "type": "article"
  },
  {
    "title": "Probabilistic bisimulation as a congruence",
    "doi": "https://doi.org/10.1145/1462179.1462181",
    "publication_date": "2009-02-01",
    "publication_year": 2009,
    "authors": "Ruggero Lanotte; Simone Tini",
    "corresponding_authors": "",
    "abstract": "We propose both an SOS transition rule format for the generative model of probabilistic processes, and an SOS transition rule format for the reactive model of the probabilistic processes. Our rule formats guarantee that probabilistic bisimulation is a congruence with respect to process algebra operations. Moreover, our rule format for generative process algebras guarantees that the probability of the moves of a given process, if there are any, sum up to 1, and the rule format for reactive process algebras guarantees that the probability of the moves of a given process labeled with the same action, if there are any, sum up to 1. We show that most operations of the probabilistic process algebras studied in the literature are captured by our formats, which, therefore, have practical applications.",
    "cited_by_count": 28,
    "openalex_id": "https://openalex.org/W2071882940",
    "type": "article"
  },
  {
    "title": "Verifying nondeterministic probabilistic channel systems against ω-regular linear-time properties",
    "doi": "https://doi.org/10.1145/1297658.1297663",
    "publication_date": "2007-12-01",
    "publication_year": 2007,
    "authors": "Christel Baier; Nathalie Bertrand; Philippe Schnoebelen",
    "corresponding_authors": "",
    "abstract": "Lossy channel systems (LCS's) are systems of finite state processes that communicate via unreliable unbounded fifo channels. We introduce NPLCS's, a variant of LCS's where message losses have a probabilistic behavior while the component processes behave nondeterministically, and study the decidability of qualitative verification problems for ω-regular linear-time properties. We show that—in contrast to finite-state Markov decision processes—the satisfaction relation for linear-time formulas depends on the type of schedulers that resolve the nondeterminism. While the qualitative model checking problem for the full class of history-dependent schedulers is undecidable, the same question for finite-memory schedulers can be solved algorithmically. Additionally, some special kinds of reachability, or recurrent reachability, qualitative properties yield decidable verification problems for the full class of schedulers, which—for this restricted class of problems—are as powerful as finite-memory schedulers, or even a subclass of them.",
    "cited_by_count": 28,
    "openalex_id": "https://openalex.org/W2083816928",
    "type": "article"
  },
  {
    "title": "Open answer set programming with guarded programs",
    "doi": "https://doi.org/10.1145/1380572.1380575",
    "publication_date": "2008-08-01",
    "publication_year": 2008,
    "authors": "Stijn Heymans; Davy Van Nieuwenborgh; Dirk Vermeir",
    "corresponding_authors": "",
    "abstract": "Open answer set programming (OASP) is an extension of answer set programming where one may ground a program with an arbitrary superset of the program's constants. We define a fixed-point logic (FPL) extension of Clark's completion such that open answer sets correspond to models of FPL formulas and identify a syntactic subclass of programs, called ( loosely ) guarded programs . Whereas reasoning with general programs in OASP is undecidable, the FPL translation of (loosely) guarded programs falls in the decidable (loosely) guarded fixed-point logic (μ(L)GF). Moreover, we reduce normal closed ASP to loosely guarded OASP, enabling, for the first time, a characterization of an answer set semantics by μLGF formulas. We further extend the open answer set semantics for programs with generalized literals. Such generalized programs (gPs) have interesting properties, for example, the ability to express infinity axioms. We restrict the syntax of gPs such that both rules and generalized literals are guarded . Via a translation to guarded fixed-point logic, we deduce 2-EXPTIME-completeness of satisfiability checking in such guarded gPs (GgPs). Bound GgPs are restricted GgPs with EXPTIME-complete satisfiability checking, but still sufficiently expressive to optimally simulate computation tree logic (CTL). We translate Datalog lite programs to GgPs, establishing equivalence of GgPs under an open answer set semantics, alternation-free μGF, and Datalog LITE.",
    "cited_by_count": 27,
    "openalex_id": "https://openalex.org/W2004758195",
    "type": "article"
  },
  {
    "title": "Bounds on the automata size for Presburger arithmetic",
    "doi": "https://doi.org/10.1145/1342991.1342995",
    "publication_date": "2008-03-01",
    "publication_year": 2008,
    "authors": "Felix Klaedtke",
    "corresponding_authors": "Felix Klaedtke",
    "abstract": "Automata provide a decision procedure for Presburger arithmetic. However, until now only crude lower and upper bounds were known on the sizes of the automata produced by the automata-based approach for Presburger arithmetic. In this article, we give an upper bound on the number of states of the minimal deterministic automaton for a Presburger arithmetic formula. This bound depends on the length of the formula and the quantifiers occurring in it. We establish the upper bound by comparing the automata for Presburger arithmetic formulas with the formulas produced by a quantifier-elimination method. We show that our bound is tight, also for nondeterministic automata. Moreover, we provide automata constructions for atomic formulas and establish lower bounds for the automata for linear equations and inequations.",
    "cited_by_count": 27,
    "openalex_id": "https://openalex.org/W2067677333",
    "type": "article"
  },
  {
    "title": "Monadic datalog over finite structures of bounded treewidth",
    "doi": "https://doi.org/10.1145/1838552.1838555",
    "publication_date": "2010-10-01",
    "publication_year": 2010,
    "authors": "Georg Gottlob; Reinhard Pichler; Fang Wei",
    "corresponding_authors": "",
    "abstract": "Bounded treewidth and monadic second-order (MSO) logic have proved to be key concepts in establishing fixed-parameter tractability results. Indeed, by Courcelle's Theorem we know that any property of finite structures, which is expressible by an MSO sentence, can be decided in linear time (data complexity) if the structures have bounded treewidth. In principle, Courcelle's Theorem can be applied directly to construct concrete algorithms by transforming the MSO evaluation problem into a tree language recognition problem. The latter can then be solved via a finite tree automaton (FTA). However, this approach has turned out to be problematical, since even relatively simple MSO formulae may lead to a “state explosion” of the FTA. In this work we propose monadic datalog (i.e., datalog where all intentional predicate symbols are unary) as an alternative method to tackle this class of fixed-parameter tractable problems. We show that if some property of finite structures is expressible in MSO then this property can also be expressed by means of a monadic datalog program over the decomposed structure : we mean by this that the original structure is augmented with new elements and new relations that encode one of its tree decompositions. In the first place, we thus compare the expressive power of two query languages. However, we also show that the resulting fragment of datalog can be evaluated in linear time (both with respect to the program size and with respect to the data size). Hence, our transformation of an MSO query into a monadic datalog program yields an alternative proof of Courcelle's Theorem. In order to actually construct efficient algorithms for problems whose tractability is due to Courcelle's Theorem, we propose to use a fragment of full (i.e., not necessarily monadic) datalog which allows for a succinct representation of the corresponding monadic datalog programs and for an efficient execution. This new approach is put to work by devising datalog programs for the 3-Colorability problem of graphs and for the PRIMALITY problem of relational schemas (i.e., testing if some attribute in a relational schema is part of a key). We also report on experimental results with a prototype implementation.",
    "cited_by_count": 25,
    "openalex_id": "https://openalex.org/W2016416699",
    "type": "article"
  },
  {
    "title": "Qualitative concurrent parity games",
    "doi": "https://doi.org/10.1145/1970398.1970404",
    "publication_date": "2011-07-01",
    "publication_year": 2011,
    "authors": "Krishnendu Chatterjee; Luca de Alfaro; Thomas A. Henzinger",
    "corresponding_authors": "",
    "abstract": "We consider two-player games played on a finite state space for an infinite number of rounds. The games are concurrent : in each round, the two players (player 1 and player 2) choose their moves independently and simultaneously; the current state and the two moves determine the successor state. We consider ω-regular winning conditions specified as parity objectives. Both players are allowed to use randomization when choosing their moves. We study the computation of the limit-winning set of states, consisting of the states where the sup-inf value of the game for player 1 is 1: in other words, a state is limit-winning if player 1 can ensure a probability of winning arbitrarily close to 1. We show that the limit-winning set can be computed in O ( n 2 d +2) time, where n is the size of the game structure and 2 d is the number of priorities (or colors). The membership problem of whether a state belongs to the limit-winning set can be decided in NP ∩ coNP. While this complexity is the same as for the simpler class of turn-based parity games, where in each state only one of the two players has a choice of moves, our algorithms are considerably more involved than those for turn-based games. This is because concurrent games do not satisfy two of the most fundamental properties of turn-based parity games. First, in concurrent games limit-winning strategies require randomization; and second, they require infinite memory.",
    "cited_by_count": 24,
    "openalex_id": "https://openalex.org/W2029583849",
    "type": "article"
  },
  {
    "title": "MWeb",
    "doi": "https://doi.org/10.1145/1877714.1877723",
    "publication_date": "2011-01-01",
    "publication_year": 2011,
    "authors": "Anastasia Analyti; Grigoris Antoniou; Carlos Viegas Damásio",
    "corresponding_authors": "",
    "abstract": "We present a principled framework for modular Web rule bases, called MWeb. According to this framework, each predicate defined in a rule base is characterized by its defining reasoning mode, scope, and exporting rule base list. Each predicate used in a rule base is characterized by its requesting reasoning mode and importing rule base list. For legal MWeb modular rule bases S , the MWebAS and MWebWFS semantics of each rule base s ∈ S with respect to S are defined model-theoretically. These semantics extend the answer set semantics (AS) and the well-founded semantics with explicit negation (WFSX) on ELPs, respectively, keeping all of their semantical and computational characteristics. Our framework supports: (1) local semantics and different points of view, (2) local closed-world and open-world assumptions, (3) scoped negation-as-failure, (4) restricted propagation of local inconsistencies, and (5) monotonicity of reasoning, for fully shared predicates.",
    "cited_by_count": 24,
    "openalex_id": "https://openalex.org/W2070983174",
    "type": "article"
  },
  {
    "title": "Query-Driven Procedures for Hybrid MKNF Knowledge Bases",
    "doi": "https://doi.org/10.1145/2480759.2480768",
    "publication_date": "2013-06-01",
    "publication_year": 2013,
    "authors": "José Júlio Alferes; Matthias Knorr; Terrance Swift",
    "corresponding_authors": "",
    "abstract": "Hybrid MKNF knowledge bases are one of the most prominent tightly integrated combinations of open-world ontology languages with closed-world (nonmonotonic) rule paradigms. Based on the logic of minimal knowledge and negation as failure (MKNF), the definition of Hybrid MKNF is parametric on the description logic (DL) underlying the ontology language, in the sense that nonmonotonic rules can extend any decidable DL language. Two related semantics have been defined for Hybrid MKNF: one that is based on the Stable Model Semantics for logic programs and one on the Well-Founded Semantics (WFS). Under WFS, the definition of Hybrid MKNF relies on a bottom-up computation that has polynomial data complexity whenever the DL language is tractable. Here we define a general query-driven procedure for Hybrid MKNF that is sound with respect to the stable model-based semantics, and sound and complete with respect to its WFS variant. This procedure is able to answer a slightly restricted form of conjunctive queries, and is based on tabled rule evaluation extended with an external oracle that captures reasoning within the ontology. Such an (abstract) oracle receives as input a query along with knowledge already derived, and replies with a (possibly empty) set of atoms, defined in the rules, whose truth would suffice to prove the initial query. With appropriate assumptions on the complexity of the abstract oracle, the general procedure maintains the data complexity of the WFS for Hybrid MKNF knowledge bases. To illustrate this approach, we provide a concrete oracle for EL + , a fragment of the lightweight DL EL ++ . Such an oracle has practical use, as EL ++ is the language underlying OWL 2 EL, which is part of the W3C recommendations for the Semantic Web, and is tractable for reasoning tasks such as subsumption. We show that query-driven Hybrid MKNF preserves polynomial data complexity when using the EL + oracle and WFS.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W2140466857",
    "type": "article"
  },
  {
    "title": "Annotated Probabilistic Temporal Logic",
    "doi": "https://doi.org/10.1145/2159531.2159535",
    "publication_date": "2012-04-01",
    "publication_year": 2012,
    "authors": "Paulo Shakarian; Gerardo I. Simari; V. S. Subrahmanian",
    "corresponding_authors": "",
    "abstract": "Annotated Probabilistic Temporal (APT) logic programs support building applications where we wish to reason about statements of the form “Formula G becomes true with a probability in the range [ L , U ] within (or in exactly) Δt time units after formula F became true.” In this paper, we present a sound, but incomplete fixpoint operator that can be used to check consistency and entailment in APT logic programs. We present the first implementation of APT-logic programs and evaluate both its compute time and convergence on a suite of 23 ground APT-logic programs that were automatically learned from two real-world data sets. In both cases, the APT-logic programs contained up to 1,000 ground rules. In one data set, entailment problems were solved on average in under 0.1 seconds per ground rule, while in the other, it took up to 1.3 seconds per ground rule. Consistency was also checked in a reasonable amount of time. When discussing entailment of APT-logic formulas, convergence of the fixpoint operator refers to ( U − L ) being below a certain threshold. We show that on virtually all of the 23 automatically generated APT-logic programs, convergence was quick---often in just 2-3 iterations of the fixpoint operator. Thus, our implementation is a practical first step towards checking consistency and entailment in temporal probabilistic logics without independence or Markovian assumptions.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W2142814561",
    "type": "article"
  },
  {
    "title": "Unification and matching on compressed terms",
    "doi": "https://doi.org/10.1145/1970398.1970402",
    "publication_date": "2011-07-01",
    "publication_year": 2011,
    "authors": "Adrià Gascón; Guillem Godoy; Manfred Schmidt-Schauß",
    "corresponding_authors": "",
    "abstract": "Term unification plays an important role in many areas of computer science, especially in those related to logic. The universal mechanism of grammar-based compression for terms, in particular the so-called singleton tree grammars (STGAs) , have recently drawn considerable attention. Using STGs, terms of exponential size and height can be represented in linear space. Furthermore, the term representation by directed acyclic graphs (dags) can be efficiently simulated. The present article is the result of an investigation on term unification and matching when the terms given as input are represented using different compression mechanisms for terms such as dags and singleton tree grammars. We describe a polynomial time algorithm for context matching with dags, when the number of different context variables is fixed for the problem. For the same problem, NP-completeness is obtained when the terms are represented using the more general formalism of singleton tree grammars. For first-order unification and matching polynomial time algorithms are presented, each of them improving previous results for those problems.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W2122839006",
    "type": "article"
  },
  {
    "title": "Embedding nonground logic programs into autoepistemic logic for knowledge-base combination",
    "doi": "https://doi.org/10.1145/1929954.1929957",
    "publication_date": "2011-05-01",
    "publication_year": 2011,
    "authors": "Jos de Bruijn; Thomas Eiter; Axel Polleres; Hans Tompits",
    "corresponding_authors": "",
    "abstract": "In the context of the Semantic Web, several approaches for combining ontologies, given in terms of theories of classical first-order logic and rule bases, have been proposed. They either cast rules into classical logic or limit the interaction between rules and ontologies. Autoepistemic logic (AEL) is an attractive formalism which allows overcoming these limitations by serving as a uniform host language to embed ontologies and nonmonotonic logic programs into it. For the latter, so far only the propositional setting has been considered. In this article, we present three embeddings of normal and three embeddings of disjunctive nonground logic programs under the stable model semantics into first-order AEL. While all embeddings correspond with respect to objective ground atoms, differences arise when considering nonatomic formulas and combinations with first-order theories. We compare the embeddings with respect to stable expansions and autoepistemic consequences, considering the embeddings by themselves, as well as combinations with classical theories. Our results reveal differences and correspondences of the embeddings, and provide useful guidance in the choice of a particular embedding for knowledge combination.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W2157081549",
    "type": "article"
  },
  {
    "title": "Proposition algebra",
    "doi": "https://doi.org/10.1145/1929954.1929958",
    "publication_date": "2011-05-01",
    "publication_year": 2011,
    "authors": "J.A. Bergstra; Alban Ponse",
    "corresponding_authors": "",
    "abstract": "Sequential propositional logic deviates from ordinary propositional logic by taking into account that during the sequential evaluation of a propositional statement,atomic propositions may yield different Boolean values at repeated occurrences. We introduce `free valuations' to capture this dynamics of a propositional statement's environment. The resulting logic is phrased as an equationally specified algebra rather than in the form of proof rules, and is named `proposition algebra'. It is strictly more general than Boolean algebra to the extent that the classical connectives fail to be expressively complete in the sequential case. The four axioms for free valuation congruence are then combined with other axioms in order define a few more valuation congruences that gradually identify more propositional statements, up to static valuation congruence (which is the setting of conventional propositional logic). Proposition algebra is developed in a fashion similar to the process algebra ACP and the program algebra PGA, via an algebraic specification which has a meaningful initial algebra for which a range of coarser congruences are considered important as well. In addition infinite objects (that is propositional statements, processes and programs respectively) are dealt with by means of an inverse limit construction which allows the transfer of knowledge concerning finite objects to facts about infinite ones while reducing all facts about infinite objects to an infinity of facts about finite ones in return.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W3105499720",
    "type": "article"
  },
  {
    "title": "Randomization in Automata on Infinite Trees",
    "doi": "https://doi.org/10.1145/2629336",
    "publication_date": "2014-07-08",
    "publication_year": 2014,
    "authors": "Arnaud Carayol; Axel Haddad; Olivier Serre",
    "corresponding_authors": "",
    "abstract": "We study finite automata running over infinite binary trees. A run of such an automaton over an input tree is a tree labeled by control states of the automaton: the labeling is built in a top-down fashion and should be consistent with the transitions of the automaton. A branch in a run is accepting if the ω-word obtained by reading the states along the branch satisfies some acceptance condition (typically an ω-regular condition such as a Büchi or a parity condition). Finally, a tree is accepted by the automaton if there exists a run over this tree in which every branch is accepting. In this article, we consider two relaxations of this definition, introducing a qualitative aspect. First, we relax the notion of accepting run by allowing a negligible set (in the sense of measure theory) of nonaccepting branches. In this qualitative setting, a tree is accepted by the automaton if there exists a run over this tree in which almost every branch is accepting. This leads to a new class of tree languages, qualitative tree languages . This class enjoys many good properties: closure under union and intersection (but not under complement), and emptiness is decidable in polynomial time. A dual class, positive tree languages , is defined by requiring that an accepting run contains a non-negligeable set of branches. The second relaxation is to replace the existential quantification (a tree is accepted if there exists some accepting run over the input tree) with a probabilistic quantification (a tree is accepted if almost every run over the input tree is accepting). For the run, we may use either classical acceptance or qualitative acceptance. In particular, for the latter, we exhibit a tight connection with partial observation Markov decision processes. Moreover, if we additionally restrict operation to the Büchi condition, we show that it leads to a class of probabilistic automata on infinite trees enjoying a decidable emptiness problem. To our knowledge, this is the first positive result for a class of probabilistic automaton over infinite trees.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W1966886635",
    "type": "article"
  },
  {
    "title": "Nondeterministic Phase Semantics and the Undecidability of Boolean BI",
    "doi": "https://doi.org/10.1145/2422085.2422091",
    "publication_date": "2013-02-01",
    "publication_year": 2013,
    "authors": "Dominique Larchey-Wendling; Didier Galmiche",
    "corresponding_authors": "",
    "abstract": "We solve the open problem of the decidability of Boolean BI logic (BBI), which can be considered the core of separation and spatial logics. For this, we define a complete phase semantics suitable for BBI and characterize it as trivial phase semantics. We deduce an embedding between trivial phase semantics for intuitionistic linear logic (ILL) and Kripke semantics for BBI. We single out the elementary fragment of ILL, which is both undecidable and complete for trivial phase semantics. Thus, we obtain the undecidability of BBI.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W2017959340",
    "type": "article"
  },
  {
    "title": "Proof Nets for Herbrand’s Theorem",
    "doi": "https://doi.org/10.1145/2422085.2422090",
    "publication_date": "2013-02-01",
    "publication_year": 2013,
    "authors": "Richard McKinley",
    "corresponding_authors": "Richard McKinley",
    "abstract": "This article explores Herbrand’s theorem as the source of a natural notion of abstract proof object for classical logic, embodying the “essence” of a sequent calculus proof. We see how to view a calculus of abstract Herbrand proofs (Herbrand nets) as an analytic proof system with syntactic cut-elimination. Herbrand nets can also be seen as a natural generalization of Miller’s expansion tree proofs to a setting including cut. We demonstrate sequentialization of Herbrand nets into a sequent calculus LK H ; each net corresponds to an equivalence class of LK H proofs under natural proof transformations. A surprising property of our cut-reduction algorithm is that it is non-confluent despite not supporting the usual examples of non-confluent reduction in classical logic.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W2143374829",
    "type": "article"
  },
  {
    "title": "Reasoning about Cognitive Trust in Stochastic Multiagent Systems",
    "doi": "https://doi.org/10.1145/3329123",
    "publication_date": "2019-07-16",
    "publication_year": 2019,
    "authors": "Xiaowei Huang; Marta Kwiatkowska; Maciej Olejnik",
    "corresponding_authors": "",
    "abstract": "We consider the setting of stochastic multiagent systems modelled as stochastic multiplayer games and formulate an automated verification framework for quantifying and reasoning about agents' trust. To capture human trust, we work with a cognitive notion of trust defined as a subjective evaluation that agent A makes about agent B's ability to complete a task, which in turn may lead to a decision by A to rely on B. We propose a probabilistic rational temporal logic PRTL*, which extends the probabilistic computation tree logic PCTL* with reasoning about mental attitudes (beliefs, goals and intentions), and includes novel operators that can express concepts of social trust such as competence, disposition and dependence. The logic can express, for example, that `agent A will eventually trust agent B with probability at least p that B will behave in a way that ensures the successful completion of a given task'. We study the complexity of the automated verification problem and, while the general problem is undecidable, we identify restrictions on the logic and the system that result in decidable, or even tractable, subproblems.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W3123858477",
    "type": "article"
  },
  {
    "title": "Model Checking Existential Logic on Partially Ordered Sets",
    "doi": "https://doi.org/10.1145/2814937",
    "publication_date": "2015-11-25",
    "publication_year": 2015,
    "authors": "Simone Bova; Robert Ganian; Stefan Szeider",
    "corresponding_authors": "",
    "abstract": "We study the problem of checking whether an existential sentence (i.e., a first-order sentence in prefix form built using existential quantifiers and all Boolean connectives) is true in a finite partially ordered set (a poset). A poset is a reflexive, antisymmetric, and transitive digraph. The problem encompasses the fundamental embedding problem of finding an isomorphic copy of a poset as an induced substructure of another poset. Model checking existential logic is already NP-hard on a fixed poset; thus, we investigate structural properties of posets yielding conditions for fixed-parameter tractability when the problem is parameterized by the sentence. We identify width as a central structural property (the width of a poset is the maximum size of a subset of pairwise incomparable elements); our main algorithmic result is that model checking existential logic on classes of finite posets of bounded width is fixed-parameter tractable. We observe a similar phenomenon in classical complexity, in which we prove that the isomorphism problem is polynomial-time tractable on classes of posets of bounded width; this settles an open problem in order theory. We surround our main algorithmic result with complexity results on less restricted, natural neighboring classes of finite posets, establishing its tightness in this sense. We also relate our work with (and demonstrate its independence of) fundamental fixed-parameter tractability results for model checking on digraphs of bounded degree and bounded clique-width.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W2189395188",
    "type": "article"
  },
  {
    "title": "Unifying Operational Weak Memory Verification: An Axiomatic Approach",
    "doi": "https://doi.org/10.1145/3545117",
    "publication_date": "2022-06-27",
    "publication_year": 2022,
    "authors": "Simon Doherty; Sadegh Dalvandi; Brijesh Dongol; Heike Wehrheim",
    "corresponding_authors": "",
    "abstract": "In this article, we propose an approach to program verification using an abstract characterisation of weak memory models. Our approach is based on a hierarchical axiom scheme that captures the observational properties of a memory model. In particular, we show that it is possible to prove correctness of a program with respect to a particular axiom scheme, and we show this proof to suffice for any memory model that satisfies the axioms. Our axiom scheme is developed using a characterisation of weakest liberal preconditions for weak memory. This characterisation naturally extends to Hoare logic and Owicki-Gries reasoning by lifting weakest liberal preconditions (defined over read/write events) to the level of programs. We study three memory models (SC, TSO, and RC11-RAR) as example instantiations of the axioms, then we demonstrate the applicability of our reasoning technique on a number of litmus tests. The majority of the proofs in this article are supported by mechanisation within Isabelle/HOL.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W4283583929",
    "type": "article"
  },
  {
    "title": "Mechanizing UNITY in Isabelle",
    "doi": "https://doi.org/10.1145/343369.343370",
    "publication_date": "2000-07-01",
    "publication_year": 2000,
    "authors": "Lawrence C. Paulson",
    "corresponding_authors": "Lawrence C. Paulson",
    "abstract": "UNITY is an abstract formalism for proving properties of concurrent systems, which typically are expressed using guarded assignments [Chandy and Misra 1988]. UNITY has been mechanized in higher-order logic using Isabelle, a proof assistant. Safety and progress primitives, their weak forms (for the substitution axiom), and the program composition operator (union) have been formalized. To give a feel for the concrete syntax, this article presents a few extracts from the Isabelle definitions and proofs. It discusses a small example, two-process mutual exclusion. A mechanical theory of unions of programs supports a degree of compositional reasoning. Original work on extending program states is presented and then illustrated through a simple example involving an array of processes.",
    "cited_by_count": 34,
    "openalex_id": "https://openalex.org/W2049023360",
    "type": "article"
  },
  {
    "title": "Polynomial-time computation via local inference relations",
    "doi": "https://doi.org/10.1145/566385.566387",
    "publication_date": "2002-10-01",
    "publication_year": 2002,
    "authors": "Robert Givan; David McAllester",
    "corresponding_authors": "",
    "abstract": "We consider the concept of a local set of inference rules. A local rule set can be automatically transformed into a rule set for which bottom-up evaluation terminates in polynomial time. The local-rule-set transformation gives polynomial-time evaluation strategies for a large variety of rule sets that cannot be given terminating evaluation strategies by any other known automatic technique. This article discusses three new results. First, it is shown that every polynomial-time predicate can be defined by an (unstratified) local rule set. Second, a new machine-recognizable subclass of the local rule sets is identified. Finally, we show that locality, as a property of rule sets, is undecidable in general.",
    "cited_by_count": 34,
    "openalex_id": "https://openalex.org/W2151097580",
    "type": "article"
  },
  {
    "title": "Typechecking XML views of relational databases",
    "doi": "https://doi.org/10.1145/772062.772065",
    "publication_date": "2003-07-01",
    "publication_year": 2003,
    "authors": "Noga Alon; Tova Milo; Frank Neven; Dan Suciu; Victor Vianu",
    "corresponding_authors": "",
    "abstract": "Motivated by the need to export relational databases as XML data in the context of the Web, we investigate the typechecking problem for transformations of relational data into tree data (XML). The problem consists of statically verifying that the output of every transformation belongs to a given output tree language (specified for XML by a DTD), for input databases satisfying given integrity constraints. The typechecking problem is parameterized by the class of formulas defining the transformation, the class of output tree languages, and the class of integrity constraints. While undecidable in its most general formulation, the typechecking problem has many special cases of practical interest that turn out to be decidable. The main contribution of this article is to trace a fairly tight boundary of decidability for typechecking in this framework. In the decidable cases we examine the complexity, and show lower and upper bounds. We also exhibit a practically appealing restriction for which typechecking is in PTIME.",
    "cited_by_count": 34,
    "openalex_id": "https://openalex.org/W2173322574",
    "type": "article"
  },
  {
    "title": "Deciding and axiomatizing weak ST bisimulation for a process algebra with recursion and action refinement",
    "doi": "https://doi.org/10.1145/566385.566386",
    "publication_date": "2002-10-01",
    "publication_year": 2002,
    "authors": "Mario Bravetti; Roberto Gorrieri",
    "corresponding_authors": "",
    "abstract": "Due to the complex nature of bisimulation equivalences that express some form of history dependence, it turned out to be problematic to decide them over nontrivial classes of recursive systems. Moreover, to the best of our knowledge, the problem of axiomatizing them over such classes of systems has never been solved. In this article, we face this problem in the case of weak ST bisimulation, an equivalence that expresses the execution of an action as the combination of the two interdependent events of action start and action termination and that supports the operation of action refinement. We first consider a basic process algebra with CSP multiway synchronization and recursion and we show that a simple technique based on static names is sufficient to decide weak ST bisimulation over processes that are finite state according to the standard interleaving semantics. Then we introduce a different technique based on dynamic names and on the new idea of compositional level-wise renaming of actions (which produces semantic models via SOS such that weak ST bisimulation can be established through standard weak bisimulation) and we show that it can be applied to decide and axiomatize weak ST bisimulation over the same class of processes. Finally, we introduce a third technique based on pointers, updated according to a pseudo-stack discipline, which preserves the possibility of deciding and axiomatizing weak ST bisimulation also when an action refinement operator is considered.",
    "cited_by_count": 32,
    "openalex_id": "https://openalex.org/W2055350841",
    "type": "article"
  },
  {
    "title": "A modal logic framework for multi-agent belief fusion",
    "doi": "https://doi.org/10.1145/1042038.1042043",
    "publication_date": "2005-01-01",
    "publication_year": 2005,
    "authors": "Churn‐Jung Liau",
    "corresponding_authors": "Churn‐Jung Liau",
    "abstract": "This article provides a modal logic framework for reasoning about multi-agent belief and its fusion. We propose logics for reasoning about cautiously merged agent beliefs that have different degrees of reliability. These logics are obtained by combining the multi-agent epistemic logic and multi-source reasoning systems. The fusion is cautious in the sense that if an agent's belief is in conflict with those of higher priorities, then his belief is completely discarded from the merged result. We consider two strategies for the cautious merging of beliefs. In the first, called level cutting fusion , if inconsistency occurs at some level, then all beliefs at the lower levels are discarded simultaneously. In the second, called level skipping fusion , only the level at which the inconsistency occurs is skipped. We present the formal semantics and axiomatic systems for these two strategies and discuss some applications of the proposed logical systems. We also develop a tableau proof system for the logics and prove the complexity result for the satisfiability and validity problems of these logics.",
    "cited_by_count": 32,
    "openalex_id": "https://openalex.org/W2074934885",
    "type": "article"
  },
  {
    "title": "Reflective metalogical frameworks",
    "doi": "https://doi.org/10.1145/1013560.1013566",
    "publication_date": "2004-07-01",
    "publication_year": 2004,
    "authors": "David Basin; Manuel Clavel; José Meseguer",
    "corresponding_authors": "",
    "abstract": "A metalogical framework is a logic with an associated methodology that is used to represent other logics and to reason about their metalogical properties. We propose that logical frameworks can be good metalogical frameworks when their theories always have initial models and they support reflective and parameterized reasoning.We develop this thesis both abstractly and concretely. Abstractly, we formalize our proposal as a set of requirements and explain how any logic satisfying these requirements can be used for metalogical reasoning. Concretely, we present membership equational logic as a particular metalogic that satisfies these requirements. Using membership equational logic, and its realization in the Maude system, we show how reflection can be used for different, nontrivial kinds of formal metatheoretic reasoning. In particular, one can prove metatheorems that relate theories or establish properties of parameterized classes of theories.",
    "cited_by_count": 29,
    "openalex_id": "https://openalex.org/W2100668485",
    "type": "article"
  },
  {
    "title": "Equivalences among aggregate queries with negation",
    "doi": "https://doi.org/10.1145/1055686.1055691",
    "publication_date": "2005-04-01",
    "publication_year": 2005,
    "authors": "Sara Cohen; Yehoshua Sagiv; Werner Nutt",
    "corresponding_authors": "",
    "abstract": "Query equivalence is investigated for disjunctive aggregate queries with negated subgoals, constants and comparisons. A full characterization of equivalence is given for the aggregation functions count, max, sum, prod, top2 and parity . A related problem is that of determining, for a given natural number N , whether two given queries are equivalent over all databases with at most N constants. This problem is called bounded equivalence . A complete characterization of decidability of bounded equivalence is given. In particular, it is shown that this problem is decidable for all the above aggregation functions as well as for cntd (count distinct) and avg . For quasilinear queries (i.e., queries in which predicates that occur positively are not repeated), it is shown that equivalence can be decided in polynomial time for the aggregation functions count, max, sum, prty, prod, top2 and avg . A similar result holds for cntd provided that a few additional conditions hold. The results are couched in terms of abstract characteristics of aggregation functions, and new proof techniques are used. Finally, the results above also imply that equivalence, under bag-set semantics, is decidable for nonaggregate queries with negation.",
    "cited_by_count": 28,
    "openalex_id": "https://openalex.org/W2090337980",
    "type": "article"
  },
  {
    "title": "Logic program-based updates",
    "doi": "https://doi.org/10.1145/1149114.1149115",
    "publication_date": "2006-07-01",
    "publication_year": 2006,
    "authors": "Yan Zhang",
    "corresponding_authors": "Yan Zhang",
    "abstract": "In logic program-based updates, contradictory information elimination, conflict resolution, and syntactic representation are three major issues that interfere with each other and significantly influence the update result. We observe that existing approaches of logic program-based updates, in one way or another, are problematic to deal with these issues. In this article, we address all these problems in a systematic manner. Our approach to the logic program-based update has the following features: (1) a prioritized logic programming language is employed for providing a formal basis of formalizing logic program-based updates, so that information conflict and its related problems in updates can be handled properly; (2) our approach presents both semantic characterization and syntactic representation for the underlying update procedure, and hence is consistent with the nature of updates within the logic program extent-declarative semantics and syntactic sensitivity; and (3) our approach also provides nontrivial solutions to simplify various update evaluation procedures under certain conditions.",
    "cited_by_count": 28,
    "openalex_id": "https://openalex.org/W2156974579",
    "type": "article"
  },
  {
    "title": "A uniform approach to constraint-solving for lists, multisets, compact lists, and sets",
    "doi": "https://doi.org/10.1145/1352582.1352583",
    "publication_date": "2008-06-01",
    "publication_year": 2008,
    "authors": "Agostino Dovier; Carla Piazza; Gianfranco Rossi",
    "corresponding_authors": "",
    "abstract": "Lists, multisets, and sets are well-known data structures whose usefulness is widely recognized in various areas of computer science. They have been analyzed from an axiomatic point of view with a parametric approach in Dovier et al. [1998], where the relevant unification algorithms have been developed. In this article, we extend these results considering more general constraints, namely, equality and membership constraints and their negative counterparts.",
    "cited_by_count": 25,
    "openalex_id": "https://openalex.org/W2029740449",
    "type": "article"
  },
  {
    "title": "The axiomatic translation principle for modal logic",
    "doi": "https://doi.org/10.1145/1276920.1276921",
    "publication_date": "2007-08-01",
    "publication_year": 2007,
    "authors": "Renate A. Schmidt; Ullrich Hustadt",
    "corresponding_authors": "",
    "abstract": "In this paper we present a translation principle, called the axiomatic translation , for reducing propositional modal logics with background theories, including triangular properties such as transitivity, Euclideanness and functionality, to decidable fragments of first-order logic. The goal of the axiomatic translation principle is to find simplified theories, which capture the inference problems in the original theory, but in a way that can be readily automated and is easier to deal with by existing (first-order) theorem provers than the standard translation. The principle of the axiomatic translation is conceptually very simple and can be almost completely automated. Soundness is automatic under reasonable assumptions, general decidability results can be stated and termination of ordered resolution is easily achieved. The non-trivial part of the approach is proving completeness. We prove results of completeness, decidability, model generation, the small model property and the interpolation property for a number of common and less common modal logics. We also present results of experiments with a number of first-order logic theorem provers which are very encouraging.",
    "cited_by_count": 24,
    "openalex_id": "https://openalex.org/W2124890997",
    "type": "article"
  },
  {
    "title": "Sup-interpretations, a semantic method for static analysis of program resources",
    "doi": "https://doi.org/10.1145/1555746.1555751",
    "publication_date": "2009-08-01",
    "publication_year": 2009,
    "authors": "Jean-Yves Marion; Romain Péchoux",
    "corresponding_authors": "",
    "abstract": "The sup-interpretation method is proposed as a new tool to control memory resources of first order functional programs with pattern matching by static analysis. It has been introduced in order to increase the intensionality, that is the number of captured algorithms, of a previous method, the quasi-interpretations. Basically, a sup-interpretation provides an upper bound on the size of function outputs. A criterion, which can be applied to terminating as well as nonterminating programs, is developed in order to bound the stack frame size polynomially. Since this work is related to quasi-interpretation, dependency pairs, and size-change principle methods, we compare these notions obtaining several results. The first result is that, given any program, we have heuristics for finding a sup-interpretation when we consider polynomials of bounded degree. Another result consists in the characterizations of the sets of functions computable in polynomial time and in polynomial space. A last result consists in applications of sup-interpretations to the dependency pair and the size-change principle methods.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W2033656559",
    "type": "article"
  },
  {
    "title": "On the completeness of compositional reasoning methods",
    "doi": "https://doi.org/10.1145/1740582.1740584",
    "publication_date": "2010-05-01",
    "publication_year": 2010,
    "authors": "Kedar S. Namjoshi; Richard Trefler",
    "corresponding_authors": "",
    "abstract": "Hardware systems and reactive software systems can be described as the composition of several concurrently active processes. Automated reasoning based on model checking algorithms can substantially increase confidence in the overall reliability of a system. Direct methods for model checking a concurrent composition, however, usually suffer from the explosion in the number of program states that arises from concurrency. Reasoning compositionally about individual processes helps mitigate this problem. A number of rules have been proposed for compositional reasoning, typically based on an assume-guarantee reasoning paradigm. Reasoning with these rules can be delicate, as some are syntactically circular in nature, in that assumptions and guarantees are mutually dependent. This is known to be a source of unsoundness. In this article, we investigate rules for compositional reasoning from the viewpoint of completeness . We show that several rules are incomplete: that is, there are properties whose validity cannot be established using (only) these rules. We derive a new, circular, reasoning rule and show it to be sound and complete. We show that the auxiliary assertions needed for completeness need be defined only on the interface of the component processes. We also show that the two main paradigms of circular and noncircular reasoning are closely related, in that a proof of one type can be transformed in a straightforward manner to one of the other type. These results give some insight into the applicability of compositional reasoning methods.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W2108096932",
    "type": "article"
  },
  {
    "title": "Unicast and multicast QoS routing with soft-constraint logic programming",
    "doi": "https://doi.org/10.1145/1838552.1838557",
    "publication_date": "2010-10-01",
    "publication_year": 2010,
    "authors": "Stefano Bistarelli; Ugo Montanari; Francesca Rossi; Francesco Santini",
    "corresponding_authors": "",
    "abstract": "We present a formal model to represent and solve the unicast/multicast routing problem in networks with quality-of-service (QoS) requirements. To attain this, first we translate the network adapting it to a weighted graph (unicast) or and-or graph (multicast), where the weight on a connector corresponds to the multidimensional cost of sending a packet on the related network link: each component of the weights vector represents a different QoS metric value (e.g., bandwidth). The second step consists in writing this graph as a program in soft-constraint logic programming (SCLP): the engine of this framework is then able to find the best paths/trees by optimizing their costs and solving the constraints imposed on them (e.g. delay ≤ 40 ms), thus finding a solution to QoS routing problems. C-semiring structures are a convenient tool to model QoS metrics. At last, we provide an implementation of the framework over scale-free networks and we suggest how the performance can be improved. The article highlights the expressivity of SCLP.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W2004288442",
    "type": "article"
  },
  {
    "title": "Decidability of Downward XPath",
    "doi": "https://doi.org/10.1145/2362355.2362362",
    "publication_date": "2012-10-01",
    "publication_year": 2012,
    "authors": "Diego Figueira",
    "corresponding_authors": "Diego Figueira",
    "abstract": "We investigate the satisfiability problem for downward-XPath, the fragment of XPath that includes the child and descendant axes, and tests for (in)equality of attributes’ values. We prove that this problem is decidable, EXPTIME-complete. These bounds also hold when path expressions allow closure under the Kleene star operator. To obtain these results, we introduce a Downward Data automata model (DD automata) over trees with data, which has a decidable emptiness problem. Satisfiability of downward-XPath can be reduced to the emptiness problem of DD automata and hence its decidability follows. Although downward-XPath does not include any horizontal axis, DD automata are more expressive and can perform some horizontal tests. Thus, we show that the satisfiability remains in EXPTIME even in the presence of the regular constraints expressible by DD automata. However, the same problem in the presence of any regular constraint is known to have a nonprimitive recursive complexity. Finally, we give the exact complexity of the satisfiability problem for several fragments of downward-XPath.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W2005612348",
    "type": "article"
  },
  {
    "title": "Graded computation tree logic",
    "doi": "https://doi.org/10.1145/2287718.2287725",
    "publication_date": "2012-08-01",
    "publication_year": 2012,
    "authors": "Alessandro Bianco; Fabio Mogavero; Aniello Murano",
    "corresponding_authors": "",
    "abstract": "In modal logics, graded (world) modalities have been deeply investigated as a useful framework for generalizing standard existential and universal modalities in such a way that they can express statements about a given number of immediately accessible worlds. These modalities have been recently investigated with respect to the μCalculus, which have provided succinctness, without affecting the satisfiability of the extended logic, that is, it remains solvable in ExpTime. A natural question that arises is how logics that allow reasoning about paths could be affected by considering graded path modalities . In this article, we investigate this question in the case of the branching-time temporal logic CTL (GCTL, for short). We prove that, although GCTL is more expressive than CTL, the satisfiability problem for GCTL remains solvable in ExpTime, even in the case that the graded numbers are coded in binary. This result is obtained by exploiting an automata-theoretic approach, which involves a model of alternating automata with satellites. The satisfiability result turns out to be even more interesting as we show that GCTL is at least exponentially more succinct than graded μCalculus.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W2114893507",
    "type": "article"
  },
  {
    "title": "YAPA",
    "doi": "https://doi.org/10.1145/2422085.2422089",
    "publication_date": "2013-02-01",
    "publication_year": 2013,
    "authors": "Mathieu Baudet; Véronique Cortier; Stéphanie Delaune",
    "corresponding_authors": "",
    "abstract": "Reasoning about the knowledge of an attacker is a necessary step in many formal analyses of security protocols. In the framework of the applied pi-calculus, as in similar languages based on equational logics, knowledge is typically expressed by two relations: deducibility and static equivalence. Several decision procedures have been proposed for these relations under a variety of equational theories. However, each theory has its particular algorithm, and none has been implemented so far. We provide a generic procedure for deducibility and static equivalence that takes as input any convergent rewrite system. We show that our algorithm covers most of the existing decision procedures for convergent theories. We also provide an efficient implementation and compare it briefly with the tools ProVerif and KiSs.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W1991537775",
    "type": "article"
  },
  {
    "title": "Logics for information systems and their dynamic extensions",
    "doi": "https://doi.org/10.1145/1970398.1970405",
    "publication_date": "2011-07-01",
    "publication_year": 2011,
    "authors": "Md. Aquil Khan; Mohua Banerjee",
    "corresponding_authors": "",
    "abstract": "The article proposes logics for information systems , which provide information about a set of objects regarding a set of attributes. Both “ complete ” and “ incomplete ” information systems are dealt with. The language of these logics contains modal operators, and constants corresponding to attributes and attribute values. Sound and complete deductive systems for these logics are presented, and the problem of decidability is addressed. Furthermore, notions of information and information update are defined, and dynamic extensions of the above logics are presented to accommodate these notions. A set of reduction axioms enables us to obtain a complete axiomatization of the dynamic logics.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W2008441772",
    "type": "article"
  },
  {
    "title": "Backdoors to Normality for Disjunctive Logic Programs",
    "doi": "https://doi.org/10.1145/2818646",
    "publication_date": "2015-10-28",
    "publication_year": 2015,
    "authors": "Johannes K. Fichte; Stefan Szeider",
    "corresponding_authors": "",
    "abstract": "The main reasoning problems for disjunctive logic programs are complete for the second level of the polynomial hierarchy and hence considered harder than the same problems for normal (i.e., disjunction-free) programs, which are on the first level. We propose a new exact method for solving the disjunctive problems which exploits the small distance of a disjunctive programs from being normal. The distance is measured in terms of the size of a smallest “backdoor to normality,” which is the smallest number of atoms whose deletion makes the program normal. Our method consists of three phases. In the first phase, a smallest backdoor is computed. We show that this can be done using an efficient algorithm for computing a smallest vertex cover of a graph. In the second phase, the backdoor is used to transform the logic program into a quantified Boolean formula (QBF) where the number of universally quantified variables equals the size of the backdoor and where the total size of the quantified Boolean formula is quasilinear in the size of the given logic program. The quasilinearity is achieved by means of a characterization of the least model of a Horn program in terms of level numberings. In a third phase, the universal variables are eliminated using universal expansion yielding a propositional formula. The blowup in the last phase is confined to a factor that is exponential in the size of the backdoor but linear in the size of the quantified Boolean formula. By checking the satisfiability of the resulting formula with a S at solver (or by checking the satisfiability of the quantified Boolean formula by a Q bf -S at solver), we can decide the A sp reasoning problems on the input program. In consequence, we have a transformation from A sp problems to propositional satisfiability where the combinatorial explosion, which is expected when transforming a problem from the second level of the polynomial hierarchy to the first level, is confined to a function of the distance to normality of the input program. In terms of parameterized complexity, the transformation is fixed-parameter tractable. We complement this result by showing that (under plausible complexity-theoretic assumptions) such a fixed-parameter tractable transformation is not possible if we consider the distance to tightness instead of distance to normality.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W1973101725",
    "type": "article"
  },
  {
    "title": "Abstract Program Slicing",
    "doi": "https://doi.org/10.1145/3029052",
    "publication_date": "2017-01-31",
    "publication_year": 2017,
    "authors": "Isabella Mastroeni; Damiano Zanardini",
    "corresponding_authors": "",
    "abstract": "In the present article, we formally define the notion of abstract program slicing , a general form of program slicing where properties of data are considered instead of their exact value. This approach is applied to a language with numeric and reference values and relies on the notion of abstract dependencies between program statements. The different forms of (backward) abstract slicing are added to an existing formal framework where traditional, nonabstract forms of slicing could be compared. The extended framework allows us to appreciate that abstract slicing is a generalization of traditional slicing, since each form of traditional slicing (dealing with syntactic dependencies) is generalized by a semantic (nonabstract) form of slicing, which is actually equivalent to an abstract form where the identity abstraction is performed on data. Sound algorithms for computing abstract dependencies and a systematic characterization of program slices are provided, which rely on the notion of agreement between program states.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W2401455848",
    "type": "article"
  },
  {
    "title": "Proof Complexity Meets Algebra",
    "doi": "https://doi.org/10.1145/3265985",
    "publication_date": "2018-12-20",
    "publication_year": 2018,
    "authors": "Albert Atserias; Joanna Ochremiak",
    "corresponding_authors": "",
    "abstract": "We analyze how the standard reductions between constraint satisfaction problems affect their proof complexity. We show that, for the most studied propositional, algebraic, and semialgebraic proof systems, the classical constructions of pp-interpretability, homomorphic equivalence, and addition of constants to a core preserve the proof complexity of the CSP. As a result, for those proof systems, the classes of constraint languages for which small unsatisfiability certificates exist can be characterized algebraically. We illustrate our results by a gap theorem saying that a constraint language either has resolution refutations of constant width or does not have bounded-depth Frege refutations of subexponential size. The former holds exactly for the widely studied class of constraint languages of bounded width. This class is also known to coincide with the class of languages with refutations of sublinear degree in Sums of Squares and Polynomial Calculus over the real field, for which we provide alternative proofs. We then ask for the existence of a natural proof system with good behavior with respect to reductions and simultaneously small-size refutations beyond bounded width. We give an example of such a proof system by showing that bounded-degree Lovász-Schrijver satisfies both requirements. Finally, building on the known lower bounds, we demonstrate the applicability of the method of reducibilities and construct new explicit hard instances of the graph three-coloring problem for all studied proof systems.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W2905780568",
    "type": "article"
  },
  {
    "title": "May-Happen-in-Parallel Analysis for Actor-Based Concurrency",
    "doi": "https://doi.org/10.1145/2824255",
    "publication_date": "2015-12-22",
    "publication_year": 2015,
    "authors": "Elvira Albert; Antonio Flores-Montoya; Samir Genaim; Enrique Martin-Martin",
    "corresponding_authors": "",
    "abstract": "This article presents a may-happen-in-parallel (MHP) analysis for languages with actor-based concurrency . In this concurrency model, actors are the concurrency units such that, when a method is invoked on an actor a 2 from a task executing on actor a 1 , statements of the current task in a 1 may run in parallel with those of the (asynchronous) call on a 2 , and with those of transitively invoked methods. The goal of the MHP analysis is to identify pairs of statements in the program that may run in parallel in any execution. Our MHP analysis is formalized as a method-level ( local ) analysis whose information can be modularly composed to obtain application-level ( global ) information. The information yielded by the MHP analysis is essential to infer more complex properties of actor-based concurrent programs, for example, data race detection, deadlock freeness, termination, and resource consumption analyses can greatly benefit from the MHP relations to increase their accuracy. We report on MayPar, a prototypical implementation of an MHP static analyzer for a distributed asynchronous language.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W2253323238",
    "type": "article"
  },
  {
    "title": "Where First-Order and Monadic Second-Order Logic Coincide",
    "doi": "https://doi.org/10.1145/2946799",
    "publication_date": "2016-09-10",
    "publication_year": 2016,
    "authors": "Michael Elberfeld; Martin Grohe; Till Tantau",
    "corresponding_authors": "",
    "abstract": "We study on which classes of graphs first-order logic ( fo ) and monadic second-order logic ( mso ) have the same expressive power. We show that for all classes C of graphs that are closed under taking subgraphs, fo and mso have the same expressive power on C if and only if, C has bounded tree depth. Tree depth is a graph invariant that measures the similarity of a graph to a star in a similar way that tree width measures the similarity of a graph to a tree. For classes just closed under taking induced subgraphs, we show an analogous result for guarded second-order logic ( gso ), the variant of mso that not only allows quantification over vertex sets but also over edge sets. A key tool in our proof is a Feferman--Vaught-type theorem that works for infinite collections of structures despite being constructive.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W2520797183",
    "type": "article"
  },
  {
    "title": "Incremental execution of guarded theories",
    "doi": "https://doi.org/10.1145/383779.383782",
    "publication_date": "2001-10-01",
    "publication_year": 2001,
    "authors": "Giuseppe De Giacomo; Hector J. Levesque; Sebastian Sardiña",
    "corresponding_authors": "",
    "abstract": "When it comes to building controllers for robots or agents, high level programming languages like Golog and ConGolog offer a useful compromise between planning-based approaches and low-level robot programming. However, two serious problems typically emerge in practical implementations of these languages: how to evaluate test in a program efficiently enough in an open-world setting, and how to make appropiate nondeterministic choices while avoiding full lookahead. Recent proposals in the literature suggest that one could tackle the first problem by exploiting sensing information, and tackle the second by specifying the amount of lookahead allowed explicitly in the program. In this paper, we combine these two ideas and demonstrate their power by presenting an interpreter, written in Prolog, for a variant of Golog that is suitable for efficiently operating in open-world setting by exploiting sensing and bounded lookahead.",
    "cited_by_count": 32,
    "openalex_id": "https://openalex.org/W2087144687",
    "type": "article"
  },
  {
    "title": "Knowledge in multiagent systems",
    "doi": "https://doi.org/10.1145/359496.359527",
    "publication_date": "2000-10-01",
    "publication_year": 2000,
    "authors": "Alessio Lomuscio; Ron van der Meyden; Mark Ryan",
    "corresponding_authors": "",
    "abstract": "The semantic framework for the modal logic of knowledge due to Halpern and Moses provides a way to ascribe knowlegde to agents in distributed and multiagent systems. In this paper we study two special cases of this framework: full systems and hypercubes . Both model static situtations in which no agents has any information about another agent's state. Full systems and hypercubes are an appropriate model for the initial configurations of many systems of interest. We establish a correspondence between full systems and hypercube systems and certain classes of Kripke frames. We show that these classes of systems correspond to the same logic. Moreover, this logic is also the same as that generated by the larger class of weakly directed frames . We provide a sound and complete axiomatization, S5WD n of this logic, and study its computational complexity. Finally, we show that under certain natural assumptions, in a model where knowledge evolves over time, S5WD n characteristics the properties of knowledge not just at the initial configuration, but also at all later configurations. In this particular, this holds for homogeneous broadcast systems, which capture settings in which agents are intially ignorant of each others local states, operate synchronously, have perfect recall, and can communicate only by broadcasting.",
    "cited_by_count": 32,
    "openalex_id": "https://openalex.org/W2170920603",
    "type": "article"
  },
  {
    "title": "Probabilistic agent programs",
    "doi": "https://doi.org/10.1145/359496.359508",
    "publication_date": "2000-10-01",
    "publication_year": 2000,
    "authors": "Jürgen Dix; Mirco Nanni; V. S. Subrahmanian",
    "corresponding_authors": "",
    "abstract": "Agents are small programs that autonomously take actions based on changes in their environment or “state”. Over the last few years, there has been an increasing number of efforts to build agents that can interact and/or collaborate with other agents. In one of these efforts Eiter et al. [1999] have shown how agents may be built on top of legacy code. However, their framework assumes that agent states are completely determined, and there is no uncertainty in an agent's state. Thus, their framework allows an agent developer to specify how his agents will react when the agent is 100% sure about what is true/false in the world state. In this paper, we propose the concept of a probabilistic agent program and show how, given an arbitrary program written in any imperative language, we may build a declarative “probabilistic” agent program on top of it which supports decision making in the presence of uncertainty. We provide two alternative semantics for probabilitic programs. We provide sound and complete algorithms to compute the semantics of positive agent programs.",
    "cited_by_count": 31,
    "openalex_id": "https://openalex.org/W2130563808",
    "type": "article"
  },
  {
    "title": "Model checking stochastic automata",
    "doi": "https://doi.org/10.1145/937555.937558",
    "publication_date": "2003-10-01",
    "publication_year": 2003,
    "authors": "Jeremy Bryans; Howard Bowman; John Derrick",
    "corresponding_authors": "",
    "abstract": "Modern distributed systems include a class of applications in which non-functional requirements are important. In particular, these applications include multimedia facilities where real time constraints are crucial to their correct functioning. In order to specify such systems it is necessary to describe that events occur at times given by probability distributions; stochastic automata have emerged as a useful technique by which such systems can be specified and verified.However, stochastic descriptions are very general, in particular they allow the use of general probability distribution functions, and therefore their verification can be complex. In the last few years, model checking has emerged as a useful verification tool for large systems. In this article we describe two model checking algorithms for stochastic automata. These algorithms consider how properties written in a simple probabilistic real-time logic can be checked against a given stochastic automaton.",
    "cited_by_count": 28,
    "openalex_id": "https://openalex.org/W2073841996",
    "type": "article"
  },
  {
    "title": "Propositional computability logic II",
    "doi": "https://doi.org/10.1145/1131313.1131319",
    "publication_date": "2006-04-01",
    "publication_year": 2006,
    "authors": "Giorgi Japaridze",
    "corresponding_authors": "Giorgi Japaridze",
    "abstract": "Computability logic is a formal theory of computational tasks and resources. Its formulas represent interactive computational problems, logical operators stand for operations on computational problems, and validity of a formula is understood as its being a scheme of problems that always have algorithmic solutions. The earlier article “Propositional computability logic I” proved soundness and completeness for the (in a sense) minimal nontrivial fragment CL1 of computability logic. The present article extends that result to the significantly more expressive propositional system CL2 . What makes CL2 more expressive than CL1 is the presence of two sorts of atoms in its language: elementary atoms , representing elementary computational problems (i.e. predicates), and general atoms , representing arbitrary computational problems. CL2 conservatively extends CL1 , with the latter being nothing but the general-atom-free fragment of the former.",
    "cited_by_count": 26,
    "openalex_id": "https://openalex.org/W4253236060",
    "type": "article"
  },
  {
    "title": "Probabilistic abstraction for model checking",
    "doi": "https://doi.org/10.1145/1276920.1276922",
    "publication_date": "2007-08-01",
    "publication_year": 2007,
    "authors": "Sophie Laplante; Richard Lassaigne; Frédéric Magniez; Sylvain Peyronnet; Michel de Rougemont",
    "corresponding_authors": "",
    "abstract": "The goal of model checking is to verify the correctness of a given program, on all its inputs. The main obstacle, in many cases, is the intractably large size of the program's transition system. Property testing is a randomized method to verify whether some fixed property holds on individual inputs, by looking at a small random part of that input. We join the strengths of both approaches by introducing a new notion of probabilistic abstraction, and by extending the framework of model checking to include the use of these abstractions. Our abstractions map transition systems associated with large graphs to small transition systems associated with small random subgraphs. This reduces the original transition system to a family of small, even constant-size, transition systems. We prove that with high probability, “sufficiently” incorrect programs will be rejected (ε-robustness). We also prove that under a certain condition (exactness), correct programs will never be rejected (soundness). Our work applies to programs for graph properties such as bipartiteness, k -colorability, or any ∃∀ first order graph properties. Our main contribution is to show how to apply the ideas of property testing to syntactic programs for such properties. We give a concrete example of an abstraction for a program for bipartiteness. Finally, we show that the relaxation of the test alone does not yield transition systems small enough to use the standard model checking method. More specifically, we prove, using methods from communication complexity, that the OBDD size remains exponential for approximate bipartiteness.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W2620748922",
    "type": "article"
  },
  {
    "title": "Defining functions on equivalence classes",
    "doi": "https://doi.org/10.1145/1183278.1183280",
    "publication_date": "2006-10-01",
    "publication_year": 2006,
    "authors": "Lawrence C. Paulson",
    "corresponding_authors": "Lawrence C. Paulson",
    "abstract": "A quotient construction defines an abstract type from a concrete type, using an equivalence relation to identify elements of the concrete type that are to be regarded as indistinguishable. The elements of a quotient type are equivalence classes : sets of equivalent concrete values. Simple techniques are presented for defining and reasoning about quotient constructions, based on a general lemma library concerning functions that operate on equivalence classes. The techniques are applied to a definition of the integers from the natural numbers, and then to the definition of a recursive datatype satisfying equational constraints.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W3122722170",
    "type": "article"
  },
  {
    "title": "Durations and parametric model-checking in timed automata",
    "doi": "https://doi.org/10.1145/1342991.1342996",
    "publication_date": "2008-03-01",
    "publication_year": 2008,
    "authors": "Véronique Bruyère; Emmanuel Dall’Olio; Jean-François Raskin",
    "corresponding_authors": "",
    "abstract": "We consider the problem of model-checking a parametric extension of the logic TCTL over timed automata and establish its decidability. Given a timed automaton, we show that the set of durations of runs starting from a region and ending in another region is definable in Presburger arithmetic (when the time domain is discrete) or in a real arithmetic (when the time domain is dense). Using this logical definition, we show that the parametric model-checking problem for the logic TCTL can be solved algorithmically; the proof of this result is simple. More generally, we are able to effectively characterize the values of the parameters that satisfy the parametric TCTL formula with respect to the given timed automaton.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W2088028681",
    "type": "article"
  },
  {
    "title": "On compositionality and its limitations",
    "doi": "https://doi.org/10.1145/1182613.1182617",
    "publication_date": "2007-01-01",
    "publication_year": 2007,
    "authors": "Alexander Rabinovich",
    "corresponding_authors": "Alexander Rabinovich",
    "abstract": "The aim of this article is to examine the applicability of a compositional method developed for a generalized product construction by Feferman and Vaught to the field of program verification.We suggest an instance of the generalized product construction and prove an appropriate composition theorem for modal logic. We illustrate the usefulness of this generalized product by showing that many “parallel composition” operations are special cases of this generalized product.We obtain positive results (the compositional method works) for basic propositional modal logic, and negative results (the compositional method fails) for more expressive logics which can express EG p ---“there is a path such that all the nodes of the path have the property p .”Applications of the composition theorem to the model-checking problem and to the parametric model-checking problem are provided.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W2105348917",
    "type": "article"
  },
  {
    "title": "A comprehensive combination framework",
    "doi": "https://doi.org/10.1145/1342991.1342992",
    "publication_date": "2008-03-01",
    "publication_year": 2008,
    "authors": "Silvio Ghilardi; Enrica Nicolini; Daniele Zucchelli",
    "corresponding_authors": "",
    "abstract": "We define a general notion of a fragment within higher-order type theory; a procedure for constraint satisfiability in combined fragments is outlined, following Nelson-Oppen schema. The procedure is in general only sound, but it becomes terminating and complete when the shared fragment enjoys suitable noetherianity conditions and admits an abstract version of a “Keisler-Shelah-like” isomorphism theorem. We show that this general decidability transfer result covers recent work on combination in first-order theories as well as in various intensional logics such as description, modal, and temporal logics.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W2168177042",
    "type": "article"
  },
  {
    "title": "Tableau calculus for preference-based conditional logics",
    "doi": "https://doi.org/10.1145/1507244.1507251",
    "publication_date": "2009-04-01",
    "publication_year": 2009,
    "authors": "Laura Giordano; Valentina Gliozzi; Nicola Olivetti; Camilla Schwind",
    "corresponding_authors": "",
    "abstract": "We present a tableau calculus for some fundamental systems of propositional conditional logics. We consider the conditional logics that can be characterized by preferential semantics (i.e., possible world structures equipped with a family of preference relations). For these logics, we provide a uniform completeness proof of the axiomatization with respect to the semantics, and a uniform labeled tableau procedure.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W1984832422",
    "type": "article"
  },
  {
    "title": "Superposition for fixed domains",
    "doi": "https://doi.org/10.1145/1805950.1805957",
    "publication_date": "2010-07-01",
    "publication_year": 2010,
    "authors": "Matthias Horbach; Christoph Weidenbach",
    "corresponding_authors": "",
    "abstract": "Superposition is an established decision procedure for a variety of first-order logic theories represented by sets of clauses. A satisfiable theory, saturated by superposition, implicitly defines a minimal term-generated model for the theory. Proving universal properties with respect to a saturated theory directly leads to a modification of the minimal model's term-generated domain, as new Skolem functions are introduced. For many applications, this is not desired. Therefore, we propose the first superposition calculus that can explicitly represent existentially quantified variables and can thus compute with respect to a given domain. This calculus is sound and refutationally complete in the limit for a first-order fixed domain semantics. For saturated Horn theories and classes of positive formulas, we can even employ the calculus to prove properties of the minimal model itself, going beyond the scope of known superposition-based approaches.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W2052434414",
    "type": "article"
  },
  {
    "title": "The geometry of linear higher-order recursion",
    "doi": "https://doi.org/10.1145/1462179.1462180",
    "publication_date": "2009-02-01",
    "publication_year": 2009,
    "authors": "Ugo Dal Lago",
    "corresponding_authors": "Ugo Dal Lago",
    "abstract": "Imposing linearity and ramification constraints allows to weaken higher-order (primitive) recursion in such a way that the class of representable functions equals the class of polynomial-time computable functions, as the works by Leivant, Hofmann, and others show. This article shows that fine-tuning these two constraints leads to different expressive strengths, some of them lying well beyond polynomial time. This is done by introducing a new semantics, called algebraic context semantics. The framework stems from Gonthier's original work (itself a model of Girard's geometry of interaction) and turns out to be a versatile and powerful tool for the quantitative analysis of normalization in the lambda calculus with constants and higher-order recursion.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W2133014686",
    "type": "article"
  },
  {
    "title": "Automated Equivalence Checking of Concurrent Quantum Systems",
    "doi": "https://doi.org/10.1145/3231597",
    "publication_date": "2018-10-31",
    "publication_year": 2018,
    "authors": "Ebrahim Ardeshir-Larijani; Simon J. Gay; Rajagopal Nagarajan",
    "corresponding_authors": "",
    "abstract": "The novel field of quantum computation and quantum information has gathered significant momentum in the last few years. It has the potential to radically impact the future of information technology and influence the development of modern society. The construction of practical, general purpose quantum computers has been challenging, but quantum cryptographic and communication devices have been available in the commercial marketplace for several years. Quantum networks have been built in various cities around the world and a dedicated satellite has been launched by China to provide secure quantum communication. Such new technologies demand rigorous analysis and verification before they can be trusted in safety- and security-critical applications. Experience with classical hardware and software systems has shown the difficulty of achieving robust and reliable implementations. We present CCS q , a concurrent language for describing quantum systems, and develop verification techniques for checking equivalence between CCS q processes. CCS q has well-defined operational and superoperator semantics for protocols that are functional , in the sense of computing a deterministic input-output relation for all interleavings arising from concurrency in the system. We have implemented QEC (Quantum Equivalence Checker), a tool that takes the specification and implementation of quantum protocols, described in CCS q , and automatically checks their equivalence. QEC is the first fully automatic equivalence checking tool for concurrent quantum systems. For efficiency purposes, we restrict ourselves to Clifford operators in the stabilizer formalism, but we are able to verify protocols over all input states. We have specified and verified a collection of interesting and practical quantum protocols, ranging from quantum communication and quantum cryptography to quantum error correction.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W2901382944",
    "type": "article"
  },
  {
    "title": "Correctness and Completeness of Logic Programs",
    "doi": "https://doi.org/10.1145/2898434",
    "publication_date": "2016-05-18",
    "publication_year": 2016,
    "authors": "Włodzimierz Drabent",
    "corresponding_authors": "Włodzimierz Drabent",
    "abstract": "We discuss proving correctness and completeness of definite clause logic programs. We propose a method for proving completeness, while for proving correctness we employ a method that should be well known but is often neglected. Also, we show how to prove completeness and correctness in the presence of SLD-tree pruning, and point out that approximate specifications simplify specifications and proofs. We compare the proof methods to declarative diagnosis (algorithmic debugging), showing that approximate specifications eliminate a major drawback of the latter. We argue that our proof methods reflect natural declarative thinking about programs, and that they can be used, formally or informally, in everyday programming.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W1804654308",
    "type": "article"
  },
  {
    "title": "Tableau Calculi for Logic Programs under Answer Set Semantics",
    "doi": "https://doi.org/10.1145/2480759.2480767",
    "publication_date": "2013-06-01",
    "publication_year": 2013,
    "authors": "Martin Gebser; Torsten Schaub",
    "corresponding_authors": "",
    "abstract": "We introduce formal proof systems based on tableau methods for analyzing computations in Answer Set Programming (ASP). Our approach furnishes fine-grained instruments for characterizing operations as well as strategies of ASP solvers. The granularity is detailed enough to capture a variety of propagation and choice methods of algorithms used for ASP solving, also incorporating SAT-based and conflict-driven learning approaches to some extent. This provides us with a uniform setting for identifying and comparing fundamental properties of ASP solving approaches. In particular, we investigate their proof complexities and show that the run-times of best-case computations can vary exponentially between different existing ASP solvers. Apart from providing a framework for comparing ASP solving approaches, our characterizations also contribute to their understanding by pinning down the constitutive atomic operations. Furthermore, our framework is flexible enough to integrate new inference patterns, and so to study their relation to existing ones. To this end, we generalize our approach and provide an extensible basis aiming at a modular incorporation of additional language constructs. This is exemplified by augmenting our basic tableau methods with cardinality constraints and disjunctions.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2000863621",
    "type": "article"
  },
  {
    "title": "Using Generalized Annotated Programs to Solve Social Network Diffusion Optimization Problems",
    "doi": "https://doi.org/10.1145/2480759.2480762",
    "publication_date": "2013-06-01",
    "publication_year": 2013,
    "authors": "Paulo Shakarian; Matthias Broecheler; V. S. Subrahmanian; Cristian Molinaro",
    "corresponding_authors": "",
    "abstract": "There has been extensive work in many different fields on how phenomena of interest (e.g., diseases, innovation, product adoption) “diffuse” through a social network. As social networks increasingly become a fabric of society, there is a need to make “optimal” decisions with respect to an observed model of diffusion. For example, in epidemiology, officials want to find a set of k individuals in a social network which, if treated, would minimize spread of a disease. In marketing, campaign managers try to identify a set of k customers that, if given a free sample, would generate maximal “buzz” about the product. In this article, we first show that the well-known Generalized Annotated Program (GAP) paradigm can be used to express many existing diffusion models. We then define a class of problems called Social Network Diffusion Optimization Problems (SNDOPs). SNDOPs have four parts: (i) a diffusion model expressed as a GAP, (ii) an objective function we want to optimize with respect to a given diffusion model, (iii) an integer k &gt; 0 describing resources (e.g., medication) that can be placed at nodes, (iv) a logical condition VC that governs which nodes can have a resource (e.g., only children above the age of 5 can be treated with a given medication). We study the computational complexity of SNDOPs and show both NP-completeness results as well as results on complexity of approximation. We then develop an exact and a heuristic algorithm to solve a large class of SNDOPproblems and show that our GREEDY-SNDOPs algorithm achieves the best possible approximation ratio that a polynomial algorithm can achieve (unless P = NP ). We conclude with a prototype experimental implementation to solve SNDOPs that looks at a real-world Wikipedia dataset consisting of over 103,000 edges.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2028757431",
    "type": "article"
  },
  {
    "title": "Concurrent Dynamic Algebra",
    "doi": "https://doi.org/10.1145/2785967",
    "publication_date": "2015-08-17",
    "publication_year": 2015,
    "authors": "Hitoshi Furusawa; Georg Struth",
    "corresponding_authors": "",
    "abstract": "We reconstruct Peleg’s concurrent dynamic logic in the context of modal Kleene algebras. We explore the algebraic structure of its multirelational semantics and develop an axiomatization of concurrent dynamic algebras from that basis. In this context, sequential composition is not associative. It interacts with parallel composition through a weak distributivity law. The modal operators of concurrent dynamic algebra are obtained from abstract axioms for domain and antidomain operators; the Kleene star is modelled as a least fixpoint. Algebraic variants of Peleg’s axioms are shown to be derivable in these algebras, and their soundness is proved relative to the multirelational model. Additional results include iteration principles for the Kleene star and a refutation of variants of Segerberg’s axiom in the multirelational setting. The most important results have been verified formally with Isabelle/HOL.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2064992609",
    "type": "article"
  },
  {
    "title": "Two-Variable Separation Logic and Its Inner Circle",
    "doi": "https://doi.org/10.1145/2724711",
    "publication_date": "2015-03-21",
    "publication_year": 2015,
    "authors": "Stéphane Demri; Morgan Deters",
    "corresponding_authors": "",
    "abstract": "Separation logic is a well-known assertion language for Hoare-style proof systems. We show that first-order separation logic with a unique record field restricted to two quantified variables and no program variables is undecidable. This is among the smallest fragments of separation logic known to be undecidable, and this contrasts with the decidability of two-variable first-order logic. We also investigate its restriction by dropping the magic wand connective, known to be decidable with nonelementary complexity, and we show that the satisfiability problem with only two quantified variables is not yet elementary recursive. Furthermore, we establish insightful and concrete relationships between two-variable separation logic and propositional interval temporal logic (PITL), data logics, and modal logics, providing an inner circle of closely related logics.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2066800627",
    "type": "article"
  },
  {
    "title": "Minimizing Deterministic Lattice Automata",
    "doi": "https://doi.org/10.1145/2631915",
    "publication_date": "2015-03-01",
    "publication_year": 2015,
    "authors": "Shulamit Halamish; Orna Kupferman",
    "corresponding_authors": "",
    "abstract": "Traditional automata accept or reject their input and are therefore Boolean. In contrast, weighted automata map each word to a value from a semiring over a large domain. The special case of lattice automata , in which the semiring is a finite lattice, has interesting theoretical properties as well as applications in formal methods. A minimal deterministic automaton captures the combinatorial nature and complexity of a formal language. Deterministic automata are used in runtime monitoring, pattern recognition, and modeling systems. Thus, the minimization problem for deterministic automata is of great interest, both theoretically and in practice. For deterministic traditional automata on finite words, a minimization algorithm, based on the Myhill-Nerode right congruence on the set of words, generates in polynomial time a canonical minimal deterministic automaton. A polynomial algorithm is known also for deterministic weighted automata over the tropical semiring. For general deterministic weighted automata, the problem of minimization is open. In this article, we study minimization of deterministic lattice automata. We show that it is impossible to define a right congruence in the context of lattices, and that no canonical minimal automaton exists. Consequently, the minimization problem is much more complicated, and we prove that it is NP-complete. As good news, we show that while right congruence fails already for finite lattices that are fully ordered, for this setting we are able to combine a finite number of right congruences and generate a minimal deterministic automaton in polynomial time.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W2004898185",
    "type": "article"
  },
  {
    "title": "From Security Protocols to Pushdown Automata",
    "doi": "https://doi.org/10.1145/2811262",
    "publication_date": "2015-09-23",
    "publication_year": 2015,
    "authors": "Rémy Chrétien; Véronique Cortier; Stéphanie Delaune",
    "corresponding_authors": "",
    "abstract": "Formal methods have been very successful in analyzing security protocols for reachability properties such as secrecy or authentication. In contrast, there are very few results for equivalence-based properties, crucial for studying, for example, privacy-like properties such as anonymity or vote secrecy. We study the problem of checking equivalence of security protocols for an unbounded number of sessions. Since replication leads very quickly to undecidability (even in the simple case of secrecy), we focus on a limited fragment of protocols (standard primitives but pairs, one variable per protocol’s rules) for which the secrecy preservation problem is known to be decidable. Surprisingly, this fragment turns out to be undecidable for equivalence. Then, restricting our attention to deterministic protocols, we propose the first decidability result for checking equivalence of protocols for an unbounded number of sessions. This result is obtained through a characterization of equivalence of protocols in terms of equality of languages of (generalized, real-time) deterministic pushdown automata. We further show that checking for equivalence of protocols is actually equivalent to checking for equivalence of generalized, real-time deterministic pushdown automata. Very recently, the algorithm for checking for equivalence of deterministic pushdown automata has been implemented. We have implemented our translation from protocols to pushdown automata, yielding the first tool that decides equivalence of (some class of) protocols, for an unbounded number of sessions. As an application, we have analyzed some protocols of the literature including a simplified version of the basic access control (BAC) protocol used in biometric passports.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W2102565724",
    "type": "article"
  },
  {
    "title": "Higher Homotopies in a Hierarchy of Univalent Universes",
    "doi": "https://doi.org/10.1145/2729979",
    "publication_date": "2015-03-21",
    "publication_year": 2015,
    "authors": "Nicolai Kraus; Christian Sattler",
    "corresponding_authors": "",
    "abstract": "For Martin-Lof type theory with a hierarchy U(0): U(1): U(2): ... of univalent universes, we show that U(n) is not an n-type. Our construction also solves the problem of finding a type that strictly has some high truncation level without using higher inductive types. In particular, U(n) is such a type if we restrict it to n-types. We have fully formalized and verified our results within the dependently typed language and proof assistant Agda.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W2104240658",
    "type": "article"
  },
  {
    "title": "Effective Interpolation and Preservation in Guarded Logics",
    "doi": "https://doi.org/10.1145/2814570",
    "publication_date": "2015-12-06",
    "publication_year": 2015,
    "authors": "Michael Benedikt; Balder ten Cate; Michael Vanden Boom",
    "corresponding_authors": "",
    "abstract": "Desirable properties of a logic include decidability, and a model theory that inherits properties of first-order logic, such as interpolation and preservation theorems. It is known that the Guarded Fragment (GF) of first-order logic is decidable and satisfies some preservation properties from first-order model theory; however, it fails to have Craig interpolation. The Guarded Negation Fragment (GNF), a recently defined extension, is known to be decidable and to have Craig interpolation. Here we give the first results on effective interpolation for extensions of GF. We provide an interpolation procedure for GNF whose complexity matches the doubly exponential upper bound for satisfiability of GNF. We show that the same construction gives not only Craig interpolation, but Lyndon interpolation and relativized interpolation, which can be used to provide effective proofs of some preservation theorems. We provide upper bounds on the size of GNF interpolants for both GNF and GF input, and complement this with matching lower bounds.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W2270291724",
    "type": "article"
  },
  {
    "title": "Why Liveness for Timed Automata Is Hard, and What We Can Do About It",
    "doi": "https://doi.org/10.1145/3372310",
    "publication_date": "2020-03-03",
    "publication_year": 2020,
    "authors": "Frédéric Herbreteau; B. Srivathsan; Thanh-Tung Tran; Igor Walukiewicz",
    "corresponding_authors": "",
    "abstract": "The reachability problem for timed automata asks if a given automaton has a run leading to an accepting state, and the liveness problem asks if the automaton has an infinite run that visits accepting states infinitely often. Both of these problems are known to be P space -complete. We show that if P ≠P space , the liveness problem is more difficult than the reachability problem; in other words, we exhibit a family of automata for which solving the reachability problem with the standard algorithm is in P but solving the liveness problem is P space -hard. This leads us to revisit the algorithmics for the liveness problem. We propose a notion of a witness for the fact that a timed automaton violates a liveness property. We give an algorithm for computing such a witness and compare it to existing solutions.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W3010307732",
    "type": "article"
  },
  {
    "title": "First-order Logic with Connectivity Operators",
    "doi": "https://doi.org/10.1145/3595922",
    "publication_date": "2023-05-08",
    "publication_year": 2023,
    "authors": "Nicole Schirrmacher; Sebastian Siebertz; Alexandre Vigny",
    "corresponding_authors": "",
    "abstract": "First-order logic (FO) can express many algorithmic problems on graphs, such as the independent set and dominating set problem parameterized by solution size. However, FO cannot express the very simple algorithmic question whether two vertices are connected. We enrich FO with connectivity predicates that are tailored to express algorithmic graph problems that are commonly studied in parameterized algorithmics. By adding the atomic predicates conn k ( x,y,z_1,..., z k ) that hold true in a graph if there exists a path between (the valuations of) x and y after (the valuations of) z 1 ,..., z k have been deleted, we obtain separator logic FO + conn. We show that separator logic can express many interesting problems, such as the feedback vertex set problem and elimination distance problems to first-order definable classes. Denote by FO + conn k the fragment of separator logic that is restricted to connectivity predicates with at most k + 2 variables (that is, at most k deletions), we show that FO + conn k + 1 is strictly more expressive than FO + conn k for all k ≥ 0 . We then study the limitations of separator logic and prove that it cannot express planarity, and, in particular, not the disjoint paths problem. We obtain the stronger disjoint-paths logic FO + DP by adding the atomic predicates disjoint-paths k [( x 1 , y 1 ),..., ( x k , y k ) that evaluate to true if there are internally vertex-disjoint paths between (the valuations of) x i and y i for all 1 ≤ i ≤ k . Disjoint-paths logic can express the disjoint paths problem, the problem of (topological) minor containment, the problem of hitting (topological) minors, and many more. Again, we show that the fragments FO + DP k that use predicates for at most k disjoint paths form a strict hierarchy of expressiveness. Finally, we compare the expressive power of the new logics with that of transitive-closure logics and monadic second-order logic.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W3178650038",
    "type": "article"
  },
  {
    "title": "Reasoning about Quality and Fuzziness of Strategic Behaviors",
    "doi": "https://doi.org/10.1145/3582498",
    "publication_date": "2023-02-09",
    "publication_year": 2023,
    "authors": "Patricia Bouyer; Orna Kupferman; Nicolas Markey; Bastien Maubert; Aniello Murano; Giuseppe Perelli",
    "corresponding_authors": "",
    "abstract": "Temporal logics are extensively used for the specification of on-going behaviors of computer systems. Two significant developments in this area are the extension of traditional temporal logics with modalities that enable the specification of on-going strategic behaviors in multi-agent systems, and the transition of temporal logics to a quantitative setting, where different satisfaction values enable the specifier to formalize concepts such as certainty or quality. In the first class, SL ( Strategy Logic ) is one of the most natural and expressive logics describing strategic behaviors. In the second class, a notable logic is LTL[ℱ] , which extends LTL with quality operators . In this work, we introduce and study SL[ℱ] , which enables the specification of quantitative strategic behaviors. The satisfaction value of an SL[ℱ] formula is a real value in [0,1], reflecting “how much” or “how well” the strategic on-going objectives of the underlying agents are satisfied. We demonstrate the applications of SL[ℱ] in quantitative reasoning about multi-agent systems, showing how it can express and measure concepts like stability in multi-agent systems, and how it generalizes some fuzzy temporal logics. We also provide a model-checking algorithm for SL[ℱ] , based on a quantitative extension of Quantified CTL ⋆ . Our algorithm provides the first decidability result for a quantitative extension of Strategy Logic. In addition, it can be used for synthesizing strategies that maximize the quality of the systems’ behavior.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4319736260",
    "type": "article"
  },
  {
    "title": "Local Search For Satisfiability Modulo Integer Arithmetic Theories",
    "doi": "https://doi.org/10.1145/3597495",
    "publication_date": "2023-05-18",
    "publication_year": 2023,
    "authors": "Shaowei Cai; Bohan Li; Xindi Zhang",
    "corresponding_authors": "",
    "abstract": "Satisfiability Modulo Theories (SMT) refers to the problem of deciding the satisfiability of a formula with respect to certain background first-order theories. In this article, we focus on Satisfiablity Modulo Integer Arithmetic, which is referred to as SMT(IA), including both linear and non-linear integer arithmetic theories. Dominant approaches to SMT rely on calling a CDCL-based SAT solver, either in a lazy or eager flavour. Local search, a competitive approach to solving combinatorial problems including SAT, however, has not been well studied for SMT. We develop the first local-search algorithm for SMT(IA) by directly operating on variables, breaking through the traditional framework. We propose a local-search framework by considering the distinctions between Boolean and integer variables. Moreover, we design a novel operator and scoring functions tailored for integer arithmetic, as well as a two-level operation selection heuristic. Putting these together, we develop a local search SMT(IA) solver called LocalSMT. Experiments are carried out to evaluate LocalSMT on benchmark sets from SMT-LIB. The results show that LocalSMT is competitive and complementary with state-of-the-art SMT solvers, and performs particularly well on those formulae with only integer variables. A simple sequential portfolio with Z3 improves the state-of-the-art on satisfiable benchmark sets from SMT-LIB.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4377021963",
    "type": "article"
  },
  {
    "title": "Resource-distribution via Boolean constraints",
    "doi": "https://doi.org/10.1145/601775.601778",
    "publication_date": "2003-01-01",
    "publication_year": 2003,
    "authors": "James Harland; David Pym",
    "corresponding_authors": "",
    "abstract": "We consider the problem of searching for proofs in sequential presentations of logics with multiplicative (or intensional) connectives. Specifically, we start with the multiplicative fragment of linear logic and extend, on the one hand, to linear logic with its additives and, on the other, to the additives of the logic of bunched implications ( BI ). We give an algebraic method for calculating the distribution of the side-formulæ in multiplicative rules which allows the occurrence or non-occurrence of a formula on a branch of a proof to be determined once sufficient information is available. Each formula in the conclusion of such a rule is assigned a Boolean expression. As a search proceeds, a set of Boolean constraint equations is generated. We show that a solution to such a set of equations determines a proof corresponding to the given search. We explain a range of strategies, from the lazy to the eager, for solving sets of constraint equations. We indicate how to apply our methods systematically to large family of relevant systems.",
    "cited_by_count": 27,
    "openalex_id": "https://openalex.org/W2112448481",
    "type": "article"
  },
  {
    "title": "Making abstract domains condensing",
    "doi": "https://doi.org/10.1145/1042038.1042040",
    "publication_date": "2005-01-01",
    "publication_year": 2005,
    "authors": "Roberto Giacobazzi; Francesco Ranzato; Francesca Scozzari",
    "corresponding_authors": "",
    "abstract": "In this article, we show that reversible analyses of logic languages by abstract interpretation can be performed without loss of precision by systematically refining abstract domains. This is obtained by adding to the abstract domain the minimal amount of concrete semantic information so that this refined abstract domain becomes rich enough to allow goal-driven and goal-independent analyses agree. These domains are known as condensing abstract domains. Essentially, an abstract domain A is condensing when the goal-driven analysis performed on A for a program P and a given query can be retrieved with no loss of precision from the goal-independent analysis on A of P . We show that condensation is an abstract domain property and that the problem of making an abstract domain condensing boils down to the problem of making the corresponding abstract interpretation complete, in a weakened form, with respect to unification. In the case of abstract domains for logic program analysis approximating computed answer substitutions, we provide a clean logical characterization of condensing domains as fragments of propositional linear logic. We apply our methodology to the systematic design of condensing domains for freeness and independence analysis.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W1973325907",
    "type": "article"
  },
  {
    "title": "Outlier detection by logic programming",
    "doi": "https://doi.org/10.1145/1297658.1297665",
    "publication_date": "2007-12-01",
    "publication_year": 2007,
    "authors": "Fabrizio Angiulli; Gianluigi Greco; Luigi Palopoli",
    "corresponding_authors": "",
    "abstract": "The development of effective knowledge discovery techniques has become a very active research area in recent years due to the important impact it has had in several relevant application domains. One interesting task therein is that of singling out anomalous individuals from a given population, for example, to detect rare events in time-series analysis settings, or to identify objects whose behavior is deviant w.r.t. a codified standard set of rules. Such exceptional individuals are usually referred to as outliers in the literature. In this article, the concept of outlier is formally stated in the context of knowledge-based systems, by generalizing that originally proposed in Angiulli et al. [2003] in the context of default theories. The chosen formal framework here is that of logic programming, wherein potential applications of techniques for outlier detection are thoroughly discussed. The proposed formalization is a novel one and helps to shed light on the nature of outliers occurring in logic bases. Also the exploitation of minimality criteria in outlier detection is illustrated. The computational complexity of outlier detection problems arising in this novel setting is also thoroughly investigated and accounted for in the paper. Finally, rewriting algorithms are proposed that transform any outlier detection problem into an equivalent inference problem under stable model semantics, thereby making outlier computation effective and realizable on top of any stable model solver.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W2042771461",
    "type": "article"
  },
  {
    "title": "Ordinary interactive small-step algorithms, II",
    "doi": "https://doi.org/10.1145/1243996.1243998",
    "publication_date": "2007-07-01",
    "publication_year": 2007,
    "authors": "Andreas Blass; Yuri Gurevich",
    "corresponding_authors": "",
    "abstract": "This is the second in a series of three articles extending the proof of the Abstract State Machine Thesis---that arbitrary algorithms are behaviorally equivalent to abstract state machines---to algorithms that can interact with their environments during a step, rather than only between steps. As in the first article of the series, we are concerned here with ordinary, small-step, interactive algorithms. This means that the algorithms: (1) proceed in discrete, global steps, (2) perform only a bounded amount of work in each step, (3) use only such information from the environment as can be regarded as answers to queries, and (4) never complete a step until all queries from that step have been answered. After reviewing the previous article's formal description of such algorithms and the definition of behavioral equivalence, we define ordinary, interactive, small-step abstract state machines (ASMs). Except for very minor modifications, these are the machines commonly used in the ASM literature. We define their semantics in the framework of ordinary algorithms and show that they satisfy the postulates for these algorithms. This material lays the groundwork for the final article in the series, in which we shall prove the Abstract State Machine thesis for ordinary, intractive, small-step algorithms: All such algorithms are equivalent to ASMs.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W4234381234",
    "type": "article"
  },
  {
    "title": "Ordinary interactive small-step algorithms, III",
    "doi": "https://doi.org/10.1145/1243996.1243999",
    "publication_date": "2007-07-01",
    "publication_year": 2007,
    "authors": "Andreas Blass; Yuri Gurevich",
    "corresponding_authors": "",
    "abstract": "This is the third in a series of three articles extending the proof of the Abstract State Machine thesis---that arbitrary algorithms are behaviorally equivalent to abstract state machines---to algorithms that can interact with their environments during a step, rather than only between steps. As in the first two articles of the series, we are concerned here with ordinary, small-step, interactive algorithms. This means that the algorithms: (1) proceed in discrete, global steps, (2) perform only a bounded amount of work in each step, (3) use only such information from the environment as can be regarded as answers to queries, and (4) never complete a step until all queries from that step have been answered. After reviewing the previous articles' definitions of such algorithms, of behavioral equivalence, and of abstract state machines (ASMs), we prove the main result: Every ordinary, interactive, small-step algorithm is behaviorally equivalent to an ASM. We also discuss some possible variations of and additions to the ASM semantics.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W4239934034",
    "type": "article"
  },
  {
    "title": "Arithmetic complexity",
    "doi": "https://doi.org/10.1145/1459010.1459012",
    "publication_date": "2009-01-01",
    "publication_year": 2009,
    "authors": "Lou van den Dries; Yiannis N. Moschovakis",
    "corresponding_authors": "",
    "abstract": "We obtain lower bounds on the cost of computing various arithmetic functions and deciding various arithmetic relations from specified primitives. This includes lower bounds for computing the greatest common divisor and deciding coprimeness of two integers, from primitives like addition, subtraction, division with remainder and multiplication. Some of our results are in terms of recursive programs, but they generalize directly to most (plausibly all) algorithms from the specified primitives. Our methods involve some elementary number theory as well as the development of some basic notions and facts about recursive algorithms.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W2294814249",
    "type": "article"
  },
  {
    "title": "Higher-order term indexing using substitution trees",
    "doi": "https://doi.org/10.1145/1614431.1614437",
    "publication_date": "2009-10-01",
    "publication_year": 2009,
    "authors": "Brigitte Pientka",
    "corresponding_authors": "Brigitte Pientka",
    "abstract": "We present a higher-order term indexing strategy based on substitution trees for simply typed lambda-terms. There are mainly two problems in adapting first-order indexing techniques. First, many operations used in building an efficient term index and retrieving a set of candidate terms from a large collection are undecidable in general for higher-order terms. Second, the scoping of variables and binders in the higher-order case presents challenges. The approach taken in this article is to reduce the problem to indexing linear higher-order patterns, a decidable fragment of higher-order terms, and delay solving terms outside of this fragment. We present insertion of terms into the index based on computing the most specific linear generalization of two linear higher-order patterns, and retrieval based on matching two linear higher-order patterns. Our theoretical framework maintains that terms are in βη-normal form, thereby eliminating the need to renormalize and raise terms during insertion and retrieval. Finally, we prove correctness of our presented algorithms. This indexing structure is implemented as part of the Twelf system to speed up the execution of the tabled higher-logic programming interpreter.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W2105146990",
    "type": "article"
  },
  {
    "title": "Certainty closure",
    "doi": "https://doi.org/10.1145/1459010.1459013",
    "publication_date": "2009-01-01",
    "publication_year": 2009,
    "authors": "Neil Yorke‐Smith; Carmen Gervet",
    "corresponding_authors": "",
    "abstract": "Constraint Programming (CP) has proved an effective paradigm to model and solve difficult combinatorial satisfaction and optimisation problems from disparate domains. Many such problems arising from the commercial world are permeated by data uncertainty. Existing CP approaches that accommodate uncertainty are less suited to uncertainty arising due to incomplete and erroneous data, because they do not build reliable models and solutions guaranteed to address the user's genuine problem as she perceives it. Other fields such as reliable computation offer combinations of models and associated methods to handle these types of uncertain data, but lack an expressive framework characterising the resolution methodology independently of the model. We present a unifying framework that extends the CP formalism in both model and solutions, to tackle ill-defined combinatorial problems with incomplete or erroneous data. The certainty closure framework brings together modelling and solving methodologies from different fields into the CP paradigm to provide reliable and efficient approches for uncertain constraint problems. We demonstrate the applicability of the framework on a case study in network diagnosis. We define resolution forms that give generic templates, and their associated operational semantics, to derive practical solution methods for reliable solutions.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W2118328349",
    "type": "article"
  },
  {
    "title": "Safety alternating automata on data words",
    "doi": "https://doi.org/10.1145/1877714.1877716",
    "publication_date": "2011-01-01",
    "publication_year": 2011,
    "authors": "Ranko Lazić",
    "corresponding_authors": "Ranko Lazić",
    "abstract": "A data word is a sequence of pairs of a letter from a finite alphabet and an element from an infinite set, where the latter can only be compared for equality. Safety one-way alternating automata with one register on infinite data words are considered, their nonemptiness is shown to be ExpSpace-complete, and their inclusion decidable but not primitive recursive. The same complexity bounds are obtained for satisfiability and refinement, respectively, for the safety fragment of linear temporal logic with freeze quantification. Dropping the safety restriction, adding past temporal operators, or adding one more register, each causes undecidability.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2021449336",
    "type": "article"
  },
  {
    "title": "Typing streams in the Λμ-calculus",
    "doi": "https://doi.org/10.1145/1805950.1805958",
    "publication_date": "2010-07-01",
    "publication_year": 2010,
    "authors": "Alexis Saurin",
    "corresponding_authors": "Alexis Saurin",
    "abstract": "Λμ-calculus is a Böhm-complete extension of Parigot's Λμ-calculus closely related with delimited control in functional programming. In this article, we investigate the meta-theory of untyped Λμ-calculus by proving confluence of the calculus and characterizing the basic observables for the Separation theorem, canonical normal forms . Then, we define Λ s , a new type system for Λμ-calculus that contains a special type construction for streams, and prove that strong normalization and type preservation hold. Thanks to the new typing discipline of Λ s , new computational behaviors can be observed, which were forbidden in previous type systems for λμ-calculi. Those new typed computational behaviors witness the stream interpretation of Λμ-calculus.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2076577093",
    "type": "article"
  },
  {
    "title": "A Generalized QSQR Evaluation Method for Horn Knowledge Bases",
    "doi": "https://doi.org/10.1145/2362355.2362360",
    "publication_date": "2012-10-01",
    "publication_year": 2012,
    "authors": "Ewa Madalińska-Bugaj; Linh Anh Nguyen",
    "corresponding_authors": "",
    "abstract": "We generalize the QSQR evaluation method to give the first set-oriented depth-first evaluation method for Horn knowledge bases. The resulting procedure closely simulates SLD-resolution (to take advantages of the goal-directed approach) and highly exploits set-at-a-time tabling. Our generalized QSQR evaluation procedure is sound and complete. It does not use adornments and annotations. To deal with function symbols, our procedure uses iterative deepening search, which iteratively increases term-depth bound for atoms and substitutions occurring in the computation. When the term-depth bound is fixed, our evaluation procedure runs in polynomial time in the size of extensional relations.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2164475654",
    "type": "article"
  },
  {
    "title": "Mechanizing the metatheory of LF",
    "doi": "https://doi.org/10.1145/1877714.1877721",
    "publication_date": "2011-01-01",
    "publication_year": 2011,
    "authors": "Christian Urban; James Cheney; Stefan Berghofer",
    "corresponding_authors": "",
    "abstract": "LF is a dependent type theory in which many other formal systems can be conveniently embedded. However, correct use of LF relies on nontrivial metatheoretic developments such as proofs of correctness of decision procedures for LF's judgments. Although detailed informal proofs of these properties have been published, they have not been formally verified in a theorem prover. We have formalized these properties within Isabelle/HOL using the Nominal Datatype Package, closely following a recent article by Harper and Pfenning. In the process, we identified and resolved a gap in one of the proofs and a small number of minor lacunae in others. We also formally derive a version of the type checking algorithm from which Isabelle/HOL can generate executable code. Besides its intrinsic interest, our formalization provides a foundation for studying the adequacy of LF encodings, the correctness of Twelf-style metatheoretic reasoning, and the metatheory of extensions to LF.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W2077128347",
    "type": "article"
  },
  {
    "title": "A Theoretical and Numerical Analysis of the Worst-Case Size of Reduced Ordered Binary Decision Diagrams",
    "doi": "https://doi.org/10.1145/3274279",
    "publication_date": "2019-01-18",
    "publication_year": 2019,
    "authors": "Jim E. Newton; Didier Verna",
    "corresponding_authors": "",
    "abstract": "Binary Decision Diagrams (BDDs) and in particular ROBDDs (Reduced Ordered BDDs) are a common data structure for manipulating Boolean expressions, integrated circuit design, type inferencers, model checkers, and many other applications. Although the ROBDD is a lightweight data structure to implement, the behavior, in terms of memory allocation, may not be obvious to the program architect. We explore experimentally, numerically, and theoretically the typical and worst-case ROBDD sizes in terms of number of nodes and residual compression ratios, as compared to unreduced BDDs. While our theoretical results are not surprising, as they are in keeping with previously known results, we believe our method contributes to the current body of research by our experimental and statistical treatment of ROBDD sizes. In addition, we provide an algorithm to calculate the worst-case size. Finally, we present an algorithm for constructing a worst-case ROBDD of a given number of variables. Our approach may be useful to projects deciding whether the ROBDD is the appropriate data structure to use, and in building worst-case examples to test their code.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W2910958598",
    "type": "article"
  },
  {
    "title": "Extending two-variable logic on data trees with order on data values and its automata",
    "doi": "https://doi.org/10.1145/2559945",
    "publication_date": "2014-02-01",
    "publication_year": 2014,
    "authors": "Tony Tan",
    "corresponding_authors": "Tony Tan",
    "abstract": "Data trees are trees in which each node, besides carrying a label from a finite alphabet, also carries a data value from an infinite domain. They have been used as an abstraction model for reasoning tasks on XML and verification. However, most existing approaches consider the case where only equality test can be performed on the data values. In this article we study data trees in which the data values come from a linearly ordered domain, and in addition to equality test, we can test whether the data value in a node is greater than the one in another node. We introduce an automata model for them which we call ordered-data tree automata (ODTA), provide its logical characterisation, and prove that its non-emptiness problem is decidable in 3-NE xp T ime . We also show that the two-variable logic on unranked data trees, studied by Bojanczyk et al. [2009], corresponds precisely to a special subclass of this automata model. Then we define a slightly weaker version of ODTA, which we call weak ODTA , and provide its logical characterisation. The complexity of the non-emptiness problem drops to NP. However, a number of existing formalisms and models studied in the literature can be captured already by weak ODTA. We also show that the definition of ODTA can be easily modified, to the case where the data values come from a tree-like partially ordered domain, such as strings.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W1992955510",
    "type": "article"
  },
  {
    "title": "Constraint Propagation for First-Order Logic and Inductive Definitions",
    "doi": "https://doi.org/10.1145/2499937.2499938",
    "publication_date": "2013-08-01",
    "publication_year": 2013,
    "authors": "Johan Wittocx; Marc Denecker; Maurice Bruynooghe",
    "corresponding_authors": "",
    "abstract": "In Constraint Programming, constraint propagation is a basic component of constraint satisfaction solvers. Here we study constraint propagation as a basic form of inference in the context of first-order logic (FO) and extensions with inductive definitions (FO(ID)) and aggregates (FO(AGG)). In a first, semantic approach, a theory of propagators and constraint propagation is developed for theories in the context of three-valued interpretations. We present an algorithm with polynomial-time data complexity. We show that constraint propagation in this manner can be represented by a datalog program. In a second, symbolic approach, the semantic algorithm is lifted to a constraint propagation algorithm in symbolic structures , symbolic representations of classes of structures. The third part of the article is an overview of existing and potential applications of constraint propagation for model generation, grounding, interactive search problems, approximate methods for ∃∀SO problems, and approximate query answering in incomplete databases.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2066021026",
    "type": "article"
  },
  {
    "title": "A resolution calculus for the branching-time temporal logic CTL",
    "doi": "https://doi.org/10.1145/2529993",
    "publication_date": "2014-02-01",
    "publication_year": 2014,
    "authors": "Lan Zhang; Ullrich Hustadt; Clare Dixon",
    "corresponding_authors": "",
    "abstract": "The branching-time temporal logic CTL is useful for specifying systems that change over time and involve quantification over possible futures. Here we present a resolution calculus for CTL that involves the translation of formulae to a normal form and the application of a number of resolution rules. We use indices in the normal form to represent particular paths and the application of the resolution rules is restricted dependent on an ordering and selection function to reduce the search space. We show that the translation preserves satisfiability, the calculus is sound, complete, and terminating, and consider the complexity of the calculus.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2080448334",
    "type": "article"
  },
  {
    "title": "Efficiently Deciding μ-Calculus with Converse over Finite Trees",
    "doi": "https://doi.org/10.1145/2724712",
    "publication_date": "2015-03-21",
    "publication_year": 2015,
    "authors": "Pierre Genevès; Nabil Layaïda; Alan Schmitt; Nils Gesbert",
    "corresponding_authors": "",
    "abstract": "We present a sound and complete satisfiability-testing algorithm and its effective implementation for an alternation-free modal μ-calculus with converse, where formulas are cycle-free and are interpreted over finite ordered trees. The time complexity of the satisfiability-testing algorithm is 2 O( n ) in terms of formula size n . The algorithm is implemented using symbolic techniques (BDD). We present crucial implementation techniques and heuristics that we used to make the algorithm as fast as possible in practice. Our implementation is available online and can be used to solve logical formulas of significant size and practical value. We illustrate this in the setting of XML trees.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2131842699",
    "type": "article"
  },
  {
    "title": "Managing Change in Graph-Structured Data Using Description Logics",
    "doi": "https://doi.org/10.1145/3143803",
    "publication_date": "2017-10-31",
    "publication_year": 2017,
    "authors": "Shqiponja Ahmetaj; Diego Calvanese; Magdalena Ortiz; Mantas Šimkus",
    "corresponding_authors": "",
    "abstract": "In this article, we consider the setting of graph-structured data that evolves as a result of operations carried out by users or applications. We study different reasoning problems, which range from deciding whether a given sequence of actions preserves the satisfaction of a given set of integrity constraints, for every possible initial data instance, to deciding the (non)existence of a sequence of actions that would take the data to an (un)desirable state, starting either from a specific data instance or from an incomplete description of it. For describing states of the data instances and expressing integrity constraints on them, we use description logics (DLs) closely related to the two-variable fragment of first-order logic with counting quantifiers. The updates are defined as actions in a simple yet flexible language, as finite sequences of conditional insertions and deletions, which allow one to use complex DL formulas to select the (pairs of) nodes for which (node or arc) labels are added or deleted. We formalize the preceding data management problems as a static verification problem and several planning problems and show that, due to the adequate choice of formalisms for describing actions and states of the data, most of these data management problems can be effectively reduced to the (un)satisfiability of suitable formulas in decidable logical formalisms. Leveraging this, we provide algorithms and tight complexity bounds for the formalized problems, both for expressive DLs and for a variant of the popular DL-Lite, advocated for data management in recent years.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2767711329",
    "type": "article"
  },
  {
    "title": "Are Short Proofs Narrow? QBF Resolution Is <i>Not</i> So Simple",
    "doi": "https://doi.org/10.1145/3157053",
    "publication_date": "2017-12-21",
    "publication_year": 2017,
    "authors": "Olaf Beyersdorff; Leroy Chew; Meena Mahajan; Anil Shukla",
    "corresponding_authors": "",
    "abstract": "The ground-breaking paper “Short Proofs Are Narrow -- Resolution Made Simple” by Ben-Sasson and Wigderson (J. ACM 2001) introduces what is today arguably the main technique to obtain resolution lower bounds: to show a lower bound for the width of proofs. Another important measure for resolution is space, and in their fundamental work, Atserias and Dalmau (J. Comput. Syst. Sci. 2008) show that lower bounds for space again can be obtained via lower bounds for width. In this article, we assess whether similar techniques are effective for resolution calculi for quantified Boolean formulas (QBFs). There are a number of different QBF resolution calculi like Q-resolution (the classical extension of propositional resolution to QBF) and the more recent calculi ∀Exp+Res and IR-calc. For these systems, a mixed picture emerges. Our main results show that the relations both between size and width and between space and width drastically fail in Q-resolution, even in its weaker tree-like version. On the other hand, we obtain positive results for the expansion-based resolution systems ∀Exp+Res and IR-calc, however, only in the weak tree-like models. Technically, our negative results rely on showing width lower bounds together with simultaneous upper bounds for size and space. For our positive results, we exhibit space and width-preserving simulations between QBF resolution calculi.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2778491775",
    "type": "article"
  },
  {
    "title": "A New Perspective on FO Model Checking of Dense Graph Classes",
    "doi": "https://doi.org/10.1145/3383206",
    "publication_date": "2020-07-05",
    "publication_year": 2020,
    "authors": "Jakub Gajarský; Petr Hliněný; Jan Óbdržálek; Daniel Lokshtanov; M. S. Ramanujan",
    "corresponding_authors": "",
    "abstract": "We study the first-order (FO) model checking problem of dense graph classes, namely, those that have FO interpretations in (or are FO transductions of) some sparse graph classes. We give a structural characterization of the graph classes that are FO interpretable in graphs of bounded degree. This characterization allows us to efficiently compute such an FO interpretation for an input graph. As a consequence, we obtain an FPT algorithm for successor-invariant FO model checking on any graph class that is FO interpretable in (or an FO transduction of) a graph class of bounded degree. The approach we use to obtain these results may also be of independent interest.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W3040102297",
    "type": "article"
  },
  {
    "title": "Identifying Efficient Abductive Hypotheses Using Multicriteria Dominance Relation",
    "doi": "https://doi.org/10.1145/2629669",
    "publication_date": "2014-08-01",
    "publication_year": 2014,
    "authors": "Maciej Komosiński; Adam Kupś; Dorota Leszczyńska-Jasion; Mariusz Urbański",
    "corresponding_authors": "",
    "abstract": "In this article, results of the automation of an abductive procedure are reported. This work is a continuation of our earlier research [Komosinski et al. 2012], where a general scheme of the procedure has been proposed. Here, a more advanced system developed to generate and evaluate abductive hypotheses is introduced. Abductive hypotheses have been generated by the implementation of the synthetic tableau method. Prior to the evaluation, the set of hypotheses has undergone several reduction phases. To assess usefulness of abductive hypotheses in the reduced set, several criteria have been employed. The evaluation of efficiency of the hypotheses has been provided by the multicriteria dominance relation. To comprehend the abductive procedure and the evaluation process more extensively, analyses have been conducted on a number of artificially generated abductive problems.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W1974666098",
    "type": "article"
  },
  {
    "title": "A Conceptual Framework for Secrecy-preserving Reasoning in Knowledge Bases",
    "doi": "https://doi.org/10.1145/2637477",
    "publication_date": "2014-12-29",
    "publication_year": 2014,
    "authors": "Tao Jia; Giora Slutzki; Vasant Honavar",
    "corresponding_authors": "",
    "abstract": "In many applications, Knowledge Bases (KBs) contain confidential or private information (secrets). The KB should be able to use this secret information in its reasoning process but in answering user queries care must be exercised so that secrets are not revealed to unauthorized users. We consider this problem under the Open World Assumption (OWA) in a setting with multiple querying agents M 1 ,…, M m that can pose queries against the KB K and selectively share answers that they receive from K with one or more other querying agents. We assume that for each M i , the KB has a prespecified set of secrets S i that need to be protected from M i . Communication between querying agents is modeled by a communication graph, a directed graph with self-loops. We introduce a general framework and propose an approach to secrecy-preserving query answering based on sound and complete proof systems. The idea is to hide the truthful answer from a querying agent M i by feigning ignorance without lying (i.e., to provide the answer ‘Unknown’ to a query q if it needs to be protected. Under the OWA, a querying agent cannot distinguish between the case that q is being protected (for reasons of secrecy) and the case that it cannot be inferred from K . In the pre-query stage we compute a set of envelopes E 1 , …, E m (restricted to a finite subset of the set of formulae that are entailed by K ) so that S i ⊆ E i , and a query α posed by agent M i can be answered truthfully whenever α ∉ E i and ¬ α ∉ E i . After the pre-query stage, the envelope is updated as needed. We illustrate this approach with two simple cases: the Propositional Horn KBs and the Description Logic AL KBs.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2004892811",
    "type": "article"
  },
  {
    "title": "An Evaluation-Driven Decision Procedure for G3i",
    "doi": "https://doi.org/10.1145/2660770",
    "publication_date": "2015-03-01",
    "publication_year": 2015,
    "authors": "Mauro Ferrari; Camillo Fiorentini; Guido Fiorino",
    "corresponding_authors": "",
    "abstract": "It is well known that G3i, the sequent calculus for intuitionistic propositional logic where weakening and contraction are absorbed into the rules, is not terminating. Indeed, due to the contraction in the rule for left implication, the naïve goal-oriented proof-search strategy, consisting in applying the rules of the calculus bottom up until possible, can generate branches of infinite length. The usual solution to this problem is to support the proof-search procedure with a loop checking mechanism that prevents the generation of infinite branches by storing and analyzing some information regarding the branch under development. In this article, we propose a new technique based on evaluation functions. An evaluation function is a lightweight computational mechanism that, analyzing only the current goal of the proof search, allows one to drive the application of rules to guarantee termination and to avoid useless backtracking. We describe an evaluation-driven proof-search procedure that given a sequent σ returns either a G3i-derivation of σ or a countermodel for σ. We prove that such a procedure is terminating and correct, and that the depth of the G3i-trees generated during proof search is quadratic in the size of σ. Finally, we discuss the overhead time introduced by evaluation functions in the proof-search procedure.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2113939721",
    "type": "article"
  },
  {
    "title": "A General Theory of Barbs, Contexts, and Labels",
    "doi": "https://doi.org/10.1145/2631916",
    "publication_date": "2014-08-01",
    "publication_year": 2014,
    "authors": "Filippo Bonchi; Fabio Gadducci; Giacoma Valentina Monreale",
    "corresponding_authors": "",
    "abstract": "Barbed bisimilarity is a widely used behavioral equivalence for interactive systems: given a set of predicates (denoted “barbs” and representing basic observations on states) and a set of contexts (representing the possible execution environments), two systems are deemed to be equivalent if they verify the same barbs whenever inserted inside any of the chosen contexts. Despite its flexibility and expressiveness, this definition of equivalence is unsatisfactory because often the quantification is over an infinite set of contexts, thus making barbed bisimilarity very hard to be verified. Should a labeled operational semantics be available, more efficient observational equivalences might be adopted. To this end, a series of techniques has been proposed to derive labeled transition systems (LTSs) from unlabeled ones, the main example being Leifer and Milner’s theory of reactive systems. The underlying intuition is that labels should be the “minimal” contexts that allow for a reduction step to be performed. However, minimality is difficult to asses, whereas the set of “intuitively” correct labels is often easily devised by the ingenuity of the researcher. This article introduces a framework that characterizes (weak) barbed bisimilarity via LTSs whose labels are (not necessarily minimal) contexts. Differently from previous proposals, our theory does not depend on the way the labeled transitions are built but instead relies on a simple set-theoretical presentation for identifying those properties such an LTS should verify to (1) capture the barbed bisimilarities of the underlying system and (2) ensure that such bisimilarities are congruences. Furthermore, we adopt suitable proof techniques to make feasible the verification of such properties. To provide a test-bed for our formalism, we instantiate it by addressing the semantics of the Mobile Ambients calculus, recasting its barbed bisimilarities via label-based behavioral equivalences.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2118901376",
    "type": "article"
  },
  {
    "title": "Expressive Completeness of Separation Logic with Two Variables and No Separating Conjunction",
    "doi": "https://doi.org/10.1145/2835490",
    "publication_date": "2016-01-07",
    "publication_year": 2016,
    "authors": "Stéphane Demri; Morgan Deters",
    "corresponding_authors": "",
    "abstract": "Separation logic is used as an assertion language for Hoare-style proof systems about programs with pointers, and there is an ongoing quest for understanding its complexity and expressive power. Herein, we show that first-order separation logic with one record field restricted to two variables and the separating implication (no separating conjunction) is as expressive as weak second-order logic, substantially sharpening a previous result. Capturing weak second-order logic with such a restricted form of separation logic requires substantial updates to known proof techniques. We develop these and, as a by-product, identify the smallest fragment of separation logic known to be undecidable: first-order separation logic with one record field, two variables, and no separating conjunction. Because we forbid ourselves the use of many syntactic resources, this underscores even further the power of separating implication on concrete heaps.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2231494278",
    "type": "article"
  },
  {
    "title": "Convolution as a Unifying Concept",
    "doi": "https://doi.org/10.1145/2874773",
    "publication_date": "2016-02-17",
    "publication_year": 2016,
    "authors": "Brijesh Dongol; Ian J. Hayes; Georg Struth",
    "corresponding_authors": "",
    "abstract": "A notion of convolution is presented in the context of formal power series together with lifting constructions characterising algebras of such series, which usually are quantales. A number of examples underpin the universality of these constructions, the most prominent ones being separation logics, where convolution is separating conjunction in an assertion quantale; interval logics, where convolution is the chop operation; and stream interval functions, where convolution is proposed for analysing the trajectories of dynamical or real-time systems. A Hoare logic can be constructed in a generic fashion on the power-series quantale, which applies to each of these examples. In many cases, commutative notions of convolution have natural interpretations as concurrency operations.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2281454872",
    "type": "article"
  },
  {
    "title": "Complexity of Two-Variable Logic on Finite Trees",
    "doi": "https://doi.org/10.1145/2996796",
    "publication_date": "2016-11-11",
    "publication_year": 2016,
    "authors": "Saguy Benaim; Michael Benedikt; Witold Charatonik; Emanuel Kieroński; Rastislav Lenhardt; Filip Mazowiecki; James Worrell",
    "corresponding_authors": "",
    "abstract": "Verification of properties expressed in the two-variable fragment of first-order logic FO 2 has been investigated in a number of contexts. The satisfiability problem for FO 2 over arbitrary structures is known to be NEXPTIME-complete, with satisfiable formulas having exponential-sized models. Over words, where FO 2 is known to have the same expressiveness as unary temporal logic, satisfiability is again NEXPTIME-complete. Over finite labelled ordered trees, FO 2 has the same expressiveness as navigational XPath, a popular query language for XML documents. Prior work on XPath and FO 2 gives a 2EXPTIME bound for satisfiability of FO 2 over trees. This work contains a comprehensive analysis of the complexity of FO 2 on trees, and on the size and depth of models. We show that different techniques are required depending on the vocabulary used, whether the trees are ranked or unranked, and the encoding of labels on trees. We also look at a natural restriction of FO 2 , its guarded version, GF 2 . Our results depend on an analysis of types in models of FO 2 formulas, including techniques for controlling the number of distinct subtrees, the depth, and the size of a witness to satisfiability for FO 2 sentences over finite trees.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2552825470",
    "type": "article"
  },
  {
    "title": "Syntactic Completeness of Proper Display Calculi",
    "doi": "https://doi.org/10.1145/3529255",
    "publication_date": "2022-04-20",
    "publication_year": 2022,
    "authors": "Jinsheng Chen; Giuseppe Greco; Alessandra Palmigiano; Apostolos Tzimoulis",
    "corresponding_authors": "",
    "abstract": "A recent strand of research in structural proof theory aims at exploring the notion of analytic calculi (i.e., those calculi that support general and modular proof-strategies for cut elimination) and at identifying classes of logics that can be captured in terms of these calculi. In this context, Wansing introduced the notion of proper display calculi as one possible design framework for proof calculi in which the analyticity desiderata are realized in a particularly transparent way. Recently, the theory of properly displayable logics (i.e., those logics that can be equivalently presented with some proper display calculus) has been developed in connection with generalized Sahlqvist theory (a.k.a. unified correspondence). Specifically, properly displayable logics have been syntactically characterized as those axiomatized by analytic inductive axioms , which can be equivalently and algorithmically transformed into analytic structural rules so the resulting proper display calculi enjoy a set of basic properties: soundness, completeness, conservativity, cut elimination, and the subformula property. In this context, the proof that the given calculus is complete w.r.t. the original logic is usually carried out syntactically , i.e., by showing that a (cut-free) derivation exists of each given axiom of the logic in the basic system to which the analytic structural rules algorithmically generated from the given axiom have been added. However, so far, this proof strategy for syntactic completeness has been implemented on a case-by-case base and not in general. In this article, we address this gap by proving syntactic completeness for properly displayable logics in any normal (distributive) lattice expansion signature. Specifically, we show that for every analytic inductive axiom a cut-free derivation can be effectively generated that has a specific shape, referred to as pre-normal form .",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W3130894656",
    "type": "article"
  },
  {
    "title": "Verification of Distributed Quantum Programs",
    "doi": "https://doi.org/10.1145/3517145",
    "publication_date": "2022-03-29",
    "publication_year": 2022,
    "authors": "Yuan Feng; Sanjiang Li; Mingsheng Ying",
    "corresponding_authors": "",
    "abstract": "Distributed quantum systems and especially the Quantum Internet have the ever-increasing potential to fully demonstrate the power of quantum computation. This is particularly true given that developing a general-purpose quantum computer is much more difficult than connecting many small quantum devices. One major challenge of implementing distributed quantum systems is programming them and verifying their correctness. In this paper, we propose a CSP-like distributed programming language to facilitate the specification and verification of such systems. After presenting its operational and denotational semantics, we develop a Hoare-style logic for distributed quantum programs and establish its soundness and (relative) completeness with respect to both partial and total correctness. The effectiveness of the logic is demonstrated by its applications in the verification of quantum teleportation and local implementation of non-local CNOT gates, two important algorithms widely used in distributed quantum systems.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W4220843399",
    "type": "article"
  },
  {
    "title": "Precise Subtyping for Asynchronous Multiparty Sessions",
    "doi": "https://doi.org/10.1145/3568422",
    "publication_date": "2022-10-20",
    "publication_year": 2022,
    "authors": "Silvia Ghilezan; Jovanka Pantović; Ivan Prokić; Alceste Scalas; Nobuko Yoshida",
    "corresponding_authors": "",
    "abstract": "Session subtyping is a cornerstone of refinement of communicating processes: A process implementing a session type (i.e., a communication protocol) T can be safely used whenever a process implementing one of its supertypes T′ is expected, in any context, without introducing deadlocks nor other communication errors. As a consequence, whenever T ≤ T′ holds, it is safe to replace an implementation of T′ with an implementation of the subtype T, which may allow for more optimised communication patterns. We present the first formalisation of the precise subtyping relation for asynchronous multiparty sessions. We show that our subtyping relation is sound(i.e., guarantees safe process replacement, as outlined above) and also complete: Any extension of the relation is unsound. To achieve our results, we develop a novel session decomposition technique, from fullsession types (including internal/external choices) into single input/output session trees (without choices). We cover multiparty sessions with asynchronousinteraction, where messages are transmitted via FIFO queues (as in the TCP/IP protocol), and prove that our subtyping is both operationally and denotationally precise. Our session decomposition technique expresses the subtyping relation as a composition of refinement relations between single input/output trees and provides a simple reasoning principle for asynchronous message optimisations.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W4306873603",
    "type": "article"
  },
  {
    "title": "Parallel-Correctness and Transferability for Conjunctive Queries under Bag Semantics",
    "doi": "https://doi.org/10.1145/3712291",
    "publication_date": "2025-01-15",
    "publication_year": 2025,
    "authors": "Bas Ketsman; Frank Neven; Brecht Vandevoort",
    "corresponding_authors": "",
    "abstract": "Single-round multiway join algorithms first reshuffle data over many servers and then evaluate the query at hand in a parallel and communication-free way. A key question is whether a given distribution policy for the reshuffle is adequate for computing a given query. This property is referred to as parallel-correctness. Another key problem is to detect whether the data reshuffle step can be avoided when evaluating subsequent queries. The latter problem is referred to as transfer of parallel-correctness. This paper extends the study of parallel-correctness and transfer of parallel-correctness of conjunctive queries to incorporate bag semantics. We provide semantical characterizations for both problems, obtain complexity bounds and discuss the relationship with their set semantics counterparts. Finally, we revisit both problems under a modified distribution model that takes advantage of a linear order on compute nodes and obtain tight complexity bounds.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4406421469",
    "type": "article"
  },
  {
    "title": "The Reachable Simulation Problem",
    "doi": "https://doi.org/10.1145/3723172",
    "publication_date": "2025-03-17",
    "publication_year": 2025,
    "authors": "Pierre Ganty; Nicolas Manini; Francesco Ranzato",
    "corresponding_authors": "",
    "abstract": "We investigate the problem of computing the reachable blocks of the simulation equivalence and its natural counterpart for the simulation preorder, referred to as the reachable simulation problem . Through a theoretical investigation of this problem, we unveil a sharp contrast with the already settled case of bisimulation equivalence. Then, we design algorithms to solve the reachable simulation problem by leveraging the idea of interleaving reachability and simulation computation while possibly avoiding the computation of all the reachable states or the whole simulation preorder. Specifically, we propose algorithms achieving different guarantees on the precision of the output, and a symbolic algorithm that operates on state partitions and relations between their blocks, which is particularly well-suited for processing infinite-state systems.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4408528848",
    "type": "article"
  },
  {
    "title": "Quantified Constraint Handling Rules",
    "doi": "https://doi.org/10.1145/3728640",
    "publication_date": "2025-04-08",
    "publication_year": 2025,
    "authors": "Vincent Barichard; Igor Stéphan",
    "corresponding_authors": "",
    "abstract": "In this article, the QCSP (Quantified Constraint Satisfaction Problems) framework is shifted to the QCHR (Quantified Constraint Handling Rules) framework by enabling dynamic generation of quantifiers and access to user-defined constraints. QCSP offers a natural framework to express PSPACE problems as finite two-players games. But to define a QCSP model, the alternation of quantifiers must be formerly known and cannot be built dynamically even if the worst case will not occur. To overcome this issue, the new QCHR formalism, that allows to generate quantifiers dynamically during the solving, is defined. QCHR models exhibit state-of-the-art performances on a priori fixed alternation of quantifiers and outperforms previous QCSP approaches when the generation of quantifiers is dynamic.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4409257271",
    "type": "article"
  },
  {
    "title": "On the Logical and Algebraic Aspects of Reasoning with Formal Contexts",
    "doi": "https://doi.org/10.1145/3733832",
    "publication_date": "2025-05-05",
    "publication_year": 2025,
    "authors": "Prosenjit Howlader; Churn‐Jung Liau",
    "corresponding_authors": "",
    "abstract": "A formal context consists of objects, properties, and the incidence relation between them. Various notions of concepts defined with respect to formal contexts and their associated algebraic structures have been studied extensively, including formal concepts in formal concept analysis (FCA), rough concepts arising from rough set theory (RST), and semiconcepts and protoconcepts for dealing with negation. While all these kinds of concepts are associated with lattices, semiconcepts and protoconcepts additionally yield an ordered algebraic structure, called double Boolean algebras. As the name suggests, a double Boolean algebra contains two underlying Boolean algebras. In this article, we investigate logical and algebraic aspects of the representation and reasoning about different concepts with respect to formal contexts. We first review our previous work on two-sorted modal logic systems KB and KF for the representation and reasoning of rough concepts and formal concepts, respectively. Then, in order to represent and reason about both formal and rough concepts in a single framework, these two logics are unified into a two-sorted Boolean modal logic BM , in which semiconcepts and protoconcepts are also expressible. Based on the logical representation of semiconcepts and protoconcepts, we prove the characterization of double Boolean algebras in terms of their underlying Boolean algebras. Finally, we also discuss the possibilities of extending our logical systems for the representation and reasoning of more fine-grained quantitative information in formal contexts.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4410092589",
    "type": "article"
  },
  {
    "title": "A Semantics for Modal Language Using a Rough Set Model Based on Subset Approximation Structure",
    "doi": "https://doi.org/10.1145/3750045",
    "publication_date": "2025-07-22",
    "publication_year": 2025,
    "authors": "Md. Aquil Khan; Ranjan Ranjan",
    "corresponding_authors": "",
    "abstract": "Motivated by rough set theory, we introduce a novel semantics for the basic modal language based on the possibility lower approximation operator of subset approximation structures. The study investigates axiomatization, expressiveness, and invariance results related to this semantics. From a rough set perspective, it provides a formal language for reasoning about the possibility lower approximation operator. Additionally, the axiomatization results obtained here provide characterizing properties of the operator.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4412564158",
    "type": "article"
  },
  {
    "title": "Hybrid-Dynamic Ehrenfeucht-Fraïssé Games",
    "doi": "https://doi.org/10.1145/3750046",
    "publication_date": "2025-07-22",
    "publication_year": 2025,
    "authors": "Guillermo Badía; Daniel Gâinâ; Alexander Knapp; Tomasz Kowalski; Martin Wirsing",
    "corresponding_authors": "",
    "abstract": "Ehrenfeucht-Fraïssé games provide means to characterize elementary equivalence for first-order logic, and by standard translation also for modal logics. We propose a novel generalization of Ehrenfeucht-Fraïssé games to hybrid-dynamic logics which is direct and fully modular: parameterized by the features of the hybrid language we wish to include, for instance, the modal and hybrid language operators as well as first-order existential quantification. We use these games to establish a new modular Fraïssé-Hintikka theorem for hybrid-dynamic propositional logic and its various fragments. We study the relationship between countable game equivalence (determined by countable Ehrenfeucht-Fraïssé games) and bisimulation (determined by countable back-and-forth systems). In general, the former turns out to be weaker than the latter, but under certain conditions on the language, the two coincide. As a corollary we obtain an analogue of the Hennessy-Milner theorem. We also prove that for reachable image-finite Kripke structures elementary equivalence implies isomorphism.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4412581569",
    "type": "article"
  },
  {
    "title": "Regular Representations of Uniform TC <sup>0</sup>",
    "doi": "https://doi.org/10.1145/3750044",
    "publication_date": "2025-07-22",
    "publication_year": 2025,
    "authors": "Lauri Hella; Juha Kontinen; Kerkko Luosto",
    "corresponding_authors": "",
    "abstract": "In this article we consider the interplay of generalized quantifiers and built-in relations over finite structures, in particular, in the range of logics capturing the circuit complexity classes AC 0 and TC 0 . It is well-known that for capturing AC 0 first-order logic has to be equipped with order and, e.g., predicates for addition and multiplication, whereas for TC 0 generalized quantifiers such as majority quantifiers are necessary. The sharp division between the classes AC 0 and TC 0 can be explained by the fact that AC 0 is not closed under restricting AC 0 -computable queries into simple subsequences of the input whereas TC 0 is closed under such relativization as its queries can be expressed in terms of first-order formulas using universe-independent generalized quantifiers and order as the only built-in relation. In the terminology of abstract logics, the above means that logics capturing AC 0 do not have the relativization property and hence they are not regular logics unlike the logics capturing TC 0 . This weakness of AC 0 has been also elaborated in the line of research on the Crane Beach Conjecture. The conjecture (which was refuted by Barrington, Immerman, Lautemann, Schweikardt and Thérien) was that if a language \\(L\\) has a neutral letter, then \\(L\\) can be defined in \\(\\text{FO}_{{\\mathcal{A}}}\\) , first-order logic with the collection of all numerical built-in relations \\({\\mathcal{A}}\\) , if and only if \\(L\\) can be already defined in \\(\\text{FO}_{\\leq}\\) . Our approach is two-fold. First, we study universe-independent cardinality quantifiers \\({{\\sf Q}}\\) defined by a parameter set \\(S\\subseteq\\mathbb{N}\\) and formulate a combinatorial criterion for \\(S\\) implying that all languages in \\({\\mathrm{DLOGTIME}}\\) -uniform TC 0 can be defined in \\(\\text{FO}_{\\leq}({{\\sf Q}})\\) . For instance, this criterion is satisfied if \\(S\\) is the range of some polynomial with positive integer coefficients of degree at least two. Second, by adapting the key properties of abstract logics to accommodate built-in relations, we define the regular interior \\({{\\mathcal{R}-\\text{int}}}({\\mathcal{L}})\\) (the largest regular \\({\\mathcal{L}}^{*}\\) such that \\({\\mathcal{L}}^{*}\\subseteq{\\mathcal{L}}\\) ) and regular closure \\({\\mathcal{R}-\\text{cl}}({\\mathcal{L}})\\) (the least regular \\({\\mathcal{L}}^{*}\\) such that \\({\\mathcal{L}}\\subseteq{\\mathcal{L}}^{*}\\) ) , of a logic \\({\\mathcal{L}}\\) with built-in relations, and show that the Crane Beach Conjecture can be interpreted as a statement concerning the regular interior of \\({\\mathcal{L}}\\) . By extending the results of Barrington et al., we further show that if \\({\\mathcal{B}}=\\{+\\}\\) , or \\({\\mathcal{B}}\\) contains only unary relations besides \\(\\leq\\) , then \\({{\\mathcal{R}-\\text{int}}}(\\text{FO}_{{\\mathcal{B}}})\\equiv\\text{FO}_{\\leq}\\) . In contrast, our results from the first part of the article imply that if \\({\\mathcal{B}}\\) contains \\(\\leq\\) and the range of a polynomial of degree at least two, then \\({\\mathcal{R}-\\text{cl}}(\\text{FO}_{{\\mathcal{B}}})\\) includes all languages in \\({\\mathrm{DLOGTIME}}\\) -uniform TC 0 .",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4412581598",
    "type": "article"
  },
  {
    "title": "AGM Belief Revision, Semantically",
    "doi": "https://doi.org/10.1145/3763234",
    "publication_date": "2025-08-25",
    "publication_year": 2025,
    "authors": "Faiq Miftakhul Falakh; Sebastian Rudolph; Kai Sauerwald",
    "corresponding_authors": "",
    "abstract": "We establish a generic, model-theoretic characterization of rational belief revision operators implementing the paradigm of minimal change according to the seminal work by Alchourrón, Gärdenfors, and Makinson (AGM). Our characterization applies to all Tarskian logics, that is, all logics with a classical model-theoretic semantics, and hence a wide variety of formalisms used in knowledge representation and beyond, including many for which a model-theoretic characterization has hitherto been lacking. Our starting point is the approach by Katsuno and Mendelzon (K&amp;M), who provided such a characterization for propositional logic over finite signatures. We generalize K&amp;M's approach to the setting of AGM-style revision over bases in arbitrary Tarskian logics, where base may refer to one of the various ways of representing an agent's beliefs (such as belief sets, arbitrary or finite sets of sentences, or single sentences). Our first core result is a representation theorem providing a two-way correspondence between AGM-style revision operators and specific assignments : functions associating every base to a “preference” relation over interpretations, which must be total but is – in contrast to prior approaches – not always transitive. As our second core contribution, we provide a characterization of all logics for which our result can be strengthened to assignments producing transitive preference relations (as in K&amp;M's original work). Alongside these main contributions, we discuss diverse variants of our findings as well as ramifications for other areas of belief revision theory.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413592245",
    "type": "article"
  },
  {
    "title": "A Nominal Approach to Equational Problems in Languages with Binders",
    "doi": "https://doi.org/10.1145/3767744",
    "publication_date": "2025-09-17",
    "publication_year": 2025,
    "authors": "Daniele Nantes-Sobrinho; Maribel Fernández; Deivid Vale; Maurício Ayala-Rincón",
    "corresponding_authors": "",
    "abstract": "Equational problems are fundamental in computer science, frequently arising as subproblems across diverse domains, including program analysis and learning from examples and counterexamples. This paper focuses on equational problems in languages with binding operators, formulating them within the nominal framework and referring to them as nominal equational problems (NEPs). We provide a comprehensive definition of solutions for NEPs and introduce a set of simplification rules for computing these solutions within the nominal ground term algebra. We rigorously prove that the simplification rules are sound , solution-preserving , and complete . Moreover, we establish that, under a specific strategy for rule application, the simplification process always terminates, thereby providing an effective algorithm for solving nominal equational problems. Finally, we demonstrate the practical relevance of our results by showcasing how nominal equational problems can serve as a framework for learning from examples and counterexamples. We also illustrate their applicability in addressing sufficient completeness problems, emphasising their utility in theoretical and practical contexts.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4414277250",
    "type": "article"
  },
  {
    "title": "Computing and Certifying Twin-Width Using Logic",
    "doi": "https://doi.org/10.1145/3769869",
    "publication_date": "2025-10-01",
    "publication_year": 2025,
    "authors": "André Schidler; Stefan Szeider",
    "corresponding_authors": "",
    "abstract": "Twin-width is a powerful graph invariant that supports the efficient solution of various NP-hard problems when the input graph has a bounded twin-width. First-order model checking is fixed-parameter tractable on graph classes of bounded twin-width [11]. This work introduces two algorithmic strategies for exact twin-width computation: SAT encodings and a Branch &amp; Bound approach. The SAT encodings explore distinct formulations of twin-width, enhancing performance across different instance types; the Branch &amp; Bound algorithm leverages cached partial solutions for improved efficiency on larger graphs. We propose a verification framework combining these methods and yield verifiable proofs for computed twin-width. Our research contributes conceptual insights into twin-width computation, including new contraction orderings and lower and upper bound techniques that can be of independent interest. We accompany our theoretical developments with a rigorous experimental evaluation.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4414729981",
    "type": "article"
  },
  {
    "title": "The complexity of linear temporal verification for continuous counter systems",
    "doi": "https://doi.org/10.1145/3769868",
    "publication_date": "2025-10-03",
    "publication_year": 2025,
    "authors": "Michael Blondin; Philip Offtermatt; Alex Sansfaçon-Buchanan",
    "corresponding_authors": "",
    "abstract": "Constant-rate multi-mode systems (MMS) are hybrid systems with finitely many modes and real-valued variables that evolve over continuous time according to mode-specific constant rates. Equivalently, they correspond to continuous vector addition systems (VAS), where counters may become negative. We introduce a variant of linear temporal logic (LTL) for MMS, and we investigate the complexity of the model-checking problem for syntactic fragments of LTL. We obtain a complexity trichotomy: Each fragment is either P-complete, NP-complete or undecidable. Since our logic can constrain the counters to remain non-negative, it further applies to continuous VAS. Thus, our results yield a framework for MMS and continuous VAS that generalizes and unify several existing results.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4414783286",
    "type": "article"
  },
  {
    "title": "Counting Answers to Unions of Conjunctive Queries: Natural Tractability Criteria and Meta-Complexity",
    "doi": "https://doi.org/10.1145/3771726",
    "publication_date": "2025-10-14",
    "publication_year": 2025,
    "authors": "Jacob Focke; Leslie Ann Goldberg; Marc Roth; Stanislav Živný",
    "corresponding_authors": "",
    "abstract": "We study the problem of counting answers to unions of conjunctive queries (UCQs) under structural restrictions on the input query. Concretely, given a class \\(C\\) of UCQs, the problem \\(\\#\\text{UCQ}(C)\\) provides as input a UCQ \\(\\Psi\\in C\\) and a database \\(\\mathcal{D}\\) and the problem is to compute the number of answers of \\(\\Psi\\) in \\(\\mathcal{D}\\) . Chen and Mengel [PODS’16] have shown that for any recursively enumerable class \\(C\\) , the problem \\(\\#\\text{UCQ}(C)\\) is either fixed-parameter tractable or hard for one of the parameterised complexity classes \\(\\mathrm{W}[1]\\) or \\(\\#\\mathrm{W}[1]\\) . However, their tractability criterion is unwieldy in the sense that, given any concrete class \\(C\\) of UCQs, it is not easy to determine how hard it is to count answers to queries in \\(C\\) . Moreover, given a single specific UCQ \\(\\Psi\\) , it is not easy to determine how hard it is to count answers to \\(\\Psi\\) . In this work, we address the question of finding a natural tractability criterion: The combined conjunctive query of a UCQ \\(\\Psi=\\varphi_{1}\\vee\\dots\\vee\\varphi_{\\ell}\\) is the conjunctive query \\(\\boldsymbol{\\wedge}\\left(\\Psi\\right)=\\varphi_{1}\\wedge\\dots\\wedge\\varphi_{\\ell}\\) . We show that under natural closure properties of \\(C\\) , the problem \\(\\#\\text{UCQ}(C)\\) is fixed-parameter tractable if and only if the combined conjunctive queries of UCQs in \\(C\\) , and their contracts, have bounded treewidth. A contract of a conjunctive query is an augmented structure, taking into account how the quantified variables are connected to the free variables — if all variables are free, then a conjunctive query is equal to its contract; in this special case the criterion for fixed-parameter tractability of \\(\\#\\text{UCQ}(C)\\) thus simplifies to the combined queries having bounded treewidth. Finally, we give evidence that a closure property on \\(C\\) is necessary for obtaining a natural tractability criterion: We show that even for a single UCQ \\(\\Psi\\) , the meta problem of deciding whether \\(\\#\\text{UCQ}(\\{\\Psi\\})\\) can be solved in time \\(O(|\\mathcal{D}|^{d})\\) is \\(\\mathrm{NP}\\) -hard for any fixed \\(d\\geq 1\\) . Moreover, we prove that a known exponential-time algorithm for solving the meta problem is optimal under assumptions from fine-grained complexity theory. As a corollary of our reduction, we also establish that approximating the Weisfeiler-Leman-Dimension of a UCQ is \\(\\mathrm{NP}\\) -hard.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4415157175",
    "type": "article"
  },
  {
    "title": "Counting of Teams in First-Order Team Logics",
    "doi": "https://doi.org/10.1145/3771721",
    "publication_date": "2025-10-14",
    "publication_year": 2025,
    "authors": "Anselm Haak; Juha Kontinen; Fabian L. Müller; Heribert Vollmer; Fan Yang",
    "corresponding_authors": "",
    "abstract": "We study descriptive complexity of counting complexity classes in the range from #P to \\({\\text{#}\\!\\cdot\\!\\text{NP}}\\) . The proof of Fagin’s characterization of NP by existential second-order logic generalizes to the counting setting in the following sense: The class #P can be logically described as the class of functions counting satisfying assignments to free relation variables in first-order formulae. This was first observed by Saluja et al. (1995). In this paper we extend this study to classes beyond #P and extensions of first-order logic with team semantics. These team-based logics are closely related to existential second-order logic and its fragments, hence our results also shed light on the complexity of counting for extensions of first-order logic in Tarski’s semantics. Our results show that the class \\({\\text{#}\\!\\cdot\\!\\text{NP}}\\) can be logically characterized by independence logic and existential second-order logic, whereas dependence logic and inclusion logic give rise to subclasses of \\({\\text{#}\\!\\cdot\\!\\text{NP}}\\) and #P , respectively. We further relate the class obtained from inclusion logic to the complexity class \\({\\text{TotP}} \\subseteq{\\text{#P}}\\) .",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4415157176",
    "type": "article"
  },
  {
    "title": "Dependently-Typed Higher-Order Logic",
    "doi": "https://doi.org/10.1145/3771725",
    "publication_date": "2025-10-14",
    "publication_year": 2025,
    "authors": "Colin Rothgang; Florian Rabe; Christoph Benzmüller",
    "corresponding_authors": "",
    "abstract": "Higher-order logic HOL offers a very simple syntax and semantics for knowledge representation and reasoning in various particular domains, including in particular representing and reasoning about typed data structures. But its type system lacks advanced features where types may depend on terms. Dependent type theory offers such a rich type system, but has rather substantial conceptual differences to HOL, as well as comparatively poor proof automation support. We introduce a dependently-typed extension DHOL of HOL that retains the style and conceptual framework of HOL. Moreover, we build a translation from DHOL to HOL and implement it as a preprocessor to HOL theorem provers able to parse TPTP, thereby making all such provers able to run on DHOL problems.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4415157189",
    "type": "article"
  },
  {
    "title": "Eliminating definitions and Skolem functions in first-order logic",
    "doi": "https://doi.org/10.1145/772062.772068",
    "publication_date": "2003-07-01",
    "publication_year": 2003,
    "authors": "Jeremy Avigad",
    "corresponding_authors": "Jeremy Avigad",
    "abstract": "From proofs in any classical first-order theory that proves the existence of at least two elements, one can eliminate definitions in polynomial time. From proofs in any classical first-order theory strong enough to code finite functions, including sequential theories, one can also eliminate Skolem functions in polynomial time.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W2152535604",
    "type": "article"
  },
  {
    "title": "How to optimize proof-search in modal logics",
    "doi": "https://doi.org/10.1145/371316.371511",
    "publication_date": "2001-04-01",
    "publication_year": 2001,
    "authors": "Андрей Воронков",
    "corresponding_authors": "Андрей Воронков",
    "abstract": "We present a bottom-up decision procedure for propositional modal logic K based on the inverse method. The procedure is based on the “inverted” version of a sequent calculus. To restrict the search space, we prove a number of redundancy criteria for derivations in the sequent calculus. We introduce a new technique of proving redundancy criteria, based on the analysis of tableau-based derivations in K. Moreover, another new technique is based on so-called traces . A new search with a strong notion of subsumption. This technique is based on so-called traces . A new formalization of the inverse method in the form of a path calculus considerably simplifies all proofs as compared to the previously published presentations of the inverse method. Experimental results demonstrate that our method is competitive with many state-of-the-art implementations of K.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W2177921372",
    "type": "article"
  },
  {
    "title": "A dynamic approach to characterizing termination of general logic programs",
    "doi": "https://doi.org/10.1145/937555.937556",
    "publication_date": "2003-10-01",
    "publication_year": 2003,
    "authors": "Yi-Dong Shen; Jia-Huai You; Li-Yan Yuan; Samuel S. P. Shen; Qiang Yang",
    "corresponding_authors": "",
    "abstract": "We present a new characterization of termination of general logic programs. Most existing termination analysis approaches rely on some static information about the structure of the source code of a logic program, such as modes/types, norms/level mappings, models/interargument relations, and the like. We propose a dynamic approach that employs some key dynamic features of an infinite (generalized) SLDNF-derivation, such as repetition of selected subgoals and recursive increase in term size. We also introduce a new formulation of SLDNF-trees, called generalized SLDNF-trees. Generalized SLDNF-trees deal with negative subgoals in the same way as Prolog and exist for any general logic programs.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W1976132254",
    "type": "article"
  },
  {
    "title": "Eternity variables to prove simulation of specifications",
    "doi": "https://doi.org/10.1145/1042038.1042044",
    "publication_date": "2005-01-01",
    "publication_year": 2005,
    "authors": "Wim H. Hesselink",
    "corresponding_authors": "Wim H. Hesselink",
    "abstract": "Simulations of specifications are introduced as a unification and generalization of refinement mappings, history variables, forward simulations, prophecy variables, and backward simulations. A specification implements another specification if and only if there is a simulation from the first one to the second one that satisfies a certain condition. By adding stutterings, the formalism allows that the concrete behaviors take more (or possibly less) steps than the abstract ones.Eternity variables are introduced as a more powerful alternative for prophecy variables and backward simulations. This formalism is semantically complete: every simulation that preserves quiescence is a composition of a forward simulation, an extension with eternity variables, and a refinement mapping. This result does not need finite invisible nondeterminism and machine closure as in the Abadi--Lamport Theorem. The requirement of internal continuity is weakened to preservation of quiescence.Almost all concepts are illustrated by tiny examples or counter-examples.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W1976331012",
    "type": "article"
  },
  {
    "title": "Heterogeneous temporal probabilistic agents",
    "doi": "https://doi.org/10.1145/1119439.1119444",
    "publication_date": "2006-01-01",
    "publication_year": 2006,
    "authors": "Jürgen Dix; Sarit Kraus; V. S. Subrahmanian",
    "corresponding_authors": "",
    "abstract": "To date, there has been no work on temporal probabilistic agent reasoning on top of heterogeneous legacy databases and software modules. We will define the concept of a heterogeneous temporal probabilistic (HTP) agent. Such agents can be built on top of existing databases, data structures, and software code bases without explicitly accessing the internal code of those systems and can take actions compatible with a policy or operating principles specified by an agent developer. We will develop a formal semantics for such agents through the notion of a feasible temporal probabilistic status interpretation (FTPSI for short). Intuitively, an FTPSI specifies what all an HTP agent is permitted/forbidden/obliged to do at various times t . As changes occur in the environment, the HTP agent must compute a new FTPSI. HTP agents continuously compute FTPSIs in order to determine what they should do and, hence, the problem of computing FTPSIs is very important. We give a sound and complete algorithm to compute FTPSIs for a very large class of HTP agents called strict HTP agents. In a given state, many FTPSIs may exist. These represent alternative courses of action that the HTP agent can take. We provide a notion of an optimal FTPSI that selects an FTPSI optimizing an objective function and give a sound and complete algorithm to compute an optimal FTPSI.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W1966626765",
    "type": "article"
  },
  {
    "title": "Paraconsistent reasoning and preferential entailments by signed quantified Boolean formulae",
    "doi": "https://doi.org/10.1145/1243996.1244001",
    "publication_date": "2007-07-01",
    "publication_year": 2007,
    "authors": "Ofer Arieli",
    "corresponding_authors": "Ofer Arieli",
    "abstract": "We introduce a uniform approach of representing a variety of paraconsistent nonmonotonic formalisms by quantified Boolean formulae (QBFs) in the context of multiple-valued logics. We show that this framework provides a useful platform for capturing, in a simple and natural way, a wide range of methods for preferential reasoning. The outcome is a subtle approach to represent the underlying formalisms, which induces a straightforward way to compute the corresponding entailments: By incorporating off-the-shelf QBF solvers it is possible to simulate within our framework various kinds of preferential formalisms, among which are Priest's logic LPm of reasoning with minimal inconsistency, Batens' adaptive logic ACLuNs2, Besnard and Schaub's inference relation &amp;vbar;= n , a variety of formula-preferential systems, some bilattice-based preferential relations (e.g., &amp;vbar;= I 1 and &amp;vbar;= I 2 ), and consequence relations for reasoning with graded uncertainty, such as the four-valued logic &amp;vbar;= 4 c .",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W2085846695",
    "type": "article"
  },
  {
    "title": "Guest editorial",
    "doi": "https://doi.org/10.1145/1555746.1555747",
    "publication_date": "2009-08-01",
    "publication_year": 2009,
    "authors": "Patrick Baillot; Jean-Yves Marion; Simona Ronchi Della Rocca",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2090097007",
    "type": "editorial"
  },
  {
    "title": "Weyl's predicative classical mathematics as a logic-enriched type theory",
    "doi": "https://doi.org/10.1145/1656242.1656246",
    "publication_date": "2010-01-01",
    "publication_year": 2010,
    "authors": "Robin Adams; Zhaohui Luo",
    "corresponding_authors": "",
    "abstract": "We construct a logic-enriched type theory LTT W that corresponds closely to the predicative system of foundations presented by Hermann Weyl in Das Kontinuum . We formalize many results from that book in LTT W , including Weyl's definition of the cardinality of a set and several results from real analysis, using the proof assistant Plastic that implements the logical framework LF. This case study shows how type theory can be used to represent a nonconstructive foundation for mathematics.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W2093863416",
    "type": "article"
  },
  {
    "title": "A theory of sampling for continuous-time metric temporal logic",
    "doi": "https://doi.org/10.1145/1838552.1838560",
    "publication_date": "2010-10-01",
    "publication_year": 2010,
    "authors": "Carlo A. Furia; Matteo Rossi",
    "corresponding_authors": "",
    "abstract": "This article revisits the classical notion of sampling in the setting of real-time temporal logics for the modeling and analysis of systems. The relationship between the satisfiability of metric temporal logic (MTL) formulas over continuous-time models and over discrete-time models is studied. It is shown to what extent discrete-time sequences obtained by sampling continuous-time signals capture the semantics of MTL formulas over the two time domains. The main results apply to “flat” formulas that do not nest temporal operators and can be applied to the problem of reducing the verification problem for MTL over continuous-time models to the same problem over discrete time, resulting in an automated partial practically efficient discretization technique.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W3123425189",
    "type": "article"
  },
  {
    "title": "An Implicit Characterization of PSPACE",
    "doi": "https://doi.org/10.1145/2159531.2159540",
    "publication_date": "2012-04-01",
    "publication_year": 2012,
    "authors": "Marco Gaboardi; Jean-Yves Marion; Simona Ronchi Della Rocca",
    "corresponding_authors": "",
    "abstract": "We present a type system for an extension of lambda calculus with a conditional construction, named STA B , that characterizes the PSPACE class. This system is obtained by extending STA, a type assignment for lambda-calculus inspired by Lafont’s Soft Linear Logic and characterizing the PTIME class. We extend STA by means of a ground type and terms for Booleans and conditional. The key issue in the design of the type system is to manage the contexts in the rule for conditional in an additive way. Thanks to this rule, we are able to program polynomial time Alternating Turing Machines. From the well-known result APTIME = PSPACE, it follows that STA B is complete for PSPACE. Conversely, inspired by the simulation of Alternating Turing machines by means of Deterministic Turing machine, we introduce a call-by-name evaluation machine with two memory devices in order to evaluate programs in polynomial space. As far as we know, this is the first characterization of PSPACE that is based on lambda calculus and light logics.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2146459129",
    "type": "article"
  },
  {
    "title": "The Complexity of Reasoning for Fragments of Autoepistemic Logic",
    "doi": "https://doi.org/10.1145/2159531.2159539",
    "publication_date": "2012-04-01",
    "publication_year": 2012,
    "authors": "Nadia Creignou; Arne Meier; Heribert Vollmer; Michael E. Thomas",
    "corresponding_authors": "",
    "abstract": "Autoepistemic logic extends propositional logic by the modal operator L . A formula φ that is preceded by an L is said to be “believed.” The logic was introduced by Moore in 1985 for modeling an ideally rational agent’s behavior and reasoning about his own beliefs. In this article we analyze all Boolean fragments of autoepistemic logic with respect to the computational complexity of the three most common decision problems expansion existence, brave reasoning and cautious reasoning. As a second contribution we classify the computational complexity of checking that a given set of formulae characterizes a stable expansion and that of counting the number of stable expansions of a given knowledge base. We improve the best known Δ 2 p -upper bound on the former problem to completeness for the second level of the Boolean hierarchy. To the best of our knowledge, this is the first paper analyzing counting problem for autoepistemic logic.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2404324099",
    "type": "article"
  },
  {
    "title": "Parallel Cost Analysis",
    "doi": "https://doi.org/10.1145/3274278",
    "publication_date": "2018-10-31",
    "publication_year": 2018,
    "authors": "Elvira Albert; Jesús Correas; Einar Broch Johnsen; Ka I Pun; Guillermo Román‐Díez",
    "corresponding_authors": "",
    "abstract": "This article presents parallel cost analysis , a static cost analysis targeting to over-approximate the cost of parallel execution in distributed systems. In contrast to the standard notion of serial cost , parallel cost captures the cost of synchronized tasks executing in parallel by exploiting the true concurrency available in the execution model of distributed processing. True concurrency is challenging for static cost analysis, because the parallelism between tasks needs to be soundly inferred, and the waiting and idle processor times at the different locations need to be accounted for. Parallel cost analysis works in three phases: (1) it performs a block-level analysis to estimate the serial costs of the blocks between synchronization points in the program; (2) it then constructs a distributed flow graph (DFG) to capture the parallelism, the waiting, and idle times at the locations of the distributed system; and (3) the parallel cost can finally be obtained as the path of maximal cost in the DFG. We prove the correctness of the proposed parallel cost analysis, and provide a prototype implementation to perform an experimental evaluation of the accuracy and feasibility of the proposed analysis.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2901933418",
    "type": "article"
  },
  {
    "title": "Path Categories and Propositional Identity Types",
    "doi": "https://doi.org/10.1145/3204492",
    "publication_date": "2018-04-30",
    "publication_year": 2018,
    "authors": "Benno van den Berg",
    "corresponding_authors": "Benno van den Berg",
    "abstract": "Connections between homotopy theory and type theory have recently attracted a lot of attention, with Voevodsky’s univalent foundations and the interpretation of Martin-Löf’s identity types in Quillen model categories as some of the highlights. In this article, we establish a connection between a natural weakening of Martin-Löf’s rules for the identity types that has been considered by Cohen, Coquand, Huber and Mörtberg in their work on a constructive interpretation of the univalence axiom on the one hand and the notion of a path category, a slight variation on the classic notion of a category of fibrant objects due to Brown, on the other. This involves showing that the syntactic category associated to a type theory with weak identity types carries the structure of a path category, strengthening earlier results by Avigad, Lumsdaine, and Kapulkin. In this way, we not only relate a well-known concept in homotopy theory with a natural concept in logic but also provide a framework for further developments.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2964293103",
    "type": "article"
  },
  {
    "title": "Interactive Realizers",
    "doi": "https://doi.org/10.1145/2159531.2159533",
    "publication_date": "2012-04-01",
    "publication_year": 2012,
    "authors": "Stefano Berardi; Ugo de’Liguoro",
    "corresponding_authors": "",
    "abstract": "We propose a realizability interpretation of a system for quantier free arithmetic which is equivalent to the fragment of classical arithmetic without nested quantifiers, called here EM 1 -arithmetic. We interpret classical proofs as interactive learning strategies, namely as processes going through several stages of knowledge and learning by interacting with the “nature,” represented by the standard interpretation of closed atomic formulas, and with each other. We obtain in this way a program extraction method by proof interpretation, which is faithful with respect to proofs, in the sense that it is compositional and that it does not need any translation.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W1970441061",
    "type": "article"
  },
  {
    "title": "Fair Synthesis for Asynchronous Distributed Systems",
    "doi": "https://doi.org/10.1145/2480759.2480761",
    "publication_date": "2013-06-01",
    "publication_year": 2013,
    "authors": "Paul Gastin; Nathalie Sznajder",
    "corresponding_authors": "",
    "abstract": "We study the synthesis problem in an asynchronous distributed setting: a finite set of processes interact locally with an uncontrollable environment and communicate with each other by sending signals -- actions controlled by a sender process and that are immediately received by the target process. The fair synthesis problem is to come up with a local strategy for each process such that the resulting fair behaviors of the system meet a given specification. We consider external specifications satisfying some natural closure properties related to the architecture. We present this new setting for studying the fair synthesis problem for distributed systems, and give decidability results for the subclass of networks where communications happen through a strongly connected graph. We claim that this framework for distributed synthesis is natural, convenient and avoids most of the usual sources of undecidability for the synthesis problem. Hence, it may open the way to a decidable theory of distributed synthesis.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W1970485613",
    "type": "article"
  },
  {
    "title": "Computing persistent homology within Coq/SSReflect",
    "doi": "https://doi.org/10.1145/2528929",
    "publication_date": "2013-11-01",
    "publication_year": 2013,
    "authors": "Jónathan Heras; Thierry Coquand; Anders Mörtberg; Vincent Siles",
    "corresponding_authors": "",
    "abstract": "Persistent homology is one of the most active branches of computational algebraic topology with applications in several contexts such as optical character recognition or analysis of point cloud data. In this article, we report on the formal development of certified programs to compute persistent Betti numbers , an instrumental tool of persistent homology, using the C oq proof assistant together with the SSR eflect extension. To this aim it has been necessary to formalize the underlying mathematical theory of these algorithms. This is another example showing that interactive theorem provers have reached a point where they are mature enough to tackle the formalization of nontrivial mathematical theories.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2021064762",
    "type": "article"
  },
  {
    "title": "Well-structured program equivalence is highly undecidable",
    "doi": "https://doi.org/10.1145/2287718.2287726",
    "publication_date": "2012-08-01",
    "publication_year": 2012,
    "authors": "Robert Goldblatt; Marcel Jackson",
    "corresponding_authors": "",
    "abstract": "We show that strict deterministic propositional dynamic logic with intersection is highly undecidable, solving a problem in the Stanford Encyclopedia of Philosophy. In fact we show something quite a bit stronger. We introduce the construction of program equivalence, which returns the value ⊤ precisely when two given programs are equivalent on halting computations. We show that virtually any variant of propositional dynamic logic has a Π 1 1 -hard validity problem if it can express even just the equivalence of well-structured programs with the empty program skip. We also show, in these cases, that the set of propositional statements valid over finite models is not recursively enumerable, so there is not even an axiomatization for finitely valid propositions.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2054812122",
    "type": "article"
  },
  {
    "title": "A Modular Type Reconstruction Algorithm",
    "doi": "https://doi.org/10.1145/3234693",
    "publication_date": "2018-10-31",
    "publication_year": 2018,
    "authors": "Florian Rabe",
    "corresponding_authors": "Florian Rabe",
    "abstract": "M mt is a framework for designing and implementing formal systems in a way that systematically abstracts from theoretical and practical aspects of their type of theoretical and logical foundations. Thus, definitions, theorems, and algorithms can be stated independently of the foundation, and language designers can focus on the essentials of a particular foundation and inherit a large-scale implementation from M mt at low cost. Going beyond the similarly motivated approach of meta-logical frameworks, M mt does not even commit to a particular meta-logic—that makes M mt level results harder to obtain but also more general. We present one such result: a type reconstruction algorithm that realizes the foundation-independent aspects generically relative to a set of rules that supply the foundation-specific knowledge. Maybe surprisingly, we see that the former covers most of the algorithm, including the most difficult details. Thus, we can easily instantiate our algorithm with rule sets for several important language features including, e.g., dependent function types. Moreover, our design is modular such that we obtain a type reconstruction algorithm for any combination of these features.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2903910822",
    "type": "article"
  },
  {
    "title": "Dichotomies in Ontology-Mediated Querying with the Guarded Fragment",
    "doi": "https://doi.org/10.1145/3375628",
    "publication_date": "2020-02-20",
    "publication_year": 2020,
    "authors": "André Hernich; Carsten Lutz; Fabio Papacchini; Frank Wolter",
    "corresponding_authors": "",
    "abstract": "We study ontology-mediated querying in the case where ontologies are formulated in the guarded fragment of first-order logic (GF) or extensions thereof with counting and where the actual queries are (unions of) conjunctive queries. Our aim is to classify the data complexity and Datalog rewritability of query evaluation depending on the ontology O , where query evaluation w.r.t. O is in PT ime (resp. Datalog rewritable) if all queries can be evaluated in PT ime w.r.t. O (resp. rewritten into Datalog under O ), and co NP-hard if at least one query is co NP-hard w.r.t. O . We identify several fragments of GF that enjoy a dichotomy between Datalog-rewritability (which implies PT ime ) and co NP-hardness as well as several other fragments that enjoy a dichotomy between PT ime and co NP-hardness, but for which PT ime does not imply Datalog-rewritability. For the latter, we establish and exploit a connection to constraint satisfaction problems. We also identify fragments for which there is no dichotomy between PT ime and co NP. To prove this, we establish a non-trivial variation of Ladner’s theorem on the existence of NP-intermediate problems. Finally, we study the decidability of whether a given ontology enjoys PT ime query evaluation, presenting both positive and negative results, depending on the fragment.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W3012562581",
    "type": "article"
  },
  {
    "title": "Interval vs. Point Temporal Logic Model Checking",
    "doi": "https://doi.org/10.1145/3281028",
    "publication_date": "2018-12-20",
    "publication_year": 2018,
    "authors": "Laura Bozzelli; Alberto Molinari; Angelo Montanari; Adriano Peron; Pietro Sala",
    "corresponding_authors": "",
    "abstract": "In the last years, model checking with interval temporal logics is emerging as a viable alternative to model checking with standard point-based temporal logics, such as LTL, CTL, CTL*, and the like. The behavior of the system is modeled by means of (finite) Kripke structures, as usual. However, while temporal logics which are interpreted \"point-wise\" describe how the system evolves state-by-state, and predicate properties of system states, those which are interpreted \"interval-wise\" express properties of computation stretches, spanning a sequence of states. A proposition letter is assumed to hold over a computation stretch (interval) if and only if it holds over each component state (homogeneity assumption). A natural question arises: is there any advantage in replacing points by intervals as the primary temporal entities, or is it just a matter of taste? In this paper, we study the expressiveness of Halpern and Shoham's interval temporal logic (HS) in model checking, in comparison with those of LTL, CTL, and CTL*. To this end, we consider three semantic variants of HS: the state-based one, introduced by Montanari et al., that allows time to branch both in the past and in the future, the computation-tree-based one, that allows time to branch in the future only, and the trace-based variant, that disallows time to branch. These variants are compared among themselves and to the aforementioned standard logics, getting a complete picture. In particular, we show that HS with trace-based semantics is equivalent to LTL (but at least exponentially more succinct), HS with computation-tree-based semantics is equivalent to finitary CTL*, and HS with state-based semantics is incomparable with all of them (LTL, CTL, and CTL*).",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W4288601052",
    "type": "article"
  },
  {
    "title": "Applying Visible Strong Equivalence in Answer-Set Program Transformations",
    "doi": "https://doi.org/10.1145/3412854",
    "publication_date": "2020-10-17",
    "publication_year": 2020,
    "authors": "Jori Bomanson; Tomi Janhunen; Ilkka Niemelä",
    "corresponding_authors": "",
    "abstract": "Strong equivalence is one of the basic notions of equivalence that have been proposed for logic programs subject to the answer-set semantics. In this article, we propose a new generalization of strong equivalence (SE) that takes the visibility of atoms into account and we characterize it in terms of appropriately revised SE-models. Our design resembles (relativized) strong equivalence but is substantially different due to adopting a strict one-to-one correspondence of models from the notion of visible equivalence. We additionally tailor the characterization for more convenient use with positive programs and provide formal tools to exploit the tailored version also in the case of some programs that use negation. We illustrate the use of visible strong equivalence and the characterizations in showing the correctness of program transformations that make use of atom visibility. Moreover, we present a translation that enables us to automate the task of verifying visible strong equivalence for particular fragments of answer-set programs. We experimentally study the efficiency of verification when the goal is to check whether an extended rule is visibly strongly equivalent to its normalization, i.e., a subprogram expressing the original rule in terms of normal rules only. In the process, we verify the outputs of several real implementations of normalization schemes on a considerable number of input rules.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W1539274708",
    "type": "article"
  },
  {
    "title": "Non-finite axiomatizability of dynamic topological logic",
    "doi": "https://doi.org/10.1145/2489334",
    "publication_date": "2014-02-01",
    "publication_year": 2014,
    "authors": "David Fernández–Duque",
    "corresponding_authors": "David Fernández–Duque",
    "abstract": "Dynamic topological logic (DTL) is a polymodal logic designed for reasoning about dynamic topological systems . These are pairs 〈 X , f 〉, where X is a topological space and f : X → X is continuous. DTL uses a language L which combines the topological S4 modality □ with temporal operators from linear temporal logic. Recently, we gave a sound and complete axiomatization DTL * for an extension of the logic to the language L * , where ◊ is allowed to act on finite sets of formulas and is interpreted as a tangled closure operator. No complete axiomatization is known in the language L, although one proof system, which we shall call KM, was conjectured to be complete by Kremer and Mints. In this article, we show that given any language L' such that L ⊆ L' ⊆ L * , the set of valid formulas of L' is not finitely axiomatizable. It follows, in particular, that KM is incomplete.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2036386940",
    "type": "article"
  },
  {
    "title": "Reasoning About Substructures and Games",
    "doi": "https://doi.org/10.1145/2757286",
    "publication_date": "2015-07-01",
    "publication_year": 2015,
    "authors": "Massimo Benerecetti; Fabio Mogavero; Aniello Murano",
    "corresponding_authors": "",
    "abstract": "Many decision problems in formal verification and design can be suitably formulated in game-theoretic terms. This is the case for the model checking of open and closed systems and both controller and reactive synthesis. Interpreted in this context, these problems require one to find a strategy (i.e., a plan) to force the system to fulfill some desired goal, no matter what the opponent (e.g., the environment) does. A strategy essentially constrains the possible behaviors of the system to those that are compatible with the decisions dictated by the plan itself. Therefore, finding a strategy to meet some goal basically reduces to identifying a portion of the model of interest (i.e., one of its substructures) that satisfies that goal. In this view, the ability to reason about substructures becomes a crucial aspect for several fundamental problems. In this article, we present and study a new branching-time temporal logic, called Substructure Temporal Logic (STL * for short), whose distinctive feature is to allow for quantifying over the possible substructure of a given structure. The logic is obtained by adding four new temporal-like operators to CTL *, whose interpretation is given relative to the partial order induced by a suitable substructure relation. STL * turns out to be very expressive and allows one to capture in a very natural way many well-known problems, such as module checking, reactive synthesis, and reasoning about games in a wide sense. A formal account of the model-theoretic properties of the new logic and results about (un)decidability and complexity of related decision problems are also provided.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2271301048",
    "type": "article"
  },
  {
    "title": "A Model for Phase Transition of Random Answer-Set Programs",
    "doi": "https://doi.org/10.1145/2926791",
    "publication_date": "2016-06-27",
    "publication_year": 2016,
    "authors": "Lian Wen; Kewen Wang; Yi-Dong Shen; Fangzhen Lin",
    "corresponding_authors": "",
    "abstract": "The critical behaviors of NP-complete problems have been studied extensively, and numerous results have been obtained for Boolean formula satisfiability (SAT) and constraint satisfaction (CSP), among others. However, few results are known for the critical behaviors of NP-hard nonmonotonic reasoning problems so far; in particular, a mathematical model for phase transition in nonmonotonic reasoning is still missing. In this article, we investigate the phase transition of negative two-literal logic programs under the answer-set semantics. We choose this class of logic programs since it is the simplest class for which the consistency problem of deciding if a program has an answer set is still NP-complete. We first introduce a new model, called quadratic model for generating random logic programs in this class. We then mathematically prove that the consistency problem for this class of logic programs exhibits a phase transition. Furthermore, the phase-transition follows an easy-hard-easy pattern. Given the correspondence between answer sets for negative two-literal programs and kernels for graphs, as a corollary, our result significantly generalizes de la Vega's well-known theorem for phase transition on the existence of kernels in random graphs. We also report some experimental results. Given our mathematical results, these experimental results are not really necessary. We include them here as they suggest that our phase-transition result is more general and likely holds for more general classes of logic programs.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2464591762",
    "type": "article"
  },
  {
    "title": "Taming Multirelations",
    "doi": "https://doi.org/10.1145/2964907",
    "publication_date": "2016-11-11",
    "publication_year": 2016,
    "authors": "Hitoshi Furusawa; Georg Struth",
    "corresponding_authors": "",
    "abstract": "Binary multirelations generalise binary relations by associating elements of a set to its subsets. We study the structure and algebra of multirelations under the operations of union, intersection, sequential, and parallel composition, as well as finite and infinite iteration. Starting from a set-theoretic investigation, we propose axiom systems for multirelations in contexts ranging from bi-monoids to bi-quantales.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2566427880",
    "type": "article"
  },
  {
    "title": "Primal Logic of Information",
    "doi": "https://doi.org/10.1145/3714426",
    "publication_date": "2025-01-21",
    "publication_year": 2025,
    "authors": "Yuri Gurevich; Andreas Blass",
    "corresponding_authors": "",
    "abstract": "Primal logic arose in access control; it has a remarkably efficient (linear time) decision procedure for its entailment problem. But primal logic is a general logic of information. In the realm of arbitrary items of information (infons), conjunction, disjunction, and implication may seem to correspond (set-theoretically) to union, intersection, and relative complementation. But, while infons are closed under union, they are not closed under intersection or relative complementation. It turns out that there is a systematic transformation of propositional intuitionistic calculi to the original (propositional) primal calculi; we call it Flatting. We extend Flatting to quantifier rules, obtaining arguably the right quantified primal logic, QPL. The QPL entailment problem is exponential-time complete, but it is polynomial-time complete in the case, of importance to applications (at least to access control), where the number of quantifiers is bounded.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4406671926",
    "type": "article"
  },
  {
    "title": "<scp>1-in-3</scp> vs. <scp>Not-All-Equal</scp> : Dichotomy of a broken promise",
    "doi": "https://doi.org/10.1145/3719007",
    "publication_date": "2025-02-20",
    "publication_year": 2025,
    "authors": "Lorenzo Ciardo; Marcin Kozik; Andrei Krokhin; Tamio-Vesa Nakajima; Stanislav Živný",
    "corresponding_authors": "",
    "abstract": "The 1-in-3 and Not-All-Equal satisfiability problems for Boolean CNF formulas are two well-known NP-hard problems. In contrast, the promise 1-in-3 vs. Not-All-Equal problem can be solved in polynomial time. In the present work, we investigate this constraint satisfaction problem in a regime where the promise is weakened from either side by a rainbow-free structure, and establish a complexity dichotomy for the resulting class of computational problems.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4407769948",
    "type": "article"
  },
  {
    "title": "Model and Program Repair via Group Actions and Structure Unwinding",
    "doi": "https://doi.org/10.1145/3719008",
    "publication_date": "2025-02-21",
    "publication_year": 2025,
    "authors": "Paul C. Attie; William Cocke",
    "corresponding_authors": "",
    "abstract": "Given a program \\(P\\) , one can construct a Kripke structure \\(\\mathcal{M}\\) . Model checking verifies that \\(P\\) satisfies a behavioral property given by a temporal logic formula \\(\\varphi\\) by checking that \\(\\mathcal{M}\\) models \\(\\varphi\\) . However, \\(\\mathcal{M}\\) can be exponentially large in \\(P\\) . The action of a symmetry group \\(G\\) on \\(\\mathcal{M}\\) and \\(\\varphi\\) can produce a smaller structure \\(\\overline{\\mathcal{M}}\\) . When \\(\\mathcal{M}\\) does not satisfy \\(\\varphi\\) , one can look for a substructure that satisfies \\(\\varphi\\) . We call this substructure-repair . We show that repairs of \\(\\overline{\\mathcal{M}}\\) lift to repairs of \\(\\mathcal{M}\\) , i.e., we can repair a concurrent program by repairing the smaller structure \\(\\overline{\\mathcal{M}}\\) and symmetrizing the resulting program. The substructures of \\(\\overline{\\mathcal{M}}\\) map to substructures of \\(\\mathcal{M}\\) preserved by \\(G\\) . We present relative completeness results, which give conditions under which the existence of a repair of \\(\\mathcal{M}\\) implies the existence of a repair of \\(\\overline{\\mathcal{M}}\\) . In cases where there is no repair of a Kripke structure \\(\\mathcal{M}\\) w.r.t. a formula, we show that there are instances where it is possible to ”unwind” \\(\\mathcal{M}\\) to generate a structure \\(\\mathcal{M'}\\) that is strongly bisimilar to \\(\\mathcal{M}\\) and for which a repair exists. This leads to a natural semantic notion, repairability , which is not preserved by strong bisimulation. We illustrate the combined use of symmetry reduction and unwinding to effect a repair. Finally, we provide closed-form results for the reductions in number of states in the Kripke structure that can be achieved by symmetry reduction.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4407838406",
    "type": "article"
  },
  {
    "title": "Maps Between Different Kinds of Two Level Credibility-limited Revision Operators",
    "doi": "https://doi.org/10.1145/3733830",
    "publication_date": "2025-05-05",
    "publication_year": 2025,
    "authors": "Marco Garapa; Eduardo Fermé; Maurício D. L. Reis",
    "corresponding_authors": "",
    "abstract": "Two-level credibility-limited revision is a non-prioritized revision operation. When revising through a two-level credibility-limited revision, two levels of credibility and one level of incredibility are considered. When revising by a sentence at the highest level of credibility, the operator behaves like a standard revision, if the sentence is at the second level of credibility, the revision process results in a standard contraction by the negation of that sentence. If the sentence is not credible, then the original belief set remains unchanged. In this article, we introduce a novel constructive method for two-level credibility-limited revision operators, based on a modified version of entrenchment relations. Additionally, we propose a semantics for this type of operators, based on Grove’s systems of spheres. Furthermore, we present axiomatic characterizations for the newly proposed operators.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4410089672",
    "type": "article"
  },
  {
    "title": "History-deterministic Parikh Automata",
    "doi": "https://doi.org/10.1145/3742431",
    "publication_date": "2025-06-02",
    "publication_year": 2025,
    "authors": "Enzo Erlich; Mario Grobler; Shibashis Guha; Ismaël Jecker; Karoliina Lehtinen; Martín Zimmermann",
    "corresponding_authors": "",
    "abstract": "Parikh automata extend finite automata by counters that can be tested for membership in a semilinear set, but only at the end of a run. Thereby, they preserve many of the desirable properties of finite automata. Deterministic Parikh automata are strictly weaker than nondeterministic ones, but enjoy better closure and algorithmic properties. This state of affairs motivates the study of intermediate forms of nondeterminism. Here, we investigate history-deterministic Parikh automata, i.e., automata whose nondeterminism can be resolved on the fly. This restricted form of nondeterminism is well-suited for applications which classically call for determinism, e.g., solving games and composition. We show that history-deterministic Parikh automata are strictly more expressive than deterministic ones, incomparable to unambiguous ones, and enjoy almost all of the closure properties of deterministic automata. Finally, we investigate the complexity of resolving nondeterminism in history-deterministic Parikh automata.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4410953508",
    "type": "article"
  },
  {
    "title": "Intuitionistic Gödel-Löb Without Sharps",
    "doi": "https://doi.org/10.1145/3748649",
    "publication_date": "2025-07-16",
    "publication_year": 2025,
    "authors": "Juan P. Aguilera; Leonardo Pacheco",
    "corresponding_authors": "",
    "abstract": "Das, van der Giessen, and Marin recently introduced \\(\\mathsf{IGL}\\) , an intuitionistic version of Gödel-Löb logic. Their proof systems involves ill-founded proofs with a progressiveness condition. Their completeness proof uses the principle of \\(\\Sigma^{1}_{1}\\) -determinacy; which is not provable in \\(\\mathsf{ZFC}\\) . We define a cyclic proof system for \\(\\mathsf{IGL}\\) and give a proof of its completeness theorem avoiding \\(\\Sigma^{1}_{1}\\) -determinacy.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4412476093",
    "type": "article"
  },
  {
    "title": "Substructural logic and partial correctness",
    "doi": "https://doi.org/10.1145/772062.772066",
    "publication_date": "2003-07-01",
    "publication_year": 2003,
    "authors": "Dexter Kozen; Jerzy Tiuryn",
    "corresponding_authors": "",
    "abstract": "We formulate a noncommutative sequent calculus for partial correctness that subsumes propositional Hoare Logic. Partial correctness assertions are represented by intuitionistic linear implication. We prove soundness and completeness over relational and trace models. As a corollary, we obtain a complete sequent calculus for inclusion and equivalence of regular expressions.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W2141931064",
    "type": "article"
  },
  {
    "title": "Hypothesis-based semantics of logic programs in multivalued logics",
    "doi": "https://doi.org/10.1145/1013560.1013565",
    "publication_date": "2004-07-01",
    "publication_year": 2004,
    "authors": "Yann Loyer; Nicolas Spyratos; Daniel Stamate",
    "corresponding_authors": "",
    "abstract": "We address the problem of defining semantics for logic programs in presence of incomplete and contradictory information coming from different sources. The information consists of facts that a central server collects and tries to combine using (a) a set of logical rules, that is, a logic program, and (b) a hypothesis representing the server's own estimates. In such a setting incomplete information from a source or contradictory information from different sources necessitate the use of many-valued logics in which programs can be evaluated and hypotheses can be tested. To carry out such activities we propose a formal framework based on bilattices such as Belnap's four-valued logics. In this framework we work with the class of programs defined by Fitting and we propose hypothesis-based semantics for such programs. We also establish an intuitively appealing connection between our hypothesis testing mechanism, on the one hand, and the well-founded semantics and Kripke-Kleene semantics of Datalog programs with negation, on the other hand.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W1986809845",
    "type": "article"
  },
  {
    "title": "Automatic generation of rule-based constraint solvers over finite domains",
    "doi": "https://doi.org/10.1145/976706.976707",
    "publication_date": "2004-04-01",
    "publication_year": 2004,
    "authors": "Slim Abdennadher; Christophe Rigotti",
    "corresponding_authors": "",
    "abstract": "A general approach to implement propagation and simplification of constraints consists of applying rules over these constraints. However, a difficulty that arises frequently when writing a constraint solver is to determine the constraint propagation algorithm. In this article, we propose a method for generating propagation and simplification rules for constraints over finite domains defined extensionally by, for example, a truth table or their tuples. The generation of rules is performed in two steps. First, propagation rules are generated. Propagation rules do not rewrite constraints but add new ones. Thus, the constraint store may contain superfluous constraints. Removing these constraints not only allows saving of space but also decreases the cost of constraint solving. Constraints can be removed using simplification rules. Thus, in a second step, some propagation rules are transformed into simplification rules.Furthermore, we show that our approach performs well on various examples, including Boolean constraints, multivalued logic, and Allen's qualitative approach to temporal logic. Moreover, an application taken from the field of digital circuit design shows that our approach is of practical use.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W2023005099",
    "type": "article"
  },
  {
    "title": "Optimizing optimal reduction",
    "doi": "https://doi.org/10.1145/1131313.1131315",
    "publication_date": "2006-04-01",
    "publication_year": 2006,
    "authors": "Paolo Coppola; Simone Martini",
    "corresponding_authors": "",
    "abstract": "We propose a type inference algorithm for lambda terms in elementary affine logic (EAL). The algorithm decorates the syntax tree of a simple typed lambda term and collects a set of linear constraints. The result is a parametric elementary type that can be instantiated with any solution of the set of collected constraints.We point out that the typeability of lambda terms in EAL has a practical counterpart, since it is possible to reduce any EAL-typeable lambda terms with the Lamping's abstract algorithm obtaining a substantial increase of performances.We show how to apply the same techniques to obtain decorations of intuitionistic proofs into linear logic proofs.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W2123808861",
    "type": "article"
  },
  {
    "title": "PELCR",
    "doi": "https://doi.org/10.1145/1243996.1243997",
    "publication_date": "2007-07-01",
    "publication_year": 2007,
    "authors": "Marco Pedicini; Francesco Quaglia",
    "corresponding_authors": "",
    "abstract": "In this article we present the implementation of an environment supporting Lévy's optimal reduction for the λ-calculus on parallel (or distributed) computing systems. In a similar approach to Lamping's, we base our work on a graph reduction technique, known as directed virtual reduction , which is actually a restriction of Danos-Regnier virtual reduction. The environment, which we refer to as PELCR (parallel environment for optimal lambda-calculus reduction), relies on a strategy for directed virtual reduction, namely half combustion . While developing PELCR we adopted both a message aggregation technique, allowing reduction of the communication overhead, and a fair policy for distributing dynamically originated load among processors. We also present an experimental study demonstrating the ability of PELCR to definitely exploit the parallelism intrinsic to λ-terms while performing the reduction. We show how PELCR allows achieving up to 70--80% of the ideal speedup on last generation multiprocessor computing systems. As a last note, the software modules have been developed with the C language and using a standard interface for message passing, that is, MPI, thus making PELCR itself a highly portable software package.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W1983303046",
    "type": "article"
  },
  {
    "title": "Removing propagation redundant constraints in redundant modeling",
    "doi": "https://doi.org/10.1145/1276920.1276925",
    "publication_date": "2007-08-01",
    "publication_year": 2007,
    "authors": "Chiu Wo Choi; Jimmy H. M. Lee; Peter J. Stuckey",
    "corresponding_authors": "",
    "abstract": "A widely adopted approach to solving constraint satisfaction problems combines systematic tree search with various degrees of constraint propagation for pruning the search space. One common technique to improve the execution efficiency is to add redundant constraints, which are constraints logically implied by others in the problem model. However, some redundant constraints are propagation redundant and hence do not contribute additional propagation information to the constraint solver. Redundant constraints arise naturally in the process of redundant modeling where two models of the same problem are connected and combined through channeling constraints. In this paper, we give general theorems for proving propagation redundancy of one constraint with respect to channeling constraints and constraints in the other model. We illustrate, on problems from CSPlib (http://www.csplib.org), how detecting and removing propagation redundant constraints in redundant modeling can speed up search by several order of magnitudes.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2070281006",
    "type": "article"
  },
  {
    "title": "Polymorphic type inference for the named nested relational calculus",
    "doi": "https://doi.org/10.1145/1297658.1297661",
    "publication_date": "2007-12-01",
    "publication_year": 2007,
    "authors": "Jan Van den Bussche; Stijn Vansummeren",
    "corresponding_authors": "",
    "abstract": "The named nested relational calculus is the canonical query language for the complex object database model and is equipped with a natural static type system. Given an expression in the language, without type declarations for the input variables, there is the problem of whether there are any input type declarations under which the expression is well-typed. Moreover, if there are, then which are they, and what is the corresponding output type for each of these? This problem is solved by a logic-based approach, and the decision problem is shown to be NP-complete.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W2045522022",
    "type": "article"
  },
  {
    "title": "Simultaneous checking of completeness and ground confluence for algebraic specifications",
    "doi": "https://doi.org/10.1145/1507244.1507250",
    "publication_date": "2009-04-01",
    "publication_year": 2009,
    "authors": "Adel Bouhoula",
    "corresponding_authors": "Adel Bouhoula",
    "abstract": "Algebraic specifications provide a powerful method for the specification of abstract data types in programming languages and software systems. Completeness and ground confluence are fundamental notions for building algebraic specifications in a correct and modular way. Related works for checking ground confluence are based on the completion techniques or on the test that all critical pairs between axioms are valid with respect to a sufficient criterion for ground confluence. It is generally accepted that such techniques may be very inefficient, even for very small specifications. Indeed, the completion procedure often diverges and there often exist many critical pairs of the axioms. In this article, we present a procedure for simultaneously checking completeness and ground confluence for specifications with free/nonfree constructors and parameterized specifications. If the specification is not complete or not ground confluent, then our procedure will output the set of patterns on whose ground instances a function is not defined and it can easily identify the rules that break ground confluence. In contrast to previous work, our method does not rely on completion techniques and does not require the computation of critical pairs of the axioms. The method is entirely implemented and allowed us to prove the completeness and the ground confluence of many specifications in a completely automatic way, where related techniques diverge or generate very complex proofs. Our system offers two main components: (i) a completeness and ground confluence analyzer that computes pattern trees of defined functions and may generate some proof obligations; and (ii) a procedure to prove (joinable) inductive conjectures which is used to discharge these proof obligations.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2020190447",
    "type": "article"
  },
  {
    "title": "Resource control graphs",
    "doi": "https://doi.org/10.1145/1555746.1555753",
    "publication_date": "2009-08-01",
    "publication_year": 2009,
    "authors": "Jean-Yves Moyen",
    "corresponding_authors": "Jean-Yves Moyen",
    "abstract": "Resource Control Graphs are an abstract representation of programs. Each state of the program is abstracted by its size, and each instruction is abstracted by the effects it has on the state size whenever it is executed. The abstractions of instruction effects are then used as weights on the arcs of a program's Control Flow Graph. Termination is proved by finding decreases in a well-founded order on state-size, in line with other termination analyses, resulting in proofs similar in spirit to those produced by Size Change Termination analysis. However, the size of states may also be used to measure the amount of space consumed by the program at each point of execution. This leads to an alternative characterisation of the Non Size Increasing programs, that is, of programs that can compute without allocating new memory. This new tool is able to encompass several existing analyses and similarities with other studies, suggesting that even more analyses might be expressable in this framework, thus giving hopes for a generic tool for studying programs.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2025356485",
    "type": "article"
  },
  {
    "title": "A general framework for sound and complete Floyd-Hoare logics",
    "doi": "https://doi.org/10.1145/1614431.1614438",
    "publication_date": "2009-10-01",
    "publication_year": 2009,
    "authors": "Rob Arthan; Ursula Martin; Erik A. Mathiesen; Paulo Oliva",
    "corresponding_authors": "",
    "abstract": "This article presents an abstraction of Hoare logic to traced symmetric monoidal categories, a very general framework for the theory of systems. Our abstraction is based on a traced monoidal functor from an arbitrary traced monoidal category into the category of preorders and monotone relations. We give several examples of how our theory generalizes usual Hoare logics (partial correctness of while programs, partial correctness of pointer programs), and provide some case studies on how it can be used to develop new Hoare logics (runtime analysis of while programs and stream circuits).",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2084929300",
    "type": "article"
  },
  {
    "title": "Proof search in Hájek's basic logic",
    "doi": "https://doi.org/10.1145/1352582.1352589",
    "publication_date": "2008-06-01",
    "publication_year": 2008,
    "authors": "Simone Bova; Franco Montagna",
    "corresponding_authors": "",
    "abstract": "We introduce a proof system for Hájek's logic BL based on a relational hypersequents framework. We prove that the rules of our logical calculus, called RHBL , are sound and invertible with respect to any valuation of BL into a suitable algebra, called (ω)[0,1]. Refining the notion of reduction tree that arises naturally from RHBL , we obtain a decision algorithm for BL provability whose running time upper bound is 2 O ( n ) , where n is the number of connectives of the input formula. Moreover, if a formula is unprovable, we exploit the constructiveness of a polynomial time algorithm for leaves validity for providing a procedure to build countermodels in (ω)[0, 1]. Finally, since the size of the reduction tree branches is O ( n 3 ), we can describe a polynomial time verification algorithm for BL unprovability.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2121227486",
    "type": "article"
  },
  {
    "title": "Inferring non-suspension conditions for logic programs with dynamic scheduling",
    "doi": "https://doi.org/10.1145/1352582.1352585",
    "publication_date": "2008-06-01",
    "publication_year": 2008,
    "authors": "Samir Genaim; Andy King",
    "corresponding_authors": "",
    "abstract": "A logic program consists of a logic component and a control component. The former is a specification in predicate logic whereas the latter defines the order of subgoal selection. The order of subgoal selection is often controlled with delay declarations that specify that a subgoal is to suspend until some condition on its arguments is satisfied. Reasoning about delay declarations is notoriously difficult for the programmer and it is not unusual for a program and a goal to reduce to a state that contains a subgoal that suspends indefinitely. Suspending subgoals are usually unintended and often indicate an error in the logic or the control. A number of abstract interpretation schemes have therefore been proposed for checking that a given program and goal cannot reduce to such a state. This article considers a reversal of this problem, advocating an analysis that for a given program infers a class of goals that do not lead to suspension. This article shows that this more general approach can have computational, implementational and user-interface advantages. In terms of user-interface, this approach leads to a lightweight point-and-click mode of operation in which, after directing the analyser at a file, the user merely has to inspect the results inferred by the analysis. In terms of implementation, the analysis can be straightforwardly realized as two simple fixpoint computations. In terms of computation, by modeling n ! different schedulings of n subgoals with a single Boolean function, it is possible to reason about the suspension behavior of large programs. In particular, the analysis is fast enough to be applied repeatedly within the program development cycle. The article also demonstrates that the method is precise enough to locate bugs in existing programs.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2133186235",
    "type": "article"
  },
  {
    "title": "A logical characterization of the counting hierarchy",
    "doi": "https://doi.org/10.1145/1459010.1459017",
    "publication_date": "2009-01-01",
    "publication_year": 2009,
    "authors": "Juha Kontinen",
    "corresponding_authors": "Juha Kontinen",
    "abstract": "In this article we give a logical characterization of the counting hierarchy. The counting hierarchy is the analogue of the polynomial hierarchy, the building block being Probabilistic polynomial time PP instead of NP. We show that the extension of first-order logic by second-order majority quantifiers of all arities describes exactly the problems in the counting hierarchy. We also consider extending the characterization to general proportional quantifiers Q k r interpreted as “more than an r -fraction of k -ary relations”. We show that the result holds for rational numbers of the form s /2 m but for any other 0 &lt; r &lt; 1 the corresponding logic satisfies the 0-1 law.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2085743552",
    "type": "article"
  },
  {
    "title": "Simplification Rules for Intuitionistic Propositional Tableaux",
    "doi": "https://doi.org/10.1145/2159531.2159536",
    "publication_date": "2012-04-01",
    "publication_year": 2012,
    "authors": "Mauro Ferrari; Camillo Fiorentini; Guido Fiorino",
    "corresponding_authors": "",
    "abstract": "The implementation of a logic requires, besides the definition of a calculus and a decision procedure, the development of techniques to reduce the search space. In this article we introduce some simplification rules for Intuitionistic propositional logic that try to replace a formula with an equi-satisfiable “simpler” one with the aim to reduce the search space. Our results are proved via semantical techniques based on Kripke models. We also provide an empirical evaluation of their impact on implementations.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2019841519",
    "type": "article"
  },
  {
    "title": "Topological Logics with Connectedness over Euclidean Spaces",
    "doi": "https://doi.org/10.1145/2480759.2480765",
    "publication_date": "2013-06-01",
    "publication_year": 2013,
    "authors": "Roman Kontchakov; Yavor Nenov; Ian Pratt‐Hartmann; Michael Zakharyaschev",
    "corresponding_authors": "",
    "abstract": "We consider the quantifier-free languages, Bc and Bc °, obtained by augmenting the signature of Boolean algebras with a unary predicate representing, respectively, the property of being connected, and the property of having a connected interior. These languages are interpreted over the regular closed sets of R n ( n ≥ 2) and, additionally, over the regular closed semilinear sets of R n . The resulting logics are examples of formalisms that have recently been proposed in the Artificial Intelligence literature under the rubric Qualitative Spatial Reasoning. We prove that the satisfiability problem for Bc is undecidable over the regular closed semilinear sets in all dimensions greater than 1, and that the satisfiability problem for Bc and Bc ° is undecidable over both the regular closed sets and the regular closed semilinear sets in the Euclidean plane. However, we also prove that the satisfiability problem for Bc ° is NP-complete over the regular closed sets in all dimensions greater than 2, while the corresponding problem for the regular closed semilinear sets is ExpTime -complete. Our results show, in particular, that spatial reasoning is much harder over Euclidean spaces than over arbitrary topological spaces.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2055865360",
    "type": "article"
  },
  {
    "title": "Nonuniform Boolean constraint satisfaction problems with cardinality constraint",
    "doi": "https://doi.org/10.1145/1805950.1805954",
    "publication_date": "2010-07-01",
    "publication_year": 2010,
    "authors": "Nadia Creignou; Henning Schnoor; Ilka Schnoor",
    "corresponding_authors": "",
    "abstract": "We study the computational complexity of Boolean constraint satisfaction problems with cardinality constraint. A Galois connection between clones and coclones has received a lot of attention in the context of complexity considerations for constraint satisfaction problems. This connection does not seem to help when considering constraint satisfaction problems that support in addition a cardinality constraint. We prove that a similar Galois connection, involving a weaker closure operator and partial polymorphisms, can be applied to such problems. Thus, we establish dichotomies for the decision as well as for the counting problems in Schaefer's framework.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2061768978",
    "type": "article"
  },
  {
    "title": "Some Subsystems of Constant-Depth Frege with Parity",
    "doi": "https://doi.org/10.1145/3243126",
    "publication_date": "2018-10-31",
    "publication_year": 2018,
    "authors": "Michal Garlík; Leszek Aleksander Kołodziejczyk",
    "corresponding_authors": "",
    "abstract": "We consider three relatively strong families of subsystems of AC 0 [2]-Frege proof systems, i.e., propositional proof systems using constant-depth formulas with an additional parity connective, for which exponential lower bounds on proof size are known. In order of increasing strength, the subsystems are (i) constant-depth proof systems with parity axioms and the (ii) treelike and (iii) daglike versions of systems introduced by Krajíček which we call PK c d (⊕). In a PK c d (⊕)-proof, lines are disjunctions (cedents) in which all disjuncts have depth at most d , parities can only appear as the outermost connectives of disjuncts, and all but c disjuncts contain no parity connective at all. We prove that treelike PK O (1) O (1) (⊕) is quasipolynomially but not polynomially equivalent to constant-depth systems with parity axioms. We also verify that the technique for separating parity axioms from parity connectives due to Impagliazzo and Segerlind can be adapted to give a superpolynomial separation between daglike PK O (1) O (1) (⊕) and AC 0 [2]-Frege; the technique is inherently unable to prove superquasipolynomial separations. We also study proof systems related to the system Res-Lin introduced by Itsykson and Sokolov. We prove that an extension of treelike Res-Lin is polynomially simulated by a system related to daglike PK O(1) O(1) (⊕), and obtain an exponential lower bound for this system.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2901148730",
    "type": "article"
  },
  {
    "title": "An Epistemic Strategy Logic",
    "doi": "https://doi.org/10.1145/3233769",
    "publication_date": "2018-10-31",
    "publication_year": 2018,
    "authors": "Xiaowei Huang; Ron van der Meyden",
    "corresponding_authors": "",
    "abstract": "This article presents an extension of temporal epistemic logic with operators that can express quantification over agent strategies. Unlike previous work on alternating temporal epistemic logic, the semantics works with systems whose states explicitly encode the strategy being used by each of the agents. This provides a natural way to express what agents would know were they to be aware of some of the strategies being used by other agents. A number of examples that rely on the ability to express an agent’s knowledge about the strategies being used by other agents are presented to motivate the framework, including reasoning about game-theoretic equilibria, knowledge-based programs, and information-theoretic computer security policies. Relationships to several variants of alternating temporal epistemic logic are discussed. The computational complexity of model checking the logic and several of its fragments are also characterized.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2963518579",
    "type": "article"
  },
  {
    "title": "Runtime Verification over Out-of-order Streams",
    "doi": "https://doi.org/10.1145/3355609",
    "publication_date": "2019-10-04",
    "publication_year": 2019,
    "authors": "David Basin; Felix Klaedtke; Eugen Zălinescu",
    "corresponding_authors": "",
    "abstract": "We present an approach for verifying systems at runtime. Our approach targets distributed systems whose components communicate with monitors over unreliable channels, where messages can be delayed, reordered, or even lost. Furthermore, our approach handles an expressive specification language that extends the real-time logic MTL with freeze quantifiers for reasoning about data values. The logic's main novelty is a new three-valued semantics that is well suited for runtime verification as it accounts for partial knowledge about a system's behavior. Based on this semantics, we present online algorithms that reason soundly and completely about streams where events can occur out of order. We also evaluate our algorithms experimentally. Depending on the specification, our prototype implementation scales to out-of-order streams with hundreds to thousands of events per second.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W3101270510",
    "type": "article"
  },
  {
    "title": "DL-Lite Ontology Revision Based on An Alternative Semantic Characterization",
    "doi": "https://doi.org/10.1145/2786759",
    "publication_date": "2015-08-17",
    "publication_year": 2015,
    "authors": "Zhe Wang; Kewen Wang; Rodney Topor",
    "corresponding_authors": "",
    "abstract": "Ontology engineering and maintenance require (semi-)automated ontology change operations. Intensive research has been conducted on TBox and ABox changes in description logics (DLs), and various change operators have been proposed in the literature. Existing operators largely fall into two categories: syntax-based and model-based. While each approach has its advantages and disadvantages, an important topic that has rarely been explored is how to achieve a balance between syntax-based and model-based approaches. Also, most existing operators are specially designed for either TBox change or ABox change, and cannot handle the general ontology revision task—given a DL knowledge base (KB, a pair consisting of a TBox and an ABox), how to revise it by a set of TBox and ABox axioms ( i.e. , a new DL KB). In this article, we introduce an alternative structure for DL-Lite, called a featured interpretation, and show that featured models provide a finite and tight characterization to the classical semantics of DL-Lite. A key issue for defining a change operator is the so-called expressibility, that is, whether a set of models (or featured models here) is axiomatizable in DLs. It is indeed much easier to obtain expressibility results for featured models than for classical DL models. As a result, the new semantics determined by featured models provides a method for defining and studying various changes of DL-Lite KBs that involve both TBoxes and ABoxes. To demonstrate the usefulness of the new semantic characterization in ontology change, we define two revision operators for DL-Lite KBs using featured models and study their properties. In particular, we show that our two operators both satisfy AGM postulates. We show that the complexity of our revisions is Π P 2 -complete, that is, on the same level as major revision operators in propositional logic, which further justifies the feasibility of our revision approach for DL-Lite. Also, we develop algorithms for these DL-Lite revisions.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W1971230887",
    "type": "article"
  },
  {
    "title": "Computing Loops with at Most One External Support Rule",
    "doi": "https://doi.org/10.1145/2422085.2422088",
    "publication_date": "2013-02-01",
    "publication_year": 2013,
    "authors": "Xiaoping Chen; Jianmin Ji; Fangzhen Lin",
    "corresponding_authors": "",
    "abstract": "A consequence of a logic program under answer set semantics is one that is true for all answer sets. This article considers using loop formulas to compute some of these consequences in order to increase the efficiency of answer set solvers. Since computing loop formulas are in general intractable, we consider only loops with either no external support or at most one external support, as their loop formulas are either unit or binary clauses. We show that for disjunctive logic programs, loop formulas of loops with no external support can be computed in polynomial time, and that an iterative procedure using unit propagation on these formulas and the program completion computes the well-founded models in the case of normal logic programs and the least fixed point of a simplification operator used by DLV for disjunctive logic programs. For loops with at most one external support, their loop formulas can be computed in polynomial time for normal logic programs, but are NP-hard for disjunctive programs. So for normal logic programs, we have a procedure similar to the iterative one for loops without any external support, but for disjunctive logic programs, we present a polynomial approximation algorithm. All these algorithms have been implemented, and our experiments show that for certain logic programs, the consequences computed by our algorithms can significantly speed up current ASP solvers cmodels, clasp, and DLV.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2006653030",
    "type": "article"
  },
  {
    "title": "Propositional Update Operators Based on Formula/Literal Dependence",
    "doi": "https://doi.org/10.1145/2499937.2499945",
    "publication_date": "2013-08-01",
    "publication_year": 2013,
    "authors": "Andreas Herzig; Jérôme Lang; Pierre Marquis",
    "corresponding_authors": "",
    "abstract": "We present and study a general family of belief update operators in a propositional setting. Its operators are based on formula/ literal dependence, which is more fine-grained than the notion of formula/ variable dependence that was proposed in the literature: formula/variable dependence is a particular case of formula/literal dependence. Our update operators are defined according to the “forget-then-conjoin” scheme: updating a belief base by an input formula consists in first forgetting in the base every literal on which the input formula has a negative influence, and then conjoining the resulting base with the input formula. The operators of our family differ by the underlying notion of formula/literal dependence, which may be defined syntactically or semantically, and which may or may not exploit further information like known persistent literals and pre-set dependencies. We argue that this allows to handle the frame problem and the ramification problem in a more appropriate way. We evaluate the update operators of our family w.r.t. two important dimensions: the logical dimension, by checking the status of the Katsuno-Mendelzon postulates for update, and the computational dimension, by identifying the complexity of a number of decision problems (including model checking, consistency and inference), both in the general case and in some restricted cases, as well as by studying compactability issues. It follows that several operators of our family are interesting alternatives to previous belief update operators.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2046433310",
    "type": "article"
  },
  {
    "title": "Calculus of cooperation and game-based reasoning about protocol privacy",
    "doi": "https://doi.org/10.1145/2287718.2287722",
    "publication_date": "2012-08-01",
    "publication_year": 2012,
    "authors": "Sara Miner More; Pavel Naumov",
    "corresponding_authors": "",
    "abstract": "The article introduces a new formal system, the calculus of cooperation, for reasoning about coalitions of players in a certain class of games. The calculus is an extension of the propositional intuitionistic logic that adds a coalition parameter to intuitionistic implication. The system is shown to be sound and complete with respect to a game semantics. One intended application of the calculus of cooperation is the verification of privacy properties in multiparty computation protocols. The article argues that such properties can be established by providing a set of strategies for a non-zero-sum, perfect information game based on the protocol. It concludes with several examples of such verifications formalized in the calculus of cooperation.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2094647900",
    "type": "article"
  },
  {
    "title": "Terminating Evaluation of Logic Programs with Finite Three-Valued Models",
    "doi": "https://doi.org/10.1145/2629337",
    "publication_date": "2014-08-01",
    "publication_year": 2014,
    "authors": "Fabrizio Riguzzi; Terrance Swift",
    "corresponding_authors": "",
    "abstract": "As evaluation methods for logic programs have become more sophisticated, the classes of programs for which termination can be guaranteed have expanded. From the perspective of ar set programs that include function symbols, recent work has identified classes for which grounding routines can terminate either on the entire program [Calimeri et al. 2008] or on suitable queries [Baselice et al. 2009]. From the perspective of tabling, it has long been known that a tabling technique called subgoal abstraction provides good termination properties for definite programs [Tamaki and Sato 1986], and this result was recently extended to stratified programs via the class of bounded term-size programs [Riguzzi and Swift 2013]. In this article, we provide a formal definition of tabling with subgoal abstraction resulting in the SLG SA algorithm. Moreover, we discuss a declarative characterization of the queries and programs for which SLG SA terminates. We call this class strongly bounded term-size programs and show its equivalence to programs with finite well-founded models. For normal programs, strongly bounded term-size programs strictly includes the finitely ground programs of Calimeri et al. [2008]. SLG SA has an asymptotic complexity on strongly bounded term-size programs equal to the best known and produces a residual program that can be sent to an answer set programming system. Finally, we describe the implementation of subgoal abstraction within the SLG-WAM of XSB and provide performance results.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2108205915",
    "type": "article"
  },
  {
    "title": "Why Is It Hard to Obtain a Dichotomy for Consistent Query Answering?",
    "doi": "https://doi.org/10.1145/2699912",
    "publication_date": "2015-03-01",
    "publication_year": 2015,
    "authors": "Gaëlle Fontaine",
    "corresponding_authors": "Gaëlle Fontaine",
    "abstract": "A database may for various reasons become inconsistent with respect to a given set of integrity constraints. In the late 1990s, the formal approach of consistent query answering was proposed in order to query such databases. Since then, a lot of efforts have been spent to classify the complexity of consistent query answering under various classes of constraints. It is known that for the most common constraints and queries, the problem is in coNP and might be coNP-hard, yet several relevant tractable classes have been identified. Additionally, the results that emerged suggested that given a set of key constraints and a conjunctive query, the problem of consistent query answering is either in PTime or is coNP-complete. However, despite all the work, as of today this dichotomy remains a conjecture. The main contribution of this article is to explain why it appears so difficult to obtain a dichotomy result in the setting of consistent query answering. Namely, we prove that such a dichotomy with respect to common classes of constraints and queries is harder to achieve than a dichotomy for the constraint satisfaction problem, which is a famous open problem since the 1990s.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2164496990",
    "type": "article"
  },
  {
    "title": "Fuzzy Equilibrium Logic",
    "doi": "https://doi.org/10.1145/2362355.2362361",
    "publication_date": "2012-10-01",
    "publication_year": 2012,
    "authors": "Steven Schockaert; Jeroen Janssen; Dirk Vermeir",
    "corresponding_authors": "",
    "abstract": "In this article, we introduce fuzzy equilibrium logic as a generalization of both Pearce equilibrium logic and fuzzy answer set programming. The resulting framework combines the capability of equilibrium logic to declaratively specify search problems, with the capability of fuzzy logics to model continuous domains. We show that our fuzzy equilibrium logic is a proper generalization of both Pearce equilibrium logic and fuzzy answer set programming, and we locate the computational complexity of the main reasoning tasks at the second level of the polynomial hierarchy. We then provide a reduction from the problem of finding fuzzy equilibrium logic models to the problem of solving a particular bilevel mixed integer program (biMIP), allowing us to implement reasoners by reusing existing work from the operations research community. To illustrate the usefulness of our framework from a theoretical perspective, we show that a well-known characterization of strong equivalence in Pearce equilibrium logic generalizes to our setting, yielding a practical method to verify whether two fuzzy answer set programs are strongly equivalent. Finally, to illustrate its application potential, we show how fuzzy equilibrium logic can be used to find strong Nash equilibria, even when players have a continuum of strategies at their disposal. As a second application example, we show how to find abductive explanations from Łukasiewicz logic theories.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2168050647",
    "type": "article"
  },
  {
    "title": "Layer Systems for Proving Confluence",
    "doi": "https://doi.org/10.1145/2710017",
    "publication_date": "2015-03-09",
    "publication_year": 2015,
    "authors": "Bertram Felgenhauer; Aart Middeldorp; Harald Zankl; Vincent van Oostrom",
    "corresponding_authors": "",
    "abstract": "We introduce layer systems for proving generalizations of the modularity of confluence for first-order rewrite systems. Layer systems specify how terms can be divided into layers. We establish structural conditions on those systems that imply confluence. Our abstract framework covers known results like modularity, many-sorted persistence, layer-preservation, and currying. We present a counterexample to an extension of persistence to order-sorted rewriting and derive new sufficient conditions for the extension to hold. All our proofs are constructive.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2176474378",
    "type": "article"
  },
  {
    "title": "Equations, Contractions, and Unique Solutions",
    "doi": "https://doi.org/10.1145/2971339",
    "publication_date": "2017-01-31",
    "publication_year": 2017,
    "authors": "Davide Sangiorgi",
    "corresponding_authors": "Davide Sangiorgi",
    "abstract": "One of the most studied behavioural equivalences is bisimilarity. Its success is much due to the associated bisimulation proof method, which can be further enhanced by means of “bisimulation up-to” techniques such as “up-to context.” A different proof method is discussed, based on a unique solution of special forms of inequations called contractions and inspired by Milner’s theorem on unique solution of equations. The method is as powerful as the bisimulation proof method and its “up-to context” enhancements. The definition of contraction can be transferred onto other behavioural equivalences, possibly contextual and non-coinductive. This enables a coinductive reasoning style on such equivalences, either by applying the method based on unique solution of contractions or by injecting appropriate contraction preorders into the bisimulation game. The techniques are illustrated in CCS-like languages; an example dealing with higher-order languages is also shown.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2603068949",
    "type": "article"
  },
  {
    "title": "Graph Logics with Rational Relations",
    "doi": "https://doi.org/10.1145/3070822",
    "publication_date": "2017-04-30",
    "publication_year": 2017,
    "authors": "Pablo Barceló; Pablo Muñoz",
    "corresponding_authors": "",
    "abstract": "Graph databases make use of logics that combine traditional first-order features with navigation on paths, in the same way logics for model checking do. However, modern applications of graph databases impose a new requirement on the expressiveness of the logics: they need comparing labels of paths based on word relations (such as prefix, subword, or subsequence). This has led to the study of logics that extend basic graph languages with features for comparing labels of paths based on regular relations or the strictly more powerful rational relations. The evaluation problem for the former logic is decidable (and even tractable in data complexity), but already extending this logic with such a common rational relation as subword or suffix makes evaluation undecidable. In practice, however, it is rare to have the need for such powerful logics. Therefore, it is more realistic to study the complexity of less expressive logics that still allow comparing paths based on practically motivated rational relations. Here we concentrate on the most basic languages, which extend graph pattern logics with path comparisons based only on suffix, subword, or subsequence. We pinpoint the complexity of evaluation for each one of these logics, which shows that all of them are decidable in elementary time (P space or NE xptime ). Furthermore, the extension with suffix is even tractable in data complexity (but the other two are not). In order to obtain our results we establish a link between the evaluation problem for graph logics and two important problems in word combinatorics: word equations with regular constraints and longest common subsequence.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2613188923",
    "type": "article"
  },
  {
    "title": "Modal Resolution",
    "doi": "https://doi.org/10.1145/3331448",
    "publication_date": "2019-08-13",
    "publication_year": 2019,
    "authors": "Cláudia Nalon; Clare Dixon; Ullrich Hustadt",
    "corresponding_authors": "",
    "abstract": "Resolution-based provers for multimodal normal logics require pruning of the search space for a proof to ameliorate the inherent intractability of the satisfiability problem for such logics. We present a clausal modal-layered hyper-resolution calculus for the basic multimodal logic, which divides the clause set according to the modal level at which clauses occur to reduce the number of possible inferences. We show that the calculus is complete for the logics being considered. We also show that the calculus can be combined with other strategies. In particular, we discuss the completeness of combining modal layering with negative and ordered resolution and provide experimental results comparing the different refinements.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2968764582",
    "type": "article"
  },
  {
    "title": "Slanted Canonicity of Analytic Inductive Inequalities",
    "doi": "https://doi.org/10.1145/3460973",
    "publication_date": "2021-07-30",
    "publication_year": 2021,
    "authors": "Laurent De Rudder; Alessandra Palmigiano",
    "corresponding_authors": "",
    "abstract": "We prove an algebraic canonicity theorem for normal LE-logics of arbitrary signature, in a generalized setting in which the non-lattice connectives are interpreted as operations mapping tuples of elements of the given lattice to closed or open elements of its canonical extension. Interestingly, the syntactic shape of LE-inequalities which guarantees their canonicity in this generalized setting turns out to coincide with the syntactic shape of analytic inductive inequalities , which guarantees LE-inequalities to be equivalently captured by analytic structural rules of a proper display calculus. We show that this canonicity result connects and strengthens a number of recent canonicity results in two different areas: subordination algebras, and transfer results via Gödel-McKinsey-Tarski translations.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W3183790100",
    "type": "article"
  },
  {
    "title": "Formalizing Negotiations Using Logic Programming",
    "doi": "https://doi.org/10.1145/2526270",
    "publication_date": "2014-04-01",
    "publication_year": 2014,
    "authors": "Tran Cao Son; Enrico Pontelli; Ngoc-Hieu Nguyen; Chiaki Sakama",
    "corresponding_authors": "",
    "abstract": "The article introduces a logical framework for negotiation among dishonest agents. The framework relies on the use of abductive logic programming as a knowledge representation language for agents to deal with incomplete information and preferences. The article shows how intentionally false or inaccurate information of agents can be encoded in the agents' knowledge bases. Such disinformation can be effectively used in the process of negotiation to have desired outcomes by agents. The negotiation processes are formulated under the answer set semantics of abductive logic programming, and they enable the exploration of various strategies that agents can employ in their negotiation. A preliminary implementation has been developed using the ASP-Prolog platform.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2063104863",
    "type": "article"
  },
  {
    "title": "The Equivalence of the Torus and the Product of Two Circles in Homotopy Type Theory",
    "doi": "https://doi.org/10.1145/2992783",
    "publication_date": "2016-11-03",
    "publication_year": 2016,
    "authors": "Kristina Sojakova",
    "corresponding_authors": "Kristina Sojakova",
    "abstract": "Homotopy type theory is a new branch of mathematics that merges insights from abstract homotopy theory and higher category theory with those of logic and type theory. It allows us to represent a variety of mathematical objects as basic type-theoretic construction, higher inductive types. We present a proof that in homotopy type theory, the torus is equivalent to the product of two circles. This result indicates that the synthetic definition of torus as a higher inductive type is indeed correct.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2220627548",
    "type": "article"
  },
  {
    "title": "Belief Merging within Fragments of Propositional Logic",
    "doi": "https://doi.org/10.1145/2898436",
    "publication_date": "2016-04-11",
    "publication_year": 2016,
    "authors": "Nadia Creignou; Odile Papini; Stefan Rümmele; Stefan Woltran",
    "corresponding_authors": "",
    "abstract": "Recently, belief change within the framework of fragments of propositional logic has gained increasing attention. Previous research focused on belief contraction and belief revision on the Horn fragment. However, the problem of belief merging within fragments of propositional logic has been mostly neglected so far. We present a general approach to defining new merging operators derived from existing ones such that the result of merging remains in the fragment under consideration. Our approach is not limited to the case of Horn fragment; it is applicable to any fragment of propositional logic characterized by a closure property on the sets of models of its formulæ. We study the logical properties of the proposed operators regarding satisfaction of merging postulates, considering, in particular, distance-based merging operators for Horn and Krom fragments.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2327787835",
    "type": "article"
  },
  {
    "title": "Invariant Checking for SMT-based Systems with Quantifiers",
    "doi": "https://doi.org/10.1145/3686153",
    "publication_date": "2024-08-03",
    "publication_year": 2024,
    "authors": "Gianluca Redondi; Alessandro Cimatti; Alberto Griggio; Kenneth L. McMillan",
    "corresponding_authors": "",
    "abstract": "This article addresses the problem of checking invariant properties for a large class of symbolic transition systems defined by a combination of SMT theories and quantifiers. State variables can be functions from an uninterpreted sort (finite but unbounded) to an interpreted sort, such as the integers under the theory of linear arithmetic. This formalism is very expressive and can be used for modeling parameterized systems, array-manipulating programs, and more. We propose two algorithms for finding universal inductive invariants for such systems. The first algorithm combines an IC3-style loop with a form of implicit predicate abstraction to construct an invariant in an incremental manner. The second algorithm constructs an under-approximation of the original problem and searches for a formula which is an inductive invariant for this case; then, the invariant is generalized to the original case and checked with a portfolio of techniques. We have implemented the two algorithms and conducted an extensive experimental evaluation, considering various benchmarks and different tools from the literature. As far as we know, our method is the first capable of handling in a large class of systems in a uniform way. The experiment shows that both algorithms are competitive with the state of the art.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4401288959",
    "type": "article"
  },
  {
    "title": "The Iteration Number of the Weisfeiler-Leman Algorithm",
    "doi": "https://doi.org/10.1145/3708891",
    "publication_date": "2024-12-20",
    "publication_year": 2024,
    "authors": "Martin Grohe; Moritz Lichter; Daniel Neuen",
    "corresponding_authors": "",
    "abstract": "We prove new upper and lower bounds on the number of iterations the \\(k\\) -dimensional Weisfeiler-Leman algorithm ( \\(k\\) -WL) requires until stabilization. For \\(k\\geq 3\\) , we show that \\(k\\) -WL stabilizes after at most \\(O(kn^{k-1}\\log n)\\) iterations (where \\(n\\) denotes the number of vertices of the input structures), obtaining the first improvement over the trivial upper bound of \\(n^{k}-1\\) and extending a previous upper bound of \\(O(n\\log n)\\) for \\(k=2\\) [Lichter et al., LICS 2019]. We complement our upper bounds by constructing \\(k\\) -ary relational structures on which \\(k\\) -WL requires at least \\(n^{\\Omega(k)}\\) iterations to stabilize. This improves over a previous lower bound of \\(n^{\\Omega(k/\\log k)}\\) [Berkholz, Nordström, LICS 2016]. We also investigate tradeoffs between the dimension and the iteration number of WL, and show that \\(d\\) -WL, where \\(d=\\lceil\\frac{3(k+1)}{2}\\rceil\\) , can simulate the \\(k\\) -WL algorithm using only \\(O(k^{2}\\cdot n^{\\lfloor k/2\\rfloor+1}\\log n)\\) many iterations, but still requires at least \\(n^{\\Omega(k)}\\) iterations for any \\(d\\) (that is sufficiently smaller than \\(n\\) ). The number of iterations required by \\(k\\) -WL to distinguish two structures corresponds to the quantifier rank of a sentence distinguishing them in the \\((k+1)\\) -variable fragment \\(\\mathsf{C}_{k+1}\\) of first-order logic with counting quantifiers. Hence, our results also imply new upper and lower bounds on the quantifier rank required in the logic \\(\\mathsf{C}_{k+1}\\) , as well as tradeoffs between variable number and quantifier rank.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4405644022",
    "type": "article"
  },
  {
    "title": "Proof-complexity results for nonmonotonic reasoning",
    "doi": "https://doi.org/10.1145/377978.377987",
    "publication_date": "2001-07-01",
    "publication_year": 2001,
    "authors": "Uwe Egly; Hans Tompits",
    "corresponding_authors": "",
    "abstract": "It is well-known that almost all nonmonotonic formalisms have a higher worst-case complexity than classical reasoning. In some sense, this observation denies one of the original motivations of nonmonotonic systems, which was the expectation taht nonmonotonic rules should help to speed-up the reasoning process, and not make it more difficult. In this paper, we look at this issue from a proof-theoretical perspective. We consider analytic calculi for certain nonmonotonic logis and analyze to what extent the presence of nonmonotonic rules can simplify the search for proofs. In particular, we show that there are classes of first-order formulae which have only extremely long “classical” proofs, i.e., proofs without applications of nonmonotonic rules, but there are short proofs using nonmonotonic inferences. Hence,despite the increase of complexity in the worst case, there are instances where nonmonotonic reasoning can be much simpler than classical (cut-free) reasoning.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W2044169892",
    "type": "article"
  },
  {
    "title": "Compilability and compact representations of revision of Horn knowledge bases",
    "doi": "https://doi.org/10.1145/343369.343391",
    "publication_date": "2000-07-01",
    "publication_year": 2000,
    "authors": "Paolo Liberatore",
    "corresponding_authors": "Paolo Liberatore",
    "abstract": "Several methods have been proposed as an attempt to deal with dynamically changing scenarios. From a computational point of view, different formalisms have different computational properties. In this article we consider knowledge bases represented as sets of Horn clauses. The importance of this case is twofold: first, inference is polynomial, thus tractable; second, Horn clauses represents causal relations between facts, thus they are of great practical importance, although not all propositional knowledge bases can be represented in Horn form. The complexity of Horn revision is still high, and in some cases coincides with the complexity of the general (non-Horn) case. We analyze the complexity of belief revision from the point of view of the compilation [Cadoli et al. 1999]: we study the possibility of reducing the complexity by allowing a (possibly expensive) preprocessing of part of the input of the problem. Extending the work of Cadoli et al.[1996], we consider the problem of compact representation of revision in the Horn case, i.e., given a knowledge base T and an update P (both represented by Horn clauses) decide whether T * P , the result of the revision, can be represented with a propositional formula whose size is polynomial in the size of T and P . We give this representation for all formalisms for which it exists, and we show that the existence of a compact representation is related to the possibility of decreasing the complexity of a formalism via a proprocessing.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W2055240122",
    "type": "article"
  },
  {
    "title": "A complete characterization of complete intersection-type preorders",
    "doi": "https://doi.org/10.1145/601775.601780",
    "publication_date": "2003-01-01",
    "publication_year": 2003,
    "authors": "Mariangiola Dezani-Ciancaglini; Furio Honsell; Fabio Alessi",
    "corresponding_authors": "",
    "abstract": "We characterize those type preorders which yield complete intersection-type assignment systems for λ-calculi, with respect to the three canonical set-theoretical semantics for intersection-types: the inference semantics, the simple semantics, and the F-semantics. These semantics arise by taking as interpretation of types subsets of applicative structures, as interpretation of the preorder relation , ≤, set-theoretic inclusion, as interpretation of the intersection constructor , ∩, set-theoretic intersection, and by taking the interpretation of the arrow constructor , → à la Scott, with respect to either any possible functionality set , or the largest one, or the least one.These results strengthen and generalize significantly all earlier results in the literature, to our knowledge, in at least three respects. First of all the inference semantics had not been considered before. Second, the characterizations are all given just in terms of simple closure conditions on the preorder relation , ≤, on the types, rather than on the typing judgments themselves. The task of checking the condition is made therefore considerably more tractable. Last, we do not restrict attention just to λ-models, but to arbitrary applicative structures which admit an interpretation function. Thus we allow also for the treatment of models of restricted λ-calculi. Nevertheless the characterizations we give can be tailored just to the case of λ-models.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W2023743160",
    "type": "article"
  },
  {
    "title": "Interaction between path and type constraints",
    "doi": "https://doi.org/10.1145/937555.937560",
    "publication_date": "2003-10-01",
    "publication_year": 2003,
    "authors": "Peter Buneman; Wenfei Fan; Scott Weinstein",
    "corresponding_authors": "",
    "abstract": "Path constraints are capable of expressing inclusion and inverse relationships and have proved useful in modeling and querying semistructured data [Abiteboul and Vianu 1999; Buneman et al. 2000]. Types also constrain the structure of data and are commonly found in traditional databases. There has also been work on imposing structure or a type system on semistructured data for storing and querying semistructured data in a traditional database system [Alon et al. 2001; Deutsch et al. 1999a; Florescu and Kossmann 1999; Shanmugasundaram et al. 1999]. One wants to know whether complexity results for reasoning about path constraints established in the untyped (semistructured) context could carry over to traditional databases, and vice versa. It is therefore appropriate to understand the interaction between types and path constraints. In addition, XML [Bray et al. 1998], which may involve both an optional schema (e.g., DTDs or XML Schema [Thompson et al. 2001]) and integrity constraints, highlights the importance of the study of the interaction.This article investigates that interaction. In particular it studies constraint implication problems, which are important both in understanding the semantics of type/constraint systems and in query optimization. It shows that path constraints interact with types in a highly intricate way. For that purpose a number of results on path constraint implication are established in the presence and absence of type systems. These results demonstrate that adding a type system may in some cases simplify reasoning about path constraints and in other cases make it harder. For example, it is shown that there is a path constraint implication problem that is decidable in PTIME in the untyped context, but that becomes undecidable when a type system is added. On the other hand, there is an implication problem that is undecidable in the untyped context, but becomes not only decidable in cubic time but also finitely axiomatizable when a type system is imposed.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W2046407079",
    "type": "article"
  },
  {
    "title": "A decomposition-based implementation of search strategies",
    "doi": "https://doi.org/10.1145/976706.976714",
    "publication_date": "2004-04-01",
    "publication_year": 2004,
    "authors": "Laurent Michel; Pascal Van Hentenryck",
    "corresponding_authors": "",
    "abstract": "Search strategies, that is, strategies that describe how to explore search trees, have raised much interest for constraint satisfaction in recent years. In particular, limited discrepancy search and its variations have been shown to achieve significant improvements in efficiency over depth-first search for some classes of applications.This article reconsiders the implementation of discrepancy search, and of search strategies in general, for applications where the search procedure is dynamic, randomized, and/or generates global cuts (or nogoods) that apply to the remaining search. It illustrates that recomputation-based implementations of discrepancy search are not robust with respect to these extensions and require special care which may increase the memory requirements significantly and destroy the genericity of the implementation.To remedy these limitations, the article proposes a novel implementation scheme based on problem decomposition, which combines the efficiency of the recomputation-based implementations with the robustness of traditional iterative implementations. Experimental results on job-shop scheduling problems illustrate the potential of this new implementation scheme, which, surprisingly, may significantly outperform recomputation-based schemes.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W2084964364",
    "type": "article"
  },
  {
    "title": "Logical definability and query languages over ranked and unranked trees",
    "doi": "https://doi.org/10.1145/1227839.1227843",
    "publication_date": "2007-04-01",
    "publication_year": 2007,
    "authors": "Michael Benedikt; Leonid Libkin; Frank Neven",
    "corresponding_authors": "",
    "abstract": "We study relations on trees defined by first-order constraints over a vocabulary that includes the tree extension relation T ≺ T ′ (holding if and only if every branch of T extends to a branch of T ′), unary node-tests, and a binary relation checking whether the domains of two trees are equal. We consider both ranked and unranked trees. These are trees with and without a restriction on the number of children of nodes. We adopt the model-theoretic approach to tree relations and study relations definable over the structure consisting of the set of all trees and the aforementioned predicates. We relate definability of sets and relations of trees to computability by tree automata. We show that some natural restrictions correspond to familiar logics in the more classical setting where every tree is a structure over a fixed vocabulary, and to logics studied in the context of XML pattern languages. We then look at relational calculi over collections of trees, and obtain quantifier-restriction results that give us bounds on the expressive power and complexity. As unrestricted relational calculi can express problems that are complete for each level of the polynomial hierarchy, we look at their restrictions, corresponding to the restricted logics over the family of all unranked trees, and find several calculi with low (NC 1 ) data complexity which still express properties important for database and document applications. We also give normal forms for safe queries in the calculus.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2044842674",
    "type": "article"
  },
  {
    "title": "Complexity results for security protocols with Diffie-Hellman exponentiation and commuting public key encryption",
    "doi": "https://doi.org/10.1145/1380572.1380573",
    "publication_date": "2008-08-01",
    "publication_year": 2008,
    "authors": "Yannick Chevalier; Ralf Küsters; Michaël Rusinowitch; Mathieu Turuani",
    "corresponding_authors": "",
    "abstract": "We show that the insecurity problem for protocols with modular exponentiation and arbitrary products allowed in exponents is NP-complete. This result is based on a protocol and intruder model which is powerful enough to uncover known attacks on the Authenticated Group Diffie-Hellman (A-GDH.2) protocol suite. To prove our results, we develop a general framework in which the Dolev-Yao intruder is extended by generic intruder rules. This framework is also applied to obtain complexity results for protocols with commuting public key encryption.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W1980456975",
    "type": "article"
  },
  {
    "title": "A new function algebra of EXPTIME functions by safe nested recursion",
    "doi": "https://doi.org/10.1145/1555746.1555748",
    "publication_date": "2009-08-01",
    "publication_year": 2009,
    "authors": "Toshiyasu Arai; Naohi Eguchi",
    "corresponding_authors": "",
    "abstract": "Bellantoni and Cook have given a function-algebra characterization of the polynomial-time computable functions via an unbounded recursion scheme which is called safe recursion. Inspired by their work, we characterize the exponential-time computable functions with the use of a safe variant of nested recursion.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2091393031",
    "type": "article"
  },
  {
    "title": "Extending the loop language with higher-order procedural variables",
    "doi": "https://doi.org/10.1145/1555746.1555750",
    "publication_date": "2009-08-01",
    "publication_year": 2009,
    "authors": "Tristan Crolard; Emmanuel Polonowski; Pierre Valarcher",
    "corresponding_authors": "",
    "abstract": "We extend Meyer and Ritchie's Loop language with higher-order procedures and procedural variables and we show that the resulting programming language (called Loop ω ) is a natural imperative counterpart of Gödel System T. The argument is two-fold: (1) we define a translation of the Loop ω language into System T and we prove that this translation actually provides a lock-step simulation, (2) using a converse translation, we show that Loop ω is expressive enough to encode any term of System T. Moreover, we define the “iteration rank” of a Loop ω program, which corresponds to the classical notion of “recursion rank” in System T, and we show that both translations preserve ranks. Two applications of these results in the area of implicit complexity are described.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2138934928",
    "type": "article"
  },
  {
    "title": "The formal system λδ",
    "doi": "https://doi.org/10.1145/1614431.1614436",
    "publication_date": "2009-10-01",
    "publication_year": 2009,
    "authors": "Ferruccio Guidi",
    "corresponding_authors": "Ferruccio Guidi",
    "abstract": "The formal system λδ is a typed λ-calculus that pursues the unification of terms, types, environments, and contexts as the main goal. λδ takes some features from the Automath-related λ-calculi and some from the pure type systems, but differs from both in that it does not include the Π construction while it provides for an abbreviation mechanism at the level of terms. λδ enjoys some important desirable properties such as the confluence of reduction, the correctness of types, the uniqueness of types up to conversion, the subject reduction of the type assignment, the strong normalization of the typed terms, and, as a corollary, the decidability of type inference problem.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2012542922",
    "type": "article"
  },
  {
    "title": "Permissive-nominal logic",
    "doi": "https://doi.org/10.1145/2287718.2287720",
    "publication_date": "2012-08-01",
    "publication_year": 2012,
    "authors": "Gilles Dowek; Murdoch J. Gabbay",
    "corresponding_authors": "",
    "abstract": "Permissive-Nominal Logic (PNL) is an extension of first-order predicate logic in which term-formers can bind names in their arguments. This allows for direct axiomatizations with binders, such as of the λ-binder of the lambda-calculus or the ∀-binder of first-order logic. It also allows us to finitely axiomatize arithmetic, and similarly to axiomatize “nominal” datatypes-with-binding. Just like first- and higher-order logic, equality reasoning is not necessary to α-rename. This gives PNL much of the expressive power of higher-order logic, but models and derivations of PNL are first-order in character, and the logic seems to strike a good balance between expressivity and simplicity.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2086167281",
    "type": "article"
  },
  {
    "title": "Finite Satisfiability of the Two-Variable Guarded Fragment with Transitive Guards and Related Variants",
    "doi": "https://doi.org/10.1145/3174805",
    "publication_date": "2018-02-09",
    "publication_year": 2018,
    "authors": "Emanuel Kieroński; Lidia Tendera",
    "corresponding_authors": "",
    "abstract": "We consider extensions of the two-variable guarded fragment, GF 2 , where distinguished binary predicates that occur only in guards are required to be interpreted in a special way (as transitive relations, equivalence relations, preorders, or partial orders). We prove that the only fragment that retains the finite (exponential) model property is GF 2 with equivalence guards without equality. For remaining fragments, we show that the size of a minimal finite model is at most doubly exponential. To obtain the result, we invent a strategy of building finite models that are formed from a number of multidimensional grids placed over a cylindrical surface. The construction yields a 2-NE xp T ime upper bound on the complexity of the finite satisfiability problem for these fragments. We improve the bounds and obtain optimal ones for all the fragments considered, in particular NE xp T ime for GF 2 with equivalence guards, and 2-E xp T ime for GF 2 with transitive guards . To obtain our results, we essentially use some results from integer programming.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2571435091",
    "type": "article"
  },
  {
    "title": "A Hoare Logic for GPU Kernels",
    "doi": "https://doi.org/10.1145/3001834",
    "publication_date": "2017-01-31",
    "publication_year": 2017,
    "authors": "Kensuke Kojima; Atsushi Igarashi",
    "corresponding_authors": "",
    "abstract": "We study a Hoare Logic to reason about parallel programs executed on graphics processing units (GPUs), called GPU kernels. During the execution of GPU kernels, multiple threads execute in lockstep, that is, execute the same instruction simultaneously. When the control branches, the two branches are executed sequentially, but during the execution of each branch only those threads that take it are enabled; after the control converges, all the threads are enabled and again execute in lockstep. In this article, we first consider a semantics in which all threads execute in lockstep (this semantics simplifies the actual execution model of GPUs) and adapt Hoare Logic to this setting by augmenting the usual Hoare triples with an additional component representing the set of enabled threads. It is determined that the soundness and relative completeness of the logic do not hold for all programs; a difficulty arises from the fact that one thread can invalidate the loop termination condition of another thread through shared memory. We overcome this difficulty by identifying an appropriate class of programs for which the soundness and relative completeness hold. Additionally, we discuss thread interleaving, which is present in the actual execution of GPUs but not in the lockstep semantics mentioned above. We show that if a program is race free, then the lockstep and interleaving semantics produce the same result. This implies that our logic is sound and relatively complete for race-free programs, even if the thread interleaving is taken into account.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2592143801",
    "type": "article"
  },
  {
    "title": "An Automatic Proving Approach to Parameterized Verification",
    "doi": "https://doi.org/10.1145/3232164",
    "publication_date": "2018-10-31",
    "publication_year": 2018,
    "authors": "Yongjian Li; Kaiqiang Duan; David N. Jansen; Jun Pang; Lijun Zhang; Yi Lv; Shaowei Cai",
    "corresponding_authors": "",
    "abstract": "Formal verification of parameterized protocols such as cache coherence protocols is a significant challenge. In this article, we propose an automatic proving approach and its prototype paraVerifier to handle this challenge within a unified framework as follows: (1) To prove the correctness of a parameterized protocol, our approach automatically discovers auxiliary invariants and the corresponding dependency relations among the discovered invariants and protocol rules from a small instance of the to-be-verified protocol, and (2) the discovered invariants and dependency graph are then automatically generalized into a parameterized form and sent to the theorem prover, Isabelle. As a side product, the final verification result of a protocol is provided by a formal and human-readable proof. Our approach has been successfully applied to a number of benchmarks, including snoopying-based and directory-based cache coherence protocols.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2902518441",
    "type": "article"
  },
  {
    "title": "Central Limit Model Checking",
    "doi": "https://doi.org/10.1145/3331452",
    "publication_date": "2019-07-16",
    "publication_year": 2019,
    "authors": "Luca Bortolussi; Luca Cardelli; Marta Kwiatkowska; Luca Laurenti",
    "corresponding_authors": "",
    "abstract": "We consider probabilistic model checking for continuous-time Markov chains (CTMCs) induced from Stochastic Reaction Networks against a fragment of Continuous Stochastic Logic (CSL) extended with reward operators. Classical numerical algorithms for CSL model checking based on uniformisation are limited to finite CTMCs and suffer from exponential growth of the state space with respect to the number of species. However, approximate techniques such as mean-field approximations and simulations combined with statistical inference are more scalable but can be time-consuming and do not support the full expressiveness of CSL. In this article, we employ a continuous-space approximation of the CTMC in terms of a Gaussian process based on the Central Limit Approximation, also known as the Linear Noise Approximation, whose solution requires solving a number of differential equations that is quadratic in the number of species and independent of the population size. We then develop efficient and scalable approximate model checking algorithms on the resulting Gaussian process, where we restrict the target regions for probabilistic reachability to convex polytopes. This allows us to derive an abstraction in terms of a time-inhomogeneous discrete-time Markov chain (DTMC), whose dimension is independent of the number of species, on which model checking is performed. Using results from probability theory, we prove the convergence in distribution of our algorithms to the corresponding measures on the original CTMC. We implement the techniques and, on a set of examples, demonstrate that they allow us to overcome the state space explosion problem, while still correctly characterizing the stochastic behaviour of the system. Our methods can be used for formal analysis of a wide range of distributed stochastic systems, including biochemical systems, sensor networks, and population protocols.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2963762038",
    "type": "article"
  },
  {
    "title": "Idempotent Anti-unification",
    "doi": "https://doi.org/10.1145/3359060",
    "publication_date": "2019-11-02",
    "publication_year": 2019,
    "authors": "David M. Cerna; Temur Kutsia",
    "corresponding_authors": "",
    "abstract": "In this article, we address two problems related to idempotent anti-unification. First, we show that there exists an anti-unification problem with a single idempotent symbol that has an infinite minimal complete set of generalizations. It means that anti-unification with a single idempotent symbol has infinitary or nullary generalization type, similar to anti-unification with two idempotent symbols, shown earlier by Loïc Pottier. Next, we develop an algorithm that takes an arbitrary idempotent anti-unification problem and computes a representation of its solution set in the form of a regular tree grammar. The algorithm does not depend on the number of idempotent function symbols in the input terms. The language generated by the grammar is the minimal complete set of generalizations of the given anti-unification problem, which implies that idempotent anti-unification is infinitary.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2988302838",
    "type": "article"
  },
  {
    "title": "Adding Successor",
    "doi": "https://doi.org/10.1145/3356339",
    "publication_date": "2019-11-17",
    "publication_year": 2019,
    "authors": "Thomas Place; Marc Zeitoun",
    "corresponding_authors": "",
    "abstract": "Given a class C of word languages, the C -separation problem asks for an algorithm that, given as input two regular languages, decides whether there exists a third language in C containing the first language, while being disjoint from the second. Separation is usually investigated as a means to obtain a deep understanding of the class C . In this article, we are mainly interested in classes defined by logical formalisms. Such classes are often built on top of each other: given some logic, one builds a stronger one by adding new predicates to its signature. A natural construction is to enrich a logic with the successor relation. In this article, we present a transfer result applying to this construction: We show that for suitable logically defined classes, separation for the logic enriched with the successor relation reduces to separation for the original logic. Our theorem also applies to a problem that is stronger than separation: covering. Moreover, we actually present two reductions: one for languages of finite words and the other for languages of infinite words.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2988492552",
    "type": "article"
  },
  {
    "title": "Non-well-founded Proof Theory of Transitive Closure Logic",
    "doi": "https://doi.org/10.1145/3404889",
    "publication_date": "2020-08-11",
    "publication_year": 2020,
    "authors": "Liron Cohen; Reuben N. S. Rowe",
    "corresponding_authors": "",
    "abstract": "Supporting inductive reasoning is an essential component is any framework of use in computer science. To do so, the logical framework must extend that of first-order logic. Transitive closure logic is a known extension of first-order logic that is particularly straightforward to automate. While other extensions of first-order logic with inductive definitions are a priori parametrized by a set of inductive definitions, the addition of a single transitive closure operator has the advantage of uniformly capturing all finitary inductive definitions. To further improve the reasoning techniques for transitive closure logic, we here present an infinitary proof system for it, which is an infinite descent –style counterpart to the existing (explicit induction) proof system for the logic. We show that the infinitary system is complete for the standard semantics and subsumes the explicit system. Moreover, the uniformity of the transitive closure operator allows semantically meaningful complete restrictions to be defined using simple syntactic criteria. Consequently, the restriction to regular infinitary (i.e., cyclic ) proofs provides the basis for an effective system for automating inductive reasoning.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W3092732582",
    "type": "article"
  },
  {
    "title": "Action Logic is Undecidable",
    "doi": "https://doi.org/10.1145/3445810",
    "publication_date": "2021-04-30",
    "publication_year": 2021,
    "authors": "Stepan Kuznetsov",
    "corresponding_authors": "Stepan Kuznetsov",
    "abstract": "Action logic is the algebraic logic (inequational theory) of residuated Kleene lattices. One of the operations of this logic is the Kleene star, which is axiomatized by an induction scheme. For a stronger system that uses an <?TeX $\\omega$?> -rule instead (infinitary action logic), Buszkowski and Palka (2007) proved <?TeX $\\Pi _1^0$?> -completeness (thus, undecidability). Decidability of action logic itself was an open question, raised by Kozen in 1994. In this article, we show that it is undecidable, more precisely, <?TeX $\\Sigma _1^0$?> -complete. We also prove the same undecidability results for all recursively enumerable logics between action logic and infinitary action logic, for fragments of these logics with only one of the two lattice (additive) connectives, and for action logic extended with the law of distributivity.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W3162960536",
    "type": "article"
  },
  {
    "title": "Łukasiewicz Games",
    "doi": "https://doi.org/10.1145/2783436",
    "publication_date": "2015-09-15",
    "publication_year": 2015,
    "authors": "Enrico Marchioni; Michael Wooldridge",
    "corresponding_authors": "",
    "abstract": "Boolean games provide a simple, compact, and theoretically attractive abstract model for studying multiagent interactions in settings where players will act strategically in an attempt to achieve individual goals. A standard critique of Boolean games, however, is that the strictly dichotomous nature of the preference relations induced by Boolean goals inevitably trivialises the nature of such strategic interactions: a player is assumed to be indifferent between all outcomes that satisfy her goal, and indifferent between all outcomes that do not satisfy her goal. While various proposals have been made to overcome this limitation, many of these proposals require the inclusion of nonlogical structures into games to capture nondichotomous preferences. In this article, we introduce Łukasiewicz games, which overcome this limitation by allowing goals to be specified using Łukasiewicz logics . By expressing goals as formulae of Łukasiewicz logics, we can express a much richer class of utility functions for players than is possible using classical Boolean logic: we can express every continuous piecewise linear polynomial function with rational coefficients over [0, 1] n as well as their finite-valued restrictions over {0, 1/ k , …, ( k − 1)/ k , 1} n . We thus obtain a representation of nondichotomous preference structures within a purely logical framework. After introducing the formal framework of Łukasiewicz games, we present a number of detailed worked examples to illustrate the framework, and then investigate some of their theoretical properties. In particular, we present a logical characterisation of the existence of Nash equilibria in finite and infinite Łukasiewicz games. We conclude by briefly discussing issues of computational complexity.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W1975822154",
    "type": "article"
  },
  {
    "title": "Pebble Weighted Automata and Weighted Logics",
    "doi": "https://doi.org/10.1145/2579819",
    "publication_date": "2014-04-01",
    "publication_year": 2014,
    "authors": "Benedikt Bollig; Paul Gastin; Benjamin Monmege; Marc Zeitoun",
    "corresponding_authors": "",
    "abstract": "We introduce new classes of weighted automata on words. Equipped with pebbles, they go beyond the class of recognizable formal power series: they capture weighted first-order logic enriched with a quantitative version of transitive closure. In contrast to previous work, this calculus allows for unrestricted use of existential and universal quantifications over positions of the input word. We actually consider both two-way and one-way pebble weighted automata. The latter class constrains the head of the automaton to walk left-to-right, resetting it each time a pebble is dropped. Such automata have already been considered in the Boolean setting, in the context of data words. Our main result states that two-way pebble weighted automata, one-way pebble weighted automata, and our weighted logic are expressively equivalent. We also give new logical characterizations of standard recognizable series.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2072929390",
    "type": "article"
  },
  {
    "title": "Belief Merging by Examples",
    "doi": "https://doi.org/10.1145/2818645",
    "publication_date": "2015-12-06",
    "publication_year": 2015,
    "authors": "Paolo Liberatore",
    "corresponding_authors": "Paolo Liberatore",
    "abstract": "A common assumption in belief revision is that the reliability of the information sources is either given, derived from temporal information, or the same for all. This article does not describe a new semantics for integration but studies the problem of obtaining the reliability of the sources given the result of a previous merging. As an example, corrections performed manually on the result of merging some databases may indicate that the relative reliability of their sources is different from what was previously assumed, helping subsequent data mergings.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2293884587",
    "type": "article"
  },
  {
    "title": "Undecidable Propositional Bimodal Logics and One-Variable First-Order Linear Temporal Logics with Counting",
    "doi": "https://doi.org/10.1145/2757285",
    "publication_date": "2015-07-01",
    "publication_year": 2015,
    "authors": "Christopher Hampson; Agi Kurucz",
    "corresponding_authors": "",
    "abstract": "First-order temporal logics are notorious for their bad computational behaviour. It is known that even the two-variable monadic fragment is highly undecidable over various linear timelines, and over branching time even one-variable fragments might be undecidable. However, there have been several attempts on finding well-behaved fragments of first-order temporal logics and related temporal description logics, mostly either by restricting the available quantifier patterns, or considering sub-Boolean languages. Here we analyse seemingly `mild' extensions of decidable one-variable fragments with counting capabilities, interpreted in models with constant, decreasing, and expanding first-order domains. We show that over most classes of linear orders these logics are (sometimes highly) undecidable, even without constant and function symbols, and with the sole temporal operator `eventually'. We establish connections with bimodal logics over 2D product structures having linear and `difference' (inequality) component relations, and prove our results in this bimodal setting. We show a general result saying that satisfiability over many classes of bimodal models with commuting linear and difference relations is undecidable. As a by-product, we also obtain new examples of finitely axiomatisable but Kripke incomplete bimodal logics. Our results generalise similar lower bounds on bimodal logics over products of two linear relations, and our proof methods are quite different from the proofs of these results. Unlike previous proofs that first `diagonally encode' an infinite grid, and then use reductions of tiling or Turing machine problems, here we make direct use of the grid-like structure of product frames and obtain undecidability by reductions of counter (Minsky) machine problems.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W3123793150",
    "type": "article"
  },
  {
    "title": "Logics with Multiteam Semantics",
    "doi": "https://doi.org/10.1145/3487579",
    "publication_date": "2022-01-14",
    "publication_year": 2022,
    "authors": "Erich Grädel; Richard Wilke",
    "corresponding_authors": "",
    "abstract": "Team semantics is the mathematical basis of modern logics of dependence and independence. In contrast to classical Tarski semantics, a formula is evaluated not for a single assignment of values to the free variables, but on a set of such assignments, called a team. Team semantics is appropriate for a purely logical understanding of dependency notions, where only the presence or absence of data matters, but being based on sets, it does not take into account multiple occurrences of data values. It is therefore insufficient in scenarios where such multiplicities matter, in particular for reasoning about probabilities and statistical independencies. Therefore, an extension from teams to multiteams (i.e. multisets of assignments) has been proposed by several authors. In this paper we aim at a systematic development of logics of dependence and independence based on multiteam semantics. We study atomic dependency properties of finite multiteams and discuss the appropriate meaning of logical operators to extend the atomic dependencies to full-fledged logics for reasoning about dependence properties in a multiteam setting. We explore properties and expressive power of a wide spectrum of different multiteam logics and compare them to second-order logic and to logics with team semantics. In many cases the results resemble what is known in team semantics, but there are also interesting differences. While in team semantics, the combination of inclusion and exclusion dependencies leads to a logic with the full power of both independence logic and existential second-order logic, independence properties of multiteams are not definable by any combination of properties that are downwards closed or union closed and thus are strictly more powerful than inclusion-exclusion logic. We also study the relationship of logics with multiteam semantics with existential second-order logic for a specific class of metafinite structures. It turns out that inclusion-exclusion logic can be characterised in a precise sense by the Presburger fragment of this logic, but for capturing independence, we need to go beyond it and add some form of multiplication. Finally, we also consider multiteams with weights in the reals and study the expressive power of formulae by means of topological properties.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W4206099430",
    "type": "article"
  },
  {
    "title": "Reasoning about evolving nonmonotonic knowledge bases",
    "doi": "https://doi.org/10.1145/1055686.1055693",
    "publication_date": "2005-04-01",
    "publication_year": 2005,
    "authors": "Thomas Eiter; Michael Fink; Giuliana Sabbatini; Hans Tompits",
    "corresponding_authors": "",
    "abstract": "Recently, several approaches to updating knowledge bases modeled as extended logic programs have been introduced, ranging from basic methods to incorporate (sequences of) sets of rules into a logic program, to more elaborate methods which use an update policy for specifying how updates must be incorporated. In this article, we introduce a framework for reasoning about evolving knowledge bases, which are represented as extended logic programs and maintained by an update policy. We first describe a formal model which captures various update approaches, and we define a logical language for expressing properties of evolving knowledge bases. We then investigate semantical and computational properties of our framework, where we focus on properties of knowledge states with respect to the canonical reasoning task of whether a given formula holds in a given evolving knowledge base. In particular, we present finitary characterizations of the evolution for certain classes of framework instances, which can be exploited for obtaining decidability results. In more detail, we characterize the complexity of reasoning for some meaningful classes of evolving knowledge bases, ranging from polynomial to double exponential space complexity.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2024598493",
    "type": "article"
  },
  {
    "title": "Pure pointer programs with iteration",
    "doi": "https://doi.org/10.1145/1805950.1805956",
    "publication_date": "2010-07-01",
    "publication_year": 2010,
    "authors": "Martin Hofmann; Ulrich Schöpp",
    "corresponding_authors": "",
    "abstract": "Many logspace algorithms are naturally described as programs that operate on a structured input (e.g., a graph), that store in memory only a constant number of pointers (e.g., to graph nodes) and that do not use pointer arithmetic. Such “pure pointer algorithms” thus are a useful abstraction for studying the nature of logspace-computation. In this article, we introduce a formal class purple of pure pointer programs and study them on locally ordered graphs. Existing classes of pointer algorithms, such as Jumping Automata on Graphs (jags) or Deterministic Transitive Closure (dtc) logic, often exclude simple programs. purple subsumes these classes and allows for a natural representation of many graph algorithms that access the input graph using a constant number of pure pointers. It does so by providing a primitive for iterating an algorithm over all nodes of the input graph in an unspecified order. Since pointers are given as an abstract data type rather than as binary digits we expect that logarithmic-size worktapes cannot be encoded using pointers as is done, for example, in totally ordered dtc-logic. We show that this is indeed the case by proving that the property “the number of nodes is a power of two,” which is in logspace, is not representable in purple.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W1987174090",
    "type": "article"
  },
  {
    "title": "A tight Karp-Lipton collapse result in bounded arithmetic",
    "doi": "https://doi.org/10.1145/1805950.1805952",
    "publication_date": "2010-07-01",
    "publication_year": 2010,
    "authors": "Olaf Beyersdorff; Sebastian Müller",
    "corresponding_authors": "",
    "abstract": "Cook and Krajíček have recently obtained the following Karp-Lipton collapse result in bounded arithmetic: if the theory PV proves NP⊆ P/ poly , then the polynomial hierarchy collapses to the Boolean hierarchy, and this collapse is provable in PV . Here we show the converse implication, thus answering an open question posed by Cook and Krajíček. We obtain this result by formalizing in PV a hard/easy argument of Buhrman et al. [2003]. In addition, we continue the investigation of propositional proof systems using advice, initiated by Cook and Krajíček. In particular, we obtain several optimality results for proof systems using advice. We further show that these optimal systems are equivalent to natural extensions of Frege systems.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W1989692246",
    "type": "article"
  },
  {
    "title": "Algorithmic analysis of array-accessing programs",
    "doi": "https://doi.org/10.1145/2287718.2287727",
    "publication_date": "2012-08-01",
    "publication_year": 2012,
    "authors": "Rajeev Alur; Pavol Černý; Scott Weinstein",
    "corresponding_authors": "",
    "abstract": "For programs whose data variables range over Boolean or finite domains, program verification is decidable, and this forms the basis of recent tools for software model checking. In this article, we consider algorithmic verification of programs that use Boolean variables, and in addition, access a single read-only array whose length is potentially unbounded, and whose elements range over an unbounded data domain. We show that the reachability problem, while undecidable in general, is (1) Pspace-complete for programs in which the array-accessing for-loops are not nested, (2) decidable for a restricted class of programs with doubly nested loops. The second result establishes connections to automata and logics defining languages over data words.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2011432313",
    "type": "article"
  },
  {
    "title": "Constraint satisfaction tractability from semi-lattice operations on infinite sets",
    "doi": "https://doi.org/10.1145/2528933",
    "publication_date": "2013-11-01",
    "publication_year": 2013,
    "authors": "Manuel Bodirsky; Dugald Macpherson; Johan Thapper",
    "corresponding_authors": "",
    "abstract": "A famous result by Jeavons, Cohen, and Gyssens shows that every Constraint Satisfaction Problem (CSP) where the constraints are preserved by a semi-lattice operation can be solved in polynomial time. This is one of the basic facts for the so-called universal algebraic approach to a systematic theory of tractability and hardness in finite domain constraint satisfaction. Not surprisingly, the theorem of Jeavons et al. fails for arbitrary infinite domain CSPs. Many CSPs of practical interest, though, and in particular those CSPs that are motivated by qualitative reasoning calculi from artificial intelligence, can be formulated with constraint languages that are rather well-behaved from a model-theoretic point of view. In particular, the automorphism group of these constraint languages tends to be large in the sense that the number of orbits of n -subsets of the automorphism group is bounded by some function in n . In this article we present a generalization of the theorem by Jeavons et al. to infinite domain CSPs where the number of orbits of n -subsets grows subexponentially in n , and prove that preservation under a semi-lattice operation for such CSPs implies polynomial-time tractability. Unlike the result of Jeavons et al., this includes CSPs that cannot be solved by Datalog.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2072543642",
    "type": "article"
  },
  {
    "title": "Nested Weighted Automata",
    "doi": "https://doi.org/10.1145/3152769",
    "publication_date": "2017-10-31",
    "publication_year": 2017,
    "authors": "Krishnendu Chatterjee; Thomas A. Henzinger; Jan Otop",
    "corresponding_authors": "",
    "abstract": "Recently there has been a significant effort to handle quantitative properties in formal verification and synthesis. While weighted automata over finite and infinite words provide a natural and flexible framework to express quantitative properties, perhaps surprisingly, some basic system properties such as average response time cannot be expressed using weighted automata or in any other known decidable formalism. In this work, we introduce nested weighted automata as a natural extension of weighted automata, which makes it possible to express important quantitative properties such as average response time. In nested weighted automata, a master automaton spins off and collects results from weighted slave automata, each of which computes a quantity along a finite portion of an infinite word. Nested weighted automata can be viewed as the quantitative analogue of monitor automata, which are used in runtime verification. We establish an almost-complete decidability picture for the basic decision problems about nested weighted automata and illustrate their applicability in several domains. In particular, nested weighted automata can be used to decide average response time properties.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2771837048",
    "type": "article"
  },
  {
    "title": "A SAT Approach to Branchwidth",
    "doi": "https://doi.org/10.1145/3326159",
    "publication_date": "2019-05-31",
    "publication_year": 2019,
    "authors": "Neha Lodha; Sebastian Ordyniak; Stefan Szeider",
    "corresponding_authors": "",
    "abstract": "Branch decomposition is a prominent method for structurally decomposing a graph, a hypergraph, or a propositional formula in conjunctive normal form. The width of a branch decomposition provides a measure of how well the object is decomposed. For many applications, it is crucial to computing a branch decomposition whose width is as small as possible. We propose an approach based on Boolean Satisfiability (SAT) to finding branch decompositions of small width. The core of our approach is an efficient SAT encoding that determines with a single SAT-call whether a given hypergraph admits a branch decomposition of a certain width. For our encoding, we propose a natural partition-based characterization of branch decompositions. The encoding size imposes a limit on the size of the given hypergraph. To break through this barrier and to scale the SAT approach to larger instances, we develop a new heuristic approach where the SAT encoding is used to locally improve a given candidate decomposition until a fixed-point is reached. This new SAT-based local improvement method scales now to instances with several thousands of vertices and edges.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2948605263",
    "type": "article"
  },
  {
    "title": "Interaction Graphs",
    "doi": "https://doi.org/10.1145/3226594",
    "publication_date": "2018-07-31",
    "publication_year": 2018,
    "authors": "Thomas Seiller",
    "corresponding_authors": "Thomas Seiller",
    "abstract": "This article exhibits a series of semantic characterisations of sublinear nondeterministic complexity classes. These results fall into the general domain of logic-based approaches to complexity theory and so-called implicit computational complexity ( icc ), i.e., descriptions of complexity classes without reference to specific machine models. In particular, it relates strongly to icc results based on linear logic, since the semantic framework considered stems from work on the latter. Moreover, the obtained characterisations are of a geometric nature: each class is characterised by a specific action of a group by measure-preserving maps.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2962736508",
    "type": "article"
  },
  {
    "title": "Incomplete SMT Techniques for Solving Non-Linear Formulas over the Integers",
    "doi": "https://doi.org/10.1145/3340923",
    "publication_date": "2019-08-17",
    "publication_year": 2019,
    "authors": "Cristina Borralleras; Daniel Larraz; Enric Rodríguez-Carbonell; Albert Oliveras; Albert Rubio",
    "corresponding_authors": "",
    "abstract": "We present new methods for solving the Satisfiability Modulo Theories problem over the theory of Quantifier-Free Non-linear Integer Arithmetic, SMT(QF-NIA), which consists of deciding the satisfiability of ground formulas with integer polynomial constraints. Following previous work, we propose to solve SMT(QF-NIA) instances by reducing them to linear arithmetic: non-linear monomials are linearized by abstracting them with fresh variables and by performing case splitting on integer variables with finite domain. For variables that do not have a finite domain, we can artificially introduce one by imposing a lower and an upper bound and iteratively enlarge it until a solution is found (or the procedure times out). The key for the success of the approach is to determine, at each iteration, which domains have to be enlarged. Previously, unsatisfiable cores were used to identify the domains to be changed, but no clue was obtained as to how large the new domains should be. Here, we explain two novel ways to guide this process by analyzing solutions to optimization problems: (i) to minimize the number of violated artificial domain bounds, solved via a Max-SMT solver, and (ii) to minimize the distance with respect to the artificial domains, solved via an Optimization Modulo Theories (OMT) solver. Using this SMT-based optimization technology allows smoothly extending the method to also solve Max-SMT problems over non-linear integer arithmetic. Finally, we leverage the resulting Max-SMT(QF-NIA) techniques to solve ∃ ∀ formulas in a fragment of quantified non-linear arithmetic that appears commonly in verification and synthesis applications.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2969580900",
    "type": "article"
  },
  {
    "title": "Inputs and Outputs in CSP",
    "doi": "https://doi.org/10.1145/3379508",
    "publication_date": "2020-05-18",
    "publication_year": 2020,
    "authors": "Ana Cavalcanti; Robert M. Hierons; Sidney Nogueira",
    "corresponding_authors": "",
    "abstract": "This article addresses refinement and testing based on CSP models, when we distinguish input and output events. In a testing experiment, the tester (or the environment) controls the inputs, and the system under test controls the outputs. The standard models and refinement relations of CSP, however, do not differentiate inputs and outputs and are not, therefore, entirely suitable for testing. Here, we consider an alphabet of events partitioned into inputs and outputs, and we present a novel refusal-testing model for CSP with a notion of input-output refusal-traces refinement. We compare that with the ioco relation often used in testing, and we find that it is more widely applicable and stronger. This means that mistakes found using traditional ioco testing do indicate mistakes in the development. Finally, we provide a CSP testing theory that takes into account inputs and outputs. With our theory, it becomes feasible to develop techniques and tools for automatic generation of realistic and sound tests from CSP models. Our work reconciles the normally disparate areas of refinement and (formal) testing by identifying how ioco testing can be used to inform refinement-based results and vice-versa.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W3027679286",
    "type": "article"
  },
  {
    "title": "Subatomic Proof Systems",
    "doi": "https://doi.org/10.1145/3173544",
    "publication_date": "2018-01-27",
    "publication_year": 2018,
    "authors": "Andrea Aler Tubella; Alessio Guglielmi",
    "corresponding_authors": "",
    "abstract": "This article presents the first in a series of results that allow us to develop a theory providing finer control over the complexity of normalization, and in particular of cut elimination. By considering atoms as self-dual noncommutative connectives, we are able to classify a vast class of inference rules in a uniform and very simple way. This allows us to define simple conditions that are easily verifiable and that ensure normalization and cut elimination by way of a general theorem. In this article, we define and consider splittable systems , which essentially make up a large class of linear logics, including Multiplicative Linear Logic and BV, and we prove for them a splitting theorem , guaranteeing cut elimination and other admissibility results as corollaries. In articles to follow, we will extend this result to nonlinear logics. The final outcome will be a comprehensive theory giving a uniform treatment for most existing logics and providing a blueprint for the design of future proof systems.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W4298033134",
    "type": "article"
  },
  {
    "title": "Abstraction in Fixpoint Logic",
    "doi": "https://doi.org/10.1145/2740964",
    "publication_date": "2015-07-08",
    "publication_year": 2015,
    "authors": "Sjoerd Cranen; Maciej Gazda; Wieger Wesselink; Tim A. C. Willemse",
    "corresponding_authors": "",
    "abstract": "We present a theory of abstraction for the framework of parameterised Boolean equation systems, a first-order fixpoint logic. Parameterised Boolean equation systems can be used to solve a variety of problems in verification. We study the capabilities of the abstraction theory by comparing it to an abstraction theory for Generalised Kripke modal Transition Systems (GTSs). We show that for model checking the modal μ-calculus, our abstractions can be exponentially more succinct than GTSs and our theory is as complete as the GTS framework for abstraction. Furthermore, we investigate the completeness of our theory irrespective of the encoded decision problem. We illustrate the potential of our theory through case studies using the first-order modal μ-calculus and a real-time extension thereof, conducted using a prototype implementation of a new syntactic transformation for parameterised Boolean equation systems.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2023331051",
    "type": "article"
  },
  {
    "title": "The Complexity of Decomposing Modal and First-Order Theories",
    "doi": "https://doi.org/10.1145/2699918",
    "publication_date": "2015-03-01",
    "publication_year": 2015,
    "authors": "Stefan Göller; Jean Christoph Jung; Markus Lohrey",
    "corresponding_authors": "",
    "abstract": "We study the satisfiability problem of the logic K 2 = K × K—the two-dimensional variant of unimodal logic, where models are restricted to asynchronous products of two Kripke frames. Gabbay and Shehtman proved in 1998 that this problem is decidable in a tower of exponentials. So far, the best-known lower bound is NEXP-hardness shown by Marx and Mikulás in 2001. Our first main result closes this complexity gap. We show that satisfiability in K 2 is nonelementary. More precisely, we prove that it is k -NEXP-complete, where k is the switching depth (the minimal modal rank among the two dimensions) of the input formula, hereby solving a conjecture of Marx and Mikulás. Using our lower-bound technique also allows us to derive nonelementary lower bounds for the two-dimensional modal logics K4 × K and S5 2 × K, for which only elementary lower bounds were previously known. Moreover, we apply our technique to prove nonelementary lower bounds for the sizes of Feferman-Vaught decompositions with respect to product for any decomposable logic that is at least as expressive as unimodal K, generalizing a recent result by the first author and Lin. For the three-variable fragment FO 3 of first-order logic, we obtain the following two immediate corollaries: the size of Feferman-Vaught decompositions with respect to disjoint sum are inherently nonelementary, and equivalent formulas in Gaifman normal form are inherently nonelementary. Our second main result consists in providing effective elementary (more precisely, doubly exponential) upper bounds for the two-variable fragment FO 2 of first-order logic both for Feferman-Vaught decompositions and for equivalent formulas in Gaifman normal form.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2054803027",
    "type": "article"
  },
  {
    "title": "Taming Paraconsistent (and Other) Logics",
    "doi": "https://doi.org/10.1145/2661636",
    "publication_date": "2014-12-12",
    "publication_year": 2014,
    "authors": "Agata Ciabattoni; Ori Lahav; Lara Spendier; Anna Zamansky",
    "corresponding_authors": "",
    "abstract": "We develop a fully algorithmic approach to “taming” logics expressed Hilbert style, that is, reformulating them in terms of analytic sequent calculi and useful semantics. Our approach applies to Hilbert calculi extending the positive fragment of propositional classical logic with axioms of a certain general form that contain new unary connectives. Our work encompasses various results already obtained for specific logics. It can be applied to new logics, as well as to known logics for which an analytic calculus or a useful semantics has so far not been available. A Prolog implementation of the method is described.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2131087632",
    "type": "article"
  },
  {
    "title": "The Ordering Principle in a Fragment of Approximate Counting",
    "doi": "https://doi.org/10.1145/2629555",
    "publication_date": "2014-08-01",
    "publication_year": 2014,
    "authors": "Albert Atserias; Neil Thapen",
    "corresponding_authors": "",
    "abstract": "The ordering principle states that every finite linear order has a least element. We show that, in the relativized setting, the surjective weak pigeonhole principle for polynomial time functions does not prove a Herbrandized version of the ordering principle over T 1 2 . This answers an open question raised in Buss et al. [2012] and completes their program to compare the strength of Jeřábek's bounded arithmetic theory for approximate counting with weakened versions of it.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2153365469",
    "type": "article"
  },
  {
    "title": "Modalities and Parametric Adjoints",
    "doi": "https://doi.org/10.1145/3514241",
    "publication_date": "2022-03-29",
    "publication_year": 2022,
    "authors": "Daniel Gratzer; Evan Cavallo; G. A. Kavvos; Adrien Guatto; Lars Birkedal",
    "corresponding_authors": "",
    "abstract": "Birkedal et al. recently introduced dependent right adjoints as an important class of (non-fibered) modalities in type theory. We observe that several aspects of their calculus are left underdeveloped and that it cannot serve as an internal language. We resolve these problems by assuming that the modal context operator is a parametric right adjoint. We show that this hitherto unrecognized structure is common. Based on these discoveries we present a new well-behaved Fitch-style multimodal type theory, which can be used as an internal language. Finally, we apply this syntax to guarded recursion and parametricity.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4220778823",
    "type": "article"
  },
  {
    "title": "A Decision Procedure for Guarded Separation Logic Complete Entailment Checking for Separation Logic with Inductive Definitions",
    "doi": "https://doi.org/10.1145/3534927",
    "publication_date": "2022-09-22",
    "publication_year": 2022,
    "authors": "Christoph Matheja; Jens Katelaan; Florian Zuleger",
    "corresponding_authors": "",
    "abstract": "We develop a doubly exponential decision procedure for the satisfiability problem of guarded separation logic —a novel fragment of separation logic featuring user-supplied inductive predicates, Boolean connectives, and separating connectives, including restricted (guarded) versions of negation, magic wand, and septraction. Moreover, we show that dropping the guards for any of the preceding connectives leads to an undecidable fragment. We further apply our decision procedure to reason about entailments in the popular symbolic heap fragment of separation logic. In particular, we obtain a doubly exponential decision procedure for entailments between (quantifier-free) symbolic heaps with inductive predicate definitions of bounded treewidth ( SL btw )—one of the most expressive decidable fragments of separation logic. Together with the recently shown 2ExpTime -hardness for entailments in said fragment, we conclude that the entailment problem for SL btw is 2ExpTime -complete—thereby closing a previously open complexity gap.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4296613475",
    "type": "article"
  },
  {
    "title": "Testing using CSP Models: Time, Inputs, and Outputs",
    "doi": "https://doi.org/10.1145/3572837",
    "publication_date": "2022-12-07",
    "publication_year": 2022,
    "authors": "James Baxter; Ana Cavalcanti; Maciej Gazda; Robert M. Hierons",
    "corresponding_authors": "",
    "abstract": "The existing testing theories for CSP cater for verification of interaction patterns (traces) and deadlocks, but not time. We address here refinement and testing based on a dialect of CSP, called tock -CSP, which can capture discrete time properties. This version of CSP has been of widespread interest for decades; recently, it has been given a denotational semantics, and model checking has become possible using a well established tool. Here, we first equip tock -CSP with a novel semantics for testing, which distinguishes input and output events: the standard models of ( tock -)CSP do not differentiate them, but for testing this is essential. We then present a new testing theory for timewise refinement, based on novel definitions of test and test execution. Finally, we reconcile refinement and testing by relating timed ioco testing and refinement in tock -CSP with inputs and outputs. With these results, this paper provides, for the first time, a systematic theory that allows both timed testing and timed refinement to be expressed. An important practical consequence is that this ensures that the notion of correctness used by developers guarantees that tests pass when applied to a correct system and, in addition, faults identified during testing correspond to development mistakes.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4311808642",
    "type": "article"
  },
  {
    "title": "Variable independence for first-order definable constraints",
    "doi": "https://doi.org/10.1145/937555.937557",
    "publication_date": "2003-10-01",
    "publication_year": 2003,
    "authors": "Leonid Libkin",
    "corresponding_authors": "Leonid Libkin",
    "abstract": "Whenever we have data represented by constraints (such as order, linear, polynomial, etc.), running time for many constraint processing algorithms can be considerably lowered if it is known that certain variables in those constraints are independent of each other. For example, when one deals with spatial and temporal databases given by constraints, the projection operation, which corresponds to quantifier elimination, is usually the costliest. Since the behavior of many quantifier elimination algorithms becomes worse as the dimension increases, eliminating certain variables from consideration helps speed up those algorithms.While these observations have been made in the literature, it remained unknown when the problem of testing if certain variables are independent is decidable, and how to efficiently construct a new representation of a constraint-set in which those variables do not appear together in the same atomic constraints. Here we answer this question. We first consider a general condition that gives us decidability of variable independence; this condition is stated in terms of model-theoretic properties of the structures corresponding to constraint classes. We then show that this condition covers the domains most relevant to spatial and temporal applications. For some of these domains, including linear and polynomial constraints over the reals, we provide a uniform decision procedure that gives us tractability as well. For those constraints, we also present a polynomial-time algorithm for producing nice constraint representations.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W2027450089",
    "type": "article"
  },
  {
    "title": "Proving correctness of timed concurrent constraint programs",
    "doi": "https://doi.org/10.1145/1024922.1024926",
    "publication_date": "2004-10-01",
    "publication_year": 2004,
    "authors": "Frank S. de Boer; Maurizio Gabbrielli; Maria Chiara Meo",
    "corresponding_authors": "",
    "abstract": "A temporal logic is presented for reasoning about the correctness of timed concurrent constraint programs. The logic is based on modalities which allow one to specify what a process produces as a reaction to what its environment inputs. These modalities provide an assumption/commitment style of specification which allows a sound and complete compositional axiomatization of the reactive behavior of timed concurrent constraint programs.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2030368531",
    "type": "article"
  },
  {
    "title": "On the complexity of the disjunction property in intuitionistic and modal logics",
    "doi": "https://doi.org/10.1145/1071596.1071598",
    "publication_date": "2005-07-01",
    "publication_year": 2005,
    "authors": "Mauro Ferrari; Camillo Fiorentini; Guido Fiorino",
    "corresponding_authors": "",
    "abstract": "In this article we study the complexity of disjunction property for intuitionistic logic, the modal logics S4 , S4.1 , Grzegorczyk logic, Gödel-Löb logic, and the intuitionistic counterpart of the modal logic K . For S4 we even prove the feasible interpolation theorem and we provide a lower bound for the length of proofs. The techniques we use do not require proving structural properties of the calculi in hand, such as the cut-elimination theorem or the normalization theorem. This is a key point of our approach, since it allows us to treat logics for which only Hilbert-style characterizations are known.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2075419333",
    "type": "article"
  },
  {
    "title": "Optimal length tree-like resolution refutations for 2SAT formulas",
    "doi": "https://doi.org/10.1145/976706.976711",
    "publication_date": "2004-04-01",
    "publication_year": 2004,
    "authors": "K. Subramani",
    "corresponding_authors": "K. Subramani",
    "abstract": "In this article, we exploit the graphical structure of 2SAT formulas to show that the shortest tree-like resolution refutation of an unsatisfiable 2SAT formula can be determined in polynomial time.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2064512355",
    "type": "article"
  },
  {
    "title": "Convergence law for random graphs with specified degree sequence",
    "doi": "https://doi.org/10.1145/1094622.1094627",
    "publication_date": "2005-10-01",
    "publication_year": 2005,
    "authors": "James F. Lynch",
    "corresponding_authors": "James F. Lynch",
    "abstract": "The degree sequence of an n -vertex graph is d 0 ,…, d n −1 , where each d i is the number of vertices of degree i in the graph. A random graph with degree sequence d 0 ,…, d n −1 is a randomly selected member of the set of graphs on {1,…, n } with that degree sequence, all choices being equally likely. Let λ 0 ,λ 1 ,… be a sequence of nonnegative reals summing to 1. A class of finite graphs has degree sequences approximated by λ 0 ,λ 1 ,… if, for every i and n , the members of the class of size n have λ i n + o(n) vertices of degree i . Our main result is a convergence law for random graphs with degree sequences approximated by some sequence λ 0 ,λ 1 ,…. With certain conditions on the sequence λ 0 ,λ 1 ,…, the probability of any first-order sentence on random graphs of size n converges to a limit as n grows.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2167523065",
    "type": "article"
  },
  {
    "title": "Compilability of propositional abduction",
    "doi": "https://doi.org/10.1145/1182613.1182615",
    "publication_date": "2007-01-01",
    "publication_year": 2007,
    "authors": "Paolo Liberatore; Marco Schaerf",
    "corresponding_authors": "",
    "abstract": "Abduction is one of the most important forms of reasoning; it has been successfully applied to several practical problems such as diagnosis. In this paper we investigate whether the computational complexity of abduction can be reduced by an appropriate use of preprocessing. This is motivated by the fact that part of the data of the problem (namely, the set of all possible assumptions and the theory relating assumptions and manifestations) are often known before the rest of the problem. In this paper, we show some complexity results about abduction when compilation is allowed.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W1624857405",
    "type": "article"
  },
  {
    "title": "Coordination in answer set programming",
    "doi": "https://doi.org/10.1145/1342991.1342993",
    "publication_date": "2008-03-01",
    "publication_year": 2008,
    "authors": "Chiaki Sakama; Katsumi Inoue",
    "corresponding_authors": "",
    "abstract": "This article studies a semantics of multiple logic programs, and synthesizes a program having such a collective semantics. More precisely, the following two problems are considered: given two logic programs P 1 and P 2 , which have the collections of answer sets AS ( P 1 ) and AS ( P 2 ), respectively; (i) find a program Q which has the set of answer sets such that AS ( Q ) = AS ( P 1 ) ∪ AS ( P 2 ); (ii) find a program R which has the set of answer sets such that AS ( R ) = AS ( P 1 ) ∩ AS ( P 2 ). A program Q satisfying the condition (i) is called generous coordination of P 1 and P 2 ; and R satisfying (ii) is called rigorous coordination of P 1 and P 2 . Generous coordination retains all of the answer sets of each program, but permits the introduction of additional answer sets of the other program. By contrast, rigorous coordination forces each program to give up some answer sets, but the result remains within the original answer sets for each program. Coordination provides a program that reflects the meaning of two or more programs. We provide methods for constructing these two types of coordination and address its application to logic-based multi-agent systems.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W1966690118",
    "type": "article"
  },
  {
    "title": "Erratum to splitting an operator",
    "doi": "https://doi.org/10.1145/1182613.1189735",
    "publication_date": "2007-01-01",
    "publication_year": 2007,
    "authors": "Joost Vennekens; David Gilis; Marc Denecker",
    "corresponding_authors": "",
    "abstract": "article Share on Erratum to splitting an operator: Algebraic modularity results for logics with fixpoint semantics Authors: Joost Vennekens K.U. Leuven K.U. LeuvenView Profile , David Gilis K.U. Leuven K.U. LeuvenView Profile , Marc Denecker K.U. Leuven K.U. LeuvenView Profile Authors Info & Claims ACM Transactions on Computational LogicVolume 8Issue 1January 2007 pp 7–eshttps://doi.org/10.1145/1182613.1189735Published:01 January 2007Publication History 3citation183DownloadsMetricsTotal Citations3Total Downloads183Last 12 Months2Last 6 weeks1 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my Alerts New Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteGet Access",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2114849031",
    "type": "erratum"
  },
  {
    "title": "On isomorphisms of intersection types",
    "doi": "https://doi.org/10.1145/1805950.1805955",
    "publication_date": "2010-07-01",
    "publication_year": 2010,
    "authors": "Mariangiola Dezani-Ciancaglini; Roberto Di Cosmo; Elio Giovannetti; Makoto Tatsuta",
    "corresponding_authors": "",
    "abstract": "The study of type isomorphisms for different λ-calculi started over twenty years ago, and a very wide body of knowledge has been established, both in terms of results and in terms of techniques. A notable missing piece of the puzzle was the characterization of type isomorphisms in the presence of intersection types. While, at first thought, this may seem to be a simple exercise, it turns out that not only finding the right characterization is not simple, but that the very notion of isomorphism in intersection types is an unexpectedly original element in the previously known landscape, breaking most of the known properties of isomorphisms of the typed λ-calculus. In particular, isomorphism is not a congruence and types that are equal in the standard models of intersection types may be nonisomorphic.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W1998616409",
    "type": "article"
  },
  {
    "title": "On (Omega-)regular model checking",
    "doi": "https://doi.org/10.1145/1838552.1838554",
    "publication_date": "2010-10-01",
    "publication_year": 2010,
    "authors": "Axel Legay; Pierre Wolper",
    "corresponding_authors": "",
    "abstract": "Checking infinite-state systems is frequently done by encoding infinite sets of states as regular languages. Computing such a regular representation of, say, the set of reachable states of a system requires acceleration techniques that can finitely compute the effect of an unbounded number of transitions. Among the acceleration techniques that have been proposed, one finds both specific and generic techniques. Specific techniques exploit the particular type of system being analyzed, for example, a system manipulating queues or integers, whereas generic techniques only assume that the transition relation is represented by a finite-state transducer, which has to be iterated. In this article, we investigate the possibility of using generic techniques in cases where only specific techniques have been exploited so far. Finding that existing generic techniques are often not applicable in cases easily handled by specific techniques, we have developed a new approach to iterating transducers. This new approach builds on earlier work, but exploits a number of new conceptual and algorithmic ideas, often induced with the help of experiments, that give it a broad scope, as well as good performances.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2063247622",
    "type": "article"
  },
  {
    "title": "Logical relations for a logical framework",
    "doi": "https://doi.org/10.1145/2536740.2536741",
    "publication_date": "2013-11-01",
    "publication_year": 2013,
    "authors": "Florian Rabe; Kristina Sojakova",
    "corresponding_authors": "",
    "abstract": "Logical relations are a central concept used to study various higher-order type theories and occur frequently in the proofs of a wide variety of meta-theorems. Besides extending the logical relation principle to more general languages, an important research question has been how to represent and thus verify logical relation arguments in logical frameworks. We formulate a theory of logical relations for Dependent Type Theory (DTT) with β η-equality which guarantees that any valid logical relation satisfies the Basic Lemma. Our definition is syntactic and reflective in the sense that a relation at a type is represented as a DTT type family but also permits expressing certain semantic definitions. We use the Edinburgh Logical Framework (LF) incarnation of DTT and implement our notion of logical relations in the type-checker Twelf. This enables us to formalize and mechanically decide the validity of logical relation arguments. Furthermore, our implementation includes a module system so that logical relations can be built modularly. We validate our approach by formalizing and verifying several syntactic and semantic meta-theorems in Twelf. Moreover, we show how object languages encoded in DTT can inherit a notion of logical relation from the logical framework.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2089613687",
    "type": "article"
  },
  {
    "title": "Generalized Eilenberg Theorem",
    "doi": "https://doi.org/10.1145/3276771",
    "publication_date": "2018-12-20",
    "publication_year": 2018,
    "authors": "Jiřı́ Adámek; Stefan Milius; Robert S.R. Myers; Henning Urbat",
    "corresponding_authors": "",
    "abstract": "For finite automata as coalgebras in a category C , we study languages they accept and varieties of such languages. This generalizes Eilenberg’s concept of a variety of languages, which corresponds to choosing as C the category of Boolean algebras. Eilenberg established a bijective correspondence between pseudovarieties of monoids and varieties of regular languages. In our generalization, we work with a pair C / D of locally finite varieties of algebras that are predual, i.e., dualize on the level of finite algebras, and we prove that pseudovarieties of D -monoids bijectively correspond to varieties of regular languages in C . As one instance, Eilenberg’s result is recovered by choosing D = sets and C = Boolean algebras. Another instance, Pin’s result on pseudovarieties of ordered monoids, is covered by taking D = posets and C = distributive lattices. By choosing as C amp;equals; D the self-predual category of join-semilattices, we obtain Polák’s result on pseudovarieties of idempotent semirings. Similarly, using the self-preduality of vector spaces over a finite field K , our result covers that of Reutenauer on pseudovarieties of K -algebras. Several new variants of Eilenberg’s theorem arise by taking other predualities, e.g., between the categories of non-unital Boolean rings and of pointed sets. In each of these cases, we also prove a local variant of the bijection, where a fixed alphabet is assumed and one considers local varieties of regular languages over that alphabet in the category C .",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2905780452",
    "type": "article"
  },
  {
    "title": "Game-Theoretic Semantics for Alternating-Time Temporal Logic",
    "doi": "https://doi.org/10.1145/3179998",
    "publication_date": "2018-07-31",
    "publication_year": 2018,
    "authors": "Valentin Goranko; Antti Kuusisto; Raine Rönnholm",
    "corresponding_authors": "",
    "abstract": "We introduce several versions of game-theoretic semantics (GTS) for Alternating-Time Temporal Logic (ATL). In GTS, truth is defined in terms of existence of a winning strategy in a semantic evaluation game. Thus, the game-theoretic perspective appears in the framework of ATL on two semantic levels: on the object level in the standard semantics of the strategic operators and on the meta-level, where game-theoretic logical semantics is applied to ATL. We unify these two perspectives into semantic evaluation games specially designed for ATL. The game-theoretic perspective enables us to identify new variants of the semantics of ATL based on limiting the time resources available to the verifier and falsifier in the semantic evaluation game. We introduce and analyze an unbounded and (ordinal) bounded GTS and prove these to be equivalent to the standard (Tarski-style) compositional semantics. We show that, in bounded GTS, truth of ATL formulae can always be determined in finite time, that is, without constructing infinite paths. We also introduce a nonequivalent finitely bounded semantics and argue that it is natural from both logical and game-theoretic perspectives.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2963046298",
    "type": "article"
  },
  {
    "title": "Completeness of Flat Coalgebraic Fixpoint Logics",
    "doi": "https://doi.org/10.1145/3157055",
    "publication_date": "2018-01-06",
    "publication_year": 2018,
    "authors": "Lutz Schröder; Yde Venema",
    "corresponding_authors": "",
    "abstract": "Modal fixpoint logics traditionally play a central role in computer science, in particular in artificial intelligence and concurrency. The μ-calculus and its relatives are among the most expressive logics of this type. However, popular fixpoint logics tend to trade expressivity for simplicity and readability and in fact often live within the single variable fragment of the μ-calculus. The family of such flat fixpoint logics includes, e.g., Linear Temporal Logic (LTL), Computation Tree Logic (CTL), and the logic of common knowledge. Extending this notion to the generic semantic framework of coalgebraic logic enables covering a wide range of logics beyond the standard μ-calculus including, e.g., flat fragments of the graded μ-calculus and the alternating-time μ-calculus (such as alternating-time temporal logic), as well as probabilistic and monotone fixpoint logics. We give a generic proof of completeness of the Kozen-Park axiomatization for such flat coalgebraic fixpoint logics.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2963435309",
    "type": "article"
  },
  {
    "title": "A First-order Logic for Reasoning about Knowledge and Probability",
    "doi": "https://doi.org/10.1145/3359752",
    "publication_date": "2020-02-02",
    "publication_year": 2020,
    "authors": "Siniša Tomović; Zoran Ognjanović; Dragan Doder",
    "corresponding_authors": "",
    "abstract": "We present a first-order probabilistic epistemic logic, which allows combining operators of knowledge and probability within a group of possibly infinitely many agents. We define its syntax and semantics and prove the strong completeness property of the corresponding axiomatic system. 1",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W3005452357",
    "type": "article"
  },
  {
    "title": "Metric Temporal Description Logics with Interval-Rigid Names",
    "doi": "https://doi.org/10.1145/3399443",
    "publication_date": "2020-08-11",
    "publication_year": 2020,
    "authors": "Franz Baader; Stefan Borgwardt; Patrick Koopmann; Ana Ozaki; Veronika Thost",
    "corresponding_authors": "",
    "abstract": "In contrast to qualitative linear temporal logics, which can be used to state that some property will eventually be satisfied, metric temporal logics allow us to formulate constraints on how long it may take until the property is satisfied. While most of the work on combining description logics (DLs) with temporal logics has concentrated on qualitative temporal logics, there is a growing interest in extending this work to the quantitative case. In this article, we complement existing results on the combination of DLs with metric temporal logics by introducing interval-rigid concept and role names. Elements included in an interval-rigid concept or role name are required to stay in it for some specified amount of time. We investigate several combinations of (metric) temporal logics with A ℒ C by either allowing temporal operators only on the level of axioms or also applying them to concepts. In contrast to most existing work on the topic, we consider a timeline based on the integers and also allow assertional axioms. We show that the worst-case complexity does not increase beyond the previously known bound of 2-E xp S pace and investigate in detail how this complexity can be reduced by restricting the temporal logic and the occurrences of interval-rigid names.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W3048586703",
    "type": "article"
  },
  {
    "title": "Mixed Iterated Revisions: Rationale, Algorithms, and Complexity",
    "doi": "https://doi.org/10.1145/3583071",
    "publication_date": "2023-02-09",
    "publication_year": 2023,
    "authors": "Paolo Liberatore",
    "corresponding_authors": "Paolo Liberatore",
    "abstract": "Several forms of iterable belief change exist, differing in the kind of change and its strength: some operators introduce formulae, others remove them; some add formulae unconditionally, others only as additions to the previous beliefs; some only relative to the current situation, others in all possible cases. A sequence of changes may involve several of them: for example, the first step is a revision, the second a contraction and the third a refinement of the previous beliefs. The ten operators considered in this article are shown to be all reducible to three: lexicographic revision, refinement, and severe withdrawal. In turn, these three can be expressed in terms of lexicographic revision at the cost of restructuring the sequence. This restructuring needs not to be done explicitly: an algorithm that works on the original sequence is shown. The complexity of mixed sequences of belief change operators is also analyzed. Most of them require only a polynomial number of calls to a satisfiability checker, some are even easier.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4319736388",
    "type": "article"
  },
  {
    "title": "A syntactical analysis of non-size-increasing polynomial time computation",
    "doi": "https://doi.org/10.1145/507382.507386",
    "publication_date": "2002-07-01",
    "publication_year": 2002,
    "authors": "Klaus Aehlig; Helmut Schwichtenberg",
    "corresponding_authors": "",
    "abstract": "A syntactical proof is given that all functions definable in a certain affine linear typed λ-calculus with iteration in all types are polynomial time computable. The proof provides explicit polynomial bounds that can easily be calculated.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2126864471",
    "type": "article"
  },
  {
    "title": "Abstract computability and algebraic specification",
    "doi": "https://doi.org/10.1145/505372.505375",
    "publication_date": "2002-04-01",
    "publication_year": 2002,
    "authors": "John V. Tucker; J. I. Zucker",
    "corresponding_authors": "",
    "abstract": "Abstract computable functions are defined by abstract finite deterministic algorithms on many-sorted algebras. We show that there exist finite universal algebraic specifications that specify uniquely (up to isomorphism) (i) all abstract computable functions on any many-sorted algebra; (ii) all functions effectively approximable by abstract computable functions on any metric algebra. We show that there exist universal algebraic specifications for all the classically computable functions on the set ℝ of real numbers. The algebraic specifications used are mainly bounded universal equations and conditional equations. We investigate the initial algebra semantics of these specifications, and derive situations where algebraic specifications precisely define the computable functions.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2021405727",
    "type": "article"
  },
  {
    "title": "Computational properties of metaquerying problems",
    "doi": "https://doi.org/10.1145/635499.635501",
    "publication_date": "2003-04-01",
    "publication_year": 2003,
    "authors": "Fabrizio Angiulli; Rachel Ben‐Eliyahu‐Zohary; Giovambattista Ianni; Luigi Palopoli",
    "corresponding_authors": "",
    "abstract": "Metaquerying is a data mining technology by which hidden dependencies among several database relations can be discovered. This tool has already been successfully applied to several real-world applications, but only preliminary results about the complexity of metaquerying can be found in the literature. In this article, we define several variants of metaquerying that encompass, as far as we know, all the variants that have been defined in the literature. We study both the combined complexity and the data complexity of these variants. We show that under the combined complexity measure metaquerying is generally intractable (unless P = NP ), lying sometimes quite high in the complexity hierarchies (as high as NP PP ), depending on the characteristics of the plausibility index. Nevertheless, we are able to single out some tractable and interesting metaquerying cases, whose combined complexity is LOGCFL-complete. As for the data complexity of metaquerying, we prove that, in general, it is within TC 0 , but lies within AC 0 in some simpler cases. Finally, we discuss the implementation of metaqueries by providing algorithms that answer them.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2076491023",
    "type": "article"
  },
  {
    "title": "Fixed-parameter complexity of semantics for logic programs",
    "doi": "https://doi.org/10.1145/601775.601779",
    "publication_date": "2003-01-01",
    "publication_year": 2003,
    "authors": "Zbigniew Lonc; Mirosław Truszczyński",
    "corresponding_authors": "",
    "abstract": "A decision problem is called parameterized if its input is a pair of strings. One of these strings is referred to as a parameter . The following problem is an example of a parameterized decision problem with k serving as a parameter: given a propositional logic program P and a nonnegative integer k , decide whether P has a stable model of size no more than k . Parameterized problems that are NP-complete often become solvable in polynomial time if the parameter is fixed. The problem to decide whether a program P has a stable model of size no more than k , where k is fixed and not a part of input, can be solved in time O ( mn k ), where m is the size of P and n is the number of atoms in P . Thus, this problem is in the class P. However, algorithms with the running time given by a polynomial of order k are not satisfactory even for relatively small values of k .The key question then is whether significantly better algorithms (with the degree of the polynomial not dependent on k ) exist. To tackle it, we use the framework of fixed-parameter complexity. We establish the fixed-parameter complexity for several parameterized decision problems involving models, supported models, and stable models of logic programs. We also establish the fixed-parameter complexity for variants of these problems resulting from restricting attention to definite Horn programs and to purely negative programs. Most of the problems considered in the paper have high fixed-parameter complexity. Thus, it is unlikely that fixing bounds on models (supported models, stable models) will lead to fast algorithms to decide the existence of such models.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2123481932",
    "type": "article"
  },
  {
    "title": "On first-order topological queries",
    "doi": "https://doi.org/10.1145/507382.507384",
    "publication_date": "2002-07-01",
    "publication_year": 2002,
    "authors": "Martin Grohe; Luc Segoufin",
    "corresponding_authors": "",
    "abstract": "One important class of spatial database queries is the class of topological queries , that is, queries invariant under homeomorphisms. We study topological queries expressible in the standard query language on spatial databases, first-order logic with various amounts of arithmetic. Our main technical result is a combinatorial characterization of the expressive power of topological first-order logic on regular spatial databases.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2176172793",
    "type": "article"
  },
  {
    "title": "Fast verification of MLL proof nets via IMLL",
    "doi": "https://doi.org/10.1145/1149114.1149116",
    "publication_date": "2006-07-01",
    "publication_year": 2006,
    "authors": "Andrzej S. Murawski; C.-H. Luke Ong",
    "corresponding_authors": "",
    "abstract": "We consider the following decision problems:ProofNet: Is a given multiplicative linear logic (MLL) proof structure a proof net?EssNet: Is a given essential net (of an intuitionistic MLL sequent) correct?In this article we show how to obtain linear-time algorithms for EssNet. As a corollary, by showing that ProofNet is linear-time reducible to EssNet (by the Trip Translation), we obtain a linear-time algorithm for ProofNet.We show further that it is possible to optimize the verification so that each node of the input structure is visited at most once. Finally, we present linear-time algorithms for sequentializing proof nets and essential nets, that is, for finding derivations of the underlying sequents.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W1983313429",
    "type": "article"
  },
  {
    "title": "The arithmetical complexity of dimension and randomness",
    "doi": "https://doi.org/10.1145/1227839.1227845",
    "publication_date": "2007-04-01",
    "publication_year": 2007,
    "authors": "John M. Hitchcock; Jack H. Lutz; Sebastiaan A. Terwijn",
    "corresponding_authors": "",
    "abstract": "Constructive dimension and constructive strong dimension are effectivizations of the Hausdorff and packing dimensions, respectively. Each infinite binary sequence A is assigned a dimension dim( A ) ∈ [0,1] and a strong dimension Dim( A ) ∈ [0,1]. Let DIM α and DIM α str be the classes of all sequences of dimension α and of strong dimension α, respectively. We show that DIM 0 is properly Π 0 2 , and that for all Δ 0 2 -computable α ∈ (0, 1], DIM α is properly Π 0 3 . To classify the strong dimension classes, we use a more powerful effective Borel hierarchy where a coenumerable predicate is used rather than an enumerable predicate in the definition of the Σ 0 1 level. For all Δ 0 2 -computable α ∈ [0, 1), we show that DIM α str is properly in the Π 0 3 level of this hierarchy. We show that DIM 1 str is properly in the Π 0 2 level of this hierarchy. We also prove that the class of Schnorr random sequences and the class of computably random sequences are properly Π 0 3 .",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2160064439",
    "type": "article"
  },
  {
    "title": "Differential recursion",
    "doi": "https://doi.org/10.1145/1507244.1507252",
    "publication_date": "2009-04-01",
    "publication_year": 2009,
    "authors": "Akitoshi Kawamura",
    "corresponding_authors": "Akitoshi Kawamura",
    "abstract": "We present a redevelopment of the theory of real-valued recursive functions that was introduced by C. Moore in 1996 by analogy with the standard formulation of the integer-valued recursive functions. While his work opened a new line of research on analog computation, the original paper contained some technical inaccuracies. We discuss possible attempts to remove the ambiguity in the behavior of the operators on partial functions, with a focus on his “primitive recursive” functions generated by the differential recursion operator that solves initial value problems. Under a reasonable reformulation, the functions in this class are shown to be analytic and computable in a strong sense in computable analysis. Despite this well-behavedness, the class turns out to be too big to have the originally purported relation to differentially algebraic functions, and hence to C. E. Shannon's model of analog computation.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W3100307655",
    "type": "article"
  },
  {
    "title": "Complete Abstractions for Checking Language Inclusion",
    "doi": "https://doi.org/10.1145/3462673",
    "publication_date": "2021-09-08",
    "publication_year": 2021,
    "authors": "Pierre Ganty; Francesco Ranzato; Pedro Valero",
    "corresponding_authors": "",
    "abstract": "We study the language inclusion problem L 1 ⊆ L 2 , where L 1 is regular or context-free. Our approach relies on abstract interpretation and checks whether an overapproximating abstraction of L 1 , obtained by approximating the Kleene iterates of its least fixpoint characterization, is included in L 2 . We show that a language inclusion problem is decidable whenever this overapproximating abstraction satisfies a completeness condition (i.e., its loss of precision causes no false alarm) and prevents infinite ascending chains (i.e., it guarantees termination of least fixpoint computations). This overapproximating abstraction of languages can be defined using quasiorder relations on words, where the abstraction gives the language of all the words “greater than or equal to” a given input word for that quasiorder. We put forward a range of such quasiorders that allow us to systematically design decision procedures for different language inclusion problems, such as regular languages into regular languages or into trace sets of one-counter nets, and context-free languages into regular languages. In the case of inclusion between regular languages, some of the induced inclusion checking procedures correspond to well-known state-of-the-art algorithms, like the so-called antichain algorithms. Finally, we provide an equivalent language inclusion checking algorithm based on a greatest fixpoint computation that relies on quotients of languages and, to the best of our knowledge, was not previously known.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W3197616549",
    "type": "article"
  },
  {
    "title": "Maps in Multiple Belief Change",
    "doi": "https://doi.org/10.1145/2362355.2362358",
    "publication_date": "2012-10-01",
    "publication_year": 2012,
    "authors": "Pavlos Peppas; Costas D. Koutras; Mary‐Anne Williams",
    "corresponding_authors": "",
    "abstract": "Multiple Belief Change extends the classical AGM framework for Belief Revision introduced by Alchourron, Gardenfors, and Makinson in the early ’80s. The extended framework includes epistemic input represented as a (possibly infinite) set of sentences , as opposed to a single sentence assumed in the original framework. The transition from single to multiple epistemic input worked out well for the operation of belief revision. The AGM postulates and the system-of-spheres model were adequately generalized and so was the representation result connecting the two. In the case of belief contraction however, the transition was not as smooth. The generalized postulates for contraction, which were shown to correspond precisely to the generalized partial meet model , failed to match up to the generalized epistemic entrenchment model . The mismatch was fixed with the addition of an extra postulate, called the limit postulate , that relates contraction by multiple epistemic input to a series of contractions by single epistemic input. The new postulate however creates problems on other fronts. First, the limit postulate needs to be mapped into appropriate constraints in the partial meet model. Second, via the Levi and Harper Identities, the new postulate translates into an extra postulate for multiple revision, which in turn needs to be characterized in terms of systems of spheres. Both these open problems are addressed in this article. In addition, the limit postulate is compared with a similar condition in the literature, called (K*F), and is shown to be strictly weaker than it. An interesting aspect of our results is that they reveal a profound connection between rationality in multiple belief change and the notion of an elementary set of possible worlds (closely related to the notion of an elementary class of models from classical logic).",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W1978803631",
    "type": "article"
  },
  {
    "title": "Verification of linear duration properties over continuous-time markov chains",
    "doi": "https://doi.org/10.1145/2528935",
    "publication_date": "2013-11-01",
    "publication_year": 2013,
    "authors": "Taolue Chen; Marco Diciolla; Marta Kwiatkowska; Alexandru Mereacre",
    "corresponding_authors": "",
    "abstract": "Stochastic modelling and algorithmic verification techniques have been proved useful in analysing and detecting unusual trends in performance and energy usage of systems such as power management controllers and wireless sensor devices. Many important properties are dependent on the cumulated time that the device spends in certain states, possibly intermittently. We study the problem of verifying continuous-time Markov Chains (CTMCs) against Linear Duration Properties (LDP), that is, properties stated as conjunctions of linear constraints over the total duration of time spent in states that satisfy a given property. We identify two classes of LDP properties, Eventuality Duration Properties (EDP) and Invariance Duration Properties (IDP), respectively referring to the reachability of a set of goal states, within a time bound; and the continuous satisfaction of a duration property over an execution path. The central question that we address is how to compute the probability of the set of infinite timed paths of the CTMC that satisfy a given LDP. We present algorithms to approximate these probabilities up to a given precision, stating their complexity and error bounds. The algorithms mainly employ an adaptation of uniformisation and the computation of volumes of multidimensional integrals under systems of linear constraints, together with different mechanisms to bound the errors.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W1984799101",
    "type": "article"
  },
  {
    "title": "Parallel Abductive Query Answering in Probabilistic Logic Programs",
    "doi": "https://doi.org/10.1145/2480759.2480764",
    "publication_date": "2013-06-01",
    "publication_year": 2013,
    "authors": "Gerardo I. Simari; John P. Dickerson; Amy Sliva; V. S. Subrahmanian",
    "corresponding_authors": "",
    "abstract": "Action-probabilistic logic programs ( ap -programs) are a class of probabilistic logic programs that have been extensively used during the last few years for modeling behaviors of entities. Rules in ap -programs have the form “If the environment in which entity E operates satisfies certain conditions, then the probability that E will take some action A is between L and U ”. Given an ap -program, we are interested in trying to change the environment, subject to some constraints, so that the probability that entity E takes some action (or combination of actions) is maximized. This is called the Basic Abductive Query Answering Problem (BAQA). We first formally define and study the complexity of BAQA, and then go on to provide an exact (exponential time) algorithm to solve it, followed by more efficient algorithms for specific subclasses of the problem. We also develop appropriate heuristics to solve BAQA efficiently. The second problem, called the Cost-based Query Answering (CBQA) problem checks to see if there is some way of achieving a desired action (or set of actions) with a probability exceeding a threshold, given certain costs. We first formally define and study an exact (intractable) approach to CBQA, and then go on to propose a more efficient algorithm for a specific subclass of ap -programs that builds on the results for the basic version of this problem. We also develop the first algorithms for parallel evaluation of CBQA. We conclude with an extensive report on experimental evaluations performed over prototype implementations of the algorithms developed for both BAQA and CBQA, showing that our parallel algorithms work well in practice.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2006998981",
    "type": "article"
  },
  {
    "title": "Epistemic Strategies and Games on Concurrent Processes",
    "doi": "https://doi.org/10.1145/2362355.2362356",
    "publication_date": "2012-10-01",
    "publication_year": 2012,
    "authors": "Konstantinos Chatzikokolakis; Sophia Knight; Catuscia Palamidessi; Prakash Panangaden",
    "corresponding_authors": "",
    "abstract": "We develop a game semantics for process algebra with two interacting agents. The purpose of our semantics is to make manifest the role of knowledge and information flow in the interactions between agents and to control the information available to interacting agents. We define games and strategies on process algebras, so that two agents interacting according to their strategies determine the execution of the process, replacing the traditional scheduler. We show that different restrictions on strategies represent different amounts of information being available to a scheduler. We also show that a certain class of strategies corresponds to the syntactic schedulers of Chatzikokolakis and Palamidessi, which were developed to overcome problems with traditional schedulers modelling interaction. The restrictions on these strategies have an explicit epistemic flavour.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2013667259",
    "type": "article"
  },
  {
    "title": "Persistent queries in the behavioral theory of algorithms",
    "doi": "https://doi.org/10.1145/1877714.1877722",
    "publication_date": "2011-01-01",
    "publication_year": 2011,
    "authors": "Andreas Blass; Yuri Gurevich",
    "corresponding_authors": "",
    "abstract": "We propose an extension of the behavioral theory of interactive sequential algorithms to deal with the following situation. A query is issued during a certain step, but the step ends before any reply is received. Later, a reply arrives, and later yet the algorithm makes use of this reply. By a persistent query, we mean a query for which a late reply might be used. Our proposal involves issuing, along with a persistent query, a location where a late reply is to be stored. After presenting our proposal in general terms, we discuss the modifications that it requires in the existing axiomatics of interactive sequential algorithms and in the existing syntax and semantics of abstract state machines. To make that discussion self-contained, we include a summary of this material before the modifications. Fortunately, only rather minor modifications are needed.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2072375373",
    "type": "article"
  },
  {
    "title": "Does Treewidth Help in Modal Satisfiability?",
    "doi": "https://doi.org/10.1145/2499937.2499939",
    "publication_date": "2013-08-01",
    "publication_year": 2013,
    "authors": "M. Praveen",
    "corresponding_authors": "M. Praveen",
    "abstract": "Many tractable algorithms for solving the Constraint Satisfaction Problem ( Csp ) have been developed using the notion of the treewidth of some graph derived from the input Csp instance. In particular, the incidence graph of the Csp instance is one such graph. We introduce the notion of an incidence graph for modal logic formulas in a certain normal form. We investigate the parameterized complexity of modal satisfiability with the modal depth of the formula and the treewidth of the incidence graph as parameters. For various combinations of Euclidean, reflexive, symmetric, and transitive models, we show either that modal satisfiability is Fixed Parameter Tractable ( Fpt ), or that it is W[1]-hard. In particular, modal satisfiability in general models is Fpt , while it is W[1]-hard in transitive models. As might be expected, modal satisfiability in transitive and Euclidean models is Fpt .",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2149632978",
    "type": "article"
  },
  {
    "title": "Algebra, proof theory and applications for an intuitionistic logic of propositions, actions and adjoint modal operators",
    "doi": "https://doi.org/10.1145/2536740.2536742",
    "publication_date": "2013-11-01",
    "publication_year": 2013,
    "authors": "Roy Dyckhoff; Mehrnoosh Sadrzadeh; Julien Truffaut",
    "corresponding_authors": "",
    "abstract": "We develop a cut-free nested sequent calculus as basis for a proof search procedure for an intuitionistic modal logic of actions and propositions. The actions act on propositions via a dynamic modality (the weakest precondition of program logics), whose left adjoint we refer to as “update” (the strongest postcondition ). The logic has agent-indexed adjoint pairs of epistemic modalities: the left adjoints encode agents' uncertainties and the right adjoints encode their beliefs. The rules for the “update” modality encode learning as a result of discarding uncertainty. We prove admissibility of Cut , and hence the soundness and completeness of the logic with respect to an algebraic semantics. We interpret the logic on epistemic scenarios that consist of honest and dishonest communication actions, add assumption rules to encode them, and prove that the calculus with the assumption rules still has the admissibility results. We apply the calculus to encode (and allow reasoning about) the classic epistemic puzzles of dirty children (a.k.a. “muddy children”) and drinking logicians and some versions with dishonesty or noise; we also give an application where the actions are movements of a robot rather than announcements.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2165797525",
    "type": "article"
  },
  {
    "title": "Parametrised Complexity of Satisfiability in Temporal Logic",
    "doi": "https://doi.org/10.1145/3001835",
    "publication_date": "2017-01-20",
    "publication_year": 2017,
    "authors": "Martin Lück; Arne Meier; Irena Schindler",
    "corresponding_authors": "",
    "abstract": "We apply the concept of formula treewidth and pathwidth to computation tree logic, linear temporal logic, and the full branching time logic. Several representations of formulas as graphlike structures are discussed, and corresponding notions of treewidth and pathwidth are introduced. As an application for such structures, we present a classification in terms of parametrised complexity of the satisfiability problem, where we make use of Courcelle’s famous theorem for recognition of certain classes of structures. Our classification shows a dichotomy between W[1]-hard and fixed-parameter tractable operator fragments almost independently of the chosen graph representation. The only fragments that are proven to be fixed-parameter tractable (FPT) are those that are restricted to the X operator. By investigating Boolean operator fragments in the sense of Post’s lattice, we achieve the same complexity as in the unrestricted case if the set of available Boolean functions can express the function “negation of the implication.” Conversely, we show containment in FPT for almost all other clones.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2582211829",
    "type": "article"
  },
  {
    "title": "Succinctness of Order-Invariant Logics on Depth-Bounded Structures",
    "doi": "https://doi.org/10.1145/3152770",
    "publication_date": "2017-10-31",
    "publication_year": 2017,
    "authors": "Kord Eickmeyer; Michael Elberfeld; Frederik Harwath",
    "corresponding_authors": "",
    "abstract": "We study the expressive power and succinctness of order-invariant sentences of first-order (FO) and monadic second-order (MSO) logic on structures of bounded tree-depth. Order-invariance is undecidable in general and, thus, one strives for logics with a decidable syntax that have the same expressive power as order-invariant sentences. We show that on structures of bounded tree-depth, order-invariant FO has the same expressive power as FO. Our proof technique allows for a fine-grained analysis of the succinctness of this translation. We show that for every order-invariant FO sentence there exists an FO sentence whose size is elementary in the size of the original sentence, and whose number of quantifier alternations is linear in the tree-depth. We obtain similar results for MSO. It is known that the expressive power of MSO and FO coincide on structures of bounded tree-depth. We provide a translation from MSO to FO and we show that this translation is essentially optimal regarding the formula size. As a further result, we show that order-invariant MSO has the same expressive power as FO with modulo-counting quantifiers on bounded tree-depth structures.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2964232764",
    "type": "article"
  },
  {
    "title": "Complexity Classifications for Logic-Based Argumentation",
    "doi": "https://doi.org/10.1145/2629421",
    "publication_date": "2014-07-08",
    "publication_year": 2014,
    "authors": "Nadia Creignou; Uwe Egly; Johannes Schmidt",
    "corresponding_authors": "",
    "abstract": "We consider logic-based argumentation in which an argument is a pair (Φ, α), where the support Φ is a minimal consistent set of formulae taken from a given knowledge base (usually denoted by Δ) that entails the claim α (a formula). We study the complexity of three central problems in argumentation: the existence of a support Φ⊆Δ, the verification of a support, and the relevance problem (given ψ, is there a support Φ such that ψ ∈ Φ?). When arguments are given in the full language of propositional logic, these problems are computationally costly tasks: the verification problem is DP-complete; the others are Σ p 2 -complete. We study these problems in Schaefer's famous framework where the considered propositional formulae are in generalized conjunctive normal form. This means that formulae are conjunctions of constraints built upon a fixed finite set of Boolean relations Γ (the constraint language). We show that according to the properties of this language Γ, deciding whether there exists a support for a claim in a given knowledge base is either polynomial, NP-complete, coNP-complete, or Σ p 2 -complete. We present a dichotomous classification, P or DP-complete, for the verification problem and a trichotomous classification for the relevance problem into either polynomial, NP-complete, or Σ p 2 -complete. These last two classifications are obtained by means of algebraic tools.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2125216182",
    "type": "article"
  },
  {
    "title": "An Assertional Proof of the Stability and Correctness of Natural Mergesort",
    "doi": "https://doi.org/10.1145/2814571",
    "publication_date": "2015-11-06",
    "publication_year": 2015,
    "authors": "K. Rustan M. Leino; Paqui Lucio",
    "corresponding_authors": "",
    "abstract": "We present a mechanically verified implementation of the sorting algorithm Natural Mergesort that consists of a few methods specified by their contracts of pre/post conditions. Methods are annotated with assertions that allow the automatic verification of the contract satisfaction. This program-proof is made using the state-of-the-art verifier Dafny . We verify not only the standard sortedness property, but also that the algorithm performs a stable sort. Throughout the article, we provide and explain the complete text of the program-proof.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2220441938",
    "type": "article"
  },
  {
    "title": "On Well-Founded Set-Inductions and Locally Monotone Operators",
    "doi": "https://doi.org/10.1145/2963096",
    "publication_date": "2016-09-10",
    "publication_year": 2016,
    "authors": "Bart Bogaerts; Joost Vennekens; Marc Denecker",
    "corresponding_authors": "",
    "abstract": "In the past, compelling arguments in favour of the well-founded semantics for autoepistemic logic have been presented. In this article, we show that for certain classes of theories, this semantics fails to identify the unique intended model. We solve this problem by refining the well-founded semantics. We develop our work in approximation fixpoint theory, an abstract algebraical study of semantics of nonmonotonic logics. As such, our results also apply to logic programming, default logic, Dung’s argumentation frameworks, and abstract dialectical frameworks.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2519968153",
    "type": "article"
  },
  {
    "title": "Parameterized Complexity of Elimination Distance to First-Order Logic Properties",
    "doi": "https://doi.org/10.1145/3517129",
    "publication_date": "2022-03-29",
    "publication_year": 2022,
    "authors": "Fedor V. Fomin; Petr A. Golovach; Dimitrios M. Thilikos",
    "corresponding_authors": "",
    "abstract": "The elimination distance to some target graph property P is a general graph modification parameter introduced by Bulian and Dawar. We initiate the study of elimination distances to graph properties expressible in first-order logic. We delimit the problem’s fixed-parameter tractability by identifying sufficient and necessary conditions on the structure of prefixes of first-order logic formulas. Our main result is the following meta-theorem: For every graph property P expressible by a first order-logic formula \\( \\varphi \\in \\Sigma _3 \\) , that is, of the form \\( \\begin{equation*} \\varphi =\\exists x_1\\exists x_2\\cdots \\exists x_r\\ \\ \\forall y_{1}\\forall y_{2}\\cdots \\forall y_{s}\\ \\ \\exists z_1\\exists z_2\\cdots \\exists z_t~~ \\psi ,\\end{equation*} \\) where \\( \\psi \\) is a quantifier-free first-order formula, checking whether the elimination distance of a graph to P does not exceed \\( k \\) , is fixed-parameter tractable parameterized by \\( k \\) . Properties of graphs expressible by formulas from \\( \\Sigma _3 \\) include being of bounded degree, excluding a forbidden subgraph, or containing a bounded dominating set. We complement this theorem by showing that such a general statement does not hold for formulas with even slightly more expressive prefix structure: There are formulas \\( \\varphi \\in \\Pi _3 \\) , for which computing elimination distance is \\( {\\sf W}[2] \\) -hard.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W3147498698",
    "type": "article"
  },
  {
    "title": "Logics for Temporal Information Systems in Rough Set Theory",
    "doi": "https://doi.org/10.1145/3549075",
    "publication_date": "2022-07-19",
    "publication_year": 2022,
    "authors": "Md. Aquil Khan; Mohua Banerjee; Sibsankar Panda",
    "corresponding_authors": "",
    "abstract": "The article discusses temporal information systems (TISs) that add the dimension of time to complete or incomplete information systems. Through TISs, one can accommodate the possibility of domains or attribute values for objects changing with time or the availability of currently missing information with time. Different patterns of flow of information give different TISs. The corresponding logics with sound and complete axiomatization are presented.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4286217004",
    "type": "article"
  },
  {
    "title": "Witnesses for Answer Sets of Logic Programs",
    "doi": "https://doi.org/10.1145/3568955",
    "publication_date": "2022-10-20",
    "publication_year": 2022,
    "authors": "Yisong Wang; Thomas Eiter; Yuanlin Zhang; Fangzhen Lin",
    "corresponding_authors": "",
    "abstract": "In this article, we consider Answer Set Programming (ASP). It is a declarative problem solving paradigm that can be used to encode a problem as a logic program whose answer sets correspond to the solutions of the problem. It has been widely applied in various domains in AI and beyond. Given that answer sets are supposed to yield solutions to the original problem, the question of “why a set of atoms is an answer set” becomes important for both semantics understanding and program debugging. It has been well investigated for normal logic programs. However, for the class of disjunctive logic programs, which is a substantial extension of that of normal logic programs, this question has not been addressed much. In this article, we propose a notion of reduct for disjunctive logic programs and show how it can provide answers to the aforementioned question. First, we show that for each answer set, its reduct provides a resolution proof for each atom in it. We then further consider minimal sets of rules that will be sufficient to provide resolution proofs for sets of atoms. Such sets of rules will be called witnesses and are the focus of this article. We study complexity issues of computing various witnesses and provide algorithms for computing them. In particular, we show that the problem is tractable for normal and headcycle-free disjunctive logic programs, but intractable for general disjunctive logic programs. We also conducted some experiments and found that for many well-known ASP and SAT benchmarks, computing a minimal witness for an atom of an answer set is often feasible.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4306873650",
    "type": "article"
  },
  {
    "title": "Eager Equality for Rational Number Arithmetic",
    "doi": "https://doi.org/10.1145/3580365",
    "publication_date": "2023-01-17",
    "publication_year": 2023,
    "authors": "J.A. Bergstra; John V. Tucker",
    "corresponding_authors": "",
    "abstract": "Eager equality for algebraic expressions over partial algebras distinguishes or separates terms only if both have defined values and they are different. We consider arithmetical algebras with division as a partial operator, called meadows, and focus on algebras of rational numbers. To study eager equality, we use common meadows, which are totalisations of partial meadows by means of absorptive elements. An axiomatisation of common meadows is the basis of an axiomatisation of eager equality as a predicate on a common meadow. Applied to the rational numbers, we prove completeness and decidability of the equational theory of eager equality. To situate eager equality theoretically, we consider two other partial equalities of increasing strictness: Kleene equality, which is equivalent to the native equality of common meadows, and one we call cautious equality. Our methods of analysis for eager equality are quite general, and so we apply them to these two other partial equalities; and, in addition to common meadows, we use three other kinds of algebra designed to totalise division. In summary, we are able to compare 13 forms of equality for the partial meadow of rational numbers. We focus on the decidability of the equational theories of these equalities. We show that for the four total algebras, eager and cautious equality are decidable. We also show that for others the Diophantine Problem over the rationals is one-one computably reducible to their equational theories. The Diophantine Problem for rationals is a longstanding open problem. Thus, eager equality has substantially less complex semantics.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4316813701",
    "type": "article"
  },
  {
    "title": "Interpolation Results for Arrays with Length and MaxDiff",
    "doi": "https://doi.org/10.1145/3587161",
    "publication_date": "2023-03-13",
    "publication_year": 2023,
    "authors": "Silvio Ghilardi; Alessandro Gianola; Deepak Kapur; Chiara Naso",
    "corresponding_authors": "",
    "abstract": "In this article, we enrich McCarthy’s theory of extensional arrays with a length and a maxdiff operation. As is well-known, some diff operation (i.e., some kind of difference function showing where two unequal arrays differ) is needed to keep interpolants quantifier free in array theories. Our maxdiff operation returns the max index where two arrays differ; thus, it has a univocally determined semantics. The length function is a natural complement of such a maxdiff operation and is needed to handle real arrays. Obtaining interpolation results for such a rich theory is a surprisingly hard task. We get such results via a thorough semantic analysis of the models of the theory and of their amalgamation and strong amalgamation properties. The results are modular with respect to the index theory; we show how to convert them into concrete interpolation algorithms via a hierarchical approach realizing a polynomial reduction to interpolation in linear arithmetics endowed with free function symbols.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4324057024",
    "type": "article"
  },
  {
    "title": "Living without Beth and Craig: Definitions and Interpolants in Description and Modal Logics with Nominals and Role Inclusions",
    "doi": "https://doi.org/10.1145/3597301",
    "publication_date": "2023-06-03",
    "publication_year": 2023,
    "authors": "Alessandro Artale; Jean Christoph Jung; Andrea Mazzullo; Ana Ozaki; Frank Wolter",
    "corresponding_authors": "",
    "abstract": "The Craig interpolation property (CIP) states that an interpolant for an implication exists iff it is valid. The projective Beth definability property (PBDP) states that an explicit definition exists iff a formula stating implicit definability is valid. Thus, the CIP and PBDP reduce potentially hard existence problems to entailment in the underlying logic. Description (and modal) logics with nominals and/or role inclusions do not enjoy the CIP nor the PBDP, but interpolants and explicit definitions have many applications, in particular in concept learning, ontology engineering, and ontology-based data management. In this article, we show that, even without Beth and Craig, the existence of interpolants and explicit definitions is decidable in description logics with nominals and/or role inclusions such as 𝒜ℒ𝒞𝒪, 𝒜ℒ𝒞ℋ, and 𝒜ℒ𝒞ℋ𝒪ℐ and corresponding hybrid modal logics. However, living without Beth and Craig makes these problems harder than entailment: the existence problems become 2ExpTime -complete in the presence of an ontology or the universal modality, and coNExpTime -complete otherwise. We also analyze explicit definition existence if all symbols (except the one that is defined) are admitted in the definition. In this case, the complexity depends on whether one considers individual or concept names. Finally, we consider the problem of computing interpolants and explicit definitions if they exist and turn the complexity upper bound proof into an algorithm computing them, at least for description logics with role inclusions.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4379209226",
    "type": "article"
  },
  {
    "title": "Complexity of propositional nested circumscription and nested abnormality theories",
    "doi": "https://doi.org/10.1145/1055686.1055688",
    "publication_date": "2005-04-01",
    "publication_year": 2005,
    "authors": "Marco Cadoli; Thomas Eiter; Georg Gottlob",
    "corresponding_authors": "",
    "abstract": "Circumscription has been recognized as an important principle for knowledge representation and common-sense reasoning. The need for a circumscriptive formalism that allows for simple yet elegant modular problem representation has led Lifschitz (AIJ, 1995) to introduce nested abnormality theories (NATs) as a tool for modular knowledge representation, tailored for applying circumscription to minimize exceptional circumstances. Abstracting from this particular objective, we propose L CIRC , which is an extension of generic propositional circumscription by allowing propositional combinations and nesting of circumscriptive theories. As shown, NATs are naturally embedded into this language, and are in fact of equal expressive capability. We then analyze the complexity of L CIRC and NATs, and in particular the effect of nesting. The latter is found to be a source of complexity, which climbs the Polynomial Hierarchy as the nesting depth increases and reaches PSPACE-completeness in the general case. We also identify meaningful syntactic fragments of NATs which have lower complexity. In particular, we show that the generalization of Horn circumscription in the NAT framework remains coNP-complete, and that Horn NATs without fixed letters can be efficiently transformed into an equivalent Horn CNF, which implies polynomial solvability of principal reasoning tasks. Finally, we also study extensions of NATs and briefly address the complexity in the first-order case. Our results give insight into the “cost” of using L CIRC (respectively, NATs) as a host language for expressing other formalisms such as action theories, narratives, or spatial theories.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2033870590",
    "type": "article"
  },
  {
    "title": "Classes of term rewrite systems with polynomial confluence problems",
    "doi": "https://doi.org/10.1145/976706.976712",
    "publication_date": "2004-04-01",
    "publication_year": 2004,
    "authors": "Guillem Godoy; Robert Nieuwenhuis; Ashish Tiwari",
    "corresponding_authors": "",
    "abstract": "The confluence property of ground (i.e., variable-free) term rewrite systems (TRS) is well known to be decidable. This was proved independently in Dauchet et al. [1987, 1990] and in Oyamaguchi [1987] using tree automata techniques and ground tree transducer techniques (originated from this problem), yielding EXPTIME decision procedures (PSPACE for strings). Since then, and until last year, the optimality of this bound had been a well-known longstanding open question (see, e.g., RTA-LOOP [2001]).In Comon et al. [2001], we gave the first polynomial-time algorithm for deciding the confluence of ground TRS. Later in Tiwari [2002] this result was extended, using abstract congruent closure techniques, to linear shallow TRS, that is, TRS where no variable occurs twice in the same rule nor at depth greater than one. Here, we give a new and much simpler proof of the latter result.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2036269369",
    "type": "article"
  },
  {
    "title": "A new decidability technique for ground term rewriting systems with applications",
    "doi": "https://doi.org/10.1145/1042038.1042042",
    "publication_date": "2005-01-01",
    "publication_year": 2005,
    "authors": "Rakesh Verma; Ara Hayrapetyan",
    "corresponding_authors": "",
    "abstract": "Programming language interpreters, proving equations (e.g. x 3 = x implies the ring is Abelian), abstract data types, program transformation and optimization, and even computation itself (e.g., turing machine) can all be specified by a set of rules, called a rewrite system. Two fundamental properties of a rewrite system are the confluence or Church--Rosser property and the unique normalization property. In this article, we develop a standard form for ground rewrite systems and the concept of standard rewriting. These concepts are then used to: prove a pumping lemma for them, and to derive a new and direct decidability technique for decision problems of ground rewrite systems. To illustrate the usefulness of these concepts, we apply them to prove: (i) polynomial size bounds for witnesses to violations of unique normalization and confluence for ground rewrite systems containing unary symbols and constants, and (ii) polynomial height bounds for witnesses to violations of unique normalization and confluence for arbitrary ground systems. Apart from the fact that our technique is direct in contrast to previous decidability results for both problems, which were indirectly obtained using tree automata techniques, this approach also yields tighter bounds for rewrite systems with unary symbols than the ones that can be derived with the indirect approach. Finally, as part of our results, we give a polynomial-time algorithm for checking whether a rewrite system has the unique normalization property for all subterms in the rules of the system.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2050856006",
    "type": "article"
  },
  {
    "title": "About the undecidability of program equivalence in finitary languages with state",
    "doi": "https://doi.org/10.1145/1094622.1094626",
    "publication_date": "2005-10-01",
    "publication_year": 2005,
    "authors": "Andrzej S. Murawski",
    "corresponding_authors": "Andrzej S. Murawski",
    "abstract": "We show how game semantics can be employed to prove that program equivalence in finitary Idealized Algol with active expressions is undecidable. We also investigate a notion of representability of languages by terms and show that finitary Idealized Algol terms of respectively second, third and higher orders define exactly regular, context-free and recursively enumerable languages.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W1968041547",
    "type": "article"
  },
  {
    "title": "Comprehending software correctness implies comprehending an intelligence-related limitation",
    "doi": "https://doi.org/10.1145/1149114.1149119",
    "publication_date": "2006-07-01",
    "publication_year": 2006,
    "authors": "Arthur Charlesworth",
    "corresponding_authors": "Arthur Charlesworth",
    "abstract": "This article applies mathematical logic to obtain a rigorous foundation for previous inherently nonrigorous results and also extends those previous results. Roughly speaking, our main theorem states: any agent A that comprehends the correctness-related properties of software S also comprehends an intelligence-related limitation of S . The theorem treats the output of S , if any, as an attempt at solving a halting problem. Previous nonrigorous attempts to obtain similar theorems depend on infallibility assumptions on both the agent and the software. The hypothesis that intelligent agents and intelligent software must be infallible has been widely questioned. In addition, recent work by others has determined that well-known previous attempts use a fallacious form of reasoning; that is, the same form of reasoning can yield paradoxical results. Our main theorem avoids infallibility assumptions on both the agent and the software. In addition, our proof is rigorous, in the sense that in principle one can carry it out in Zermelo-Fraenkel set theory. The software correctness framework considered in the main theorem is that of Hoare logic.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W1998541552",
    "type": "article"
  },
  {
    "title": "Efficient solving of quantified inequality constraints over the real numbers",
    "doi": "https://doi.org/10.1145/1166109.1166113",
    "publication_date": "2006-10-01",
    "publication_year": 2006,
    "authors": "Stefan Ratschan",
    "corresponding_authors": "Stefan Ratschan",
    "abstract": "Let a quantified inequality constraint over the reals be a formula in the first-order predicate language over the structure of the real numbers, where the allowed predicate symbols are ≤ and <. Solving such constraints is an undecidable problem when allowing function symbols such sin or cos. In this article, we give an algorithm that terminates with a solution for all, except for very special, pathological inputs. We ensure the practical efficiency of this algorithm by employing constraint programming techniques.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2953183575",
    "type": "article"
  },
  {
    "title": "Foundational certified code in the Twelf metalogical framework",
    "doi": "https://doi.org/10.1145/1352582.1352584",
    "publication_date": "2008-06-01",
    "publication_year": 2008,
    "authors": "Karl Crary; Susmit Sarkar",
    "corresponding_authors": "",
    "abstract": "Foundational certified code systems seek to prove untrusted programs to be safe relative to safety policies given in terms of actual machine architectures, thereby improving the systems' flexibility and extensibility. Using the Twelf metalogical framework, we have constructed a safety policy for the IA-32 architecture with a trusted runtime library. The safety policy is based on a formalized operational semantics. We have also developed a complete, foundational proof that a fully expressive typed assembly language satisfies that safety policy.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2019626854",
    "type": "article"
  },
  {
    "title": "A compositional semantics for CHR",
    "doi": "https://doi.org/10.1145/1462179.1462183",
    "publication_date": "2009-02-01",
    "publication_year": 2009,
    "authors": "Maurizio Gabbrielli; Maria Chiara Meo",
    "corresponding_authors": "",
    "abstract": "Constraint Handling Rules (CHR) is a committed-choice declarative language which has been designed for writing constraint solvers. A CHR program consists of multiheaded guarded rules which allow to rewrite constraints into simpler ones until a solved form is reached. CHR has received considerable attention, both from the practical and from the theoretical side. Nevertheless, due the use of multiheaded clauses, there are several aspects of the CHR semantics which have not been clarified yet. In particular, no compositional semantics for CHR has been defined so far. In this article we introduce a fix-point semantics which characterizes the input/output behavior of a CHR program and which is and-compositional, that is, which allows to retrieve the semantics of a conjunctive query from the semantics of its components. Such a semantics can be used as a basis to define incremental and modular analysis and verification tools.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2045796613",
    "type": "article"
  },
  {
    "title": "Typing Messages for Free in Security Protocols",
    "doi": "https://doi.org/10.1145/3343507",
    "publication_date": "2019-09-12",
    "publication_year": 2019,
    "authors": "Rémy Chrétien; Véronique Cortier; Antoine Dallon; Stéphanie Delaune",
    "corresponding_authors": "",
    "abstract": "Security properties of cryptographic protocols are typically expressed as reachability or equivalence properties. Secrecy and authentication are examples of reachability properties, while privacy properties such as untraceability, vote secrecy, or anonymity are generally expressed as behavioral equivalence in a process algebra that models security protocols. Our main contribution is to reduce the search space for attacks for reachability as well as equivalence properties. Specifically, we show that if there is an attack then there is one that is well-typed. Our result holds for a large class of typing systems, a family of equational theories that encompasses all standard primitives, and protocols without else branches. For many standard protocols, we deduce that it is sufficient to look for attacks that follow the format of the messages expected in an honest execution, therefore considerably reducing the search space.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2797326439",
    "type": "article"
  },
  {
    "title": "On the Verification of Livelock-Freedom and Self-Stabilization on Parameterized Rings",
    "doi": "https://doi.org/10.1145/3326456",
    "publication_date": "2019-06-05",
    "publication_year": 2019,
    "authors": "Alex Klinkhamer; Ali Ebnenasir",
    "corresponding_authors": "",
    "abstract": "This article investigates the verification of livelock-freedom and self-stabilization on parameterized rings consisting of symmetric, constant space, deterministic, and self-disabling processes. The results of this article have a significant impact on several fields, including scalable distributed systems, resilient and self- * systems, and verification of parameterized systems. First, we identify necessary and sufficient local conditions for the existence of global livelocks in parameterized unidirectional rings with unbounded (but finite) number of processes under the interleaving semantics. Using a reduction from the periodic domino problem, we show that, in general, verifying livelock-freedom of parameterized unidirectional rings is undecidable (specifically, Π 1 0 -complete) even for constant space, deterministic, and self-disabling processes. This result implies that verifying self-stabilization for parameterized rings of self-disabling processes is also undecidable. We also show that verifying livelock-freedom and self-stabilization remain undecidable under (1) synchronous execution semantics, (2) the FIFO consistency model, and (3) any scheduling policy. We then present a new scope-based method for detecting and constructing livelocks in parameterized rings. The proposed semi-algorithm behind our scope-based verification is based on a novel paradigm for the detection of livelocks that totally circumvents state space exploration. Our experimental results on an implementation of the proposed semi-algorithm are very promising as we have found livelocks in parameterized rings in a few microseconds on a regular laptop. The results of this article have significant implications for scalable distributed systems with cyclic topologies.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2951238781",
    "type": "article"
  },
  {
    "title": "Tractability Frontier of Data Complexity in Team Semantics",
    "doi": "https://doi.org/10.1145/3471618",
    "publication_date": "2021-10-22",
    "publication_year": 2021,
    "authors": "Arnaud Durand; Juha Kontinen; Nicolas de Rugy-Altherre; Jouko Väänánen",
    "corresponding_authors": "",
    "abstract": "We study the data complexity of model checking for logics with team semantics. We focus on dependence, inclusion, and independence logic formulas under both strict and lax team semantics. Our results delineate a clear tractability/intractability frontiers in data complexity of both quantifier-free and quantified formulas for each of the logics. For inclusion logic under the lax semantics, we reduce the model-checking problem to the satisfiability problem of so-called dual-Horn Boolean formulas. Via this reduction, we give an alternative proof for the known result that the data complexity of inclusion logic is in PTIME.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2962851006",
    "type": "article"
  },
  {
    "title": "The formal system lambdadelta.",
    "doi": null,
    "publication_date": "2009-01-01",
    "publication_year": 2009,
    "authors": "Ferruccio Guidi",
    "corresponding_authors": "Ferruccio Guidi",
    "abstract": "",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2963225861",
    "type": "article"
  },
  {
    "title": "The Bernays-Schönfinkel-Ramsey Class of Separation Logic with Uninterpreted Predicates",
    "doi": "https://doi.org/10.1145/3380809",
    "publication_date": "2020-03-02",
    "publication_year": 2020,
    "authors": "Mnacho Echenim; Radu Iosif; Nicolas Peltier",
    "corresponding_authors": "",
    "abstract": "This article investigates the satisfiability problem for Separation Logic with k record fields, with unrestricted nesting of separating conjunctions and implications. It focuses on prenex formulæ with a quantifier prefix in the language ∃*∀* that contain uninterpreted (heap-independent) predicate symbols. In analogy with first-order logic, we call this fragment Bernays-Schönfinkel-Ramsey Separation Logic [BSR(SL k )]. In contrast with existing work on Separation Logic, in which the universe of possible locations is assumed to be infinite, we consider both finite and infinite universes in the present article. We show that, unlike in first-order logic, the (in)finite satisfiability problem is undecidable for BSR(SL k ). Then we define two non-trivial subsets thereof, for which the finite and infinite satisfiability problems are PSPACE-complete, respectively, assuming that the maximum arity of the uninterpreted predicate symbols does not depend on the input. These fragments are defined by controlling the polarity of the occurrences of separating implications, as well as the occurrences of universally quantified variables within their scope. These decidability results have natural applications in program verification, as they allow to automatically prove lemmas that occur in, e.g., entailment checking between inductively defined predicates and validity checking of Hoare triples expressing partial correctness conditions.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2992863903",
    "type": "article"
  },
  {
    "title": "The Power of the Weak",
    "doi": "https://doi.org/10.1145/3372392",
    "publication_date": "2020-01-09",
    "publication_year": 2020,
    "authors": "Facundo Carreiro; Alessandro Facchini; Yde Venema; Fabio Zanasi",
    "corresponding_authors": "",
    "abstract": "A landmark result in the study of logics for formal verification is Janin and Walukiewicz’s theorem, stating that the modal μ-calculus (μML) is equivalent modulo bisimilarity to standard monadic second-order logic (here abbreviated as SMSO) over the class of labelled transition systems (LTSs for short). Our work proves two results of the same kind, one for the alternation-free or noetherian fragment μ N ML of μML on the modal side and one for WMSO, weak monadic second-order logic, on the second-order side. In the setting of binary trees, with explicit functions accessing the left and right successor of a node, it was known that WMSO is equivalent to the appropriate version of alternation-free μ-calculus. Our analysis shows that the picture changes radically once we consider, as Janin and Walukiewicz did, the standard modal μ-calculus, interpreted over arbitrary LTSs. The first theorem that we prove is that, over LTSs, μ N ML is equivalent modulo bisimilarity to noetherian MSO (NMSO), a newly introduced variant of SMSO where second-order quantification ranges over “conversely well-founded” subsets only. Our second theorem starts from WMSO and proves it equivalent modulo bisimilarity to a fragment of μ N ML defined by a notion of continuity. Analogously to Janin and Walukiewicz’s result, our proofs are automata-theoretic in nature: As another contribution, we introduce classes of parity automata characterising the expressiveness of WMSO and NMSO (on tree models) and of μ C ML and μ N ML (for all transition systems).",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2999779760",
    "type": "article"
  },
  {
    "title": "Display to Labeled Proofs and Back Again for Tense Logics",
    "doi": "https://doi.org/10.1145/3460492",
    "publication_date": "2021-06-28",
    "publication_year": 2021,
    "authors": "Agata Ciabattoni; Tim S. Lyon; Revantha Ramanayake; Alwen Tiu",
    "corresponding_authors": "",
    "abstract": "We introduce translations between display calculus proofs and labeled calculus proofs in the context of tense logics. First, we show that every derivation in the display calculus for the minimal tense logic Kt extended with general path axioms can be effectively transformed into a derivation in the corresponding labeled calculus. Concerning the converse translation, we show that for Kt extended with path axioms, every derivation in the corresponding labeled calculus can be put into a special form that is translatable to a derivation in the associated display calculus. A key insight in this converse translation is a canonical representation of display sequents as labeled polytrees. Labeled polytrees, which represent equivalence classes of display sequents modulo display postulates, also shed light on related correspondence results for tense logics.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W3175155954",
    "type": "article"
  },
  {
    "title": "1-Safe Petri Nets and Special Cube Complexes",
    "doi": "https://doi.org/10.1145/3322095",
    "publication_date": "2019-07-16",
    "publication_year": 2019,
    "authors": "Jérémie Chalopin; Victor Chepoi",
    "corresponding_authors": "",
    "abstract": "Nielsen et al. [35] proved that every 1-safe Petri net N unfolds into an event structure E N . By a result of Thiagarajan [46], these unfoldings are exactly the trace-regular event structures. Thiagarajan [46] conjectured that regular event structures correspond exactly to trace-regular event structures. In a recent paper (Chalopin and Chepoi [12]), we disproved this conjecture, based on the striking bijection between domains of event structures, median graphs, and CAT(0) cube complexes. However, we proved that Thiagarajan’s conjecture is true for regular event structures whose domains are principal filters of universal covers of finite special cube complexes. In the current article, we prove the converse: To any finite 1-safe Petri net N , one can associate a finite special cube complex X N such that the domain of the event structure E N (obtained as the unfolding of N ) is a principal filter of the universal cover X̃ N of X N . This establishes a bijection between 1-safe Petri nets and finite special cube complexes and provides a combinatorial characterization of trace-regular event structures. Using this bijection and techniques from graph theory and geometry (MSO theory of graphs, bounded treewidth, and bounded hyperbolicity), we disprove yet another conjecture by Thiagarajan (from the paper with Yang [48]) that the monadic second-order logic of a 1-safe Petri net (i.e., of its event structure unfolding) is decidable if and only if its unfolding is grid-free. It was proven by Thiagarajan and Yang [48] that the MSO logic is undecidable if the unfolding is not grid-free. Our counterexample is the trace-regular event structure that arises from a virtually special square complex Z. The domain of this event structure Ė Z is the principal filter of the universal cover Z̃ of Z in which to each vertex we added a pendant edge. The graph of the domain of Ė Z has bounded hyperbolicity (and, thus, the event structure Ė Z is grid-free) but has infinite treewidth. Using results of Seese, Courcelle, and Müller and Schupp, we show that this implies that the MSO theory of the event structure Ė Z is undecidable.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4288281500",
    "type": "article"
  },
  {
    "title": "On the Expressive Power of Multiple Heads in CHR",
    "doi": "https://doi.org/10.1145/2071368.2071374",
    "publication_date": "2012-01-01",
    "publication_year": 2012,
    "authors": "Cinzia Di Giusto; Maurizio Gabbrielli; Maria Chiara Meo",
    "corresponding_authors": "",
    "abstract": "Constraint Handling Rules (CHR) is a committed-choice declarative language that has been originally designed for writing constraint solvers and is nowadays a general purpose language. CHR programs consist of multiheaded guarded rules which allow to rewrite constraints into simpler ones until a solved form is reached. Many empirical evidences suggest that multiple heads augment the expressive power of the language, however no formal result in this direction has been proved, so far. In the first part of this article we analyze the Turing completeness of CHR with respect to the underlying constraint theory. We prove that if the constraint theory is powerful enough then restricting to single head rules does not affect the Turing completeness of the language. On the other hand, differently from the case of the multiheaded language, the single head CHR language is not Turing powerful when the underlying signature (for the constraint theory) does not contain function symbols. In the second part we prove that, no matter which constraint theory is considered, under some reasonable assumptions it is not possible to encode the CHR language (with multi-headed rules) into a single headed language while preserving the semantics of the programs. We also show that, under some stronger assumptions, considering an increasing number of atoms in the head of a rule augments the expressive power of the language. These results provide a formal proof for the claim that multiple heads augment the expressive power of the CHR language.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2021215313",
    "type": "article"
  },
  {
    "title": "Logical foundations for more expressive declarative temporal logic programming languages",
    "doi": "https://doi.org/10.1145/2528931",
    "publication_date": "2013-11-01",
    "publication_year": 2013,
    "authors": "Jose Gaintzarain; Paqui Lucio",
    "corresponding_authors": "",
    "abstract": "In this article, we present a declarative propositional temporal logic programming language called TeDiLog that is a combination of the temporal and disjunctive paradigms in logic programming. TeDiLog is, syntactically, a sublanguage of the well-known Propositional Linear-time Temporal Logic (PLTL). TeDiLog allows both eventualities and always-formulas to occur in clause heads and also in clause bodies. To the best of our knowledge, TeDiLog is the first declarative temporal logic programming language that achieves this high degree of expressiveness. We establish the logical foundations of our proposal by formally defining operational and logical semantics for TeDiLog and by proving their equivalence. The operational semantics of TeDiLog relies on a restriction of the invariant-free temporal resolution procedure for PLTL that was introduced by Gaintzarain et al. in [2013]. We define a fixpoint semantics that captures the reverse (bottom-up) operational mechanism and prove its equivalence with the logical semantics. We also provide illustrative examples and comparison with other proposals.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2065468698",
    "type": "article"
  },
  {
    "title": "The Complexity of Positive First-Order Logic without Equality",
    "doi": "https://doi.org/10.1145/2071368.2071373",
    "publication_date": "2012-01-01",
    "publication_year": 2012,
    "authors": "Florent Madelaine; Barnaby Martin",
    "corresponding_authors": "",
    "abstract": "We study the complexity of evaluating positive equality-free sentences of first-order (FO) logic over a fixed, finite structure B . This may be seen as a natural generalisation of the nonuniform quantified constraint satisfaction problem QCSP( B ). We introduce surjective hyper-endomorphisms and use them in proving a Galois connection that characterizes definability in positive equality-free FO. Through an algebraic method, we derive a complete complexity classification for our problems as B ranges over structures of size at most three. Specifically, each problem either is in L, is NP-complete, is co-NP-complete, or is Pspace-complete.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2113995039",
    "type": "article"
  },
  {
    "title": "Graph Reachability and Pebble Automata over Infinite Alphabets",
    "doi": "https://doi.org/10.1145/2499937.2499940",
    "publication_date": "2013-08-01",
    "publication_year": 2013,
    "authors": "Tony Tan",
    "corresponding_authors": "Tony Tan",
    "abstract": "Let D denote an infinite alphabet -- a set that consists of infinitely many symbols. A word w = a 0 b 0 a 1 b 1 ⋯ a n b n of even length over D can be viewed as a directed graph G w whose vertices are the symbols that appear in w , and the edges are ( a 0 , b 0 ), ( a 1 , b 1 ), ..., ( a n , b n ). For a positive integer m , define a language R m such that a word w = a 0 b 0 ⋯ a n b n ∈ R m if and only if there is a path in the graph G w of length ≤ m from the vertex a 0 to the vertex b n . We establish the following hierarchy theorem for pebble automata over infinite alphabet. For every positive integer k , (i) there exists a k -pebble automaton that accepts the language R 2k − 1 ; (ii) there is no k -pebble automaton that accepts the language R 2k + 1 − 2 . Using this fact, we establish the following main results in this article: (a) a strict hierarchy of the pebble automata languages based on the number of pebbles; (b) the separation of monadic second order logic from the pebble automata languages; (c) the separation of one-way deterministic register automata languages from pebble automata languages.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2164433662",
    "type": "article"
  },
  {
    "title": "Datalog Queries Distributing over Components",
    "doi": "https://doi.org/10.1145/3022743",
    "publication_date": "2017-01-31",
    "publication_year": 2017,
    "authors": "Tom J. Ameloot; Bas Ketsman; Frank Neven; Daniel Zinn",
    "corresponding_authors": "",
    "abstract": "We investigate the class D of queries that distribute over components. These are the queries that can be evaluated by taking the union of the query results over the connected components of the database instance. We show that it is undecidable whether a (positive) Datalog program distributes over components. Additionally, we show that connected Datalog¬ (the fragment of Datalog¬ where all rules are connected) provides an effective syntax for Datalog¬ programs that distribute over components under the stratified as well as under the well-founded semantics. As a corollary, we obtain a simple proof for one of the main results in previous work [Zinn et al. 2012], namely that the classic win-move query is in F 2 (a particular class of coordination-free queries).",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2593492066",
    "type": "article"
  },
  {
    "title": "Possibilistic Justification Logic",
    "doi": "https://doi.org/10.1145/3091118",
    "publication_date": "2017-04-30",
    "publication_year": 2017,
    "authors": "Che-Ping Su; Tuan-Fang Fan; Churn‐Jung Liau",
    "corresponding_authors": "",
    "abstract": "Justification logic originated from the study of the logic of proofs. However, in a more general setting, it may be regarded as a kind of explicit epistemic logic. In such logic, the reasons a fact is believed are explicitly represented as justification terms. Traditionally, the modeling of uncertain beliefs is crucially important for epistemic reasoning. Graded modal logics interpreted with possibility theory semantics have been successfully applied to the representation and reasoning of uncertain beliefs; however, they cannot keep track of the reasons an agent believes a fact. This article is aimed at extending the graded modal logics with explicit justifications. We introduce a possibilistic justification logic, present its syntax and semantics, and investigate its metaproperties, such as soundness, completeness, and realizability.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2621139739",
    "type": "article"
  },
  {
    "title": "Detecting Decidable Classes of Finitely Ground Logic Programs with Function Symbols",
    "doi": "https://doi.org/10.1145/3143804",
    "publication_date": "2017-10-31",
    "publication_year": 2017,
    "authors": "Marco Calautti; Sergio Greco; Irina Trubitsyna",
    "corresponding_authors": "",
    "abstract": "In this article, we propose a new technique for checking whether the bottom-up evaluation of logic programs with function symbols terminates. The technique is based on the definition of mappings from arguments to strings of function symbols, representing possible values which could be taken by arguments during the bottom-up evaluation. Starting from mappings, we identify mapping-restricted arguments, a subset of limited arguments, namely arguments that take values from finite domains. Mapping-restricted programs, consisting of rules whose arguments are all mapping restricted, are terminating under the bottom-up computation, as all of its arguments take values from finite domains. We show that mappings can be computed by transforming the original program into a unary logic program: this allows us to establish decidability of checking if a program is mapping restricted. We study the complexity of the presented approach and compare it to other techniques known in the literature. We also introduce an extension of the proposed approach that is able to recognize a wider class of logic programs. The presented technique provides a significant improvement, as it can detect terminating programs not identified by other criteria proposed so far. Furthermore, it can be combined with other techniques to further enlarge the class of programs recognized as terminating under the bottom-up evaluation.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2769306164",
    "type": "article"
  },
  {
    "title": "An Effective Characterization of the Alternation Hierarchy in Two-Variable Logic",
    "doi": "https://doi.org/10.1145/3149822",
    "publication_date": "2017-10-31",
    "publication_year": 2017,
    "authors": "Andreas Krebs; Howard Straubing",
    "corresponding_authors": "",
    "abstract": "We give an algebraic characterization, based on the bilateral semidirect product of finite monoids, of the quantifier alternation hierarchy in two-variable first-order logic on finite words. As a consequence, we obtain a new proof that this hierarchy is strict. Moreover, by application of the theory of finite categories, we are able to make our characterization effective: that is, there is an algorithm for determining the exact quantifier alternation depth for a given language definable in two-variable logic.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2963384346",
    "type": "article"
  },
  {
    "title": "The Hoare Logic of Deterministic and Nondeterministic Monadic Recursion Schemes",
    "doi": "https://doi.org/10.1145/2835491",
    "publication_date": "2016-01-07",
    "publication_year": 2016,
    "authors": "Konstantinos Mamouras",
    "corresponding_authors": "Konstantinos Mamouras",
    "abstract": "The equational theory of deterministic monadic recursion schemes is known to be decidable by the result of Sénizergues on the decidability of the problem of DPDA equivalence. In order to capture some properties of the domain of computation, we augment equations with certain hypotheses. This preserves the decidability of the theory, which we call simple implicational theory . The asymptotically fastest algorithm known for deciding the equational theory, and also for deciding the simple implicational theory, has a running time that is nonelementary. We therefore consider a restriction of the properties about schemes to check: instead of arbitrary equations f ≡ g between schemes, we focus on propositional Hoare assertions { p } f { q }, where f is a scheme and p , q are tests. Such Hoare assertions have a straightforward encoding as equations. For this subclass of program properties, we can also handle nondeterminism at the syntactic and/or at the semantic level, without increasing the complexity of the theories. We investigate the Hoare theory of monadic recursion schemes, that is, the set of valid implications whose conclusions are Hoare assertions and whose premises are of a certain simple form. We present a sound and complete Hoare-style calculus for this theory. We also show that the Hoare theory can be decided in exponential time, and that it is complete for this class.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2228757736",
    "type": "article"
  },
  {
    "title": "Logics capturing local properties",
    "doi": "https://doi.org/10.1145/371282.371388",
    "publication_date": "2001-01-01",
    "publication_year": 2001,
    "authors": "Leonid Libkin",
    "corresponding_authors": "Leonid Libkin",
    "abstract": "Well-known theorems of Hanf and Gaifman establishing locality of first-order definable properties have been used in many applications. These theorems were recently generalized to other logics, which led to new applications in descriptive complexity and database theory. However, a logical characterization of local properties that correspond to Hanf's and Gaifman's theorems is still lacking. Such a characterization only exists for structures of bounded valence. In this paper, we give logical characterizations of local properties behind Hanf's and Gaifman's theorems. We first deal with an infinitary logic with counting terms and quantifiers that is known to capture Hanf-locality on structures of bounded valence. We show that testing isomorphism of neighborhoods can be added to it without violating Hanf-locality, while increasing its expressive power. We then show that adding local second-order quantification to it caputures precisely all Hanf-local properties. To capture Gaifman-locality, one must also add a (potentially infinite) case statement. We further show that the hierarchy based on the number of variants in the case statement is strict.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2000222614",
    "type": "article"
  },
  {
    "title": "Termination of simply moded logic programs with dynamic scheduling",
    "doi": "https://doi.org/10.1145/1013560.1013564",
    "publication_date": "2004-07-01",
    "publication_year": 2004,
    "authors": "Annalisa Bossi; Sandro Etalle; Sabina Rossi; Jan‐Georg Smaus",
    "corresponding_authors": "",
    "abstract": "In logic programming, dynamic scheduling indicates the feature by means of which the choice of the atom to be selected at each resolution step is done at runtime and does not follow a fixed selection rule such as the left-to-right one of Prolog. Input-consuming derivations were introduced to model dynamic scheduling while abstracting from the technical details. In this article, we provide a sufficient and necessary criterion for termination of input-consuming derivations of simply moded logic programs. The termination criterion we propose is based on a denotational semantics for partial derivations which is defined in the spirit of model-theoretic semantics previously proposed for left-to-right derivations.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2154930848",
    "type": "article"
  },
  {
    "title": "Datalog programs and their persistency numbers",
    "doi": "https://doi.org/10.1145/1071596.1071597",
    "publication_date": "2005-07-01",
    "publication_year": 2005,
    "authors": "Foto Afrati; Stavros S. Cosmadakis; Eugénie Foustoucos",
    "corresponding_authors": "",
    "abstract": "The relation between Datalog programs and homomorphism problems and between Datalog programs and bounded treewidth structures has been recognized for some time and given much attention recently. Additionally, the essential role of persistent variables (of program expansions) in solving several relevant problems has also started to be observed. It turns out that to understand the contribution of these persistent variables to the difficulty of some expressibility problems, we need to understand the interrelationship among different notions of persistency numbers , some of which we introduce and/or formalize in the present work.This article is a first foundational study of the various persistency numbers and their interrelationships. To prove the relations among these persistency numbers, we had to develop some nontrivial technical tools that promise to help in proving other interesting results too. More precisely, we define the adorned dependency graph of a program , a useful tool for visualizing sets of persistent variables, and we define automata that recognize persistent sets in expansions.We start by elaborating on finer definitions of expansions and queries, which capture aspects of homomorphism problems on bounded treewidth structures. The main results of this article are (a) a program transformation technique, based on automata-theoretic tools, which manipulates persistent variables (leading, in certain cases, to programs of fewer persistent variables); (b) a categorization of the different roles of persistent variables; this is done by defining four notions of persistency numbers which capture the propagation of persistent variables from a syntactical level to a semantical one; (c) decidability results concerning the syntactical notions of persistency numbers that we have defined; and (d) the exhibition of new classes of programs for which boundedness is undecidable.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2069782013",
    "type": "article"
  },
  {
    "title": "Sound and complete elimination of singleton kinds",
    "doi": "https://doi.org/10.1145/1227839.1227840",
    "publication_date": "2007-04-01",
    "publication_year": 2007,
    "authors": "Karl Crary",
    "corresponding_authors": "Karl Crary",
    "abstract": "Singleton kinds provide an elegant device for expressing type equality information resulting from modern module languages, but they can complicate the metatheory of languages in which they appear. I present a translation from a language with singleton kinds to one without, and prove this translation to be sound and complete. This translation is useful for type-preserving compilers generating typed target languages. The proof of soundness and completeness is done by normalizing type equivalence derivations using Stone and Harper's type equivalence decision procedure.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2125422552",
    "type": "article"
  },
  {
    "title": "Generalizing consistency and other constraint properties to quantified constraints",
    "doi": "https://doi.org/10.1145/1507244.1507247",
    "publication_date": "2009-04-01",
    "publication_year": 2009,
    "authors": "Lucas Bordeaux; Marco Cadoli; Toni Mancini",
    "corresponding_authors": "",
    "abstract": "Quantified constraints and Quantified Boolean Formulae are typically much more difficult to reason with than classical constraints, because quantifier alternation makes the usual notion of solution inappropriate. As a consequence, basic properties of Constraint Satisfaction Problems (CSPs), such as consistency or substitutability, are not completely understood in the quantified case. These properties are important because they are the basis of most of the reasoning methods used to solve classical (existentially quantified) constraints, and it is desirable to benefit from similar reasoning methods in the resolution of quantified constraints. In this article, we show that most of the properties that are used by solvers for CSP can be generalized to quantified CSP. This requires a rethinking of a number of basic concepts; in particular, we propose a notion of outcome that generalizes the classical notion of solution and on which all definitions are based. We propose a systematic study of the relations which hold between these properties, as well as complexity results regarding the decision of these properties. Finally, and since these problems are typically intractable, we generalize the approach used in CSP and propose weaker, easier to check notions based on locality , which allow to detect these properties incompletely but in polynomial time.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2022485444",
    "type": "article"
  },
  {
    "title": "Duality between Unprovability and Provability in Forward Refutation-search for Intuitionistic Propositional Logic",
    "doi": "https://doi.org/10.1145/3372299",
    "publication_date": "2020-03-03",
    "publication_year": 2020,
    "authors": "Camillo Fiorentini; Mauro Ferrari",
    "corresponding_authors": "",
    "abstract": "The inverse method is a saturation-based theorem-proving technique; it relies on a forward proof-search strategy and can be applied to cut-free calculi enjoying the subformula property. Here, we apply this method to derive the unprovability of a goal formula G in Intuitionistic Propositional Logic. To this aim we design a forward calculus FRJ ( G ) for Intuitionistic unprovability, which is appropriate for constructively ascertaining the unprovability of a formula G by providing a concise countermodel for it; in particular, we prove that the generated countermodels have minimal height. Moreover, we clarify the role of the saturated database obtained as result of a failed proof-search in FRJ ( G ) by showing how to extract from such a database a derivation witnessing the Intuitionistic validity of the goal.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2798196221",
    "type": "article"
  },
  {
    "title": "A Simple Modal Logic for Reasoning in Multigranulation Rough Set Model",
    "doi": "https://doi.org/10.1145/3274664",
    "publication_date": "2018-10-31",
    "publication_year": 2018,
    "authors": "Md. Aquil Khan; Vineeta Singh Patel",
    "corresponding_authors": "",
    "abstract": "The notions of strong/weak approximations have been studied extensively in recent years. These approximations are based on a structure of the form ( W,{R i } i∈ N ), called the multiple-source approximation system, where R i is an equivalence relation on W , and N is an initial segment of the set N of natural numbers. We propose and explore a simple modal language and semantics that can be used to reason about the strong/weak approximations of concepts. Moreover, our study is not confined to collections of equivalence relations only, but other types of relations are also considered. This study is important, keeping in view the notions of generalized approximation spaces with relations other than equivalence.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2900488505",
    "type": "article"
  },
  {
    "title": "Satisfiability of Modal Inclusion Logic",
    "doi": "https://doi.org/10.1145/3356043",
    "publication_date": "2019-09-27",
    "publication_year": 2019,
    "authors": "Lauri Hella; Antti Kuusisto; Arne Meier; Heribert Vollmer",
    "corresponding_authors": "",
    "abstract": "We investigate the computational complexity of the satisfiability problem of modal inclusion logic. We distinguish two variants of the problem: one for the strict and another one for the lax semantics. Both problems turn out to be EXPTIME-complete on general structures. Finally, we show how for a specific class of structures NEXPTIME-completeness for these problems under strict semantics can be achieved.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2975393337",
    "type": "article"
  },
  {
    "title": "Dynamic QBF Dependencies in Reduction and Expansion",
    "doi": "https://doi.org/10.1145/3355995",
    "publication_date": "2019-11-17",
    "publication_year": 2019,
    "authors": "Olaf Beyersdorff; Joshua Blinkhorn",
    "corresponding_authors": "",
    "abstract": "We provide the first proof complexity results for QBF dependency calculi. By showing that the reflexive resolution path dependency scheme admits exponentially shorter Q-resolution proofs on a known family of instances, we answer a question first posed by Slivovsky and Szeider in 2014 [37]. Further, we conceive a method of QBF solving in which dependency recomputation is utilised as a form of inprocessing. Formalising this notion, we introduce a new version of Q-resolution in which a dependency scheme is applied dynamically. We demonstrate the further potential of this approach beyond that of the existing static system with an exponential separation. Last, we show that the same picture emerges in an analogous approach to the universal expansion paradigm.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2983793616",
    "type": "article"
  },
  {
    "title": "Arithmetic complexity via effective names for random sequences",
    "doi": "https://doi.org/10.1145/2287718.2287724",
    "publication_date": "2012-08-01",
    "publication_year": 2012,
    "authors": "Bjørn Kjos-Hanssen; Frank Stephan; Jason Teutsch",
    "corresponding_authors": "",
    "abstract": "We investigate enumerability properties for classes of sets which permit recursive, lexicographically increasing approximations, or left-r.e. sets. In addition to pinpointing the complexity of left-r.e. Martin-L\\\"{o}f, computably, Schnorr, and Kurtz random sets, weakly 1-generics and their complementary classes, we find that there exist characterizations of the third and fourth levels of the arithmetic hierarchy purely in terms of these notions. More generally, there exists an equivalence between arithmetic complexity and existence of numberings for classes of left-r.e. sets with shift-persistent elements. While some classes (such as Martin-L\\\"{o}f randoms and Kurtz non-randoms) have left-r.e. numberings, there is no canonical, or acceptable, left-r.e. numbering for any class of left-r.e. randoms. Finally, we note some fundamental differences between left-r.e. numberings for sets and reals.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W1964546061",
    "type": "article"
  },
  {
    "title": "Super-Solutions",
    "doi": "https://doi.org/10.1145/2627354",
    "publication_date": "2014-07-08",
    "publication_year": 2014,
    "authors": "Cristian Molinaro; Amy Sliva; V. S. Subrahmanian",
    "corresponding_authors": "",
    "abstract": "Annotated Probabilistic Temporal (APT) logic programs are a form of logic programs that allow users to state (or systems to automatically learn) rules of the form “formula G becomes true Δ t time units after formula F became true with ℓ to u % probability.” In this article, we deal with abductive reasoning in APT logic: given an APT logic program Π, a set of formulas H that can be “added” to Π, and a (temporal) goal g , is there a subset S of H such that Π ∪ S is consistent and entails the goal g ? In general, there are many different solutions to the problem and some of them can be highly repetitive, differing only in some unimportant temporal aspects. We propose a compact representation called super-solutions that succinctly represent sets of such solutions. Super-solutions are compact, but lossless representations of sets of such solutions. We study the complexity of existence of basic, super-, and maximal super-solutions as well as check if a set is a solution/super-solution/maximal super-solution. We then leverage a geometric characterization of the problem to suggest a set of pruning strategies and interesting properties that can be leveraged to make the search of basic and super-solutions more efficient. We propose correct sequential algorithms to find solutions and super-solutions. In addition, we develop parallel algorithms to find basic and super-solutions.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W1994852375",
    "type": "article"
  },
  {
    "title": "Optimal Tableau Method for Constructive Satisfiability Testing and Model Synthesis in the Alternating-Time Temporal Logic ATL <sup>+</sup>",
    "doi": "https://doi.org/10.1145/2811261",
    "publication_date": "2015-10-28",
    "publication_year": 2015,
    "authors": "Serenella Cerrito; Amélie David; Valentin Goranko",
    "corresponding_authors": "",
    "abstract": "We develop a sound, complete, and practically implementable tableau-based decision method for constructive satisfiability testing and model synthesis for the fragment ATL + of the full alternating-time temporal logic ALT * . The method extends in an essential way a previously developed tableau-based decision method for ATL and works in 2EXPTIME, which is the optimal worst-case complexity of the satisfiability problem for ATL + . We also discuss how suitable parameterizations and syntactic restrictions on the class of input ATL + formulas can reduce the complexity of the satisfiability problem.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2017979528",
    "type": "article"
  },
  {
    "title": "Normal Higher-Order Termination",
    "doi": "https://doi.org/10.1145/2699913",
    "publication_date": "2015-03-09",
    "publication_year": 2015,
    "authors": "Jean-Pierre Jouannaud; Albert Rubio",
    "corresponding_authors": "",
    "abstract": "We extend the termination proof methods based on reduction orderings to higher-order rewriting systems based on higher-order pattern matching. We accommodate, on the one hand, a weakly polymorphic, algebraic extension of Church’s simply typed λ-calculus and, on the other hand, any use of eta, as a reduction, as an expansion, or as an equation. The user’s rules may be of any type in this type system, either a base, functional, or weakly polymorphic type.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2137965931",
    "type": "article"
  },
  {
    "title": "Canonisation and Definability for Graphs of Bounded Rank Width",
    "doi": "https://doi.org/10.1145/3568025",
    "publication_date": "2022-10-26",
    "publication_year": 2022,
    "authors": "Martin Grohe; Daniel Neuen",
    "corresponding_authors": "",
    "abstract": "We prove that the combinatorial Weisfeiler-Leman algorithm of dimension (3 k +4) is a complete isomorphism test for the class of all graphs of rank width at most k . Rank width is a graph invariant that, similarly to tree width, measures the width of a certain style of hierarchical decomposition of graphs; it is equivalent to clique width. It was known that isomorphism of graphs of rank width k is decidable in polynomial time (Grohe and Schweitzer, FOCS 2015), but the best previously known algorithm has a running time n f(k) for a non-elementary function f . Our result yields an isomorphism test for graphs of rank width k running in time n O(k) . Another consequence of our result is the first polynomial-time canonisation algorithm for graphs of bounded rank width. Our second main result is that fixed-point logic with counting captures polynomial time on all graph classes of bounded rank width.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2913482449",
    "type": "article"
  },
  {
    "title": "MaxSAT Resolution and Subcube Sums",
    "doi": "https://doi.org/10.1145/3565363",
    "publication_date": "2022-10-17",
    "publication_year": 2022,
    "authors": "Yuval Filmus; Meena Mahajan; Gaurav Sood; Marc Vinyals",
    "corresponding_authors": "",
    "abstract": "We study the MaxRes rule in the context of certifying unsatisfiability. We show that it can be exponentially more powerful than tree-like resolution, and when augmented with weakening (the system MaxResW), p-simulates tree-like resolution. In devising a lower bound technique specific to MaxRes (and not merely inheriting lower bounds from Res), we define a new proof system called the SubCubeSums proof system. This system, which p-simulates MaxResW, can be viewed as a special case of the semialgebraic Sherali-Adams proof system. In expressivity, it is the integral restriction of conical juntas studied in the contexts of communication complexity and extension complexity. We show that it is not simulated by Res. Using a proof technique qualitatively different from the lower bounds that MaxResW inherits from Res, we show that Tseitin contradictions on expander graphs are hard to refute in SubCubeSums. We also establish a lower bound technique via lifting: for formulas requiring large degree in SubCubeSums, their XOR-ification requires large size in SubCubeSums.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W3027534747",
    "type": "article"
  },
  {
    "title": "Coalgebraic Reasoning with Global Assumptions in Arithmetic Modal Logics",
    "doi": "https://doi.org/10.1145/3501300",
    "publication_date": "2022-01-14",
    "publication_year": 2022,
    "authors": "Clemens Kupke; Dirk Pattinson; Lutz Schröder",
    "corresponding_authors": "",
    "abstract": "We establish a generic upper bound ExpTime for reasoning with global assumptions (also known as TBoxes) in coalgebraic modal logics. Unlike earlier results of this kind, our bound does not require a tractable set of tableau rules for the instance logics, so that the result applies to wider classes of logics. Examples are Presburger modal logic, which extends graded modal logic with linear inequalities over numbers of successors, and probabilistic modal logic with polynomial inequalities over probabilities. We establish the theoretical upper bound using a type elimination algorithm. We also provide a global caching algorithm that potentially avoids building the entire exponential-sized space of candidate states, and thus offers a basis for practical reasoning. This algorithm still involves frequent fixpoint computations; we show how these can be handled efficiently in a concrete algorithm modelled on Liu and Smolka’s linear-time fixpoint algorithm. Finally, we show that the upper complexity bound is preserved under adding nominals to the logic, i.e., in coalgebraic hybrid logic.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W3081939111",
    "type": "article"
  },
  {
    "title": "Satisfiability Problems on Sums of Kripke Frames",
    "doi": "https://doi.org/10.1145/3508068",
    "publication_date": "2022-04-22",
    "publication_year": 2022,
    "authors": "Ilya Shapirovsky",
    "corresponding_authors": "Ilya Shapirovsky",
    "abstract": "We consider the operation of sum on Kripke frames, where a family of frames-summands is indexed by elements of another frame. In many cases, the modal logic of sums inherits the finite model property and decidability from the modal logic of summands [Babenyshev and Rybakov 2010 ; Shapirovsky 2018 ]. In this paper we show that, under a general condition, the satisfiability problem on sums is polynomial space Turing reducible to the satisfiability problem on summands. In particular, for many modal logics decidability in PSpace is an immediate corollary from the semantic characterization of the logic.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W3115410114",
    "type": "article"
  },
  {
    "title": "A Meta-theory for Big-step Semantics",
    "doi": "https://doi.org/10.1145/3522729",
    "publication_date": "2022-04-06",
    "publication_year": 2022,
    "authors": "Francesco Dagnino",
    "corresponding_authors": "Francesco Dagnino",
    "abstract": "It is well known that big-step semantics is not able to distinguish stuck and non-terminating computations. This is a strong limitation as it makes it very difficult to reason about properties involving infinite computations, such as type soundness, which cannot even be expressed. We show that this issue is only apparent: the distinction between stuck and diverging computations is implicit in any big-step semantics and it just needs to be uncovered. To achieve this goal, we develop a systematic study of big-step semantics: we introduce an abstract definition of what a big-step semantics is, we define a notion of computation by formalizing the evaluation algorithm implicitly associated with any big-step semantics, and we show how to canonically extend a big-step semantics to characterize stuck and diverging computations. Building on these notions, we describe a general proof technique to show that a predicate is sound, that is, it prevents stuck computation, with respect to a big-step semantics. One needs to check three properties relating the predicate and the semantics, and if they hold, the predicate is sound. The extended semantics is essential to establish this meta-logical result but is of no concerns to the user, who only needs to prove the three properties of the initial big-step semantics. Finally, we illustrate the technique by several examples, showing that it is applicable also in cases where subject reduction does not hold, and hence the standard technique for small-step semantics cannot be used.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W3156427813",
    "type": "article"
  },
  {
    "title": "Asynchronous Announcements",
    "doi": "https://doi.org/10.1145/3481806",
    "publication_date": "2022-02-11",
    "publication_year": 2022,
    "authors": "Philippe Balbiani; Hans van Ditmarsch; Saúl Fernández González",
    "corresponding_authors": "",
    "abstract": "We propose a multi-agent epistemic logic of asynchronous announcements, where truthful announcements are publicly sent but individually received by agents, and in the order in which they were sent. Additional to epistemic modalities the logic contains dynamic modalities for making announcements and for receiving them. What an agent believes is a function of her initial uncertainty and of the announcements she has received. Beliefs need not be truthful, because announcements already made may not yet have been received. As announcements are true when sent, certain message sequences can be ruled out, just like inconsistent cuts in distributed computing. We provide a complete axiomatization for this asynchronous announcement logic ( AA ). It is a reduction system that also demonstrates that any formula in AA is equivalent to one without dynamic modalities, just as for public announcement logic. A detailed example modelling message exchanging processes in distributed computing in AA closes our investigation.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4211099339",
    "type": "article"
  },
  {
    "title": "SAT-Inspired Eliminations for Superposition",
    "doi": "https://doi.org/10.1145/3565366",
    "publication_date": "2022-09-30",
    "publication_year": 2022,
    "authors": "Petar Vukmirović; Jasmin Christian Blanchette; Marijn J. H. Heule",
    "corresponding_authors": "",
    "abstract": "Optimized SAT solvers not only preprocess the clause set, they also transform it during solving as inprocessing. Some preprocessing techniques have been generalized to first-order logic with equality. In this article, we port inprocessing techniques to work with superposition, a leading first-order proof calculus, and we strengthen known preprocessing techniques. Specifically, we look into elimination of hidden literals, variables (predicates), and blocked clauses. Our evaluation using the Zipperposition prover confirms that the new techniques usefully supplement the existing superposition machinery.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4298140626",
    "type": "article"
  },
  {
    "title": "Hypothetical answers to continuous queries over data streams",
    "doi": "https://doi.org/10.1145/3688845",
    "publication_date": "2024-08-17",
    "publication_year": 2024,
    "authors": "Luı́s Cruz-Filipe; Graça Gaspar; Isabel Nunes",
    "corresponding_authors": "",
    "abstract": "Answers to continuous queries over data streams are often delayed until some relevant input arrives through the data stream. These delays may turn answers when they arrive, obsolete to users who sometimes have to make decisions with no help whatsoever. Therefore, it can be useful to provide hypothetical answers—“given the current information, it is possible that X will become true at time t”—instead of no information at all. In this work, we present a semantics for queries and corresponding answers that cover such hypothetical answers, together with an incremental online algorithm for updating the set of facts that are consistent with the currently available information. Our framework also works in a language supporting negation.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2946433718",
    "type": "article"
  },
  {
    "title": "Strong Backdoors for Default Logic",
    "doi": "https://doi.org/10.1145/3655024",
    "publication_date": "2024-03-30",
    "publication_year": 2024,
    "authors": "Johannes K. Fichte; Arne Meier; Irena Schindler",
    "corresponding_authors": "",
    "abstract": "In this article, we introduce a notion of backdoors to Reiter’s propositional default logic and study structural properties of it. Also we consider the problems of backdoor detection (parameterised by the solution size) as well as backdoor evaluation (parameterised by the size of the given backdoor) for various kinds of target classes (CNF, KROM, MONOTONE) and all SCHAEFER classes. Also, we study generalisations of HORN-formulas, namely QHORN, RHORN, as well as DUALHORN. For these classes, we also classify the computational complexity of the implication problem. We show that backdoor detection is fixed-parameter tractable for the considered target classes and prove a complete trichotomy for backdoor evaluation. The problems are either fixed-parameter tractable, para-DeltaP2-complete, or para-NP-complete, depending on the target class.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2951741824",
    "type": "article"
  },
  {
    "title": "Stackelberg-Pareto Synthesis",
    "doi": "https://doi.org/10.1145/3651162",
    "publication_date": "2024-03-09",
    "publication_year": 2024,
    "authors": "Véronique Bruyère; Baptiste Fievet; Jean-François Raskin; Clément Tamines",
    "corresponding_authors": "",
    "abstract": "We study the framework of two-player Stackelberg games played on graphs in which Player 0 announces a strategy and Player 1 responds rationally with a strategy that is an optimal response. While it is usually assumed that Player 1 has a single objective, we consider here the new setting where he has several. In this context, after responding with his strategy, Player 1 gets a payoff in the form of a vector of Booleans corresponding to his satisfied objectives. Rationality of Player 1 is encoded by the fact that his response must produce a Pareto-optimal payoff given the strategy of Player 0. We study for several kinds of ω-regular objectives the Stackelberg-Pareto Synthesis problem which asks whether Player 0 can announce a strategy which satisfies his objective, whatever the rational response of Player 1. We show that this problem is fixed-parameter tractable for games in which objectives are all reachability, safety, Büchi, co-Büchi, Boolean Büchi, parity, Muller, Streett, or Rabin objectives. We also show that this problem is NEXPTIME -complete except for the cases of Büchi objectives for which it is NP -complete and co-Büchi objectives for which it is in NEXPTIME and NP -hard. The problem is already NP -complete in the simple case of reachability objectives and graphs that are trees.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W3132445226",
    "type": "article"
  },
  {
    "title": "First-Order Temporal Logic on Finite Traces: Semantic Properties, Decidable Fragments, and Applications",
    "doi": "https://doi.org/10.1145/3651161",
    "publication_date": "2024-03-05",
    "publication_year": 2024,
    "authors": "Alessandro Artale; Andrea Mazzullo; Ana Ozaki",
    "corresponding_authors": "",
    "abstract": "Formalisms based on temporal logics interpreted over finite strict linear orders, known in the literature as finite traces , have been used for temporal specification in automated planning, process modelling, (runtime) verification and synthesis of programs, as well as in knowledge representation and reasoning. In this article, we focus on first-order temporal logic on finite traces . We first investigate preservation of equivalences and satisfiability of formulas between finite and infinite traces, by providing a set of semantic and syntactic conditions to guarantee when the distinction between reasoning in the two cases can be blurred. Moreover, we show that the satisfiability problem on finite traces for several decidable fragments of first-order temporal logic is ExpSpace -complete, as in the infinite trace case, while it decreases to NExpTime when finite traces bounded in the number of instants are considered. This leads also to new complexity results for temporal description logics over finite traces. Finally, we investigate applications to planning and verification, in particular by establishing connections with the notions of insensitivity to infiniteness and safety from the literature.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4392472846",
    "type": "article"
  },
  {
    "title": "One or Nothing: Anti-unification over the Simply-Typed Lambda Calculus",
    "doi": "https://doi.org/10.1145/3654798",
    "publication_date": "2024-03-28",
    "publication_year": 2024,
    "authors": "David M. Cerna; Michal Buran",
    "corresponding_authors": "",
    "abstract": "Generalization techniques have many applications, including template construction, argument generalization, and indexing. Modern interactive provers can exploit advancement in generalization methods over expressive type theories to further develop proof generalization techniques and other transformations. So far, investigations concerned with anti-unification (AU) over λ-terms and similar type theories have focused on developing algorithms for well-studied variants. These variants forbid the nesting of generalization variables, restrict the structure of their arguments, and are unitary . Extending these methods to more expressive variants is important to applications. We consider the case of nested generalization variables and show that the AU problem is nullary (using capture-avoiding substitutions), even when the arguments to free variables are severely restricted.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4393259325",
    "type": "article"
  },
  {
    "title": "Fundamental Logic is Decidable",
    "doi": "https://doi.org/10.1145/3665328",
    "publication_date": "2024-06-17",
    "publication_year": 2024,
    "authors": "Juan P. Aguilera; Jan Bydžovský",
    "corresponding_authors": "",
    "abstract": "It is shown that Holliday’s propositional Fundamental Logic is decidable in polynomial time and that first-order Fundamental Logic is decidable in double-exponential time. The proof also yields a double-exponential–time decision procedure for first-order orthologic.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4399727858",
    "type": "article"
  },
  {
    "title": "Deciding the confluence of ordered term rewrite systems",
    "doi": "https://doi.org/10.1145/601775.601777",
    "publication_date": "2003-01-01",
    "publication_year": 2003,
    "authors": "Hubert Comon; Paliath Narendran; Robert Nieuwenhuis; Michaël Rusinowitch",
    "corresponding_authors": "",
    "abstract": "replace me",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W1987538043",
    "type": "article"
  },
  {
    "title": "A theory of normed simulations",
    "doi": "https://doi.org/10.1145/1024922.1024923",
    "publication_date": "2004-10-01",
    "publication_year": 2004,
    "authors": "David Griffioen; Frits Vaandrager",
    "corresponding_authors": "",
    "abstract": "In existing simulation proof techniques, a single step in a lower-level specification may be simulated by an extended execution fragment in a higher-level one. As a result, it is cumbersome to mechanize these techniques using general purpose theorem provers. Moreover, it is undecidable whether a given relation is a simulation, even if tautology checking is decidable for the underlying specification logic. This paper introduces various types of normed simulations. In a normed simulation, each step in a lower-level specification can be simulated by at most one step in the higher-level one, for any related pair of states. In earlier work we demonstrated that normed simulations are quite useful as a vehicle for the formalization of refinement proofs via theorem provers. Here we show that normed simulations also have pleasant theoretical properties: (1) under some reasonable assumptions, it is decidable whether a given relation is a normed forward simulation, provided tautology checking is decidable for the underlying logic; (2) at the semantic level, normed forward and backward simulations together form a complete proof method for establishing behavior inclusion, provided that the higher-level specification has finite invisible nondeterminism.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2105564020",
    "type": "article"
  },
  {
    "title": "First-order complete and computationally complete query languages for spatio-temporal databases",
    "doi": "https://doi.org/10.1145/1342991.1342997",
    "publication_date": "2008-03-01",
    "publication_year": 2008,
    "authors": "Floris Geerts; Sofie Haesevoets; Bart Kuijpers",
    "corresponding_authors": "",
    "abstract": "We address a fundamental question concerning spatio-temporal database systems: “What are exactly spatio-temporal queries?” We define spatio-temporal queries to be computable mappings that are also generic , meaning that the result of a query may only depend to a limited extent on the actual internal representation of the spatio-temporal data. Genericity is defined as invariance under groups of geometric transformations that preserve certain characteristics of spatio-temporal data (e.g., collinearity, distance, velocity, acceleration, …). These groups depend on the notions that are relevant in particular spatio-temporal database applications. These transformations also have the distinctive property that they respect the monotone and unidirectional nature of time. We investigate different genericity classes with respect to the constraint database model for spatio-temporal databases and we identify sound and complete languages for the first-order and the computable queries in these genericity classes. We distinguish between genericity determined by time-invariant transformations, genericity notions concerning physical quantities and genericity determined by time-dependent transformations.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W1967926597",
    "type": "article"
  },
  {
    "title": "Stratification in Approximation Fixpoint Theory and Its Application to Active Integrity Constraints",
    "doi": "https://doi.org/10.1145/3430750",
    "publication_date": "2021-01-05",
    "publication_year": 2021,
    "authors": "Bart Bogaerts; Luı́s Cruz-Filipe",
    "corresponding_authors": "",
    "abstract": "Approximation fixpoint theory (AFT) is an algebraic study of fixpoints of lattice operators that unifies various knowledge representation formalisms. In AFT, stratification of operators has been studied, essentially resulting in a theory that specifies when certain types of fixpoints can be computed stratum per stratum. Recently, novel types of fixpoints related to groundedness have been introduced in AFT. In this article, we study how those fixpoints behave under stratified operators. One recent application domain of AFT is the field of active integrity constraints (AICs). We apply our extended stratification theory to AICs and find that existing notions of stratification in AICs are covered by this general algebraic definition of stratification. As a result, we obtain stratification results for a large variety of semantics for AICs.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W3120364302",
    "type": "article"
  },
  {
    "title": "Small Circuits and Dual Weak PHP in the Universal Theory of p-time Algorithms",
    "doi": "https://doi.org/10.1145/3446207",
    "publication_date": "2021-04-30",
    "publication_year": 2021,
    "authors": "Jan Krajı́ček",
    "corresponding_authors": "Jan Krajı́ček",
    "abstract": "We prove, under a computational complexity hypothesis, that it is consistent with the true universal theory of p-time algorithms that a specific p-time function extending $n$ bits to $m \\geq n^2$ bits violates the dual weak pigeonhole principle: every string $y$ of length $m$ equals the value of the function for some $x$ of length $n$. The function is the truth-table function assigning to a circuit the table of the function it computes and the hypothesis is that every language in P has circuits of a fixed polynomial size $n^d$.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W3162316592",
    "type": "article"
  },
  {
    "title": "Strategic Knowledge Acquisition",
    "doi": "https://doi.org/10.1145/3459993",
    "publication_date": "2021-06-28",
    "publication_year": 2021,
    "authors": "Kaya Deuser; Pavel Naumov",
    "corresponding_authors": "",
    "abstract": "The article proposes a trimodal logical system that can express the strategic ability of coalitions to learn from their experience. The main technical result is the completeness of the proposed system.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W3176680477",
    "type": "article"
  },
  {
    "title": "Algorithmic Compression of Finite Tree Languages by Rigid Acyclic Grammars",
    "doi": "https://doi.org/10.1145/3127401",
    "publication_date": "2017-09-21",
    "publication_year": 2017,
    "authors": "Sebastian Eberhard; Gabriel Ebner; Stefan Hetzl",
    "corresponding_authors": "",
    "abstract": "We present an algorithm to optimally compress a finite set of terms using a vectorial totally rigid acyclic tree grammar. This class of grammars has a tight connection to proof theory, and the grammar compression problem considered in this article has applications in automated deduction. The algorithm is based on a polynomial-time reduction to the MaxSAT optimization problem. The crucial step necessary to justify this reduction consists of applying a term rewriting relation to vectorial totally rigid acyclic tree grammars. Our implementation of this algorithm performs well on a large real-world dataset.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2189337051",
    "type": "article"
  },
  {
    "title": "Quantified Constraint Satisfaction Problem on Semicomplete Digraphs",
    "doi": "https://doi.org/10.1145/3007899",
    "publication_date": "2017-01-31",
    "publication_year": 2017,
    "authors": "Petar Đapić; Petar Marković; Barnaby Martin",
    "corresponding_authors": "",
    "abstract": "We study the (non-uniform) quantified constraint satisfaction problem QCSP( H ) as H ranges over semicomplete digraphs. We obtain a complexity-theoretic trichotomy: QCSP( H ) is either in P, is NP-complete, or is Pspace-complete. The largest part of our work is the algebraic classification of precisely which semicomplete digraphs enjoy only essentially unary polymorphisms, which is combinatorially interesting in its own right.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2605983742",
    "type": "article"
  },
  {
    "title": "Automated Generation of Erotetic Search Scenarios",
    "doi": "https://doi.org/10.1145/3056537",
    "publication_date": "2017-04-30",
    "publication_year": 2017,
    "authors": "Szymon Chlebowski; Maciej Komosiński; Adam Kupś",
    "corresponding_authors": "",
    "abstract": "This article concerns automated generation and processing of erotetic search scenarios (ESSs). ESSs are formal constructs characterized in Inferential Erotetic Logic that enable finding possible answers to a posed question by decomposing it into auxiliary questions. The first part of this work describes a formal account on ESSs. The formal approach is then applied to automatically generate ESSs, and the resulting scenarios are evaluated according to a number of criteria. These criteria are subjected to discordance analysis that reveals their mutual relationships. Finally, knowledge concerning relationships between different values of evaluation criteria is extracted by applying Apriori—an association rules mining algorithm. The proposed approach of integration of formal erotetic logic with computational tools provides extensive insight into the former and helps with the development of efficient ESSs.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2613532714",
    "type": "article"
  },
  {
    "title": "One Hierarchy Spawns Another",
    "doi": "https://doi.org/10.1145/3143805",
    "publication_date": "2017-10-31",
    "publication_year": 2017,
    "authors": "Hubie Chen; Moritz Müller",
    "corresponding_authors": "",
    "abstract": "We study the problem of conjunctive query evaluation relative to a class of queries. This problem is formulated here as the relational homomorphism problem relative to a class of structures A , in which each instance must be a pair of structures such that the first structure is an element of A . We present a comprehensive complexity classification of these problems, which strongly links graph-theoretic properties of A to the complexity of the corresponding homomorphism problem. In particular, we define a binary relation on graph classes, which is a preorder, and completely describe the resulting hierarchy given by this relation. This relation is defined in terms of a notion that we call graph deconstruction and that is a variant of the well-known notion of tree decomposition. We then use this hierarchy of graph classes to infer a complexity hierarchy of homomorphism problems that is comprehensive up to a computationally very weak notion of reduction, namely, a parameterized version of quantifier-free, first-order reduction. In doing so, we obtain a significantly refined complexity classification of homomorphism problems as well as a unifying, modular, and conceptually clean treatment of existing complexity classifications. We then present and develop the theory of Ehrenfeucht-Fraïssé-style pebble games, which solve the homomorphism problems where the cores of the structures in A have bounded tree depth. This condition characterizes those classical homomorphism problems decidable in logarithmic space, assuming a hypothesis from parameterized space complexity. Finally, we use our framework to classify the complexity of model checking existential sentences having bounded quantifier rank.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2767449129",
    "type": "article"
  },
  {
    "title": "Uniqueness of Normal Forms for Shallow Term Rewrite Systems",
    "doi": "https://doi.org/10.1145/3060144",
    "publication_date": "2017-04-30",
    "publication_year": 2017,
    "authors": "Nicholas R. Radcliffe; Luis F. T. Moraes; Rakesh Verma",
    "corresponding_authors": "",
    "abstract": "Uniqueness of normal forms (UN = ) is an important property of term rewrite systems. UN = is decidable for ground (i.e., variable-free) systems and undecidable in general. Recently, it was shown to be decidable for linear, shallow systems. We generalize this previous result and show that this property is decidable for shallow rewrite systems, in contrast to confluence, reachability, and other related properties, which are all undecidable for flat systems. We also prove an upper bound on the complexity of our algorithm. Our decidability result is optimal in a sense, since we prove that the UN = property is undecidable for two classes of linear rewrite systems: left-flat systems in which right-hand sides are of height at most two and right-flat systems in which left-hand sides are of height at most two.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2962928105",
    "type": "article"
  },
  {
    "title": "Dynamic Reasoning Systems",
    "doi": "https://doi.org/10.1145/2798727",
    "publication_date": "2015-11-14",
    "publication_year": 2015,
    "authors": "Daniel G. Schwartz",
    "corresponding_authors": "Daniel G. Schwartz",
    "abstract": "A dynamic reasoning system (DRS) is an adaptation of a conventional formal logical system that explicitly portrays reasoning as a temporal activity, with each extralogical input to the system and each inference rule application being viewed as occurring at a distinct timestep. Every DRS incorporates some well-defined logic together with a controller that serves to guide the reasoning process in response to user inputs. Logics are generic, whereas controllers are application specific. Every controller does, nonetheless, provide an algorithm for nonmonotonic belief revision. The general notion of a DRS comprises a framework within which one can formulate the logic and algorithms for a given application and prove that the algorithms are correct, that is, that they serve to (1) derive all salient information and (2) preserve the consistency of the belief set. This article illustrates the idea with ordinary first-order predicate calculus, suitably modified for the present purpose, and two examples. The latter example revisits some classic nonmonotonic reasoning puzzles (Opus the Penguin, Nixon Diamond) and shows how these can be resolved in the context of a DRS, using an expanded version of first-order logic that incorporates typed predicate symbols. All concepts are rigorously defined and effectively computable, thereby providing the foundation for a future software implementation.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W1520756217",
    "type": "article"
  },
  {
    "title": "A Certified Reduction Strategy for Homological Image Processing",
    "doi": "https://doi.org/10.1145/2630789",
    "publication_date": "2014-07-08",
    "publication_year": 2014,
    "authors": "María Jesús Adán Poza; César Domínguez; Jónathan Heras; Julio Rubio",
    "corresponding_authors": "",
    "abstract": "The analysis of digital images using homological procedures is an outstanding topic in the area of Computational Algebraic Topology. In this article, we describe a certified reduction strategy to deal with digital images, but one preserving their homological properties. We stress both the advantages of our approach (mainly, the formalization of the mathematics allowing us to verify the correctness of algorithms) and some limitations (related to the performance of the running systems inside proof assistants). The drawbacks are overcome using techniques that provide an integration of computation and deduction. Our driving application is a problem in bioinformatics, where the accuracy and reliability of computations are specially requested.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W1967904520",
    "type": "article"
  },
  {
    "title": "Inference of Field-Sensitive Reachability and Cyclicity",
    "doi": "https://doi.org/10.1145/2629478",
    "publication_date": "2014-08-01",
    "publication_year": 2014,
    "authors": "Damiano Zanardini; Samir Genaim",
    "corresponding_authors": "",
    "abstract": "In heap-based languages, knowing that a variable x points to an acyclic data structure is useful for analyzing termination. This information guarantees that the depth of the data structure to which x points is greater than the depth of the structure pointed to by x. fld , and allows bounding the number of iterations of a loop that traverses the data structure on fld . In general, proving termination needs acyclicity, unless program-specific or nonautomated reasoning is performed. However, recent work could prove that certain loops terminate even without inferring acyclicity, because they traverse data structures “acyclically.” Consider a double-linked list: if it is possible to demonstrate that every cycle involves both the “next” and the “prev” field, then a traversal on “next” terminates since no cycle will be traversed completely. This article develops a static analysis inferring field-sensitive reachability and cyclicity information, which is more general than existing approaches. Propositional formulæ are computed, which describe which fields may or may not be traversed by paths in the heap. Consider a tree with edges “left” and “right” to the left and right subtrees, and “parent” to the parent node: termination of a loop traversing leaf-up cannot be guaranteed by state-of-the-art analyses. Instead, propositional formulæ computed by this analysis indicate that cycles must traverse “parent” and at least one between “left” and “right”: termination is guaranteed, as no cycle is traversed completely. This work defines the necessary abstract domains and builds an abstract semantics on them. A prototypical implementation provides the expected result on relevant examples.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W1987635382",
    "type": "article"
  },
  {
    "title": "Logical Characterizations of Behavioral Relations on Transition Systems of Probability Distributions",
    "doi": "https://doi.org/10.1145/2641566",
    "publication_date": "2014-09-16",
    "publication_year": 2014,
    "authors": "Silvia Crafà; Francesco Ranzato",
    "corresponding_authors": "",
    "abstract": "Probabilistic nondeterministic processes are commonly modeled as probabilistic LTSs (PLTSs). A number of logical characterizations of the main behavioral relations on PLTSs have been studied. In particular, Parma and Segala [2007] and Hermanns et al. [2011] define a probabilistic Hennessy-Milner logic interpreted over probability distributions, whose corresponding logical equivalence/preorder when restricted to Dirac distributions coincides with standard bisimulation/simulation between the states of a PLTS. This result is here extended by studying the full logical equivalence/preorder between (possibly non-Dirac) distributions in terms of a notion of bisimulation/simulation defined on an LTS whose states are distributions (dLTS). We show that the well-known spectrum of behavioral relations on nonprobabilistic LTSs as well as their corresponding logical characterizations in terms of Hennessy-Milner logic scales to the probabilistic setting when considering dLTSs.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W1989849430",
    "type": "article"
  },
  {
    "title": "Decidability of Approximate Skolem Problem and Applications to Logical Verification of Dynamical Properties of Markov Chains",
    "doi": "https://doi.org/10.1145/2666772",
    "publication_date": "2014-12-12",
    "publication_year": 2014,
    "authors": "M. Biscaia; David Henriques; Paulo Mateus",
    "corresponding_authors": "",
    "abstract": "When studying probabilistic dynamical systems, temporal logic has typically been used to analyze path properties. Recently, there has been some interest in analyzing the dynamical evolution of state probabilities of these systems. In this article, we show that verifying linear temporal properties concerning the state evolution induced by a Markov chain is equivalent to the decidability of the Skolem problem -- a long-standing open problem in Number Theory. However, from a practical point of view, usually it is enough to check properties up to some acceptable error bound ϵ. We show that an approximate version of the Skolem problem is decidable, and that it can be applied to verify, up to arbitrarily small ϵ, linear temporal properties of the state evolution induced by a Markov chain.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2020183404",
    "type": "article"
  },
  {
    "title": "LoCo—A Logic for Configuration Problems",
    "doi": "https://doi.org/10.1145/2629454",
    "publication_date": "2014-07-08",
    "publication_year": 2014,
    "authors": "Markus Aschinger; Conrad Drescher; Georg Gottlob; Heribert Vollmer",
    "corresponding_authors": "",
    "abstract": "In this work, we present LoCo, a fragment of classical first-order logic carefully tailored for expressing technical product configuration problems. The core feature of LoCo is that the number of components used in configurations does not have to be finitely bounded explicitly, but instead is bounded implicitly through the axioms. Computing configurations is equivalent to the task of model finding. We present the language, related algorithms, and complexity results as well as a prototypical implementation via answer set programming.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2050815510",
    "type": "article"
  },
  {
    "title": "Lax Theory Morphisms",
    "doi": "https://doi.org/10.1145/2818644",
    "publication_date": "2015-10-28",
    "publication_year": 2015,
    "authors": "Florian Rabe",
    "corresponding_authors": "Florian Rabe",
    "abstract": "When relating formal languages, e.g., in logic or type theory, it is often important to establish representation theorems. These interpret one language in terms of another in a way that preserves semantic properties such as provability or typing. Metalanguages for stating representation theorems can be divided into two groups: First, computational languages are very expressive (usually Turing-complete), but verifying the representation theorems is very difficult (often prohibitively so); second, declarative languages are restricted to certain classes of representation theorems (often based on theory morphisms), for which correctness is decidable. Neither is satisfactory, and this article contributes to the investigation of the trade-off between these two methods. Concretely, we introduce lax theory morphisms, which combine some of the advantages of each: they are substantially more expressive than conventional theory morphisms, but they share many of the invariants that make theory morphisms easy to work with. Specifically, we introduce lax morphisms between theories of a dependently typed logical framework, but our approach and results carry over to most declarative metalanguages. We demonstrate the usefulness of lax theory morphisms by stating and verifying a type erasure translation from typed to untyped first-order logic. The translation is stated as a single lax theory morphism, and the invariants of the framework guarantee its correctness. This is the first time such a complex translation has be verified in a declarative framework.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2095327196",
    "type": "article"
  },
  {
    "title": "Index Problems for Game Automata",
    "doi": "https://doi.org/10.1145/2946800",
    "publication_date": "2016-11-02",
    "publication_year": 2016,
    "authors": "Alessandro Facchini; Filip Murlak; Michał Skrzypczak",
    "corresponding_authors": "",
    "abstract": "For a given regular language of infinite trees, one can ask about the minimal number of priorities needed to recognize this language with a nondeterministic, alternating, or weak alternating parity automaton. These questions are known as, respectively, the nondeterministic, alternating, and weak Rabin-Mostowski index problems. Whether they can be answered effectively is a long-standing open problem, solved so far only for languages recognizable by deterministic automata (the alternating variant trivializes). We investigate a wider class of regular languages, recognizable by so-called game automata, which can be seen as the closure of deterministic ones under complementation and composition. Game automata are known to recognize languages arbitrarily high in the alternating Rabin-Mostowski index hierarchy; that is, the alternating index problem does not trivialize anymore. Our main contribution is that all three index problems are decidable for languages recognizable by game automata. Additionally, we show that it is decidable whether a given regular language can be recognized by a game automaton.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2247132892",
    "type": "article"
  },
  {
    "title": "Zeno, Hercules, and the Hydra",
    "doi": "https://doi.org/10.1145/2874774",
    "publication_date": "2016-02-17",
    "publication_year": 2016,
    "authors": "Ranko Lazić; Joël Ouaknine; James Worrell",
    "corresponding_authors": "",
    "abstract": "Metric temporal logic (MTL) is one of the most prominent specification formalisms for real-time systems. Over infinite timed words, full MTL is undecidable, but satisfiability for a syntactially defined safety fragment, called safety MTL, was proved decidable several years ago. Satisfiability for safety MTL is also known to be equivalent to a fair termination problem for a class of channel machines with insertion errors. However, hitherto, its precise computational complexity has remained elusive, with only a nonelementary lower bound. Via another equivalent problem, namely termination for a class of rational relations, we show that satisfiability for safety MTL is A ckermann -complete (i.e., among the easiest nonprimitive recursive problems). This is surprising since decidability was originally established using Higman’s Lemma, suggesting a much higher nonmultiply recursive complexity.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2280377303",
    "type": "article"
  },
  {
    "title": "A Decision Procedure for a Theory of Finite Sets with Finite Integer Intervals",
    "doi": "https://doi.org/10.1145/3625230",
    "publication_date": "2023-09-23",
    "publication_year": 2023,
    "authors": "Maximiliano Cristiá; Gianfranco Rossi",
    "corresponding_authors": "",
    "abstract": "In this paper we extend a decision procedure for the Boolean algebra of finite sets with cardinality constraints (ℒ |⋅| ) to a decision procedure for ℒ |⋅| extended with set terms denoting finite integer intervals (ℒ [] ). In ℒ [] interval limits can be integer linear terms including unbounded variables . These intervals are a useful extension because they allow to express non-trivial set operators such as the minimum and maximum of a set, still in a quantifier-free logic. Hence, by providing a decision procedure for ℒ [] it is possible to automatically reason about a new class of quantifier-free formulas. The decision procedure is implemented as part of the { log } (‘setlog’) tool. The paper includes a case study based on the elevator algorithm showing that { log } can automatically discharge all its invariance lemmas, some of which involve intervals.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W3162701640",
    "type": "article"
  },
  {
    "title": "A Decidable Fragment of First Order Modal Logic: Two Variable Term Modal Logic",
    "doi": "https://doi.org/10.1145/3593584",
    "publication_date": "2023-04-19",
    "publication_year": 2023,
    "authors": "Anantha Padmanabha; R. Ramanujam",
    "corresponding_authors": "",
    "abstract": "First order modal logic (𝖥𝖮𝖬𝖫) is built by extending First Order Logic (𝖥𝖮) with modal operators. A typical formula is of the form \\(\\forall x \\exists y \\Box P(x,y)\\) . Not only is 𝖥𝖮𝖬𝖫 undecidable, even simple fragments like that of restriction to unary predicate symbols, guarded fragment and two variable fragment, which are all decidable for 𝖥𝖮 become undecidable for 𝖥𝖮𝖬𝖫. In this paper we study Term Modal logic (𝖳𝖬𝖫) which allows modal operators to be indexed by terms. A typical formula is of the form \\(\\forall x \\exists y~\\Box _x P(x,y)\\) . There is a close correspondence between 𝖳𝖬𝖫 and 𝖥𝖮𝖬𝖫 and we explore this relationship in detail in the paper. In contrast to 𝖥𝖮𝖬𝖫, we show that the two variable fragment (without constants, equality) of 𝖳𝖬𝖫 is decidable. Further, we prove that adding a single constant makes the two variable fragment of 𝖳𝖬𝖫 undecidable. On the other hand, when equality is added to the logic, it loses the finite model property.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4366407870",
    "type": "article"
  },
  {
    "title": "Inputs, Outputs, and Composition in the Logic of Information Flows",
    "doi": "https://doi.org/10.1145/3604553",
    "publication_date": "2023-07-15",
    "publication_year": 2023,
    "authors": "Heba Aamer; Bart Bogaerts; Dimitri Surinx; Eugenia Ternovska; Jan Van den Bussche",
    "corresponding_authors": "",
    "abstract": "The logic of information flows (LIF) is a general framework in which tasks of a procedural nature can be modeled in a declarative, logic-based fashion. The first contribution of this article is to propose semantic and syntactic definitions of inputs and outputs of LIF expressions. We study how the two relate and show that our syntactic definition is optimal in a sense that is made precise. The second contribution is a systematic study of the expressive power of sequential composition in LIF. Our results on composition tie in the results on inputs and outputs and relate LIF to first-order logic (FO) and bounded-variable LIF to bounded- variable FO. This article is the extended version of a paper presented at KR 2020 [ 2 ].",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4384407481",
    "type": "article"
  },
  {
    "title": "Higher-order pattern complement and the strict λ-calculus",
    "doi": "https://doi.org/10.1145/937555.937559",
    "publication_date": "2003-10-01",
    "publication_year": 2003,
    "authors": "Alberto Momigliano; Frank Pfenning",
    "corresponding_authors": "",
    "abstract": "We address the problem of complementing higher-order patterns without repetitions of existential variables. Differently from the first-order case, the complement of a pattern cannot, in general, be described by a pattern, or even by a finite set of patterns. We therefore generalize the simply-typed λ-calculus to include an internal notion of strict function so that we can directly express that a term must depend on a given variable. We show that, in this more expressive calculus, finite sets of patterns without repeated variables are closed under complement and intersection. Our principal application is the transformational approach to negation in higher-order logic programs.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2077870744",
    "type": "article"
  },
  {
    "title": "Decidability results for sets with atoms",
    "doi": "https://doi.org/10.1145/1131313.1131317",
    "publication_date": "2006-04-01",
    "publication_year": 2006,
    "authors": "Agostino Dovier; Andrea Formisano; Eugenio G. Omodeo",
    "corresponding_authors": "",
    "abstract": "Formal set theory is traditionally concerned with pure sets; consequently, the satisfiability problem for fragments of set theory was most often addressed (and in many cases positively solved) in the pure framework. In practical applications, however, it is common to assume the existence of a number of primitive objects (sometimes called atoms ) that can be members of sets but behave differently from them. If these entities are assumed to be devoid of members, the standard extensionality axiom must be revised; then decidability results can sometimes be achieved via reduction to the pure case and sometimes can be based on direct goal-driven algorithms. An alternative approach to modeling atoms that allows one to retain the original formulation of extensionality was proposed by Quine: atoms are self-singletons. In this article we adopt this approach in coping with the satisfiability problem: We show the decidability of this problem relativized to ∃*∀-sentences, and develop a goal-driven unification algorithm.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W1971558321",
    "type": "article"
  },
  {
    "title": "Quantitative Aspects of Linear and Affine Closed Lambda Terms",
    "doi": "https://doi.org/10.1145/3173547",
    "publication_date": "2018-04-30",
    "publication_year": 2018,
    "authors": "Pierre Lescanne",
    "corresponding_authors": "Pierre Lescanne",
    "abstract": "Affine λ-terms are λ-terms in which each bound variable occurs at most once, and linear λ-terms are λ-terms in which each bound variable occurs once and only once. In this article, we count the number of affine closed λ-terms of size n , linear closed λ-terms of size n , affine closed β-normal forms of size n , and linear closed β-normal forms of size n , for several measures of the size of λ-terms. From these formulas, we show how we can derive programs for generating all the terms of size n for each class. The foundation of all of this is a specific data structure, made of contexts in which one counts all the holes at each level of abstractions by λ’s.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2592316181",
    "type": "article"
  },
  {
    "title": "Hierarchies in Inclusion Logic with Lax Semantics",
    "doi": "https://doi.org/10.1145/3204521",
    "publication_date": "2018-07-31",
    "publication_year": 2018,
    "authors": "Miika Hannula",
    "corresponding_authors": "Miika Hannula",
    "abstract": "We study the expressive power of fragments of inclusion logic under the so-called lax team semantics. The fragments are defined either by restricting the number of universal quantifiers, the number of inclusion atoms, or the arity of inclusion atoms. We show that the whole expressive power of inclusion logic can be captured using only five inclusion atoms in finite ordered models or, alternatively, only one universal quantifier in general. The arity hierarchy is shown to be strict by relating the question to the study of arity hierarchies in fixed point logics.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2890423770",
    "type": "article"
  },
  {
    "title": "Synchronizing Data Words for Register Automata",
    "doi": "https://doi.org/10.1145/3309760",
    "publication_date": "2019-03-27",
    "publication_year": 2019,
    "authors": "Karin Quaas; Mahsa Shirmohammadi",
    "corresponding_authors": "",
    "abstract": "Register automata (RAs) are finite automata extended with a finite set of registers to store and compare data from an infinite domain. We study the concept of synchronizing data words in RAs: does there exist a data word that sends all states of the RA to a single state? For deterministic RAs with k registers ( k -DRAs), we prove that inputting data words with 2 k +1 distinct data from the infinite data domain is sufficient to synchronize. We show that the synchronization problem for DRAs is in general PSPACE-complete, and it is NLOGSPACE-complete for 1-DRAs. For nondeterministic RAs (NRAs), we show that Ackermann( n ) distinct data (where n is the size of the RA) might be necessary to synchronize. The synchronization problem for NRAs is in general undecidable; however, we establish Ackermann-completeness of the problem for 1-NRAs. Another main result is the NEXPTIME-completeness of the length-bounded synchronization problem for NRAs, where a bound on the length of the synchronizing data word, written in binary, is given. A variant of this last construction allows to prove that the length-bounded universality problem for NRAs is co-NEXPTIME-complete.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2926815817",
    "type": "article"
  },
  {
    "title": "Modular Labelled Sequent Calculi for Abstract Separation Logics",
    "doi": "https://doi.org/10.1145/3197383",
    "publication_date": "2018-04-28",
    "publication_year": 2018,
    "authors": "Zhé Hóu; Ranald Clouston; Rajeev Goré; Alwen Tiu",
    "corresponding_authors": "",
    "abstract": "Separation logics are a family of extensions of Hoare logic for reasoning about programs that manipulate resources such as memory locations. These logics are \"abstract\" because they are independent of any particular concrete resource model. Their assertion languages, called Propositional Abstract Separation Logics (PASLs), extend the logic of (Boolean) Bunched Implications (BBI) in various ways. In particular, these logics contain the connectives ∗ and -∗, denoting the composition and extension of resources, respectively. This added expressive power comes at a price, since the resulting logics are all undecidable. Given their wide applicability, even a semi-decision procedure for these logics is desirable. Although several PASLs and their relationships with BBI are discussed in the literature, the proof theory of, and automated reasoning for, these logics were open problems solved by the conference version of this article, which developed a modular proof theory for various PASLs using cut-free labelled sequent calculi. This paper non-trivially improves upon this previous work by giving a general framework of calculi on which any new axiom in the logic satisfying a certain form corresponds to an inference rule in our framework, and the completeness proof is generalised to consider such axioms. Our base calculus handles Calcagno et al.'s original logic of separation algebras by adding sound rules for partial-determinism and cancellativity, while preserving cut-elimination. We then show that many important properties in separation logic, such as indivisible unit, disjointness, splittability, and cross-split, can be expressed in our general axiom form. Thus, our framework offers inference rules and completeness for these properties for free. Finally, we show how our calculi reduce to calculi with global label substitutions, enabling more efficient implementation.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2962815822",
    "type": "article"
  },
  {
    "title": "Checking Admissibility Using Natural Dualities",
    "doi": "https://doi.org/10.1145/3275115",
    "publication_date": "2018-12-20",
    "publication_year": 2018,
    "authors": "Leonardo Manuel Cabrer; Benjamin Freisberg; George Metcalfe; H. A. Priestley",
    "corresponding_authors": "",
    "abstract": "This article presents a new method for obtaining small algebras to check the admissibility—equivalently, validity in free algebras—of quasi-identities in a finitely generated quasivariety. Unlike a previous algebraic approach of Metcalfe and Röthlisberger, which is feasible only when the relevant free algebra is not too large, this method exploits natural dualities for quasivarieties to work with structures of smaller cardinality and surjective rather than injective morphisms. A number of case studies are described here that could not be be solved using the algebraic approach, including (quasi)varieties of MS-algebras, double Stone algebras, and involutive Stone algebras.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2963632537",
    "type": "article"
  },
  {
    "title": "Monadic Datalog, Tree Validity, and Limited Access Containment",
    "doi": "https://doi.org/10.1145/3344514",
    "publication_date": "2019-10-04",
    "publication_year": 2019,
    "authors": "Michael Benedikt; Pierre Bourhis; Georg Gottlob; Pierre Senellart",
    "corresponding_authors": "",
    "abstract": "We reconsider the problem of containment of monadic datalog (MDL) queries in unions of conjunctive queries (UCQs). Prior work has dealt with special cases of the problem but has left the precise complexity characterization open. In addition, the complexity of one important special case, that of containment under access patterns, was not known before. We start by revisiting the connection between MDL/UCQ containment and containment problems involving regular tree languages. We then present a general approach for getting tighter bounds on the complexity of query containment, based on analysis of the number of mappings of queries into tree-like instances. We give two applications of the machinery. We first give an important special case of the MDL/UCQ containment problem that is in EXPTIME, and we use this bound to show an EXPTIME bound on containment under access patterns. Second, we show that the same technique can be used to get a new tight upper bound for containment of tree automata in UCQs. We finally show that the new MDL/UCQ upper bounds are tight. We establish a 2EXPTIME lower bound on the MDL/UCQ containment problem, resolving an open problem from the early 1990s. This bound holds for the MDL/CQ containment problem as well. We also show that changes to the conditions given in our special cases can not be eliminated, and that in particular slight variations of the problem of containment under access patterns become 2EXPTIME-complete.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2979988222",
    "type": "article"
  },
  {
    "title": "Model Checking MITL Formulae on Timed Automata",
    "doi": "https://doi.org/10.1145/3383687",
    "publication_date": "2020-04-17",
    "publication_year": 2020,
    "authors": "Claudio Menghi; Marcello M. Bersani; Matteo Rossi; Pierluigi San Pietro",
    "corresponding_authors": "",
    "abstract": "Timed Automata (TA) is de facto a standard modelling formalism to represent systems when the interest is the analysis of their behaviour as time progresses. This modelling formalism is mostly used for checking whether the behaviours of a system satisfy a set of properties of interest. Even if efficient model-checkers for Timed Automata exist, these tools are not easily configurable. First, they are not designed to easily allow adding new Timed Automata constructs, such as new synchronization mechanisms or communication procedures, but they assume a fixed set of Timed Automata constructs. Second, they usually do not support the Metric Interval Temporal Logic (MITL) and rely on a precise semantics for the logic in which the property of interest is specified, which cannot be easily modified and customized. Finally, they do not easily allow using different solvers that may speed up verification in different contexts. This article presents a novel technique to perform model checking of Metric Interval Temporal Logic (MITL) properties on TA. The technique relies on the translation of both the TA and the MITL formula into an intermediate Constraint LTL over clocks (CLTLoc) formula, which is verified through an available decision procedure. The technique is flexible, since the intermediate logic allows the encoding of new semantics as well as new TA constructs, by just adding new CLTLoc formulae. Furthermore, our technique is not bound to a specific solver as the intermediate CLTLoc formula can be verified using different procedures.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W3022492366",
    "type": "article"
  },
  {
    "title": "Hypersequents and Systems of Rules",
    "doi": "https://doi.org/10.1145/3180075",
    "publication_date": "2018-04-02",
    "publication_year": 2018,
    "authors": "Agata Ciabattoni; Francesco A. Genco",
    "corresponding_authors": "",
    "abstract": "We define a bi-directional embedding between hypersequent calculi and a subclass of systems of rules (2-systems). In addition to showing that the two proof frameworks have the same expressive power, the embedding allows for the recovery of the benefits of locality for 2-systems, analyticity results for a large class of such systems, and a rewriting of hypersequent rules as natural deduction rules.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4299603271",
    "type": "article"
  },
  {
    "title": "Least upper bounds on the size of confluence and church-rosser diagrams in term rewriting and λ-calculus",
    "doi": "https://doi.org/10.1145/2528934",
    "publication_date": "2013-11-01",
    "publication_year": 2013,
    "authors": "Jeroen Ketema; Jakob Grue Simonsen",
    "corresponding_authors": "",
    "abstract": "We study confluence and the Church-Rosser property in term rewriting and λ-calculus with explicit bounds on term sizes and reduction lengths. Given a system R , we are interested in the lengths of the reductions in the smallest valleys t → * s ′ * ← t ′ expressed as a function: —for confluence a function vs R ( m , n ) where the valleys are for peaks t ← s → * t ′ with s of size at most m and the reductions of maximum length n , and —for the Church-Rosser property a function cvs R ( m , n ) where the valleys are for conversions t ↔ * t ′ with t and t ′ of size at most m and the conversion of maximum length n . For confluent Term Rewriting Systems (TRSs), we prove that vs R is a total computable function, and for linear such systems that cvs R is a total computable function. Conversely, we show that every total computable function is the lower bound on the functions vs R ( m , n ) and cvs R ( m , n ) for some TRS R : In particular, we show that for every total computable function φ: N → N there is a TRS R with a single term s such that vs R (| s |, n ) ≥ φ( n ) and cvs R ( n , n ) ≥ φ( n ) for all n . For orthogonal TRSs R we prove that there is a constant k such that: (a) vs R ( m , n ) is bounded from above by a function exponential in k and (b) cvs R ( m , n ) is bounded from above by a function in the fourth level of the Grzegorczyk hierarchy. Similarly, for λ-calculus, we show that vs R ( m , n ) is bounded from above by a function in the fourth level of the Grzegorczyk hierarchy.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W1982355434",
    "type": "article"
  },
  {
    "title": "A calculus of multiary sequent terms",
    "doi": "https://doi.org/10.1145/1929954.1929959",
    "publication_date": "2011-05-01",
    "publication_year": 2011,
    "authors": "José Espírito Santo; Luís Pinto",
    "corresponding_authors": "",
    "abstract": "Multiary sequent terms were originally introduced as a tool for proving termination of permutative conversions in cut-free sequent calculus. This work develops the language of multiary sequent terms into a term calculus for the computational (Curry-Howard) interpretation of a fragment of sequent calculus with cuts and cut-elimination rules. The system, called generalized multiary λ-calculus , is a rich extension of the λ-calculus where the computational content of the sequent calculus format is explained through an enlarged form of the application constructor. Such constructor exhibits the features of multiarity (the ability to form lists of arguments) and generality (the ability to prescribe a kind of continuation). The system integrates in a modular way the multiary λ-calculus and an isomorphic copy of the λ-calculus with generalized application, Λ J (in particular, natural deduction is captured internally up to isomorphism). In addition, the system: (i) comes with permutative conversion rules, whose role is to eliminate the new features of application; (ii) is equipped with reduction rules — either the μ-rule, typical of the multiary setting, or rules for cut-elimination, which enlarge the ordinary β-rule. This article establishes the metatheory of the system, with emphasis on the role of the μ-rule, and including a study of the interaction of reduction and permutative conversions.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2128959251",
    "type": "article"
  },
  {
    "title": "Reachability Problems in Piecewise FIFO Systems",
    "doi": "https://doi.org/10.1145/2071368.2071375",
    "publication_date": "2012-01-01",
    "publication_year": 2012,
    "authors": "Naghmeh Ghafari; Arie Gurfinkel; Nils Klarlund; Richard Trefler",
    "corresponding_authors": "",
    "abstract": "Systems consisting of several finite components that communicate via unbounded perfect FIFO channels (i.e., FIFO systems) arise naturally in modeling distributed systems. Despite well-known difficulties in analyzing such systems, they are of significant interest as they can describe a wide range of communication protocols. In this article, we study the problem of computing the set of reachable states of a FIFO system composed of piecewise components. This problem is closely related to calculating the set of all possible channel contents, that is, the limit language , for each control location. We present an algorithm for calculating the limit language of a system with a single communication channel. For multichannel systems, we show that the limit language is piecewise if the initial language is piecewise. Our construction is not effective in general; however, we provide algorithms for calculating the limit language of a restricted class of multichannel systems in which messages are not passed around in cycles through different channels. We show that the worst case complexity of our algorithms for single-channel and important subclasses of multichannel systems is exponential in the size of the initial content of the channels.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2139289843",
    "type": "article"
  },
  {
    "title": "Structural Analysis of Boolean Equation Systems",
    "doi": "https://doi.org/10.1145/2071368.2071376",
    "publication_date": "2012-01-01",
    "publication_year": 2012,
    "authors": "Jeroen J. A. Keiren; Michel Reniers; Tim A. C. Willemse",
    "corresponding_authors": "",
    "abstract": "We analyze the problem of solving Boolean equation systems through the use of structure graphs . The latter are obtained through an elegant set of Plotkin-style deduction rules. Our main contribution is that we show that equation systems with bisimilar structure graphs have the same solution. We show that our work conservatively extends earlier work, conducted by Keiren and Willemse, in which dependency graphs were used to analyze a subclass of Boolean equation systems, viz ., equation systems in standard recursive form . We illustrate our approach by a small example, demonstrating the effect of simplifying an equation system through minimization of its structure graph.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2144698929",
    "type": "article"
  },
  {
    "title": "Resource-bounded continuity and sequentiality for type-two functionals",
    "doi": "https://doi.org/10.1145/507382.507387",
    "publication_date": "2002-07-01",
    "publication_year": 2002,
    "authors": "Samuel R. Buss; Bruce M. Kapron",
    "corresponding_authors": "",
    "abstract": "We define notions of resource-bounded continuity and sequentiality for type-two functionals with total inputs, and prove that in the resource-bounded model there are continuous functionals which cannot be efficiently simulated by sequential functionals. We also show that for some naturally defined classes of continuous functionals an efficient simulation is possible.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2177400022",
    "type": "article"
  },
  {
    "title": "Some applications of logic to feasibility in higher types",
    "doi": "https://doi.org/10.1145/976706.976713",
    "publication_date": "2004-04-01",
    "publication_year": 2004,
    "authors": "Aleksandar Ignjatović; Arun Sharma",
    "corresponding_authors": "",
    "abstract": "While it is commonly accepted that computability on a Turing machine in polynomial time represents a correct formalization of the notion of a feasibly computable function, there is no similar agreement on how to extend this notion on functionals , that is, what functionals should be considered feasible. One possible paradigm was introduced by Mehlhorn, who extended Cobham's definition of feasible functions to type 2 functionals. Subsequently, this class of functionals (with inessential changes of the definition) was studied by Townsend who calls this class POLY , and by Kapron and Cook who call the same class basic feasible functionals . Kapron and Cook gave an oracle Turing machine model characterisation of this class. In this article, we demonstrate that the class of basic feasible functionals has recursion theoretic properties which naturally generalise the corresponding properties of the class of feasible functions, thus giving further evidence that the notion of feasibility of functionals mentioned above is correctly chosen. We also improve the Kapron and Cook result on machine representation.Our proofs are based on essential applications of logic. We introduce a weak fragment of second order arithmetic with second order variables ranging over functions from N N which suitably characterises basic feasible functionals, and show that it is a useful tool for investigating the properties of basic feasible functionals. In particular, we provide an example how one can extract feasible programs from mathematical proofs that use nonfeasible functions.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2170846453",
    "type": "article"
  },
  {
    "title": "From 2-Sequents and Linear Nested Sequents to Natural Deduction for Normal Modal Logics",
    "doi": "https://doi.org/10.1145/3461661",
    "publication_date": "2021-06-28",
    "publication_year": 2021,
    "authors": "Simone Martini; Andrea Masini; Margherita Zorzi",
    "corresponding_authors": "",
    "abstract": "We extend to natural deduction the approach of Linear Nested Sequents and of 2-sequents. Formulas are decorated with a spatial coordinate, which allows a formulation of formal systems in the original spirit of natural deduction -- only one introduction and one elimination rule per connective, no additional (structural) rule, no explicit reference to the accessibility relation of the intended Kripke models. We give systems for the normal modal logics from K to S4. For the intuitionistic versions of the systems, we define proof reduction, and prove proof normalization, thus obtaining a syntactical proof of consistency. For logics K and K4 we use existence predicates (following Scott) for formulating sound deduction rules.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W3175065535",
    "type": "article"
  },
  {
    "title": "Progression of Decomposed Local-Effect Action Theories",
    "doi": "https://doi.org/10.1145/3091119",
    "publication_date": "2017-04-30",
    "publication_year": 2017,
    "authors": "Denis Ponomaryov; Mikhail Soutchanski",
    "corresponding_authors": "",
    "abstract": "In many tasks related to reasoning about consequences of a logical theory, it is desirable to decompose the theory into a number of weakly related or independent components. However, a theory may represent knowledge that is subject to change, as a result of executing actions that have effects on some of the initial properties mentioned in the theory. Having once computed a decomposition of a theory, it is advantageous to know whether a decomposition has to be computed again in the newly changed theory (obtained from taking into account changes resulting from execution of an action). In this article, we address this problem in the scope of the situation calculus, where a change of an initial theory is related to the notion of progression. Progression provides a form of forward reasoning; it relies on forgetting values of those properties, which are subject to change, and computing new values for them. We consider decomposability and inseparability, two component properties known from the literature, and contribute by studying the conditions (1) when these properties are preserved and (2) when they are lost wrt progression and the related operation of forgetting. To show the latter, we demonstrate the boundaries using a number of negative examples. To show the former, we identify cases when these properties are preserved under forgetting and progression of initial theories in local-effect basic action theories of the situation calculus. Our article contributes to bridging two different communities in knowledge representation, namely, research on modularity and research on reasoning about actions.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2615306226",
    "type": "article"
  },
  {
    "title": "Good-for-Game QPTL: An Alternating Hodges Semantics",
    "doi": "https://doi.org/10.1145/3565365",
    "publication_date": "2022-10-21",
    "publication_year": 2022,
    "authors": "Dylan Bellier; Massimo Benerecetti; Dario Della Monica; Fabio Mogavero",
    "corresponding_authors": "",
    "abstract": "An extension of QPTL is considered where functional dependencies among the quantified variables can be restricted in such a way that their current values are independent of the future values of the other variables. This restriction is tightly connected to the notion of behavioral strategies in game-theory and allows the resulting logic to naturally express game-theoretic concepts. Inspired by the work on logics of dependence and independence, we provide a new compositional semantics for QPTL that allows for expressing such functional dependencies among variables. The fragment where only restricted quantifications are considered, called behavioral quantifications , allows for linear-time properties that are satisfiable if and only if they are realisable in the Pnueli-Rosner sense. This fragment can be decided, for both model checking and satisfiability , in 2 Exp Time and is expressively equivalent to QPTL , though significantly less succinct.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W3153705421",
    "type": "article"
  },
  {
    "title": "O-Minimal Invariants for Discrete-Time Dynamical Systems",
    "doi": "https://doi.org/10.1145/3501299",
    "publication_date": "2022-01-14",
    "publication_year": 2022,
    "authors": "Shaull Almagor; Dmitry Chistikov; Joël Ouaknine; James Worrell",
    "corresponding_authors": "",
    "abstract": "Termination analysis of linear loops plays a key rôle in several areas of computer science, including program verification and abstract interpretation. Already for the simplest variants of linear loops the question of termination relates to deep open problems in number theory, such as the decidability of the Skolem and Positivity Problems for linear recurrence sequences, or equivalently reachability questions for discrete-time linear dynamical systems. In this article, we introduce the class of o-minimal invariants , which is broader than any previously considered, and study the decidability of the existence and algorithmic synthesis of such invariants as certificates of non-termination for linear loops equipped with a large class of halting conditions. We establish two main decidability results, one of them conditional on Schanuel’s conjecture is transcendental number theory.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4205250428",
    "type": "article"
  },
  {
    "title": "A Category Theoretic View of Contextual Types: From Simple Types to Dependent Types",
    "doi": "https://doi.org/10.1145/3545115",
    "publication_date": "2022-06-29",
    "publication_year": 2022,
    "authors": "Jason Z. S. Hu; Brigitte Pientka; Ulrich Schöpp",
    "corresponding_authors": "",
    "abstract": "We describe the categorical semantics for a simply typed variant and a simplified dependently typed variant of Cocon, a contextual modal type theory where the box modality mediates between the weak function space that is used to represent higher-order abstract syntax (HOAS) trees and the strong function space that describes (recursive) computations about them. What makes Cocon different from standard type theories is the presence of first-class contexts and contextual objects to describe syntax trees that are closed with respect to a given context of assumptions. Following M. Hofmann's work, we use a presheaf model to characterise HOAS trees. Surprisingly, this model already provides the necessary structure to also model Cocon. In particular, we can capture the contextual objects of Cocon using a comonad $\\flat$ that restricts presheaves to their closed elements. This gives a simple semantic characterisation of the invariants of contextual types (e.g. substitution invariance) and identifies Cocon as a type-theoretic syntax of presheaf models. We further extend this characterisation to dependent types using categories with families and show that we can model a fragment of Cocon without recursor in the Fitch-style dependent modal type theory presented by Birkedal et. al..",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4298334981",
    "type": "article"
  },
  {
    "title": "Generalizing Parikh’s Criterion for Relevance-Sensitive Belief Revision",
    "doi": "https://doi.org/10.1145/3572907",
    "publication_date": "2022-11-25",
    "publication_year": 2022,
    "authors": "Theofanis Aravanis",
    "corresponding_authors": "Theofanis Aravanis",
    "abstract": "Parikh proposed his relevance-sensitive axiom to remedy the weakness of the classical AGM paradigm in addressing relevant change. An insufficiency of Parikh’s criterion, however, is its dependency on the contingent beliefs of a belief set to be revised, since the former only constrains the revision process of splittable theories (i.e., theories that can be divided in mutually disjoint compartments). The case of arbitrary non-splittable belief sets remains out of the scope of Parikh’s approach. On that premise, we generalize Parikh’s criterion, introducing (both axiomatically and semantically) a new notion of relevance, which we call relevance at the sentential level . We show that the proposed notion of relevance is universal (as it is applicable to arbitrary belief sets) and acts in a more refined way as compared to Parikh’s proposal; as we illustrate, this latter feature of relevance at the sentential level potentially leads to a significant drop in the computational resources required for implementing belief revision. Furthermore, we prove that Dalal’s popular revision operator respects, to a certain extent, relevance at the sentential level. Last but not least, the tight relation between local and relevance-sensitive revision is pointed out.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4309940924",
    "type": "article"
  },
  {
    "title": "A note on the complexity of propositional Hoare logic",
    "doi": "https://doi.org/10.1145/343369.343404",
    "publication_date": "2000-07-01",
    "publication_year": 2000,
    "authors": "Ernie Cohen; Dexter Kozen",
    "corresponding_authors": "",
    "abstract": "We provide a simpler alternative proof of the PSPACE -hardness of propositional Hoare logic (PHL).",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2027983931",
    "type": "article"
  },
  {
    "title": "Revisiting quantification in autoepistemic logic",
    "doi": "https://doi.org/10.1145/566385.566388",
    "publication_date": "2002-10-01",
    "publication_year": 2002,
    "authors": "Michael Kaminski; Guy Rey",
    "corresponding_authors": "",
    "abstract": "In this article, we introduce first-order autoepistemic logic. Our definition is semantical and is based on the intuition similar to that lying behind the definition of first-order default logic. Thus, our definition of first-order autoepistemic logic well complies with that of first-order default logic and circumscription, providing a substantial evidence for its acceptance.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2030773975",
    "type": "article"
  },
  {
    "title": "An elementary fragment of second-order lambda calculus",
    "doi": "https://doi.org/10.1145/1055686.1055695",
    "publication_date": "2005-04-01",
    "publication_year": 2005,
    "authors": "Klaus Aehlig; Jan Johannsen",
    "corresponding_authors": "",
    "abstract": "A fragment of second-order lambda calculus (System F ) is defined that characterizes the elementary recursive functions. Type quantification is restricted to be noninterleaved and stratified, that is, the types are assigned levels, and a quantified variable can only be instantiated by a type of smaller level, with a slightly liberalized treatment of the level zero.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W1984066424",
    "type": "article"
  },
  {
    "title": "Complexity results on DPLL and resolution",
    "doi": "https://doi.org/10.1145/1119439.1119442",
    "publication_date": "2006-01-01",
    "publication_year": 2006,
    "authors": "Paolo Liberatore",
    "corresponding_authors": "Paolo Liberatore",
    "abstract": "DPLL and resolution are two popular methods for solving the problem of propositional satisfiability. Rather than algorithms, they are families of algorithms, as their behavior depend on some choices they face during execution: DPLL depends on the choice of the literal to branch on; resolution depends on the choice of the pair of clauses to resolve at each step. The complexity of making the optimal choice is analyzed in this paper. Extending previous results, we prove that choosing the optimal literal to branch on in DPLL is Delta[log]^2-hard, and becomes NP^PP-hard if branching is only allowed on a subset of variables. Optimal choice in regular resolution is both NP-hard and CoNP-hard. The problem of determining the size of the optimal proofs is also analyzed: it is CoNP-hard for DPLL, and Delta[log]^2-hard if a conjecture we make is true. This problem is CoNP-hard for regular resolution.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W3121883445",
    "type": "article"
  },
  {
    "title": "On unification for bounded distributive lattices",
    "doi": "https://doi.org/10.1145/1227839.1227844",
    "publication_date": "2007-04-01",
    "publication_year": 2007,
    "authors": "Viorica Sofronie-Stokkermans",
    "corresponding_authors": "Viorica Sofronie-Stokkermans",
    "abstract": "We give a method for deciding unifiability in the variety of bounded distributive lattices. For this, we reduce the problem of deciding whether a unification problem S has a solution to the problem of checking the satisfiability of a set Φ S of ground clauses. This is achieved by using a structure-preserving translation to clause form. The satisfiability check can then be performed by either a resolution-based theorem prover or a SAT checker. We apply the method to unification with free constants and to unification with linear constant restrictions, and show that, in fact, it yields a decision procedure for the positive theory of the variety of bounded distributive lattices. We also consider the problem of unification over (i.e., in an algebraic extension of) the free lattice. Complexity issues are also addressed.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W1983663398",
    "type": "article"
  },
  {
    "title": "Reasoning with recursive loops under the PLP framework",
    "doi": "https://doi.org/10.1145/1380572.1380576",
    "publication_date": "2008-08-01",
    "publication_year": 2008,
    "authors": "Yi-Dong Shen",
    "corresponding_authors": "Yi-Dong Shen",
    "abstract": "Recursive loops in a logic program present a challenging problem to the PLP (Probabilistic Logic Programming) framework. On the one hand, they loop forever so that the PLP backward-chaining inferences would never stop. On the other hand, they may generate cyclic influences, which are disallowed in Bayesian networks. Therefore, in existing PLP approaches, logic programs with recursive loops are considered to be problematic and thus are excluded. In this article, we propose a novel solution to this problem by making use of recursive loops to build a stationary dynamic Bayesian network. We introduce a new PLP formalism, called a Bayesian knowledge base . It allows recursive loops and contains logic clauses of the form A ← A 1 ,…, A l , true , Context , Types , which naturally formulate the knowledge that the A i s have direct influences on A in the context Context under the type constraints Types . We use the well-founded model of a logic program to define the direct influence relation and apply SLG-resolution to compute the space of random variables together with their parental connections. This establishes a clear declarative semantics for a Bayesian knowledge base. We view a logic program with recursive loops as a special temporal model, where backward-chaining cycles of the form A ← … A ← … are interpreted as feedbacks. This extends existing PLP approaches, which mainly aim at (nontemporal) relational models.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2122666826",
    "type": "article"
  },
  {
    "title": "Parallel-Correctness and Containment for Conjunctive Queries with Union and Negation",
    "doi": "https://doi.org/10.1145/3329120",
    "publication_date": "2019-06-07",
    "publication_year": 2019,
    "authors": "Gaetano Geck; Bas Ketsman; Frank Neven; Thomas Schwentick",
    "corresponding_authors": "",
    "abstract": "Single-round multiway join algorithms first reshuffle data over many servers and then evaluate the query at hand in a parallel and communication-free way. A key question is whether a given distribution policy for the reshuffle is adequate for computing a given query, also referred to as parallel-correctness. This article extends the study of the complexity of parallel-correctness and its constituents, parallel-soundness and parallel-completeness, to unions of conjunctive queries with negation. As a by-product, it is shown that the containment problem for conjunctive queries with negation is coNEXPTIME-complete.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2255433971",
    "type": "article"
  },
  {
    "title": "Characterisation of Normalisation Properties for λμ using Strict Negated Intersection Types",
    "doi": "https://doi.org/10.1145/3149823",
    "publication_date": "2018-01-31",
    "publication_year": 2018,
    "authors": "Steffen van Bakel",
    "corresponding_authors": "Steffen van Bakel",
    "abstract": "We show characterisation results for normalisation, head-normalisation, and strong normalisation for λ μ using intersection types. We reach these results for a strict notion of type assignment for λ μ that is the natural restriction of the domain-based system of van Bakel et al. (2011) for λ μ by limiting the type inclusion relation to just intersection elimination. We show that this system respects β μ-equality, by showing both soundness and completeness results. We then define a notion of reduction on derivations that corresponds to cut-elimination, and show that this is strongly normalisable. We use this strong normalisation result to show an approximation result, and through that a characterisation of head-normalisation. Using the approximation result, we show that there is a very strong relation between the system of van Bakel et al. (2011) and ours. We then introduce a notion of type assignment that eliminates ω as an assignable type, and show, using the strong normalisation result for derivation reduction, that all terms typeable in this system are strongly normalisable as well, and show that all strongly normalisable terms are typeable. We conclude by adding type variables to our system, and show that system essentially is that of van Bakel (2010b).",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2788816999",
    "type": "article"
  },
  {
    "title": "Compositional Synthesis of Piece-Wise Functions by Learning Classifiers",
    "doi": "https://doi.org/10.1145/3173545",
    "publication_date": "2018-04-30",
    "publication_year": 2018,
    "authors": "Daniel Neider; Shambwaditya Saha; P. Madhusudan",
    "corresponding_authors": "",
    "abstract": "We present a novel general technique that uses classifier learning to synthesize piece-wise functions (functions that split the domain into regions and apply simpler functions to each region) against logical synthesis specifications. Our framework works by combining a synthesizer of functions for fixed concrete inputs and a synthesizer of predicates that can be used to define regions. We develop a theory of single-point refutable specifications that facilitate generating concrete counterexamples using constraint solvers. We implement the framework for synthesizing piece-wise functions in linear integer arithmetic, combining leaf expression synthesis using constraint-solving with predicate synthesis using enumeration, and tie them together using a decision tree classifier. We demonstrate that this compositional approach is competitive compared to existing synthesis engines on a set of synthesis specifications.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2802858733",
    "type": "article"
  },
  {
    "title": "Relating Paths in Transition Systems",
    "doi": "https://doi.org/10.1145/3231596",
    "publication_date": "2018-07-31",
    "publication_year": 2018,
    "authors": "Cătălin Dima; Bastien Maubert; Sophie Pinchinat",
    "corresponding_authors": "",
    "abstract": "We revisit Janin and Walukiewicz’s classic result on the expressive completeness of the modal mu-calculus with respect to Monadic Second Order Logic (MSO), which is where the mu-calculus corresponds precisely to the fragment of MSO that is invariant under bisimulation. We show that adding binary relations over finite paths in the picture may alter the situation. We consider a general setting where finite paths of transition systems are linked by means of a fixed binary relation. This setting gives rise to natural extensions of MSO and the mu-calculus, that we call the MSO with paths relation and the jumping mu-calculus , the expressivities of which we aim at comparing. We first show that “bounded-memory” binary relations bring about no additional expressivity to either of the two logics, and thus preserve expressive completeness. In contrast, we show that for a natural, classic “infinite-memory” binary relation stemming from games with imperfect information, the existence of a winning strategy in such games, though expressible in the bisimulation-invariant fragment of MSO with paths relation, cannot be expressed in the jumping mu-calculus. Expressive completeness thus fails for this relation. These results crucially rely on our observation that the jumping mu-calculus has a tree automata counterpart: the jumping tree automata , hence the name of the jumping mu-calculus. We also prove that for observable winning conditions, the existence of winning strategies in games with imperfect information is expressible in the jumping mu-calculus. Finally, we derive from our main theorem that jumping automata cannot be projected, and ATL with imperfect information does not admit expansion laws.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2891752042",
    "type": "article"
  },
  {
    "title": "Where fail-safe default logics fail",
    "doi": "https://doi.org/10.1145/1227839.1227842",
    "publication_date": "2007-04-01",
    "publication_year": 2007,
    "authors": "Paolo Liberatore",
    "corresponding_authors": "Paolo Liberatore",
    "abstract": "Reiter's original definition of default logic allows for the application of a default that contradicts one previously applied. We call this condition failure . The possibility of generating failures has been in the past considered a semantical problem, and variants have been proposed to solve it. We show that it is instead a computational feature that is needed to encode some domains into default logic.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2951291273",
    "type": "article"
  },
  {
    "title": "Geometry of Interaction for MALL via Hughes--Van Glabbeek Proof-Nets",
    "doi": "https://doi.org/10.1145/3234694",
    "publication_date": "2018-10-31",
    "publication_year": 2018,
    "authors": "Masahiro Hamano",
    "corresponding_authors": "Masahiro Hamano",
    "abstract": "This article presents, for the first time, a Geometry of Interaction (GoI) interpretation inspired from Hughes--Van Glabbeek (HvG) proof-nets for multiplicative additive linear logic (MALL). Our GoI dynamically captures HvG’s geometric correctness criterion—the toggling cycle condition—in terms of algebraic operators. Our new ingredient is a scalar extension of the *-algebra in Girard’s *-ring of partial isometries over a Boolean polynomial ring with literals of eigenweights as indeterminates. To capture feedback arising from cuts, we construct a finer-grained execution formula. The expansion of this execution formula is longer than that for collections of slices for multiplicative GoI, hence it is harder to prove termination. Our GoI gives a dynamical, semantical account of Boolean valuations (in particular, pruning sub-proofs), conversion of weights (in particular, α-conversion), and additive (co)contraction, peculiar to additive proof-theory. Termination of our execution formula is shown to correspond to HvG’s toggling criterion. The slice-wise restriction of our execution formula (by collapsing the Boolean structure) yields the well-known correspondence, explicit or implicit in previous works on multiplicative GoI, between the convergence of execution formulas and acyclicity of proof-nets. Feedback arising from the execution formula by restricting to the Boolean polynomial structure yields autonomous definability of eigenweights among cuts from the rest of the eigenweights.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2964244682",
    "type": "article"
  },
  {
    "title": "Probabilistic Epistemic Updates on Algebras",
    "doi": "https://doi.org/10.1145/3341725",
    "publication_date": "2019-08-21",
    "publication_year": 2019,
    "authors": "Willem Conradie; Sabine Frittella; Alessandra Palmigiano; Apostolos Tzimoulis; Nachoem M. Wijnberg",
    "corresponding_authors": "",
    "abstract": "The present article contributes to the development of the mathematical theory of epistemic updates using the tools of duality theory. Here, we focus on Probabilistic Dynamic Epistemic Logic (PDEL). We dually characterize the product update construction of PDEL-models as a certain construction transforming the complex algebras associated with the given model into the complex algebra associated with the updated model. Thanks to this construction, an interpretation of the language of PDEL can be defined on algebraic models based on Heyting algebras. This justifies our proposal for the axiomatization of the intuitionistic counterpart of PDEL.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2969806710",
    "type": "article"
  },
  {
    "title": "Beyond Uniform Equivalence between Answer-set Programs",
    "doi": "https://doi.org/10.1145/3422361",
    "publication_date": "2020-12-02",
    "publication_year": 2020,
    "authors": "Johannes Oetsch; Martina Seidl; Hans Tompits; Stefan Woltran",
    "corresponding_authors": "",
    "abstract": "This article deals with advanced notions of equivalence between nonmonotonic logic programs under the answer-set semantics, a topic of considerable interest, because such notions form the basis for program verification and are useful for program optimisation, debugging, and modular programming. In fact, there is extensive research in answer-set programming (ASP) dealing with different notions of equivalence between programs. Prominent among these notions is uniform equivalence , which checks whether two programs have the same semantics when joined with an arbitrary set of facts. In this article, we study a family of more fine-grained versions of uniform equivalence, viz. relativised uniform equivalence with projection , which extends standard uniform equivalence in terms of two additional parameters: one for specifying the input alphabet and one for specifying the output alphabet for programs. In particular, the second parameter is used for projecting answer sets to a set of designated output atoms. Answer-set projection, in particular, allows to compare programs that make use of different auxiliary atoms, which is important for practical programming aspects. We introduce novel semantic characterisations for the program correspondence problems under consideration and analyse their computational complexity. In the general case, deciding these problems lies on the third level of the polynomial hierarchy. Therefore, this task cannot be efficiently reduced to propositional answer-set programs itself (under the usual complexity-theoretic assumptions). However, reductions to quantified Boolean formulas (QBFs) are feasible. Indeed, we provide efficient (in fact, linear-time constructible) reductions to QBFs and discuss simplifications for certain special cases. These QBF reductions yield the basis for a prototype implementation, the system cc ⊤, for deciding correspondence problems by using off-the-shelf QBF solvers. We discuss an application of cc ⊤ for verifying the correctness of solutions by students drawn from a laboratory course on logic programming and knowledge representation at the Technische Universität Wien, employing relativised uniform equivalence with projection as the underlying program correspondence notion.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W3108594459",
    "type": "article"
  },
  {
    "title": "Alternating Tree Automata with Qualitative Semantics",
    "doi": "https://doi.org/10.1145/3431860",
    "publication_date": "2020-12-17",
    "publication_year": 2020,
    "authors": "Raphaël Berthon; Nathanaël Fijalkow; Emmanuel Filiot; Shibashis Guha; Bastien Maubert; Aniello Murano; Laureline Pinault; Sophie Pinchinat; Sasha Rubin; Olivier Serre",
    "corresponding_authors": "",
    "abstract": "We study alternating automata with qualitative semantics over infinite binary trees: Alternation means that two opposing players construct a decoration of the input tree called a run, and the qualitative semantics says that a run of the automaton is accepting if almost all branches of the run are accepting. In this article, we prove a positive and a negative result for the emptiness problem of alternating automata with qualitative semantics. The positive result is the decidability of the emptiness problem for the case of Büchi acceptance condition. An interesting aspect of our approach is that we do not extend the classical solution for solving the emptiness problem of alternating automata, which first constructs an equivalent non-deterministic automaton. Instead, we directly construct an emptiness game making use of imperfect information. The negative result is the undecidability of the emptiness problem for the case of co-Büchi acceptance condition. This result has two direct consequences: the undecidability of monadic second-order logic extended with the qualitative path-measure quantifier and the undecidability of the emptiness problem for alternating tree automata with non-zero semantics, a recently introduced probabilistic model of alternating tree automata.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W3112127587",
    "type": "article"
  },
  {
    "title": "De Morgan Dual Nominal Quantifiers Modelling Private Names in Non-Commutative Logic",
    "doi": "https://doi.org/10.1145/3325821",
    "publication_date": "2019-07-16",
    "publication_year": 2019,
    "authors": "Ross Horne; Alwen Tiu; Bogdan Aman; Gabriel Ciobanu",
    "corresponding_authors": "",
    "abstract": "This paper explores the proof theory necessary for recommending an expressive but decidable first-order system, named MAV1, featuring a de Morgan dual pair of nominal quantifiers. These nominal quantifiers called `new' and `wen' are distinct from the self-dual Gabbay-Pitts and Miller-Tiu nominal quantifiers. The novelty of these nominal quantifiers is they are polarised in the sense that `new' distributes over positive operators while `wen' distributes over negative operators. This greater control of bookkeeping enables private names to be modelled in processes embedded as formulae in MAV1. The technical challenge is to establish a cut elimination result, from which essential properties including the transitivity of implication follow. Since the system is defined using the calculus of structures, a generalisation of the sequent calculus, novel techniques are employed. The proof relies on an intricately designed multiset-based measure of the size of a proof, which is used to guide a normalisation technique called splitting. The presence of equivariance, which swaps successive quantifiers, induces complex inter-dependencies between nominal quantifiers, additive conjunction and multiplicative operators in the proof of splitting. Every rule is justified by an example demonstrating why the rule is necessary for soundly embedding processes and ensuring that cut elimination holds.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W3125770603",
    "type": "article"
  },
  {
    "title": "Parameterized Weighted Containment",
    "doi": "https://doi.org/10.1145/2665076",
    "publication_date": "2014-12-23",
    "publication_year": 2014,
    "authors": "Guy Avni; Orna Kupferman",
    "corresponding_authors": "",
    "abstract": "Partially specified systems and specifications are used in formal methods such as stepwise design and query checking. Existing methods consider a setting in which systems and their correctness are Boolean. In recent years, there has been growing interest and need for quantitative formal methods, where systems may be weighted and specifications may be multivalued. Weighted automata, which map input words to a numerical value, play a key role in quantitative reasoning. Technically, every transition in a weighted automaton A has a cost, and the value A assigns to a finite word w is the sum of the costs on the transitions traversed along the most expensive accepting run of A on w . We study parameterized weighted containment : given three weighted automata A , B , and C , with B being partial, the goal is to find an assignment to the missing costs in B so that we end up with B ′ for which B ′≤ C , where ≤ is the weighted counterpart of containment. We also consider a one-sided version of the problem, where only A or only C is given in addition to B , and the goal is to find a minimal assignment with which A ≤ B ′ or, respectively, a maximal one with which B ′ ≤ C . We argue that both problems are useful in stepwise design of weighted systems as well as approximated minimization of weighted automata. We show that when the automata are deterministic, we can solve the problems in polynomial time. Our solution is based on the observation that the set of legal assignments to k missing costs forms a k -dimensional polytope. The technical challenge is to find an assignment in polynomial time even though the polytope is defined by means of exponentially many inequalities. We do so by developing a divide-and-conquer algorithm based on a separation oracle for polytopes. For nondeterministic automata, the weighted setting is much more complex, and in fact even nonparameterized containment is undecidable. We are able to show positive results for variants of the problems, where containment is replaced by simulation.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W1966557697",
    "type": "article"
  },
  {
    "title": "On the Power of Substitution in the Calculus of Structures",
    "doi": "https://doi.org/10.1145/2701424",
    "publication_date": "2015-04-21",
    "publication_year": 2015,
    "authors": "Novak Novaković; Lutz Straßburger",
    "corresponding_authors": "",
    "abstract": "There are two contributions in this article. First, we give a direct proof of the known fact that Frege systems with substitution can be p-simulated by the calculus of structures (CoS) extended with the substitution rule. This is done without referring to the p-equivalence of extended Frege systems and Frege systems with substitution. Second, we then show that the cut-free CoS with substitution is p-equivalent to the cut-free CoS with extension.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W1979474827",
    "type": "article"
  },
  {
    "title": "Logic of Intuitionistic Interactive Proofs (Formal Theory of Perfect Knowledge Transfer)",
    "doi": "https://doi.org/10.1145/2811263",
    "publication_date": "2015-09-17",
    "publication_year": 2015,
    "authors": "Simon Kramer",
    "corresponding_authors": "Simon Kramer",
    "abstract": "We produce a decidable super-intuitionistic normal modal logic of internalised intuitionistic (and thus disjunctive and monotonic) interactive proofs (LIiP) from an existing classical counterpart of classical monotonic non-disjunctive interactive proofs (LiP). Intuitionistic interactive proofs effect a durable epistemic impact in the possibly adversarial communication medium CM (which is imagined as a distinguished agent), and only in that, that consists in the permanent induction of the perfect and thus disjunctive knowledge of their proof goal by means of CM's knowledge of the proof: If CM knew my proof then CM would persistently and also disjunctively know that my proof goal is true. So intuitionistic interactive proofs effect a lasting transfer of disjunctive propositional knowledge (disjunctively knowable facts) in the communication medium of multi-agent distributed systems via the transmission of certain individual knowledge (knowable intuitionistic proofs). Our (necessarily) CM-centred notion of proof is also a disjunctive explicit refinement of KD45-belief, and yields also such a refinement of standard S5-knowledge. Monotonicity but not communality is a commonality of LiP, LIiP, and their internalised notions of proof. As a side-effect, we offer a short internalised proof of the Disjunction Property of Intuitionistic Logic (originally proved by Goedel).",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2051231771",
    "type": "article"
  },
  {
    "title": "Ramsey-Based Inclusion Checking for Visibly Pushdown Automata",
    "doi": "https://doi.org/10.1145/2774221",
    "publication_date": "2015-08-26",
    "publication_year": 2015,
    "authors": "Oliver Friedmann; Felix Klaedtke; Martin Lange",
    "corresponding_authors": "",
    "abstract": "Checking whether one formal language is included in another is important in many verification tasks. In this article, we provide solutions for checking the inclusion of languages given by visibly pushdown automata over both finite and infinite words. Visibly pushdown automata are a richer automaton model than the classical finite-state automata, which allows one, for example, to reason about the nesting of procedure calls in the executions of recursive imperative programs. The presented solutions do not rely on explicit automaton constructions for determinization and complementation. Instead, they are more direct and generalize the so-called Ramsey-based inclusion-checking algorithms, which apply to classical finite-state automata and proved to be effective there to visibly pushdown automata. We also experimentally evaluate these algorithms, demonstrating the virtues of avoiding explicit determinization and complementation constructions.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2063384625",
    "type": "article"
  },
  {
    "title": "Refining the Process Rewrite Systems Hierarchy via Ground Tree Rewrite Systems",
    "doi": "https://doi.org/10.1145/2629679",
    "publication_date": "2014-08-01",
    "publication_year": 2014,
    "authors": "Stefan Göller; Anthony W. Lin",
    "corresponding_authors": "",
    "abstract": "In his seminal paper, Mayr introduced the well-known process rewrite systems (PRS) hierarchy, which contains many well-studied classes of infinite-state systems including pushdown systems (PDS), Petri nets, and PA-processes. A separate development in the term rewriting community introduced the notion of ground tree rewrite systems (GTRS), which is a model that strictly extends PDS while still enjoying desirable decidable properties. There have been striking similarities between the verification problems that have been shown decidable (and undecidable) over GTRS and over models in the PRS hierarchy such as PA and PAD processes. It is open to what extent PRS and GTRS are connected in terms of their expressive power. In this article, we pinpoint the exact connection between GTRS and models in the PRS hierarchy in terms of their expressive power with respect to strong, weak, and branching bisimulation. Among others, this connection allows us to give new insights into the decidability results for subclasses of PRS, such as simpler proofs of known decidability results of verifications problems on PAD.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2065713030",
    "type": "article"
  },
  {
    "title": "Three syntactic theories for combinatory graph reduction",
    "doi": "https://doi.org/10.1145/2528932",
    "publication_date": "2013-11-01",
    "publication_year": 2013,
    "authors": "Olivier Danvy; Ian Zerny",
    "corresponding_authors": "",
    "abstract": "We present a purely syntactic theory of graph reduction for the canonical combinators S, K, and I, where graph vertices are represented with evaluation contexts and let expressions. We express this rst syntactic theory as a storeless reduction semantics of combinatory terms. We then factor out the introduction of let expressions to denote as many graph vertices as possible upfront instead of on demand . The factored terms can be interpreted as term graphs in the sense of Barendregt et al. We express this second syntactic theory, which we prove equivalent to the rst, as a storeless reduction semantics of combinatory term graphs. We then recast let bindings as bindings in a global store, thus shifting, in Strachey's words, from denotable entities to storable entities. The store-based terms can still be interpreted as term graphs. We express this third syntactic theory, which we prove equivalent to the second, as a store-based reduction semantics of combinatory term graphs. We then refocus this store-based reduction semantics into a store-based abstract machine. The architecture of this store-based abstract machine coincides with that of Turner's original reduction machine. The three syntactic theories presented here therefore properly account for combinatory graph reduction As We Know It. These three syntactic theories scale to handling the Y combinator. This article therefore illustrates the scientic consensus of theoreticians and implementors about graph reduction: it is the same combinatory elephant.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2073131294",
    "type": "article"
  },
  {
    "title": "On the Variable Hierarchy of First-Order Spectra",
    "doi": "https://doi.org/10.1145/2733376",
    "publication_date": "2015-03-21",
    "publication_year": 2015,
    "authors": "Eryk Kopczyński; Tony Tan",
    "corresponding_authors": "",
    "abstract": "The spectrum of a first-order logic sentence is the set of natural numbers that are cardinalities of its finite models. In this article, we study the hierarchy of first-order spectra based on the number of variables. It has been conjectured that it collapses to three variables. We show the opposite: it forms an infinite hierarchy. However, despite the fact that more variables can express more spectra, we show that to establish whether the class of first-order spectra is closed under complement, it is sufficient to consider sentences using only three variables and binary relations.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2146314802",
    "type": "article"
  },
  {
    "title": "Safety and Liveness, Weakness and Strength, and the Underlying Topological Relations",
    "doi": "https://doi.org/10.1145/2532440",
    "publication_date": "2014-04-01",
    "publication_year": 2014,
    "authors": "Cindy Eisner; Dana Fisman; John Havlicek",
    "corresponding_authors": "",
    "abstract": "We present a characterization that shows what it means for a formula to be a weak or strong version of another formula. We show that the weak version of a formula is not the same as Alpern and Schneider's safety component, but can be achieved by taking the closure in the Cantor topology over an augmented alphabet in which every formula is satisfiable. The resulting characterization allows us to show that the set of semantically weak formulas is exactly the set of nonpathological safety formulas. Furthermore, we use the characterization to show that the original versions of the ieee standard temporal logics psl and sva are broken, and we show that the source of the problem lies in the semantics of the sere intersection and fusion operators. Finally, we use the topological characterization to show the internal consistency of the alternative semantics adopted by the latest version of the psl standard.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2164131403",
    "type": "article"
  },
  {
    "title": "Computational Complexity Via Finite Types",
    "doi": "https://doi.org/10.1145/2764906",
    "publication_date": "2015-06-16",
    "publication_year": 2015,
    "authors": "Andrea Asperti",
    "corresponding_authors": "Andrea Asperti",
    "abstract": "We address computational complexity writing polymorphic functions between finite types (i.e., types with a finite number of canonical elements), expressing costs in terms of the cardinality of these types. This allows us to rediscover, in a more syntactical setting, the known result that the different levels in the hierarchy of higher-order primitive recursive functions (Gödel system T), when interpreted over finite structures, precisely capture basic complexity classes: functions of rank 1 characterize LOGSPACE, rank 2 PTIME, rank 3 PSPACE, rank 4 EXPTIME = DTIME(2 poly ), and so on.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2199053348",
    "type": "article"
  },
  {
    "title": "How Hard Is Positive Quantification?",
    "doi": "https://doi.org/10.1145/2981544",
    "publication_date": "2016-11-03",
    "publication_year": 2016,
    "authors": "Aleksy Schubert; Paweł Urzyczyn; Daria Walukiewicz-Chrząszcz",
    "corresponding_authors": "",
    "abstract": "We show that the constructive predicate logic with positive (covariant) quantification is hard for doubly exponential universal time, that is, for the class co- 2-N exptime . Our approach is to represent proof-search as computation of an alternating automaton. The memory of the automaton is structured in a way that strictly corresponds to scopes of the binders used in the constructed proof. This provides an application of automata-theoretic techniques in proof theory.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2547321601",
    "type": "article"
  },
  {
    "title": "Deductive inference for the interiors and exteriors of horn theories",
    "doi": "https://doi.org/10.1145/2287718.2287723",
    "publication_date": "2012-08-01",
    "publication_year": 2012,
    "authors": "Kazuhisa Makino; Hirotaka Ono",
    "corresponding_authors": "",
    "abstract": "In this article, we investigate deductive inference for interiors and exteriors of Horn knowledge bases, where interiors and exteriors were introduced by Makino and Ibaraki [1996] to study stability properties of knowledge bases. We present a linear time algorithm for deduction for interiors and show that deduction is coNP-complete for exteriors. Under model-based representation, we show that the deduction problem for interiors is NP-complete while the one for exteriors is coNP-complete. As for Horn envelopes of exteriors, we show that it is linearly solvable under model-based representation, while it is coNP-complete under formula-based representation. We also discuss polynomially solvable cases for all the intractable problems.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W1484469872",
    "type": "article"
  },
  {
    "title": "Logical queries over views",
    "doi": "https://doi.org/10.1145/1656242.1656243",
    "publication_date": "2010-01-01",
    "publication_year": 2010,
    "authors": "James Bailey; Guozhu Dong; Anthony Widjaja To",
    "corresponding_authors": "",
    "abstract": "We study the problem of deciding the satisfiability of first-order logic queries over views, with our aim to delimit the boundary between the decidable and the undecidable fragments of this language. Views currently occupy a central place in database research due to their role in applications such as information integration and data warehousing. Our main result is the identification of a decidable class of first-order queries over unary conjunctive views that generalizes the decidability of the classical class of first-order sentences over unary relations known as the Löwenheim class. We then demonstrate how various extensions of this class lead to undecidability and also provide some expressivity results. Besides its theoretical interest, our new decidable class is potentially interesting for use in applications such as deciding implication of complex dependencies, analysis of a restricted class of active database rules, and ontology reasoning.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2004894395",
    "type": "article"
  },
  {
    "title": "Erratum for “What causes a system to satisfy a specification?”",
    "doi": "https://doi.org/10.1145/1805950.1805959",
    "publication_date": "2010-07-01",
    "publication_year": 2010,
    "authors": "Hana Chockler; Joseph Y. Halpern; Orna Kupferman",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2075382334",
    "type": "erratum"
  },
  {
    "title": "Translating to Co-Büchi Made Tight, Unified, and Useful",
    "doi": "https://doi.org/10.1145/2362355.2362357",
    "publication_date": "2012-10-01",
    "publication_year": 2012,
    "authors": "Udi Boker; Orna Kupferman",
    "corresponding_authors": "",
    "abstract": "We solve the longstanding open problems of the blow-up involved in the translations, when possible, of a nondeterministic Büchi word automaton (NBW) to a nondeterministic co-Büchi word automaton (NCW) and to a deterministic co-Büchi word automaton (DCW). For the NBW to NCW translation, the currently known upper bound is 2 O(n log n) and the lower bound is 1.5 n . We improve the upper bound to n 2 n and describe a matching lower bound of 2 Ω(n) . For the NBW to DCW translation, the currently known upper bound is 2 O(n log n) . We improve it to 2 O(n) , which is asymptotically tight. Both of our upper-bound constructions are based on a simple subset construction, do not involve intermediate automata with richer acceptance conditions, and can be implemented symbolically. We continue and solve the open problems of translating nondeterministic Streett, Rabin, Muller, and parity word automata to NCW and to DCW. Going via an intermediate NBW is not optimal and we describe direct, simple, and asymptotically tight constructions, involving a 2 Θ(n) blow-up. The constructions are variants of the subset construction, providing a unified approach for translating all common classes of automata to NCW and DCW. Beyond the theoretical importance of the results, we point to numerous applications of the new constructions. In particular, they imply a simple subset-construction based translation, when possible, of LTL to deterministic Büchi word automata.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2095489261",
    "type": "article"
  },
  {
    "title": "Complexity of Data Dependence Problems for Program Schemas with Concurrency",
    "doi": "https://doi.org/10.1145/2159531.2159537",
    "publication_date": "2012-04-01",
    "publication_year": 2012,
    "authors": "Sebastian Danicic; Robert M. Hierons; Michael R. Laurence",
    "corresponding_authors": "",
    "abstract": "The problem of deciding whether one point in a program is data dependent upon another is fundamental to program analysis and has been widely studied. In this article we consider this problem at the abstraction level of program schemas in which computations occur in the Herbrand domain of terms and predicate symbols, which represent arbitrary predicate functions, are allowed. Given a vertex l in the flowchart of a schema S having only equality (variable copying) assignments, and variables v , w , we show that it is PSPACE-hard to decide whether there exists an execution of a program defined by S in which v holds the initial value of w at at least one occurrence of l on the path of execution, with membership in PSPACE holding provided there is a constant upper bound on the arity of any predicate in S . We also consider the ‘dual’ problem in which v is required to hold the initial value of w at every occurrence of l , for which the analogous results hold. Additionally, the former problem for programs with nondeterministic branching (in effect, free schemas) in which assignments with functions are allowed is proved to be polynomial-time decidable provided a constant upper bound is placed upon the number of occurrences of the concurrency operator in the schemas being considered. This result is promising since many concurrent systems have a relatively small number of threads (concurrent processes), especially when compared with the number of statements they have.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2121670372",
    "type": "article"
  },
  {
    "title": "Complexity of propositional proofs under a promise",
    "doi": "https://doi.org/10.1145/1740582.1740586",
    "publication_date": "2010-05-01",
    "publication_year": 2010,
    "authors": "Nachum Dershowitz; Iddo Tzameret",
    "corresponding_authors": "",
    "abstract": "We study—within the framework of propositional proof complexity—the problem of certifying unsatisfiability of CNF formulas under the promise that any satisfiable formula has many satisfying assignments, where many stands for an explicitly specified function Λ in the number of variables n . To this end, we develop propositional proof systems under different measures of promises (i.e., different Λ) as extensions of resolution. This is done by augmenting resolution with axioms that, roughly, can eliminate sets of truth assignments defined by Boolean circuits. We then investigate the complexity of such systems, obtaining an exponential separation in the average case between resolution under different size promises: (1) Resolution has polynomial-size refutations for all unsatisfiable 3CNF formulas when the promise is ϵ…2 n , for any constant 0&lt;ϵ&lt;1. (2) There are no subexponential size resolution refutations for random 3CNF formulas, when the promise is 2 Δ n , for any constant 0&lt;δ&lt;1 (and the number of clauses is O ( n 3/2-ϵ ), for 0&lt;ϵ&lt;1/2). “ Goods Satisfactory or Money Refunded ” —The Eaton Promise",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2153912760",
    "type": "article"
  },
  {
    "title": "Basic theory of feature trees",
    "doi": "https://doi.org/10.1145/1013560.1013561",
    "publication_date": "2004-07-01",
    "publication_year": 2004,
    "authors": "Pawel Mielniczuk",
    "corresponding_authors": "Pawel Mielniczuk",
    "abstract": "We present a decision algorithm for the problem Val ( FT ) of deciding validity of first-order sentences in the theory of feature trees. Its time complexity is exp ⌊c·m⌋ ( c · n ) where n is the length of a sentence, m is the quantifier depth of a sequence, and c is a constant. The function exp i ( j ) is an exponential tower of 2's of height i , to power j (exp 0 ( j ) = j and exp i +1 ( j ) = 2 exp i ( j ) ). Moreover we prove that the presented algorithm is optimal, deriving a lower bound which matches the upper one.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2125226703",
    "type": "article"
  },
  {
    "title": "Kleene algebra with domain",
    "doi": "https://doi.org/10.1145/1166109.1166116",
    "publication_date": "2006-10-01",
    "publication_year": 2006,
    "authors": "Jules Desharnais; Bernhard Möller; Georg Struth",
    "corresponding_authors": "",
    "abstract": "We propose Kleene algebra with domain (KAD), an extension of Kleene algebra by simple equational axioms for a domain and a codomain operation. KAD considerably augments the expressiveness of Kleene algebra, in particular for the specification and analysis of programs and state transition systems. We develop the basic calculus, present the most interesting models and discuss some related theories. We demonstrate applicability by two examples: algebraic reconstructions of Noethericity and propositional Hoare logic based on equational reasoning.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2953324945",
    "type": "article"
  },
  {
    "title": "Higher-order Recursion Schemes and Collapsible Pushdown Automata: Logical Properties",
    "doi": "https://doi.org/10.1145/3452917",
    "publication_date": "2021-04-30",
    "publication_year": 2021,
    "authors": "Christopher H. Broadbent; Arnaud Carayol; C.-H. Luke Ong; Olivier Serre",
    "corresponding_authors": "",
    "abstract": "This article studies the logical properties of a very general class of infinite ranked trees, namely, those generated by higher-order recursion schemes. We consider, for both monadic second-order logic and modal <?TeX $\\mu$?> -calculus, three main problems: model-checking, logical reflection (a.k.a. global model-checking, that asks for a finite description of the set of elements for which a formula holds), and selection (that asks, if exists, for some finite description of a set of elements for which an MSO formula with a second-order free variable holds). For each of these problems, we provide an effective solution. This is obtained, thanks to a known connection between higher-order recursion schemes and collapsible pushdown automata and on previous work regarding parity games played on transition graphs of collapsible pushdown automata.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W3161173369",
    "type": "article"
  },
  {
    "title": "Generalized Realizability and Basic Logic",
    "doi": "https://doi.org/10.1145/3468856",
    "publication_date": "2021-09-08",
    "publication_year": 2021,
    "authors": "A. Yu. Konovalov",
    "corresponding_authors": "A. Yu. Konovalov",
    "abstract": "Let V be a set of number-theoretical functions. We define a notion of absolute V -realizability for predicate formulas and sequents in such a way that the indices of functions in V are used for interpreting the implication and the universal quantifier. In this article, we prove that Basic Predicate Calculus is sound with respect to the semantics of absolute V -realizability if V satisfies some natural conditions.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W3197890969",
    "type": "article"
  },
  {
    "title": "Graphs Identified by Logics with Counting",
    "doi": "https://doi.org/10.1145/3417515",
    "publication_date": "2021-10-22",
    "publication_year": 2021,
    "authors": "Sandra Kiefer; Pascal Schweitzer; Erkal Selman",
    "corresponding_authors": "",
    "abstract": "We classify graphs and, more generally, finite relational structures that are identified by C^2 , that is, two-variable first-order logic with counting. Using this classification, we show that it can be decided in almost linear time whether a structure is identified by C^2 . Our classification implies that for every graph identified by this logic, all vertex-colored versions of it are also identified. A similar statement is true for finite relational structures. We provide constructions that solve the inversion problem for finite relational structures in linear time. By a result due to Otto, this problem has been known to be polynomial-time solvable. For graphs, we conclude that every C^2 -equivalence class contains a representative whose orbits are exactly the classes of the C^2 -partition of its vertex set and which has a single automorphism witnessing this fact. We show that such statements are not true for general k by providing examples of graphs of order linear in k which are identified by C^3 , but for which the orbit partition is strictly finer than the C^k -partition. We also construct identified graphs which have vertex-colored versions that are not identified by C^k .",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W3208077660",
    "type": "article"
  },
  {
    "title": "The strength of replacement in weak arithmetic",
    "doi": "https://doi.org/10.1145/1166109.1166114",
    "publication_date": "2006-10-01",
    "publication_year": 2006,
    "authors": "Stephen Cook; Neil Thapen",
    "corresponding_authors": "",
    "abstract": "The replacement (or collection or choice) axiom scheme BB(Γ) asserts bounded quantifier exchange as follows: ∀i < |a| ∃x < aϕ(i,x) → ∃w ∀i < |a|ϕ(i,[w]i), for ϕ in the class Γ of formulas. The theory S12 proves the scheme BB(Σb1), and thus in S12 every Σb1 formula is equivalent to a strict Σb1 formula (in which all non-sharply-bounded quantifiers are in front). Here we prove (sometimes subject to an assumption) that certain theories weaker than S12 do not prove either BB(Σb1) or BB(Σb0). We show (unconditionally) that V 0 does not prove BB(Σb0), where V0 (essentially IΣ1,b0) is the two-sorted theory associated with the complexity class AC0. We show that PV does not prove BB(Σb0), assuming that integer factoring is not possible in probabilistic polynomial time. Johannsen and Pollett introduced the theory C02 associated with the complexity class TC0, and later introduced an apparently weaker theory Δb1 − CR for the same class. We use our methods to show that Δb1 − CR is indeed weaker than C02, assuming that RSA is secure against probabilistic polynomial time attack.Our main tool is the KPT witnessing theorem.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4297986018",
    "type": "article"
  },
  {
    "title": "Flat and one-variable clauses",
    "doi": "https://doi.org/10.1145/1380572.1380577",
    "publication_date": "2008-08-01",
    "publication_year": 2008,
    "authors": "Helmut Seidl; Kumar Neeraj Verma",
    "corresponding_authors": "",
    "abstract": "Cryptographic protocols with single blind copying were defined and modeled by Comon and Cortier using the new class C of first-order clauses. They showed its satisfiability problem to be in 3-DEXPTIME. We improve this result by showing that satisfiability for this class is NEXPTIME-complete, using new resolution techniques. We show satisfiability to be DEXPTIME-complete if clauses are Horn, which is what is required for modeling cryptographic protocols. While translation to Horn clauses only gives a DEXPTIME upper bound for the secrecy problem for these protocols, we further show that this secrecy problem is actually DEXPTIME-complete.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2131990213",
    "type": "article"
  },
  {
    "title": "The Probability of a Computable Output from a Random Oracle",
    "doi": "https://doi.org/10.1145/3091527",
    "publication_date": "2017-07-31",
    "publication_year": 2017,
    "authors": "George Barmpalias; Douglas Cenzer; Christopher P. Porter",
    "corresponding_authors": "",
    "abstract": "Consider a universal oracle Turing machine that prints a finite or an infinite binary sequence, based on the answers to the binary queries that it makes during the computation. We study the probability that this output is infinite and computable when the machine is given a random (in the probabilistic sense) stream of bits as the answers to its queries during an infinitary computation. Surprisingly, we find that these probabilities are the entire class of real numbers in (0,1) that can be written as the difference of two halting probabilities relative to the halting problem. In particular, there are universal Turing machines that produce a computable infinite output with probability exactly 1/2. Our results contrast a large array of facts (the most well-known being the randomness of Chaitin’s halting probability) that witness maximal initial segment complexity of probabilities associated with universal machines. Our proof uses recent advances in algorithmic randomness.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2566853169",
    "type": "article"
  },
  {
    "title": "An Operational Semantics for the Cognitive Architecture ACT-R and Its Translation to Constraint Handling Rules",
    "doi": "https://doi.org/10.1145/3218818",
    "publication_date": "2018-07-31",
    "publication_year": 2018,
    "authors": "Daniel Gall; Thom Frühwirth",
    "corresponding_authors": "",
    "abstract": "Computational psychology has the aim to explain human cognition by computational models of cognitive processes. The cognitive architecture Adaptive Control of Thought--Rational (ACT-R) is popular to develop such models. Although ACT-R has a well-defined psychological theory and has been used to explain many cognitive processes, there are two problems that make it hard to reason formally about its cognitive models: First, ACT-R lacks a computational formalization of its underlying production rule system, and, second, there are many different implementations and extensions of ACT-R with many technical artifacts complicating formal reasoning even more. This article describes a formal operational semantics—the very abstract semantics —that abstracts from as many technical details as possible, keeping it open to extensions and different implementations of the ACT-R theory. In a second step, this semantics is refined to define some of its abstract features that are found in many implementations of ACT-R—called the abstract semantics . It concentrates on the procedural core of ACT-R and is suitable for analysis of the general transition system, since it still abstracts from details like timing, the sub-symbolic layer of ACT-R or conflict resolution. Furthermore, a translation of ACT-R models to the declarative programming language Constraint Handling Rules (CHR) is defined. This makes the abstract semantics an executable specification of ACT-R. CHR has been used successfully to embed other rule-based formalisms like graph transformation systems or functional programming. There are many theoretical results and practical tools that support formal reasoning about and analysis of CHR programs. The translation of ACT-R models to CHR is proven sound and complete w.r.t. the abstract operational semantics of ACT-R. This paves the way to analysis of ACT-R models through CHR analysis results and tools. Therefore, to the best of our knowledge, our abstract semantics is the first abstract formulation of ACT-R suitable for both analysis and execution.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2593727116",
    "type": "article"
  },
  {
    "title": "Merging in the Horn Fragment",
    "doi": "https://doi.org/10.1145/3043700",
    "publication_date": "2017-01-31",
    "publication_year": 2017,
    "authors": "Adrian Haret; Stefan Rümmele; Stefan Woltran",
    "corresponding_authors": "",
    "abstract": "Belief merging is a central operation within the field of belief change and addresses the problem of combining multiple, possibly mutually inconsistent knowledge bases into a single, consistent one. A current research trend in belief change is concerned with representation theorems tailored to fragments of logic, in particular Horn logic. Hereby, the goal is to guarantee that the result of the change operations stays within the fragment under consideration. While several such results have been obtained for Horn revision and Horn contraction, merging of Horn theories has been neglected so far. In this article, we provide a novel representation theorem for Horn merging by strengthening the standard merging postulates. Moreover, we present concrete Horn merging operators satisfying all postulates.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2600034178",
    "type": "article"
  },
  {
    "title": "Typed Nominal Rewriting",
    "doi": "https://doi.org/10.1145/3161558",
    "publication_date": "2018-01-31",
    "publication_year": 2018,
    "authors": "Elliot Fairweather; Maribel Fernández",
    "corresponding_authors": "",
    "abstract": "Nominal terms extend first-order terms with nominal features and as such constitute a meta-language for reasoning about the named variables of an object language in the presence of meta-level variables. This article introduces a number of type systems for nominal terms of increasing sophistication and demonstrates their application in the areas of rewriting and equational reasoning. Two simple type systems inspired by Church’s simply typed lambda calculus are presented where only well-typed terms are considered to exist, over which α-equivalence is then axiomatised. The first requires atoms to be strictly annotated whilst the second explores the consequences of a more relaxed de Bruijn-style approach in the presence of atom-capturing substitution. A final type system of richer ML-like polymorphic types is then given in the style of Curry, in which elements of the term language are deemed typeable or not only subsequent to the definition of alpha-equivalence. Principal types are shown to exist and an inference algorithm given to compute them. This system is then used to define two presentations of typed nominal rewriting, one more expressive and one more efficient, the latter also giving rise to a notion of typed nominal equational reasoning.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2787938925",
    "type": "article"
  },
  {
    "title": "Definability of Cai-Fürer-Immerman Problems in Choiceless Polynomial Time",
    "doi": "https://doi.org/10.1145/3154456",
    "publication_date": "2018-02-09",
    "publication_year": 2018,
    "authors": "Wied Pakusa; Svenja Schalthöfer; Erkal Selman",
    "corresponding_authors": "",
    "abstract": "Choiceless Polynomial Time (CPT) is one of the most promising candidates in the search for a logic capturing P time . The question whether there is a logic that expresses exactly the polynomial-time computable properties of finite structures, which has been open for more than 30 years, is one of the most important and challenging problems in finite model theory. The strength of Choiceless Polynomial Time is its ability to perform isomorphism-invariant computations over structures, using hereditarily finite sets as data structures. But, because of isomorphism-invariance, it is choiceless in the sense that it cannot select an arbitrary element of a set—an operation that is crucial for many classical algorithms. CPT can define many interesting P time queries, including (a certain version of) the Cai-Fürer-Immerman (CFI) query. The CFI-query is particularly interesting, because it separates fixed-point logic with counting from P time and has since remained the main benchmark for the expressibility of logics within P time . The CFI-construction associates with each connected graph a set of CFI-graphs that can be partitioned into exactly two isomorphism classes called odd and even CFI-graphs. The problem is to decide, given a CFI-graph, whether it is odd or even. For the case where the CFI-graphs arise from ordered graphs, Dawar, Richerby, and Rossman proved that the CFI-query is CPT-definable. However, definability of the CFI-query over general graphs remains open. Our first contribution generalises the result by Dawar, Richerby, and Rossman to the variant of the CFI-query derived from graphs with colour classes of logarithmic size, instead of colour class size one. Second, we consider the CFI-query over graph classes where the maximal degree is linear in the size of the graphs. For the latter, we establish CPT-definability using only sets of small, constant rank, which is known to be impossible for the general case. In our CFI-recognising procedures we strongly make use of the ability of CPT to create sets, rather than tuples only, and we further prove that, if CPT worked over tuples instead, then no such procedure would be definable. We introduce a notion of “sequencelike objects” based on the structure of the graphs’ symmetry groups, and we show that no CPT-program that only uses sequencelike objects can decide the CFI-query over complete graphs, which have linear maximal degree. From a broader perspective, this generalises a result by Blass, Gurevich, and van den Bussche about the power of isomorphism-invariant machine models (for polynomial time) to a setting with counting.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2793462183",
    "type": "article"
  },
  {
    "title": "Toward a Uniform Theory of Effectful State Machines",
    "doi": "https://doi.org/10.1145/3372880",
    "publication_date": "2020-03-13",
    "publication_year": 2020,
    "authors": "Sergey Goncharov; Stefan Milius; Alexandra Silva",
    "corresponding_authors": "",
    "abstract": "Using recent developments in coalgebraic and monad-based semantics, we present a uniform study of various notions of machines, e.g. finite state machines, multi-stack machines, Turing machines, valence automata, and weighted automata. They are instances of Jacobs' notion of a T-automaton, where T is a monad. We show that the generic language semantics for T-automata correctly instantiates the usual language semantics for a number of known classes of machines/languages, including regular, context-free, recursively-enumerable and various subclasses of context free languages (e.g. deterministic and real-time ones). Moreover, our approach provides new generic techniques for studying the expressivity power of various machine-based models.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2897326228",
    "type": "article"
  },
  {
    "title": "Pure Sequent Calculi",
    "doi": "https://doi.org/10.1145/3319501",
    "publication_date": "2019-05-31",
    "publication_year": 2019,
    "authors": "Ori Lahav; Yoni Zohar",
    "corresponding_authors": "",
    "abstract": "Analyticity, also known as the subformula property, typically guarantees decidability of derivability in propositional sequent calculi. To utilize this fact, two substantial gaps have to be addressed: (i) What makes a sequent calculus analytic? and (ii) How do we obtain an efficient decision procedure for derivability in an analytic calculus? In the first part of this article, we answer these questions for pure calculi —a general family of fully structural propositional sequent calculi whose rules allow arbitrary context formulas. We provide a sufficient syntactic criterion for analyticity in these calculi, as well as a productive method to construct new analytic calculi from given ones. We further introduce a scalable decision procedure for derivability in analytic pure calculi by showing that it can be (uniformly) reduced to classical satisfiability. In the second part of the article, we study the extension of pure sequent calculi with modal operators. We show that such extensions preserve the analyticity of the calculus and identify certain restricted operators (which we call “Next” operators) that are also amenable for a general reduction of derivability to classical satisfiability. Our proofs are all semantic, utilizing several strong general soundness and completeness theorems with respect to non-deterministic semantic frameworks: bivaluations (for pure calculi) and Kripke models (for their extension with modal operators).",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2949019224",
    "type": "article"
  },
  {
    "title": "Tight Bounds on the Asymptotic Descriptive Complexity of Subgraph Isomorphism",
    "doi": "https://doi.org/10.1145/3303881",
    "publication_date": "2019-03-29",
    "publication_year": 2019,
    "authors": "Oleg Verbitsky; Maksim Zhukovskii",
    "corresponding_authors": "",
    "abstract": "Let v ( F ) denote the number of vertices in a fixed connected pattern graph F . We show an infinite family of patterns F such that the existence of a subgraph isomorphic to F is expressible by a first-order sentence of quantifier depth 2/3 v ( F ) + 1, assuming that the host graph is sufficiently large and connected. However, this is impossible for any F using less than 2/3 v ( F ) - 2 first-order variables.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2963399986",
    "type": "article"
  },
  {
    "title": "Verification Methods for the Computationally Complete Symbolic Attacker Based on Indistinguishability",
    "doi": "https://doi.org/10.1145/3343508",
    "publication_date": "2019-10-04",
    "publication_year": 2019,
    "authors": "Gergei Bana; Rohit Chadha; Ajay Kumar Eeralla; Mitsuhiro Okada",
    "corresponding_authors": "",
    "abstract": "In recent years, a new approach has been developed for verifying security protocols with the aim of combining the benefits of symbolic attackers and the benefits of unconditional soundness: the technique of the computationally complete symbolic attacker of Bana and Comon (BC) [8]. In this article, we argue that the real breakthrough of this technique is the recent introduction of its version for indistinguishability [9], because, with the extensions we introduce here, for the first time, there is a computationally sound symbolic technique that is syntactically strikingly simple, to which translating standard computational security notions is a straightforward matter, and that can be effectively used for verification of not only equivalence properties but trace properties of protocols as well. We first fully develop the core elements of this newer version by introducing several new axioms. We illustrate the power and the diverse use of the introduced axioms on simple examples first. We introduce an axiom expressing the Decisional Diffie-Hellman property. We analyze the Diffie-Hellman key exchange, both in its simplest form and an authenticated version as well. We provide computationally sound verification of real-or-random secrecy of the Diffie-Hellman key exchange protocol for multiple sessions, without any restrictions on the computational implementation other than the DDH assumption. We also show authentication for a simplified version of the station-to-station protocol using UF-CMA assumption for digital signatures. Finally, we axiomatize IND-CPA, IND-CCA1, and IND-CCA2 security properties and illustrate their usage. We have formalized the axiomatic system in an interactive theorem prover, Coq, and have machine-checked the proofs of various auxiliary theorems and security properties of Diffie-Hellman and station-to-station protocol.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2979563688",
    "type": "article"
  },
  {
    "title": "Hardness Characterisations and Size-width Lower Bounds for QBF Resolution",
    "doi": "https://doi.org/10.1145/3565286",
    "publication_date": "2022-09-28",
    "publication_year": 2022,
    "authors": "Olaf Beyersdorff; Joshua Blinkhorn; Meena Mahajan; Tomáš Peitl",
    "corresponding_authors": "",
    "abstract": "We provide a tight characterisation of proof size in resolution for quantified Boolean formulas (QBF) via circuit complexity. Such a characterisation was previously obtained for a hierarchy of QBF Frege systems [ 16 ], but leaving open the most important case of QBF resolution. Different from the Frege case, our characterisation uses a new version of decision lists as its circuit model, which is stronger than the CNFs the system works with. Our decision list model is well suited to compute countermodels for QBFs. Our characterisation works for both Q-Resolution and QU-Resolution. Using our characterisation, we obtain a size-width relation for QBF resolution in the spirit of the celebrated result for propositional resolution [ 4 ]. However, our result is not just a replication of the propositional relation—intriguingly ruled out for QBF in previous research [ 12 ]—but shows a different dependence between size, width, and quantifier complexity. An essential ingredient is an improved relation between the size and width of term decision lists; this may be of independent interest. We demonstrate that our new technique elegantly reproves known QBF hardness results and unifies previous lower-bound techniques in the QBF domain.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W3013210104",
    "type": "article"
  },
  {
    "title": "On Proof Complexity of Resolution over Polynomial Calculus",
    "doi": "https://doi.org/10.1145/3506702",
    "publication_date": "2022-07-22",
    "publication_year": 2022,
    "authors": "Erfan Khaniki",
    "corresponding_authors": "Erfan Khaniki",
    "abstract": "The proof system Res (PC d,R ) is a natural extension of the Resolution proof system that instead of disjunctions of literals operates with disjunctions of degree d multivariate polynomials over a ring R with Boolean variables. Proving super-polynomial lower bounds for the size of Res ( PC 1, R )-refutations of Conjunctive normal forms (CNFs) is one of the important problems in propositional proof complexity. The existence of such lower bounds is even open for Res ( PC 1,𝔽 ) when 𝔽 is a finite field, such as 𝔽 2 . In this article, we investigate Res ( PC d,R ) and tree-like Res ( PC d,R ) and prove size-width relations for them when R is a finite ring. As an application, we prove new lower bounds and reprove some known lower bounds for every finite field 𝔽 as follows: (1) We prove almost quadratic lower bounds for Res ( PC d ,𝔽)-refutations for every fixed d . The new lower bounds are for the following CNFs: (a) Mod q Tseitin formulas ( char (𝔽)≠ q ) and Flow formulas, (b) Random k -CNFs with linearly many clauses. (2) We also prove super-polynomial (more than n k for any fixed k ) and also exponential (2 nϵ for an ϵ &gt; 0) lower bounds for tree-like Res ( PC d ,𝔽 )-refutations based on how big d is with respect to n for the following CNFs: (a) Mod q Tseitin formulas ( char (𝔽)≠ q ) and Flow formulas, (b) Random k -CNFs of suitable densities, (c) Pigeonhole principle and Counting mod q principle. The lower bounds for the dag-like systems are the first nontrivial lower bounds for these systems, including the case d =1. The lower bounds for the tree-like systems were known for the case d =1 (except for the Counting mod q principle, in which lower bounds for the case d &gt; 1 were known too). Our lower bounds extend those results to the case where d &gt; 1 and also give new proofs for the case d =1.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W3013941449",
    "type": "article"
  },
  {
    "title": "The Temporal Logic of Coalitional Goal Assignments in Concurrent Multiplayer Games",
    "doi": "https://doi.org/10.1145/3517128",
    "publication_date": "2022-04-14",
    "publication_year": 2022,
    "authors": "Sebastian Enqvist; Valentin Goranko",
    "corresponding_authors": "",
    "abstract": "We introduce and study a natural extension of the Alternating time temporal logic ATL , called Temporal Logic of Coalitional Goal Assignments (TLCGA). It features one new and quite expressive coalitional strategic operator, called the coalitional goal assignment operator ⦉ γ ⦊, where γ is a mapping assigning to each set of players in the game its coalitional goal , formalised by a path formula of the language of TLCGA, i.e., a formula prefixed with a temporal operator X , U , or G , representing a temporalised objective for the respective coalition, describing the property of the plays on which that objective is satisfied. Then, the formula ⦉ γ ⦊ intuitively says that there is a strategy profile Σ for the grand coalition Agt such that for each coalition C , the restriction Σ | C of Σ to C is a collective strategy of C that enforces the satisfaction of its objective γ (C) in all outcome plays enabled by Σ | C . We establish fixpoint characterizations of the temporal goal assignments in a μ-calculus extension of TLCGA, discuss its expressiveness and illustrate it with some examples, prove bisimulation invariance and Hennessy–Milner property for it with respect to a suitably defined notion of bisimulation, construct a sound and complete axiomatic system for TLCGA, and obtain its decidability via finite model property.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W3114442593",
    "type": "article"
  },
  {
    "title": "QCSP on Reflexive Tournaments",
    "doi": "https://doi.org/10.1145/3508069",
    "publication_date": "2022-04-06",
    "publication_year": 2022,
    "authors": "Benoît Larose; Barnaby Martin; Petar Marković; Daniël Paulusma; Siani Smith; Stanislav Živný",
    "corresponding_authors": "",
    "abstract": "We give a complexity dichotomy for the Quantified Constraint Satisfaction Problem \\( \\mathrm{QCSP}(\\mathrm{H}) \\) when \\( \\mathrm{H} \\) is a reflexive tournament. It is well known that reflexive tournaments can be split into a sequence of strongly connected components \\( \\mathrm{H}_1,\\ldots ,\\mathrm{H}_n \\) so that there exists an edge from every vertex of \\( \\mathrm{H}_i \\) to every vertex of \\( \\mathrm{H}_j \\) if and only if \\( i\\lt j \\) . We prove that if \\( \\mathrm{H} \\) has both its initial and final strongly connected component (possibly equal) of size 1, then \\( \\mathrm{QCSP}(\\mathrm{H}) \\) is in \\( \\mathsf {NL} \\) and otherwise \\( \\mathrm{QCSP}(\\mathrm{H}) \\) is \\( \\mathsf {NP} \\) -hard.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W3155570673",
    "type": "article"
  },
  {
    "title": "The Complexity of Quantified Constraints: Collapsibility, Switchability, and the Algebraic Formulation",
    "doi": "https://doi.org/10.1145/3568397",
    "publication_date": "2022-10-17",
    "publication_year": 2022,
    "authors": "Catarina Carvalho; Florent Madelaine; Barnaby Martin; Dmitriy Zhuk",
    "corresponding_authors": "",
    "abstract": "Let 𝔸 be an idempotent algebra on a finite domain. By mediating between results of Chen [ 1 ] and Zhuk [ 2 ], we argue that if 𝔸 satisfies the polynomially generated powers property (PGP) and ℬ is a constraint language invariant under 𝔸 (i.e., in Inv(𝔸)), then QCSP ℬ is in NP. In doing this, we study the special forms of PGP, switchability, and collapsibility, in detail, both algebraically and logically, addressing various questions such as decidability on the way. We then prove a complexity-theoretic converse in the case of infinite constraint languages encoded in propositional logic, that if Inv}(𝔸) satisfies the exponentially generated powers property (EGP), then QCSP (Inv(𝔸)) is co-NP-hard. Since Zhuk proved that only PGP and EGP are possible, we derive a full dichotomy for the QCSP, justifying what we term the Revised Chen Conjecture . This result becomes more significant now that the original Chen Conjecture (see [ 3 ]) is known to be false [ 4 ]. Switchability was introduced by Chen [ 1 ] as a generalization of the already-known collapsibility [ 5 ]. There, an algebra 𝔸 :=({ 0,1,2}; r ) was given that is switchable and not collapsible. We prove that, for all finite subsets Δ of Inv (𝔸 A), Pol (Δ) is collapsible. The significance of this is that, for QCSP on finite structures, it is still possible all QCSP tractability (in NP) explained by switchability is already explained by collapsibility. At least, no counterexample is known to this.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W3176180680",
    "type": "article"
  },
  {
    "title": "Preferred First-Order Answer Set Programs",
    "doi": "https://doi.org/10.1145/2579817",
    "publication_date": "2014-04-01",
    "publication_year": 2014,
    "authors": "Vernon Asuncion; Yan Zhang; Yi Zhou",
    "corresponding_authors": "",
    "abstract": "In this article, we consider the issue of how first-order answer set programs can be extended for handling preference reasoning. To this end, we propose a progression-based preference semantics for first-order answer set programs while explicit preference relations are presented. We study essential properties of the proposed preferred answer set semantics. To understand the expressiveness of preferred first-order answer set programming, we further specify a second-order logic representation which precisely characterizes the progression-based preference semantics.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2036349108",
    "type": "article"
  },
  {
    "title": "On the Decidability of Elementary Modal Logics",
    "doi": "https://doi.org/10.1145/2817825",
    "publication_date": "2015-09-23",
    "publication_year": 2015,
    "authors": "Jakub Michaliszyn; Jan Otop; Emanuel Kieroński",
    "corresponding_authors": "",
    "abstract": "We consider the satisfiability problem for modal logic over first-order definable classes of frames. We confirm the conjecture from Hemaspaandra and Schnoor [2008] that modal logic is decidable over classes definable by universal Horn formulae. We provide a full classification of Horn formulae with respect to the complexity of the corresponding satisfiability problem. It turns out, that except for the trivial case of inconsistent formulae, local satisfiability is either NP-complete or PS pace -complete, and global satisfiability is NP-complete, PS pace -complete, or E xp T ime -complete. We also show that the finite satisfiability problem for modal logic over Horn definable classes of frames is decidable. On the negative side, we show undecidability of two related problems. First, we exhibit a simple universal three-variable formula defining the class of frames over which modal logic is undecidable. Second, we consider the satisfiability problem of bimodal logic over Horn definable classes of frames, and also present a formula leading to undecidability.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2040640762",
    "type": "article"
  },
  {
    "title": "Bounds for the Quantifier Depth in Finite-Variable Logics",
    "doi": "https://doi.org/10.1145/2732409",
    "publication_date": "2015-04-21",
    "publication_year": 2015,
    "authors": "Christoph Berkholz; Andreas Krebs; Oleg Verbitsky",
    "corresponding_authors": "",
    "abstract": "Given two structures G and H distinguishable in FO k (first-order logic with k variables), let A k ( G , H ) denote the minimum alternation depth of a FO k formula distinguishing G from H . Let A k ( n ) be the maximum value of A k ( G , H ) over n -element structures. We prove the strictness of the quantifier alternation hierarchy of FO 2 in a strong quantitative form, namely A 2 ( n ) &gt; n /8 − 2, which is tight up to a constant factor. For each k ⩾ 2, it holds that A k ( n ) &gt; log k + 1 n − 2 even over colored trees, which is also tight up to a constant factor if k ⩾ 3. For k ⩾ 3, the last lower bound holds also over uncolored trees, whereas the alternation hierarchy of FO 2 collapses even over all uncolored graphs. We also show examples of colored graphs G and H on n vertices that can be distinguished in FO 2 much more succinctly if the alternation number is increased just by one: Whereas in Σ i it is possible to distinguish G from H with bounded quantifier depth, in Π i this requires quantifier depth Ω( n 2 ). The quadratic lower bound is best possible here because, if G and H can be distinguished in FO k with i quantifier alternations, this can be done with quantifier depth n 2 k − 2 + 1 and the same number of alternations.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2115765086",
    "type": "article"
  },
  {
    "title": "Limiting Until in Ordered Tree Query Languages",
    "doi": "https://doi.org/10.1145/2856104",
    "publication_date": "2016-03-17",
    "publication_year": 2016,
    "authors": "Michael Benedikt; Clemens Ley",
    "corresponding_authors": "",
    "abstract": "Marx and de Rijke have shown that the navigational core of the w3c XML query language XPath is not first-order complete; that is, it cannot express every query definable in first-order logic over the navigational predicates. How can one extend XPath to get a first-order complete language? Marx has shown that Conditional XPath—an extension of XPath with an “Until” operator—is first-order complete. The completeness argument makes essential use of the presence of upward axes in Conditional XPath. We examine whether it is possible to get “forward-only” languages that are first-order complete for Boolean queries on ordered trees. It is easy to see that a variant of the temporal logic CTL * is first-order complete; the variant has path quantifiers for downward, leftward, and rightward paths, while along a path one can check arbitrary formulas of Linear Temporal Logic (LTL). This language has two major disadvantages: It requires path quantification in both horizontal directions (in particular, it requires looking backward at the prior siblings of a node), and it requires the consideration of formulas of LTL of arbitrary complexity on vertical paths. This last is in contrast with Marx’s Conditional XPath, which requires only the checking of a single Until operator on a path. We investigate whether either of these restrictions can be eliminated. Our main results are negative ones. We show that if we restrict our CTL * language by having an Until operator in only one horizontal direction, then we lose completeness. We also show that no restriction to a “small” subset of LTL along vertical paths is sufficient for first-order completeness. Smallness here means of bounded “Until Depth,” a measure of complexity of LTL formulas defined by Etessami and Wilke. In particular, it follows from our work that Conditional XPath with only forward axes is not expressively complete; this extends results proved by Rabinovich and Maoz in the context of infinite unordered trees.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2266126362",
    "type": "article"
  },
  {
    "title": "Rational Region-Based Affine Logic of the Real Plane",
    "doi": "https://doi.org/10.1145/2897190",
    "publication_date": "2016-04-11",
    "publication_year": 2016,
    "authors": "Adam Trybus",
    "corresponding_authors": "Adam Trybus",
    "abstract": "The region-based spatial logics, where variables are set to range over certain subsets of geometric space, are the focal point of the qualitative spatial reasoning, a subfield of the KR&amp;R research area. A lot of attention has been devoted to developing the topological spatial logics, leaving other systems relatively underexplored. We are concerned with a specific example of a region-based affine spatial logic. Building on the previous results on spatial logics with convexity, we axiomatise the theory of M = 〈 ROQ (R 2 ), conv M , ≤ M 〉, where ROQ (R 2 ) is the set of regular open rational polygons of the real plane; conv M is the convexity property and ≤ M is the inclusion relation. The axiomatisation uses two infinitary rules of inference and a number of axiom schemas.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2312571665",
    "type": "article"
  },
  {
    "title": "On the Proof Complexity of Paris-Harrington and Off-Diagonal Ramsey Tautologies",
    "doi": "https://doi.org/10.1145/2946801",
    "publication_date": "2016-09-10",
    "publication_year": 2016,
    "authors": "Lorenzo Carlucci; Nicola Galesi; Massimo Lauria",
    "corresponding_authors": "",
    "abstract": "We study the proof complexity of Paris-Harrington’s Large Ramsey Theorem for bi-colorings of graphs and of off-diagonal Ramsey’s Theorem. For Paris-Harrington, we prove a non-trivial conditional lower bound in Resolution and a non-trivial upper bound in bounded-depth Frege. The lower bound is conditional on a (very reasonable) hardness assumption for a weak (quasi-polynomial) Pigeonhole principle in R es (2). We show that under such an assumption, there is no refutation of the Paris-Harrington formulas of size quasi-polynomial in the number of propositional variables. The proof technique for the lower bound extends the idea of using a combinatorial principle to blow up a counterexample for another combinatorial principle beyond the threshold of inconsistency. A strong link with the proof complexity of an unbalanced off-diagonal Ramsey principle is established. This is obtained by adapting some constructions due to Erdős and Mills. We prove a non-trivial Resolution lower bound for a family of such off-diagonal Ramsey principles.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2518743604",
    "type": "article"
  },
  {
    "title": "Faster Property Testers in a Variation of the Bounded Degree Model",
    "doi": "https://doi.org/10.1145/3584948",
    "publication_date": "2023-02-23",
    "publication_year": 2023,
    "authors": "Isolde Adler; Polly Fahey",
    "corresponding_authors": "",
    "abstract": "Property testing algorithms are highly efficient algorithms that come with probabilistic accuracy guarantees. For a property P , the goal is to distinguish inputs that have P from those that are far from having P with high probability correctly, by querying only a small number of local parts of the input. In property testing on graphs, the distance is measured by the number of edge modifications (additions or deletions) that are necessary to transform a graph into one with property P . Much research has focused on the query complexity of such algorithms, i. e., the number of queries the algorithm makes to the input, but in view of applications, the running time of the algorithm is equally relevant. In (Adler, Harwath, STACS 2018), a natural extension of the bounded degree graph model of property testing to relational databases of bounded degree was introduced, and it was shown that on databases of bounded degree and bounded tree-width, every property that is expressible in monadic second-order logic with counting (CMSO) is testable with constant query complexity and sublinear running time. It remains open whether this can be improved to constant running time. In this article we introduce a new model, which is based on the bounded degree model, but the distance measure allows both edge (tuple) modifications and vertex (element) modifications. We show that every property that is testable in the classical model is testable in our model with the same query complexity and running time, but the converse is not true. Our main theorem shows that on databases of bounded degree and bounded tree-width, every property that is expressible in CMSO is testable with constant query complexity and constant running time in the new model. Our proof methods include the semilinearity of the neighborhood histograms of databases having the property and a result by Alon (Proposition 19.10 in Lovász, Large networks and graph limits, 2012) that states that for every bounded degree graph \\(\\mathcal {G}\\) there exists a constant size graph \\(\\mathcal {H}\\) that has a similar neighborhood distribution to \\(\\mathcal {G}\\) . It can be derived from a result in (Benjamini et al., Advances in Mathematics 2010) that hyperfinite hereditary properties are testable with constant query complexity and constant running time in the classical model (and hence in the new model). Using our methods, we give an alternative proof that hyperfinite hereditary properties are testable with constant query complexity and constant running time in the new model. We argue that our model is natural and our meta-theorem showing constant-time CMSO testability supports this.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W3085282378",
    "type": "article"
  },
  {
    "title": "Number of Variables for Graph Differentiation and the Resolution of Graph Isomorphism Formulas",
    "doi": "https://doi.org/10.1145/3580478",
    "publication_date": "2023-01-21",
    "publication_year": 2023,
    "authors": "Jacobo Torán; Florian Wörz",
    "corresponding_authors": "",
    "abstract": "We show that the number of variables and the quantifier depth needed to distinguish a pair of graphs by first-order logic sentences exactly match the complexity measures of clause width and depth needed to refute the corresponding graph isomorphism formula in propositional narrow resolution. Using this connection, we obtain upper and lower bounds for refuting graph isomorphism formulas in (normal) resolution. In particular, we show that if k is the minimum number of variables needed to distinguish two graphs with n vertices each, then there is an n O ( k ) resolution refutation size upper bound for the corresponding isomorphism formula, as well as lower bounds of 2 k -1 and k for the treelike resolution size and resolution clause space for this formula. We also show a (normal) resolution size lower bound of exp (Ω ( k 2 / n )) for the case of colored graphs with constant color class sizes. Applying these results, we prove the first exponential lower bound for graph isomorphism formulas in the proof system SRC-1, a system that extends resolution with a global symmetry rule, thereby answering an open question posed by Schweitzer and Seebach.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4317659259",
    "type": "article"
  },
  {
    "title": "Generating Extended Resolution Proofs with a BDD-Based SAT Solver",
    "doi": "https://doi.org/10.1145/3595295",
    "publication_date": "2023-05-22",
    "publication_year": 2023,
    "authors": "Randal E. Bryant; Marijn J. H. Heule",
    "corresponding_authors": "",
    "abstract": "In 2006, Biere, Jussila, and Sinz made the key observation that the underlying logic behind algorithms for constructing Reduced, Ordered Binary Decision Diagrams (BDDs) can be encoded as steps in a proof in the extended resolution logical framework. Through this, a BDD-based Boolean satisfiability (SAT) solver can generate a checkable proof of unsatisfiability. Such a proof indicates that the formula is truly unsatisfiable without requiring the user to trust the BDD package or the SAT solver built on top of it. We extend their work to enable arbitrary existential quantification of the formula variables, a critical capability for BDD-based SAT solvers. We demonstrate the utility of this approach by applying a BDD-based solver, implemented by extending an existing BDD package, to several challenging Boolean satisfiability problems. Our results demonstrate scaling for parity formulas as well as the Urquhart, mutilated chessboard, and pigeonhole problems far beyond that of other proof-generating SAT solvers.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4377238723",
    "type": "article"
  },
  {
    "title": "Extensible Proof Systems for Infinite-State Systems",
    "doi": "https://doi.org/10.1145/3622786",
    "publication_date": "2023-09-13",
    "publication_year": 2023,
    "authors": "Rance Cleaveland; Jeroen J. A. Keiren",
    "corresponding_authors": "",
    "abstract": "This article revisits soundness and completeness of proof systems for proving that sets of states in infinite-state labeled transition systems satisfy formulas in the modal mu-calculus in order to develop proof techniques that permit the seamless inclusion of new features in this logic. Our approach relies on novel results in lattice theory, which give constructive characterizations of both greatest and least fixpoints of monotonic functions over complete lattices. We show how these results may be used to reason about the sound and complete tableau method for this problem due to Bradfield and Stirling. We also show how the flexibility of our lattice-theoretic basis simplifies reasoning about tableau-based proof strategies for alternative classes of systems. In particular, we extend the modal mu-calculus with timed modalities, and prove that the resulting tableau method is sound and complete for timed transition systems.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4386711086",
    "type": "article"
  },
  {
    "title": "Decidability of the Satisfiability Problem for Boolean Set Theory with the Unordered Cartesian Product Operator",
    "doi": "https://doi.org/10.1145/3626823",
    "publication_date": "2023-10-06",
    "publication_year": 2023,
    "authors": "Domenico Cantone; Pietro Ursino",
    "corresponding_authors": "",
    "abstract": "We give a positive solution to the decidability problem for the fragment of set theory, dubbed BST ⊗, consisting of quantifier-free formulae involving the Boolean set operators of union, intersection, and set difference, along with the unordered Cartesian product operator ⊗ (where \\(s \\otimes t := \\big \\lbrace \\lbrace u,v\\rbrace \\,\\texttt {|}\\:u \\in s \\wedge v \\in t \\big \\rbrace\\) ), and the equality predicate, but no membership. Specifically, we provide nondeterministic exponential decision procedures for both the ordinary and the finite satisfiability problems for BST ⊗. We expect that these decision procedures can be adapted for the standard Cartesian product and, with added technicalities, to the cases involving membership, providing a solution to a longstanding problem in computable set theory.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4387398410",
    "type": "article"
  },
  {
    "title": "Domain-dependent knowledge in answer set planning",
    "doi": "https://doi.org/10.1145/1166109.1166110",
    "publication_date": "2006-10-01",
    "publication_year": 2006,
    "authors": "Tran Cao Son; Chitta Baral; Nam Tran; Sheila A. McIlraith",
    "corresponding_authors": "",
    "abstract": "In this article we consider three different kinds of domain-dependent control knowledge (temporal, procedural and HTN-based) that are useful in planning. Our approach is declarative and relies on the language of logic programming with answer set semantics (AnsProlog*). AnsProlog* is designed to plan without control knowledge. We show how temporal, procedural and HTN-based control knowledge can be incorporated into AnsProlog* by the modular addition of a small number of domain-dependent rules, without the need to modify the planner. We formally prove the correctness of our planner, both in the absence and presence of the control knowledge. Finally, we perform some initial experimentation that demonstrates the potential reduction in planning time that can be achieved when procedural domain knowledge is used to solve planning problems with large plan length.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2953082263",
    "type": "article"
  },
  {
    "title": "Splitting an operator",
    "doi": "https://doi.org/10.1145/1166109.1166115",
    "publication_date": "2006-10-01",
    "publication_year": 2006,
    "authors": "Joost Vennekens; David Gilis; Marc Denecker",
    "corresponding_authors": "",
    "abstract": "It is well known that, under certain conditions, it is possible to split logic programs under stable model semantics, that is, to divide such a program into a number of different \"levels\", such that the models of the entire program can be constructed by incrementally constructing models for each level. Similar results exist for other nonmonotonic formalisms, such as auto-epistemic logic and default logic. In this work, we present a general, algebraic splitting theory for logics with a fixpoint semantics. Together with the framework of approximation theory, a general fixpoint theory for arbitrary operators, this gives us a uniform and powerful way of deriving splitting results for each logic with a fixpoint semantics. We demonstrate the usefulness of these results, by generalizing existing results for logic programming, auto-epistemic logic and default logic.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4212806761",
    "type": "article"
  },
  {
    "title": "Modal abstractions of concurrent behavior",
    "doi": "https://doi.org/10.1145/1929954.1929955",
    "publication_date": "2011-05-01",
    "publication_year": 2011,
    "authors": "Flemming Nielson; Sebastian Nanz; Hanne Riis Nielson",
    "corresponding_authors": "",
    "abstract": "We present an effective algorithm for the automatic construction of finite modal transition systems as abstractions of potentially infinite concurrent processes. Modal transition systems are recognized as valuable abstractions for model checking because they allow for the validation as well as refutation of safety and liveness properties. However, the algorithmic construction of finite abstractions from potentially infinite concurrent processes is a missing link that prevents their more widespread usage for model checking of concurrent systems. Our algorithm is a worklist algorithm using concepts from abstract interpretation and operating upon mappings from sets to intervals in order to express simultaneous over- and underapproximations of the multisets of process actions available in a particular state. We obtain a finite abstraction that is 3-valued in both states and transitions and that supports the definition of a 3-valued modal logic for validating as well as refuting properties of systems. The construction is illustrated on a few examples, including the Ingemarsson-Tang-Wong key agreement protocol.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2005263036",
    "type": "article"
  },
  {
    "title": "First-Order Logic on Higher-Order Nested Pushdown Trees",
    "doi": "https://doi.org/10.1145/2480759.2480760",
    "publication_date": "2013-06-01",
    "publication_year": 2013,
    "authors": "Alexander Kartzow",
    "corresponding_authors": "Alexander Kartzow",
    "abstract": "We introduce a new hierarchy of higher-order nested pushdown trees generalising Alur et al.’s concept of nested pushdown trees. Nested pushdown trees are useful representations of control flows in the verification of programs with recursive calls of first-order functions. Higher-order nested pushdown trees are expansions of unfoldings of graphs generated by higher-order pushdown systems. Moreover, the class of nested pushdown trees of level n is uniformly first-order interpretable in the class of collapsible pushdown graphs of level n + 1. The relationship between the class of higher-order pushdown graphs and the class of collapsible higher-order pushdown graphs is not very well understood. We hope that the further study of the nested pushdown tree hierarchy leads to a better understanding of these two hierarchies. In this article, we are concerned with the first-order model checking problem on higher-order nested pushdown trees. We show that the first-order model checking on the first two levels of this hierarchy is decidable. Moreover, we obtain an alternating 2-EXPTIME algorithm for the class of nested pushdown trees of level 1. The proof technique involves a pseudo-local analysis of strategies in the Ehrenfeucht-Fraïssé games on two identical copies of a nested pushdown tree. Ordinary locality arguments in the spirit of Gaifman’s lemma do not apply here because nested pushdown trees tend to have small diameters. We introduce the notion of relevant ancestors which provide a sufficient description of the FO k -type of each element in a higher-order nested pushdown tree. The local analysis of these ancestors allows us to prove the existence of restricted winning strategies in the Ehrenfeucht-Fraïssé game. These strategies are then used to create a first-order model checking algorithm.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2027482757",
    "type": "article"
  },
  {
    "title": "Common Knowledge in Email Exchanges",
    "doi": "https://doi.org/10.1145/2499937.2499944",
    "publication_date": "2013-08-01",
    "publication_year": 2013,
    "authors": "Floor Sietsma; Krzysztof R. Apt",
    "corresponding_authors": "",
    "abstract": "We consider a framework in which a group of agents communicates by means of emails, with the possibility of replies, forwards and blind carbon copies (BCC). We study the epistemic consequences of such email exchanges by introducing an appropriate epistemic language and semantics. This allows us to find out what agents learn from the emails they receive and to determine when a group of agents acquires common knowledge of the fact that an email was sent. We also show that in our framework from the epistemic point of view the BCC feature of emails cannot be simulated using messages without BCC recipients.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2129749388",
    "type": "article"
  },
  {
    "title": "Typed interpretations of extensible objects",
    "doi": "https://doi.org/10.1145/566385.566389",
    "publication_date": "2002-10-01",
    "publication_year": 2002,
    "authors": "Viviana Bono; Michele Bugliesi; Silvia Crafà",
    "corresponding_authors": "",
    "abstract": "Finding typed encodings of object-oriented into procedural or functional programming sheds light on the theoretical foundations of object-oriented languages and their specific typing constructs and techniques. This article describes a type preserving and computationally adequate interpretation of a full-fledged object calculus that supports message passing and constructs for object update and extension. The target theory is a higher-order λ-calculus with records and recursive folds/unfolds, polymorphic and recursive types, and subtyping. The interpretation specializes to calculi of nonextensible objects, and validates the expected subtypin",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2091611864",
    "type": "article"
  },
  {
    "title": "Symbolic semantic rules for producing compact STGLAs from value passing process descriptions",
    "doi": "https://doi.org/10.1145/1013560.1013563",
    "publication_date": "2004-07-01",
    "publication_year": 2004,
    "authors": "Marco Bernardo",
    "corresponding_authors": "Marco Bernardo",
    "abstract": "Value passing process algebras with infinite data domains need to be equipped with symbolic semantic models in order for their analysis to be possible. This means that appropriate symbolic models and the related verification algorithms must be developed, together with suitable semantic rules mapping the value passing process descriptions to such symbolic models. In this article, we first introduce the model of the symbolic transition graphs with lookahead assignment (STGLAs), a variant of the symbolic transition graphs with assignment (STGAs) of Lin that can undergo to the strong, weak and observational bisimulation equivalence checking algorithms of Li and Chen. We then define a set of symbolic semantic rules that map a useful fragment of value passing CCS to finite STGLAs without making any assumption about the variable names. We demonstrate that the symbolic semantic rules are correct with respect to both the usual concrete semantic rules and the novel issue of the assignment application order. Finally, we prove that, for the considered fragment of value passing CCS, the STGLAs produced by the symbolic semantic rules are optimal with respect to a certain compactness criterion, thus improving on the symbolic models and the semantic rules previously proposed in the literature.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2065978248",
    "type": "article"
  },
  {
    "title": "Super logic programs",
    "doi": "https://doi.org/10.1145/963927.963931",
    "publication_date": "2004-01-01",
    "publication_year": 2004,
    "authors": "Stefan Brass; Jürgen Dix; Teodor C. Przymusiński",
    "corresponding_authors": "",
    "abstract": "The Autoepistemic Logic of Knowledge and Belief (AELB) is a powerful nonmonotonic formalism introduced by Teodor Przymusinski in 1994. In this paper, we specialize it to a class of theories called \"super logic programs\". We argue that these programs form a natural generalization of standard logic programs. In particular, they allow disjunctions and default negation of arbitrary positive objective formulas.Our main results are two new and important characterizations of the static semantics of these programs, one syntactic, and one model-theoretic. The syntactic fixed point characterization is much simpler than the fixed point construction of the static semantics for arbitrary AELB theories. The model-theoretic characterization via Kripke models allows one to construct finite representations of the inherently infinite static expansions.Both characterizations can be used as the basis of algorithms for query answering under the static semantics. We describe a query-answering interpreter for super programs that we developed based on the model-theoretic characterization and which is available on the web.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2143323021",
    "type": "article"
  },
  {
    "title": "Disjunction and modular goal-directed proof search",
    "doi": "https://doi.org/10.1145/1071596.1071599",
    "publication_date": "2005-07-01",
    "publication_year": 2005,
    "authors": "Matthew Stone",
    "corresponding_authors": "Matthew Stone",
    "abstract": "This article explores goal-directed proof search in first-order multimodal logic. I focus on a family of modal logics which offer the expressive power to specify modular goals and local assumptions. A modular goal must be proved from designated assumptions; conversely, a local assumption can only be used to prove a designated goal. Indefinite modal specifications can avoid combinatorial interactions among independent ambiguities by making separate goals modular and corresponding disjunctive alternatives local. Such specifications can effectively guarantee that provable goals have short proofs. The key result of this article is to establish a sound and complete goal-directed proof system that actively uses the modularity and locality of modal logic to constrain proof search. In particular, logically independent, local ambiguities will not interact in proof search. The challenge is that, in goal-directed proof, a modal prover cannot simply reason locally, in a module, because modularity is a property of formulas rather than proof problems. The result therefore requires prior proof-theoretic justifications of logic programming to be extended, strengthened, and combined with new proof-theoretic analyses of modal deduction.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2169894969",
    "type": "article"
  },
  {
    "title": "Deciding strategy properties of contract-signing protocols",
    "doi": "https://doi.org/10.1145/1740582.1740585",
    "publication_date": "2010-05-01",
    "publication_year": 2010,
    "authors": "Detlef Kähler; Ralf Küsters; Thomas Wilke",
    "corresponding_authors": "",
    "abstract": "Research on the automatic analysis of cryptographic protocols has so far concentrated on reachability properties, such as secrecy and authentication. In this article, we prove that certain game-theoretic security properties, including balance for contract-signing protocols, can be decided in a Dolev-Yao style model with a bounded number of sessions. The decision algorithm that we develop is based on standard constraint-solving procedures, which, in the past, have successfully been employed in tools for reachability properties. Our result thus paves the way for extending these tools to deal with game-theoretic security properties.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W1977276947",
    "type": "article"
  },
  {
    "title": "Proofs, tests and continuation passing style",
    "doi": "https://doi.org/10.1145/1462179.1462184",
    "publication_date": "2009-02-01",
    "publication_year": 2009,
    "authors": "Stefano Guerrini; Andrea Masini",
    "corresponding_authors": "",
    "abstract": "The concept of syntactical duality is central in logic. In particular, the duality defined by classical negation, or more syntactically by left and right in sequents, has been widely used to relate logic and computations. We study the proof/test duality proposed by Girard in his 1999 paper on the meaning of logical rules. In detail, starting from the notion of “test” proposed by Girard, we develop a notion of test for intuitionistic logic and we give a complete deductive system whose computational interpretation is the target language of the call-by-value and call-by-name continuation passing style translations.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2112607161",
    "type": "article"
  },
  {
    "title": "Expressiveness of Logic Programs under the General Stable Model Semantics",
    "doi": "https://doi.org/10.1145/3039244",
    "publication_date": "2017-04-30",
    "publication_year": 2017,
    "authors": "Heng Zhang; Yan Zhang",
    "corresponding_authors": "",
    "abstract": "Stable model semantics had been recently generalized to non-Herbrand structures by several works, which provides a unified framework and solid logical foundations for answer set programming. This article focuses on the expressiveness of normal and disjunctive logic programs under general stable model semantics. A translation from disjunctive logic programs to normal logic programs is proposed for infinite structures. Over finite structures, some disjunctive logic programs are proved to be intranslatable to normal logic programs if the arities of auxiliary predicates and functions are bounded in a certain way. The equivalence of the expressiveness of normal logic programs and disjunctive logic programs over arbitrary structures is also shown to coincide with that over finite structures and coincide with whether the complexity class NP is closed under complement. Moreover, to obtain a more explicit picture of the expressiveness, some intertranslatability results between logic program classes, and fragments of second-order logic are established.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W237647712",
    "type": "article"
  },
  {
    "title": "Information Flow under Budget Constraints",
    "doi": "https://doi.org/10.1145/3152768",
    "publication_date": "2017-10-31",
    "publication_year": 2017,
    "authors": "Pavel Naumov; Tao Jia",
    "corresponding_authors": "",
    "abstract": "Although first proposed in the database theory as properties of functional dependencies between attributes, Armstrong’s axioms capture general principles of information flow by describing properties of dependencies between sets of pieces of information. This article generalizes Armstrong’s axioms to a setting in which there is a cost associated with information. The proposed logical system captures general principles of dependencies between pieces of information constrained by a given budget.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2775642312",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1656242",
    "publication_date": "2010-01-01",
    "publication_year": 2010,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "We study the problem of deciding the satisfiability of first-order logic queries over views, with our aim to delimit the boundary between the decidable and the undecidable fragments of this language. Views currently occupy a central place in database ...",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4239845892",
    "type": "paratext"
  },
  {
    "title": "Inference from Visible Information and Background Knowledge",
    "doi": "https://doi.org/10.1145/3452919",
    "publication_date": "2021-04-30",
    "publication_year": 2021,
    "authors": "Michael Benedikt; Pierre Bourhis; Balder ten Cate; Gabrieled Puppis; Michael Vanden Boom",
    "corresponding_authors": "",
    "abstract": "We provide a wide-ranging study of the scenario where a subset of the relations in a relational vocabulary are visible to a user --- that is, their complete contents are known --- while the remaining relations are invisible. We also have a background theory --- invariants given by logical sentences --- which may relate the visible relations to invisible ones, and also may constrain both the visible and invisible relations in isolation. We want to determine whether some other information, given as a positive existential formula, can be inferred using only the visible information and the background theory. This formula whose inference we are concered with is denoted as the \\emph{query}. We consider whether positive information about the query can be inferred, and also whether negative information -- the sentence does not hold -- can be inferred. We further consider both the instance-level version of the problem, where both the query and the visible instance are given, and the schema-level version, where we want to know whether truth or falsity of the query can be inferred in some instance of the schema.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W3173409349",
    "type": "article"
  },
  {
    "title": "Reiterman’s Theorem on Finite Algebras for a Monad",
    "doi": "https://doi.org/10.1145/3464691",
    "publication_date": "2021-09-08",
    "publication_year": 2021,
    "authors": "Jiřı́ Adámek; Liang-Ting Chen; Stefan Milius; Henning Urbat",
    "corresponding_authors": "",
    "abstract": "Profinite equations are an indispensable tool for the algebraic classification of formal languages. Reiterman’s theorem states that they precisely specify pseudovarieties, i.e., classes of finite algebras closed under finite products, subalgebras and quotients. In this article, Reiterman’s theorem is generalized to finite Eilenberg-Moore algebras for a monad T on a category D: we prove that a class of finite T -algebras is a pseudovariety iff it is presentable by profinite equations. As a key technical tool, we introduce the concept of a profinite monad T ^ associated to the monad T , which gives a categorical view of the construction of the space of profinite terms.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W3198235119",
    "type": "article"
  },
  {
    "title": "A Formal System for the Universal Quantification of Schematic Variables",
    "doi": "https://doi.org/10.1145/3470646",
    "publication_date": "2021-10-22",
    "publication_year": 2021,
    "authors": "Ferruccio Guidi",
    "corresponding_authors": "Ferruccio Guidi",
    "abstract": "We advocate the use of de Bruijn’s universal abstraction \\lambda {\\mathord \\infty }{}{}{} for the quantification of schematic variables in the predicative setting, and we present a typed \\lambda {}{}{}{} -calculus featuring the quantifier \\lambda {\\mathord \\infty }{}{}{} accompanied by other practically useful constructions like explicit substitutions and expected type annotations. Our calculus stands just on two notions, i.e., bound rt-reduction and parametric validity, and has the expressive power of \\lambda \\mathord \\rightarrow . Thus, while not aiming at being a logical framework by itself, it does enjoy many desired invariants of logical frameworks including confluence of reduction, strong normalization, preservation of type by reduction, decidability, correctness of types and uniqueness of types up to conversion. This calculus belongs to the \\lambda \\delta family of formal systems, which borrow some features from the pure type systems and some from the languages of the Automath tradition, but stand outside both families. In particular, our calculus includes and evolves two earlier systems of this family. Moreover, a machine-checked specification of its theory is available.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W3210894027",
    "type": "article"
  },
  {
    "title": "Syntax-Preserving Belief Change Operators for Logic Programs",
    "doi": "https://doi.org/10.1145/3190783",
    "publication_date": "2018-04-30",
    "publication_year": 2018,
    "authors": "Sebastian Binnewies; Zhiqiang Zhuang; Kewen Wang; Bela Stantić",
    "corresponding_authors": "",
    "abstract": "Recent methods have adapted the well-established AGM and belief base frameworks for belief change to cover belief revision in logic programs. In this study here, we present two new sets of belief change operators for logic programs. They focus on preserving the explicit relationships expressed in the rules of a program, a feature that is missing in purely semantic approaches that consider programs only in their entirety. In particular, operators of the latter class fail to satisfy preservation and support, two important properties for belief change in logic programs required to ensure intuitive results. We address this shortcoming of existing approaches by introducing partial meet and ensconcement constructions for logic program belief change, which allow us to define syntax-preserving operators for satisfying preservation and support. Our work is novel in that our constructions not only preserve more information from a logic program during a change operation than existing ones, but they also facilitate natural definitions of contraction operators, the first in the field to the best of our knowledge. To evaluate the rationality of our operators, we translate the revision and contraction postulates from the AGM and belief base frameworks to the logic programming setting. We show that our operators fully comply with the belief base framework and formally state the interdefinability between our operators. We further compare our approach to two state-of-the-art logic program revision methods and demonstrate that our operators address the shortcomings of one and generalise the other method.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2604807150",
    "type": "article"
  },
  {
    "title": "Finite-State Map-Reduce Computation and Relational Algebra Queries",
    "doi": "https://doi.org/10.1145/3197384",
    "publication_date": "2018-04-30",
    "publication_year": 2018,
    "authors": "Frank Neven; Nicole Schweikardt; Frédéric Servais; Tony Tan",
    "corresponding_authors": "",
    "abstract": "We introduce three formal models of distributed systems for query evaluation on massive databases: Distributed Streaming with Register Automata (DSAs), Distributed Streaming with Register Transducers (DSTs), and Distributed Streaming with Register Transducers and Joins (DSTJs). These models are based on the map-reduce paradigm where the input is transformed into a dataset of key-value pairs, and on each key a local computation is performed on the values associated with that key resulting in another set of key-value pairs. Computation proceeds in a constant number of rounds, where the result of the last round is the input to the next round, and transformation of key-value pairs is required to be generic. The difference between the three models is in the local computation part. In DSAs it is limited to making one pass over its input using a register automaton, while in DSTs it can make two passes: in the first pass it uses a finite state automaton and in the second it uses a register transducer. The third model DSTJs is an extension of DSTs, where local computations are capable of constructing the Cartesian product of two sets. We obtain the following results: (1) DSAs can evaluate first-order queries over bounded degree databases; (2) DSTs can evaluate semijoin algebra queries over arbitrary databases; (3) DSTJs can evaluate the whole relational algebra over arbitrary databases; (4) DSTJs are strictly stronger than DSTs, which in turn are strictly stronger than DSAs; (5) within DSAs, DSTs, and DSTJs, there is a strict hierarchy w.r.t. the number of rounds.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2810808851",
    "type": "article"
  },
  {
    "title": "Automated Deduction in Gödel Logic",
    "doi": "https://doi.org/10.1145/3218817",
    "publication_date": "2018-07-31",
    "publication_year": 2018,
    "authors": "Dušan Guller",
    "corresponding_authors": "Dušan Guller",
    "abstract": "This article addresses the deduction problem of a formula from a countable theory in the first-order Gödel logic. We generalise the well-known hyperresolution principle for deduction in Gödel logic. Our approach is based on translation of a formula to an equivalent satisfiable finite order clausal theory, consisting of order clauses. We introduce a notion of quantified atom: a formula a is a quantified atom if a = Qx , p ( t 0 , …, t n ), where Q is a quantifier (∀, ∃), p ( t 0 , …, t n ) is an atom, and x is a variable occurring in p ( t 0 , …, t n ); for all i ≤ n , either t i = x or x does not occur in t i . Then an order clause is a finite set of order literals of the form ϵ 1 ⋄ ϵ 2 , where ϵ i is either an atom, or a truth constant ( 0 , 1 ), or a quantified atom, and ⋄ is either a connective ≖, equality, or ≺ strict order. ≖ and ≺ are interpreted by the equality and standard strict linear order on [ 0 , 1 ], respectively. On the basis of the hyperresolution principle, a calculus operating over order clausal theories is devised. The calculus is proved to be refutation sound and complete for the countable case. As an interesting consequence, we get an affirmative solution to the open problem of recursive enumerability of unsatisfiable formulae in Gödel logic.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2890827357",
    "type": "article"
  },
  {
    "title": "Reasoning about Strategic Abilities",
    "doi": "https://doi.org/10.1145/3309761",
    "publication_date": "2019-03-18",
    "publication_year": 2019,
    "authors": "Nils Bulling; Wojciech Jamroga; Matei Popovici",
    "corresponding_authors": "",
    "abstract": "In alternating-time temporal logic ATL * , agents with perfect recall assign choices to sequences of states, i.e., to possible finite histories of the game. However, when a nested strategic modality is interpreted, the new strategy does not take into account the previous sequence of events. It is as if agents collect their observations in the nested game again from scratch, thus, effectively forgetting what they observed before. Intuitively, it does not fit the assumption of agents having perfect recall of the past. In this article, we investigate the alternative semantics for ATL * where the past is not forgotten in nested games. We show that the standard semantics of ATL * coincides with the “truly perfect recall” semantics for agents with perfect information and in case of so-called “objective” abilities under uncertainty. On the other hand, the two semantics differ significantly for the most popular (“subjective”) notion of ability under imperfect information. The same applies to the standard vs. “truly perfect recall” semantics of ATL * with persistent strategies. We compare the relevant variants of ATL * by looking at their expressive power, sets of validities, and tractability of model checking.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2921537151",
    "type": "article"
  },
  {
    "title": "Binary Reachability of Timed-register Pushdown Automata and Branching Vector Addition Systems",
    "doi": "https://doi.org/10.1145/3326161",
    "publication_date": "2019-05-31",
    "publication_year": 2019,
    "authors": "Lorenzo Clemente; Sławomir Lasota; Ranko Lazić; Filip Mazowiecki",
    "corresponding_authors": "",
    "abstract": "Timed-register pushdown automata constitute a very expressive class of automata, whose transitions may involve state, input, and top-of-stack timed registers with unbounded differences. They strictly subsume pushdown timed automata of Bouajjani et al., dense-timed pushdown automata of Abdulla et al., and orbit-finite timed-register pushdown automata of Clemente and Lasota. We give an effective logical characterisation of the reachability relation of timed-register pushdown automata. As a corollary, we obtain a doubly exponential time procedure for the non-emptiness problem. We show that the complexity reduces to singly exponential under the assumption of monotonic time. The proofs involve a novel model of one-dimensional integer branching vector addition systems with states. As a result interesting on its own, we show that reachability sets of the latter model are semilinear and computable in exponential time.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2948751124",
    "type": "article"
  },
  {
    "title": "Minkowski Games",
    "doi": "https://doi.org/10.1145/3230741",
    "publication_date": "2018-07-31",
    "publication_year": 2018,
    "authors": "Stéphane Le Roux; Arno Pauly; Jean-François Raskin",
    "corresponding_authors": "",
    "abstract": "We introduce and study Minkowski games. These are two-player games, where the players take turns to choose positions in R&lt;sup&lt;d&lt;/sup&lt; based on some rules. Variants include boundedness games, where one player wants to keep the positions bounded, and the other wants to escape to infinity; as well as safety games, where one player wants to stay within a prescribed set, while the other wants to leave it. We provide some general characterizations of which player can win such games and explore the computational complexity of the associated decision problems. A natural representation of boundedness games yields coNP-completeness, whereas the safety games are undecidable.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2991018442",
    "type": "article"
  },
  {
    "title": "MTL and TPTL for One-Counter Machines",
    "doi": "https://doi.org/10.1145/3372789",
    "publication_date": "2019-12-20",
    "publication_year": 2019,
    "authors": "Shiguang Feng; Claudia Carapelle; Oliver Fernández Gil; Karin Quaas",
    "corresponding_authors": "",
    "abstract": "Metric Temporal Logic (MTL) and Timed Propositional Temporal Logic (TPTL) are quantitative extensions of Linear Temporal Logic (LTL) that are prominent and widely used in the verification of real-timed systems. We study MTL and TPTL as specification languages for one-counter machines. It is known that model checking one-counter machines against formulas of Freeze LTL (FLTL), a strict fragment of TPTL, is undecidable. We prove that in our setting, MTL is strictly less expressive than TPTL, and incomparable in expressiveness to FLTL, so undecidability for MTL is not implied by the result for FLTL. We show, however, that the model-checking problem for MTL is undecidable. We further prove that the satisfiability problem for the unary fragments of TPTL and MTL are undecidable; for TPTL, this even holds for the fragment in which only one register and the finally modality is used. This is opposed to a known decidability result for the satisfiability problem for the same fragment of FLTL.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2995528133",
    "type": "article"
  },
  {
    "title": "Spectrum of FO Logic with Quantifier Depth 4 is Finite",
    "doi": "https://doi.org/10.1145/3641547",
    "publication_date": "2024-01-22",
    "publication_year": 2024,
    "authors": "Yury Yarovikov; Maksim Zhukovskii",
    "corresponding_authors": "",
    "abstract": "The k -spectrum is the set of all α &gt; 0 such that G(n,n −α ) does not obey the 0-1 law for FO sentences with quantifier depth at most k . In this article, we prove that the minimum k such that the k -spectrum is infinite equals 5.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3216731410",
    "type": "article"
  },
  {
    "title": "Characterising Modal Formulas with Examples",
    "doi": "https://doi.org/10.1145/3649461",
    "publication_date": "2024-02-27",
    "publication_year": 2024,
    "authors": "Balder ten Cate; Raoul Koudijs",
    "corresponding_authors": "",
    "abstract": "We study the existence of finite characterisations for modal formulas. A finite characterisation of a modal formula φ is a finite collection of positive and negative examples that distinguishes φ from every other, non-equivalent modal formula, where an example is a finite pointed Kripke structure. This definition can be restricted to specific frame classes and to fragments of the modal language: a modal fragment ℒ admits finite characterisations with respect to a frame class ℱ if every formula φ ∈ ℒ has a finite characterisation with respect to ℒ consisting of examples that are based on frames in ℱ. Finite characterisations are useful for illustration, interactive specification and debugging of formal specifications, and their existence is a precondition for exact learnability with membership queries. We show that the full modal language admits finite characterisations with respect to a frame class ℱ only when the modal logic of ℱ is locally tabular. We then study which modal fragments, freely generated by some set of connectives, admit finite characterisations. Our main result is that the positive modal language without the truth-constants ⊤ and ⊥ admits finite characterisations w.r.t. the class of all frames. This result is essentially optimal: finite characterisability fails when the language is extended with the truth constant ⊤ or ⊥ or with all but very limited forms of negation.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4392192143",
    "type": "article"
  },
  {
    "title": "The Complexity of LTL Rational Synthesis",
    "doi": "https://doi.org/10.1145/3648473",
    "publication_date": "2024-02-28",
    "publication_year": 2024,
    "authors": "Orna Kupferman; Noam Shenwald",
    "corresponding_authors": "",
    "abstract": "In rational synthesis , we automatically construct a reactive system that satisfies its specification in all rational environments, namely environments that have objectives and act to fulfill them. We complete the study of the complexity of LTL rational synthesis, when the objectives are given by formulas in Linear Temporal Logic. Our contribution is threefold. First, we tighten the known upper bounds for settings that were left open in earlier work. Second, our complexity analysis is parametric, and we describe tight upper and lower bounds in each of the problem parameters: the game graph, the objectives of the system components, and the objectives of the environment components. Third, we generalize the definition of rational synthesis by adding hostile players to the setting and by combining the cooperative and non-cooperative approaches studied in earlier work.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4392240364",
    "type": "article"
  },
  {
    "title": "Computationally Hard Problems for Logic Programs under Answer Set Semantics",
    "doi": "https://doi.org/10.1145/3676964",
    "publication_date": "2024-07-10",
    "publication_year": 2024,
    "authors": "Yuping Shen; Xishun Zhao",
    "corresponding_authors": "",
    "abstract": "Showing that a problem is hard for a model of computation is one of the most challenging tasks in theoretical computer science, logic and mathematics. For example, it remains beyond reach to find an explicit problem that cannot be computed by polynomial size propositional formulas (PF). As a model of computation, logic programs (LP) under answer set semantics are as expressive as PF and also \\(\\mathtt{NP}\\) -complete for satisfiability checking. In this article, we show that the PAR problem is hard for LP, i.e., deciding whether a binary string contains an odd number of \\(1\\) ’s requires exponential size LP. The proof idea is first to transform logic programs into equivalent boolean circuits and then apply a probabilistic method known as random restriction to obtain an exponential lower bound. Based on the main result, we generalize a sufficient condition for identifying hard problems for LP and give a separation map for an LP family from a computational point of view, whose members are all equally expressive and share the same reasoning complexity.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4400487601",
    "type": "article"
  },
  {
    "title": "Cutting Planes Width and the Complexity of Graph Isomorphism Refutations",
    "doi": "https://doi.org/10.1145/3677121",
    "publication_date": "2024-07-18",
    "publication_year": 2024,
    "authors": "Jacobo Torán; Florian Wörz",
    "corresponding_authors": "",
    "abstract": "The width complexity measure plays a central role in resolution and other propositional proof systems like Polynomial Calculus (under the name of degree). The study of width lower bounds is the most used method for proving size lower bounds, and it is known that for the mentioned proof systems, proofs with small width also imply the existence of proofs with small size. Not much has been studied, however, about the width parameter in the cutting planes (CP) proof system, a measure that was introduced by Dantchev and Martin in 2009 under the name of CP cutwidth. In this article, we study the width complexity of CP refutations of graph isomorphism formulas. For a pair of non-isomorphic graphs \\(G\\) and \\(H\\) , we show a direct connection between the Weisfeiler–Leman differentiation number \\(\\mathsf{WL}(G,H)\\) of the graphs and the width of a CP refutation for the corresponding isomorphism formula \\(\\mathrm{Iso}(G,H)\\) . In particular, we show that if \\(\\mathsf{WL}(G,H)\\leq k\\) , then there is a CP refutation of \\(\\mathrm{Iso}(G,H)\\) with width \\(k\\) , and if \\(\\mathsf{WL}(G,H) \\gt k\\) , then there are no CP refutations of \\(\\mathrm{Iso}(G,H)\\) with width \\(k-2\\) . Similar results are known for other proof systems, like Resolution, Sherali–Adams, or Polynomial Calculus. We also obtain polynomial-length CP refutations from our width bound for isomorphism formulas for graphs with constant Weisfeiler–Leman dimension. Furthermore, we notice that a length lower bound for refuting graph isomorphism formulas in the subsystem of tree-like cutting planes with polynomially bounded coefficients follows from known results.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4400772806",
    "type": "article"
  },
  {
    "title": "The Implication Problem for Functional Dependencies and Variants of Marginal Distribution Equivalences",
    "doi": "https://doi.org/10.1145/3677120",
    "publication_date": "2024-07-18",
    "publication_year": 2024,
    "authors": "Minna Hirvonen",
    "corresponding_authors": "Minna Hirvonen",
    "abstract": "We study functional dependencies together with two different probabilistic dependency notions: unary marginal identity and unary marginal distribution equivalence. A unary marginal identity states that two variables \\(x\\) and \\(y\\) are identically distributed. A unary marginal distribution equivalence states that the multiset consisting of the marginal probabilities of all the values for variable \\(x\\) is the same as the corresponding multiset for \\(y\\) . We present a sound and complete axiomatization for the class of these dependencies and show that it has Armstrong relations. The axiomatization is infinite, but we show that there can be no finite axiomatization. The implication problem for the subclass that contains only functional dependencies and unary marginal identities can be simulated with functional dependencies and unary inclusion atoms, and therefore the problem is in polynomial-time. This complexity bound also holds in the case of the full class, which we show by constructing a polynomial-time algorithm.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4400772967",
    "type": "article"
  },
  {
    "title": "Compound Logics for Modification Problems",
    "doi": "https://doi.org/10.1145/3696451",
    "publication_date": "2024-09-20",
    "publication_year": 2024,
    "authors": "Fedor V. Fomin; Petr A. Golovach; Ignasi Sau; Giannos Stamoulis; Dimitrios M. Thilikos",
    "corresponding_authors": "",
    "abstract": "We introduce a novel model-theoretic framework inspired from graph modification and based on the interplay between model theory and algorithmic graph minors. The core of our framework is a new compound logic operating with two types of sentences, expressing graph modification: the modulator sentence, defining some property of the modified part of the graph, and the target sentence, defining some property of the resulting graph. In our framework, modulator sentences are in counting monadic second-order logic ( CMSO ) and have models of bounded treewidth, while target sentences express first-order logic ( FO ) properties. Our logic captures problems that are not definable in first-order logic and, moreover, may have instances of unbounded treewidth. Our main result is that, for this compound logic, model-checking can be done in quadratic time on minor-free graphs. The proposed logic can be seen as a general framework to capitalize on the potential of the irrelevant vertex technique. It gives a way to deal with problem instances of unbounded treewidth, for which Courcelle's theorem does not apply. The proof of our meta-theorem combines novel combinatorial results related to the Flat Wall theorem along with elements of the proof of Courcelle's theorem and Gaifman's theorem. Our algorithmic meta-theorem encompasses, unifies, and extends the known meta-algorithmic results for CMSO and FO on minor-closed graph classes.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4402678918",
    "type": "article"
  },
  {
    "title": "Solving promise equations over monoids and groups",
    "doi": "https://doi.org/10.1145/3698106",
    "publication_date": "2024-09-27",
    "publication_year": 2024,
    "authors": "Alberto Larrauri; Stanislav Živný",
    "corresponding_authors": "",
    "abstract": "We give a complete complexity classification for the problem of finding a solution to a given system of equations over a fixed finite monoid, given that a solution over a more restricted monoid exists. As a corollary, we obtain a complexity classification for the same problem over groups.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4402921912",
    "type": "article"
  },
  {
    "title": "A Saturation-Based Unification Algorithm for Higher-Order Rational Patterns",
    "doi": "https://doi.org/10.1145/3704265",
    "publication_date": "2024-11-12",
    "publication_year": 2024,
    "authors": "Zhibo Chen; Frank Pfenning",
    "corresponding_authors": "",
    "abstract": "Higher-order unification has been shown to be undecidable [Huet 1973]. Miller discovered the pattern fragment and subsequently showed that higher-order pattern unification is decidable and has most general unifiers [1991]. We extend the algorithm to higher-order rational terms (a.k.a. regular Böhm trees [Huet 1998], a form of cyclic \\(\\lambda\\) -terms) and show that pattern unification on higher-order rational terms is decidable and has most general unifiers. We prove the soundness and completeness of the algorithm.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4404257041",
    "type": "article"
  },
  {
    "title": "Model Checking Strategic Abilities in Information-sharing Systems",
    "doi": "https://doi.org/10.1145/3704919",
    "publication_date": "2024-11-19",
    "publication_year": 2024,
    "authors": "Francesco Belardinelli; Ioana Boureanu; Cătălin Dima; Vadim Malvone",
    "corresponding_authors": "",
    "abstract": "We introduce a subclass of concurrent game structures (CGS) with imperfect information in which agents are endowed with private data-sharing capabilities. Importantly, our CGSs are such that it is still decidable to model-check these CGSs against a relevant fragment of ATL. These systems can be thought as a generalisation of architectures allowing information forks, that is, cases where strategic abilities lead to certain agents outside a coalition privately sharing information with selected agents inside that coalition. Moreover, in our case, in the initial states of the system, we allow information forks from agents outside a given set \\(A\\) to agents inside this group \\(A\\) . For this reason, together with the fact that the communication in our models underpins a specialised form of broadcast, we call our formalism \\(A\\) -cast systems . To underline, the fragment of ATL for which we show the model-checking problem to be decidable over \\(A\\) -cast is a large and significant one; it expresses coalitions over agents in any subset of the set \\(A\\) . Indeed, as we show, our systems and this ATL fragments can encode security problems that are notoriously hard to express faithfully: terrorist-fraud attacks in identity schemes.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4404527829",
    "type": "article"
  },
  {
    "title": "Knuth--bendix constraint solving is NP-complete",
    "doi": "https://doi.org/10.1145/1055686.1055692",
    "publication_date": "2005-04-01",
    "publication_year": 2005,
    "authors": "Konstantin Korovin; Андрей Воронков",
    "corresponding_authors": "",
    "abstract": "We show the NP-completeness of the existential theory of term algebras with the Knuth--Bendix order by giving a nondeterministic polynomial-time algorithm for solving Knuth--Bendix ordering constraints.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2021951582",
    "type": "article"
  },
  {
    "title": "Convergent approximate solving of first-order constraints by approximate quantifiers",
    "doi": "https://doi.org/10.1145/976706.976709",
    "publication_date": "2004-04-01",
    "publication_year": 2004,
    "authors": "Stefan Ratschan",
    "corresponding_authors": "Stefan Ratschan",
    "abstract": "Exactly solving first-order constraints (i.e., first-order formulas over a certain predefined structure) can be a very hard, or even undecidable problem. In continuous structures like the real numbers it is promising to compute approximate solutions instead of exact ones. However, the quantifiers of the first-order predicate language are an obstacle to allowing approximations to arbitrary small error bounds. In this article, we remove this obstacle by modifying the first-order language and replacing the classical quantifiers with approximate quantifiers. These also have two additional advantages: First, they are tunable, in the sense that they allow the user to decide on the trade-off between precision and efficiency. Second, they introduce additional expressivity into the first-order language by allowing reasoning over the size of solution sets.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2025497968",
    "type": "article"
  },
  {
    "title": "Linking Focusing and Resolution with Selection",
    "doi": "https://doi.org/10.1145/3373276",
    "publication_date": "2020-02-20",
    "publication_year": 2020,
    "authors": "Guillaume Burel",
    "corresponding_authors": "Guillaume Burel",
    "abstract": "Focusing and selection are techniques that shrink the proof-search space for respectively sequent calculi and resolution. To bring out a link between them, we generalize them both: we introduce a sequent calculus where each occurrence of an atomic formula can have a positive or a negative polarity; and a resolution method where each literal, whatever its sign, can be selected in input clauses. We prove the equivalence between cut-free proofs in this sequent calculus and derivations of the empty clause in that resolution method. Such a generalization is not semi-complete in general, which allows us to consider complete instances that correspond to theories of any logical strength. We present three complete instances: first, our framework allows us to show that ordinary focusing corresponds to hyperresolution and semantic resolution; the second instance is deduction modulo theory and the related framework called superdeduction; and a new setting, not captured by any existing framework, extends deduction modulo theory with rewriting rules having several left-hand sides, which restricts even more the proof-search space.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2790463784",
    "type": "article"
  },
  {
    "title": "Extending Liquid Types to Arrays",
    "doi": "https://doi.org/10.1145/3362740",
    "publication_date": "2020-01-21",
    "publication_year": 2020,
    "authors": "Manuel Montenegro; Susana Nieva; Ricardo Peña; Clara Segura",
    "corresponding_authors": "",
    "abstract": "A liquid type is an ordinary Hindley-Milner type annotated with a logical predicate that states the properties satisfied by the elements of that type. Liquid types are a powerful tool for program verification, as programmers can use them to specify pre- and post conditions of their programs, whereas the predicates of intermediate variables and auxiliary functions are inferred automatically. Type inference is feasible in this context, as the logical predicates within liquid types are constrained to a quantifier-free logic to maintain decidability. In this article, we extend liquid types by allowing them to contain quantified properties on arrays so that they can be used to infer invariants on array-related programs (e.g., implementations of sorting algorithms). Although quantified logic is, in general, undecidable, we restrict properties on arrays to a decidable subset introduced by Bradley et al. We describe in detail the extended type system, the verification condition generator, and the iterative weakening algorithm for inferring invariants. After proving the correctness and completeness of these two algorithms, we apply them to find invariants on a set of algorithms involving array manipulations.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W3001875841",
    "type": "article"
  },
  {
    "title": "Finite Open-world Query Answering with Number Restrictions",
    "doi": "https://doi.org/10.1145/3365834",
    "publication_date": "2020-07-05",
    "publication_year": 2020,
    "authors": "Antoine Amarilli; Michael Benedikt",
    "corresponding_authors": "",
    "abstract": "Open-world query answering is the problem of deciding, given a set of facts, conjunction of constraints, and query, whether the facts and constraints imply the query. This amounts to reasoning over all instances that include the facts and satisfy the constraints. We study finite open-world query answering (FQA), which assumes that the underlying world is finite and thus only considers the finite completions of the instance. The major known decidable cases of FQA derive from the following: the guarded fragment of first-order logic, which can express referential constraints (data in one place points to data in another) but cannot express number restrictions such as functional dependencies; and the guarded fragment with number restrictions but on a signature of arity only two. In this article, we give the first decidability results for FQA that combine both referential constraints and number restrictions for arbitrary signatures: We show that, for unary inclusion dependencies and functional dependencies, the finiteness assumption of FQA can be lifted up to taking the finite implication closure of the dependencies. Our result relies on new techniques to construct finite universal models of such constraints for any bound on the maximal query size.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W3040069683",
    "type": "article"
  },
  {
    "title": "Model Checking a Logic for True Concurrency",
    "doi": "https://doi.org/10.1145/3412853",
    "publication_date": "2020-10-26",
    "publication_year": 2020,
    "authors": "Paolo Baldan; Tommaso Padoan",
    "corresponding_authors": "",
    "abstract": "We study the model-checking problem for a logic for true concurrency, whose formulae predicate about events in computations and their causal dependencies. The logic, which represents the logical counterpart of history-preserving bisimilarity, is naturally interpreted over event structures or any formalism that can be given a causal semantics, like Petri nets. It includes least and greatest fixpoint operators and thus it can express properties of infinite computations. Since the event structure associated with a system is typically infinite (even if the system is finite state), already the decidability of model-checking is non-trivial. We first develop a local model-checking technique based on a tableau system, for which, over a class of event structures satisfying a suitable regularity condition, referred to as strong regularity, we prove termination, soundness, and completeness. The tableau system allows for a clean and intuitive proof of decidability, but a direct implementation of the procedure can be extremely inefficient. For easing the development of a more efficient model-checking technique, we move to an automata-theoretic framework. Given a formula and a strongly regular event structure, we show how to construct a parity tree automaton whose language is non-empty if and only if the event structure satisfies the formula. The automaton is usually infinite. We discuss how it can be quotiented to an equivalent finite automaton, where emptiness can be checked effectively. To show the applicability of the approach, we discuss how it instantiates to finite safe Petri nets, providing also a corresponding proof-of-concept model-checking tool.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W3095895296",
    "type": "article"
  },
  {
    "title": "A Subatomic Proof System for Decision Trees",
    "doi": "https://doi.org/10.1145/3545116",
    "publication_date": "2022-06-28",
    "publication_year": 2022,
    "authors": "Chris Barrett; Alessio Guglielmi",
    "corresponding_authors": "",
    "abstract": "We design a proof system for propositional classical logic that integrates two languages for Boolean functions: standard conjunction-disjunction-negation and binary decision trees. We give two reasons to do so. The first is proof-theoretical naturalness: the system consists of all and only the inference rules generated by the single, simple, linear scheme of the recently introduced subatomic logic. Thanks to this regularity, cuts are eliminated via a natural construction. The second reason is that the system generates efficient proofs. Indeed, we show that a certain class of tautologies due to Statman, which cannot have better than exponential cut-free proofs in the sequent calculus, have polynomial cut-free proofs in our system. We achieve this by using the same construction that we use for cut elimination. In summary, by expanding the language of propositional logic, we make its proof theory more regular and generate more proofs, some of which are very efficient. That design is made possible by considering atoms as superpositions of their truth values, which are connected by self-dual, non-commutative connectives. A proof can then be projected via each atom into two proofs, one for each truth value, without a need for cuts. Those projections are semantically natural and are at the heart of the constructions in this paper. To accommodate self-dual non-commutativity, we compose proofs in deep inference.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W3159047636",
    "type": "article"
  },
  {
    "title": "Extensional equivalence and singleton types",
    "doi": "https://doi.org/10.1145/1166109.1166112",
    "publication_date": "2006-10-01",
    "publication_year": 2006,
    "authors": "C. Addison Stone; Robert Harper",
    "corresponding_authors": "",
    "abstract": "We study the λΠΣS≤ calculus, which contains singleton types S(M) classifying terms of base type provably equivalent to the term M. The system includes dependent types for pairs and functions (Σ and Π) and a subtyping relation induced by regarding singletons as subtypes of the base type. The decidability of type checking for this language is non-obvious, since to type check we must be able to determine equivalence of well-formed terms. But in the presence of singleton types, the provability of an equivalence judgment Γ ⊢ M1 ≡M2 : A can depend both on the typing context Γ and on the particular type A at which M1 and M2 are compared.We show how to prove decidability of term equivalence, hence of type checking, in λΠΣS≤ by exhibiting a type-directed algorithm for directly computing normal forms. The correctness of normalization is shown using an unusual variant of Kripke logical relations organized around sets; rather than defining a logical equivalence relation, we work directly with (subsets of) the corresponding equivalence classes.We then provide a more efficient algorithm for checking type equivalence without constructing normal forms. We also show that type checking, subtyping, and all other judgments of the system are decidable.The λΠΣS≤ calculus models type constructors and kinds in the intermediate language used by the TILT compiler for Standard ML to implement the SML module system. The decidability of λΠΣS≤ term equivalence allows us to show decidability of type checking for TILT's intermediate language. We also obtain a consistency result that allows us to prove type safety for the intermediate language. The algorithms derived here form the core of the type checker used for internal type checking in TILT.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4252452406",
    "type": "article"
  },
  {
    "title": "Reducible Theories and Amalgamations of Models",
    "doi": "https://doi.org/10.1145/3565364",
    "publication_date": "2022-09-29",
    "publication_year": 2022,
    "authors": "Bahar Aameri; Michael Grüninger",
    "corresponding_authors": "",
    "abstract": "Within knowledge representation in artificial intelligence, a first-order ontology is a theory in first-order logic that axiomatizes the concepts in some domain. Ontology verification is concerned with the relationship between the intended models of an ontology and the models of the axiomatization of the ontology. In particular, we want to characterize the models of an ontology up to isomorphism and determine whether or not these models are equivalent to the intended models of the ontology. Unfortunately, it can be quite difficult to characterize the models of an ontology up to isomorphism. In the first half of this article, we review the different metalogical relationships between first-order theories and identify which relationship is needed for ontology verification. In particular, we will demonstrate that the notion of logical synonymy is needed to specify a representation theorem for the class of models of one first-order ontology with respect to another. In the second half of the article, we discuss the notion of reducible theories and show we can specify representation theorems by which models are constructed by amalgamating models of the constituent ontologies.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4297999774",
    "type": "article"
  },
  {
    "title": "A Generalized Realizability and Intuitionistic Logic",
    "doi": "https://doi.org/10.1145/3565367",
    "publication_date": "2022-09-29",
    "publication_year": 2022,
    "authors": "A. Yu. Konovalov",
    "corresponding_authors": "A. Yu. Konovalov",
    "abstract": "Let V be a set of number-theoretical functions. We define a notion of V -realizability for predicate formulas in such a way that the indices of functions in V are used for interpreting the implication and the universal quantifier. In this article, we prove that Intuitionistic Predicate Calculus is sound with respect to the semantics of V -realizability if and only if some natural conditions for V hold.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4297999804",
    "type": "article"
  },
  {
    "title": "SAT Modulo Symmetries for Graph Generation and Enumeration",
    "doi": "https://doi.org/10.1145/3670405",
    "publication_date": "2024-06-09",
    "publication_year": 2024,
    "authors": "Markus Kirchweger; Stefan Szeider",
    "corresponding_authors": "",
    "abstract": "We propose a novel SAT-based approach to graph generation. Our approach utilizes the interaction between a CDCL SAT solver and a special symmetry propagator where the SAT solver runs on an encoding of the desired graph property. The symmetry propagator checks partially generated graphs for minimality with respect to a lexicographic ordering during the solving process. This approach has several advantages over a static symmetry breaking: (i) symmetries are detected early in the generation process, (ii) symmetry breaking is seamlessly integrated into the CDCL procedure, and (iii) the propagator performs a complete symmetry breaking without causing a prohibitively large initial encoding. We instantiate our approach by generating extremal graphs with certain restrictions in terms of forbidden subgraphs and diameter. In particular, we could confirm the Murty-Simon Conjecture (1979) on diameter-2-critical graphs for graphs up to 19 vertices and prove the exact number of Ramsey graphs \\(\\mathcal{R}(3,5,n)\\) and \\(\\mathcal{R}(4,4,n)\\) .",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4399509059",
    "type": "article"
  },
  {
    "title": "A Reversible Perspective on Petri Nets and Event Structures",
    "doi": "https://doi.org/10.1145/3686154",
    "publication_date": "2024-08-02",
    "publication_year": 2024,
    "authors": "Hernán Melgratti; Claudio Antares Mezzina; G. Pinna",
    "corresponding_authors": "",
    "abstract": "Event structures have emerged as a foundational model for concurrent computation, explaining computational processes by outlining the events and the relationships that dictate their execution. They play a pivotal role in the study of key aspects of concurrent computation models, such as causality and independence, and have found applications across a broad range of languages and models, spanning realms like persistence, probabilities, and quantum computing. Recently, event structures have been extended to address reversibility, where computational processes can undo previous computations. In this context, reversible event structures provide abstract representations of processes capable of both forward and backward steps in a computation. Since their introduction, event structures have played a crucial role in bridging operational models, traditionally exemplified by Petri nets and process calculi, with denotational ones, i.e., algebraic domains. In this context, we revisit the standard connection between Petri nets and event structures under the lenses of reversibility. Specifically, we introduce a subset of contextual Petri nets, dubbed reversible causal nets , that precisely correspond to reversible prime event structures. The distinctive feature of reversible causal nets lies in deriving causality from inhibitor arcs, departing from the conventional dependence on the overlap between the postset and preset of transitions. In this way, we are able to operationally explain the full model of reversible prime event structures.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4401248727",
    "type": "article"
  },
  {
    "title": "Erratum for “Randomization in Automata on Infinite Trees”",
    "doi": "https://doi.org/10.1145/2824254",
    "publication_date": "2015-10-19",
    "publication_year": 2015,
    "authors": "Arnaud Carayol; Axel Haddad; Olivier Serre",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W1976311396",
    "type": "erratum"
  },
  {
    "title": "A Confluent Rewriting System Having No Computable, One-Step, Normalizing Strategy",
    "doi": "https://doi.org/10.1145/2699917",
    "publication_date": "2015-02-17",
    "publication_year": 2015,
    "authors": "Jakob Grue Simonsen",
    "corresponding_authors": "Jakob Grue Simonsen",
    "abstract": "A full and finitely generated Church-Rosser term rewriting system is presented that has no computable one-step, normalizing strategy; the system is both left- and right-linear. The result provides a negative answer to a question posed by Kennaway in 1989: Number 10 on the List of Open Problems in Rewriting.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2085574851",
    "type": "article"
  },
  {
    "title": "Degree lower bounds of tower-type for approximating formulas with parity quantifiers",
    "doi": "https://doi.org/10.1145/2559948",
    "publication_date": "2014-02-01",
    "publication_year": 2014,
    "authors": "Albert Atserias; Anuj Dawar",
    "corresponding_authors": "",
    "abstract": "Kolaitis and Kopparty have shown that for any first-order formula with parity quantifiers over the language of graphs, there is a family of multivariate polynomials of constant-degree that agree with the formula on all but a 2 −Ω( n ) -fraction of the graphs with n vertices. The proof bounds the degree of the polynomials by a tower of exponentials whose height is the nesting depth of parity quantifiers in the formula. We show that this tower-type dependence is necessary. We build a family of formulas of depth q whose approximating polynomials must have degree bounded from below by a tower of exponentials of height proportional to q . Our proof has two main parts. First, we adapt and extend the results by Kolaitis and Kopparty that describe the joint distribution of the parities of the numbers of copies of small subgraphs in a random graph to the setting of graphs of growing size. Second, we analyze a variant of Karp's graph canonical labeling algorithm and exploit its massive parallelism to get a formula of low depth that defines an almost canonical pre-order on a random graph.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2113478995",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2802139",
    "publication_date": "2015-11-19",
    "publication_year": 2015,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "In 2003, Atserias and Dalmau resolved a major open question about the resolution proof system by establishing that the space complexity of a Conjunctive Normal Form (CNF) formula is always an upper bound on the width needed to refute the formula. Their ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4229675349",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2851089",
    "publication_date": "2016-03-28",
    "publication_year": 2016,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Desirable properties of a logic include decidability, and a model theory that inherits properties of first-order logic, such as interpolation and preservation theorems. It is known that the Guarded Fragment (GF) of first-order logic is decidable and ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4232082496",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2894199",
    "publication_date": "2016-07-22",
    "publication_year": 2016,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "A notion of convolution is presented in the context of formal power series together with lifting constructions characterising algebras of such series, which usually are quantales. A number of examples underpin the universality of these constructions, ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4232203304",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2590829",
    "publication_date": "2014-02-01",
    "publication_year": 2014,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "In a recently launched research program for developing logic as a formal theory of (interactive) computability, several very interesting logics have been introduced and axiomatized. These fragments of the larger Computability Logic aim not only to ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4232384954",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2656934",
    "publication_date": "2014-11-19",
    "publication_year": 2014,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "In his seminal paper, Mayr introduced the well-known process rewrite systems (PRS) hierarchy, which contains many well-studied classes of infinite-state systems including pushdown systems (PDS), Petri nets, and PA-processes. A separate development in ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4233340443",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2830313",
    "publication_date": "2015-12-10",
    "publication_year": 2015,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Differential game logic (dGL) is a logic for specifying and verifying properties of hybrid games, i.e., games that combine discrete, continuous, and adversarial dynamics. Unlike hybrid systems, hybrid games allow choices in the system dynamics to be ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4234959199",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2737801",
    "publication_date": "2015-03-21",
    "publication_year": 2015,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "A full and finitely generated Church-Rosser term rewriting system is presented that has no computable one-step, normalizing strategy; the system is both left- and right-linear. The result provides a negative answer to a question posed by Kennaway in ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4235479907",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2764956",
    "publication_date": "2015-07-08",
    "publication_year": 2015,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "There are two contributions in this article. First, we give a direct proof of the known fact that Frege systems with substitution can be p-simulated by the calculus of structures (CoS) extended with the substitution rule. This is done without referring ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4238564985",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2648783",
    "publication_date": "2014-07-08",
    "publication_year": 2014,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Annotated Probabilistic Temporal (APT) logic programs are a form of logic programs that allow users to state (or systems to automatically learn) rules of the form “formula G becomes true Δt time units after formula F became true with ℓ to u% ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4242455949",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2670130",
    "publication_date": "2015-03-24",
    "publication_year": 2015,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Traditional automata accept or reject their input and are therefore Boolean. In contrast, weighted automata map each word to a value from a semiring over a large domain. The special case of lattice automata, in which the semiring is a finite lattice, ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4244055099",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2616911",
    "publication_date": "2014-04-01",
    "publication_year": 2014,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "In this article, we consider the issue of how first-order answer set programs can be extended for handling preference reasoning. To this end, we propose a progression-based preference semantics for first-order answer set programs while explicit ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4245799006",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2996393",
    "publication_date": "2016-11-15",
    "publication_year": 2016,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Indistinguishability properties are essential in formal verification of cryptographic protocols. They are needed to model anonymity properties, strong versions of confidentiality, and resistance against offline guessing attacks. Indistinguishability ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4256002996",
    "type": "paratext"
  },
  {
    "title": "The Effects of Adding Reachability Predicates in Quantifier-Free Separation Logic",
    "doi": "https://doi.org/10.1145/3448269",
    "publication_date": "2021-04-30",
    "publication_year": 2021,
    "authors": "Stéphane Demri; Étienne Lozes; Alessio Mansutti",
    "corresponding_authors": "",
    "abstract": "The list segment predicate ls used in separation logic for verifying programs with pointers is well suited to express properties on singly-linked lists. We study the effects of adding ls to the full quantifier-free separation logic with the separating conjunction and implication, which is motivated by the recent design of new fragments in which all these ingredients are used indifferently and verification tools start to handle the magic wand connective. This is a very natural extension that has not been studied so far. We show that the restriction without the separating implication can be solved in polynomial space by using an appropriate abstraction for memory states, whereas the full extension is shown undecidable by reduction from first-order separation logic. Many variants of the logic and fragments are also investigated from the computational point of view when ls is added, providing numerous results about adding reachability predicates to quantifier-free separation logic.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W3174904711",
    "type": "article"
  },
  {
    "title": "Collapsible Pushdown Parity Games",
    "doi": "https://doi.org/10.1145/3457214",
    "publication_date": "2021-06-28",
    "publication_year": 2021,
    "authors": "Christopher H. Broadbent; Arnaud Carayol; Matthew Hague; Andrzej S. Murawski; C.-H. Luke Ong; Olivier Serre",
    "corresponding_authors": "",
    "abstract": "This article studies a large class of two-player perfect-information turn-based parity games on infinite graphs, namely, those generated by collapsible pushdown automata. The main motivation for studying these games comes from the connections from collapsible pushdown automata and higher-order recursion schemes, both models being equi-expressive for generating infinite trees. Our main result is to establish the decidability of such games and to provide an effective representation of the winning region as well as of a winning strategy. Thus, the results obtained here provide all necessary tools for an in-depth study of logical properties of trees generated by collapsible pushdown automata/recursion schemes.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W3175427225",
    "type": "article"
  },
  {
    "title": "The Complexity of Counting Problems Over Incomplete Databases",
    "doi": "https://doi.org/10.1145/3461642",
    "publication_date": "2021-09-08",
    "publication_year": 2021,
    "authors": "Marcelo Arenas; Pablo Barceló; Mikaël Monet",
    "corresponding_authors": "",
    "abstract": "We study the complexity of various fundamental counting problems that arise in the context of incomplete databases, i.e., relational databases that can contain unknown values in the form of labeled nulls. Specifically, we assume that the domains of these unknown values are finite and, for a Boolean query q , we consider the following two problems: Given as input an incomplete database D , (a) return the number of completions of D that satisfy q ; or (b) return the number of valuations of the nulls of D yielding a completion that satisfies q . We obtain dichotomies between #P-hardness and polynomial-time computability for these problems when q is a self-join–free conjunctive query and study the impact on the complexity of the following two restrictions: (1) every null occurs at most once in D (what is called Codd tables ); and (2) the domain of each null is the same. Roughly speaking, we show that counting completions is much harder than counting valuations: For instance, while the latter is always in #P, we prove that the former is not in #P under some widely believed theoretical complexity assumption. Moreover, we find that both (1) and (2) can reduce the complexity of our problems. We also study the approximability of these problems and show that, while counting valuations always has a fully polynomial-time randomized approximation scheme (FPRAS), in most cases counting completions does not. Finally, we consider more expressive query languages and situate our problems with respect to known complexity classes.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W3197242963",
    "type": "article"
  },
  {
    "title": "EXPSPACE-Completeness of the Logics K4 × S5 and S4 × S5 and the Logic of Subset Spaces",
    "doi": "https://doi.org/10.1145/3465384",
    "publication_date": "2021-09-08",
    "publication_year": 2021,
    "authors": "Peter Hertling; Gisela Krommes",
    "corresponding_authors": "",
    "abstract": "It is known that the satisfiability problems of the product logics K4 × S5 and S4 × S5 are NEXPTIME-hard and that the satisfiability problem of the logic SSL of subset spaces is PSPACE-hard. Furthermore, it is known that the satisfiability problems of these logics are in N2EXPTIME. We improve the lower and the upper bounds for the complexity of these problems by showing that all three problems are in ESPACE and are EXPSPACE-complete under logspace reduction.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W3198236183",
    "type": "article"
  },
  {
    "title": "Local Belief Dynamics in Network Knowledge Bases",
    "doi": "https://doi.org/10.1145/3477394",
    "publication_date": "2021-10-22",
    "publication_year": 2021,
    "authors": "Fabio R. Gallo; Gerardo I. Simari; María Vanina Martínez; Natalia Abad Santos; Marcelo Alejandro Falappa",
    "corresponding_authors": "",
    "abstract": "People are becoming increasingly more connected to each other as social networks continue to grow both in number and variety, and this is true for autonomous software agents as well. Taking them as a collection, such social platforms can be seen as one complex network with many different types of relations, different degrees of strength for each relation, and a wide range of information on each node. In this context, social media posts made by users are reflections of the content of their own individual (or local) knowledge bases; modeling how knowledge flows over the network—or how this can possibly occur—is therefore of great interest from a knowledge representation and reasoning perspective. In this article, we provide a formal introduction to the network knowledge base model, and then focus on the problem of how a single agent’s knowledge base changes when exposed to a stream of news items coming from other members of the network. We do so by taking the classical belief revision approach of first proposing desirable properties for how such a local operation should be carried out (theoretical characterization), arriving at three different families of local operators, exploring concrete algorithms (algorithmic characterization) for two of the families, and proving properties about the relationship between the two characterizations (representation theorem). One of the most important differences between our approach and the classical models of belief revision is that in our case the input is more complex, containing additional information about each piece of information.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W3208538265",
    "type": "article"
  },
  {
    "title": "Piecewise Linear Valued CSPs Solvable by Linear Programming Relaxation",
    "doi": "https://doi.org/10.1145/3488721",
    "publication_date": "2021-11-22",
    "publication_year": 2021,
    "authors": "Manuel Bodirsky; Marcello Mamino; Caterina Viola",
    "corresponding_authors": "",
    "abstract": "Valued constraint satisfaction problems (VCSPs) are a large class of combinatorial optimisation problems. The computational complexity of VCSPs depends on the set of allowed cost functions in the input. Recently, the computational complexity of all VCSPs for finite sets of cost functions over finite domains has been classified. Many natural optimisation problems, however, cannot be formulated as VCSPs over a finite domain. We initiate the systematic investigation of infinite-domain VCSPs by studying the complexity of VCSPs for piecewise linear homogeneous cost functions. Such VCSPs can be solved in polynomial time if the cost functions are improved by fully symmetric fractional operations of all arities. We show this by reducing the problem to a finite-domain VCSP which can be solved using the basic linear program relaxation. It follows that VCSPs for submodular PLH cost functions can be solved in polynomial time; in fact, we show that submodular PLH functions form a maximally tractable class of PLH cost functions.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W3214912144",
    "type": "article"
  },
  {
    "title": "Symmetric Circuits for Rank Logic",
    "doi": "https://doi.org/10.1145/3476227",
    "publication_date": "2021-11-22",
    "publication_year": 2021,
    "authors": "Anuj Dawar; Gregory Wilsenach",
    "corresponding_authors": "",
    "abstract": "Fixed-point logic with rank (FPR) is an extension of fixed-point logic with counting (FPC) with operators for computing the rank of a matrix over a finit field. The expressive power of FPR properly extends that of FPC and is contained in P, but it is not known if that containment is proper. We give a circuit characterization for FPR in terms of families of symmetric circuits with rank gates, along the lines of that for FPC given by Anderson and Dawar in 2017. This requires the development of a broad framework of circuits in which the individual gates compute functions that are not symmetric (i.e., invariant under all permutations of their inputs). This framework also necessitates the development of novel techniques to prove the equivalence of circuits and logic. Both the framework and the techniques are of greater generality than the main result.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W3215989809",
    "type": "article"
  },
  {
    "title": "Universal Equivalence and Majority of Probabilistic Programs over Finite Fields",
    "doi": "https://doi.org/10.1145/3487063",
    "publication_date": "2021-11-22",
    "publication_year": 2021,
    "authors": "Gilles Barthe; Charlie Jacomme; Steve Kremer",
    "corresponding_authors": "",
    "abstract": "We study decidability problems for equivalence of probabilistic programs for a core probabilistic programming language over finite fields of fixed characteristic. The programming language supports uniform sampling, addition, multiplication, and conditionals and thus is sufficiently expressive to encode Boolean and arithmetic circuits. We consider two variants of equivalence: The first one considers an interpretation over the finite field F q , while the second one, which we call universal equivalence, verifies equivalence over all extensions F q k of F q . The universal variant typically arises in provable cryptography when one wishes to prove equivalence for any length of bitstrings, i.e., elements of F 2 k for any k . While the first problem is obviously decidable, we establish its exact complexity, which lies in the counting hierarchy. To show decidability and a doubly exponential upper bound of the universal variant, we rely on results from algorithmic number theory and the possibility to compare local zeta functions associated to given polynomials. We then devise a general way to draw links between the universal probabilistic problems and widely studied problems on linear recurrence sequences. Finally, we study several variants of the equivalence problem, including a problem we call majority, motivated by differential privacy. We also define and provide some insights about program indistinguishability, proving that it is decidable for programs always returning 0 or 1.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W3216210238",
    "type": "article"
  },
  {
    "title": "Instantiation Schemes for Nested Theories",
    "doi": "https://doi.org/10.1145/2480759.2480763",
    "publication_date": "2013-06-01",
    "publication_year": 2013,
    "authors": "Mnacho Echenim; Nicolas Peltier",
    "corresponding_authors": "",
    "abstract": "This article investigates under which conditions instantiation-based proof procedures can be combined in a nested way, in order to mechanically construct new instantiation procedures for richer theories. Interesting applications in the field of verification are emphasized, particularly for handling extensions of the theory of arrays.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2030508846",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1877714",
    "publication_date": "2011-01-01",
    "publication_year": 2011,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Infons are statements viewed as containers of information (rather then representations of truth values). The logic of infons turns out to be a conservative extension of logic known as constructive or intuitionistic. Distributed Knowledge Authorization ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4231001362",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1929954",
    "publication_date": "2011-05-01",
    "publication_year": 2011,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "We present an effective algorithm for the automatic construction of finite modal transition systems as abstractions of potentially infinite concurrent processes. Modal transition systems are recognized as valuable abstractions for model checking because ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4231044179",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1970398",
    "publication_date": "2011-07-01",
    "publication_year": 2011,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "We study a system, called NEL, which is the mixed commutative/noncommutative linear logic BV augmented with linear logic's exponentials. Equivalently, NEL is MELL augmented with the noncommutative self-dual connective seq. In this article, we show a ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4243443163",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2422085",
    "publication_date": "2013-02-01",
    "publication_year": 2013,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Constraint Handling Rules (CHR) is a declarative rule-based programming language that has cut out its niche over the course of the last 20 years. It generalizes concurrent constraint logic programming to multiple heads, thus closing the gap to multiset ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4246073502",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2480759",
    "publication_date": "2013-06-01",
    "publication_year": 2013,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "We introduce a new hierarchy of higher-order nested pushdown trees generalising Alur et al.’s concept of nested pushdown trees. Nested pushdown trees are useful representations of control flows in the verification of programs with recursive calls of ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4246824298",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2499937",
    "publication_date": "2013-08-01",
    "publication_year": 2013,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "In Constraint Programming, constraint propagation is a basic component of constraint satisfaction solvers. Here we study constraint propagation as a basic form of inference in the context of first-order logic (FO) and extensions with inductive ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4248712125",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2555591",
    "publication_date": "2013-11-01",
    "publication_year": 2013,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "We consider the enumeration problem of Monadic Second-Order (MSO) queries with first-order free variables over trees. In Bagan [2006] it was shown that this problem is in CONSTANT-DELAYlin. An enumeration problem belongs to CONSTANT-DELAYlin if for an ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4255604998",
    "type": "paratext"
  },
  {
    "title": "CSL 2008 special issue",
    "doi": "https://doi.org/10.1145/1805950.1805951",
    "publication_date": "2010-07-01",
    "publication_year": 2010,
    "authors": "Michael Kaminski; Simone Martini",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2005706472",
    "type": "article"
  },
  {
    "title": "Undecidability and intractability results concerning datalog programs and their persistency numbers",
    "doi": "https://doi.org/10.1145/1656242.1656247",
    "publication_date": "2010-01-01",
    "publication_year": 2010,
    "authors": "Stavros S. Cosmadakis; Eugénie Foustoucos; Anastasios Sidiropoulos",
    "corresponding_authors": "",
    "abstract": "The relation between Datalog programs and homomorphism problems, and, between Datalog programs and bounded treewidth structures has been recognized for some time and given much attention recently. Additionally, the essential role of persistent variables (in program expansions) for solving several relevant problems has also started to be observed. In Afrati et al. [2005] the general notion of program persistencies was refined into four notions (two syntactical ones and two semantical ones) and the interrelationship between these four persistency numbers was studied. In the present article (1) we prove undecidability results concerning the semantical notions of persistency number--modulo equivalence, of persistency number and of characteristic integer, (2) we exhibit new classes of programs for which boundedness is undecidable and (3) we prove intractabiltity results concerning the syntactical notions of weak persistency number and of weak characteristic integer.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2072786848",
    "type": "article"
  },
  {
    "title": "On the distributivity of LTL specifications",
    "doi": "https://doi.org/10.1145/1740582.1740588",
    "publication_date": "2010-05-01",
    "publication_year": 2010,
    "authors": "Marko Samer; Helmut Veith",
    "corresponding_authors": "",
    "abstract": "In this article, we investigate LTL specifications where γ[φ ∧ ψ] is equivalent to γ[φ] ∧ γ[ψ] independent of φ and ψ. Formulas γ with this property are called distributive queries because they naturally arise in Chan's seminal approach to temporal logic query solving [Chan 2000]. As recognizing distributive LTL queries is PSpace-complete, we consider distributive fragments of LTL defined by templates as in Buccafurri et al. [2001]. Our main result is a syntactic characterization of distributive LTL queries in terms of LTL templates: we construct a context-free template grammar LTLQ x which guarantees that all specifications obtained from LTLQ x are distributive, and all templates not obtained from LTLQ x have simple nondistributive instantiations.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2107594468",
    "type": "article"
  },
  {
    "title": "The Complexity of Proving the Discrete Jordan Curve Theorem",
    "doi": "https://doi.org/10.1145/2071368.2071377",
    "publication_date": "2012-01-01",
    "publication_year": 2012,
    "authors": "Phuong Nguyen; Stephen Cook",
    "corresponding_authors": "",
    "abstract": "The Jordan curve theorem (JCT) states that a simple closed curve divides the plane into exactly two connected regions. We formalize and prove the theorem in the context of grid graphs, under different input settings, in theories of bounded arithmetic that correspond to small complexity classes. The theory V 0 (2) (corresponding to AC 0 (2)) proves that any set of edges that form disjoint cycles divides the grid into at least two regions. The theory V 0 (corresponding to AC 0 ) proves that any sequence of edges that form a simple closed curve divides the grid into exactly two regions. As a consequence, the Hex tautologies and the st-connectivity tautologies have polynomial size AC 0 (2)- Frege -proofs, which improves results of Buss which only apply to the stronger proof system TC 0 - Frege .",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2171572930",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2362355",
    "publication_date": "2012-10-01",
    "publication_year": 2012,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "We develop a game semantics for process algebra with two interacting agents. The purpose of our semantics is to make manifest the role of knowledge and information flow in the interactions between agents and to control the information available to ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4234015779",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2159531",
    "publication_date": "2012-04-01",
    "publication_year": 2012,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Nominal logic is an extension of first-order logic with equality, name-binding, renaming via name-swapping and freshness of names. Contrarily to lambda-terms, in nominal terms, bindable names, called atoms, and instantiable variables are considered as ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4237633147",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1555746",
    "publication_date": "2009-08-01",
    "publication_year": 2009,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Bellantoni and Cook have given a function-algebra characterization of the polynomial-time computable functions via an unbounded recursion scheme which is called safe recursion. Inspired by their work, we characterize the exponential-time computable ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4238119547",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1805950",
    "publication_date": "2010-07-01",
    "publication_year": 2010,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4239038400",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1838552",
    "publication_date": "2010-10-01",
    "publication_year": 2010,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "The main challenge in using abstractions effectively is to construct a suitable abstraction for the system being verified. One approach that tries to address this problem is that of counterexample guided abstraction refinement (CEGAR), wherein one ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4239114662",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1740582",
    "publication_date": "2010-05-01",
    "publication_year": 2010,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "We introduce a new tractable temporal constraint language, which strictly contains the Ord-Horn language of Bürkert and Nebel and the class of AND/OR precedence constraints. The algorithm we present for this language decides whether a given set of ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4239899273",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1507244",
    "publication_date": "2009-04-01",
    "publication_year": 2009,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Timed automata [Alur and Dill 1994] comprise a popular model for describing real-time and embedded systems and reasoning formally about them. Efficient model-checking algorithms have been developed and implemented in tools such as Kronos [Daws et al. ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4240119146",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2071368",
    "publication_date": "2012-01-01",
    "publication_year": 2012,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "There is a growing interest in techniques for detecting whether a logic specification is satisfied too easily, or vacuously. For example, the specification “every request is eventually followed by an acknowledgment” is satisfied vacuously by a system ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4242574344",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1459010",
    "publication_date": "2009-01-01",
    "publication_year": 2009,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4249132629",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2287718",
    "publication_date": "2012-08-01",
    "publication_year": 2012,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "The article investigates the power of the dynamic complexity classes DynFO, DynQF, and DynPROP over string languages. The latter two classes contain problems that can be maintained using quantifier-free first-order updates, with and without auxiliary ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4250492278",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1614431",
    "publication_date": "2009-10-01",
    "publication_year": 2009,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Games on graphs with ω-regular objectives provide a model for the control and synthesis of reactive systems. Every ω-regular objective can be decomposed into a safety part and a liveness part. The liveness part ensures that something good happens “...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4256254201",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1462179",
    "publication_date": "2009-02-01",
    "publication_year": 2009,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Imposing linearity and ramification constraints allows to weaken higher-order (primitive) recursion in such a way that the class of representable functions equals the class of polynomial-time computable functions, as the works by Leivant, Hofmann, and ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4256691387",
    "type": "paratext"
  },
  {
    "title": "Recycling computed answers in rewrite systems for abduction",
    "doi": "https://doi.org/10.1145/1227839.1227841",
    "publication_date": "2007-04-01",
    "publication_year": 2007,
    "authors": "Fangzhen Lin; Jia-Huai You",
    "corresponding_authors": "",
    "abstract": "In rule-based systems, goal-oriented computations correspond naturally to the possible ways that an observation may be explained. In some applications, we need to compute explanations for a series of observations with the same domain. The question arises as to whether previously computed answers can be recycled. A “yes” answer could result in substantial savings of repeated computations. For systems based on classical logic, the answer is yes. For nonmonotonic systems, however, one tends to believe that the answer should be no , since recycling is a form of adding information. In this article, we show that computed answers can always be recycled, in a nontrivial way, for the class of rewrite procedures proposed earlier by the authors for logic programs with negation. We present some experimental results on an encoding of the logistics domain.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W1981144118",
    "type": "article"
  },
  {
    "title": "On the Parameterized Complexity of Finding Small Unsatisfiable Subsets of CNF Formulas and CSP Instances",
    "doi": "https://doi.org/10.1145/3091528",
    "publication_date": "2017-07-31",
    "publication_year": 2017,
    "authors": "Ronald de Haan; Iyad Kanj; Stefan Szeider",
    "corresponding_authors": "",
    "abstract": "In many practical settings it is useful to find a small unsatisfiable subset of a given unsatisfiable set of constraints. We study this problem from a parameterized complexity perspective, taking the size of the unsatisfiable subset as the natural parameter where the set of constraints is either (i) given a set of clauses, i.e., a formula in conjunctive normal Form (CNF), or (ii) as an instance of the Constraint Satisfaction Problem (CSP). In general, the problem is fixed-parameter in tractable. For an instance of the propositional satisfiability problem (SAT), it was known to be W[1]-complete. We establish A[2]-completeness for CSP instances, where A[2]-hardness prevails already for the Boolean case. With these fixed-parameter intractability results for the general case in mind, we consider various restricted classes of inputs and draw a detailed complexity landscape. It turns out that often Boolean CSP and CNF formulas behave similarly, but we also identify notable exceptions to this rule. The main part of this article is dedicated to classes of inputs that are induced by Boolean constraint languages that Schaefer [1978] identified as the maximal constraint languages with a tractable satisfiability problem. We show that for the CSP setting, the problem of finding small unsatisfiable subsets remains fixed-parameter intractable for all Schaefer languages for which the problem is non-trivial. We show that this is also the case for CNF formulas with the exception of the class of bijunctive (Krom) formulas, which allows for an identification of a small unsatisfiable subset in polynomial time. In addition, we consider various restricted classes of inputs with bounds on the maximum number of times that a variable occurs (the degree), bounds on the arity of constraints, and bounds on the domain size. For the case of CNF formulas, we show that restricting the degree is enough to obtain fixed-parameter tractability, whereas for the case of CSP instances, one needs to restrict the degree, the arity, and the domain size simultaneously to establish fixed-parameter tractability. Finally, we relate the problem of finding small unsatisfiable subsets of a set of constraints to the problem of identifying whether a given variable-value assignment is entailed or forbidden already by a small subset of constraints. Moreover, we use the connection between the two problems to establish similar parameterized complexity results also for the latter problem.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2747084554",
    "type": "article"
  },
  {
    "title": "Interval Temporal Logic for Visibly Pushdown Systems",
    "doi": "https://doi.org/10.1145/3583756",
    "publication_date": "2023-02-15",
    "publication_year": 2023,
    "authors": "Laura Bozzelli; Angelo Montanari; Adriano Peron",
    "corresponding_authors": "",
    "abstract": "In this article, we introduce and investigate an extension of Halpern and Shoham’s interval temporal logic HS for the specification and verification of branching-time context-free requirements of pushdown systems under a state-based semantics over Kripke structures enforcing visibility of the pushdown operations. The proposed logic, called nested BHS , supports branching-time both in the past and in the future and is able to express non-regular properties of linear and branching behaviours of procedural contexts in a natural way. It strictly subsumes well-known linear time context-free extensions of LTL such as CaRet [ 4 ] and NWTL [ 2 ]. The main result is the decidability of the visibly pushdown model-checking problem against nested BHS . The proof exploits a non-trivial automata-theoretic construction.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2997017553",
    "type": "article"
  },
  {
    "title": "On Monotonic Determinacy and Rewritability for Recursive Queries and Views",
    "doi": "https://doi.org/10.1145/3572836",
    "publication_date": "2023-01-05",
    "publication_year": 2023,
    "authors": "Michael Benedikt; Stanislav Kikot; Piotr Ostropolski-Nalewaja; Miguel Romero",
    "corresponding_authors": "",
    "abstract": "A query Q is monotonically determined over a set of views V if Q can be expressed as a monotonic function of the view image. In the case of relational algebra views and queries, monotonic determinacy coincides with rewritability as a union of conjunctive queries, and it is decidable in important special cases, such as for conjunctive query views and queries. We investigate the situation for views and queries in the recursive query language Datalog. We give both positive and negative results about the ability to decide monotonic determinacy, and also about the co-incidence of monotonic determinacy with Datalog rewritability.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3011376106",
    "type": "article"
  },
  {
    "title": "Exemplar Longest Common Subsequence",
    "doi": null,
    "publication_date": "2007-01-01",
    "publication_year": 2007,
    "authors": "Paola Bonizzoni; Gianluca Della Vedova; Riccardo Dondi; Guillaume Fertin; Rafaella Rizzi; Stéphane Vialette",
    "corresponding_authors": "",
    "abstract": "In this paper, we investigate the computational and approximation complexity of the Exemplar Longest Common Subsequence of a set of sequences (ELCS problem), a generalization of the Longest Common Subsequence problem, where the input sequences are over the union of two disjoint sets of symbols, a set of mandatory symbols and a set of optional symbols. We show that different versions of the problem are APX-hard even for instances with two sequences. Moreover, we show that the related problem of determining the existence of a feasible solution of the Exemplar Longest Common Subsequence of two sequences is NP-hard. On the positive side, we first present an efficient algorithm for the ELCS problem over instances of two sequences where each mandatory symbol can appear in total at most three times in the sequences. Furthermore, we present two fixed parameter algorithms for the ELCS problem over instances of two sequences where the parameter is the number of mandatory symbols.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3020057378",
    "type": "article"
  },
  {
    "title": "Parameterized Complexity of Logic-based Argumentation in Schaefer’s Framework",
    "doi": "https://doi.org/10.1145/3582499",
    "publication_date": "2023-01-31",
    "publication_year": 2023,
    "authors": "Yasir Mahmood; Arne Meier; Johannes Schmidt",
    "corresponding_authors": "",
    "abstract": "Argumentation is a well-established formalism dealing with conflicting information by generating and comparing arguments. It has been playing a major role in AI for decades. In logic-based argumentation, we explore the internal structure of an argument. Informally, a set of formulas is the support for a given claim if it is consistent, subset-minimal, and implies the claim. In such a case, the pair of the support and the claim together is called an argument. In this article, we study the propositional variants of the following three computational tasks studied in argumentation: ARG (exists a support for a given claim with respect to a given set of formulas), ARG-Check (is a given set a support for a given claim), and ARG-Rel (similarly as ARG plus requiring an additionally given formula to be contained in the support). ARG-Check is complete for the complexity class DP, and the other two problems are known to be complete for the second level of the polynomial hierarchy (Creignou et al. 2014 and Parson et al., 2003) and, accordingly, are highly intractable. Analyzing the reason for this intractability, we perform a two-dimensional classification: First, we consider all possible propositional fragments of the problem within Schaefer’s framework (STOC 1978) and then study different parameterizations for each of the fragments. We identify a list of reasonable structural parameters (size of the claim, support, knowledge base) that are connected to the aforementioned decision problems. Eventually, we thoroughly draw a fine border of parameterized intractability for each of the problems showing where the problems are fixed-parameter tractable and when this exactly stops. Surprisingly, several cases are of very high intractability (para-NP and beyond).",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3131365428",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1297658",
    "publication_date": "2007-12-01",
    "publication_year": 2007,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "This work exploits and extends the game-based framework of CTL model checking for counterexample and incremental abstraction-refinement. We define a game-based CTL model checking for abstract models over the 3-valued semantics, which can be used for ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4231129217",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1182613",
    "publication_date": "2007-01-01",
    "publication_year": 2007,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "This article introduces a logical system, called BV, which extends multiplicative linear logic by a noncommutative self-dual logical operator. This extension is particularly challenging for the sequent calculus, and so far, it is not achieved therein. ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4231693170",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1276920",
    "publication_date": "2007-08-01",
    "publication_year": 2007,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "In this paper we present a translation principle, called the axiomatic translation, for reducing propositional modal logics with background theories, including triangular properties such as transitivity, Euclideanness and functionality, to decidable ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4236790624",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1352582",
    "publication_date": "2008-06-01",
    "publication_year": 2008,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Lists, multisets, and sets are well-known data structures whose usefulness is widely recognized in various areas of computer science. They have been analyzed from an axiomatic point of view with a parametric approach in Dovier et al. [1998], where the ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4237418062",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1380572",
    "publication_date": "2008-08-01",
    "publication_year": 2008,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "We show that the insecurity problem for protocols with modular exponentiation and arbitrary products allowed in exponents is NP-complete. This result is based on a protocol and intruder model which is powerful enough to uncover known attacks on the ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4239083120",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3091105",
    "publication_date": "2017-06-23",
    "publication_year": 2017,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "This article concerns automated generation and processing of erotetic search scenarios (ESSs). ESSs are formal constructs characterized in Inferential Erotetic Logic that enable finding possible answers to a posed question by decomposing it into ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4239595066",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1342991",
    "publication_date": "2008-03-01",
    "publication_year": 2008,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "We define a general notion of a fragment within higher-order type theory; a procedure for constraint satisfiability in combined fragments is outlined, following Nelson-Oppen schema. The procedure is in general only sound, but it becomes terminating and ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4239963500",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3143777",
    "publication_date": "2017-12-19",
    "publication_year": 2017,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "We present an algorithm to optimally compress a finite set of terms using a vectorial totally rigid acyclic tree grammar. This class of grammars has a tight connection to proof theory, and the grammar compression problem considered in this article has ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4241847831",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3041822",
    "publication_date": "2017-04-13",
    "publication_year": 2017,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "We apply the concept of formula treewidth and pathwidth to computation tree logic, linear temporal logic, and the full branching time logic. Several representations of formulas as graphlike structures are discussed, and corresponding notions of ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4248528737",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3130378",
    "publication_date": "2017-08-21",
    "publication_year": 2017,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Consider a universal oracle Turing machine that prints a finite or an infinite binary sequence, based on the answers to the binary queries that it makes during the computation. We study the probability that this output is infinite and computable when ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4248753309",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1227839",
    "publication_date": "2007-04-01",
    "publication_year": 2007,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4254608274",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1243996",
    "publication_date": "2007-07-01",
    "publication_year": 2007,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4254810950",
    "type": "paratext"
  },
  {
    "title": "Circular (Yet Sound) Proofs in Propositional Logic",
    "doi": "https://doi.org/10.1145/3579997",
    "publication_date": "2023-01-30",
    "publication_year": 2023,
    "authors": "Albert Atserias; Massimo Lauria",
    "corresponding_authors": "",
    "abstract": "Proofs in propositional logic are typically presented as trees of derived formulas or, alternatively, as directed acyclic graphs of derived formulas. This distinction between tree-like vs. dag-like structure is particularly relevant when making quantitative considerations regarding, for example, proof size. Here we analyze a more general type of structural restriction for proofs in rule-based proof systems. In this definition, proofs are directed graphs of derived formulas in which cycles are allowed as long as every formula is derived at least as many times as it is required as a premise. We call such proofs \"circular\". We show that, for all sets of standard inference rules with single or multiple conclusions, circular proofs are sound. We start the study of the proof complexity of circular proofs at Circular Resolution, the circular version of Resolution. We immediately see that Circular Resolution is stronger than Dag-like Resolution since, as we show, the propositional encoding of the pigeonhole principle has circular Resolution proofs of polynomial size. Furthermore, for derivations of clauses from clauses, we show that Circular Resolution is, surprisingly, equivalent to Sherali-Adams, a proof system for reasoning through polynomial inequalities that has linear programming at its base. As corollaries we get: 1) polynomial-time (LP-based) algorithms that find Circular Resolution proofs of constant width, 2) examples that separate Circular from Dag-like Resolution, such as the pigeonhole principle and its variants, and 3) exponentially hard cases for Circular Resolution. Contrary to the case of Circular Resolution, for Frege we show that circular proofs can be converted into tree-like proofs with at most polynomial overhead.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4318477445",
    "type": "article"
  },
  {
    "title": "Comparing the Expressiveness of the π-calculus and CCS",
    "doi": "https://doi.org/10.1145/3611013",
    "publication_date": "2023-09-14",
    "publication_year": 2023,
    "authors": "Rob van Glabbeek",
    "corresponding_authors": "Rob van Glabbeek",
    "abstract": "This paper shows that the π-calculus with implicit matching is no more expressive than CCS γ , a variant of CCS in which the result of a synchronisation of two actions is itself an action subject to relabelling or restriction, rather than the silent action τ. This is done by exhibiting a compositional translation from the π-calculus with implicit matching to CCS γ that is valid up to strong barbed bisimilarity. The full π-calculus can be similarly expressed in CCS γ enriched with the triggering operation of Meije . I also show that these results cannot be recreated with CCS in the rôle of CCS γ , not even up to reduction equivalence, and not even for the asynchronous π-calculus without restriction or replication. Finally, I observe that CCS cannot be encoded in the π-calculus.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4386746420",
    "type": "article"
  },
  {
    "title": "Perspective Games",
    "doi": "https://doi.org/10.1145/3627705",
    "publication_date": "2023-10-30",
    "publication_year": 2023,
    "authors": "Orna Kupferman; Gal Vardi",
    "corresponding_authors": "",
    "abstract": "We introduce and study perspective games , which model multi-agent systems in which agents can view only the parts of the system that they own. As in standard multi-player turn-based games, the vertices of the game graph are partitioned among the players. Starting from an initial vertex, the players jointly generate a computation, with each player deciding the successor vertex whenever the generated computation reaches a vertex she owns. A perspective strategy for a player depends only on the history of visits in her vertices. Thus, unlike observation-based models of partial visibility, where uncertainty is longitudinal – players partially observe all vertices in the history, uncertainty in the perspective model is transverse – players fully observe part of the vertices in the history. We consider deterministic and probabilistic perspective games, with structural (e.g., Büchi or parity) and behavioral (e.g., LTL formulas) winning conditions. For these settings, we study the theoretical properties of the game as well as the decidability and complexity of the problem of deciding whether a player has a winning perspective strategy, in terms of both the game graph and the objectives. We compare perspective strategies with memoryless ones, and study an extension of the temporal logic ATL ⋆ with path quantifiers that capture perspective and memoryless strategies.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4388104999",
    "type": "article"
  },
  {
    "title": "Products, Polynomials and Differential Equations in the Stream Calculus",
    "doi": "https://doi.org/10.1145/3632747",
    "publication_date": "2023-11-14",
    "publication_year": 2023,
    "authors": "Michele Boreale; Luisa Collodi; Daniele Gorla",
    "corresponding_authors": "",
    "abstract": "We study connections among polynomials, differential equations, and streams over a field 𝕂, in terms of algebra and coalgebra. We first introduce the class of (F,G) - products on streams, those where the stream derivative of a product can be expressed as a polynomial function of the streams and their derivatives. Our first result is that, for every (F,G) -product, there is a canonical way to construct a transition function on polynomials such that the resulting unique final coalgebra morphism from polynomials into streams is the (unique) commutative 𝕂-algebra homomorphism—and vice versa. This implies that one can algebraically reason on streams via their polynomial representation. We apply this result to obtain an algebraic-geometric decision algorithm for polynomial stream equivalence, for an underlying generic (F,G) -product. Finally, we extend this algorithm to solve a more general problem: finding all valid polynomial equalities that fit in a user specified polynomial template.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4388671839",
    "type": "article"
  },
  {
    "title": "On the Complexity of Model Checking Knowledge and Time",
    "doi": "https://doi.org/10.1145/3637212",
    "publication_date": "2023-12-13",
    "publication_year": 2023,
    "authors": "Laura Bozzelli; Bastien Maubert; Aniello Murano",
    "corresponding_authors": "",
    "abstract": "We establish the precise complexity of the model-checking problem for the main logics of knowledge and time. While this problem was known to be non-elementary for agents with perfect recall, with a number of exponentials that increases with the alternation of knowledge operators, the precise complexity of the problem when the maximum alternation is fixed has been an open problem for 20 years. We close it by establishing improved upper bounds for CTL * with knowledge and providing matching lower bounds that also apply for epistemic extensions of LTL and CTL . We also study the model-checking problem for these logics on systems satisfying the “no learning” property, introduced by Halpern and Vardi in their taxonomy of logics of knowledge and time, and we settle the complexity in almost all cases.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4389675173",
    "type": "article"
  },
  {
    "title": "LICS 2003 special issue",
    "doi": "https://doi.org/10.1145/1094622.1094624",
    "publication_date": "2005-10-01",
    "publication_year": 2005,
    "authors": "Phokion G. Kolaitis",
    "corresponding_authors": "Phokion G. Kolaitis",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2052132194",
    "type": "article"
  },
  {
    "title": "The Complexity of Minimal Inference Problem for Conservative Constraint Languages",
    "doi": "https://doi.org/10.1145/3301410",
    "publication_date": "2019-02-18",
    "publication_year": 2019,
    "authors": "Michał Wrona",
    "corresponding_authors": "Michał Wrona",
    "abstract": "We study the complexity of the inference problem for propositional circumscription (the minimal inference problem) over arbitrary finite domains. The problem is of fundamental importance in nonmonotonic logics and commonsense reasoning. The complexity of the problem for the two-element domain has been completely classified. In this article, we classify the complexity of the problem over all conservative languages. We consider a version of the problem parameterized by a set of relations (a constraint language), from which we are allowed to build a knowledge base, and where a linear order used to compare models is a part of an input. We show that in this setting the problem is either Π P 2 -complete, coNP-complete, or in P. The classification is based on a coNP-hardness proof for a new class of languages, an analysis of languages that do not express any member of the class, and a new general polynomial-time algorithm solving the minimal inference problem for a large class of languages.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2916261673",
    "type": "article"
  },
  {
    "title": "A Representation Theorem for Change through Composition of Activities",
    "doi": "https://doi.org/10.1145/3329121",
    "publication_date": "2019-07-26",
    "publication_year": 2019,
    "authors": "Bahar Aameri; Michael Grüninger",
    "corresponding_authors": "",
    "abstract": "The expanding use of information systems in industrial and commercial settings has increased the need for interoperation between software systems. In particular, many social, industrial, and business information systems require a common basis for a seamless exchange of complex process information. This is, however, inhibited, because different systems may use distinct terminologies or assume different meanings for the same terms. A common solution to this problem is to develop logical theories that act as an intermediate language between different parties. In this article, we characterize a class of activities that can act as intermediate languages between different parties in those cases. We show that for each domain with finite number of elements there exists a class of activities, we called canonical activities, such that all possible changes within the domain can be represented as a sequence of occurrences of those activities. We use an algebraic structure for representing change and characterizing canonical activities, which enables us to abstract away domain-dependent properties of processes and activities, and demonstrate general properties of formalisms required for semantic integration of dynamic information systems.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2966293955",
    "type": "article"
  },
  {
    "title": "Reason-maintenance Belief Logic with Uncertain Information",
    "doi": "https://doi.org/10.1145/3355608",
    "publication_date": "2019-09-19",
    "publication_year": 2019,
    "authors": "Tuan-Fang Fan; Churn‐Jung Liau",
    "corresponding_authors": "",
    "abstract": "In this article, we propose a logic for reasoning about belief based on fusion of uncertain information. The resultant reason-maintenance possibilistic belief logic can represent both implicit and explicit uncertain beliefs of an agent. While implicit beliefs stipulate what are believable, explicit beliefs can trace the process of belief formation by information fusion. To set up the formal framework, we start with developing a basic reason-maintenance belief logic, present its syntax and semantics, and investigate its axiomatization and properties. Then, we extend the basic logic to accommodate the possibilistic uncertainty of information and beliefs, provide a complete axiomatization of the extended logic, and show that it can address the reason-maintenance issue of partially inconsistent beliefs. We also demonstrate the applicability of our formalisms by using several examples in realistic scenarios.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2974780078",
    "type": "article"
  },
  {
    "title": "識別不能性に基づく計算完全記号攻撃者のための検証法【JST・京大機械翻訳】",
    "doi": null,
    "publication_date": "2019-01-01",
    "publication_year": 2019,
    "authors": "Bana Gergei; Chadha Rohit; Eeralla Ajay Kumar; Okada Mitsuhiro",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3158934356",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3347091",
    "publication_date": "2019-09-07",
    "publication_year": 2019,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "We consider probabilistic model checking for continuous-time Markov chains (CTMCs) induced from Stochastic Reaction Networks against a fragment of Continuous Stochastic Logic (CSL) extended with reward operators. Classical numerical algorithms for CSL ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4232022746",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3371152",
    "publication_date": "2019-12-20",
    "publication_year": 2019,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "We provide the first proof complexity results for QBF dependency calculi. By showing that the reflexive resolution path dependency scheme admits exponentially shorter Q-resolution proofs on a known family of instances, we answer a question first posed ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4232384942",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3313982",
    "publication_date": "2019-04-04",
    "publication_year": 2019,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "In this work, we explore the connections between (linear) nested sequent calculi and ordinary sequent calculi for normal and non-normal modal logics. By proposing local versions to ordinary sequent rules, we obtain linear nested sequent calculi for a ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4236579153",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1119439",
    "publication_date": "2006-01-01",
    "publication_year": 2006,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "This article studies an implementation methodology for partial and disjunctive stable models where partiality and disjunctions are unfolded from a logic program so that an implementation of stable models for normal (disjunction-free) programs can be ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4237184537",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3301291",
    "publication_date": "2019-02-05",
    "publication_year": 2019,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "We analyze how the standard reductions between constraint satisfaction problems affect their proof complexity. We show that, for the most studied propositional, algebraic, and semialgebraic proof systems, the classical constructions of pp-...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4242207046",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1183278",
    "publication_date": "2006-10-01",
    "publication_year": 2006,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "In this article we consider three different kinds of domain-dependent control knowledge (temporal, procedural and HTN-based) that are useful in planning. Our approach is declarative and relies on the language of logic programming with answer set ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4242599412",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1131313",
    "publication_date": "2006-04-01",
    "publication_year": 2006,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "We show that constant-depth Frege systems with counting axioms modulo m polynomially simulate Nullstellensatz refutations modulo m. Central to this is a new definition of reducibility from propositional formulas to systems of polynomials. Using our ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4242656229",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3293495",
    "publication_date": "2018-12-08",
    "publication_year": 2018,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Mmt is a framework for designing and implementing formal systems in a way that systematically abstracts from theoretical and practical aspects of their type of theoretical and logical foundations. Thus, definitions, theorems, and algorithms can be ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4243315604",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1149114",
    "publication_date": "2006-07-01",
    "publication_year": 2006,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "In logic program-based updates, contradictory information elimination, conflict resolution, and syntactic representation are three major issues that interfere with each other and significantly influence the update result. We observe that existing ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4245413378",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3176362",
    "publication_date": "2018-02-15",
    "publication_year": 2018,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "The ground-breaking paper “Short Proofs Are Narrow -- Resolution Made Simple” by Ben-Sasson and Wigderson (J. ACM 2001) introduces what is today arguably the main technique to obtain resolution lower bounds: to show a lower bound for the width of ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4246042094",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3185755",
    "publication_date": "2018-06-28",
    "publication_year": 2018,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Choiceless Polynomial Time (CPT) is one of the most promising candidates in the search for a logic capturing Ptime. The question whether there is a logic that expresses exactly the polynomial-time computable properties of finite structures, which has ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4247417387",
    "type": "paratext"
  },
  {
    "title": "Editorial",
    "doi": "https://doi.org/10.1145/1094622.1094623",
    "publication_date": "2005-10-01",
    "publication_year": 2005,
    "authors": "Krzysztof R. Apt",
    "corresponding_authors": "Krzysztof R. Apt",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4249256426",
    "type": "editorial"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3338853",
    "publication_date": "2019-07-16",
    "publication_year": 2019,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Analyticity, also known as the subformula property, typically guarantees decidability of derivability in propositional sequent calculi. To utilize this fact, two substantial gaps have to be addressed: (i) What makes a sequent calculus analytic? and (ii) ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4250147265",
    "type": "paratext"
  },
  {
    "title": "Defining functions on equivalence classes",
    "doi": "https://doi.org/10.1145/1166109.1166111",
    "publication_date": "2006-10-01",
    "publication_year": 2006,
    "authors": "Lawrence C. Paulson",
    "corresponding_authors": "Lawrence C. Paulson",
    "abstract": "A quotient construction defines an abstract type from a concrete type, using an equivalence relation to identify elements of the concrete type that are to be regarded as indistinguishable. The elements of a quotient type are equivalence classes: sets of equivalent concrete values. Simple techniques are presented for defining and reasoning about quotient constructions, based on a general lemma library concerning functions that operate on equivalence classes. The techniques are applied to a definition of the integers from the natural numbers, and then to the definition of a recursive datatype satisfying equational constraints.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4251197167",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3361969",
    "publication_date": "2019-10-04",
    "publication_year": 2019,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Security properties of cryptographic protocols are typically expressed as reachability or equivalence properties. Secrecy and authentication are examples of reachability properties, while privacy properties such as untraceability, vote secrecy, or ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4251805254",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3274693",
    "publication_date": "2018-09-18",
    "publication_year": 2018,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "We study the expressive power of fragments of inclusion logic under the so-called lax team semantics. The fragments are defined either by restricting the number of universal quantifiers, the number of inclusion atoms, or the arity of inclusion atoms. We ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4253604416",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1166109",
    "publication_date": "2006-10-01",
    "publication_year": 2006,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4254483488",
    "type": "paratext"
  },
  {
    "title": "Model-Checking on Ordered Structures",
    "doi": "https://doi.org/10.1145/3360011",
    "publication_date": "2020-03-02",
    "publication_year": 2020,
    "authors": "Kord Eickmeyer; Jan van den Heuvel; Ken‐ichi Kawarabayashi; Stephan Kreutzer; Patrice Ossona de Mendez; Michał Pilipczuk; Daniel A. Quiroz; Roman Rabinovich; Sebastian Siebertz",
    "corresponding_authors": "",
    "abstract": "We study the model-checking problem for first- and monadic second-order logic on finite relational structures. The problem of verifying whether a formula of these logics is true on a given structure is considered intractable in general, but it does become tractable on interesting classes of structures, such as on classes whose Gaifman graphs have bounded treewidth. In this paper we continue this line of research and study model-checking for first- and monadic second-order logic in the presence of an ordering on the input structure. We do so in two settings: the general ordered case, where the input structures are equipped with a fixed order or successor relation, and the order invariant case, where the formulas may resort to an ordering, but their truth must be independent of the particular choice of order. In the first setting we show very strong intractability results for most interesting classes of structures. In contrast, in the order invariant case we obtain tractability results for order-invariant monadic second-order formulas on the same classes of graphs as in the unordered case. For first-order logic, we obtain tractability of successor-invariant formulas on classes whose Gaifman graphs have bounded expansion. Furthermore, we show that model-checking for order-invariant first-order formulas is tractable on coloured posets of bounded width.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3009631975",
    "type": "article"
  },
  {
    "title": "Undecidable Cases of Model Checking Probabilistic Temporal-Epistemic Logic",
    "doi": "https://doi.org/10.1145/3409250",
    "publication_date": "2020-10-14",
    "publication_year": 2020,
    "authors": "Ron van der Meyden; Manas K. Patra",
    "corresponding_authors": "",
    "abstract": "We investigate the decidability of model checking logics of time, knowledge, and probability, with respect to two epistemic semantics: the clock and synchronous perfect recall semantics in partially observable discrete-time Markov chains. Decidability results are known for certain restricted logics with respect to these semantics, subject to a variety of restrictions that are either unexplained or involve a longstanding unsolved mathematical problem. We show that mild generalizations of the known decidable cases suffice to render the model checking problem definitively undecidable. In particular, for the synchronous perfect recall semantics, a generalization from temporal operators with finite reach to operators with infinite reach renders model checking undecidable. The case of the clock semantics is closely related to a monadic second-order logic of time and probability that is known to be decidable, except on a set of measure zero. We show that two distinct extensions of this logic make model checking undecidable. One of these involves polynomial combinations of probability terms, the other involves monadic second-order quantification into the scope of probability operators. These results explain some of the restrictions in previous work.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3096440824",
    "type": "article"
  },
  {
    "title": "Typal Heterogeneous Equality Types",
    "doi": "https://doi.org/10.1145/3379447",
    "publication_date": "2020-04-19",
    "publication_year": 2020,
    "authors": "Andrew M. Pitts",
    "corresponding_authors": "Andrew M. Pitts",
    "abstract": "The usual homogeneous form of equality type in Martin-L\\\"of Type Theory contains identifications between elements of the same type. By contrast, the heterogeneous form of equality contains identifications between elements of possibly different types. This paper introduces a simple set of axioms for such types. The axioms are equivalent to the combination of systematic elimination rules for both forms of equality, albeit with typal (also known as \"propositional\") computation properties, together with Streicher's Axiom K, or equivalently, the principle of uniqueness of identity proofs.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3121803535",
    "type": "article"
  },
  {
    "title": "How Good Is a Strategy in a Game with Nature?",
    "doi": "https://doi.org/10.1145/3377137",
    "publication_date": "2020-02-20",
    "publication_year": 2020,
    "authors": "Arnaud Carayol; Olivier Serre",
    "corresponding_authors": "",
    "abstract": "We consider games with two antagonistic players—Éloïse (modelling a program) and Abélard (modelling a Byzantine environment)—and a third, unpredictable and uncontrollable player, which we call Nature. Motivated by the fact that the usual probabilistic semantics very quickly leads to undecidability when considering either infinite game graphs or imperfect-information, we propose two alternative semantics that lead to decidability where the probabilistic one fails: one based on counting and one based on topology.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3123477732",
    "type": "article"
  },
  {
    "title": "Editorial: ACM Transactions on computational logic",
    "doi": null,
    "publication_date": "2001-01-01",
    "publication_year": 2001,
    "authors": "Krzysztof R. Apt; Antonis Kakas; Fereidoon Sadri",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W1590490896",
    "type": "editorial"
  },
  {
    "title": "LICS 2001 special issue",
    "doi": "https://doi.org/10.1145/772062.772063",
    "publication_date": "2003-07-01",
    "publication_year": 2003,
    "authors": "Erich Grädel; Joseph Y. Halpern; Radha Jaghadeesan; Adolfo Piperno",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2068417643",
    "type": "article"
  },
  {
    "title": "Editorial",
    "doi": "https://doi.org/10.1145/383779.383823",
    "publication_date": "2001-10-01",
    "publication_year": 2001,
    "authors": "Krzysztof R. Apt; Antonis Kakas; Fariba Sadri",
    "corresponding_authors": "",
    "abstract": "This special issue of the ACM Transactions on Computational Logic (TOCL) is dedicated to Robert A. Kowalski, or as he is better known, to Bob Kowalski, on the occasion of his 60th birthday. Throughout his distinguished research career Bob has been interested in various forms of logic-based reasoning from the computer science point of view. This novel view of logic has had an impact on a number of areas, including programming languages, databases, artificial intelligence, natural language processing, and more recently machine learning. In the late sixties and early seventies Bob contributed to the development of the theory of resolution by proposing a number of modifications to the original proposal of Alan Robinson. One of the notions that withstood the test of time is his and Hayes concept of semantic trees. This research eventually led him to the seminal 1974 paper Predicate Logic as a Programming Language which is at the roots of the logic programming paradigm. His early work with Maarten van Emden provided a direction for the subsequent research on procedural and declarative semantics of programming languages within the specific field of logic programming. In turn, his influential dictum \"Algorithm+Logic=Control\" has shaped our views on the essence of declarative programming within the logic programming framework and has had a large impact on the design of new control mechanisms for this approach to programming. His subsequent research revealed the rich potential of the logic programming paradigm. He showed how legal, metalevel, and commonsense reasoning can naturally be formalized by means of logic programs. His work with Marek Sergot on the event calculus had a long-standing impact on the research effort of representing temporal knowledge and formalizing commonsense reasoning. His research on verification of integrity constraints for database systems became highly relevant in deductive and temporal databases, while his work on abductive reasoning and argumentation was influential for mechanized legal and diagnostic reasoning. More recently, his work on multiagent systems has helped shape new approaches to building intelligent distributed systems. Several of these themes can be found in the collection of papers that constitute this special issue. All of these papers were solicited directly by the guest editors but, conforming to the high standards of TOCL, went through the usual rigorous refereeing process. We would like to thank the authors of the contributed papers for their willingness and interest in contributing to this issue. We also thank the referees for their precious time in providing helpful reviews of the submissions. And to Bob we extend our best wishes and hope he will agree with us that this special issue shows, at least partly, the long-term impact of his research.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4248834677",
    "type": "editorial"
  },
  {
    "title": "Book review [Review of: K.R. Apt (2000) Logic in Computer Science: modelling and reasoning about systems]",
    "doi": null,
    "publication_date": "2000-01-01",
    "publication_year": 2000,
    "authors": "Femke van Raamsdonk",
    "corresponding_authors": "Femke van Raamsdonk",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2732000377",
    "type": "article"
  },
  {
    "title": "Zero-One Laws for Existential First-Order Sentences of Bounded Quantifier Depth",
    "doi": "https://doi.org/10.1145/3489466",
    "publication_date": "2022-01-18",
    "publication_year": 2022,
    "authors": "Moumanti Podder; Maksim Zhukovskii",
    "corresponding_authors": "",
    "abstract": "For any fixed positive integer k , let α k denote the smallest α ∈ (0,1) such that the random graph sequence { G ( n, n -α )} n does not satisfy the zero-one law for the set ε k of all existential first-order sentences that are of quantifier depth at most k . This article finds upper and lower bounds on α k , showing that as k → ∞, we have α k = ( k - 2 - t ( k )) -1 for some function t ( k ) = Θ ( k -2 ). We also establish the precise value of α k when k = 4.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2959020644",
    "type": "article"
  },
  {
    "title": "Continuous One-counter Automata",
    "doi": "https://doi.org/10.1145/3558549",
    "publication_date": "2022-08-23",
    "publication_year": 2022,
    "authors": "Michael Blondin; Tim Leys; Filip Mazowiecki; Philip Offtermatt; Guillermo A. Pérez",
    "corresponding_authors": "",
    "abstract": "We study the reachability problem for continuous one-counter automata, COCA for short. In such automata, transitions are guarded by upper- and lower-bound tests against the counter value. Additionally, the counter updates associated with taking transitions can be (non-deterministically) scaled down by a nonzero factor between zero and one. Our three main results are as follows: we prove (1) that the reachability problem for COCA with global upper- and lower-bound tests is in NC 2 ; (2) that, in general, the problem is decidable in polynomial time; and (3) that it is NP-complete for COCA with parametric counter updates and bound tests.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3123946441",
    "type": "article"
  },
  {
    "title": "The Intersection of Algorithmically Random Closed Sets and Effective Dimension",
    "doi": "https://doi.org/10.1145/3545114",
    "publication_date": "2022-06-25",
    "publication_year": 2022,
    "authors": "Adam Case; Christopher P. Porter",
    "corresponding_authors": "",
    "abstract": "In this article, we study several aspects of the intersections of algorithmically random closed sets. First, we answer a question of Cenzer and Weber, showing that the operation of intersecting relatively random closed sets (random with respect to certain underlying measures induced by Bernoulli measures on the space of codes of closed sets), which preserves randomness, can be inverted: a random closed set of the appropriate type can be obtained as the intersection of two relatively random closed sets. We then extend the Cenzer/Weber analysis to the intersection of multiple random closed sets, identifying the Bernoulli measures with respect to which the intersection of relatively random closed sets can be non-empty. We lastly apply our analysis to provide a characterization of the effective Hausdorff dimension of sequences in terms of the degree of intersectability of random closed sets that contain them.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3135361590",
    "type": "article"
  },
  {
    "title": "Are Two Binary Operators Necessary to Obtain a Finite Axiomatisation of Parallel Composition?",
    "doi": "https://doi.org/10.1145/3529535",
    "publication_date": "2022-04-20",
    "publication_year": 2022,
    "authors": "Luca Aceto; Valentina Castiglioni; Wan Fokkink; Anna Ingólfsdóttir; Bas Luttik",
    "corresponding_authors": "",
    "abstract": "Bergstra and Klop have shown that bisimilarity has a finite equational axiomatisation over ACP/CCS extended with the binary left and communication merge operators. Moller proved that auxiliary operators are necessary to obtain a finite axiomatisation of bisimilarity over CCS, and Aceto et al. showed that this remains true when Hennessy’s merge is added to that language. These results raise the question of whether there is one auxiliary binary operator whose addition to CCS leads to a finite axiomatisation of bisimilarity. We contribute to answering this question in the simplified setting of the recursion-, relabelling-, and restriction-free fragment of CCS. We formulate three natural assumptions pertaining to the operational semantics of auxiliary operators and their relationship to parallel composition and prove that an auxiliary binary operator facilitating a finite axiomatisation of bisimilarity in the simplified setting cannot satisfy all three assumptions.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4224297410",
    "type": "article"
  },
  {
    "title": "On Composing Finite Forests with Modal Logics",
    "doi": "https://doi.org/10.1145/3569954",
    "publication_date": "2022-12-29",
    "publication_year": 2022,
    "authors": "Bartosz Bednarczyk; Stéphane Demri; Raul Fervari; Alessio Mansutti",
    "corresponding_authors": "",
    "abstract": "We study the expressivity and complexity of two modal logics interpreted on finite forests and equipped with standard modalities to reason on submodels. The logic \\(\\mathsf {ML} ({\\color{black}{{\\vert\\!\\!\\vert\\!\\vert}}})\\) extends the modal logic K with the composition operator \\({\\color{black}{{\\vert\\!\\!\\vert\\!\\vert}}}\\) from ambient logic whereas \\(\\mathsf {ML} (\\mathbin {\\ast })\\) features the separating conjunction \\(\\mathbin {\\ast }\\) from separation logic. Both operators are second-order in nature. We show that \\(\\mathsf {ML} ({\\color{black}{{\\vert\\!\\!\\vert\\!\\vert}}})\\) is as expressive as the graded modal logic \\(\\mathsf {GML}\\) (on trees) whereas \\(\\mathsf {ML} (\\mathbin {\\ast })\\) is strictly less expressive than \\(\\mathsf {GML}\\) . Moreover, we establish that the satisfiability problem is Tower -complete for \\(\\mathsf {ML} (\\mathbin {\\ast })\\) , whereas it is (only) AExp Pol -complete for \\(\\mathsf {ML} ({\\color{black}{{\\vert\\!\\!\\vert\\!\\vert}}})\\) , a result that is surprising given their relative expressivity. As by-products, we solve open problems related to sister logics such as static ambient logic and modal separation logic.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4313254506",
    "type": "article"
  },
  {
    "title": "Semantic Analysis of a Linear Temporal Extension of Quantum Logic and Its Dynamic Aspect",
    "doi": "https://doi.org/10.1145/3576926",
    "publication_date": "2022-12-16",
    "publication_year": 2022,
    "authors": "Tsubasa Takagi",
    "corresponding_authors": "Tsubasa Takagi",
    "abstract": "Although various dynamic or temporal logics have been proposed to verify quantum protocols and systems, these two viewpoints have not been studied comprehensively enough. We propose Linear Temporal Quantum Logic (LTQL), a linear temporal extension of quantum logic with a quantum implication, and extend it to Dynamic Linear Temporal Quantum Logic (DLTQL). This logic has temporal operators to express transitions by unitary operators (quantum gates) and dynamic ones to express those by projections (projective measurement). We then prove some logical properties of the relationship between these two transitions expressed by LTQL and DLTQL. A drawback in applying LTQL to the verification of quantum protocols is that these logics cannot express the future operator in linear temporal logic. We propose a way to mitigate this drawback by using a translation from (D)LTQL to Linear Temporal Modal Logic (LTML) and a simulation. This translation reduces the satisfiability problem of (D)LTQL formulas to that of LTML with the classical semantics over quantum states.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4313476582",
    "type": "article"
  },
  {
    "title": "Editorial",
    "doi": "https://doi.org/10.1145/507382.507383",
    "publication_date": "2002-07-01",
    "publication_year": 2002,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "This special issue of ACM Transactions on Computational Logic is devoted to papers first presented at LICS 2000, the 15th Annual IEEE Symposium on Logic in Computer Science, held June 26--29, 2000, in Santa Barbara, California.In consultation with the LICS 2000 program committee, the guest editors selected five papers presented at the conference and invited their authors to submit full versions of the papers to this special issue. All submissions were refereed according to the usual standards of ACM Transactions on Computational Logic . They cover a range of lively areas within Logic in Computer Science, reflecting well the quality of the conference. We are grateful to the authors of the papers for their excellent contributions, and to all members of the program committee and reviewers for their efforts.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4298875133",
    "type": "editorial"
  },
  {
    "title": "Decidability of a Sound Set of Inference Rules for Computational Indistinguishability",
    "doi": "https://doi.org/10.1145/3423169",
    "publication_date": "2021-01-19",
    "publication_year": 2021,
    "authors": "Adrien Koutsos",
    "corresponding_authors": "Adrien Koutsos",
    "abstract": "Computational indistinguishability is a key property in cryptography and verification of security protocols. Current tools for proving it rely on cryptographic game transformations. We follow Bana and Comon’s approach [7, 8], axiomatizing what an adversary cannot distinguish. We prove the decidability of a set of first-order axioms that are computationally sound, though incomplete, for protocols with a bounded number of sessions whose security is based on an &lt;small&gt;IND-CCA 2 &lt;/small&gt; encryption scheme. Alternatively, our result can be viewed as the decidability of a family of cryptographic game transformations. Our proof relies on term rewriting and automated deduction techniques.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3122697410",
    "type": "article"
  },
  {
    "title": "α β-Relations and the Actual Meaning of α-Renaming",
    "doi": "https://doi.org/10.1145/3426471",
    "publication_date": "2021-01-15",
    "publication_year": 2021,
    "authors": "Michele Basaldella",
    "corresponding_authors": "Michele Basaldella",
    "abstract": "In this work we provide an alternative, and equivalent, formulation of the concept of λ-theory without introducing the notion of substitution and the sets of all, free and bound variables occurring in a term. We call α β-relations our alternative versions of λ-theories. We also clarify the actual role of α-renaming in the lambda calculus: it expresses a property of extensionality for a certain class of terms. To motivate the necessity of α-renaming, we construct an unusual denotational model of the lambda calculus that validates all structural and beta conditions but not α-renaming. The article also has a survey character.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3124530788",
    "type": "article"
  },
  {
    "title": "Reasoning about Petri Nets: A Calculus Based on Resolution and Dynamic Logic",
    "doi": "https://doi.org/10.1145/3441655",
    "publication_date": "2021-04-30",
    "publication_year": 2021,
    "authors": "Bruno Lopes; Cláudia Nalon; Edward Hermann Hæusler",
    "corresponding_authors": "",
    "abstract": "Petri Nets are a widely used formalism to deal with concurrent systems. Dynamic Logics (DLs) are a family of modal logics where each modality corresponds to a program. Petri-PDL is a logical language that combines these two approaches: it is a dynamic logic where programs are replaced by Petri Nets. In this work we present a clausal resolution-based calculus for Petri-PDL. Given a Petri-PDL formula, we show how to obtain its translation into a normal form to which a set of resolution-based inference rules are applied. We show that the resulting calculus is sound, complete, and terminating. Some examples of the application of the method are also given.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3160968851",
    "type": "article"
  },
  {
    "title": "Expressiveness and Nash Equilibrium in Iterated Boolean Games",
    "doi": "https://doi.org/10.1145/3439900",
    "publication_date": "2021-04-30",
    "publication_year": 2021,
    "authors": "Julián Gutiérrez; Paul Harrenstein; Giuseppe Perelli; Michael Wooldridge",
    "corresponding_authors": "",
    "abstract": "We define and investigate a novel notion of expressiveness for temporal logics that is based on game theoretic equilibria of multi-agent systems. We use iterated Boolean games as our abstract model of multi-agent systems [Gutierrez et al. 2013, 2015a]. In such a game, each agent <?TeX $i$?> has a goal <?TeX $\\gamma _i$?> , represented using (a fragment of) Linear Temporal Logic ( <?TeX $\\mathrm{LTL}$?> ) . The goal <?TeX $\\gamma _i$?> captures agent <?TeX $i$?> ’s preferences, in the sense that the models of <?TeX $\\gamma _i$?> represent system behaviours that would satisfy <?TeX $i$?> . Each player controls a subset of Boolean variables <?TeX $\\Phi _i$?> , and at each round in the game, player <?TeX $i$?> is at liberty to choose values for variables <?TeX $\\Phi _i$?> in any way that she sees fit. Play continues for an infinite sequence of rounds, and so as players act they collectively trace out a model for <?TeX $\\mathrm{LTL}$?> , which for every player will either satisfy or fail to satisfy their goal. Players are assumed to act strategically, taking into account the goals of other players, in an attempt to bring about computations satisfying their goal. In this setting, we apply the standard game-theoretic concept of (pure) Nash equilibria. The (possibly empty) set of Nash equilibria of an iterated Boolean game can be understood as inducing a set of computations, each computation representing one way the system could evolve if players chose strategies that together constitute a Nash equilibrium. Such a set of equilibrium computations expresses a temporal property—which may or may not be expressible within a particular <?TeX $\\mathrm{LTL}$?> fragment. The new notion of expressiveness that we formally define and investigate is then as follows: What temporal properties are characterised by the Nash equilibria of games in which agent goals are expressed in specific fragments of <?TeX $\\mathrm{LTL}$?> ? We formally define and investigate this notion of expressiveness for a range of <?TeX $\\mathrm{LTL}$?> fragments. For example, a very natural question is the following: Suppose we have an iterated Boolean game in which every goal is represented using a particular fragment <?TeX $L$?> of <?TeX $\\mathrm{LTL}$?> : is it then always the case that the equilibria of the game can be characterised within <?TeX $L$?> ? We show that this is not true in general.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3166627015",
    "type": "article"
  },
  {
    "title": "Kripke Semantics for Intersection Formulas",
    "doi": "https://doi.org/10.1145/3453481",
    "publication_date": "2021-07-22",
    "publication_year": 2021,
    "authors": "Andrej Dudenhefner; Paweł Urzyczyn",
    "corresponding_authors": "",
    "abstract": "We propose a notion of the Kripke-style model for intersection logic. Using a game interpretation, we prove soundness and completeness of the proposed semantics. In other words, a formula is provable (a type is inhabited) if and only if it is forced in every model. As a by-product, we obtain another proof of normalization for the Barendregt–Coppo–Dezani intersection type assignment system.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3184909403",
    "type": "article"
  },
  {
    "title": "Lower Bounds on OBDD Proofs with Several Orders",
    "doi": "https://doi.org/10.1145/3468855",
    "publication_date": "2021-09-08",
    "publication_year": 2021,
    "authors": "Sam Buss; Dmitry Itsykson; Alexander Knop; Artur Riazanov; Dmitry Sokolov",
    "corresponding_authors": "",
    "abstract": "This article is motivated by seeking lower bounds on OBDD(∧, w, r) refutations, namely, OBDD refutations that allow weakening and arbitrary reorderings. We first work with 1 - NBP ∧ refutations based on read-once nondeterministic branching programs. These generalize OBDD(∧, r) refutations. There are polynomial size 1 - NBP(∧) refutations of the pigeonhole principle, hence 1-NBP(∧) is strictly stronger than OBDD}(∧, r). There are also formulas that have polynomial size tree-like resolution refutations but require exponential size 1-NBP(∧) refutations. As a corollary, OBDD}(∧, r) does not simulate tree-like resolution, answering a previously open question. The system 1-NBP(∧, ∃) uses projection inferences instead of weakening. 1-NBP(∧, ∃ k is the system restricted to projection on at most k distinct variables. We construct explicit constant degree graphs G n on n vertices and an ε &gt; 0, such that 1-NBP(∧, ∃ ε n ) refutations of the Tseitin formula for G n require exponential size. Second, we study the proof system OBDD}(∧, w, r ℓ ), which allows ℓ different variable orders in a refutation. We prove an exponential lower bound on the complexity of tree-like OBDD(∧, w, r ℓ ) refutations for ℓ = ε log n , where n is the number of variables and ε &gt; 0 is a constant. The lower bound is based on multiparty communication complexity.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3196881647",
    "type": "article"
  }
]
[
  {
    "title": "Principled design of the modern Web architecture",
    "doi": "https://doi.org/10.1145/514183.514185",
    "publication_date": "2002-05-01",
    "publication_year": 2002,
    "authors": "Roy T. Fielding; Richard N. Taylor",
    "corresponding_authors": "",
    "abstract": "The World Wide Web has succeeded in large part because its software architecture has been designed to meet the needs of an Internet-scale distributed hypermedia application. The modern Web architecture emphasizes scalability of component interactions, generality of interfaces, independent deployment of components, and intermediary components to reduce interaction latency, enforce security, and encapsulate legacy systems. In this article we introduce the Representational State Transfer (REST) architectural style, developed as an abstract model of the Web architecture and used to guide our redesign and definition of the Hypertext Transfer Protocol and Uniform Resource Identifiers. We describe the software engineering principles guiding REST and the interaction constraints chosen to retain those principles, contrasting them to the constraints of other architectural styles. We then compare the abstract model to the currently deployed Web architecture in order to elicit mismatches between the existing protocols and the applications they are intended to support.",
    "cited_by_count": 1661,
    "openalex_id": "https://openalex.org/W2001291669",
    "type": "article"
  },
  {
    "title": "Web mining for web personalization",
    "doi": "https://doi.org/10.1145/643477.643478",
    "publication_date": "2003-02-01",
    "publication_year": 2003,
    "authors": "Magdalini Eirinaki; Michalis Vazirgiannis",
    "corresponding_authors": "",
    "abstract": "Web personalization is the process of customizing a Web site to the needs of specific users, taking advantage of the knowledge acquired from the analysis of the user's navigational behavior (usage data) in correlation with other information collected in the Web context, namely, structure, content, and user profile data. Due to the explosive growth of the Web, the domain of Web personalization has gained great momentum both in the research and commercial areas. In this article we present a survey of the use of Web mining for Web personalization. More specifically, we introduce the modules that comprise a Web personalization system, emphasizing the Web usage mining module. A review of the most common methods that are used as well as technical issues that occur is given, along with a brief overview of the most popular tools and applications available from software vendors. Moreover, the most important research initiatives in the Web usage mining and personalization areas are presented.",
    "cited_by_count": 863,
    "openalex_id": "https://openalex.org/W2012451152",
    "type": "article"
  },
  {
    "title": "Searching the Web",
    "doi": "https://doi.org/10.1145/383034.383035",
    "publication_date": "2001-08-01",
    "publication_year": 2001,
    "authors": "Arvind Arasu; Junghoo Cho; Héctor García-Molina; Andreas Paepcke; Sriram Raghavan",
    "corresponding_authors": "",
    "abstract": "We offer an overview of current Web search engine design. After introducing a generic search engine architecture, we examine each engine component in turn. We cover crawling, local Web page storage, indexing, and the use of link analysis for boosting search performance. The most common design and implementation techniques for each of these components are presented. For this presentation we draw from the literature and from our own experimental search engine testbed. Emphasis is on introducing the fundamental concepts and the results of several performance analyses we conducted to compare different designs.",
    "cited_by_count": 531,
    "openalex_id": "https://openalex.org/W2029500199",
    "type": "article"
  },
  {
    "title": "Inside PageRank",
    "doi": "https://doi.org/10.1145/1052934.1052938",
    "publication_date": "2005-02-01",
    "publication_year": 2005,
    "authors": "Monica Bianchini; Marco Gori; Franco Scarselli",
    "corresponding_authors": "",
    "abstract": "Although the interest of a Web page is strictly related to its content and to the subjective readers' cultural background, a measure of the page authority can be provided that only depends on the topological structure of the Web. PageRank is a noticeable way to attach a score to Web pages on the basis of the Web connectivity. In this article, we look inside PageRank to disclose its fundamental properties concerning stability, complexity of computational scheme, and critical role of parameters involved in the computation. Moreover, we introduce a circuit analysis that allows us to understand the distribution of the page score, the way different Web communities interact each other, the role of dangling pages (pages with no outlinks), and the secrets for promotion of Web pages.",
    "cited_by_count": 518,
    "openalex_id": "https://openalex.org/W2293888960",
    "type": "article"
  },
  {
    "title": "Toward trustworthy recommender systems",
    "doi": "https://doi.org/10.1145/1278366.1278372",
    "publication_date": "2007-10-01",
    "publication_year": 2007,
    "authors": "Bamshad Mobasher; Robin Burke; Runa Bhaumik; Chad Williams",
    "corresponding_authors": "",
    "abstract": "Publicly accessible adaptive systems such as collaborative recommender systems present a security problem. Attackers, who cannot be readily distinguished from ordinary users, may inject biased profiles in an attempt to force a system to “adapt” in a manner advantageous to them. Such attacks may lead to a degradation of user trust in the objectivity and accuracy of the system. Recent research has begun to examine the vulnerabilities and robustness of different collaborative recommendation techniques in the face of “profile injection” attacks. In this article, we outline some of the major issues in building secure recommender systems, concentrating in particular on the modeling of attacks and their impact on various recommendation algorithms. We introduce several new attack models and perform extensive simulation-based evaluations to show which attacks are most successful and practical against common recommendation techniques. Our study shows that both user-based and item-based algorithms are highly vulnerable to specific attack models, but that hybrid algorithms may provide a higher degree of robustness. Using our formal characterization of attack models, we also introduce a novel classification-based approach for detecting attack profiles and evaluate its effectiveness in neutralizing attacks.",
    "cited_by_count": 455,
    "openalex_id": "https://openalex.org/W1989279326",
    "type": "article"
  },
  {
    "title": "XRel : A path-based approach to storage and retrieval of XML documents using relational databases",
    "doi": null,
    "publication_date": "2001-01-01",
    "publication_year": 2001,
    "authors": "Masatoshi Yoshikawa; Toshiyuki Amagasa; Takeyuki Shimura; Shunsuke Uemura",
    "corresponding_authors": "",
    "abstract": "This article describes XRel, a novel approach for storage and retrieval of XML documents using relational databases. In this approach, an XML document is decomposed into nodes on the basis of its tree structure and stored in relational tables according to the node type, with path information from the root to each node. XRel enables us to store XML documents using a fixed relational schema without any information about DTDs and also to utilize indices such as the B 1 -tree and the R-tree supported by database management systems. Thus, XRel does not need any extension of relational databases for storing XML documents. For processing XML queries, we present an algorithm for translating a core subset of XPath expressions into SQL queries. Finally, we demonstrate the effectiveness of this approach through several experiments using actual XML documents.",
    "cited_by_count": 451,
    "openalex_id": "https://openalex.org/W2139242647",
    "type": "article"
  },
  {
    "title": "Inferring binary trust relationships in Web-based social networks",
    "doi": "https://doi.org/10.1145/1183463.1183470",
    "publication_date": "2006-11-01",
    "publication_year": 2006,
    "authors": "Jennifer Golbeck; James Hendler",
    "corresponding_authors": "",
    "abstract": "The growth of Web-based social networking and the properties of those networks have created great potential for producing intelligent software that integrates a user's social network and preferences. Our research looks particularly at assigning trust in Web-based social networks and investigates how trust information can be mined and integrated into applications. This article introduces a definition of trust suitable for use in Web-based social networks with a discussion of the properties that will influence its use in computation. We then present two algorithms for inferring trust relationships between individuals that are not directly connected in the network. Both algorithms are shown theoretically and through simulation to produce calculated trust values that are highly accurate.. We then present TrustMail, a prototype email client that uses variations on these algorithms to score email messages in the user's inbox based on the user's participation and ratings in a trust network.",
    "cited_by_count": 442,
    "openalex_id": "https://openalex.org/W1985109665",
    "type": "article"
  },
  {
    "title": "Stance and Sentiment in Tweets",
    "doi": "https://doi.org/10.1145/3003433",
    "publication_date": "2017-06-12",
    "publication_year": 2017,
    "authors": "Saif M. Mohammad; Parinaz Sobhani; Svetlana Kiritchenko",
    "corresponding_authors": "",
    "abstract": "We can often detect from a person’s utterances whether he or she is in favor of or against a given target entity—one’s stance toward the target. However, a person may express the same stance toward a target by using negative or positive language. Here for the first time we present a dataset of tweet–target pairs annotated for both stance and sentiment. The targets may or may not be referred to in the tweets, and they may or may not be the target of opinion in the tweets. Partitions of this dataset were used as training and test sets in a SemEval-2016 shared task competition. We propose a simple stance detection system that outperforms submissions from all 19 teams that participated in the shared task. Additionally, access to both stance and sentiment annotations allows us to explore several research questions. We show that although knowing the sentiment expressed by a tweet is beneficial for stance classification, it alone is not sufficient. Finally, we use additional unlabeled data through distant supervision techniques and word embeddings to further improve stance classification.",
    "cited_by_count": 434,
    "openalex_id": "https://openalex.org/W2347127863",
    "type": "article"
  },
  {
    "title": "Taxonomy of XML schema languages using formal language theory",
    "doi": "https://doi.org/10.1145/1111627.1111631",
    "publication_date": "2005-11-01",
    "publication_year": 2005,
    "authors": "Makoto Murata; Dongwon Lee; Murali Mani; Kohsuke Kawaguchi",
    "corresponding_authors": "",
    "abstract": "On the basis of regular tree grammars, we present a formal framework for XML schema languages. This framework helps to describe, compare, and implement such schema languages in a rigorous manner. Our main results are as follows: (1) a simple framework to study three classes of tree languages (local, single-type, and regular); (2) classification and comparison of schema languages (DTD, W3C XML Schema, and RELAX NG) based on these classes; (3) efficient document validation algorithms for these classes; and (4) other grammatical concepts and advanced validation algorithms relevant to an XML model (e.g., binarization, derivative-based validation).",
    "cited_by_count": 413,
    "openalex_id": "https://openalex.org/W2105748890",
    "type": "article"
  },
  {
    "title": "Selective Markov models for predicting Web page accesses",
    "doi": "https://doi.org/10.1145/990301.990304",
    "publication_date": "2004-05-01",
    "publication_year": 2004,
    "authors": "Mukund Deshpande; George Karypis",
    "corresponding_authors": "",
    "abstract": "The problem of predicting a user's behavior on a Web site has gained importance due to the rapid growth of the World Wide Web and the need to personalize and influence a user's browsing experience. Markov models and their variations have been found to be well suited for addressing this problem. Of the different variations of Markov models, it is generally found that higher-order Markov models display high predictive accuracies on Web sessions that they can predict. However, higher-order models are also extremely complex due to their large number of states, which increases their space and run-time requirements. In this article, we present different techniques for intelligently selecting parts of different order Markov models so that the resulting model has a reduced state complexity, while maintaining a high predictive accuracy.",
    "cited_by_count": 412,
    "openalex_id": "https://openalex.org/W2169240294",
    "type": "article"
  },
  {
    "title": "Rethinking the design of the Internet",
    "doi": "https://doi.org/10.1145/383034.383037",
    "publication_date": "2001-08-01",
    "publication_year": 2001,
    "authors": "Marjory S. Blumenthal; David D. Clark",
    "corresponding_authors": "",
    "abstract": "This article looks at the Internet and the changing set of requirements for the Internet as it becomes more commercial, more oriented toward the consumer, and used for a wider set of purposes. We discuss a set of principles that have guided the design of the Internet, called the end-to-end arguments, and we conclude that there is a risk that the range of new requirements now emerging could have the consequence of compromising the Internet's original design principles. Were this to happen, the Internet might lose some of its key features, in particular its ability to support new and unanticipated applications. We link this possible outcome to a number of trends: the rise of new stakeholders in the Internet, in particular Internet service providers; new government interests; the changing motivations of a growing user base; and the tension between the demand for trustworthy overall operation and the inability to trust the behavior of individual users.",
    "cited_by_count": 403,
    "openalex_id": "https://openalex.org/W2093973064",
    "type": "article"
  },
  {
    "title": "Teaching Johnny not to fall for phish",
    "doi": "https://doi.org/10.1145/1754393.1754396",
    "publication_date": "2010-05-01",
    "publication_year": 2010,
    "authors": "Ponnurangam Kumaraguru; Steve Sheng; Alessandro Acquisti; Lorrie Faith Cranor; Jason Hong",
    "corresponding_authors": "",
    "abstract": "Phishing attacks, in which criminals lure Internet users to Web sites that spoof legitimate Web sites, are occurring with increasing frequency and are causing considerable harm to victims. While a great deal of effort has been devoted to solving the phishing problem by prevention and detection of phishing emails and phishing Web sites, little research has been done in the area of training users to recognize those attacks. Our research focuses on educating users about phishing and helping them make better trust decisions. We identified a number of challenges for end-user security education in general and anti-phishing education in particular: users are not motivated to learn about security; for most users, security is a secondary task; it is difficult to teach people to identify security threats without also increasing their tendency to misjudge nonthreats as threats. Keeping these challenges in mind, we developed an email-based anti-phishing education system called “PhishGuru” and an online game called “Anti-Phishing Phil” that teaches users how to use cues in URLs to avoid falling for phishing attacks. We applied learning science instructional principles in the design of PhishGuru and Anti-Phishing Phil. In this article we present the results of PhishGuru and Anti-Phishing Phil user studies that demonstrate the effectiveness of these tools. Our results suggest that, while automated detection systems should be used as the first line of defense against phishing attacks, user education offers a complementary approach to help people better recognize fraudulent emails and websites.",
    "cited_by_count": 368,
    "openalex_id": "https://openalex.org/W2071869991",
    "type": "article"
  },
  {
    "title": "Argumentation Mining",
    "doi": "https://doi.org/10.1145/2850417",
    "publication_date": "2016-03-30",
    "publication_year": 2016,
    "authors": "Marco Lippi; Paolo Torroni",
    "corresponding_authors": "",
    "abstract": "Argumentation mining aims at automatically extracting structured arguments from unstructured textual documents. It has recently become a hot topic also due to its potential in processing information originating from the Web, and in particular from social media, in innovative ways. Recent advances in machine learning methods promise to enable breakthrough applications to social and economic sciences, policy making, and information technology: something that only a few years ago was unthinkable. In this survey article, we introduce argumentation models and methods, review existing systems and applications, and discuss challenges and perspectives of this exciting new research area.",
    "cited_by_count": 358,
    "openalex_id": "https://openalex.org/W2327805699",
    "type": "article"
  },
  {
    "title": "Novelty and Diversity in Top-N Recommendation -- Analysis and Evaluation",
    "doi": "https://doi.org/10.1145/1944339.1944341",
    "publication_date": "2011-03-01",
    "publication_year": 2011,
    "authors": "Neil Hurley; Mi Zhang",
    "corresponding_authors": "",
    "abstract": "For recommender systems that base their product rankings primarily on a measure of similarity between items and the user query, it can often happen that products on the recommendation list are highly similar to each other and lack diversity. In this article we argue that the motivation of diversity research is to increase the probability of retrieving unusual or novel items which are relevant to the user and introduce a methodology to evaluate their performance in terms of novel item retrieval. Moreover, noting that the retrieval of a set of items matching a user query is a common problem across many applications of information retrieval, we formulate the trade-off between diversity and matching quality as a binary optimization problem, with an input control parameter allowing explicit tuning of this trade-off. We study solution strategies to the optimization problem and demonstrate the importance of the control parameter in obtaining desired system performance. The methods are evaluated for collaborative recommendation using two datasets and case-based recommendation using a synthetic dataset constructed from the public-domain Travel dataset.",
    "cited_by_count": 316,
    "openalex_id": "https://openalex.org/W1967787801",
    "type": "article"
  },
  {
    "title": "Fog Computing for the Internet of Things",
    "doi": "https://doi.org/10.1145/3301443",
    "publication_date": "2019-04-02",
    "publication_year": 2019,
    "authors": "Carlo Puliafito; Enzo Mingozzi; Francesco Longo; Antonio Puliafito; Omer Rana",
    "corresponding_authors": "",
    "abstract": "Research in the Internet of Things (IoT) conceives a world where everyday objects are connected to the Internet and exchange, store, process, and collect data from the surrounding environment. IoT devices are becoming essential for supporting the delivery of data to enable electronic services, but they are not sufficient in most cases to host application services directly due to their intrinsic resource constraints. Fog Computing (FC) can be a suitable paradigm to overcome these limitations, as it can coexist and cooperate with centralized Cloud systems and extends the latter toward the network edge. In this way, it is possible to distribute resources and services of computing, storage, and networking along the Cloud-to-Things continuum. As such, FC brings all the benefits of Cloud Computing (CC) closer to end (user) devices. This article presents a survey on the employment of FC to support IoT devices and services. The principles and literature characterizing FC are described, highlighting six IoT application domains that may benefit from the use of this paradigm. The extension of Cloud systems towards the network edge also creates new challenges and can have an impact on existing approaches employed in Cloud-based deployments. Research directions being adopted by the community are highlighted, with an indication of which of these are likely to have the greatest impact. An overview of existing FC software and hardware platforms for the IoT is also provided, along with the standardisation efforts in this area initiated by the OpenFog Consortium (OFC).",
    "cited_by_count": 301,
    "openalex_id": "https://openalex.org/W2929921254",
    "type": "article"
  },
  {
    "title": "Latency-Aware Application Module Management for Fog Computing Environments",
    "doi": "https://doi.org/10.1145/3186592",
    "publication_date": "2018-11-30",
    "publication_year": 2018,
    "authors": "Redowan Mahmud; Kotagiri Ramamohanarao; Rajkumar Buyya",
    "corresponding_authors": "",
    "abstract": "The fog computing paradigm has drawn significant research interest as it focuses on bringing cloud-based services closer to Internet of Things (IoT) users in an efficient and timely manner. Most of the physical devices in the fog computing environment, commonly named fog nodes, are geographically distributed, resource constrained, and heterogeneous. To fully leverage the capabilities of the fog nodes, large-scale applications that are decomposed into interdependent Application Modules can be deployed in an orderly way over the nodes based on their latency sensitivity. In this article, we propose a latency-aware Application Module management policy for the fog environment that meets the diverse service delivery latency and amount of data signals to be processed in per unit of time for different applications. The policy aims to ensure applications’ Quality of Service (QoS) in satisfying service delivery deadlines and to optimize resource usage in the fog environment. We model and evaluate our proposed policy in an iFogSim-simulated fog environment. Results of the simulation studies demonstrate significant improvement in performance over alternative latency-aware strategies.",
    "cited_by_count": 238,
    "openalex_id": "https://openalex.org/W2903434459",
    "type": "article"
  },
  {
    "title": "Patterns in the Chaos—A Study of Performance Variation and Predictability in Public IaaS Clouds",
    "doi": "https://doi.org/10.1145/2885497",
    "publication_date": "2016-04-19",
    "publication_year": 2016,
    "authors": "Philipp Leitner; Jürgen Cito",
    "corresponding_authors": "",
    "abstract": "Benchmarking the performance of public cloud providers is a common research topic. Previous work has already extensively evaluated the performance of different cloud platforms for different use cases, and under different constraints and experiment setups. In this article, we present a principled, large-scale literature review to collect and codify existing research regarding the predictability of performance in public Infrastructure-as-a-Service (IaaS) clouds. We formulate 15 hypotheses relating to the nature of performance variations in IaaS systems, to the factors of influence of performance variations, and how to compare different instance types. In a second step, we conduct extensive real-life experimentation on four cloud providers to empirically validate those hypotheses. We show that there are substantial differences between providers. Hardware heterogeneity is today less prevalent than reported in earlier research, while multitenancy has a dramatic impact on performance and predictability, but only for some cloud providers. We were unable to discover a clear impact of the time of the day or the day of the week on cloud performance.",
    "cited_by_count": 201,
    "openalex_id": "https://openalex.org/W1651603302",
    "type": "article"
  },
  {
    "title": "Federated Learning in a Medical Context: A Systematic Literature Review",
    "doi": "https://doi.org/10.1145/3412357",
    "publication_date": "2021-06-02",
    "publication_year": 2021,
    "authors": "Bjarne Pfitzner; Nico Steckhan; Bert Arnrich",
    "corresponding_authors": "",
    "abstract": "Data privacy is a very important issue. Especially in fields like medicine, it is paramount to abide by the existing privacy regulations to preserve patients’ anonymity. However, data is required for research and training machine learning models that could help gain insight into complex correlations or personalised treatments that may otherwise stay undiscovered. Those models generally scale with the amount of data available, but the current situation often prohibits building large databases across sites. So it would be beneficial to be able to combine similar or related data from different sites all over the world while still preserving data privacy. Federated learning has been proposed as a solution for this, because it relies on the sharing of machine learning models, instead of the raw data itself. That means private data never leaves the site or device it was collected on. Federated learning is an emerging research area, and many domains have been identified for the application of those methods. This systematic literature review provides an extensive look at the concept of and research into federated learning and its applicability for confidential healthcare datasets.",
    "cited_by_count": 193,
    "openalex_id": "https://openalex.org/W3169231731",
    "type": "article"
  },
  {
    "title": "An Emotional Analysis of False Information in Social Media and News Articles",
    "doi": "https://doi.org/10.1145/3381750",
    "publication_date": "2020-04-19",
    "publication_year": 2020,
    "authors": "Bilal Ghanem; Paolo Rosso; Francisco Rangel",
    "corresponding_authors": "",
    "abstract": "Fake news is risky, since it has been created to manipulate readers’ opinions and beliefs. In this work, we compared the language of false news to the real one of real news from an emotional perspective, considering a set of false information types (propaganda, hoax, clickbait, and satire) from social media and online news article sources. Our experiments showed that false information has different emotional patterns in each of its types, and emotions play a key role in deceiving the reader. Based on that, we proposed an LSTM neural network model that is emotionally infused to detect false news.",
    "cited_by_count": 181,
    "openalex_id": "https://openalex.org/W3023367181",
    "type": "article"
  },
  {
    "title": "A Dynamic Service Migration Mechanism in Edge Cognitive Computing",
    "doi": "https://doi.org/10.1145/3239565",
    "publication_date": "2019-04-03",
    "publication_year": 2019,
    "authors": "Min Chen; Wei Li; Giancarlo Fortino; Yixue Hao; Long Hu; Iztok Humar",
    "corresponding_authors": "",
    "abstract": "Driven by the vision of edge computing and the success of rich cognitive services based on artificial intelligence, a new computing paradigm, edge cognitive computing (ECC), is a promising approach that applies cognitive computing at the edge of the network. ECC has the potential to provide the cognition of users and network environmental information, and further to provide elastic cognitive computing services to achieve a higher energy efficiency and a higher Quality of Experience (QoE) compared to edge computing. This article first introduces our architecture of the ECC and then describes its design issues in detail. Moreover, we propose an ECC-based dynamic service migration mechanism to provide insight into how cognitive computing is combined with edge computing. In order to evaluate the proposed mechanism, a practical platform for dynamic service migration is built up, where the services are migrated based on the behavioral cognition of a mobile user. The experimental results show that the proposed ECC architecture has ultra-low latency and a high user experience, while providing better service to the user, saving computing resources, and achieving a high energy efficiency.",
    "cited_by_count": 177,
    "openalex_id": "https://openalex.org/W2888704015",
    "type": "article"
  },
  {
    "title": "Understanding Ethereum via Graph Analysis",
    "doi": "https://doi.org/10.1145/3381036",
    "publication_date": "2020-04-17",
    "publication_year": 2020,
    "authors": "Ting Chen; Zihao Li; Yu-Xiao Zhu; Jiachi Chen; Xiapu Luo; John C. S. Lui; Xiaodong Lin; Xiaosong Zhang",
    "corresponding_authors": "",
    "abstract": "Ethereum, a blockchain, supports its own cryptocurrency named Ether and smart contracts. Although more than 8M smart contracts have been deployed on Ethereum, little is known about the characteristics of its users, smart contracts, and the relationships among them. We conduct the first systematic study on Ethereum by leveraging graph analysis to characterize three major activities on Ethereum, namely money transfer, smart contract creation, and smart contract invocation. We collect all transaction data, construct three graphs from the data to characterize major activities via graph analysis, and discover new insights. Moreover, we address three security issues based on graphs.",
    "cited_by_count": 164,
    "openalex_id": "https://openalex.org/W3017072639",
    "type": "article"
  },
  {
    "title": "Phishing Scams Detection in Ethereum Transaction Network",
    "doi": "https://doi.org/10.1145/3398071",
    "publication_date": "2020-07-07",
    "publication_year": 2020,
    "authors": "Liang Chen; Jiaying Peng; Yang Liu; Jintang Li; Fenfang Xie; Zibin Zheng",
    "corresponding_authors": "",
    "abstract": "Blockchain has attracted an increasing amount of researches, and there are lots of refreshing implementations in different fields. Cryptocurrency as its representative implementation, suffers the economic loss due to phishing scams. In our work, accounts and transactions are treated as nodes and edges, thus detection of phishing accounts can be modeled as a node classification problem. Correspondingly, we propose a detecting method based on Graph Convolutional Network and autoencoder to precisely distinguish phishing accounts. Experiments on different large-scale real-world datasets from Ethereum show that our proposed model consistently performs promising results compared with related methods.",
    "cited_by_count": 154,
    "openalex_id": "https://openalex.org/W3087349682",
    "type": "article"
  },
  {
    "title": "The Cloud-edge-based Dynamic Reconfiguration to Service Workflow for Mobile Ecommerce Environments",
    "doi": "https://doi.org/10.1145/3391198",
    "publication_date": "2021-01-13",
    "publication_year": 2021,
    "authors": "Honghao Gao; Wanqiu Huang; Yucong Duan",
    "corresponding_authors": "",
    "abstract": "The emergence of mobile service composition meets the current needs for real-time eCommerce. However, the requirements for eCommerce, such as safety and timeliness, are becoming increasingly strict. Thus, the cloud-edge hybrid computing model has been introduced to accelerate information processing, especially in a mobile scenario. However, the mobile environment is characterized by limited resource storage and users who frequently move, and these characteristics strongly affect the reliability of service composition running in this environment. Consequently, applications are likely to fail if inappropriate services are invoked. To ensure that the composite service can operate normally, traditional dynamic reconfiguration methods tend to focus on cloud services scheduling. Unfortunately, most of these approaches cannot support timely responses to dynamic changes. In this article, the cloud-edge based dynamic reconfiguration to service workflow for mobile eCommerce environments is proposed. First, the service quality concept is extended. Specifically, the value and cost attributes of a service are considered. The value attribute is used to assess the stability of the service for some time to come, and the cost attribute is the cost of a service invocation. Second, a long short-term memory (LSTM) neural network is used to predict the stability of services, which is related to the calculation of the value attribute. Then, in view of the limited available equipment resources, a method for calculating the cost of calling a service is introduced. Third, candidate services are selected by considering both service stability and the cost of service invocation, thus yielding a dynamic reconfiguration scheme that is more suitable for the cloud-edge environment. Finally, a series of comparative experiments were carried out, and the experimental results prove that the method proposed in this article offers higher stability, less energy consumption, and more accurate service prediction.",
    "cited_by_count": 125,
    "openalex_id": "https://openalex.org/W3118879517",
    "type": "article"
  },
  {
    "title": "Privacy-Aware Traffic Flow Prediction Based on Multi-Party Sensor Data with Zero Trust in Smart City",
    "doi": "https://doi.org/10.1145/3511904",
    "publication_date": "2022-03-28",
    "publication_year": 2022,
    "authors": "Fan Wang; Guangshun Li; Yilei Wang; Wajid Rafique; Mohammad R. Khosravi; Guanfeng Liu; Yuwen Liu; Lianyong Qi",
    "corresponding_authors": "",
    "abstract": "With the continuous increment of city volume and size, a number of traffic-related urban units (e.g., vehicles, roads, buildings, etc.) are emerging rapidly, which plays a heavy burden on the scientific traffic control of smart cities. In this situation, it is becoming a necessity to utilize the sensor data from massive cameras deployed at city crossings for accurate traffic flow prediction. However, the traffic sensor data are often distributed and stored by different organizations or parties with zero trust, which impedes the multi-party sensor data sharing significantly due to privacy concerns. Therefore, it requires challenging efforts to balance the trade-off between data sharing and data privacy to enable cross-organization traffic data fusion and prediction. In light of this challenge, we put forward an accurate LSH (locality-sensitive hashing)-based traffic flow prediction approach with the ability to protect privacy. Finally, through a series of experiments deployed on a real-world traffic dataset, we demonstrate the feasibility of our proposal in terms of prediction accuracy and efficiency while guaranteeing sensor data privacy.",
    "cited_by_count": 85,
    "openalex_id": "https://openalex.org/W4220951298",
    "type": "article"
  },
  {
    "title": "XDuce",
    "doi": "https://doi.org/10.1145/767193.767195",
    "publication_date": "2003-05-01",
    "publication_year": 2003,
    "authors": "Haruo Hosoya; Benjamin C. Pierce",
    "corresponding_authors": "",
    "abstract": "XDuce is a statically typed programming language for XML processing. Its basic data values are XML documents, and its types (so-called regular expression types ) directly correspond to document schemas. XDuce also provides a flexible form of regular expression pattern matching , integrating conditional branching, tag checking, and subtree extraction, as well as dynamic typechecking. We survey the principles of XDuce's design, develop examples illustrating its key features, describe its foundations in the theory of regular tree automata, and present a complete formal definition of its core, along with a proof of type safety.",
    "cited_by_count": 349,
    "openalex_id": "https://openalex.org/W1966814918",
    "type": "article"
  },
  {
    "title": "Estimating frequency of change",
    "doi": "https://doi.org/10.1145/857166.857170",
    "publication_date": "2003-08-01",
    "publication_year": 2003,
    "authors": "Junghoo Cho; Héctor García-Molina",
    "corresponding_authors": "",
    "abstract": "Many online data sources are updated autonomously and independently. In this article, we make the case for estimating the change frequency of data to improve Web crawlers, Web caches and to help data mining. We first identify various scenarios, where different applications have different requirements on the accuracy of the estimated frequency. Then we develop several \"frequency estimators\" for the identified scenarios, showing analytically and experimentally how precise they are. In many cases, our proposed estimators predict change frequencies much more accurately and improve the effectiveness of applications. For example, a Web crawler could achieve 35% improvement in \"freshness\" simply by adopting our proposed estimator.",
    "cited_by_count": 336,
    "openalex_id": "https://openalex.org/W1976624301",
    "type": "article"
  },
  {
    "title": "Collaborative recommendation",
    "doi": "https://doi.org/10.1145/1031114.1031116",
    "publication_date": "2004-11-01",
    "publication_year": 2004,
    "authors": "Michael P. O’Mahony; Neil Hurley; Nicholas Kushmerick; G.C.M. Silvestre",
    "corresponding_authors": "",
    "abstract": "Collaborative recommendation has emerged as an effective technique for personalized information access. However, there has been relatively little theoretical analysis of the conditions under which the technique is effective. To explore this issue, we analyse the &lt;i&gt;robustness&lt;/i&gt; of collaborative recommendation: the ability to make recommendations despite (possibly intentional) noisy product ratings. There are two aspects to robustness: recommendation &lt;i&gt;accuracy&lt;/i&gt; and &lt;i&gt;stability&lt;/i&gt;. We formalize recommendation accuracy in machine learning terms and develop theoretically justified models of accuracy. In addition, we present a framework to examine recommendation stability in the context of a widely-used collaborative filtering algorithm. For each case, we evaluate our analysis using several real-world data-sets. Our investigation is both practically relevant for enterprises wondering whether collaborative recommendation leaves their marketing operations open to attack, and theoretically interesting for the light it sheds on a comprehensive theory of collaborative recommendation.",
    "cited_by_count": 331,
    "openalex_id": "https://openalex.org/W2000855935",
    "type": "article"
  },
  {
    "title": "Link analysis ranking: algorithms, theory, and experiments",
    "doi": "https://doi.org/10.1145/1052934.1052942",
    "publication_date": "2005-02-01",
    "publication_year": 2005,
    "authors": "Allan Borodin; Gareth O. Roberts; Jeffrey S. Rosenthal; Panayiotis Tsaparas",
    "corresponding_authors": "",
    "abstract": "The explosive growth and the widespread accessibility of the Web has led to a surge of research activity in the area of information retrieval on the World Wide Web. The seminal papers of Kleinberg [1998, 1999] and Brin and Page [1998] introduced Link Analysis Ranking , where hyperlink structures are used to determine the relative authority of a Web page and produce improved algorithms for the ranking of Web search results. In this article we work within the hubs and authorities framework defined by Kleinberg and we propose new families of algorithms. Two of the algorithms we propose use a Bayesian approach, as opposed to the usual algebraic and graph theoretic approaches. We also introduce a theoretical framework for the study of Link Analysis Ranking algorithms. The framework allows for the definition of specific properties of Link Analysis Ranking algorithms, as well as for comparing different algorithms. We study the properties of the algorithms that we define, and we provide an axiomatic characterization of the INDEGREE heuristic which ranks each node according to the number of incoming links. We conclude the article with an extensive experimental evaluation. We study the quality of the algorithms, and we examine how different structures in the graphs affect their performance.",
    "cited_by_count": 317,
    "openalex_id": "https://openalex.org/W2111289574",
    "type": "article"
  },
  {
    "title": "XRel",
    "doi": "https://doi.org/10.1145/383034.383038",
    "publication_date": "2001-08-01",
    "publication_year": 2001,
    "authors": "Masatoshi Yoshikawa; Toshiyuki Amagasa; Takeyuki Shimura; Shunsuke Uemura",
    "corresponding_authors": "",
    "abstract": "This article describes XRel, a novel approach for storage and retrieval of XML documents using relational databases. In this approach, an XML document is decomposed into nodes on the basis of its tree structure and stored in relational tables according to the node type, with path information from the root to each node. XRel enables us to store XML documents using a fixed relational schema without any information about DTDs and also to utilize indices such as the B + -tree and the R -tree supported by database management systems. Thus, XRel does not need any extension of relational databases for storing XML documents. For processing XML queries, we present an algorithm for translating a core subset of XPath expressions into SQL queries. Finally, we demonstrate the effectiveness of this approach through several experiments using actual XML documents.",
    "cited_by_count": 300,
    "openalex_id": "https://openalex.org/W4243649771",
    "type": "article"
  },
  {
    "title": "xlinkit",
    "doi": "https://doi.org/10.1145/514183.514186",
    "publication_date": "2002-05-01",
    "publication_year": 2002,
    "authors": "Christian Nentwich; Licia Capra; Wolfgang Emmerich; Anthony Finkelsteiin",
    "corresponding_authors": "",
    "abstract": "xlinkit is a lightweight application service that provides rule-based link generation and checks the consistency of distributed Web content. It leverages standard Internet technologies, notably XML, XPath, and XLink. xlinkit can be used as part of a consistency management scheme or in applications that require smart link generation, including portal construction and management of large document repositories. In this article we show how consistency constraints can be expressed and checked. We describe a novel semantics for first-order logic that produces links instead of truth values and give an account of our content management strategy. We present the architecture of our service and the results of two substantial case studies that use xlinkit for checking course syllabus information and for validating UML models supplied by industrial partners.",
    "cited_by_count": 282,
    "openalex_id": "https://openalex.org/W2012959900",
    "type": "article"
  },
  {
    "title": "Topical web crawlers",
    "doi": "https://doi.org/10.1145/1031114.1031117",
    "publication_date": "2004-11-01",
    "publication_year": 2004,
    "authors": "Filippo Menczer; Gautam Pant; Padmini Srinivasan",
    "corresponding_authors": "",
    "abstract": "Topical crawlers are increasingly seen as a way to address the scalability limitations of universal search engines, by distributing the crawling process across users, queries, or even client computers. The context available to such crawlers can guide the navigation of links with the goal of efficiently locating highly relevant target pages. We developed a framework to fairly evaluate topical crawling algorithms under a number of performance metrics. Such a framework is employed here to evaluate different algorithms that have proven highly competitive among those proposed in the literature and in our own previous research. In particular we focus on the tradeoff between exploration and exploitation of the cues available to a crawler, and on adaptive crawlers that use machine learning techniques to guide their search. We find that the best performance is achieved by a novel combination of explorative and exploitative bias, and introduce an evolutionary crawler that surpasses the performance of the best nonadaptive crawler after sufficiently long crawls. We also analyze the computational complexity of the various crawlers and discuss how performance and complexity scale with available resources. Evolutionary crawlers achieve high efficiency and scalability by distributing the work across concurrent agents, resulting in the best performance/cost ratio.",
    "cited_by_count": 275,
    "openalex_id": "https://openalex.org/W2151007976",
    "type": "article"
  },
  {
    "title": "Moderately hard, memory-bound functions",
    "doi": "https://doi.org/10.1145/1064340.1064341",
    "publication_date": "2005-05-01",
    "publication_year": 2005,
    "authors": "Martı́n Abadi; Mike Burrows; Mark S. Manasse; Ted Wobber",
    "corresponding_authors": "",
    "abstract": "A resource may be abused if its users incur little or no cost. For example, e-mail abuse is rampant because sending an e-mail has negligible cost for the sender. It has been suggested that such abuse may be discouraged by introducing an artificial cost in the form of a moderately expensive computation. Thus, the sender of an e-mail might be required to pay by computing for a few seconds before the e-mail is accepted. Unfortunately, because of sharp disparities across computer systems, this approach may be ineffective against malicious users with high-end systems, prohibitively slow for legitimate users with low-end systems, or both. Starting from this observation, we research moderately hard functions that most recent systems will evaluate at about the same speed. For this purpose, we rely on memory-bound computations. We describe and analyze a family of moderately hard, memory-bound functions, and we explain how to use them for protecting against abuses.",
    "cited_by_count": 217,
    "openalex_id": "https://openalex.org/W1998350371",
    "type": "article"
  },
  {
    "title": "Model-driven development of context-aware Web applications",
    "doi": "https://doi.org/10.1145/1189740.1189742",
    "publication_date": "2007-02-01",
    "publication_year": 2007,
    "authors": "Stefano Ceri; Florian Daniel; Maristella Matera; Federico Michele Facca",
    "corresponding_authors": "",
    "abstract": "Context-aware, multi-channel Web applications are more and more gaining consensus among both content providers and consumers, but very few proposals exist for their conceptual modeling. This article illustrates a conceptual framework that provides modeling facilities for context-aware, multichannel Web applications; it also shows how high-level modeling constructs can drive the application development process through automatic code generation. Our work stresses the importance of user-independent, context-triggered adaptation actions, in which the context plays the role of a “first class” actor , operating independently of users on the same hypertext the users navigate. Modeling concepts are based on WebML (Web Modeling Language), an already established conceptual model for data-intensive Web applications, which is also accompanied by a development method and a CASE tool. However, given their general validity, the concepts of this article shape up a complete framework that can be adopted independently of the chosen model, method, and tool.",
    "cited_by_count": 158,
    "openalex_id": "https://openalex.org/W2155648179",
    "type": "article"
  },
  {
    "title": "A Multilingual Evaluation for Online Hate Speech Detection",
    "doi": "https://doi.org/10.1145/3377323",
    "publication_date": "2020-03-14",
    "publication_year": 2020,
    "authors": "Michele Corazza; Stefano Menini; Elena Cabrio; Sara Tonelli; Serena Villata",
    "corresponding_authors": "",
    "abstract": "The increasing popularity of social media platforms such as Twitter and Facebook has led to a rise in the presence of hate and aggressive speech on these platforms. Despite the number of approaches recently proposed in the Natural Language Processing research area for detecting these forms of abusive language, the issue of identifying hate speech at scale is still an unsolved problem. In this article, we propose a robust neural architecture that is shown to perform in a satisfactory way across different languages; namely, English, Italian, and German. We address an extensive analysis of the obtained experimental results over the three languages to gain a better understanding of the contribution of the different components employed in the system, both from the architecture point of view (i.e., Long Short Term Memory, Gated Recurrent Unit, and bidirectional Long Short Term Memory) and from the feature selection point of view (i.e., ngrams, social network–specific features, emotion lexica, emojis, word embeddings). To address such in-depth analysis, we use three freely available datasets for hate speech detection on social media in English, Italian, and German.",
    "cited_by_count": 149,
    "openalex_id": "https://openalex.org/W3011385529",
    "type": "article"
  },
  {
    "title": "Irony Detection in Twitter",
    "doi": "https://doi.org/10.1145/2930663",
    "publication_date": "2016-07-09",
    "publication_year": 2016,
    "authors": "Delia Irazú Hernández Farías; Viviana Patti; Paolo Rosso",
    "corresponding_authors": "",
    "abstract": "Irony has been proven to be pervasive in social media, posing a challenge to sentiment analysis systems. It is a creative linguistic phenomenon where affect-related aspects play a key role. In this work, we address the problem of detecting irony in tweets, casting it as a classification problem. We propose a novel model that explores the use of affective features based on a wide range of lexical resources available for English, reflecting different facets of affect. Classification experiments over different corpora show that affective information helps in distinguishing among ironic and nonironic tweets. Our model outperforms the state of the art in almost all cases.",
    "cited_by_count": 139,
    "openalex_id": "https://openalex.org/W2463843470",
    "type": "article"
  },
  {
    "title": "Internet of Things (IoT)",
    "doi": "https://doi.org/10.1145/3013520",
    "publication_date": "2016-12-07",
    "publication_year": 2016,
    "authors": "Elisa Bertino; Kim‐Kwang Raymond Choo; Dimitrios Georgakopolous; ‪Surya Nepal‬",
    "corresponding_authors": "",
    "abstract": "The Internet of Things (IoT) is the latest Internet evolution that incorporates a diverse range of things such as sensors, actuators, and services deployed by different organizations and individuals to support a variety of applications. The information captured by IoT present an unprecedented opportunity to solve large-scale problems in those application domains to deliver services; example applications include precision agriculture, environment monitoring, smart health, smart manufacturing, and smart cities. Like all other Internet based services in the past, IoT-based services are also being developed and deployed without security consideration. By nature, IoT devices and services are vulnerable to malicious cyber threats as they cannot be given the same protection that is received by enterprise services within an enterprise perimeter. While IoT services will play an important role in our daily life resulting in improved productivity and quality of life, the trend has also “encouraged” cyber-exploitation and evolution and diversification of malicious cyber threats. Hence, there is a need for coordinated efforts from the research community to address resulting concerns, such as those presented in this special section. Several potential research topics are also identified in this special section.",
    "cited_by_count": 132,
    "openalex_id": "https://openalex.org/W2560411358",
    "type": "article"
  },
  {
    "title": "A Graph Analytical Approach for Topic Detection",
    "doi": "https://doi.org/10.1145/2542214.2542215",
    "publication_date": "2013-12-01",
    "publication_year": 2013,
    "authors": "Hassan Sayyadi; Louiqa Raschid",
    "corresponding_authors": "",
    "abstract": "Topic detection with large and noisy data collections such as social media must address both scalability and accuracy challenges. KeyGraph is an efficient method that improves on current solutions by considering keyword cooccurrence. We show that KeyGraph has similar accuracy when compared to state-of-the-art approaches on small, well-annotated collections, and it can successfully filter irrelevant documents and identify events in large and noisy social media collections. An extensive evaluation using Amazon’s Mechanical Turk demonstrated the increased accuracy and high precision of KeyGraph, as well as superior runtime performance compared to other solutions.",
    "cited_by_count": 128,
    "openalex_id": "https://openalex.org/W1989894105",
    "type": "article"
  },
  {
    "title": "Aggregate Characterization of User Behavior in Twitter and Analysis of the Retweet Graph",
    "doi": "https://doi.org/10.1145/2700060",
    "publication_date": "2015-03-12",
    "publication_year": 2015,
    "authors": "David R. Bild; Yue Liu; Robert P. Dick; Z. Morley Mao; Dan S. Wallach",
    "corresponding_authors": "",
    "abstract": "Most previous analysis of Twitter user behavior is focused on individual information cascades and the social followers graph. We instead study aggregate user behavior and the retweet graph with a focus on quantitative descriptions. We find that the lifetime tweet distribution is a type-II discrete Weibull stemming from a power law hazard function, the tweet rate distribution, although asymptotically power law, exhibits a lognormal cutoff over finite sample intervals, and the inter-tweet interval distribution is power law with exponential cutoff. The retweet graph is small-world and scale-free, like the social graph, but is less disassortative and has much stronger clustering. These differences are consistent with it better capturing the real-world social relationships of and trust between users. Beyond just understanding and modeling human communication patterns and social networks, applications for alternative, decentralized microblogging systems-both predicting real-word performance and detecting spam-are discussed.",
    "cited_by_count": 122,
    "openalex_id": "https://openalex.org/W1999458239",
    "type": "article"
  },
  {
    "title": "Can We Predict a Riot? Disruptive Event Detection Using Twitter",
    "doi": "https://doi.org/10.1145/2996183",
    "publication_date": "2017-03-27",
    "publication_year": 2017,
    "authors": "Nasser Alsaedi; Pete Burnap; Omer Rana",
    "corresponding_authors": "",
    "abstract": "In recent years, there has been increased interest in real-world event detection using publicly accessible data made available through Internet technology such as Twitter, Facebook, and YouTube. In these highly interactive systems, the general public are able to post real-time reactions to “real world” events, thereby acting as social sensors of terrestrial activity. Automatically detecting and categorizing events, particularly small-scale incidents, using streamed data is a non-trivial task but would be of high value to public safety organisations such as local police, who need to respond accordingly. To address this challenge, we present an end-to-end integrated event detection framework that comprises five main components: data collection, pre-processing, classification, online clustering, and summarization. The integration between classification and clustering enables events to be detected, as well as related smaller-scale “disruptive events,” smaller incidents that threaten social safety and security or could disrupt social order. We present an evaluation of the effectiveness of detecting events using a variety of features derived from Twitter posts, namely temporal, spatial, and textual content. We evaluate our framework on a large-scale, real-world dataset from Twitter. Furthermore, we apply our event detection system to a large corpus of tweets posted during the August 2011 riots in England. We use ground-truth data based on intelligence gathered by the London Metropolitan Police Service, which provides a record of actual terrestrial events and incidents during the riots, and show that our system can perform as well as terrestrial sources, and even better in some cases.",
    "cited_by_count": 115,
    "openalex_id": "https://openalex.org/W2601783998",
    "type": "article"
  },
  {
    "title": "Architectural Principles for Cloud Software",
    "doi": "https://doi.org/10.1145/3104028",
    "publication_date": "2018-02-02",
    "publication_year": 2018,
    "authors": "Claus Pahl; Pooyan Jamshidi; Olaf Zimmermann",
    "corresponding_authors": "",
    "abstract": "A cloud is a distributed Internet-based software system providing resources as tiered services. Through service-orientation and virtualization for resource provisioning, cloud applications can be deployed and managed dynamically. We discuss the building blocks of an architectural style for cloud-based software systems. We capture style-defining architectural principles and patterns for control-theoretic, model-based architectures for cloud software. While service orientation is agreed on in the form of service-oriented architecture and microservices, challenges resulting from multi-tiered, distributed and heterogeneous cloud architectures cause uncertainty that has not been sufficiently addressed. We define principles and patterns needed for effective development and operation of adaptive cloud-native systems.",
    "cited_by_count": 114,
    "openalex_id": "https://openalex.org/W2793142602",
    "type": "article"
  },
  {
    "title": "Deep Reinforcement Scheduling for Mobile Crowdsensing in Fog Computing",
    "doi": "https://doi.org/10.1145/3234463",
    "publication_date": "2019-04-16",
    "publication_year": 2019,
    "authors": "He Li; Kaoru Ota; Mianxiong Dong",
    "corresponding_authors": "",
    "abstract": "Mobile crowdsensing becomes a promising technology for the emerging Internet of Things (IoT) applications in smart environments. Fog computing is enabling a new breed of IoT services, which is also a new opportunity for mobile crowdsensing. Thus, in this article, we introduce a framework enabling mobile crowdsensing in fog environments with a hierarchical scheduling strategy. We first introduce the crowdsensing framework that has a hierarchical structure to organize different resources. Since different positions and performance of fog nodes influence the quality of service (QoS) of IoT applications, we formulate a scheduling problem in the hierarchical fog structure and solve it by using a deep reinforcement learning–based strategy. From extensive simulation results, our solution outperforms other scheduling solutions for mobile crowdsensing in the given fog computing environment.",
    "cited_by_count": 111,
    "openalex_id": "https://openalex.org/W2938135176",
    "type": "article"
  },
  {
    "title": "A Cost-Efficient Container Orchestration Strategy in Kubernetes-Based Cloud Computing Infrastructures with Heterogeneous Resources",
    "doi": "https://doi.org/10.1145/3378447",
    "publication_date": "2020-04-17",
    "publication_year": 2020,
    "authors": "Zhiheng Zhong; Rajkumar Buyya",
    "corresponding_authors": "",
    "abstract": "Containers, as a lightweight application virtualization technology, have recently gained immense popularity in mainstream cluster management systems like Google Borg and Kubernetes. Prevalently adopted by these systems for task deployments of diverse workloads such as big data, web services, and IoT, they support agile application deployment, environmental consistency, OS distribution portability, application-centric management, and resource isolation. Although most of these systems are mature with advanced features, their optimization strategies are still tailored to the assumption of a static cluster. Elastic compute resources would enable heterogeneous resource management strategies in response to the dynamic business volume for various types of workloads. Hence, we propose a heterogeneous task allocation strategy for cost-efficient container orchestration through resource utilization optimization and elastic instance pricing with three main features. The first one is to support heterogeneous job configurations to optimize the initial placement of containers into existing resources by task packing. The second one is cluster size adjustment to meet the changing workload through autoscaling algorithms. The third one is a rescheduling mechanism to shut down underutilized VM instances for cost saving and reallocate the relevant jobs without losing task progress. We evaluate our approach in terms of cost and performance on the Australian National Cloud Infrastructure (Nectar). Our experiments demonstrate that the proposed strategy could reduce the overall cost by 23% to 32% for different types of cloud workload patterns when compared to the default Kubernetes framework.",
    "cited_by_count": 109,
    "openalex_id": "https://openalex.org/W3021735597",
    "type": "article"
  },
  {
    "title": "A Blockchain-empowered Access Control Framework for Smart Devices in Green Internet of Things",
    "doi": "https://doi.org/10.1145/3433542",
    "publication_date": "2021-06-16",
    "publication_year": 2021,
    "authors": "Liang Tan; Na Shi; Keping Yu; Moayad Aloqaily; Yaser Jararweh",
    "corresponding_authors": "",
    "abstract": "Green Internet of things (GIoT) generally refers to a new generation of Internet of things design concept. It can save energy and reduce emissions, reduce environmental pollution, waste of resources, and harm to human body and environment, in which green smart device (GSD) is a basic unit of GIoT for saving energy. With the access of a large number of heterogeneous bottom-layer GSDs in GIoT, user access and control of GSDs have become more and more complicated. Since there is no unified GSD management system, users need to operate different GIoT applications and access different GIoT cloud platforms when accessing and controlling these heterogeneous GSDs. This fragmented GSD management model not only increases the complexity of user access and control for heterogeneous GSDs, but also reduces the scalability of GSDs applications. To address this issue, this article presents a blockchain-empowered general GSD access control framework, which provides users with a unified GSD management platform. First, based on the World Wide Web Consortium (W3C) decentralized identifiers (DIDs) standard, users and GSD are issued visual identity ( VID ). Then, we extended the GSD-DIDs protocol to authenticate devices and users. Finally, based on the characteristics of decentralization and non-tampering of blockchain, a unified access control system for GSD was designed, including the registration, granting, and revoking of access rights. We implement and test on the Raspberry Pi device and the FISCO-BCOS alliance chain. The experimental results prove that the framework provides a unified and feasible way for users to achieve decentralized, lightweight, and fine-grained access control of GSDs. The solution reduces the complexity of accessing and controlling GSDs, enhances the scalability of GSD applications, as well as guarantees the credibility and immutability of permission data and identity data during access.",
    "cited_by_count": 109,
    "openalex_id": "https://openalex.org/W3170888612",
    "type": "article"
  },
  {
    "title": "Things of Interest Recommendation by Leveraging Heterogeneous Relations in the Internet of Things",
    "doi": "https://doi.org/10.1145/2837024",
    "publication_date": "2016-03-30",
    "publication_year": 2016,
    "authors": "Lina Yao; Quan Z. Sheng; Anne H. H. Ngu; Xue Li",
    "corresponding_authors": "",
    "abstract": "The emerging Internet of Things (IoT) bridges the gap between the physical and the digital worlds, which enables a deeper understanding of user preferences and behaviors. The rich interactions and relations between users and things call for effective and efficient recommendation approaches to better meet users’ interests and needs. In this article, we focus on the problem of things recommendation in IoT, which is important for many applications such as e-Commerce and health care. We discuss the new properties of recommending things of interest in IoT, and propose a unified probabilistic factor based framework by fusing relations across heterogeneous entities of IoT, for example, user-thing relations, user-user relations, and thing-thing relations, to make more accurate recommendations. Specifically, we develop a hypergraph to model things’ spatiotemporal correlations, on top of which implicit things correlations can be generated. We have built an IoT testbed to validate our approach and the experimental results demonstrate its feasibility and effectiveness.",
    "cited_by_count": 96,
    "openalex_id": "https://openalex.org/W2318523312",
    "type": "article"
  },
  {
    "title": "Privacy-preserving Federated Deep Learning for Wearable IoT-based Biomedical Monitoring",
    "doi": "https://doi.org/10.1145/3428152",
    "publication_date": "2021-01-05",
    "publication_year": 2021,
    "authors": "Yekta Said Can; Cem Ersoy",
    "corresponding_authors": "",
    "abstract": "IoT devices generate massive amounts of biomedical data with increased digitalization and development of the state-of-the-art automated clinical data collection systems. When combined with advanced machine learning algorithms, the big data could be useful to improve the health systems for decision-making, diagnosis, and treatment. Mental healthcare is also attracting attention, since most medical problems can be associated with mental states. Affective computing is among the emerging biomedical informatics fields for automatically monitoring a person’s mental state in ambulatory environments by using physiological and physical signals. However, although affective computing applications are promising to improve our daily lives, before analyzing physiological signals, privacy issues and concerns need to be dealt with. Federated learning is a promising candidate for developing high-performance models while preserving the privacy of individuals. It is a privacy protection solution that stores model parameters instead of the data itself and abides by the data protection laws such as EU General Data Protection Regulation (GDPR) and California Consumer Privacy Act (CCPA). We applied federated learning to heart activity data collected with smart bands for stress-level monitoring in different events. We achieved encouraging results for using federated learning in IoT-based wearable biomedical monitoring systems by preserving the privacy of the data.",
    "cited_by_count": 96,
    "openalex_id": "https://openalex.org/W3119097278",
    "type": "article"
  },
  {
    "title": "A Simulation-driven Methodology for IoT Data Mining Based on Edge Computing",
    "doi": "https://doi.org/10.1145/3402444",
    "publication_date": "2021-03-08",
    "publication_year": 2021,
    "authors": "Claudio Savaglio; Giancarlo Fortino",
    "corresponding_authors": "",
    "abstract": "With the ever-increasing diffusion of smart devices and Internet of Things (IoT) applications, a completely new set of challenges have been added to the Data Mining domain. Edge Mining and Cloud Mining refer to Data Mining tasks aimed at IoT scenarios and performed according to, respectively, Cloud or Edge computing principles. Given the orthogonality and interdependence among the Data Mining task goals (e.g., accuracy, support, precision), the requirements of IoT applications (mainly bandwidth, energy saving, responsiveness, privacy preserving, and security) and the features of Edge/Cloud deployments (de-centralization, reliability, and ease of management), we propose EdgeMiningSim, a simulation-driven methodology inspired by software engineering principles for enabling IoT Data Mining. Such a methodology drives the domain experts in disclosing actionable knowledge, namely descriptive or predictive models for taking effective actions in the constrained and dynamic IoT scenario. A Smart Monitoring application is instantiated as a case study, aiming to exemplify the EdgeMiningSim approach and to show its benefits in effectively facing all those multifaceted aspects that simultaneously impact on IoT Data Mining.",
    "cited_by_count": 95,
    "openalex_id": "https://openalex.org/W3135594516",
    "type": "article"
  },
  {
    "title": "InFeMo: Flexible Big Data Management Through a Federated Cloud System",
    "doi": "https://doi.org/10.1145/3426972",
    "publication_date": "2021-10-22",
    "publication_year": 2021,
    "authors": "Christos Stergiou; Kostas E. Psannis; Brij B. Gupta",
    "corresponding_authors": "",
    "abstract": "This paper introduces and describes a novel architecture scenario based on Cloud Computing and counts on the innovative model of Federated Learning. The proposed model is named Integrated Federated Model , with the acronym InFeMo . InFeMo incorporates all the existing Cloud models with a federated learning scenario, as well as other related technologies that may have integrated use with each other, offering a novel integrated scenario. In addition to this, the proposed model is motivated to deliver a more energy efficient system architecture and environment for the users, which aims to the scope of data management. Also, by applying the InFeMo the user would have less waiting time in every procedure queue. The proposed system was built on the resources made available by Cloud Service Providers (CSPs) and by using the PaaS (Platform as a Service) model, in order to be able to handle user requests better and faster. This research tries to fill a scientific gap in the field of federated Cloud systems. Thus, taking advantage of the existing scenarios of FedAvg and CO-OP, we were keen to end up with a new federated scenario that merges these two algorithms, and aiming for a more efficient model that is able to select, depending on the occasion, if it “trains” the model locally in client or globally in server.",
    "cited_by_count": 93,
    "openalex_id": "https://openalex.org/W3158613031",
    "type": "article"
  },
  {
    "title": "AI-empowered IoT Security for Smart Cities",
    "doi": "https://doi.org/10.1145/3406115",
    "publication_date": "2021-07-22",
    "publication_year": 2021,
    "authors": "Zhihan Lv; Liang Qiao; Amit Kumar Singh; Qingjun Wang",
    "corresponding_authors": "",
    "abstract": "Smart cities fully utilize the new generation of Internet of Things (IoT) technology in the process of urban informatization to optimize the urban management and service. However, in the IoT system, while information exchange and communication, wireless sensor network devices may not be able to resist all forms of attacks, which may lead to security issues such as user data disclosure. Aiming at the information security risks in smart city, the typical technologies in IoT is analyzed from the perspective of IoT perception layer and provides corresponding security solutions for the existing security threats. Regarding the communication security, the emerging wireless technology, long range (LoRa), is discussed, and the performance of wireless communication protocol is analyzed through simulation experiments, to verify that the IoT technology based on LoRa communication technology can improve the security of the system in the construction of smart city. The results show that REBEB, a new backoff algorithm, is similar to the binary exponential backoff algorithm in terms of throughput performance. REBEB focuses more on fairness, which is up to 0.985, and to a certain extent, its security is significantly improved. The fairness of REBEB algorithm is more than 0.4 in different nodes and competing windows, and the fairness of the system is better when the number of nodes is small. To sum up, the IoT system based on LoRa communication can effectively improve the security performance of the system in the construction of smart city and avoid the security threats in the IoT signal transmission.",
    "cited_by_count": 92,
    "openalex_id": "https://openalex.org/W3185504986",
    "type": "article"
  },
  {
    "title": "Supervised Anomaly Detection in Uncertain Pseudoperiodic Data Streams",
    "doi": "https://doi.org/10.1145/2806890",
    "publication_date": "2016-01-22",
    "publication_year": 2016,
    "authors": "Jiangang Ma; Le Sun; Hua Wang; Yanchun Zhang; Uwe Aickelin",
    "corresponding_authors": "",
    "abstract": "Uncertain data streams have been widely generated in many Web applications. The uncertainty in data streams makes anomaly detection from sensor data streams far more challenging. In this article, we present a novel framework that supports anomaly detection in uncertain data streams. The proposed framework adopts the wavelet soft-thresholding method to remove the noises or errors in data streams. Based on the refined data streams, we develop effective period pattern recognition and feature extraction techniques to improve the computational efficiency. We use classification methods for anomaly detection in the corrected data stream. We also empirically show that the proposed approach shows a high accuracy of anomaly detection on several real datasets.",
    "cited_by_count": 91,
    "openalex_id": "https://openalex.org/W2265638863",
    "type": "article"
  },
  {
    "title": "PrivacyCheck",
    "doi": "https://doi.org/10.1145/3127519",
    "publication_date": "2018-08-07",
    "publication_year": 2018,
    "authors": "Razieh Nokhbeh Zaeem; Rachel L. German; K. Suzanne Barber",
    "corresponding_authors": "",
    "abstract": "Prior research shows that only a tiny percentage of users actually read the online privacy policies they implicitly agree to while using a website. Prior research also suggests that users ignore privacy policies because these policies are lengthy and, on average, require 2 years of college education to comprehend. We propose a novel technique that tackles this problem by automatically extracting summaries of online privacy policies. We use data mining models to analyze the text of privacy policies and answer 10 basic questions concerning the privacy and security of user data, what information is gathered from them, and how this information is used. In order to train the data mining models, we thoroughly study privacy policies of 400 companies (considering 10% of all listings on NYSE, Nasdaq, and AMEX stock markets) across industries. Our free Chrome browser extension, PrivacyCheck, utilizes the data mining models to summarize any HTML page that contains a privacy policy. PrivacyCheck stands out from currently available counterparts because it is readily applicable on any online privacy policy. Cross-validation results show that PrivacyCheck summaries are accurate 40% to 73% of the time. Over 400 independent Chrome users are currently using PrivacyCheck.",
    "cited_by_count": 90,
    "openalex_id": "https://openalex.org/W2885362917",
    "type": "article"
  },
  {
    "title": "Intelligent Intrusion Detection in Low-Power IoTs",
    "doi": "https://doi.org/10.1145/2990499",
    "publication_date": "2016-12-09",
    "publication_year": 2016,
    "authors": "Ahmed Saeed; Ali Ahmadinia; Abbas Javed; Hadi Larijani",
    "corresponding_authors": "",
    "abstract": "Security and privacy of data are one of the prime concerns in today’s Internet of Things (IoT). Conventional security techniques like signature-based detection of malware and regular updates of a signature database are not feasible solutions as they cannot secure such systems effectively, having limited resources. Programming languages permitting immediate memory accesses through pointers often result in applications having memory-related errors, which may lead to unpredictable failures and security vulnerabilities. Furthermore, energy efficient IoT devices running on batteries cannot afford the implementation of cryptography algorithms as such techniques have significant impact on the system power consumption. Therefore, in order to operate IoT in a secure manner, the system must be able to detect and prevent any kind of intrusions before the network (i.e., sensor nodes and base station) is destabilised by the attackers. In this article, we have presented an intrusion detection and prevention mechanism by implementing an intelligent security architecture using random neural networks (RNNs). The application’s source code is also instrumented at compile time in order to detect out-of-bound memory accesses. It is based on creating tags, to be coupled with each memory allocation and then placing additional tag checking instructions for each access made to the memory. To validate the feasibility of the proposed security solution, it is implemented for an existing IoT system and its functionality is practically demonstrated by successfully detecting the presence of any suspicious sensor node within the system operating range and anomalous activity in the base station with an accuracy of 97.23%. Overall, the proposed security solution has presented a minimal performance overhead.",
    "cited_by_count": 89,
    "openalex_id": "https://openalex.org/W2560185016",
    "type": "article"
  },
  {
    "title": "An Experimental Analysis of Security Vulnerabilities in Industrial IoT Devices",
    "doi": "https://doi.org/10.1145/3379542",
    "publication_date": "2020-05-18",
    "publication_year": 2020,
    "authors": "Xingbin Jiang; Michele Lora; Sudipta Chattopadhyay",
    "corresponding_authors": "",
    "abstract": "The revolutionary development of the Internet of Things has triggered a huge demand for Internet of Things devices. They are extensively applied to various fields of social activities, and concerning manufacturing, they are a key enabling concept for the Industry 4.0 ecosystem. Industrial Internet of Things (IIoT) devices share common vulnerabilities with standard IoT devices, which are increasingly exposed to the attackers. As such, connected industrial devices may become sources of cyber, as well as physical, threats for people and assets in industrial environments. In this work, we examine the attack surfaces of a networked embedded system, composed of devices representative of those typically used in the IIoT field. We carry on an analysis of the current state of the security of IIoT technologies. The analysis guides the identification of a set of attack vectors for the examined networked embedded system. We set up the corresponding concrete attack scenarios to gain control of the system actuators and perform some hazardous operations. In particular, we propose a couple of variations of Mirai attack specifically tailored for attacking industrial environments. Finally, we discuss some possible",
    "cited_by_count": 87,
    "openalex_id": "https://openalex.org/W3028311012",
    "type": "article"
  },
  {
    "title": "Concurrent Practical Byzantine Fault Tolerance for Integration of Blockchain and Supply Chain",
    "doi": "https://doi.org/10.1145/3395331",
    "publication_date": "2020-07-07",
    "publication_year": 2020,
    "authors": "Xiaolong Xu; Dawei Zhu; Xiaoxian Yang; Shuo Wang; Lianyong Qi; Wanchun Dou",
    "corresponding_authors": "",
    "abstract": "Currently, the integration of the supply chain and blockchain is promising, as blockchain successfully eliminates the bullwhip effect in the supply chain. Generally, concurrent Practical Byzantine Fault Tolerance (PBFT) consensus method, named C-PBFT, is powerful to deal with the consensus inefficiencies, caused by the fast node expansion in the supply chain. However, due to the tremendous complicated transactions in the supply chain, it remains challenging to select the credible primary peers in the concurrent clusters. To address this challenge, the peers in the supply chain are classified into several clusters by analyzing the historic transactions in the ledger. Then, the primary peer for each cluster is identified by reputation assessment. Finally, the performance of C-PBFT is evaluated by conducting experiments in Fabric.",
    "cited_by_count": 85,
    "openalex_id": "https://openalex.org/W3087287021",
    "type": "article"
  },
  {
    "title": "Detecting Misogyny and Xenophobia in Spanish Tweets Using Language Technologies",
    "doi": "https://doi.org/10.1145/3369869",
    "publication_date": "2020-03-14",
    "publication_year": 2020,
    "authors": "Flor Miriam Plaza-del-Arco; M. Dolores Molina-González; Luís Alfonso Ureña López; María Teresa Martín Valdivia",
    "corresponding_authors": "",
    "abstract": "Today, misogyny and xenophobia are some of the most important social problems. With the increase in the use of social media, this feeling of hatred toward women and immigrants can be more easily expressed, and therefore it can have harmful effects on social media users. For this reason, it is important to develop systems capable of detecting hateful comments automatically. In this article, we analyze the hate speech in Spanish tweets against women and immigrants conducting classification experiments using different approaches. Moreover, we create appropriate language resources for hate speech detection in Spanish.",
    "cited_by_count": 76,
    "openalex_id": "https://openalex.org/W3010933031",
    "type": "article"
  },
  {
    "title": "Investigating the Spread of Coronavirus Disease via Edge-AI and Air Pollution Correlation",
    "doi": "https://doi.org/10.1145/3424222",
    "publication_date": "2021-07-22",
    "publication_year": 2021,
    "authors": "V. Gomathy; K. Janarthanan; Fadi Al‐Turjman; R. Sitharthan; M. Rajesh; K. Vengatesan; T. Priya Reshma",
    "corresponding_authors": "",
    "abstract": "Coronavirus Disease 19 (COVID-19) is a highly infectious viral disease affecting millions of people worldwide in 2020. Several studies have shown that COVID-19 results in a severe acute respiratory syndrome and may lead to death. In past research, a greater number of respiratory diseases has been caused by exposure to air pollution for long periods of time. This article investigates the spread of COVID-19 as a result of air pollution by applying linear regression in machine learning method based edge computing. The analysis in this investigation have been based on the death rates caused by COVID-19 as well as the region of death rates based on hazardous air pollution using data retrieved from the Copernicus Sentinel-5P satellite. The results obtained in the investigation prove that the mortality rate due to the spread of COVID-19 is 77% higher in areas with polluted air. This investigation also proves that COVID-19 severely affected 68% of the individuals who had been exposed to polluted air.",
    "cited_by_count": 74,
    "openalex_id": "https://openalex.org/W3184922128",
    "type": "article"
  },
  {
    "title": "esDNN: Deep Neural Network Based Multivariate Workload Prediction in Cloud Computing Environments",
    "doi": "https://doi.org/10.1145/3524114",
    "publication_date": "2022-03-14",
    "publication_year": 2022,
    "authors": "Minxian Xu; Chenghao Song; Huaming Wu; Sukhpal Singh Gill; Kejiang Ye; Chengzhong Xu",
    "corresponding_authors": "",
    "abstract": "Cloud computing has been regarded as a successful paradigm for IT industry by providing benefits for both service providers and customers. In spite of the advantages, cloud computing also suffers from distinct challenges, and one of them is the inefficient resource provisioning for dynamic workloads. Accurate workload predictions for cloud computing can support efficient resource provisioning and avoid resource wastage. However, due to the high-dimensional and high-variable features of cloud workloads, it is difficult to predict the workloads effectively and accurately. The current dominant work for cloud workload prediction is based on regression approaches or recurrent neural networks, which fail to capture the long-term variance of workloads. To address the challenges and overcome the limitations of existing works, we proposed an e fficient supervised learning-based D eep N eural Network ( esDNN ) approach for cloud workload prediction. First, we utilize a sliding window to convert the multivariate data into a supervised learning time series that allows deep learning for processing. Then, we apply a revised Gated Recurrent Unit (GRU) to achieve accurate prediction. To show the effectiveness of esDNN, we also conduct comprehensive experiments based on realistic traces derived from Alibaba and Google cloud data centers. The experimental results demonstrate that esDNN can accurately and efficiently predict cloud workloads. Compared with the state-of-the-art baselines, esDNN can reduce the mean square errors significantly, e.g., 15%. rather than the approach using GRU only. We also apply esDNN for machines auto-scaling, which illustrates that esDNN can reduce the number of active hosts efficiently, thus the costs of service providers can be optimized.",
    "cited_by_count": 72,
    "openalex_id": "https://openalex.org/W4221005058",
    "type": "article"
  },
  {
    "title": "Sustainable Security for the Internet of Things Using Artificial Intelligence Architectures",
    "doi": "https://doi.org/10.1145/3448614",
    "publication_date": "2021-06-16",
    "publication_year": 2021,
    "authors": "Celestine Iwendi; Saif Ur Rehman; Abdul Rehman Javed; Suleman Khan; Gautam Srivastava",
    "corresponding_authors": "",
    "abstract": "In this digital age, human dependency on technology in various fields has been increasing tremendously. Torrential amounts of different electronic products are being manufactured daily for everyday use. With this advancement in the world of Internet technology, cybersecurity of software and hardware systems are now prerequisites for major business’ operations. Every technology on the market has multiple vulnerabilities that are exploited by hackers and cyber-criminals daily to manipulate data sometimes for malicious purposes. In any system, the Intrusion Detection System (IDS) is a fundamental component for ensuring the security of devices from digital attacks. Recognition of new developing digital threats is getting harder for existing IDS. Furthermore, advanced frameworks are required for IDS to function both efficiently and effectively. The commonly observed cyber-attacks in the business domain include minor attacks used for stealing private data. This article presents a deep learning methodology for detecting cyber-attacks on the Internet of Things using a Long Short Term Networks classifier. Our extensive experimental testing show an Accuracy of 99.09%, F1-score of 99.46%, and Recall of 99.51%, respectively. A detailed metric representing our results in tabular form was used to compare how our model was better than other state-of-the-art models in detecting cyber-attacks with proficiency.",
    "cited_by_count": 68,
    "openalex_id": "https://openalex.org/W3169324926",
    "type": "article"
  },
  {
    "title": "A Mutual Security Authentication Method for RFID-PUF Circuit Based on Deep Learning",
    "doi": "https://doi.org/10.1145/3426968",
    "publication_date": "2021-10-22",
    "publication_year": 2021,
    "authors": "Wei Liang; Songyou Xie; Dafang Zhang; Xiong Li; Kuan‐Ching Li",
    "corresponding_authors": "",
    "abstract": "The Industrial Internet of Things ( IIoT ) is designed to refine and optimize the process controls, thereby leveraging improvements in economic benefits, such as efficiency and productivity. However, the Radio Frequency Identification ( RFID ) technology in an IIoT environment has problems such as low security and high cost. To overcome such issues, a mutual authentication scheme that is suitable for RFID systems, wherein techniques in Deep Learning ( DL ) are incorporated onto the Arbiter Physical Unclonable Function ( APUF ) for the secured access authentication of the IC circuits on the IoT, is proposed. The design applies the APUF-MPUF mutual authentication structure obtained by DL to generate essential real-time authentication information, thereby taking advantage of the feature that the tag in the PUF circuit structure does not need to store any essential information and resolving the problem of key storage. The proposed scheme also uses a bitwise comparison method, which hides the PUF response information and effectively reduces the resource overhead of the system during the verification process, to verify the correctness of the two strings. Security analysis demonstrates that the proposed scheme has high robustness and security against different conventional attack methods, and the storage and communication costs are 95.7% and 42.0% lower than the existing schemes, respectively.",
    "cited_by_count": 66,
    "openalex_id": "https://openalex.org/W3208885160",
    "type": "article"
  },
  {
    "title": "A Supply-chain System Framework Based on Internet of Things Using Blockchain Technology",
    "doi": "https://doi.org/10.1145/3409798",
    "publication_date": "2021-01-29",
    "publication_year": 2021,
    "authors": "Qun Song; Yuhao Chen; Yan Zhong; Kun Lan; Simon Fong; Rui Tang",
    "corresponding_authors": "",
    "abstract": "Numerous supply-chain combines with internet of things (IoT) applications have been proposed, and many methods and algorithms enhance the convenience of supply chains. However, new businesses still find it challenging to enter a supply chain, because unauthorised IoT devices of different companies illegally access resources. As security is paramount in a supply chain, IoT management has become very difficult. Public resources allocation and waste management also pose a problem. To solve the above problems, we proposed a new IoT management framework that embraces blockchain technology to help companies to form a supply chain effectively. This framework consists of an access control system, a backup peer mechanism and an internal data isolation and transmission approach. The access control system has a registrar module and an inspection module. The registrar module is mainly responsible for information registration with a registration policy, which has to be followed by all the companies in the supply chain. Besides, it provides a revocation and updating function. The inspection module focuses on judging misbehaviour and monitors the actions of the subjects; when any misoperation occurs, the system will correspondingly penalise violators. So that all related actions and information are verified and stored into blockchain, the IoT access control and safety of IoT admission are enhanced. Furthermore, in a blockchain system, if one single peer in the network breaks down, then the whole system may stop, because consensus cannot be reached. The data of the broken peer may be lost if it does not commit yet. The backup peer mechanism allows the primary peer and the backup peer to connect to an inspecting server for acquiring real-time data. The internal data isolation and transmission modules transmit and stores private data without creating a new subchannel. The proposed method is taken full account of the stability of the network and the fault tolerance to guarantee the robust of the system. To obtain unbiases results, experiments are conducted in two different blockchain environment. The results show our proposed method are promising IoT blockchain system for the supply chain.",
    "cited_by_count": 65,
    "openalex_id": "https://openalex.org/W3126854539",
    "type": "article"
  },
  {
    "title": "Pre-Trained Convolutional Neural Networks for Breast Cancer Detection Using Ultrasound Images",
    "doi": "https://doi.org/10.1145/3418355",
    "publication_date": "2021-07-16",
    "publication_year": 2021,
    "authors": "Mehedi Masud; M. Shamim Hossain; Hesham Alhumyani; Sultan S. Alshamrani; Omar Cheikhrouhou; Saleh Ibrahim; Ghulam Muhammad; Amr E. Eldin Rashed; Brij B. Gupta",
    "corresponding_authors": "",
    "abstract": "Volunteer computing based data processing is a new trend in healthcare applications. Researchers are now leveraging volunteer computing power to train deep learning networks consisting of billions of parameters. Breast cancer is the second most common cause of death in women among cancers. The early detection of cancer may diminish the death risk of patients. Since the diagnosis of breast cancer manually takes lengthy time and there is a scarcity of detection systems, development of an automatic diagnosis system is needed for early detection of cancer. Machine learning models are now widely used for cancer detection and prediction research for improving the successive therapy of patients. Considering this need, this study implements pre-trained convolutional neural network based models for detecting breast cancer using ultrasound images. In particular, we tuned the pre-trained models for extracting key features from ultrasound images and included a classifier on the top layer. We measured accuracy of seven popular state-of-the-art pre-trained models using different optimizers and hyper-parameters through fivefold cross validation. Moreover, we consider Grad-CAM and occlusion mapping techniques to examine how well the models extract key features from the ultrasound images to detect cancers. We observe that after fine tuning, DenseNet201 and ResNet50 show 100% accuracy with Adam and RMSprop optimizers. VGG16 shows 100% accuracy using the Stochastic Gradient Descent optimizer. We also develop a custom convolutional neural network model with a smaller number of layers compared to large layers in the pre-trained models. The model also shows 100% accuracy using the Adam optimizer in classifying healthy and breast cancer patients. It is our belief that the model will assist healthcare experts with improved and faster patient screening and pave a way to further breast cancer research.",
    "cited_by_count": 65,
    "openalex_id": "https://openalex.org/W3185855491",
    "type": "article"
  },
  {
    "title": "Web of Digital Twins",
    "doi": "https://doi.org/10.1145/3507909",
    "publication_date": "2022-02-03",
    "publication_year": 2022,
    "authors": "Alessandro Ricci; Angelo Croatti; Stefano Mariani; Sara Montagna; Marco Picone",
    "corresponding_authors": "",
    "abstract": "In recent years, digital twins have been pervading different application domains—from manufacturing to healthcare—as an approach for virtualising different kinds of physical entities (things, products, machines). The dominant view developed in the literature so far is about the virtualisation of individual physical assets in a closed-system perspective. In this article, we introduce and explore a broader perspective that we call Web of Digital Twins (WoDT), in which the digital twin paradigm is exploited for the pervasive softwarisation of possibly large-scale interrelated physical realities. A WoDT can be conceived as an open, distributed and dynamic ecosystem of connected digital twins, functioning as an interoperable service-oriented layer for applications running on top, especially smart applications and multiagent systems. The article introduces an abstract model and architecture aimed to capture key aspects of the idea not bound to any specific application domains or implementing technologies and discusses their adoption in engineering real-world systems. To this purpose, two concrete case studies are considered, in the context of healthcare and smart mobility. Finally, the article includes a discussion of a selected set of research directions.",
    "cited_by_count": 65,
    "openalex_id": "https://openalex.org/W4210446628",
    "type": "article"
  },
  {
    "title": "Data Dissemination for Industry 4.0 Applications in Internet of Vehicles Based on Short-term Traffic Prediction",
    "doi": "https://doi.org/10.1145/3430505",
    "publication_date": "2021-10-25",
    "publication_year": 2021,
    "authors": "Chen Chen; Lei Liu; Shaohua Wan; Xiaozhe Hui; Qingqi Pei",
    "corresponding_authors": "",
    "abstract": "As a key use case of Industry 4.0 and the Smart City, the Internet of Vehicles (IoV) provides an efficient way for city managers to regulate the traffic flow, improve the commuting performance, reduce the transportation facility cost, alleviate the traffic jam, and so on. In fact, the significant development of Internet of Vehicles has boosted the emergence of a variety of Industry 4.0 applications, e.g., smart logistics, intelligent transforation, and autonomous driving. The prerequisite of deploying these applications is the design of efficient data dissemination schemes by which the interactive information could be effectively exchanged. However, in Internet of Vehicles, an efficient data scheme should adapt to the high node movement and frequent network changing. To achieve the objective, the ability to predict short-term traffic is crucial for making optimal policy in advance. In this article, we propose a novel data dissemination scheme by exploring short-term traffic prediction for Industry 4.0 applications enabled in Internet of Vehicles. First, we present a three-tier network architecture with the aim to simply network management and reduce communication overheads. To capture dynamic network changing, a deep learning network is employed by the controller in this architecture to predict short-term traffic with the availability of enormous traffic data. Based on the traffic prediction, each road segment can be assigned a weight through the built two-dimensional delay model, enabling the controller to make routing decisions in advance. With the global weight information, the controller leverages the ant colony optimization algorithm to find the optimal routing path with minimum delay. Extensive simulations are carried out to demonstrate the accuracy of the traffic prediction model and the superiority of the proposed data dissemination scheme for Industry 4.0 applications.",
    "cited_by_count": 64,
    "openalex_id": "https://openalex.org/W3210170961",
    "type": "article"
  },
  {
    "title": "A Blockchain-Based Access Control Scheme for Zero Trust Cross-Organizational Data Sharing",
    "doi": "https://doi.org/10.1145/3511899",
    "publication_date": "2022-07-18",
    "publication_year": 2022,
    "authors": "Keke Gai; Yufeng She; Liehuang Zhu; Kim‐Kwang Raymond Choo; Zhiguo Wan",
    "corresponding_authors": "",
    "abstract": "Multi-organization data sharing is becoming increasingly prevalent due to the interconnectivity of systems and the need for collaboration across organizations (e.g., exchange of data in a supply chain involving multiple upstream and downstream vendors). There are, however, data security concerns due to lack of trust between organizations that may be located in jurisdictions with varying security and privacy legislation and culture (also referred to as a zero trust environment). Hence, in such a zero trust setting, one should introduce strengthened, yet efficient, access control mechanisms to facilitate cross-organizational data access and exchange requests. Contemporary access control schemes generally focus on protecting a single objective rather than multiple parties, due to higher security costs. In this article, we propose a blockchain-based access control scheme, designed to facilitate lightweight data sharing among different organizations. Specifically, our approach utilizes the consortium blockchain to establish a trustworthy environment, in which a Role-Based Access Control (RBAC) model is then deployed using our proposed multi-signature protocol and smart contract methods. Evaluation of our proposed approach is performed on the HyperLedger Fabric consortium blockchain platform using both Caliper and BFT-SMaRT benchmarks, and the findings demonstrate the utility of our approach.",
    "cited_by_count": 59,
    "openalex_id": "https://openalex.org/W4285727657",
    "type": "article"
  },
  {
    "title": "Digital Twin of Intelligent Small Surface Defect Detection with Cyber-manufacturing Systems",
    "doi": "https://doi.org/10.1145/3571734",
    "publication_date": "2022-11-17",
    "publication_year": 2022,
    "authors": "Yirui Wu; Hao Cao; Guoqiang Yang; Tong Lü; Shaohua Wan",
    "corresponding_authors": "",
    "abstract": "With the remarkable technological development in cyber-physical systems, industry 4.0 has evolved by use of a significant concept named digital twin (DT). However, it is still difficult to construct a relationship between twin simulation and a real scenario considering dynamic variations, especially when dealing with small surface defect detection tasks with high performance and computation resource requirements. In this article, we aim to construct cyber-manufacturing systems to achieve a DT solution for small surface defect detection task. Focusing on DT-based solution, the proposed system consists of an Edge–Cloud architecture and a surface defect detection algorithm. Considering dynamic characteristics and real-time response requirement, Edge–Cloud architecture is built to achieve smart manufacturing by efficiently collecting, processing, analyzing, and storing data produced by factory. A deep learning–based algorithm is then constructed to detect surface defeats based on multi-modal data, i.e., imaging and depth data. Experiments show the proposed algorithm could achieve high accuracy and recall in small defeat detection task, thus constructing DT in cyber-manufacturing.",
    "cited_by_count": 57,
    "openalex_id": "https://openalex.org/W4309617247",
    "type": "article"
  },
  {
    "title": "BACKM-EHA: A Novel Blockchain-enabled Security Solution for IoMT-based E-healthcare Applications",
    "doi": "https://doi.org/10.1145/3511898",
    "publication_date": "2022-03-25",
    "publication_year": 2022,
    "authors": "Mohammad Wazid; Prosanta Gope",
    "corresponding_authors": "",
    "abstract": "E-health is the use of information and communication technology (ICT) for the healthcare-related services. It uses various types of digital technologies and telecommunications, such as computers, sensing devices, Internet, and mobile devices to deliver medical services. Internet of Medical Things (IoMT) is a communication environment optimized for low-power devices (for example, health sensors and actuators) and operation on, in, or around the human body (i.e., a patient). It can be used in various applications that are related to healthcare, such as “body automation,” “healthcare,” “medical monitoring,” “body interaction,” and “medical implants (i.e., pacemaker).” Most of the communications happen in IoMT-based e-healthcare system are wireless in nature. This may cause severe threats to the security of the system. Various information security-related attacks, i.e., replay, man-in-the-middle attack (MiTM), impersonation, privileged insider, unauthorised session key computation, credentials leakage, stolen verifier, malware injection are possible in IoMT-based e-healthcare system. These threats and attacks can create serious problems in the social life of an individual, as this may reveal their confidential healthcare information to other unauthorised parties. Therefore, it is essential to propose an access control and key management scheme to secure the communication of a IoMT-based e-healthcare system. Moreover, the security of such kind of scheme can also be enhanced through the deployment of a blockchain mechanism. Therefore, in this article, we propose a blockchain-enabled access control and key management protocol for IoMT-based e-healthcare system that is named as “BACKM-EHA” in short. The security analysis of proposed BACKM-EHA is also provided through the standard, i.e., “Real-Or-Random model.” The various conducted security analyses prove the security of BACKM-EHA against the different types of potential attacks. The performance of BACKM-EHA is better than the other existing schemes, as it requires less communication cost, computation cost, and provides more “security and functionality features.”",
    "cited_by_count": 51,
    "openalex_id": "https://openalex.org/W4221046479",
    "type": "article"
  },
  {
    "title": "Tolerance Analysis of Cyber-Manufacturing Systems to Cascading Failures",
    "doi": "https://doi.org/10.1145/3579847",
    "publication_date": "2023-01-12",
    "publication_year": 2023,
    "authors": "Xiuwen Fu; Pasquale Pace; Gianluca Aloi; Antonio Guerrieri; Wenfeng Li; Giancarlo Fortino",
    "corresponding_authors": "",
    "abstract": "In practical cyber-manufacturing systems (CMS), the node component is the forwarder of information and the provider of services. This dual role makes the whole system have the typical physical-services interaction characteristic, making CMS more vulnerable to cascading failures than general manufacturing systems. In this work, in order to reasonably characterize the cascading process of CMS, we first develop an interdependent network model for CMS from a physical-service networking perspective. On this basis, a realistic cascading failure model for CMS is designed with full consideration of the routing-oriented load distribution characteristics of the physical network and selective load distribution characteristics of the service network. Through extensive experiments, the soundness of the proposed model has been verified and some meaningful findings have been obtained: (1) attacks on the physical network are more likely to trigger cascading failures and may cause more damage; (2) interdependency failures are the main cause of performance degradation in the service network during cascading failures; and (3) isolation failures are the main cause of performance degradation in the physical network during cascading failures. The obtained results can certainly help users to design a more reliable CMS against cascading failures.",
    "cited_by_count": 47,
    "openalex_id": "https://openalex.org/W4315779569",
    "type": "article"
  },
  {
    "title": "Towards Human-AI Teaming to Mitigate Alert Fatigue in Security Operations Centres",
    "doi": "https://doi.org/10.1145/3670009",
    "publication_date": "2024-05-30",
    "publication_year": 2024,
    "authors": "Mohan Baruwal Chhetri; Shahroz Tariq; Ronal Singh; Fatemeh Jalalvand; Cécile Paris; ‪Surya Nepal‬",
    "corresponding_authors": "",
    "abstract": "Security Operations Centres (SOCs) play a pivotal role in defending organisations against evolving cyber threats. They function as central hubs for detecting, analysing, and responding promptly to cyber incidents with the primary objective of ensuring the confidentiality, integrity, and availability of digital assets. However, they struggle against the growing problem of alert fatigue, where the sheer volume of alerts overwhelms SOC analysts and raises the risk of overlooking critical threats. In recent times, there has been a growing call for human-AI teaming, wherein humans and AI collaborate with each other, leveraging their complementary strengths and compensating for their weaknesses. The rapid advances in AI and the growing integration of AI-enabled tools and technologies within SOCs give rise to a compelling argument for the implementation of human-AI teaming within the SOC environment. Therefore, in this article, we present our vision for human-AI teaming to address the problem of alert fatigue in the SOC. We propose the 𝒜 2 𝒞 Framework, which enables flexible and dynamic decision making by allowing seamless transitions between automated, augmented, and collaborative modes of operation. Our framework allows AI-powered automation for routine alerts, AI-driven augmentation for expedited expert decision making, and collaborative exploration for tackling complex, novel threats. By implementing and operationalising 𝒜 2 𝒞, SOCs can significantly reduce alert fatigue while empowering analysts to efficiently and effectively respond to security incidents.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W4399187206",
    "type": "article"
  },
  {
    "title": "Location management for mobile commerce applications in wireless Internet environment",
    "doi": "https://doi.org/10.1145/857166.857169",
    "publication_date": "2003-08-01",
    "publication_year": 2003,
    "authors": "Upkar Varshney",
    "corresponding_authors": "Upkar Varshney",
    "abstract": "With recent advances in devices, middleware, applications and networking infrastructure, the wireless Internet is becoming a reality. We believe that some of the major drivers of the wireless Internet will be emerging mobile applications such as mobile commerce. Although many of these are futuristic, some applications including user-and location-specific mobile advertising, location-based services, and mobile financial services are beginning to be commercialized. Mobile commerce applications present several interesting and complex challenges including location management of products, services, devices, and people. Further, these applications have fairly diverse requirements from the underlying wireless infrastructure in terms of location accuracy, response time, multicast support, transaction frequency and duration, and dependability. Therefore, research is necessary to address these important and complex challenges. In this article, we present an integrated location management architecture to support the diverse location requirements of m-commerce applications. The proposed architecture is capable of supporting a range of location accuracies, wider network coverage, wireless multicast, and infrastructure dependability for m-commerce applications. The proposed architecture can also support several emerging mobile applications. Additionally, several interesting research problems and directions in location management for wireless Internet applications are presented and discussed.",
    "cited_by_count": 180,
    "openalex_id": "https://openalex.org/W1991534497",
    "type": "article"
  },
  {
    "title": "Self-similarity in the web",
    "doi": "https://doi.org/10.1145/572326.572328",
    "publication_date": "2002-08-01",
    "publication_year": 2002,
    "authors": "Stephen Dill; Ravi Kumar; Kevin S. McCurley; Sridhar Rajagopalan; D. Sivakumar; Andrew Tomkins",
    "corresponding_authors": "",
    "abstract": "Algorithmic tools for searching and mining the Web are becoming increasingly sophisticated and vital. In this context, algorithms that use and exploit structural information about the Web perform better than generic methods in both efficiency and reliability.We present an extensive characterization of the graph structure of the Web, with a view to enabling high-performance applications that make use of this structure. In particular, we show that the Web emerges as the outcome of a number of essentially independent stochastic processes that evolve at various scales. A striking consequence of this scale invariance is that the structure of the Web is \"fractal\"---cohesive subregions display the same characteristics as the Web at large. An understanding of this underlying fractal nature is therefore applicable to designing data services across multiple domains and scales.We describe potential applications of this line of research to optimized algorithm design for Web-scale data analysis.",
    "cited_by_count": 178,
    "openalex_id": "https://openalex.org/W2089800021",
    "type": "article"
  },
  {
    "title": "Privacy through pseudonymity in user-adaptive systems",
    "doi": "https://doi.org/10.1145/767193.767196",
    "publication_date": "2003-05-01",
    "publication_year": 2003,
    "authors": "Alfred Kobsa; Jörg Schreck",
    "corresponding_authors": "",
    "abstract": "User-adaptive applications cater to the needs of each individual computer user, taking for example users' interests, level of expertise, preferences, perceptual and motoric abilities, and the usage environment into account. Central user modeling servers collect and process the information about users that different user-adaptive systems require to personalize their user interaction.Adaptive systems are generally better able to cater to users the more data their user modeling systems collect and process about them. They therefore gather as much data as possible and \"lay them in stock\" for possible future usage. Moreover, data collection usually takes place without users' initiative and sometimes even without their awareness, in order not to cause distraction. Both is in conflict with users' privacy concerns that became manifest in numerous recent consumer polls, and with data protection laws and guidelines that call for parsimony, purpose-orientation, and user notification or user consent when personal data are collected and processed.This article discusses security requirements to guarantee privacy in user-adaptive systems and explores ways to keep users anonymous while fully preserving personalized interaction with them. User anonymization in personalized systems goes beyond current models in that not only users must remain anonymous, but also the user modeling system that maintains their personal data. Moreover, users' trust in anonymity can be expected to lead to more extensive and frank interaction, hence to more and better data about the user, and thus to better personalization. A reference model for pseudonymous and secure user modeling is presented that meets many of the proposed requirements.",
    "cited_by_count": 166,
    "openalex_id": "https://openalex.org/W1995006095",
    "type": "article"
  },
  {
    "title": "Characterizing the scalability of a large web-based shopping system",
    "doi": "https://doi.org/10.1145/383034.383036",
    "publication_date": "2001-08-01",
    "publication_year": 2001,
    "authors": "Martin Arlitt; Diwakar Krishnamurthy; Jerry Rolia",
    "corresponding_authors": "",
    "abstract": "This article presents an analysis of five days of workload data from a large Web-based shopping system. The multitier environment of this Web-based shopping system includes Web servers, application servers, database servers, and an assortment of load-balancing and firewall appliances. We characterize user requests and sessions and determine their impact on system performance scalability. The purpose of our study is to assess scalability and support capacity planning exercises for the multitier system. We find that horizontal scalability is not always an adequate mechanism for supporting increased workloads and that personalization and robots can have a significant impact on system scalability.",
    "cited_by_count": 164,
    "openalex_id": "https://openalex.org/W2008427707",
    "type": "article"
  },
  {
    "title": "HTTP Cookies",
    "doi": "https://doi.org/10.1145/502152.502153",
    "publication_date": "2001-11-01",
    "publication_year": 2001,
    "authors": "David M. Kristol",
    "corresponding_authors": "David M. Kristol",
    "abstract": "How did we get from a world where cookies were something you ate and where \"nontechies\" were unaware of \"Netscape cookies\" to a world where cookies are a hot-button privacy issue for many computer users? This article describes how HTTP \"cookies\" work and how Netscape's original specification evolved into an IETF Proposed Standard. I also offer a personal perspective on how what began as a straightforward technical specification turned into a political flashpoint when it tried to address nontechnical issues such as privacy.",
    "cited_by_count": 161,
    "openalex_id": "https://openalex.org/W1973556911",
    "type": "article"
  },
  {
    "title": "Online information disclosure",
    "doi": "https://doi.org/10.1145/1183463.1183467",
    "publication_date": "2006-11-01",
    "publication_year": 2006,
    "authors": "Kai-Lung Hui; Bernard C. Y. Tan; Chyan-Yee Goh",
    "corresponding_authors": "",
    "abstract": "To increase their revenue from electronic commerce, more and more Internet businesses are soliciting personal information from consumers in order to target products and services at the right consumers. But when deciding whether to disclose their personal information to Internet businesses, consumers may weigh the concerns of giving up information privacy against the benefits of information disclosure. This article examines how Internet businesses can motivate consumers to disclose their personal information. Based on a synthesis of the literature, the article identifies seven types of extrinsic or intrinsic benefits that Internet businesses can provide when soliciting personal information from consumers. Through comprehensive conceptual and empirical validation processes, the article develops an instrument that allows Internet businesses to gauge the preference of consumers for the various types of benefits. By testing a set of nomological networks, some ideas are presented to Internet businesses about what types of benefits may be more effective given the personality traits of particular consumer populations. Besides providing a foundation for efforts aimed at developing theories on information, privacy and information disclosure, the results of this research provide useful suggestions to Internet businesses on how best to solicit personal information from consumers. Implications for research and practical application are discussed.",
    "cited_by_count": 157,
    "openalex_id": "https://openalex.org/W2014471472",
    "type": "article"
  },
  {
    "title": "Web servers under overload",
    "doi": "https://doi.org/10.1145/1125274.1125276",
    "publication_date": "2006-02-01",
    "publication_year": 2006,
    "authors": "Bianca Schroeder; Mor Harchol‐Balter",
    "corresponding_authors": "",
    "abstract": "This article provides a detailed implementation study on the behavior of web serves that serve static requests where the load fluctuates over time (transient overload). Various external factors are considered, including WAN delays and losses and different client behavior models. We find that performance can be dramatically improved via a kernel-level modification to the web server to change the scheduling policy at the server from the standard FAIR (processor-sharing) scheduling to SRPT (shortest-remaining-processing-time) scheduling. We find that SRPT scheduling induces no penalties. In particular, throughput is not sacrificed and requests for long files experience only negligibly higher response times under SRPT than they did under the original FAIR scheduling.",
    "cited_by_count": 144,
    "openalex_id": "https://openalex.org/W1986166139",
    "type": "article"
  },
  {
    "title": "Conformance checking of service behavior",
    "doi": "https://doi.org/10.1145/1361186.1361189",
    "publication_date": "2008-05-01",
    "publication_year": 2008,
    "authors": "Wil M. P. van der Aalst; Marlon Dumas; Chun Ouyang; A. Rozinat; Eric Verbeek",
    "corresponding_authors": "",
    "abstract": "A service-oriented system is composed of independent software units, namely services, that interact with one another exclusively through message exchanges. The proper functioning of such system depends on whether or not each individual service behaves as the other services expect it to behave. Since services may be developed and operated independently, it is unrealistic to assume that this is always the case. This article addresses the problem of checking and quantifying how much the actual behavior of a service, as recorded in message logs, conforms to the expected behavior as specified in a process model. We consider the case where the expected behavior is defined using the BPEL industry standard (Business Process Execution Language for Web Services). BPEL process definitions are translated into Petri nets and Petri net-based conformance checking techniques are applied to derive two complementary indicators of conformance: fitness and appropriateness . The approach has been implemented in a toolset for business process analysis and mining, namely ProM, and has been tested in an environment comprising multiple Oracle BPEL servers.",
    "cited_by_count": 137,
    "openalex_id": "https://openalex.org/W2070239227",
    "type": "article"
  },
  {
    "title": "Provisioning servers in the application tier for e-commerce systems",
    "doi": "https://doi.org/10.1145/1189740.1189747",
    "publication_date": "2007-02-01",
    "publication_year": 2007,
    "authors": "Daniel Antunes Maciel Villela; Prashant Pradhan; Dan Rubenstein",
    "corresponding_authors": "",
    "abstract": "Server providers that support e-commerce applications as a service for multiple e-commerce Web sites traditionally use a tiered server architecture. This architecture includes an application tier to process requests for dynamically generated content. How this tier is provisioned can significantly impact a provider's profit margin. In this article we study methods to provision servers in the application serving tier that increase a server provider's profits. First, we examine actual traces of request arrivals to the application tier of an e-commerce site, and show that the arrival process is effectively Poisson. Next, we construct an optimization problem in the context of a set of application servers modeled as M / G /1/ PS queueing systems, and derive three simple methods that approximate the allocation that maximizes profits. Simulation results demonstrate that our approximation methods achieve profits that are close to optimal, and are significantly higher than those achieved via simple heuristics.",
    "cited_by_count": 118,
    "openalex_id": "https://openalex.org/W2018802579",
    "type": "article"
  },
  {
    "title": "Model-driven design and deployment of service-enabled web applications",
    "doi": "https://doi.org/10.1145/1084772.1084773",
    "publication_date": "2005-08-01",
    "publication_year": 2005,
    "authors": "Ioana Manolescu; Marco Brambilla; Stefano Ceri; Sara Comai; Piero Fraternali",
    "corresponding_authors": "",
    "abstract": "Significant effort is currently invested in application integration, enabling business processes of different companies to interact and form complex multiparty processes. Web service standards, based on WSDL (Web Service Definition Language), have been adopted as process-to-process communication paradigms. However, the conceptual modeling of applications using Web services has not yet been addressed. Interaction with Web services is often specified at the level of the source code; thus, Web service interfaces are buried within a programmatic specification.In this article, we argue that Web services should be considered first-class citizens in the specification of Web applications. Thus, service-enabled Web applications should benefit from the high-level modeling and automatic code generation techniques that have long been advocated for Web application design and implementation. To this end, we extend a declarative model for specifying data-intensive Web applications in two directions: (i) high-level modeling of Web services and their interactions with the Web applications which use them, and (ii) modeling and specification of Web applications implementing new, complex Web services.Our approach is fully implemented within a CASE tool allowing the high-level modeling and automatic deployment of service-enabled Web applications.",
    "cited_by_count": 118,
    "openalex_id": "https://openalex.org/W2170418117",
    "type": "article"
  },
  {
    "title": "Web service clustering using multidimensional angles as proximity measures",
    "doi": "https://doi.org/10.1145/1552291.1552294",
    "publication_date": "2009-07-01",
    "publication_year": 2009,
    "authors": "Christian Platzer; Florian Rosenberg; Schahram Dustdar",
    "corresponding_authors": "",
    "abstract": "Increasingly, application developers seek the ability to search for existing Web services within large Internet-based repositories. The goal is to retrieve services that match the user's requirements. With the growing number of services in the repositories and the challenges of quickly finding the right ones, the need for clustering related services becomes evident to enhance search engine results with a list of similar services for each hit. In this article, a statistical clustering approach is presented that enhances an existing distributed vector space search engine for Web services with the possibility of dynamically calculating clusters of similar services for each hit in the list found by the search engine. The focus is laid on a very efficient and scalable clustering implementation that can handle very large service repositories. The evaluation with a large service repository demonstrates the feasibility and performance of the approach.",
    "cited_by_count": 110,
    "openalex_id": "https://openalex.org/W1993332216",
    "type": "article"
  },
  {
    "title": "A context-based mediation approach to compose semantic Web services",
    "doi": "https://doi.org/10.1145/1294148.1294152",
    "publication_date": "2007-11-01",
    "publication_year": 2007,
    "authors": "Michaël Mrissa; Chirine Ghédira; Djamal Benslimane; Zakaria Maamar; Florian Rosenberg; Schahram Dustdar",
    "corresponding_authors": "",
    "abstract": "Web services composition is a keystone in the development of interoperable systems. However, despite the widespread adoption of Web services, several obstacles still hinder their smooth automatic semantic reconciliation when being composed. Consistent understanding of data exchanged between composed Web services is hampered by various implicit modeling assumptions and representations. Our contribution in this article revolves around context and how it enriches data exchange between Web services. In particular, a context-based mediation approach to solve semantic heterogeneities between composed Web services is presented.",
    "cited_by_count": 108,
    "openalex_id": "https://openalex.org/W1981607177",
    "type": "article"
  },
  {
    "title": "Design and implementation trade-offs for wide-area resource discovery",
    "doi": "https://doi.org/10.1145/1391949.1391952",
    "publication_date": "2008-09-01",
    "publication_year": 2008,
    "authors": "Jeannie Albrecht; David Oppenheimer; Amin Vahdat; David A. Patterson",
    "corresponding_authors": "",
    "abstract": "We describe the design and implementation of SWORD, a scalable resource discovery service for wide-area distributed systems. In contrast to previous systems, SWORD allows users to describe desired resources as a topology of interconnected groups with required intragroup, intergroup, and per-node characteristics, along with the utility that the application derives from specified ranges of metric values. This design gives users the flexibility to find geographically distributed resources for applications that are sensitive to both node and network characteristics, and allows the system to rank acceptable configurations based on their quality for that application. Rather than evaluating a single implementation of SWORD, we explore a variety of architectural designs that deliver the required functionality in a scalable and highly available manner. We discuss the trade-offs of using a centralized architecture as compared to a fully decentralized design to perform wide-area resource discovery. To summarize our results, we found that a centralized architecture based on 4-node server cluster sites at network-peering facilities outperforms a decentralized DHT-based resource discovery infrastructure with respect to query latency for all but the smallest number of sites. However, although a centralized architecture shows significant promise in stable environments, we find that our decentralized implementation has acceptable performance and also benefits from the DHT's self-healing properties in more volatile environments. We evaluate the advantages and disadvantages of centralized and distributed resource discovery architectures on 1000 hosts in emulation and on approximately 200 PlanetLab nodes spread across the Internet.",
    "cited_by_count": 107,
    "openalex_id": "https://openalex.org/W2011018751",
    "type": "article"
  },
  {
    "title": "Characterization of national Web domains",
    "doi": "https://doi.org/10.1145/1239971.1239973",
    "publication_date": "2007-05-01",
    "publication_year": 2007,
    "authors": "Ricardo Baeza‐Yates; Carlos Castillo; Efthimis N. Efthimiadis",
    "corresponding_authors": "",
    "abstract": "During the last few years, several studies on the characterization of the public Web space of various national domains have been published. The pages of a country are an interesting set for studying the characteristics of the Web because at the same time these are diverse (as they are written by several authors) and yet rather similar (as they share a common geographical, historical and cultural context). This article discusses the methodologies used for presenting the results of Web characterization studies, including the granularity at which different aspects are presented, and a separation of concerns between contents, links, and technologies. Based on this, we present a side-by-side comparison of the results of 12 Web characterization studies, comprising over 120 million pages from 24 countries. The comparison unveils similarities and differences between the collections and sheds light on how certain results of a single Web characterization study on a sample may be valid in the context of the full Web.",
    "cited_by_count": 106,
    "openalex_id": "https://openalex.org/W1999478104",
    "type": "article"
  },
  {
    "title": "Resource space model, OWL and database",
    "doi": "https://doi.org/10.1145/1391949.1391954",
    "publication_date": "2008-09-01",
    "publication_year": 2008,
    "authors": "Hai Zhuge; Yunpeng Xing; Peng Shi",
    "corresponding_authors": "",
    "abstract": "Semantics exhibits diversity in the real world, mental abstraction world, document world, and machine world. Studying mappings between different forms of semantics helps unveil the uniformity in the diversity. This article investigates the mappings between three typical semantic models: the Web ontology language (OWL), relational database model, and resource space model (a classification-based semantic model). By establishing mappings between the semantic primitives of the three models, we study the mapping from OWL description onto resource space and analyze the normal forms of the generated resource space. Mapping back from resource space onto OWL description is then discussed. Further, we investigate the mapping between OWL description and relational database, as well as the mapping between relational database and resource space. Normal forms of the generated relational tables are analyzed. To support advanced applications on the future Web, we suggest integrating the resource space, OWL, and databases to form a powerful semantic platform that enables different semantic models to enhance each other.",
    "cited_by_count": 102,
    "openalex_id": "https://openalex.org/W2006320931",
    "type": "article"
  },
  {
    "title": "Security and identification indicators for browsers against spoofing and phishing attacks",
    "doi": "https://doi.org/10.1145/1391949.1391950",
    "publication_date": "2008-09-01",
    "publication_year": 2008,
    "authors": "Amir Herzberg; Ahmad Jbara",
    "corresponding_authors": "",
    "abstract": "In spite of the use of standard Web security measures (SSL/TLS), users enter sensitive information such as passwords into fake Web sites. Such fake sites cause substantial damages to individuals and corporations. In this work, we identify several vulnerabilities of browsers, focusing on security and identification indicators. We present improved security and identification indicators, as we implemented in TrustBar, a browser extension we developed. With TrustBar, users can assign a name or logo to identify SSL/TLS-protected sites; if users did not assign a name or logo, TrustBar identifies protected sites by the name or logo of the site, and by the certificate authority (CA) who identified the site. We present usability experiments which compared TrustBar's indicators to the basic indicators available in most browsers (padlock, URL, and https prefix), and some relevant secure-usability principles.",
    "cited_by_count": 102,
    "openalex_id": "https://openalex.org/W2150326939",
    "type": "article"
  },
  {
    "title": "Detecting visually similar Web pages",
    "doi": "https://doi.org/10.1145/1754393.1754394",
    "publication_date": "2010-05-01",
    "publication_year": 2010,
    "authors": "Teh-Chung Chen; Scott Dick; James Miller",
    "corresponding_authors": "",
    "abstract": "We propose a novel approach for detecting visual similarity between two Web pages. The proposed approach applies Gestalt theory and considers a Web page as a single indivisible entity. The concept of supersignals, as a realization of Gestalt principles, supports our contention that Web pages must be treated as indivisible entities. We objectify, and directly compare, these indivisible supersignals using algorithmic complexity theory. We illustrate our approach by applying it to the problem of detecting phishing scams. Via a large-scale, real-world case study, we demonstrate that 1) our approach effectively detects similar Web pages; and 2) it accuractely distinguishes legitimate and phishing pages.",
    "cited_by_count": 99,
    "openalex_id": "https://openalex.org/W2025635041",
    "type": "article"
  },
  {
    "title": "Using probabilistic confidence models for trust inference in Web-based social networks",
    "doi": "https://doi.org/10.1145/1754393.1754397",
    "publication_date": "2010-05-01",
    "publication_year": 2010,
    "authors": "Ugur Kuter; Jennifer Golbeck",
    "corresponding_authors": "",
    "abstract": "In this article, we describe a new approach that gives an explicit probabilistic interpretation for social networks. In particular, we focus on the observation that many existing Web-based trust-inference algorithms conflate the notions of “trust” and “confidence,” and treat the amalgamation of the two concepts to compute the trust value associated with a social relationship. Unfortunately, the result of such an algorithm that merges trust and confidence is not a trust value, but rather a new variable in the inference process. Thus, it is hard to evaluate the outputs of such an algorithm in the context of trust inference. This article first describes a formal probabilistic network model for social networks that allows us to address that issue. Then we describe SUNNY, a new trust inference algorithm that uses probabilistic sampling to separately estimate trust information and our confidence in the trust estimate and use the two values in order to compute an estimate of trust based on only those information sources with the highest confidence estimates. We present an experimental evaluation of SUNNY. In our experiments, SUNNY produced more accurate trust estimates than the well-known trust inference algorithm TidalTrust, demonstrating its effectiveness. Finally, we discuss the implications these results will have on systems designed for personalizing content and making recommendations.",
    "cited_by_count": 97,
    "openalex_id": "https://openalex.org/W2017992786",
    "type": "article"
  },
  {
    "title": "A Multimedia Recommender System",
    "doi": "https://doi.org/10.1145/2532640",
    "publication_date": "2013-11-01",
    "publication_year": 2013,
    "authors": "Massimiliano Albanese; Antonio d’Acierno; Vincenzo Moscato; Fabio Persia; Antonio Picariello",
    "corresponding_authors": "",
    "abstract": "The extraordinary technological progress we have witnessed in recent years has made it possible to generate and exchange multimedia content at an unprecedented rate. As a consequence, massive collections of multimedia objects are now widely available to a large population of users. As the task of browsing such large collections could be daunting, Recommender Systems are being developed to assist users in finding items that match their needs and preferences. In this article, we present a novel approach to recommendation in multimedia browsing systems, based on modeling recommendation as a social choice problem. In social choice theory, a set of voters is called to rank a set of alternatives, and individual rankings are aggregated into a global ranking. In our formulation, the set of voters and the set of alternatives both coincide with the set of objects in the data collection. We first define what constitutes a choice in the browsing domain and then define a mechanism to aggregate individual choices into a global ranking. The result is a framework for computing customized recommendations by originally combining intrinsic features of multimedia objects, past behavior of individual users, and overall behavior of the entire community of users. Recommendations are ranked using an importance ranking algorithm that resembles the well-known PageRank strategy. Experiments conducted on a prototype of the proposed system confirm the effectiveness and efficiency of our approach.",
    "cited_by_count": 89,
    "openalex_id": "https://openalex.org/W2040809877",
    "type": "article"
  },
  {
    "title": "One-time cookies",
    "doi": "https://doi.org/10.1145/2220352.2220353",
    "publication_date": "2012-06-01",
    "publication_year": 2012,
    "authors": "Italo Dacosta; Saurabh Chakradeo; Mustaque Ahamad; Patrick Traynor",
    "corresponding_authors": "",
    "abstract": "HTTP cookies are the de facto mechanism for session authentication in Web applications. However, their inherent security weaknesses allow attacks against the integrity of Web sessions. HTTPS is often recommended to protect cookies, but deploying full HTTPS support can be challenging due to performance and financial concerns, especially for highly distributed applications. Moreover, cookies can be exposed in a variety of ways even when HTTPS is enabled. In this article, we propose one-time cookies (OTC), a more robust alternative for session authentication. OTC prevents attacks such as session hijacking by signing each user request with a session secret securely stored in the browser. Unlike other proposed solutions, OTC does not require expensive state synchronization in the Web application, making it easily deployable in highly distributed systems. We implemented OTC as a plug-in for the popular WordPress platform and as an extension for Firefox and Firefox for mobile browsers. Our extensive experimental analysis shows that OTC introduces a latency of less than 6 ms when compared to cookies—a negligible overhead for most Web applications. Moreover, we show that OTC can be combined with HTTPS to effectively add another layer of security to Web applications. In so doing, we demonstrate that one-time cookies can significantly improve the security of Web applications with minimal impact on performance and scalability.",
    "cited_by_count": 87,
    "openalex_id": "https://openalex.org/W1996474511",
    "type": "article"
  },
  {
    "title": "On the Dynamics of Social Media Popularity",
    "doi": "https://doi.org/10.1145/2665065",
    "publication_date": "2014-12-17",
    "publication_year": 2014,
    "authors": "Flávio Figueiredo; Jussara M. Almeida; Marcos André Gonçalves; Fabrí­cio Benevenuto",
    "corresponding_authors": "",
    "abstract": "Understanding the factors that impact the popularity dynamics of social media can drive the design of effective information services, besides providing valuable insights to content generators and online advertisers. Taking YouTube as case study, we analyze how video popularity evolves since upload, extracting popularity trends that characterize groups of videos. We also analyze the referrers that lead users to videos, correlating them, features of the video and early popularity measures with the popularity trend and total observed popularity the video will experience. Our findings provide fundamental knowledge about popularity dynamics and its implications for services such as advertising and search.",
    "cited_by_count": 80,
    "openalex_id": "https://openalex.org/W2142306706",
    "type": "article"
  },
  {
    "title": "A Unified Model for the Mobile-Edge-Cloud Continuum",
    "doi": "https://doi.org/10.1145/3226644",
    "publication_date": "2019-04-01",
    "publication_year": 2019,
    "authors": "Luciano Baresi; Danilo Filgueira Mendonça; Martín Garriga; Sam Guinea; Giovanni Quattrocchi",
    "corresponding_authors": "",
    "abstract": "Technologies such as mobile, edge, and cloud computing have the potential to form a computing continuum for new, disruptive applications. At runtime, applications can choose to execute parts of their logic on different infrastructures that constitute the continuum, with the goal of minimizing latency and battery consumption and maximizing availability. In this article, we propose A3-E, a unified model for managing the life cycle of continuum applications. In particular, A3-E exploits the Functions-as-a-Service model to bring computation to the continuum in the form of microservices. Furthermore, A3-E selects where to execute a certain function based on the specific context and user requirements. The article also presents a prototype framework that implements the concepts behind A3-E. Results show that A3-E is capable of dynamically deploying microservices and routing the application’s requests, reducing latency by up to 90% when using edge instead of cloud resources, and battery consumption by 74% when computation has been offloaded.",
    "cited_by_count": 80,
    "openalex_id": "https://openalex.org/W2931168649",
    "type": "article"
  },
  {
    "title": "Advanced Security Testbed Framework for Wearable IoT Devices",
    "doi": "https://doi.org/10.1145/2981546",
    "publication_date": "2016-12-07",
    "publication_year": 2016,
    "authors": "Shachar Siboni; Asaf Shabtai; Nils Ole Tippenhauer; Jemin Lee; Yuval Elovici",
    "corresponding_authors": "",
    "abstract": "Analyzing the security of Wearable Internet-of-Things (WIoT) devices is considered a complex task due to their heterogeneous nature. In addition, there is currently no mechanism that performs security testing for WIoT devices in different contexts. In this article, we propose an innovative security testbed framework targeted at wearable devices, where a set of security tests are conducted, and a dynamic analysis is performed by realistically simulating environmental conditions in which WIoT devices operate. The architectural design of the proposed testbed and a proof-of-concept, demonstrating a preliminary analysis and the detection of context-based attacks executed by smartwatch devices, are presented.",
    "cited_by_count": 68,
    "openalex_id": "https://openalex.org/W2559987443",
    "type": "article"
  },
  {
    "title": "On the Need of Trustworthy Sensing and Crowdsourcing for Urban Accessibility in Smart City",
    "doi": "https://doi.org/10.1145/3133327",
    "publication_date": "2017-10-26",
    "publication_year": 2017,
    "authors": "Catia Prandi; Silvia Mirri; Stefano Ferretti; Paola Salomoni",
    "corresponding_authors": "",
    "abstract": "Mobility in urban environments is an undisputed key factor that can affect citizens’ well-being and quality of life. This is particularly relevant for those people with disabilities or with reduced mobility who have to face the presence of barriers in urban areas. In this scenario, the availability of information about such architectural elements (together with facilities) can greatly support citizens’ mobility by enhancing their independence and their abilities in conducting daily outdoor activities. With this in mind, we have designed and developed mobile Pervasive Accessibility Social Sensing (mPASS), a system that provides users with personalized paths, computed on the basis of their own preferences and needs, with a customizable and accessible interface. The system collects data from crowdsourcing and crowdsensing to map urban and architectural accessibility by providing reliable information coming from different data sources with different levels of trustworthiness. In this context, reliability can be ensured by properly managing crowdsourced and crowdsensed data, combined when possible with authoritative datasets, provided by disability rights organizations and local authorities. To demonstrate this claim, in this article we present our trustworthiness model and discuss results we have obtained by simulations.",
    "cited_by_count": 66,
    "openalex_id": "https://openalex.org/W2766907534",
    "type": "article"
  },
  {
    "title": "A Scalable Framework for Provisioning Large-Scale IoT Deployments",
    "doi": "https://doi.org/10.1145/2850416",
    "publication_date": "2016-03-29",
    "publication_year": 2016,
    "authors": "Michael Vögler; Johannes M. Schleicher; Christian Inzinger; Schahram Dustdar",
    "corresponding_authors": "",
    "abstract": "Internet of Things (IoT) devices are usually considered external application dependencies that only provide data or process and execute simple instructions. The recent emergence of IoT devices with embedded execution environments allows practitioners to deploy and execute custom application logic directly on the device. This approach fundamentally changes the overall process of designing, developing, deploying, and managing IoT systems. However, these devices exhibit significant differences in available execution environments, processing, and storage capabilities. To accommodate this diversity, a structured approach is needed to uniformly and transparently deploy application components onto a large number of heterogeneous devices. This is especially important in the context of large-scale IoT systems, such as in the smart city domain. In this article, we present LEONORE, an infrastructure toolset that provides elastic provisioning of application components on resource-constrained and heterogeneous edge devices in large-scale IoT deployments. LEONORE supports push-based as well as pull-based deployments. To improve scalability and reduce generated network traffic between cloud and edge infrastructure, we present a distributed provisioning approach that deploys LEONORE local nodes within the deployment infrastructure close to the actual edge devices. We show that our solution is able to elastically provision large numbers of devices using a testbed based on a real-world industry scenario.",
    "cited_by_count": 65,
    "openalex_id": "https://openalex.org/W2253906049",
    "type": "article"
  },
  {
    "title": "An Online Algorithm for Task Offloading in Heterogeneous Mobile Clouds",
    "doi": "https://doi.org/10.1145/3122981",
    "publication_date": "2018-01-20",
    "publication_year": 2018,
    "authors": "Bowen Zhou; Amir Vahid Dastjerdi; Rodrigo N. Calheiros; Rajkumar Buyya",
    "corresponding_authors": "",
    "abstract": "Mobile cloud computing is emerging as a promising approach to enrich user experiences at the mobile device end. Computation offloading in a heterogeneous mobile cloud environment has recently drawn increasing attention in research. The computation offloading decision making and tasks scheduling among heterogeneous shared resources in mobile clouds are becoming challenging problems in terms of providing global optimal task response time and energy efficiency. In this article, we address these two problems together in a heterogeneous mobile cloud environment as an optimization problem. Different from conventional distributed computing system scheduling problems, our joint offloading and scheduling optimization problem considers unique contexts of mobile clouds such as wireless network connections and mobile device mobility, which makes the problem more complex. We propose a context-aware mixed integer programming model to provide off-line optimal solutions for making the offloading decisions and scheduling the offloaded tasks among the shared computing resources in heterogeneous mobile clouds. The objective is to minimize the global task completion time (i.e., makespan). To solve the problem in real time, we further propose a deterministic online algorithm—the Online Code Offloading and Scheduling (OCOS) algorithm—based on the rent/buy problem and prove the algorithm is 2-competitive. Performance evaluation results show that the OCOS algorithm can generate schedules that have around two times shorter makespan than conventional independent task scheduling algorithms. Also, it can save around 30% more on makespan of task execution schedules than conventional offloading strategies, and scales well as the number of users grows.",
    "cited_by_count": 64,
    "openalex_id": "https://openalex.org/W2782955024",
    "type": "article"
  },
  {
    "title": "Joint QoS-aware and Cost-efficient Task Scheduling for Fog-cloud Resources in a Volunteer Computing System",
    "doi": "https://doi.org/10.1145/3418501",
    "publication_date": "2021-07-16",
    "publication_year": 2021,
    "authors": "Farooq Hoseiny; Sadoon Azizi; Mohammad Shojafar; Rahim Tafazolli",
    "corresponding_authors": "",
    "abstract": "Volunteer computing is an Internet-based distributed computing in which volunteers share their extra available resources to manage large-scale tasks. However, computing devices in a Volunteer Computing System (VCS) are highly dynamic and heterogeneous in terms of their processing power, monetary cost, and data transferring latency. To ensure both of the high Quality of Service (QoS) and low cost for different requests, all of the available computing resources must be used efficiently. Task scheduling is an NP-hard problem that is considered as one of the main critical challenges in a heterogeneous VCS. Due to this, in this article, we design two task scheduling algorithms for VCSs, named Min-CCV and Min-V . The main goal of the proposed algorithms is jointly minimizing the computation, communication, and delay violation cost for the Internet of Things (IoT) requests. Our extensive simulation results show that proposed algorithms are able to allocate tasks to volunteer fog/cloud resources more efficiently than the state-of-the-art. Specifically, our algorithms improve the deadline satisfaction task rates around 99.5% and decrease the total cost between 15 to 53% in comparison with the genetic-based algorithm.",
    "cited_by_count": 62,
    "openalex_id": "https://openalex.org/W3186289268",
    "type": "article"
  },
  {
    "title": "Multi-Tier Stack of Block Chain with Proxy Re-Encryption Method Scheme on the Internet of Things Platform",
    "doi": "https://doi.org/10.1145/3421508",
    "publication_date": "2021-10-29",
    "publication_year": 2021,
    "authors": "Bharat S. Rawal; M. Poongodi; Gunasekaran Manogaran; Mounir Hamdi",
    "corresponding_authors": "",
    "abstract": "Block chain provides an innovative solution to information storage, transaction execution, security, and trust building in an open environment. The block chain is technological progress for cyber security and cryptography, with efficiency-related cases varying in smart grids, smart contracts, over the IoT, etc. The movement to exchange data on a server has massively increased with the introduction of the Internet of Things. Hence, in this research, Splitting of proxy re-encryption method (Split-PRE) has been suggested based on the IoT to improve security and privacy in a private block chain. This study proposes a block chain-based proxy re-encryption program to resolve both the trust and scalability problems and to simplify the transactions. After encryption, the system saves the Internet of Things data in a distributed cloud. The framework offers dynamic, smart contracts between the sensor and the device user without the intervention of a trustworthy third party to exchange the captured IoT data. It uses an efficient proxy re-encryption system, which provides the owner and the person existing in the smart contract to see the data. The experimental outcomes show that the proposed approach enhances the efficiency, security, privacy, and feasibility of the system when compared to other existing methods.",
    "cited_by_count": 59,
    "openalex_id": "https://openalex.org/W3211155009",
    "type": "article"
  },
  {
    "title": "AI-enabled IoT-Edge Data Analytics for Connected Living",
    "doi": "https://doi.org/10.1145/3421510",
    "publication_date": "2021-07-16",
    "publication_year": 2021,
    "authors": "Zhihan Lv; Liang Qiao; Sahil Verma; Kavita Kavita",
    "corresponding_authors": "",
    "abstract": "As deep learning, virtual reality, and other technologies become mature, real-time data processing applications running on intelligent terminals are emerging endlessly; meanwhile, edge computing has developed rapidly and has become a popular research direction in the field of distributed computing. Edge computing network is a network computing environment composed of multi-edge computing nodes and data centers. First, the edge computing framework and key technologies are analyzed to improve the performance of real-time data processing applications. In the system scenario where the collaborative deployment tasks of multi-edge nodes and data centers are considered, the stream processing task deployment process is formally described, and an efficient multi-edge node-computing center collaborative task deployment algorithm is proposed, which solves the problem of copy-free task deployment in the task deployment problem. Furthermore, a heterogeneous edge collaborative storage mechanism with tight coupling of computing and data is proposed, which solves the contradiction between the limited computing and storage capabilities of data and intelligent terminals, thereby improving the performance of data processing applications. Here, a Feasible Solution (FS) algorithm is designed to solve the problem of placing copy-free data processing tasks in the system. The FS algorithm has excellent results once considering the overall coordination. Under light load, the V value is reduced by 73% compared to the Only Data Center-available (ODC) algorithm and 41% compared to the Hash algorithm. Under heavy load, the V value is reduced by 66% compared to the ODC algorithm and 35% compared to the Hash algorithm. The algorithm has achieved good results after considering the overall coordination and cooperation and can more effectively use the bandwidth of edge nodes to transmit and process data stream, so that more tasks can be deployed in edge computing nodes, thereby saving time for data transmission to the data centers. The end-to-end collaborative real-time data processing task scheduling mechanism proposed here can effectively avoid the disadvantages of long waiting times and unable to obtain the required data, which significantly improves the success rate of the task and thus ensures the performance of real-time data processing.",
    "cited_by_count": 57,
    "openalex_id": "https://openalex.org/W3185636585",
    "type": "article"
  },
  {
    "title": "Mobile Crowd-sensing Applications: Data Redundancies, Challenges, and Solutions",
    "doi": "https://doi.org/10.1145/3431502",
    "publication_date": "2021-10-29",
    "publication_year": 2021,
    "authors": "Tu N. Nguyen; Sherali Zeadally",
    "corresponding_authors": "",
    "abstract": "Conventional data collection methods that use Wireless Sensor Networks (WSNs) suffer from disadvantages such as deployment location limitation, geographical distance, as well as high construction and deployment costs of WSNs. Recently, various efforts have been promoting mobile crowd-sensing (such as a community with people using mobile devices) as a way to collect data based on existing resources. A Mobile Crowd-Sensing System can be considered as a Cyber-Physical System (CPS), because it allows people with mobile devices to collect and supply data to CPSs’ centers. In practical mobile crowd-sensing applications, due to limited budgets for the different expenditure categories in the system, it is necessary to minimize the collection of redundant information to save more resources for the investor. We study the problem of selecting participants in Mobile Crowd-Sensing Systems without redundant information such that the number of users is minimized and the number of records (events) reported by users is maximized, also known as the Participant-Report-Incident Redundant Avoidance (PRIRA) problem. We propose a new approximation algorithm, called the Maximum-Participant-Report Algorithm (MPRA) to solve the PRIRA problem. Through rigorous theoretical analysis and experimentation, we demonstrate that our proposed method performs well within reasonable bounds of computational complexity.",
    "cited_by_count": 57,
    "openalex_id": "https://openalex.org/W3209836183",
    "type": "article"
  },
  {
    "title": "Predictive Analytics for Smart Parking: A Deep Learning Approach in Forecasting of IoT Data",
    "doi": "https://doi.org/10.1145/3412842",
    "publication_date": "2021-06-09",
    "publication_year": 2021,
    "authors": "Francesco Piccialli; Fabio Giampaolo; Edoardo Prezioso; Danilo Crisci; Salvatore Cuomo",
    "corresponding_authors": "",
    "abstract": "Nowadays, a sustainable and smart city focuses on energy efficiency and the reduction of polluting emissions through smart mobility projects and initiatives to “sensitize” infrastructure. Smart parking is one of the building blocks of intelligent mobility, innovative mobility that aims to be flexible, integrated, and sustainable and consequently integrated into a Smart City. By using the Internet of Things (IoT) sensors located in the parking areas or the underground car parks in combination with a mobile application, which indicates to citizens the free places in the different areas of the city and guides them toward the chosen parking, it is possible to reduce air pollution and fluidifying noise traffic. In this article, we present and discuss an innovative Deep Learning-based ensemble technique in forecasting the parking space occupancy to reduce the search time for parking and to optimize the flow of cars in particularly congested areas, with an overall positive impact on traffic in urban centres. A genetic algorithm has also been used to optimize predictors parameters. The main goal is to design an intelligent IoT-based service that can predict, in the next few hours, the parking spaces occupancy of a street. The proposed approach has been assessed on a real IoT dataset composed by over than 15M of collected sensor records. Obtained results demonstrate that our method outperforms both single predictors and the widely used strategy of the mean providing inherently robust predictions.",
    "cited_by_count": 50,
    "openalex_id": "https://openalex.org/W3172883511",
    "type": "article"
  },
  {
    "title": "Synergic Deep Learning for Smart Health Diagnosis of COVID-19 for Connected Living and Smart Cities",
    "doi": "https://doi.org/10.1145/3453168",
    "publication_date": "2021-11-29",
    "publication_year": 2021,
    "authors": "K. Shankar; Eswaran Perumal; Mohamed Elhoseny; Fatma Taher; Brij B. Gupta; Ahmed A. Abd El‐Latif",
    "corresponding_authors": "",
    "abstract": "COVID-19 pandemic has led to a significant loss of global deaths, economical status, and so on. To prevent and control COVID-19, a range of smart, complex, spatially heterogeneous, control solutions, and strategies have been conducted. Earlier classification of 2019 novel coronavirus disease (COVID-19) is needed to cure and control the disease. It results in a requirement of secondary diagnosis models, since no precise automated toolkits exist. The latest finding attained using radiological imaging techniques highlighted that the images hold noticeable details regarding the COVID-19 virus. The application of recent artificial intelligence (AI) and deep learning (DL) approaches integrated to radiological images finds useful to accurately detect the disease. This article introduces a new synergic deep learning (SDL)-based smart health diagnosis of COVID-19 using Chest X-Ray Images. The SDL makes use of dual deep convolutional neural networks (DCNNs) and involves a mutual learning process from one another. Particularly, the representation of images learned by both DCNNs is provided as the input of a synergic network, which has a fully connected structure and predicts whether the pair of input images come under the identical class. Besides, the proposed SDL model involves a fuzzy bilateral filtering (FBF) model to pre-process the input image. The integration of FBL and SDL resulted in the effective classification of COVID-19. To investigate the classifier outcome of the SDL model, a detailed set of simulations takes place and ensures the effective performance of the FBF-SDL model over the compared methods.",
    "cited_by_count": 50,
    "openalex_id": "https://openalex.org/W3217423340",
    "type": "article"
  },
  {
    "title": "Rotating behind Privacy: An Improved Lightweight Authentication Scheme for Cloud-based IoT Environment",
    "doi": "https://doi.org/10.1145/3425707",
    "publication_date": "2021-06-09",
    "publication_year": 2021,
    "authors": "Shehzad Ashraf Chaudhry; Azeem Irshad; Khalid Yahya; Neeraj Kumar; Mamoun Alazab; Yousaf Bin Zikria",
    "corresponding_authors": "",
    "abstract": "The advancements in the internet of things (IoT) require specialized security protocols to provide unbreakable security along with computation and communication efficiencies. Moreover, user privacy and anonymity has emerged as an integral part, along with other security requirements. Unfortunately, many recent authentication schemes to secure IoT-based systems were either proved as vulnerable to different attacks or prey of inefficiencies. Some of these schemes suffer from a faulty design that happened mainly owing to undue emphasis on privacy and anonymity alongside performance efficiency. This article aims to show the design faults by analyzing a very recent hash functions-based authentication scheme for cloud-based IoT systems with misunderstood privacy cum efficiency tradeoff owing to an unadorned design flaw, which is also present in many other such schemes. Precisely, it is proved in this article that the scheme of Wazid et al. cannot provide mutual authentication and key agreement between a user and a sensor node when there exists more than one registered user. We then proposed an improved scheme and proved its security through formal and informal methods. The proposed scheme completes the authentication cycle with a minor increase in computation cost but provides all security goals along with privacy.",
    "cited_by_count": 47,
    "openalex_id": "https://openalex.org/W3169298935",
    "type": "article"
  },
  {
    "title": "Social-Chain",
    "doi": "https://doi.org/10.1145/3419102",
    "publication_date": "2021-01-05",
    "publication_year": 2021,
    "authors": "Zheng Yan; Li Peng; Wei Feng; Laurence T. Yang",
    "corresponding_authors": "",
    "abstract": "Pervasive Social Networking (PSN) supports online and instant social activities with the support of heterogeneous networks. Since reciprocal activities among both familiar/unfamiliar strangers and acquaintances are quite common in PSN, it is essential to offer trust information to PSN users. Past work normally evaluates trust based on a centralized party, which is not feasible due to the dynamic changes of PSN topology and its specific characteristics. The literature still lacks a decentralized trust evaluation scheme in PSN. In this article, we propose a novel blockchain-based decentralized system for trust evaluation in PSN, called Social-Chain. Considering mobile devices normally lack computing resources to process cryptographic puzzle calculation, we design a lightweight consensus mechanism based on Proof-of-Trust (PoT), which remarkably improves system effectivity compared with other blockchain systems. Serious security analysis and experimental results further illustrate the security and efficiency of Social-Chain for being feasibly applied into PSN.",
    "cited_by_count": 46,
    "openalex_id": "https://openalex.org/W3119160602",
    "type": "article"
  },
  {
    "title": "Knowledge Graph Construction with a <i>Façade</i> : A Unified Method to Access Heterogeneous Data Sources on the Web",
    "doi": "https://doi.org/10.1145/3555312",
    "publication_date": "2022-11-04",
    "publication_year": 2022,
    "authors": "Luigi Asprino; Enrico Daga; Aldo Gangemi; Paul Mulholland",
    "corresponding_authors": "",
    "abstract": "Data integration is the dominant use case for RDF Knowledge Graphs. However, Web resources come in formats with weak semantics (for example, CSV and JSON), or formats specific to a given application (for example, BibTex, HTML, and Markdown). To solve this problem, Knowledge Graph Construction (KGC) is gaining momentum due to its focus on supporting users in transforming data into RDF. However, using existing KGC frameworks result in complex data processing pipelines, which mix structural and semantic mappings, whose development and maintenance constitute a significant bottleneck for KG engineers. Such frameworks force users to rely on different tools, sometimes based on heterogeneous languages, for inspecting sources, designing mappings, and generating triples, thus making the process unnecessarily complicated. We argue that it is possible and desirable to equip KG engineers with the ability of interacting with Web data formats by relying on their expertise in RDF and the well-established SPARQL query language [ 2 ]. In this article, we study a unified method for data access to heterogeneous data sources with Facade-X, a meta-model implemented in a new data integration system called SPARQL Anything. We demonstrate that our approach is theoretically sound, since it allows a single meta-model, based on RDF, to represent data from (a) any file format expressible in BNF syntax, as well as (b) any relational database. We compare our method to state-of-the-art approaches in terms of usability (cognitive complexity of the mappings) and general performance. Finally, we discuss the benefits and challenges of this novel approach by engaging with the reference user community.",
    "cited_by_count": 44,
    "openalex_id": "https://openalex.org/W4308206224",
    "type": "article"
  },
  {
    "title": "Edge Computing AI-IoT Integrated Energy-efficient Intelligent Transportation System for Smart Cities",
    "doi": "https://doi.org/10.1145/3507906",
    "publication_date": "2022-02-03",
    "publication_year": 2022,
    "authors": "Suresh Chavhan; Deepak Gupta; Sarada Prasad Gochhayat; B. N. Chandana; Ashish Khanna; K. Shankar; Joel J. P. C. Rodrigues",
    "corresponding_authors": "",
    "abstract": "With the advancement of information and communication technologies (ICTs), there has been high-scale utilization of IoT and adoption of AI in the transportation system to improve the utilization of energy, reduce greenhouse gas (GHG) emissions, increase quality of services, and provide many extensive benefits to the commuters and transportation authorities. In this article, we propose a novel edge-based AI-IoT integrated energy-efficient intelligent transport system for smart cities by using a distributed multi-agent system. An urban area is divided into multiple regions, and each region is sub-divided into a finite number of zones. At each zone an optimal number of RSUs are installed along with the edge computing devices. The MAS deployed at each RSU collects a huge volume of data from the various sensors, devices, and infrastructures. The edge computing device uses the collected raw data from the MAS to process, analyze, and predict. The predicted information will be shared with the neighborhood RSUs, vehicles, and cloud by using MAS with the help of IoT. The predicted information can be used by freight vehicles to maintain smooth and steady movement, which results in reduction in GHG emissions and energy consumption, and finally improves the freight vehicles’ mileage by reducing traffic congestion in the urban areas. We have exhaustively carried out the simulation results and demonstrated the effectiveness of the proposed system.",
    "cited_by_count": 42,
    "openalex_id": "https://openalex.org/W4210751492",
    "type": "article"
  },
  {
    "title": "Using Deep Learning Models to Detect Fake News about COVID-19",
    "doi": "https://doi.org/10.1145/3533431",
    "publication_date": "2022-05-06",
    "publication_year": 2022,
    "authors": "Mu‐Yen Chen; Yi-Wei Lai; Jiunn-Woei Lian",
    "corresponding_authors": "",
    "abstract": "The proliferation of mobile networked devices has made it easier and faster than ever for people to obtain and share information. However, this occasionally results in the propagation of erroneous information, which may be difficult to distinguish from the truth. The widespread diffusion of such information can result in irrational and poor decision making on potentially important issues. In 2020, this coincided with the global outbreak of Coronavirus Disease (COVID-19) , a highly contagious and deadly virus. The proliferation of misinformation about COVID-19 on social media has already been identified as an “infodemic” by the World Health Organization (WHO) , posing significant challenges for global governments seeking to manage the pandemic. This has driven an urgent need for methods to automatically detect and identify such misinformation. The research uses multiple deep learning model frameworks to detect misinformation in Chinese and English, and compare them based on different text feature selection s. The model learns the textual characteristics of each type of true and misinformation for subsequent true/false prediction. The long and short-term memory (LSTM) model, the gated recurrent unit (GRU) model, and the bidirectional long and short-term memory (BiLSTM) model were selected for fake news detection. BiLSTM produces the best detection result, with detection accuracy reaching 94% for short-sentence English texts, and 99% for long-sentence English texts, while the accuracy for Chinese texts was 82% .",
    "cited_by_count": 38,
    "openalex_id": "https://openalex.org/W4229081359",
    "type": "article"
  },
  {
    "title": "The Doge of Wall Street: Analysis and Detection of Pump and Dump Cryptocurrency Manipulations",
    "doi": "https://doi.org/10.1145/3561300",
    "publication_date": "2022-09-02",
    "publication_year": 2022,
    "authors": "Massimo La Morgia; Alessandro Mei; Francesco Sassi; Julinda Stefa",
    "corresponding_authors": "",
    "abstract": "Cryptocurrencies are increasingly popular. Even people who are not experts have started to invest in these assets, and nowadays, cryptocurrency exchanges process transactions for over 100 billion US dollars per month. Despite this, many cryptocurrencies have low liquidity and are highly prone to market manipulation. This paper performs an in-depth analysis of two market manipulations organized by communities over the Internet: The pump and dump and the crowd pump. The pump and dump scheme is a fraud as old as the stock market. Now, it has new vitality in the loosely regulated market of cryptocurrencies. Groups of highly coordinated people systematically arrange this scam, usually on Telegram and Discord. We monitored these groups for more than 3 years, detecting around 900 individual events. We report on three case studies related to pump and dump groups. We leverage our unique dataset of the verified pump and dumps to build a machine learning model able to detect a pump and dump in 25 seconds from the moment it starts, achieving the results of 94.5% of F1-score. Then, we move on to the crowd pump, a new phenomenon that hit the news in the first months of 2021, when a Reddit community inflated the price of the GameStop stocks (GME) by over 1,900% on Wall Street, the world’s largest stock exchange. Later, other Reddit communities replicated the operation on the cryptocurrency markets. The targets were DogeCoin (DOGE) and Ripple (XRP). We reconstruct how these operations developed and discuss differences and analogies with the standard pump and dump. We believe this study helps understand a widespread phenomenon affecting cryptocurrency markets. The detection algorithms we develop effectively detect these events in real-time and helps investors stay out of the market when these frauds are in action.",
    "cited_by_count": 37,
    "openalex_id": "https://openalex.org/W3159176111",
    "type": "article"
  },
  {
    "title": "S-BDS: An Effective Blockchain-based Data Storage Scheme in Zero-Trust IoT",
    "doi": "https://doi.org/10.1145/3511902",
    "publication_date": "2022-02-12",
    "publication_year": 2022,
    "authors": "Jin Wang; Jiahao Chen; Naixue Xiong; Osama Alfarraj; Amr Tolba; Yongjun Ren",
    "corresponding_authors": "",
    "abstract": "With the development of the Internet of Things (IoT) , a large-scale, heterogeneous, and dynamic distributed network has been formed among IoT devices. There is an extreme need to establish a trust mechanism between devices, and blockchain can provide a zero-trust security framework for IoT. However, the efficiency of the blockchain is far from meeting the application requirements of the IoT, which has become the biggest resistance to the application of the blockchain in the IoT. Therefore, this paper combines sharding to build an effective Blockchain-based IoT data storage scheme (S-BDS) . Sharding can solve the problem of blockchain capacity and scalability. While the blockchain provides data immutability and traceability for the IoT, it also brings huge demands for data credibility verification. The communication delay in the IoT system seriously affects the security of the system, while the Merkle proof of traditional blockchain occupies a lot of communication resources. This paper constructs Insertable Vector Commitment (IVC) in the bilinear group and replaces the Merkle tree with IVC to store IoT data in the blockchain. The construct has small-sized proof. It also has the ability to record the number of updates, which can prevent replay-attacks. Experiments show that each block processes 1,000 transactions, the proof size of a single data piece is 30% of the original scheme, and proofs from different shards can be aggregated. IVC can effectively reduce communication congestion and improve the stability and security of the IoT system.",
    "cited_by_count": 33,
    "openalex_id": "https://openalex.org/W4211108011",
    "type": "article"
  },
  {
    "title": "Federated Learning-based Information Leakage Risk Detection for Secure Medical Internet of Things",
    "doi": "https://doi.org/10.1145/3639466",
    "publication_date": "2024-01-09",
    "publication_year": 2024,
    "authors": "Tingting Wang; Tao Tang; Zhen Cai; Kai Fang; Jinyu Tian; Jianqing Li; Wei Wang; Feng Xia",
    "corresponding_authors": "",
    "abstract": "The Medical Internet of Things (MIoT) requires extreme information and communication security, particularly for remote consultation systems. MIoT’s integration of physical and computational components creates a seamless network of medical devices providing high-quality care via continuous monitoring and treatment. However, traditional security methods such as cryptography cannot prevent privacy compromise and information leakage caused by security breaches. To solve this issue, this paper proposes a novel Federated Learning Intrusion Detection System (FLIDS). FLIDS combines Generative Adversarial Network (GAN) and Federated Learning (FL) to detect cyber attacks like Denial of Service (DoS), data modification, and data injection using machine learning. FLIDS shows exceptional performance with over 99% detection accuracy and 1% False Positive Rate (FPR). It saves bandwidth by transmitting 3.8 times fewer bytes compared to central data collection. These results prove FLIDS’ effectiveness in detecting and mitigating security threats in Medical Cyber-Physical Systems (MCPS). The paper recommends scaling up FLIDS to use computing resources from multiple mobile devices for better intrusion detection accuracy and efficiency while reducing the burden on individual devices in MIoT.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W4390781042",
    "type": "article"
  },
  {
    "title": "Developing a bidding agent for multiple heterogeneous auctions",
    "doi": "https://doi.org/10.1145/857166.857167",
    "publication_date": "2003-08-01",
    "publication_year": 2003,
    "authors": "Patricia Anthony; Nicholas R. Jennings",
    "corresponding_authors": "",
    "abstract": "Due to the proliferation of online auctions, there is an increasing need to monitor and bid in multiple auctions in order to procure the best deal for the desired good. To this end, this paper reports on the development of a heuristic decision making framework that an autonomous agent can exploit to tackle the problem of bidding across multiple auctions with varying start and end times and with varying protocols (including English, Dutch and Vickrey). The framework is flexible, configurable, and enables the agent to adopt varying tactics and strategies that attempt to ensure that the desired item is delivered in a manner consistent with the user's preferences. Given this large space of possibilities, we employ a genetic algorithm to search (offline) for effective strategies in common classes of environment. The strategies that emerge from this evolution are then codified into the agent's reasoning behaviour so that it can select the most appropriate strategy to employ in its prevailing circumstances. The proposed framework has been implemented in a simulated marketplace environment and its effectiveness has been empirically demonstrated.",
    "cited_by_count": 123,
    "openalex_id": "https://openalex.org/W2142473753",
    "type": "article"
  },
  {
    "title": "(How) can mobile agents do secure electronic transactions on untrusted hosts? A survey of the security issues and the current solutions",
    "doi": "https://doi.org/10.1145/643477.643479",
    "publication_date": "2003-02-01",
    "publication_year": 2003,
    "authors": "Joris Claessens; Bart Preneel; Joos Vandewalle",
    "corresponding_authors": "",
    "abstract": "This article investigates if and how mobile agents can execute secure electronic transactions on untrusted hosts. An overview of the security issues of mobile agents is first given. The problem of untrusted (i.e., potentially malicious) hosts is one of these issues, and appears to be the most difficult to solve. The current approaches to counter this problem are evaluated, and their relevance for secure electronic transactions is discussed. In particular, a state-of-the-art survey of mobile agent-based secure electronic transactions is presented.",
    "cited_by_count": 118,
    "openalex_id": "https://openalex.org/W2121655131",
    "type": "article"
  },
  {
    "title": "Behavior-based modeling and its application to Email analysis",
    "doi": "https://doi.org/10.1145/1149121.1149125",
    "publication_date": "2006-05-01",
    "publication_year": 2006,
    "authors": "Salvatore J. Stolfo; Shlomo Hershkop; Chia-Wei Hu; Wei‐Jen Li; Olivier Nimeskern; Ke Wang",
    "corresponding_authors": "",
    "abstract": "The Email Mining Toolkit (EMT) is a data mining system that computes behavior profiles or models of user email accounts. These models may be used for a multitude of tasks including forensic analyses and detection tasks of value to law enforcement and intelligence agencies, as well for as other typical tasks such as virus and spam detection. To demonstrate the power of the methods, we focus on the application of these models to detect the early onset of a viral propagation without “content-base ” (or signature-based) analysis in common use in virus scanners. We present several experiments using real email from 15 users with injected simulated viral emails and describe how the combination of different behavior models improves overall detection rates. The performance results vary depending upon parameter settings, approaching 99 % true positive (TP) (percentage of viral emails caught) in general cases and with 0.38 % false positive (FP) (percentage of emails with attachments that are mislabeled as viral). The models used for this study are based upon volume and velocity statistics of a user's email rate and an analysis of the user's (social) cliques revealed in the person's email behavior. We show by way of simulation that virus propagations are detectable since viruses may emit emails at rates different than human behavior suggests is normal, and email is directed to groups of recipients in ways that violate the users' typical communications with their social groups.",
    "cited_by_count": 107,
    "openalex_id": "https://openalex.org/W2169300738",
    "type": "article"
  },
  {
    "title": "Generating semantically enriched user profiles for Web personalization",
    "doi": "https://doi.org/10.1145/1278366.1278371",
    "publication_date": "2007-10-01",
    "publication_year": 2007,
    "authors": "Sarabjot Singh Anand; Patricia M. Kearney; Mary Shapcott",
    "corresponding_authors": "",
    "abstract": "Traditional collaborative filtering generates recommendations for the active user based solely on ratings of items by other users. However, most businesses today have item ontologies that provide a useful source of content descriptors that can be used to enhance the quality of recommendations generated. In this article, we present a novel approach to integrating user rating vectors with an item ontology to generate recommendations. The approach is novel in measuring similarity between users in that it first derives factors, referred to as impacts , driving the observed user behavior and then uses these factors within the similarity computation. In doing so, a more comprehensive user model is learned that is sensitive to the context of the user visit. An evaluation of our recommendation algorithm was carried out using data from an online retailer of movies with over 94,000 movies, 44,000 actors, and 10,000 directors within the item knowledge base. The evaluation showed a statistically significant improvement in the prediction accuracy over traditional collaborative filtering. Additionally, the algorithm was shown to generate recommendations for visitors that belong to sparse sections of the user space, areas where traditional collaborative filtering would generally fail to generate accurate recommendations.",
    "cited_by_count": 100,
    "openalex_id": "https://openalex.org/W2013728466",
    "type": "article"
  },
  {
    "title": "Semantics-based composition-oriented discovery of Web services",
    "doi": "https://doi.org/10.1145/1391949.1391953",
    "publication_date": "2008-09-01",
    "publication_year": 2008,
    "authors": "Antonio Brogi; Sara Corfini; Răzvan Popescu",
    "corresponding_authors": "",
    "abstract": "Service discovery and service aggregation are two crucial issues in the emerging area of service-oriented computing (SOC). We propose a new technique for the discovery of (Web) services that accounts for the need of composing several services to satisfy a client query. The proposed algorithm makes use of OWL-S ontologies, and explicitly returns the sequence of atomic process invocations that the client must perform in order to achieve the desired result. When no full match is possible, the algorithm features a flexible matching by returning partial matches and by suggesting additional inputs that would produce a full match.",
    "cited_by_count": 98,
    "openalex_id": "https://openalex.org/W1992904693",
    "type": "article"
  },
  {
    "title": "Characteristics of streaming media stored on the Web",
    "doi": "https://doi.org/10.1145/1111627.1111629",
    "publication_date": "2005-11-01",
    "publication_year": 2005,
    "authors": "Mingzhe Li; Mark Claypool; Robert Kinicki; James H. Nichols",
    "corresponding_authors": "",
    "abstract": "Despite the growth in multimedia, there have been few studies that focus on characterizing streaming audio and video stored on the Web. This investigation used a customized Web crawler to traverse 17 million Web pages from diverse geographic locations and identify nearly 30,000 streaming audio and video clips available for analysis. Using custom-built extraction tools, these streaming media objects were analyzed to determine attributes such as media type, encoding format, playout duration, bitrate, resolution, and codec. The streaming media content encountered is dominated by proprietary audio and video formats with the top four commercial products being RealPlayer, Windows Media Player, MP3 and QuickTime. The distribution of the stored playout durations of streaming audio and video clips are long-tailed. More than half of the streaming media clips encountered are video, encoded primarily for broadband connections and at resolutions considerably smaller than the resolutions of typical monitors.",
    "cited_by_count": 95,
    "openalex_id": "https://openalex.org/W2154842137",
    "type": "article"
  },
  {
    "title": "On the state of IP spoofing defense",
    "doi": "https://doi.org/10.1145/1516539.1516541",
    "publication_date": "2009-05-01",
    "publication_year": 2009,
    "authors": "Toby Ehrenkranz; Jun Li",
    "corresponding_authors": "",
    "abstract": "IP source address spoofing has plagued the Internet for many years. Attackers spoof source addresses to mount attacks and redirect blame. Researchers have proposed many mechanisms to defend against spoofing, with varying levels of success. With the defense mechanisms available today, where do we stand? How do the various defense mechanisms compare? This article first looks into the current state of IP spoofing, then thoroughly surveys the current state of IP spoofing defense. It evaluates data from the Spoofer Project, and describes and analyzes host-based defense methods, router-based defense methods, and their combinations. It further analyzes what obstacles stand in the way of deploying those modern solutions and what areas require further research.",
    "cited_by_count": 87,
    "openalex_id": "https://openalex.org/W1976066853",
    "type": "article"
  },
  {
    "title": "Technology supports for distributed and collaborative learning over the internet",
    "doi": "https://doi.org/10.1145/1323651.1323656",
    "publication_date": "2008-02-01",
    "publication_year": 2008,
    "authors": "Qing Li; Rynson W. H. Lau; Timothy K. Shih; Frederick W. B. Li",
    "corresponding_authors": "",
    "abstract": "With the advent of Internet and World Wide Web (WWW) technologies, distance education (e-learning or Web-based learning) has enabled a new era of education. There are a number of issues that have significant impact on distance education, including those from educational, sociological, and psychological perspectives. Rather than attempting to cover exhaustively all the related perspectives, in this survey article, we focus on the technological issues. A number of technology issues are discussed, including distributed learning, collaborative learning, distributed content management, mobile and situated learning, and multimodal interaction and augmented devices for e-learning. Although we have tried to include the state-of-the-art technologies and systems here, it is anticipated that many new ones will emerge in the near future. As such, we point out several emerging issues and technologies that we believe are promising, for the purpose of highlighting important directions for future research.",
    "cited_by_count": 87,
    "openalex_id": "https://openalex.org/W2166635874",
    "type": "article"
  },
  {
    "title": "Resource overbooking and application profiling in a shared Internet hosting platform",
    "doi": "https://doi.org/10.1145/1462159.1462160",
    "publication_date": "2009-02-01",
    "publication_year": 2009,
    "authors": "Bhuvan Urgaonkar; Prashant Shenoy; Timothy Roscoe",
    "corresponding_authors": "",
    "abstract": "In this article, we present techniques for provisioning CPU and network resources in shared Internet hosting platforms running potentially antagonistic third-party applications. The primary contribution of our work is to demonstrate the feasibility and benefits of overbooking resources in shared Internet platforms. Since an accurate estimate of an application's resource needs is necessary when overbooking resources, we present techniques to profile applications on dedicated nodes, possibly while in service, and use these profiles to guide the placement of application components onto shared nodes. We then propose techniques to overbook cluster resources in a controlled fashion. We outline an empirical appraoch to determine the degree of overbooking that allows a platform to achieve improvements in revenue while providing performance guarantees to Internet applications. We show how our techniques can be combined with commonly used QoS resource allocation mechanisms to provide application isolation and performance guarantees at run-time. We implement our techniques in a Linux cluster and evaluate them using common server applications. We find that the efficiency (and consequently revenue) benefits from controlled overbooking of resources can be dramatic. Specifically, we find that overbooking resources by as little as 1% we can increase the utilization of the cluster by a factor of two, and a 5% overbooking yields a 300--500% improvement, while still providing useful resource guarantees to applications.",
    "cited_by_count": 80,
    "openalex_id": "https://openalex.org/W2145825359",
    "type": "article"
  },
  {
    "title": "An ontology-driven approach for semantic information retrieval on the Web",
    "doi": "https://doi.org/10.1145/1552291.1552293",
    "publication_date": "2009-07-01",
    "publication_year": 2009,
    "authors": "Antonio M. Rinaldi",
    "corresponding_authors": "Antonio M. Rinaldi",
    "abstract": "The concept of relevance is a hot topic in the information retrieval process. In recent years the extreme growth of digital documents brought to light the need for novel approaches and more efficient techniques to improve the accuracy of IR systems to take into account real users' information needs. In this article we propose a novel metric to measure the semantic relatedness between words. Our approach is based on ontologies represented using a general knowledge base for dynamically building a semantic network. This network is based on linguistic properties and it is combined with our metric to create a measure of semantic relatedness. In this way we obtain an efficient strategy to rank digital documents from the Internet according to the user's interest domain. The proposed methods, metrics, and techniques are implemented in a system for information retrieval on the Web. Experiments are performed on a test set built using a directory service having information about analyzed documents. The obtained results compared to other similar systems show an effective improvement.",
    "cited_by_count": 75,
    "openalex_id": "https://openalex.org/W2073680939",
    "type": "article"
  },
  {
    "title": "BogusBiter",
    "doi": "https://doi.org/10.1145/1754393.1754395",
    "publication_date": "2010-05-01",
    "publication_year": 2010,
    "authors": "Chuan Yue; Haining Wang",
    "corresponding_authors": "",
    "abstract": "Many anti-phishing mechanisms currently focus on helping users verify whether a Web site is genuine. However, usability studies have demonstrated that prevention-based approaches alone fail to effectively suppress phishing attacks and protect Internet users from revealing their credentials to phishing sites. In this paper, instead of preventing human users from “biting the bait,” we propose a new approach to protect against phishing attacks with “bogus bites.” We develop BogusBiter , a unique client-side anti-phishing tool, which transparently feeds a relatively large number of bogus credentials into a suspected phishing site. BogusBiter conceals a victim's real credential among bogus credentials, and moreover, it enables a legitimate Web site to identify stolen credentials in a timely manner. Leveraging the power of client-side automatic phishing detection techniques, BogusBiter is complementary to existing preventive anti-phishing approaches. We implemented BogusBiter as an extension to the Firefox 2 Web browser, and evaluated its efficacy through real experiments on both phishing and legitimate Web sites. Our experimental results indicate that it is promising to use BogusBiter to transparently protect against phishing attacks.",
    "cited_by_count": 72,
    "openalex_id": "https://openalex.org/W1977776704",
    "type": "article"
  },
  {
    "title": "Hadoop-Based Intelligent Care System (HICS)",
    "doi": "https://doi.org/10.1145/3108936",
    "publication_date": "2017-11-04",
    "publication_year": 2017,
    "authors": "M. Mazhar Rathore; Anand Paul; Awais Ahmad; Marco Anisetti; Gwanggil Jeon",
    "corresponding_authors": "",
    "abstract": "The Internet of Things (IoT) is increasingly becoming a worldwide network of interconnected things that are uniquely addressable, via standard communication protocols. The use of IoT for continuous monitoring of public health is being rapidly adopted by various countries while generating a massive volume of heterogeneous, multisource, dynamic, and sparse high-velocity data. Handling such an enormous amount of high-speed medical data while integrating, collecting, processing, analyzing, and extracting knowledge constitutes a challenging task. On the other hand, most of the existing IoT devices do not cooperate with one another by using the same medium of communication. For this reason, it is a challenging task to develop healthcare applications for IoT that fulfill all user needs through real-time monitoring of health parameters. Therefore, to address such issues, this article proposed a Hadoop-based intelligent care system (HICS) that demonstrates IoT-based collaborative contextual Big Data sharing among all of the devices in a healthcare system. In particular, the proposed system involves a network architecture with enhanced processing features for data collection generated by millions of connected devices. In the proposed system, various sensors, such as wearable devices, are attached to the human body and measure health parameters and transmit them to a primary mobile device (PMD). The collected data are then forwarded to intelligent building (IB) using the Internet where the data are thoroughly analyzed to identify abnormal and serious health conditions. Intelligent building consists of (1) a Big Data collection unit (used for data collection, filtration, and load balancing); (2) a Hadoop processing unit (HPU) (composed of Hadoop distributed file system (HDFS) and MapReduce); and (3) an analysis and decision unit. The HPU, analysis, and decision unit are equipped with a medical expert system, which reads the sensor data and performs actions in the case of an emergency situation. To demonstrate the feasibility and efficiency of the proposed system, we use publicly available medical sensory datasets and real-time sensor traffic while identifying the serious health conditions of patients by using thresholds, statistical methods, and machine-learning techniques. The results show that the proposed system is very efficient and able to process high-speed WBAN sensory data in real time.",
    "cited_by_count": 64,
    "openalex_id": "https://openalex.org/W2767711810",
    "type": "article"
  },
  {
    "title": "Cheating in Online Games",
    "doi": "https://doi.org/10.1145/2602570",
    "publication_date": "2014-05-01",
    "publication_year": 2014,
    "authors": "Jeremy Blackburn; Nicolas Kourtellis; John Skvoretz; Matei Ripeanu; Adriana Iamnitchi",
    "corresponding_authors": "",
    "abstract": "Online gaming is a multi-billion dollar industry that entertains a large, global population. One unfortunate phenomenon, however, poisons the competition and spoils the fun: cheating. The costs of cheating span from industry-supported expenditures to detect and limit it, to victims’ monetary losses due to cyber crime. This article studies cheaters in the Steam Community, an online social network built on top of the world’s dominant digital game delivery platform. We collected information about more than 12 million gamers connected in a global social network, of which more than 700 thousand have their profiles flagged as cheaters. We also observed timing information of the cheater flags, as well as the dynamics of the cheaters’ social neighborhoods. We discovered that cheaters are well embedded in the social and interaction networks: their network position is largely indistinguishable from that of fair players. Moreover, we noticed that the number of cheaters is not correlated with the geographical, real-world population density, or with the local popularity of the Steam Community. Also, we observed a social penalty involved with being labeled as a cheater: cheaters lose friends immediately after the cheating label is publicly applied. Most importantly, we observed that cheating behavior spreads through a social mechanism: the number of cheater friends of a fair player is correlated with the likelihood of her becoming a cheater in the future. This allows us to propose ideas for limiting cheating contagion.",
    "cited_by_count": 63,
    "openalex_id": "https://openalex.org/W2036131226",
    "type": "article"
  },
  {
    "title": "Approximate Semantic Matching of Events for the Internet of Things",
    "doi": "https://doi.org/10.1145/2633684",
    "publication_date": "2014-07-15",
    "publication_year": 2014,
    "authors": "Souleiman Hasan; Edward Curry",
    "corresponding_authors": "",
    "abstract": "Event processing follows a decoupled model of interaction in space, time, and synchronization. However, another dimension of semantic coupling also exists and poses a challenge to the scalability of event processing systems in highly semantically heterogeneous and dynamic environments such as the Internet of Things (IoT). Current state-of-the-art approaches of content-based and concept-based event systems require a significant agreement between event producers and consumers on event schema or an external conceptual model of event semantics. Thus, they do not address the semantic coupling issue. This article proposes an approach where participants only agree on a distributional statistical model of semantics represented in a corpus of text to derive semantic similarity and relatedness. It also proposes an approximate model for relaxing the semantic coupling dimension via an approximation-enabled rule language and an approximate event matcher. The model is formalized as an ensemble of semantic and top- k matchers along with a probability model for uncertainty management. The model has been empirically validated on large sets of events and subscriptions synthesized from real-world smart city and energy management systems. Experiments show that the proposed model achieves more than 95% F 1 Score of effectiveness and thousands of events/sec of throughput for medium degrees of approximation while not requiring users to have complete prior knowledge of event semantics. In semantically loosely-coupled environments, one approximate subscription can compensate for hundreds of exact subscriptions to cover all possibilities in environments which require complete prior knowledge of event semantics. Results indicate that approximate semantic event processing could play a promising role in the IoT middleware layer.",
    "cited_by_count": 63,
    "openalex_id": "https://openalex.org/W2160569229",
    "type": "article"
  },
  {
    "title": "An Argumentation Approach for Resolving Privacy Disputes in Online Social Networks",
    "doi": "https://doi.org/10.1145/3003434",
    "publication_date": "2017-06-27",
    "publication_year": 2017,
    "authors": "Nadin Kökciyan; Nefise Yaglikci; Pınar Yolum",
    "corresponding_authors": "",
    "abstract": "Preserving users’ privacy is important for Web systems. In systems where transactions are managed by a single user, such as e-commerce systems, preserving privacy of the transactions is merely the capability of access control. However, in online social networks, where each transaction is managed by and has effect on others, preserving privacy is difficult. In many cases, the users’ privacy constraints are distributed, expressed in a high-level manner, and would depend on information that only becomes available over interactions with others. Hence, when a content is being shared by a user, others who might be affected by the content should discuss and agree on how the content will be shared online so that none of their privacy constraints are violated. To enable this, we model users of the social networks as agents that represent their users’ privacy constraints as semantic rules. Agents argue with each other on propositions that enable their privacy rules by generating facts and assumptions from their ontology. Moreover, agents can seek help from others by requesting new information to enrich their ontology. Using assumption-based argumentation, agents decide whether a content should be shared or not. We evaluate the applicability of our approach on real-life privacy scenarios in comparison with user surveys.",
    "cited_by_count": 62,
    "openalex_id": "https://openalex.org/W2727623526",
    "type": "article"
  },
  {
    "title": "Cost-Aware Cloud Bursting for Enterprise Applications",
    "doi": "https://doi.org/10.1145/2602571",
    "publication_date": "2014-05-01",
    "publication_year": 2014,
    "authors": "Tian Guo; Upendra Sharma; Prashant Shenoy; Timothy Wood; Sambit Sahu",
    "corresponding_authors": "",
    "abstract": "The high cost of provisioning resources to meet peak application demands has led to the widespread adoption of pay-as-you-go cloud computing services to handle workload fluctuations. Some enterprises with existing IT infrastructure employ a hybrid cloud model where the enterprise uses its own private resources for the majority of its computing, but then “bursts” into the cloud when local resources are insufficient. However, current commercial tools rely heavily on the system administrator’s knowledge to answer key questions such as when a cloud burst is needed and which applications must be moved to the cloud. In this article, we describe Seagull, a system designed to facilitate cloud bursting by determining which applications should be transitioned into the cloud and automating the movement process at the proper time. Seagull optimizes the bursting of applications using an optimization algorithm as well as a more efficient but approximate greedy heuristic. Seagull also optimizes the overhead of deploying applications into the cloud using an intelligent precopying mechanism that proactively replicates virtualized applications, lowering the bursting time from hours to minutes. Our evaluation shows over 100% improvement compared to naïve solutions but produces more expensive solutions compared to ILP. However, the scalability of our greedy algorithm is dramatically better as the number of VMs increase. Our evaluation illustrates scenarios where our prototype can reduce cloud costs by more than 45% when bursting to the cloud, and that the incremental cost added by precopying applications is offset by a burst time reduction of nearly 95%.",
    "cited_by_count": 61,
    "openalex_id": "https://openalex.org/W2063001501",
    "type": "article"
  },
  {
    "title": "CloudMF",
    "doi": "https://doi.org/10.1145/3125621",
    "publication_date": "2018-01-20",
    "publication_year": 2018,
    "authors": "Nicolas Ferry; Franck Chauvel; Hui Song; Alessandro Rossini; Maksym Lushpenko; Arnor Solberg",
    "corresponding_authors": "",
    "abstract": "While the number of cloud solutions is continuously increasing, the development and operation of large-scale and distributed cloud applications are still challenging. A major challenge is the lack of interoperability between the existing cloud solutions, which increases the complexity of maintaining and evolving complex applications potentially deployed across multiple cloud infrastructures and platforms. In this article, we show how the Cloud Modelling Framework leverages model-driven engineering and supports the DevOps ideas to tame this complexity by providing: (i) a domain-specific language for specifying the provisioning and deployment of multi-cloud applications, and (ii) a models@run-time environment for their continuous provisioning, deployment, and adaptation.",
    "cited_by_count": 61,
    "openalex_id": "https://openalex.org/W2785146489",
    "type": "article"
  },
  {
    "title": "Revisiting the Risks of Bitcoin Currency Exchange Closure",
    "doi": "https://doi.org/10.1145/3155808",
    "publication_date": "2018-09-30",
    "publication_year": 2018,
    "authors": "Tyler Moore; Nicolas Christin; Janos Szurdi",
    "corresponding_authors": "",
    "abstract": "Bitcoin has enjoyed wider adoption than any previous cryptocurrency; yet its success has also attracted the attention of fraudsters who have taken advantage of operational insecurity and transaction irreversibility. We study the risk that investors face from the closure of Bitcoin exchanges, which convert between Bitcoins and hard currency. We examine the track record of 80 Bitcoin exchanges established between 2010 and 2015. We find that nearly half (38) have since closed, with customer account balances sometimes wiped out. Fraudsters are sometimes to blame, but not always. Twenty-five exchanges suffered security breaches, 15 of which subsequently closed. We present logistic regressions using longitudinal data on Bitcoin exchanges aggregated quarterly. We find that experiencing a breach is correlated with a 13 times greater odds that an exchange will close in that same quarter. We find that higher-volume exchanges are less likely to close (each doubling in trade volume corresponds to a 12% decrease in the odds of closure). We also find that exchanges that derive most of their business from trading less popular (fiat) currencies, which are offered by at most one competitor, are less likely to close.",
    "cited_by_count": 60,
    "openalex_id": "https://openalex.org/W2895636773",
    "type": "article"
  },
  {
    "title": "Measuring Third-party Tracker Power across Web and Mobile",
    "doi": "https://doi.org/10.1145/3176246",
    "publication_date": "2018-08-07",
    "publication_year": 2018,
    "authors": "Reuben Binns; Jun Zhao; Max Van Kleek; Nigel Shadbolt",
    "corresponding_authors": "",
    "abstract": "Third-party networks collect vast amounts of data about users via websites and mobile applications. Consolidations among tracker companies can significantly increase their individual tracking capabilities, prompting scrutiny by competition regulators. Traditional measures of market share, based on revenue or sales, fail to represent the tracking capability of a tracker, especially if it spans both web and mobile. This article proposes a new approach to measure the concentration of tracking capability, based on the reach of a tracker on popular websites and apps. Our results reveal that tracker prominence and parent–subsidiary relationships have significant impact on accurately measuring concentration.",
    "cited_by_count": 59,
    "openalex_id": "https://openalex.org/W2963967433",
    "type": "article"
  },
  {
    "title": "Using Centrality Measures to Predict Helpfulness-Based Reputation in Trust Networks",
    "doi": "https://doi.org/10.1145/2981545",
    "publication_date": "2017-02-25",
    "publication_year": 2017,
    "authors": "Pasquale De Meo; Katarzyna Musial-Gabrys; Domenico Rosaci; Giuseppe M. L. Sarné; Lora Aroyo",
    "corresponding_authors": "",
    "abstract": "In collaborative Web-based platforms, user reputation scores are generally computed according to two orthogonal perspectives: (a) helpfulness-based reputation (HBR) scores and (b) centrality-based reputation (CBR) scores. In HBR approaches, the most reputable users are those who post the most helpful reviews according to the opinion of the members of their community. In CBR approaches, a “who-trusts-whom” network—known as a trust network —is available and the most reputable users occupy the most central position in the trust network, according to some definition of centrality. The identification of users featuring large HBR scores is one of the most important research issue in the field of Social Networks, and it is a critical success factor of many Web-based platforms like e-marketplaces, product review Web sites, and question-and-answering systems. Unfortunately, user reviews/ratings are often sparse, and this makes the calculation of HBR scores inaccurate. In contrast, CBR scores are relatively easy to calculate provided that the topology of the trust network is known. In this article, we investigate if CBR scores are effective to predict HBR ones, and, to perform our study, we used real-life datasets extracted from CIAO and Epinions (two product review Web sites) and Wikipedia and applied five popular centrality measures—Degree Centrality, Closeness Centrality, Betweenness Centrality, PageRank and Eigenvector Centrality—to calculate CBR scores. Our analysis provides a positive answer to our research question: CBR scores allow for predicting HBR ones and Eigenvector Centrality was found to be the most important predictor. Our findings prove that we can leverage trust relationships to spot those users producing the most helpful reviews for the whole community.",
    "cited_by_count": 58,
    "openalex_id": "https://openalex.org/W2592232731",
    "type": "article"
  },
  {
    "title": "Collaborative Location Recommendation by Integrating Multi-dimensional Contextual Information",
    "doi": "https://doi.org/10.1145/3134438",
    "publication_date": "2018-02-05",
    "publication_year": 2018,
    "authors": "Lina Yao; Quan Z. Sheng; Xianzhi Wang; Wei Emma Zhang; Yongrui Qin",
    "corresponding_authors": "",
    "abstract": "Point-of-Interest (POI) recommendation is a new type of recommendation task that comes along with the prevalence of location-based social networks and services in recent years. Compared with traditional recommendation tasks, POI recommendation focuses more on making personalized and context-aware recommendations to improve user experience. Traditionally, the most commonly used contextual information includes geographical and social context information. However, the increasing availability of check-in data makes it possible to design more effective location recommendation applications by modeling and integrating comprehensive types of contextual information, especially the temporal information. In this article, we propose a collaborative filtering method based on Tensor Factorization, a generalization of the Matrix Factorization approach, to model the multi-dimensional contextual information. Tensor Factorization naturally extends Matrix Factorization by increasing the dimensionality of concerns, within which the three-dimensional model is the one most popularly used. Our method exploits a high-order tensor to fuse heterogeneous contextual information about users’ check-ins instead of the traditional two-dimensional user-location matrix. The factorization of this tensor leads to a more compact model of the data that is naturally suitable for integrating contextual information to make POI recommendations. Based on the model, we further improve the recommendation accuracy by utilizing the internal relations within users and locations to regularize the latent factors. Experimental results on a large real-world dataset demonstrate the effectiveness of our approach.",
    "cited_by_count": 58,
    "openalex_id": "https://openalex.org/W2763015105",
    "type": "article"
  },
  {
    "title": "Brains or Beauty",
    "doi": "https://doi.org/10.1145/2998572",
    "publication_date": "2017-01-04",
    "publication_year": 2017,
    "authors": "Beste F. Yuksel; Penny Collisson; Mary Czerwinski",
    "corresponding_authors": "",
    "abstract": "Software-based agents are becoming increasingly ubiquitous and automated. However, current technology and algorithms are still fallible, which considerably affects users’ trust and interaction with such agents. In this article, we investigate two factors that can engender user trust in agents: reliability and attractiveness of agents. We show that agent reliability is not more important than agent attractiveness. Subjective user ratings of agent trust and perceived accuracy suggest that attractiveness may be even more important than reliability.",
    "cited_by_count": 56,
    "openalex_id": "https://openalex.org/W2570668993",
    "type": "article"
  },
  {
    "title": "Model-Based Collaborative Personalized Recommendation on Signed Social Rating Networks",
    "doi": "https://doi.org/10.1145/2934681",
    "publication_date": "2016-07-09",
    "publication_year": 2016,
    "authors": "Gianni Costa; Riccardo Ortale",
    "corresponding_authors": "",
    "abstract": "Recommendation on signed social rating networks is studied through an innovative approach. Bayesian probabilistic modeling is used to postulate a realistic generative process, wherein user and item interactions are explained by latent factors, whose relevance varies within the underlying network organization into user communities and item groups. Approximate posterior inference captures distrust propagation and drives Gibbs sampling to allow rating and (dis)trust prediction for recommendation along with the unsupervised exploratory analysis of network organization. Comparative experiments reveal the superiority of our approach in rating and link prediction on Epinions and Ciao , besides community quality and recommendation sensitivity to network organization.",
    "cited_by_count": 55,
    "openalex_id": "https://openalex.org/W2473171929",
    "type": "article"
  },
  {
    "title": "Revealing the City That We Cannot See",
    "doi": "https://doi.org/10.1145/2677208",
    "publication_date": "2014-12-17",
    "publication_year": 2014,
    "authors": "Thiago H. Silva; Pedro O. S. Vaz de Melo; Jussara M. Almeida; Juliana Salles; Antônio A. F. Loureiro",
    "corresponding_authors": "",
    "abstract": "We here investigate the potential of participatory sensor networks derived from location sharing systems, such as Foursquare, to understand the human dynamics of cities. We propose the City Image visualization technique, which builds a transition graph mapping people's movements between location categories, and demonstrate its use to identify similarities and differences of human dynamics across cities by clustering cities according to their citizens' routines. We also analyze centrality metrics of the transition graphs built for different cities, considering transitions between specific venues. We show that these metrics complement the City Image technique, contributing to a deeper understanding of city dynamics.",
    "cited_by_count": 54,
    "openalex_id": "https://openalex.org/W2006544310",
    "type": "article"
  },
  {
    "title": "On Selecting Recommenders for Trust Evaluation in Online Social Networks",
    "doi": "https://doi.org/10.1145/2807697",
    "publication_date": "2015-11-26",
    "publication_year": 2015,
    "authors": "Wenjun Jiang; Jie Wu; Guojun Wang",
    "corresponding_authors": "",
    "abstract": "Trust is a central component of social interactions among humans. Many applications motivate the consideration of trust evaluation in online social networks (OSNs). Some work has been proposed based on a trusted graph. However, it is still an open challenge to construct a trusted graph, especially in terms of selecting proper recommenders, which can be used to predict the trustworthiness of an unknown target efficiently and effectively. Based on the intuition that people who are close to and influential to us can make more proper and acceptable recommendations, we present the idea of recommendation-aware trust evaluation (RATE). We further model the recommender selection problem as an optimization problem, with the objectives of higher accuracy, lower risk (uncertainty), and lower cost. Four metrics: trustworthiness , expertise , uncertainty , and cost , are identified to measure and adjust the quality of recommenders. We focus on a 1-hop recommender selection, for which we propose the FluidTrust model to better illustrate the trust--decision making process of a user. We also discuss the extension of multihop scenarios and multitarget scenarios. Experimental results, with the real social network datasets of Epinions and Advogato, validate the effectiveness of RATE: it can predict trust with higher accuracy (it gains about 20% higher accuracy in Epinions), lower risk, and less cost (about a 30% improvement).",
    "cited_by_count": 52,
    "openalex_id": "https://openalex.org/W2202271862",
    "type": "article"
  },
  {
    "title": "Big Data Analysis of Internet of Things System",
    "doi": "https://doi.org/10.1145/3389250",
    "publication_date": "2020-07-07",
    "publication_year": 2020,
    "authors": "Zhihan Lv; Amit Kumar Singh",
    "corresponding_authors": "",
    "abstract": "The study aims at exploring the Internet of things (IoT) system from the perspective of data and further improving the performance of the IoT system. The IoT data energy collection and information transmission system model is constructed by combining IoT and wireless relay cooperative transmission technology. Moreover, the energy efficiency, outage probability (OP), and accuracy of the model are evaluated by simulation experiments. The results show that, in the energy efficiency analysis, with the increase of power split factor ρ, the information transmission ability of the system increases. Whereas, the energy collection ability decreases, so the energy efficiency is reduced. Thus, choosing a more suitable power split factor for the energy efficiency of IoT is important. By analyzing OP and bit error rate (BER), as the values of m (Nakagami, the fading index of the fading distribution) and multi-hop paths increase, the OP and BER are reduced while the system performance is increased. Therefore, this article uses wireless relay cooperative transmission technology to integrate big data analysis into the IoT system. Finally, by adding multi-hop path and other methods to reduce the OP and BER of system, the system performance is improved. It provides experimental basis for the development of IoT systems.",
    "cited_by_count": 52,
    "openalex_id": "https://openalex.org/W3041717539",
    "type": "article"
  },
  {
    "title": "Fog in the Clouds",
    "doi": "https://doi.org/10.1145/3382756",
    "publication_date": "2020-07-07",
    "publication_year": 2020,
    "authors": "G. Faraci; Christian Grasso; Giovanni Schembra",
    "corresponding_authors": "",
    "abstract": "Internet of Things (IoT) has emerged as a huge paradigm shift by connecting a versatile and massive collection of smart objects to the Internet, coming to play an important role in our daily lives. Data produced by IoT devices can generate a number of computational tasks that cannot be executed locally on the IoT devices. The most common solution is offloading these tasks to external devices with higher computational and storage capabilities, usually provided by centralized servers in remote clouds or on the edge by using the fog computing paradigm. Nevertheless, in some IoT scenarios there are remote or challenging areas where it is difficult to connect an IoT network to a fog platform with appropriate links, especially if IoT devices produce a lot of data that require processing in real-time. To this purpose, in this article, we propose to use unmanned aerial vehicles (UAVs) as fog nodes. Although this idea is not new, this is the first work that considers power consumption of the computing element installed on board UAVs, which is crucial, since it may influence flight mission duration. A System Controller (SC) is in charge of deciding the number of active CPUs at runtime by maximizing an objective function weighing power consumption, job loss probability, and processing latency. Reinforcement Learning (RL) is used to support SC in its decisions. A numerical analysis is carried out in a use case to show how to use the model introduced in the article to decide the computation power of the computing element in terms of number of available CPUs and CPU clock speed, and evaluate the achieved performance gain of the proposed framework.",
    "cited_by_count": 52,
    "openalex_id": "https://openalex.org/W3080840693",
    "type": "article"
  },
  {
    "title": "Personalized Review Recommendation based on Users’ Aspect Sentiment",
    "doi": "https://doi.org/10.1145/3414841",
    "publication_date": "2020-10-06",
    "publication_year": 2020,
    "authors": "Huang ChunLi; Wenjun Jiang; Jie Wu; Guojun Wang",
    "corresponding_authors": "",
    "abstract": "Product reviews play an important role in guiding users’ purchase decision-making in e-commerce platforms. However, it is challenging for users to find helpful reviews that meet their preferences and experiences among an overwhelming amount of reviews. Some works have been done to recommend helpful reviews to users, either from personalized or non-personalized views. While some existing models recommend similar users’ reviews for a target user, they either neglect the target user’s aspect preferences or the user-product interactions for measuring user similarity. Moreover, those models predict review helpfulness at the review-level (a review is taken as a whole); few of them consider the aspect-level. To address the above issues, we propose an aspect sentiment similarity-based personalized review recommendation model ( A2SPR ), which quantifies review helpfulness and recommends reviews that are customized for each individual. We analyze users’ aspect preferences from reviews and improve user similarity with users’ fine-grained sentiment and product relevance. Furthermore, we redefine the review helpfulness score at the aspect level, which indicates the review’s reference value for users’ purchase decisions. Finally, we recommend the top k helpful reviews for individuals based on the review helpfulness score. To validate the performance of the proposed model, eight baselines are developed and compared. Experimental results show that our model performs better than those baselines in both the coverage and precision.",
    "cited_by_count": 52,
    "openalex_id": "https://openalex.org/W3099190990",
    "type": "article"
  },
  {
    "title": "Fuzzy Clustering of Crowdsourced Test Reports for Apps",
    "doi": "https://doi.org/10.1145/3106164",
    "publication_date": "2018-02-02",
    "publication_year": 2018,
    "authors": "He Jiang; Xin Chen; Tieke He; Zhenyu Chen; Xiaochen Li",
    "corresponding_authors": "",
    "abstract": "DevOps is a new approach to drive a seamless Application (App) cycle from development to delivery. As a critical part to promote the successful implementation of DevOps, testing can significantly improve team productivity and reliably deliver user experience. However, it is difficult to use traditional testing to cover diverse mobile phones, network environments, operating systems, and so on. Hence, many large companies crowdsource their App testing tasks to workers from open platforms. In crowdsourced testing, test reports submitted by workers may be highly redundant, and their quality may vary sharply. Meanwhile, multi-bug test reports may be submitted, and their root causes are hard to diagnose. Hence, it is a time-consuming and tedious task for developers to manually inspect these test reports. To help developers address the above challenges, we issue the new problem of Fuzzy Clustering Test Reports (FULTER). Aiming to resolve FULTER, a series of barriers need to be overcome. In this study, we propose a new framework named Test Report Fuzzy Clustering Framework (TERFUR) by aggregating redundant and multi-bug test reports into clusters to reduce the number of inspected test reports. First, we construct a filter to remove invalid test reports to break through the invalid barrier . Then, a preprocessor is built to enhance the descriptions of short test reports to break through the uneven barrier . Last, a two-phase merging algorithm is proposed to partition redundant and multi-bug test reports into clusters that can break through the multi-bug barrier . Experimental results over 1,728 test reports from five industrial Apps show that TERFUR can cluster test reports by up to 78.15% in terms of AverageP , 78.41% in terms of AverageR , and 75.82% in terms of AverageF1 and outperform comparative methods by up to 31.69%, 33.06%, and 24.55%, respectively. In addition, the effectiveness of TERFUR is validated in prioritizing test reports for manual inspection.",
    "cited_by_count": 50,
    "openalex_id": "https://openalex.org/W2789717644",
    "type": "article"
  },
  {
    "title": "MANDOLA",
    "doi": "https://doi.org/10.1145/3371276",
    "publication_date": "2020-03-04",
    "publication_year": 2020,
    "authors": "Demetris Paschalides; Dimosthenis Stephanidis; Andreas S. Andreou; Kalia Orphanou; George Pallis; Marios D. Dikaiakos; Evangelos P. Markatos",
    "corresponding_authors": "",
    "abstract": "In recent years, the increasing propagation of hate speech in online social networks and the need for effective counter-measures have drawn significant investment from social network companies and researchers. This has resulted in the development of many web platforms and mobile applications for reporting and monitoring online hate speech incidents. In this article, we present MANDOLA, a big-data processing system that monitors, detects, visualizes, and reports the spread and penetration of online hate-related speech using big-data approaches. MANDOLA consists of six individual components that intercommunicate to consume, process, store, and visualize statistical information regarding hate speech spread online. We also present a novel ensemble-based classification algorithm for hate speech detection that can significantly improve the performance of MANDOLA’s ability to detect hate speech. To present the functionality and usability of our system, we present a use case scenario of real-life event annotation and data correlation. As shown from the performance of the individual modules, as well as the usability and functionality of the whole system, MANDOLA is a powerful system for reporting and monitoring online hate speech.",
    "cited_by_count": 49,
    "openalex_id": "https://openalex.org/W3009118286",
    "type": "article"
  },
  {
    "title": "Privacy-preserving Time-series Medical Images Analysis Using a Hybrid Deep Learning Framework",
    "doi": "https://doi.org/10.1145/3383779",
    "publication_date": "2020-07-07",
    "publication_year": 2020,
    "authors": "Zijie Yue; Shuai Ding; Lei Zhao; Youtao Zhang; Zehong Cao; M. Tanveer; Alireza Jolfaei; Xi Zheng",
    "corresponding_authors": "",
    "abstract": "Time-series medical images are an important type of medical data that contain rich temporal and spatial information. As a state-of-the-art, computer-aided diagnosis (CAD) algorithms are usually used on these image sequences to improve analysis accuracy. However, such CAD algorithms are often required to upload medical images to honest-but-curious servers, which introduces severe privacy concerns. To preserve privacy, the existing CAD algorithms support analysis on each encrypted image but not on the whole encrypted image sequences, which leads to the loss of important temporal information among frames. To meet this challenge, a convolutional-LSTM network, named HE-CLSTM, is proposed for analyzing time-series medical images encrypted by a fully homomorphic encryption mechanism. Specifically, several convolutional blocks are constructed to extract discriminative spatial features, and LSTM-based sequence analysis layers (HE-LSTM) are leveraged to encode temporal information from the encrypted image sequences. Moreover, a weighted unit and a sequence voting layer are designed to incorporate both spatial and temporal features with different weights to improve performance while reducing the missed diagnosis rate. The experimental results on two challenging benchmarks (a Cervigram dataset and the BreaKHis public dataset) provide strong evidence that our framework can encode visual representations and sequential dynamics from encrypted medical image sequences; our method achieved AUCs above 0.94 both on the Cervigram and BreaKHis datasets, constituting a significant margin of statistical improvement compared with several competing methods.",
    "cited_by_count": 49,
    "openalex_id": "https://openalex.org/W3013484560",
    "type": "article"
  },
  {
    "title": "Integrity Verification Mechanism of Sensor Data Based on Bilinear Map Accumulator",
    "doi": "https://doi.org/10.1145/3380749",
    "publication_date": "2020-07-07",
    "publication_year": 2020,
    "authors": "Yongjun Ren; Jian Qi; Yepeng Liu; Jin Wang; Gwang-Jun Kim",
    "corresponding_authors": "",
    "abstract": "With the explosive growth in the number of IoT devices, ensuring the integrity of the massive data generated by these devices has become an important issue. Due to the limitation of hardware, most past data integrity verification schemes randomly select partial data blocks and then perform integrity validation on those blocks instead of examining the entire dataset. This will result in that unsampled data blocks cannot be detected even if they are tampered with. To solve this problem, we propose a new and effective integrity auditing mechanism of sensor data based on a bilinear map accumulator. Using the proposed approach will examine all the data blocks in the dataset, not just some of the data blocks, thus, eliminating the possibility of any cloud manipulation. Compared with other schemes, our proposed solution has been proved to be highly secure for all necessary security requirements, including tag forgery, data deletion, replacement, replay, and data leakage attacks. The solution reduces the computational and storage costs of cloud storage providers and verifiers, and also supports dynamic operations for data owners to insert, delete, and update data by using a tag index table (TIT). Compared with existing schemes based on RSA accumulator, our scheme has the advantages of fast verification and witness generation and no need to map data blocks to prime numbers. The new solution supports all the characteristics of a data integrity verification scheme.",
    "cited_by_count": 49,
    "openalex_id": "https://openalex.org/W3042727075",
    "type": "article"
  },
  {
    "title": "Enabling Workload Engineering in Edge, Fog, and Cloud Computing through OpenStack-based Middleware",
    "doi": "https://doi.org/10.1145/3309705",
    "publication_date": "2019-04-04",
    "publication_year": 2019,
    "authors": "Giovanni Merlino; Rustem Dautov; Salvatore Distefano; Dario Bruneo",
    "corresponding_authors": "",
    "abstract": "To enable and support smart environments, a recent ICT trend promotes pushing computation from the remote Cloud as close to data sources as possible, resulting in the emergence of the Fog and Edge computing paradigms. Together with Cloud computing, they represent a stacked architecture, in which raw datasets are first pre-processed locally at the Edge and then vertically offloaded to the Fog and/or the Cloud. However, as hardware is becoming increasingly powerful, Edge devices are seen as candidates for offering data processing capabilities, able to pool and share computing resources to achieve better performance at a lower network latency—a pattern that can be also applied to Fog nodes. In these circumstances, it is important to enable efficient, intelligent, and balanced allocation of resources, as well as their further orchestration, in an elastic and transparent manner. To address such a requirement, this article proposes an OpenStack-based middleware platform through which resource containers at the Edge, Fog, and Cloud levels can be discovered, combined, and provisioned to end users and applications, thereby facilitating and orchestrating offloading processes. As demonstrated through a proof of concept on an intelligent surveillance system, by converging the Edge, Fog, and Cloud, the proposed architecture has the potential to enable faster data processing, as compared to processing at the Edge, Fog, or Cloud levels separately. This also allows architects to combine different offloading patterns in a flexible and fine-grained manner, thus providing new workload engineering patterns. Measurements demonstrated the effectiveness of such patterns, even outperforming edge clusters.",
    "cited_by_count": 47,
    "openalex_id": "https://openalex.org/W2933625913",
    "type": "article"
  },
  {
    "title": "The Security of Medical Data on Internet Based on Differential Privacy Technology",
    "doi": "https://doi.org/10.1145/3382769",
    "publication_date": "2020-07-07",
    "publication_year": 2020,
    "authors": "Zhihan Lv; Francesco Piccialli",
    "corresponding_authors": "",
    "abstract": "The study aims at discussing the security of medical data in the Internet era. By using k-anonymity (K-A) and differential privacy (DP), an algorithm model combining K-A and DP was proposed, which was simulated through the experiments. In the Magic and EIA datasets, the algorithm constructed was compared with K-A and the L-diversity model to verify the performance of the model. The model constructed based on DP had the lowest privacy-leakage risks, which increased with the number of identifiers in the Magic and EIA datasets, and the information disclosure was the least. In addition, in its usability analysis, it was found that its value was the most obviously improved and its operation efficiency was the highest. The K-A-DP algorithm can effectively reduce the risk of privacy leakage and information loss, and has achieved excellent results. Despite the deficiencies in the process of the experiment, the study still provides a reference for solving the problem of medical data security.",
    "cited_by_count": 47,
    "openalex_id": "https://openalex.org/W3095364169",
    "type": "article"
  },
  {
    "title": "CROWD: Crow Search and Deep Learning based Feature Extractor for Classification of Parkinson’s Disease",
    "doi": "https://doi.org/10.1145/3418500",
    "publication_date": "2021-06-09",
    "publication_year": 2021,
    "authors": "Mehedi Masud; Parminder Singh; Gurjot Singh Gaba; Avinash Kaur; Roobaea Alroobaea; Mubarak Alrashoud; Salman A. AlQahtani",
    "corresponding_authors": "",
    "abstract": "Edge Artificial Intelligence (AI) is the latest trend for next-generation computing for data analytics, particularly in predictive edge analytics for high-risk diseases like Parkinson’s Disease (PD). Deep learning learning techniques facilitate edge AI applications for enhanced, real-time handling of data. Dopamine is the cause of Parkinson’s that happens due to the interference of brain cells that produce the substance to regulate the communication of brain cells. The brain cells responsible for generating the dopamine perform adaptation, control, and movement with fluency. Parkinson’s motor symptoms appear on the loss of 60% to 80% of cells, due to the non-production of appropriate dopamine. Recent research found a close connection between the speech impairment and PD. Many researchers have developed a classification algorithm to identify the PD from speech signals. In this article, Adaptive Crow Search Algorithm (ACSA) and Deep Learning (DL)–based optimal feature selection method are introduced. The proposed model is the combination of CROW Search and Deep learning (CROWD) stack sparse autoencoder neural network. Parkinson’s dataset is taken for the experiment from the Irvine dataset repository at the University of California (UCI). In the first phase, dataset cleaning is performed to handle the missing values in the dataset. After that, the proposed ACSA algorithm is employed to find the scrunched feature vector. Furthermore, stack spare autoencoder with seven hidden layers is employed to generate the compressed feature vector. The performance of the proposed CROWD autoencoder model is compared with three feature selection approaches for six supervised classification techniques. The experiment result demonstrates that the performance of the proposed CROWD autoencoder feature selection model has outperformed the benchmarked feature selection techniques: (i) Maximum Relevance (mRMR) (ii) Recursive Feature Elimination (RFE), and (iii) Correlation-based Feature Selection (CFS), to classify Parkinson’s disease. This research has significance in the healthcare sector for the enhancement of classification accuracy up to 0.96%.",
    "cited_by_count": 42,
    "openalex_id": "https://openalex.org/W3166973134",
    "type": "article"
  },
  {
    "title": "A Comparative Study of AI-Based Intrusion Detection Techniques in Critical Infrastructures",
    "doi": "https://doi.org/10.1145/3406093",
    "publication_date": "2021-07-22",
    "publication_year": 2021,
    "authors": "Safa Otoum; Burak Kantarcı; Hussein T. Mouftah",
    "corresponding_authors": "",
    "abstract": "Volunteer computing uses Internet-connected devices (laptops, PCs, smart devices, etc.), in which their owners volunteer them as storage and computing power resources, has become an essential mechanism for resource management in numerous applications. The growth of the volume and variety of data traffic on the Internet leads to concerns on the robustness of cyberphysical systems especially for critical infrastructures. Therefore, the implementation of an efficient Intrusion Detection System for gathering such sensory data has gained vital importance. In this article, we present a comparative study of Artificial Intelligence (AI)-driven intrusion detection systems for wirelessly connected sensors that track crucial applications. Specifically, we present an in-depth analysis of the use of machine learning, deep learning and reinforcement learning solutions to recognise intrusive behavior in the collected traffic. We evaluate the proposed mechanisms by using KDD’99 as real attack dataset in our simulations. Results present the performance metrics for three different IDSs, namely the Adaptively Supervised and Clustered Hybrid IDS (ASCH-IDS), Restricted Boltzmann Machine-based Clustered IDS (RBC-IDS), and Q-learning based IDS (Q-IDS), to detect malicious behaviors. We also present the performance of different reinforcement learning techniques such as State-Action-Reward-State-Action Learning (SARSA) and the Temporal Difference learning (TD). Through simulations, we show that Q-IDS performs with <?TeX $100\\%$?> detection rate while SARSA-IDS and TD-IDS perform at the order of <?TeX $99.5\\%$?> .",
    "cited_by_count": 40,
    "openalex_id": "https://openalex.org/W3183510328",
    "type": "article"
  },
  {
    "title": "Joint Encryption and Compression-Based Watermarking Technique for Security of Digital Documents",
    "doi": "https://doi.org/10.1145/3414474",
    "publication_date": "2021-01-13",
    "publication_year": 2021,
    "authors": "Amit Kumar Singh; S. Thakur; Alireza Jolfaei; Gautam Srivastava; Mohamed Elhoseny; Anand Mohan",
    "corresponding_authors": "",
    "abstract": "Recently, due to the increase in popularity of the Internet, the problem of digital data security over the Internet is increasing at a phenomenal rate. Watermarking is used for various notable applications to secure digital data from unauthorized individuals. To achieve this, in this article, we propose a joint encryption then-compression based watermarking technique for digital document security. This technique offers a tool for confidentiality, copyright protection, and strong compression performance of the system. The proposed method involves three major steps as follows: (1) embedding of multiple watermarks through non-sub-sampled contourlet transform, redundant discrete wavelet transform, and singular value decomposition; (2) encryption and compression via SHA-256 and Lempel Ziv Welch (LZW), respectively; and (3) extraction/recovery of multiple watermarks from the possibly distorted cover image. The performance estimations are carried out on various images at different attacks, and the efficiency of the system is determined in terms of peak signal-to-noise ratio (PSNR) and normalized correlation (NC), structural similarity index measure (SSIM), number of changing pixel rate (NPCR), unified averaged changed intensity (UACI), and compression ratio (CR). Furthermore, the comparative analysis of the proposed system with similar schemes indicates its superiority to them.",
    "cited_by_count": 39,
    "openalex_id": "https://openalex.org/W3120466715",
    "type": "article"
  },
  {
    "title": "Driver Identification Using Optimized Deep Learning Model in Smart Transportation",
    "doi": "https://doi.org/10.1145/3412353",
    "publication_date": "2022-02-12",
    "publication_year": 2022,
    "authors": "Chandrasekar Ravi; Anmol Tigga; Thippa Reddy Gadekallu; Saqib Hakak; Mamoun Alazab",
    "corresponding_authors": "",
    "abstract": "The Intelligent Transportation System (ITS) is said to revolutionize the travel experience by making it safe, secure, and comfortable for the people. Although vehicles have been automated up to a certain extent, it still has critical security issues that require thorough study and advanced solutions. The security vulnerabilities of ITS allows the attacker to steal the vehicle. Therefore, the identification of drivers is required in order to develop a safe and secure system so that the vehicles can be protected from theft. There are two ways in which a driver can be identified: 1) face recognition of the driver, and 2) based on driving behavior. Face recognition includes image processing of 2-D images and learning of the features, which require high computational power. Drivers are known to have unique driving styles, whose data can be captured by the sensors. Therefore, the second method identifies drivers based on the analysis of the sensor data and it requires comparatively lesser computational power. In this paper, an optimized deep learning model is trained on the sensor data to correctly identify the drivers. The Long Short-Term Memory (LSTM) deep learning model is optimized for better performance. The novelty of the approach in this work is the inclusion of hyperparameter tuning using a nature-inspired optimization algorithm, which is an important and essential step in discovering the optimal hyperparameters for training the model which in turn increases the accuracy. The CAN-BUS dataset is used for experimentation and evaluation of the training model. Evaluation parameters such as accuracy, precision score, F1 score, and ROC AUC curve are considered to evaluate the performance of the model.",
    "cited_by_count": 31,
    "openalex_id": "https://openalex.org/W4211040998",
    "type": "article"
  },
  {
    "title": "PPRP: Preserving-Privacy Route Planning Scheme in VANETs",
    "doi": "https://doi.org/10.1145/3430507",
    "publication_date": "2022-02-03",
    "publication_year": 2022,
    "authors": "Yangfan Liang; Yining Liu; Brij B. Gupta",
    "corresponding_authors": "",
    "abstract": "Route planning helps a vehicle to share a message with the roadside units (RSUs) on its path in advance, which greatly speeds the authentication between the vehicle and the RSUs when the vehicle enters the RSUs’ coverage. In addition, since only a small amount of necessary information needs to be shared between the vehicle and the RSUs, route planning can reduce the storage overhead of the vehicle’s on-board unit (OBU) and the RSUs. However, the message sharing requires the assistance of the certification authority (CA), which will lead CA easily to obtain the vehicle’s planning route. Although CA knows the vehicle’s registration information and helps the vehicle to communicate with RSUs, it is unacceptable that the path of their vehicle is obtained by CA for most drivers. In fact, vehicle’s sensitive information such as planning route, starting time, stop place, should be privacy for others including CA. Inspired with the method of oblivious transfer, a preserving-privacy route planning scheme in VANETs is proposed in this article, in which, a vehicle deduces the information of RSUs on its path with the help of CA, while CA knows nothing about which RSUs’ information has been deduced by the vehicle. Later, fast authentication or other service is easily achieved between the vehicle and the RSUs (V2R) with the pre-shared information. After V2R authentication, vehicles could easily communicate with adjacent vehicles with the help of RSUs (V2V). Finally, compared with related schemes, performance evaluation illustrates the proposed scheme is better in terms of time consumption.",
    "cited_by_count": 28,
    "openalex_id": "https://openalex.org/W4210622103",
    "type": "article"
  },
  {
    "title": "AI-Enabled Task Offloading for Improving Quality of Computational Experience in Ultra Dense Networks",
    "doi": "https://doi.org/10.1145/3491217",
    "publication_date": "2022-03-14",
    "publication_year": 2022,
    "authors": "Bo Gu; Mamoun Alazab; Ziqi Lin; Xu Zhang; Jun Huang",
    "corresponding_authors": "",
    "abstract": "Multi-access edge computing (MEC) and ultra-dense networking (UDN) are recognized as two promising paradigms for future mobile networks that can be utilized to improve the spectrum efficiency and the quality of computational experience (QoCE) . In this paper, we study the task offloading problem in an MEC-enabled UDN architecture with the aim to minimize the task duration while satisfying the energy budget constraints. Due to the dynamics associated with the environment and parameter uncertainty, designing an optimal task offloading algorithm is highly challenging. Consequently, we propose an online task offloading algorithm based on a state-of-the-art deep reinforcement learning (DRL) technique: asynchronous advantage actor-critic (A3C) . It is worthy of remark that the proposed method requires neither instantaneous channel state information (CSI) nor prior knowledge of the computational capabilities of the base stations. Simulations show that the our method is able to learn a good offloading policy to obtain a near-optimal task allocation while meeting energy budget constraints of mobile devices in the UDN environment.",
    "cited_by_count": 27,
    "openalex_id": "https://openalex.org/W4221003844",
    "type": "article"
  },
  {
    "title": "A Softwarized Intrusion Detection System for IoT-Enabled Smart Healthcare System",
    "doi": "https://doi.org/10.1145/3634748",
    "publication_date": "2023-11-27",
    "publication_year": 2023,
    "authors": "Danish Javeed; Tianhan Gao; Muhammad Shahid Saeed; Prabhat Kumar; Randhir Kumar; Alireza Jolfaei",
    "corresponding_authors": "",
    "abstract": "The Internet of Things-enabled Smart Healthcare System (IoT-SHS) is a networked infrastructure of intelligent wearables, software applications, health systems, and services that continuously monitors and transmits patient-sensitive data using an open wireless channel. The conventional security mechanisms are unsuitable for detecting attacks in the dynamic IoT-SHS context due to resource limitations and heterogeneity in low-cost healthcare devices. Deep Learning (DL) solutions for Intrusion Detection System (IDS) and softwarization of the network has the potential to achieve secure network services in the IoT-SHS environment. Motivated by the aforementioned discussion, we propose an intelligent softwarized IDS for protecting the critical infrastructure of the IoT-SHS ecosystem. Specifically, the DL-based IDS is designed using a hybrid cuda Long Short-Term Memory Deep Neural Network (cuLSTM-DNN) algorithm to assist network administrators in efficient decision-making for the generated intrusions. To further bolster the system’s resilience, we suggest a deployment architecture for the proposed CUDA-powered IDS using OpenStack Tacker in a real SDN environment, ensuring that virtual machines can directly utilize the host’s NVIDIA GPU, thereby streamlining and enhancing the network’s operational efficiency. The experimental results using the CICDDoS2019 dataset confirm the effectiveness of the proposed framework over some baseline and recent state-of-the-art techniques.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W4389057640",
    "type": "article"
  },
  {
    "title": "Advanced Context-Sensitive Access Management for Edge-Driven IoT Data Sharing as a Service",
    "doi": "https://doi.org/10.1145/3721430",
    "publication_date": "2025-03-01",
    "publication_year": 2025,
    "authors": "Phu H. Nguyen; Huu-Ha Nguyen; Phu H. Phung; Hong‐Linh Truong; Thomas Cheung",
    "corresponding_authors": "",
    "abstract": "The Internet of Things (IoT) is becoming increasingly ubiquitous, acting as an important source of real-time data for various applications. By allowing data exchange between various parties along the IoT devices-Edge-Cloud computing continuum, the larger societal benefits of the IoT can be achieved. Assuring security and fostering confidence for IoT data sharing, however, is one of the biggest obstacles. Sharing real-time data originating from connected devices is crucial to real-world intelligent IoT applications, i.e., based on artificial intelligence/machine learning. Such IoT data sharing involves multiple parties for different purposes and is usually based on data contracts that might depend on the dynamic change of IoT data variety and velocity. We aim to support multiple parties (aka tenants) with dynamic contracts based on the data value for their specific contextual purposes. This work addresses these challenges by introducing a novel dynamic context-based policy enforcement framework to support IoT data sharing (on-Edge) based on dynamic contracts. Our enforcement framework allows IoT Data Hub owners to define extensible rules and metrics to govern the tenants accessing the shared data on the Edge based on policies defined with static and dynamic contexts. We have created an edge-centered architecture that enables multi-tenant use cases with tenant-specific application deployment and IoT-context-based data sharing on edge servers. Our proof-of-concept prototype for sharing sensitive data such as surveillance camera videos has illustrated our proposed framework. The experimental results demonstrated that our framework could soundly and timely enforce context-based policies at runtime with moderate overhead. Moreover, the context and policy changes are correctly reflected in the system in nearly real-time. We have addressed the need to enable multi-parties IoT (data) resources to be shared based on contracts, especially with dynamic IoT contexts, for tenant applications on the edge to allow their closer access to data.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4408070676",
    "type": "article"
  },
  {
    "title": "HeLoRA: LoRA-heterogeneous Federated Fine-tuning for Foundation Models",
    "doi": "https://doi.org/10.1145/3723877",
    "publication_date": "2025-03-15",
    "publication_year": 2025,
    "authors": "Boyu Fan; Xiang Su; Sasu Tarkoma; Pan Hui",
    "corresponding_authors": "",
    "abstract": "Foundation models (FMs) have achieved state-of-the-art performance across various domains, benefiting from their vast number of parameters and the extensive amount of publicly available training data. However, real-world deployments reveal challenges such as system heterogeneity, where not all devices can handle the complexity of FMs, and emerging privacy concerns that limit the availability of public data. To address these challenges, we propose HeLoRA, a novel approach combining low-rank adaptation (LoRA) with federated learning to enable heterogeneous federated fine-tuning. HeLoRA allows clients to fine-tune models with different complexities by adjusting the rank values of LoRA matrices, tailoring the process to each device’s capabilities. To tackle the challenge of aggregating models with different structures, HeLoRA introduces two variants, i.e., HeLoRA-Pad and HeLoRA-KD. HeLoRA-Pad employs context-based padding to standardize the LoRA matrices, aligning them with the global model through a rank-based adaptive aggregation strategy. In contrast, HeLoRA-KD leverages the idea of deep mutual learning for aggregation, allowing heterogeneous models to retain their original structures. Extensive experiments with various datasets and ablation studies demonstrate that HeLoRA outperforms existing baselines, promising to enhance the practical deployment of FMs in diverse real-world environments.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4408489664",
    "type": "article"
  },
  {
    "title": "The use of web structure and content to identify subjectively interesting web usage patterns",
    "doi": "https://doi.org/10.1145/767193.767194",
    "publication_date": "2003-05-01",
    "publication_year": 2003,
    "authors": "Robert Cooley",
    "corresponding_authors": "Robert Cooley",
    "abstract": "The discipline of Web Usage Mining has grown rapidly in the past few years, despite the crash of the e-commerce boom of the late 1990s. Web Usage Mining is the application of data mining techniques to Web clickstream data in order to extract usage patterns. Yet, with all of the resources put into the problem, claims of success have been limited and are often tied to specific Web site properties that are not found in general. One reason for the limited success has been a component of Web Usage Mining that is often overlooked---the need to understand the content and structure of a Web site. The processing and quantification of a Web sites content and structure for all but completely static and single frame Web sites is arguably one of the most difficult tasks to automate in the Web Usage Mining process. This article shows that, not only is the Web Usage Mining process enhanced by content and structure, it cannot be completed without it. The results of experiments run on data from a large e-commerce site are presented to show that proper preprocessing cannot be completed without the use of Web site content and structure, and that the effectiveness of pattern analysis is greatly enhanced.",
    "cited_by_count": 91,
    "openalex_id": "https://openalex.org/W2022120051",
    "type": "article"
  },
  {
    "title": "On filter effects in web caching hierarchies",
    "doi": "https://doi.org/10.1145/503334.503337",
    "publication_date": "2002-02-01",
    "publication_year": 2002,
    "authors": "Carey Williamson",
    "corresponding_authors": "Carey Williamson",
    "abstract": "This article studies the \"filter effects\" that occur in Web proxy caching hierarchies due to the presence of multiple levels of caches. That is, the presence of one level of cache changes the structural characteristics of the workload presented to the next level of cache, since only the requests that miss in one cache are forwarded to the next cache.Trace-driven simulations, with empirical and synthetic traces, are used to demonstrate the presence and magnitude of the filter effects in a multilevel Web proxy caching hierarchy. Experiments focus on the effects of cache size, cache replacement policy, Zipf slope, and the depth of the Web proxy caching hierarchy.Finally, the article considers novel cache management techniques that can better exploit the changing workload characteristics across a multilevel Web proxy caching hierarchy. Trace-driven simulations are used to evaluate the performance of these approaches. The simulation results demonstrate that size-based partitioning and heterogeneous cache replacement policies each offer improvements in overall caching performance. The sensitivity of the results to the degree of workload overlap among child-level proxy caches is also studied.",
    "cited_by_count": 91,
    "openalex_id": "https://openalex.org/W2058165990",
    "type": "article"
  },
  {
    "title": "Fine-grained control of security capabilities",
    "doi": "https://doi.org/10.1145/967030.967033",
    "publication_date": "2004-02-01",
    "publication_year": 2004,
    "authors": "Dan Boneh; Xuhua Ding; Gene Tsudik",
    "corresponding_authors": "",
    "abstract": "We present a new approach for fine-grained control over users' security privileges (fast revocation of credentials) centered around the concept of an on-line semi-trusted mediator (SEM). The use of a SEM in conjunction with a simple threshold variant of the RSA cryptosystem (mediated RSA) offers a number of practical advantages over current revocation techniques. The benefits include simplified validation of digital signatures, efficient certificate revocation for legacy systems and fast revocation of signature and decryption capabilities. This paper discusses both the architecture and the implementation of our approach as well as its performance and compatibility with the existing infrastructure. Experimental results demonstrate its practical aspects.",
    "cited_by_count": 77,
    "openalex_id": "https://openalex.org/W2168483707",
    "type": "article"
  },
  {
    "title": "24-hour knowledge factory",
    "doi": "https://doi.org/10.1145/1275505.1275507",
    "publication_date": "2007-08-01",
    "publication_year": 2007,
    "authors": "Amar Gupta; Satwik Seshasai",
    "corresponding_authors": "",
    "abstract": "Several of the outsourcing endeavors of today will gradually converge to a hybrid outsourcing model that will involve a team spread across three or more strategically-located centers interconnected by Internet technology. White-collar professionals in the US, Australia, and Poland, for example, could each work on a standard 9--5 basis, transfer the activity to a colleague in the next center, thereby enabling work to be performed on a round-the-clock basis. The effective use of sequential workers in such a 24-hour knowledge factory requires that professional tasks be broken down to the level where individuals can work on them with minimal interaction with their peers, and where new approaches can be employed to reduce the effort involved in transitioning from one employee to the next. This article describes an Internet-based prototype system that uses a Web-based interactive approach, coupled with a unique data model, to optimize collection and storage of design rationale and history from stakeholders and workers. The idea of multiple individuals acting as one “composite persona” is explored in the context of facilitating tasks and knowledge to be shared across the Internet in a seamless manner. The article also describes related activities in the commercial arena.",
    "cited_by_count": 74,
    "openalex_id": "https://openalex.org/W1998650530",
    "type": "article"
  },
  {
    "title": "Searching for experts on the Web",
    "doi": "https://doi.org/10.1145/1183463.1183464",
    "publication_date": "2006-11-01",
    "publication_year": 2006,
    "authors": "Irma Becerra‐Fernandez",
    "corresponding_authors": "Irma Becerra‐Fernandez",
    "abstract": "This article presents the role of ontologies and Web mining techniques in the construction and maintenance of experts' profiles. This article also discusses the development of contemporary expertise-locator knowledge management systems and, specifically, the implementation details of two such systems: the Searchable Answer Generating Engine (SAGE), and Expert Seeker. SAGE is a Web-based expertise locator system, which searches for researchers in universities in Florida based on specified criteria, including expertise in a specific domain. Expert Seeker's purpose is to search for experts in one of the best-known knowledge organizations, the National Aeronautics and Space Administration. Implementation details, results to date, and future plans for these systems are also presented.",
    "cited_by_count": 73,
    "openalex_id": "https://openalex.org/W2040191342",
    "type": "article"
  },
  {
    "title": "Stanford WebBase components and applications",
    "doi": "https://doi.org/10.1145/1149121.1149124",
    "publication_date": "2006-05-01",
    "publication_year": 2006,
    "authors": "Junghoo Cho; Héctor García-Molina; Taher H. Haveliwala; Wang Lam; Andreas Paepcke; Sriram Raghavan; Gary Wesley",
    "corresponding_authors": "",
    "abstract": "We describe the design and performance of WebBase, a tool for Web research. The system includes a highly customizable crawler, a repository for collected Web pages, an indexer for both text and link-related page features, and a high-speed content distribution facility. The distribution module enables researchers world-wide to retrieve pages from WebBase, and stream them across the Internet at high speed. The advantage for the researchers is that they need not all crawl the Web before beginning their research. WebBase has been used by scores of research and teaching organizations world-wide, mostly for investigations into Web topology and linguistic content analysis. After describing the system's architecture, we explain our engineering decisions for each of the WebBase components, and present respective performance measurements.",
    "cited_by_count": 71,
    "openalex_id": "https://openalex.org/W2000333294",
    "type": "article"
  },
  {
    "title": "Model-driven design and development of semantic Web service applications",
    "doi": "https://doi.org/10.1145/1294148.1294151",
    "publication_date": "2007-11-01",
    "publication_year": 2007,
    "authors": "Marco Brambilla; Stefano Ceri; Federico Michele Facca; Irene Celino; Dario Cerizza; Emanuele Della Valle",
    "corresponding_authors": "",
    "abstract": "This article proposes a model-driven methodology to design and develop semantic Web service applications and their components, described according to the emerging WSMO standard. In particular, we show that business processes and Web engineering models have sufficient expressive power to support the semiautomatic extraction of semantic descriptions (i.e., WSMO ontologies, goals, Web services, and mediators), thus partially hiding the complexity of dealing with semantics. Our method is based on existing models for the specification of business processes (BPMN) combined with Web engineering models for designing and developing semantically rich Web applications (WebML). The proposed approach leads from an abstract view of the business needs to a concrete implementation of the application by means of several design steps; high-level models are transformed into software components. Our framework increases the efficiency of the whole design process, yielding to the construction of semantic Web service applications spanning over several enterprises.",
    "cited_by_count": 63,
    "openalex_id": "https://openalex.org/W2016430614",
    "type": "article"
  },
  {
    "title": "MCEP",
    "doi": "https://doi.org/10.1145/2633688",
    "publication_date": "2014-07-15",
    "publication_year": 2014,
    "authors": "Beate Ottenwälder; Boris Koldehofe; Kurt Rothermel; Kirak Hong; David Lillethun; Umakishore Ramachandran",
    "corresponding_authors": "",
    "abstract": "With the proliferation of mobile devices and sensors, complex event proceesing (CEP) is becoming increasingly important to scalably detect situations in real time. Current CEP systems are not capable of dealing efficiently with highly dynamic mobile consumers whose interests change with their location. We introduce the distributed mobile CEP (MCEP) system which automatically adapts the processing of events according to a consumer's location. MCEP significantly reduces latency, network utilization, and processing overhead by providing on-demand and opportunistic adaptation algorithms to dynamically assign event streams and computing resources to operators of the MCEP system.",
    "cited_by_count": 52,
    "openalex_id": "https://openalex.org/W2134155551",
    "type": "article"
  },
  {
    "title": "A smart web service based on the context of things",
    "doi": "https://doi.org/10.1145/2078316.2078321",
    "publication_date": "2012-01-01",
    "publication_year": 2012,
    "authors": "Jing He; Yanchun Zhang; Guangyan Huang; Jinli Cao",
    "corresponding_authors": "",
    "abstract": "Combining the Semantic Web and the Ubiquitous Web, Web 3.0 is for things . The Semantic Web enables human knowledge to be machine-readable and the Ubiquitous Web allows Web services to serve any thing, forming a bridge between the virtual world and the real world. By using context, Web services can become smarter—that is, aware of the target things' or applications' physical environments, or situations and respond proactively and intelligently. Existing methods for implementing context-aware Web services on Web 2.0 mainly enumerate different implementations corresponding to different attribute values of the context, in order to improve the Quality of Services (QoS). However, things in the physical world are extremely diverse, which poses new problems for Web services: it is difficult to unify the context of things and to implement a flexible smart Web service for things. This article proposes a novel smart Web service based on the context of things, which is implemented using a REpresentational State Transfer for Things (Thing-REST) style, to tackle the two problems. In a smart Web service, the user's description (semantic context) and sensor reports (sensing context) are two channels for acquiring the context of things which are then employed by ontology services to make the context of things machine-readable. With guidance of domain knowledge services, event detection services can analyze things' needs particularly, well through the context of things. We then propose a Thing-REST style to manage the context of things and user context, and to mashup Web services through three structures (i.e., chain, select, and merge) to implement smart Web services. A smart plant watering-service application demonstrates the effectiveness of our method.",
    "cited_by_count": 50,
    "openalex_id": "https://openalex.org/W2001829231",
    "type": "article"
  },
  {
    "title": "The Uncertain Web",
    "doi": "https://doi.org/10.1145/2847252",
    "publication_date": "2015-12-28",
    "publication_year": 2015,
    "authors": "Djamal Benslimane; Quan Z. Sheng; Mahmoud Barhamgi; Henri Prade",
    "corresponding_authors": "",
    "abstract": "editorial Free Access Share on The Uncertain Web: Concepts, Challenges, and Current Solutions Authors: Djamal Benslimane Claude Bernard University Lyon 1, CEDEX, France Claude Bernard University Lyon 1, CEDEX, FranceView Profile , Quan Z. Sheng The University of Adelaide, SA, Australia The University of Adelaide, SA, AustraliaView Profile , Mahmoud Barhamgi The Open University & Claude Bernard University Lyon 1 The Open University & Claude Bernard University Lyon 1View Profile , Henri Prade Paul Sabatier University & University Technology Sydney, Ultimo NSW, Australia Paul Sabatier University & University Technology Sydney, Ultimo NSW, AustraliaView Profile Authors Info & Claims ACM Transactions on Internet TechnologyVolume 16Issue 1February 2016 Article No.: 1pp 1–6https://doi.org/10.1145/2847252Published:28 December 2015Publication History 11citation477DownloadsMetricsTotal Citations11Total Downloads477Last 12 Months26Last 6 weeks2 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 47,
    "openalex_id": "https://openalex.org/W2219965000",
    "type": "article"
  },
  {
    "title": "Authentication Protocol for an IoT-Enabled LTE Network",
    "doi": "https://doi.org/10.1145/2981547",
    "publication_date": "2016-12-09",
    "publication_year": 2016,
    "authors": "Neetesh Saxena; Santiago Grijalva; Narendra S. Chaudhari",
    "corresponding_authors": "",
    "abstract": "The Evolved Packet System-based Authentication and Key Agreement (EPS-AKA) protocol of the long-term evolution (LTE) network does not support Internet of Things (IoT) objects and has several security limitations, including transmission of the object’s (user/device) identity and key set identifier in plaintext over the network, synchronization, large overhead, limited identity privacy, and security attack vulnerabilities. In this article, we propose a new secure and efficient AKA protocol for the LTE network that supports secure and efficient communications among various IoT devices as well as among the users. Analysis shows that our protocol is secure, efficient, and privacy preserved, and reduces bandwidth consumption during authentication.",
    "cited_by_count": 45,
    "openalex_id": "https://openalex.org/W2560683465",
    "type": "article"
  },
  {
    "title": "Measurement Theory-Based Trust Management Framework for Online Social Communities",
    "doi": "https://doi.org/10.1145/3015771",
    "publication_date": "2017-03-24",
    "publication_year": 2017,
    "authors": "Yefeng Ruan; Ping Zhang; Lina Alfantoukh; Arjan Durresi",
    "corresponding_authors": "",
    "abstract": "We propose a trust management framework based on measurement theory to infer indirect trust in online social communities using trust’s transitivity property. Inspired by the similarities between human trust and measurement, we propose a new trust metric, composed of impression and confidence, which captures both trust level and its certainty. Furthermore, based on error propagation theory, we propose a method to compute indirect confidence according to different trust transitivity and aggregation operators. We perform experiments on two real data sets, Epinions.com and Twitter, to validate our framework. Also, we show that inferring indirect trust can connect more pairs of users.",
    "cited_by_count": 45,
    "openalex_id": "https://openalex.org/W2600815905",
    "type": "article"
  },
  {
    "title": "SoIoT",
    "doi": "https://doi.org/10.1145/2835492",
    "publication_date": "2016-04-15",
    "publication_year": 2016,
    "authors": "In‐Young Ko; Han-Gyu Ko; Angel Jimenez-Molina; Jung Hyun Kwon",
    "corresponding_authors": "",
    "abstract": "An emerging issue in urban computing environments is the seamless selection, composition, and delivery of user-centric services that run over what is known as the Internet of Things (IoT). This challenge is about enabling services actuated by IoT devices to be delivered spontaneously from the perspective of users. To accomplish this goal, we propose the Service-Oriented Internet of Things (SoIoT), a user-centric IoT-based service framework, which integrates services that utilize IoT resources in an urban computing environment. This framework provides a task-oriented computing approach that enables the composition of IoT-based services in a spontaneous manner to accomplish a user task. Tasks can also be recommended to users based on the available IoT resources in an environment and on the contextual knowledge that is represented and managed in social, spatial, and temporal aspects. These tasks are then bound to a set of service instances and performed in a distributed manner. This final composition ensures the Quality of Service (QoS) requirements of the tasks and is assigned to multiple client devices for the efficient utilization of IoT resources. We prove the practicality of our approach by showing a real-case service scenario implemented in our IoT-based test-bed as well as experimental results.",
    "cited_by_count": 42,
    "openalex_id": "https://openalex.org/W2337936032",
    "type": "article"
  },
  {
    "title": "Unsupervised Extraction of Popular Product Attributes from E-Commerce Web Sites by Considering Customer Reviews",
    "doi": "https://doi.org/10.1145/2857054",
    "publication_date": "2016-04-15",
    "publication_year": 2016,
    "authors": "Lidong Bing; Tak-Lam Wong; Wai Lam",
    "corresponding_authors": "",
    "abstract": "We develop an unsupervised learning framework for extracting popular product attributes from product description pages originated from different E-commerce Web sites. Unlike existing information extraction methods that do not consider the popularity of product attributes, our proposed framework is able to not only detect popular product features from a collection of customer reviews but also map these popular features to the related product attributes. One novelty of our framework is that it can bridge the vocabulary gap between the text in product description pages and the text in customer reviews. Technically, we develop a discriminative graphical model based on hidden Conditional Random Fields. As an unsupervised model, our framework can be easily applied to a variety of new domains and Web sites without the need of labeling training samples. Extensive experiments have been conducted to demonstrate the effectiveness and robustness of our framework.",
    "cited_by_count": 41,
    "openalex_id": "https://openalex.org/W2340809461",
    "type": "article"
  },
  {
    "title": "A Fog-Based Application for Human Activity Recognition Using Personal Smart Devices",
    "doi": "https://doi.org/10.1145/3266142",
    "publication_date": "2019-03-28",
    "publication_year": 2019,
    "authors": "Federico Concone; Giuseppe Lo Re; Marco Morana",
    "corresponding_authors": "",
    "abstract": "The diffusion of heterogeneous smart devices capable of capturing and analysing data about users, and/or the environment, has encouraged the growth of novel sensing methodologies. One of the most attractive scenarios in which such devices, such as smartphones, tablet computers, or activity trackers, can be exploited to infer relevant information is human activity recognition (HAR). Even though some simple HAR techniques can be directly implemented on mobile devices, in some cases, such as when complex activities need to be analysed timely, users’ smart devices can operate as part of a more complex architecture. In this article, we propose a multi-device HAR framework that exploits the fog computing paradigm to move heavy computation from the sensing layer to intermediate devices and then to the cloud. As compared to traditional cloud-based solutions, this choice allows to overcome processing and storage limitations of wearable devices while also reducing the overall bandwidth consumption. Experimental analysis aims to evaluate the performance of the entire platform in terms of accuracy of the recognition process while also highlighting the benefits it might bring in smart environments.",
    "cited_by_count": 40,
    "openalex_id": "https://openalex.org/W2926525016",
    "type": "article"
  },
  {
    "title": "Adaptive Resource Allocation for Computation Offloading",
    "doi": "https://doi.org/10.1145/3284553",
    "publication_date": "2019-04-03",
    "publication_year": 2019,
    "authors": "Marios Avgeris; Dimitrios Dechouniotis; Νικόλαος Αθανασόπουλος; Symeon Papavassiliou",
    "corresponding_authors": "",
    "abstract": "Although mobile devices today have powerful hardware and networking capabilities, they fall short when it comes to executing compute-intensive applications. Computation offloading (i.e., delegating resource-consuming tasks to servers located at the edge of the network) contributes toward moving to a mobile cloud computing paradigm. In this work, a two-level resource allocation and admission control mechanism for a cluster of edge servers offers an alternative choice to mobile users for executing their tasks. At the lower level, the behavior of edge servers is modeled by a set of linear systems, and linear controllers are designed to meet the system’s constraints and quality of service metrics, whereas at the upper level, an optimizer tackles the problems of load balancing and application placement toward the maximization of the number the offloaded requests. The evaluation illustrates the effectiveness of the proposed offloading mechanism regarding the performance indicators, such as application average response time, and the optimal utilization of the computational resources of edge servers.",
    "cited_by_count": 39,
    "openalex_id": "https://openalex.org/W2896560674",
    "type": "article"
  },
  {
    "title": "Towards Communication-Efficient and Attack-Resistant Federated Edge Learning for Industrial Internet of Things",
    "doi": "https://doi.org/10.1145/3453169",
    "publication_date": "2021-12-06",
    "publication_year": 2021,
    "authors": "Yi Liu; Ruihui Zhao; Jiawen Kang; Abdulsalam Yassine; Dusit Niyato; Jialiang Peng",
    "corresponding_authors": "",
    "abstract": "Federated Edge Learning (FEL) allows edge nodes to train a global deep learning model collaboratively for edge computing in the Industrial Internet of Things (IIoT), which significantly promotes the development of Industrial 4.0. However, FEL faces two critical challenges: communication overhead and data privacy. FEL suffers from expensive communication overhead when training large-scale multi-node models. Furthermore, due to the vulnerability of FEL to gradient leakage and label-flipping attacks, the training process of the global model is easily compromised by adversaries. To address these challenges, we propose a communication-efficient and privacy-enhanced asynchronous FEL framework for edge computing in IIoT. First, we introduce an asynchronous model update scheme to reduce the computation time that edge nodes wait for global model aggregation. Second, we propose an asynchronous local differential privacy mechanism, which improves communication efficiency and mitigates gradient leakage attacks by adding well-designed noise to the gradients of edge nodes. Third, we design a cloud-side malicious node detection mechanism to detect malicious nodes by testing the local model quality. Such a mechanism can avoid malicious nodes participating in training to mitigate label-flipping attacks. Extensive experimental studies on two real-world datasets demonstrate that the proposed framework can not only improve communication efficiency but also mitigate malicious attacks while its accuracy is comparable to traditional FEL frameworks.",
    "cited_by_count": 36,
    "openalex_id": "https://openalex.org/W3111292980",
    "type": "article"
  },
  {
    "title": "Machine Learning and Soil Humidity Sensing: Signal Strength Approach",
    "doi": "https://doi.org/10.1145/3418207",
    "publication_date": "2021-10-29",
    "publication_year": 2021,
    "authors": "Lea Dujić Rodić; Tomislav Županović; Toni Perković; Petar Šolić; Joel J. P. C. Rodrigues",
    "corresponding_authors": "",
    "abstract": "The Internet-of-Things vision of ubiquitous and pervasive computing gives rise to future smart irrigation systems comprising the physical and digital worlds. A smart irrigation ecosystem combined with Machine Learning can provide solutions that successfully solve the soil humidity sensing task in order to ensure optimal water usage. Existing solutions are based on data received from the power hungry/expensive sensors that are transmitting the sensed data over the wireless channel. Over time, the systems become difficult to maintain, especially in remote areas due to the battery replacement issues with a large number of devices. Therefore, a novel solution must provide an alternative, cost- and energy-effective device that has unique advantage over the existing solutions. This work explores the concept of a novel, low-power, LoRa-based, cost-effective system that achieves humidity sensing using Deep Learning techniques that can be employed to sense soil humidity with high accuracy simply by measuring the signal strength of the given underground beacon device.",
    "cited_by_count": 36,
    "openalex_id": "https://openalex.org/W3211063584",
    "type": "article"
  },
  {
    "title": "Intelligent Control and Security of Fog Resources in Healthcare Systems via a Cognitive Fog Model",
    "doi": "https://doi.org/10.1145/3382770",
    "publication_date": "2020-07-07",
    "publication_year": 2020,
    "authors": "Mohammed Al-Khafajiy; Safa Otoum; Thar Baker; Muhammad Asim; Zakaria Maamar; Moayad Aloqaily; Mark Taylor; Martin Randles",
    "corresponding_authors": "",
    "abstract": "There have been significant advances in the field of Internet of Things (IoT) recently, which have not always considered security or data security concerns: A high degree of security is required when considering the sharing of medical data over networks. In most IoT-based systems, especially those within smart-homes and smart-cities, there is a bridging point (fog computing) between a sensor network and the Internet which often just performs basic functions such as translating between the protocols used in the Internet and sensor networks, as well as small amounts of data processing. The fog nodes can have useful knowledge and potential for constructive security and control over both the sensor network and the data transmitted over the Internet. Smart healthcare services utilise such networks of IoT systems. It is therefore vital that medical data emanating from IoT systems is highly secure, to prevent fraudulent use, whilst maintaining quality of service providing assured, verified and complete data. In this article, we examine the development of a Cognitive Fog (CF) model, for secure, smart healthcare services, that is able to make decisions such as opting-in and opting-out from running processes and invoking new processes when required, and providing security for the operational processes within the fog system. Overall, the proposed ensemble security model performed better in terms of Accuracy Rate, Detection Rate, and a lower False Positive Rate (standard intrusion detection measurements) than three base classifiers (K-NN, DBSCAN, and DT) using a standard security dataset (NSL-KDD).",
    "cited_by_count": 35,
    "openalex_id": "https://openalex.org/W3041199072",
    "type": "article"
  },
  {
    "title": "Proactive Defense for Internet-of-things: Moving Target Defense With Cyberdeception",
    "doi": "https://doi.org/10.1145/3467021",
    "publication_date": "2021-09-14",
    "publication_year": 2021,
    "authors": "Mengmeng Ge; Jin-Hee Cho; Dong Seong Kim; Gaurav Dixit; Ing-Ray Chen",
    "corresponding_authors": "",
    "abstract": "Resource constrained Internet-of-Things (IoT) devices are highly likely to be compromised by attackers, because strong security protections may not be suitable to be deployed. This requires an alternative approach to protect vulnerable components in IoT networks. In this article, we propose an integrated defense technique to achieve intrusion prevention by leveraging cyberdeception (i.e., a decoy system) and moving target defense (i.e., network topology shuffling). We evaluate the effectiveness and efficiency of our proposed technique analytically based on a graphical security model in a software-defined networking (SDN)-based IoT network. We develop four strategies (i.e., fixed/random and adaptive/hybrid) to address “when” to perform network topology shuffling and three strategies (i.e., genetic algorithm/decoy attack path-based optimization/random) to address “how” to perform network topology shuffling on a decoy-populated IoT network, and we analyze which strategy can best achieve a system goal, such as prolonging the system lifetime, maximizing deception effectiveness, maximizing service availability, or minimizing defense cost. We demonstrated that a software-defined IoT network running our intrusion prevention technique at the optimal parameter setting prolongs system lifetime, increases attack complexity of compromising critical nodes, and maintains superior service availability compared with a counterpart IoT network without running our intrusion prevention technique. Further, when given a single goal or a multi-objective goal (e.g., maximizing the system lifetime and service availability while minimizing the defense cost) as input, the best combination of “when” and “how” strategies is identified for executing our proposed technique under which the specified goal can be best achieved.",
    "cited_by_count": 35,
    "openalex_id": "https://openalex.org/W3200064363",
    "type": "article"
  },
  {
    "title": "Data Privacy Based on IoT Device Behavior Control Using Blockchain",
    "doi": "https://doi.org/10.1145/3434776",
    "publication_date": "2021-01-05",
    "publication_year": 2021,
    "authors": "Faiza Loukil; Chirine Ghédira; Khouloud Boukadi; Benharkat Aïcha-Nabila; Elhadj Benkhelifa",
    "corresponding_authors": "",
    "abstract": "The Internet of Things (IoT) is expected to improve the individuals’ quality of life. However, ensuring security and privacy in the IoT context is a non-trivial task due to the low capability of these connected devices. Generally, the IoT device management is based on a centralized entity that validates communication and connection rights. Therefore, this centralized entity can be considered as a single point of failure. Yet, in the case of distributed approaches, it is difficult to delegate the right validation to IoT devices themselves in untrustworthy IoT environments. Fortunately, the blockchain may provide decentralization of overcoming the trust problem while designing a privacy-preserving system. To this end, we propose a novel privacy-preserving IoT device management framework based on the blockchain technology. In the proposed system, the IoT devices are controlled by several smart contracts that validate the connection rights according to the privacy permission settings predefined by the data owners and the stored record array of detected misbehavior of each IoT device. In fact, smart contracts can immediately detect the devices that have vulnerabilities and have been hacked or pose a threat to the IoT network. Therefore, the data owner’s privacy is preserved by enforcing the control over the own devices. For validation purposes, we deploy the proposed solution on a private Ethereum blockchain and give the performance evaluation.",
    "cited_by_count": 33,
    "openalex_id": "https://openalex.org/W3106736588",
    "type": "article"
  },
  {
    "title": "Stance-level Sarcasm Detection with BERT and Stance-centered Graph Attention Networks",
    "doi": "https://doi.org/10.1145/3533430",
    "publication_date": "2022-05-02",
    "publication_year": 2022,
    "authors": "Yazhou Zhang; Dan Ma; Prayag Tiwari; Chen Zhang; Mehedi Masud; Mohammad Shorfuzzaman; Dawei Song",
    "corresponding_authors": "",
    "abstract": "Computational Linguistics (CL) associated with the Internet of Multimedia Things (IoMT)-enabled multimedia computing applications brings several research challenges, such as real-time speech understanding, deep fake video detection, emotion recognition, home automation, and so on. Due to the emergence of machine translation, CL solutions have increased tremendously for different natural language processing (NLP) applications. Nowadays, NLP-enabled IoMT is essential for its success. Sarcasm detection, a recently emerging artificial intelligence (AI) and NLP task, aims at discovering sarcastic, ironic, and metaphoric information implied in texts that are generated in the IoMT. It has drawn much attention from the AI and IoMT research community. The advance of sarcasm detection and NLP techniques will provide a cost-effective, intelligent way to work together with machine devices and high-level human-to-device interactions. However, existing sarcasm detection approaches neglect the hidden stance behind texts, thus insufficient to exploit the full potential of the task. Indeed, the stance, i.e., whether the author of a text is in favor of, against, or neutral toward the proposition or target talked in the text, largely determines the text’s actual sarcasm orientation. To fill the gap, in this research, we propose a new task: stance-level sarcasm detection (SLSD), where the goal is to uncover the author’s latent stance and based on it to identify the sarcasm polarity expressed in the text. We then propose an integral framework, which consists of Bidirectional Encoder Representations from Transformers (BERT) and a novel stance-centered graph attention networks (SCGAT). Specifically, BERT is used to capture the sentence representation, and SCGAT is designed to capture the stance information on specific target. Extensive experiments are conducted on a Chinese sarcasm sentiment dataset we created and the SemEval-2018 Task 3 English sarcasm dataset. The experimental results prove the effectiveness of the SCGAT framework over state-of-the-art baselines by a large margin.",
    "cited_by_count": 25,
    "openalex_id": "https://openalex.org/W4225271996",
    "type": "article"
  },
  {
    "title": "Three-tier Storage Framework Based on TBchain and IPFS for Protecting IoT Security and Privacy",
    "doi": "https://doi.org/10.1145/3549910",
    "publication_date": "2022-09-05",
    "publication_year": 2022,
    "authors": "Ying Li; Yaxin Yu; Xingwei Wang",
    "corresponding_authors": "",
    "abstract": "Recently, most of the Internet of things (IoT) infrastructures are highly centralized with single points of failure, which results in serious security and privacy issues of IoT data. Fortunately, blockchain technique can provide a decentralized and secure IoT framework to deal with security issues based on the characteristics of decentralization, non-tampering, openness, transparency, and traceability. However, the blockchain consensus protocol guarantees the safety and reliability of data, but it also brings problems such as scalability limitations and poor storage extensibility, resulting in the inability to directly integrate blockchain and the IoT in existing conditions. In this article, a private three-tier local blockchain, Three-tier architecture Blockchain (TBchain), is proposed to solve the problem by splitting part of the transactions in the public blockchain and locking them in a higher-level blockchain TBchain. Additionally, the private blockchain TBchain is connected to the public blockchain to build a hierarchical blockchain network to provide privacy protection for the IoT data stored on the blockchain. Finally, we implement an IoT framework based on TBchain and the InterPlanetary File System (IPFS) to realize the decentralized IoT, which guarantees the user’s access control right to personal data. Experimental results show that the IoT framework based on TBchain and IPFS realizes the user’s access control right to personal data by verifying in advance to ensure the confidentiality and security of shared data, and improves the security and privacy of IoT data and transactions. Moreover, we prove that the scalability and storage extensibility of the blockchain is positively correlated with the number of data blocks in TBchain.",
    "cited_by_count": 25,
    "openalex_id": "https://openalex.org/W4294600491",
    "type": "article"
  },
  {
    "title": "Fog Computing Platforms for Smart City Applications: A Survey",
    "doi": "https://doi.org/10.1145/3488585",
    "publication_date": "2022-02-03",
    "publication_year": 2022,
    "authors": "Thiago Pereira da Silva; Thaı́s Batista; Frederico Lopes; Aluizio Rocha Neto; Flávia C. Delicato; Paulo F. Pires; Atslands R. da Rocha",
    "corresponding_authors": "",
    "abstract": "Emerging IoT applications with stringent requirements on latency and data processing have posed many challenges to cloud-centric platforms for Smart Cities. Recently, Fog Computing has been advocated as a promising approach to support such new applications and handle the increasing volume of IoT data and devices. The Fog Computing paradigm is characterized by a horizontal system-level architecture where devices close to end-users and IoT devices are used for processing, storage, and networking functions. Fog Computing platforms aim to facilitate the development of applications and systems for Smart Cities by providing services and abstractions designed to integrate data from IoT devices and various information systems deployed in the city. Despite the potential of the Fog Computing paradigm, the literature still lacks a broad, comprehensive overview of what has been investigated on the use of such paradigm in platforms for Smart Cities and open issues to be addressed in future research and development. In this paper, a systematic mapping study was performed and we present a comprehensive understanding of the use of the Fog Computing paradigm in Smart Cities platforms, providing an overview of the current state of research on this topic, and identifying important gaps in the existing approaches and promising research directions.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W4210397446",
    "type": "article"
  },
  {
    "title": "Negative Information Measurement at AI Edge: A New Perspective for Mental Health Monitoring",
    "doi": "https://doi.org/10.1145/3471902",
    "publication_date": "2022-01-22",
    "publication_year": 2022,
    "authors": "Min Chen; Kefeng Shen; Rui Wang; Yiming Miao; Yingying Jiang; Kai Hwang; Yixue Hao; Guangming Tao; Long Hu; Zhongchun Liu",
    "corresponding_authors": "",
    "abstract": "The outbreak of the corona virus disease 2019 (COVID-19) has caused serious harm to people’s physical and mental health. Due to the serious situation of the epidemic, a lot of negative energy information increases people’s psychological burden. However, effective interventions against mental health problems are not in abundance. To address such challenges, in this article, we propose the concept of negative information to describe information that has a negative impact on people’s mental health. To achieve the measurement of negative information, the level of mental health inversely measures the degree of negative information. Specifically, we design a system to measure the negative information used to monitor the mental health state of the user under the impact of negative information. The cognition of mental health is realized based on the intelligent algorithm deployed on the edge cloud, and the needs of users can be responded to in real time in practical applications. Finally, we use real collected dataset to verify the influence of negative information. The experiments show that the system can achieve negative information measurement and provide an effective countermeasure for solving mental health problems during a pandemic situation.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W4207048847",
    "type": "article"
  },
  {
    "title": "A Novel Cross-Domain Recommendation with Evolution Learning",
    "doi": "https://doi.org/10.1145/3639567",
    "publication_date": "2024-01-05",
    "publication_year": 2024,
    "authors": "Yi-Cheng Chen; Wang-Chien Lee",
    "corresponding_authors": "",
    "abstract": "In this “info-plosion” era, recommendation systems (or recommenders) play a significant role in finding interesting items in the surge of online digital activities and e-commerce. Several techniques have been widely applied for recommendation systems, but the cold-start and sparsity problems remain a major challenge. The cold-start problem occurs when generating recommendations for new users and items without sufficient information. Sparsity refers to the problem of having a large amount of users and items but with few transactions or interactions. In this article, a novel cross-domain recommendation model, Cross-Domain Evolution Learning Recommendation (abbreviated as CD-ELR), is developed to communicate the information from different domains in order to tackle the cold-start and sparsity issues by integrating matrix factorization and recurrent neural network. We introduce an evolutionary concept to describe the preference variation of users over time. Furthermore, several optimization methods are developed for combining the domain features for precision recommendation. Experimental results show that CD-ELR outperforms existing state-of-the-art recommendation baselines. Finally, we conduct experiments on several real-world datasets to demonstrate the practicability of the proposed CD-ELR.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W4390603613",
    "type": "article"
  },
  {
    "title": "Design and development of data-intensive web sites",
    "doi": "https://doi.org/10.1145/643477.643480",
    "publication_date": "2003-02-01",
    "publication_year": 2003,
    "authors": "Paolo Merialdo; Paolo Atzeni; Giansalvatore Mecca",
    "corresponding_authors": "",
    "abstract": "Data-intensive Web sites are large sites based on a back-end database, with a fairly complex hypertext structure. The paper develops two main contributions: (a) a specific design methodology for data-intensive Web sites, composed of a set of steps and design transformations that lead from a conceptual specification of the domain of interest to the actual implementation of the site; (b) a tool called H omer , conceived to support the site design and implementation process, by allowing the designer to move through the various steps of the methodology, and to automate the generation of the code needed to implement the actual site.Our approach to site design is based on a clear separation between several design activities, namely database design, hypertext design, and presentation design. All these activities are carried on by using high-level models, all subsumed by an extension of the nested relational model; the mappings between the models can be nicely expressed using an extended relational algebra for nested structures. Based on the design artifacts produced during the design process, and on their representation in the algebraic framework, H omer is able to generate all the code needed for the actual generation of the site, in a completely automatic way.",
    "cited_by_count": 68,
    "openalex_id": "https://openalex.org/W2072378993",
    "type": "article"
  },
  {
    "title": "Supporting application development in the semantic web",
    "doi": "https://doi.org/10.1145/1064340.1064342",
    "publication_date": "2005-05-01",
    "publication_year": 2005,
    "authors": "Daniel Oberle; Steffen Staab; Rudi Studer; Raphael Volz",
    "corresponding_authors": "",
    "abstract": "The Semantic Web augments the current WWW by giving information a well-defined meaning, better enabling computers and people to work in cooperation. This is done by adding machine understandable content to Web resources. Such added content is called metadata, whose semantics is provided by referring to an ontology---a domain's conceptualization agreed upon by a community. The Semantic Web relies on the complex interaction of several technologies involving ontologies. Therefore, sophisticated Semantic Web applications typically comprise more than one software module. Instead of coming up with proprietary solutions, developers should be able to rely on a generic infrastructure for application development in this context. We call such an infrastructure Application Server for the Semantic Web whose design and development are based on existing Application Servers. However, we apply and augment their underlying concepts for use in the Semantic Web and integrate semantic technology within the server itself. The article discusses requirements and design issues of such a server, presents our implementation KAON SERVER and demonstrates its usefulness by a detailed scenario.",
    "cited_by_count": 66,
    "openalex_id": "https://openalex.org/W2058167777",
    "type": "article"
  },
  {
    "title": "PageRank revisited",
    "doi": "https://doi.org/10.1145/1151087.1151090",
    "publication_date": "2006-08-01",
    "publication_year": 2006,
    "authors": "Michael Brinkmeier",
    "corresponding_authors": "Michael Brinkmeier",
    "abstract": "PageRank, one part of the search engine Google, is one of the most prominent link-based rankings of documents in the World Wide Web. Usually it is described as a Markov chain modeling a specific random surfer. In this article, an alternative representation as a power series is given. Nonetheless, it is possible to interpret the values as probabilities in a random surfer setting, differing from the usual one.Using the new description we restate and extend some results concerning the convergence of the standard iteration used for PageRank. Furthermore we take a closer look at sinks and sources, leading to some suggestions for faster implementations.",
    "cited_by_count": 66,
    "openalex_id": "https://openalex.org/W2294903580",
    "type": "article"
  },
  {
    "title": "XQueC",
    "doi": "https://doi.org/10.1145/1239971.1239974",
    "publication_date": "2007-05-01",
    "publication_year": 2007,
    "authors": "Andrei Arion; Angela Bonifati; Ioana Manolescu; Andrea Pugliese",
    "corresponding_authors": "",
    "abstract": "XML compression has gained prominence recently because it counters the disadvantage of the verbose representation XML gives to data. In many applications, such as data exchange and data archiving, entirely compressing and decompressing a document is acceptable. In other applications, where queries must be run over compressed documents, compression may not be beneficial since the performance penalty in running the query processor over compressed data outweighs the data compression benefits. While balancing the interests of compression and query processing has received significant attention in the domain of relational databases, these results do not immediately translate to XML data. In this article, we address the problem of embedding compression into XML databases without degrading query performance. Since the setting is rather different from relational databases, the choice of compression granularity and compression algorithms must be revisited. Query execution in the compressed domain must also be rethought in the framework of XML query processing due to the richer structure of XML data. Indeed, a proper storage design for the compressed data plays a crucial role here. The XQ ue C system ( XQ uery Processor and C ompressor) covers a wide set of XQuery queries in the compressed domain and relies on a workload-based cost model to perform the choices of the compression granules and of their corresponding compression algorithms. As a consequence, XQueC provides efficient query processing on compressed XML data. An extensive experimental assessment is presented, showing the effectiveness of the cost model, the compression ratios, and the query execution times.",
    "cited_by_count": 60,
    "openalex_id": "https://openalex.org/W2001179357",
    "type": "article"
  },
  {
    "title": "Mining User preference using Spy voting for search engine personalization",
    "doi": "https://doi.org/10.1145/1278366.1278368",
    "publication_date": "2007-10-01",
    "publication_year": 2007,
    "authors": "Wilfred Ng; Lin Deng; Dik Lun Lee",
    "corresponding_authors": "",
    "abstract": "This article addresses search engine personalization. We present a new approach to mining a user's preferences on the search results from clickthrough data and using the discovered preferences to adapt the search engine's ranking function for improving search quality. We develop a new preference mining technique called SpyNB , which is based on the practical assumption that the search results clicked on by the user reflect the user's preferences but does not draw any conclusions about the results that the user did not click on. As such, SpyNB is still valid even if the user does not follow any order in reading the search results or does not click on all relevant results. Our extensive offline experiments demonstrate that SpyNB discovers many more accurate preferences than existing algorithms do. The interactive online experiments further confirm that SpyNB and our personalization approach are effective in practice. We also show that the efficiency of SpyNB is comparable to existing simple preference mining algorithms.",
    "cited_by_count": 56,
    "openalex_id": "https://openalex.org/W2059470448",
    "type": "article"
  },
  {
    "title": "Preserving data privacy in outsourcing data aggregation services",
    "doi": "https://doi.org/10.1145/1275505.1275510",
    "publication_date": "2007-08-01",
    "publication_year": 2007,
    "authors": "Li Xiong; Subramanyam Chitti; Ling Liu",
    "corresponding_authors": "",
    "abstract": "Advances in distributed service-oriented computing and Internet technology have formed a strong technology push for outsourcing and information sharing. There is an increasing need for organizations to share their data across organization boundaries both within the country and with countries that may have lesser privacy and security standards. Ideally, we wish to share certain statistical data and extract the knowledge from the private databases without revealing any additional information of each individual database apart from the aggregate result that is permitted. In this article, we describe two scenarios for outsourcing data aggregation services and present a set of decentralized peer-to-peer protocols for supporting data sharing across multiple private databases while minimizing the data disclosure among individual parties. Our basic protocols include a set of novel probabilistic computation mechanisms for important primitive data aggregation operations across multiple private databases such as max, min, and top k selection. We provide an analytical study of our basic protocols in terms of precision, efficiency, and privacy characteristics. Our advanced protocols implement an efficient algorithm for performing k NN classification across multiple private databases. We provide a set of experiments to evaluate the proposed protocols in terms of their correctness, efficiency, and privacy characteristics.",
    "cited_by_count": 55,
    "openalex_id": "https://openalex.org/W2121539488",
    "type": "article"
  },
  {
    "title": "Privacy-preserving similarity-based text retrieval",
    "doi": "https://doi.org/10.1145/1667067.1667071",
    "publication_date": "2010-02-01",
    "publication_year": 2010,
    "authors": "HweeHwa Pang; Jialie Shen; Ramayya Krishnan",
    "corresponding_authors": "",
    "abstract": "Users of online services are increasingly wary that their activities could disclose confidential information on their business or personal activities. It would be desirable for an online document service to perform text retrieval for users, while protecting the privacy of their activities. In this article, we introduce a privacy-preserving, similarity-based text retrieval scheme that (a) prevents the server from accurately reconstructing the term composition of queries and documents, and (b) anonymizes the search results from unauthorized observers. At the same time, our scheme preserves the relevance-ranking of the search server, and enables accounting of the number of documents that each user opens. The effectiveness of the scheme is verified empirically with two real text corpora.",
    "cited_by_count": 54,
    "openalex_id": "https://openalex.org/W2094877496",
    "type": "article"
  },
  {
    "title": "A semantic approach to approximate service retrieval",
    "doi": "https://doi.org/10.1145/1294148.1294150",
    "publication_date": "2007-11-01",
    "publication_year": 2007,
    "authors": "Eran Toch; Avigdor Gal; Iris Reinhartz-Berger; Dov Dori",
    "corresponding_authors": "",
    "abstract": "Web service discovery is one of the main applications of semantic Web services, which extend standard Web services with semantic annotations. Current discovery solutions were developed in the context of automatic service composition. Thus, the “client” of the discovery procedure is an automated computer program rather than a human, with little, if any, tolerance to inexact results. However, in the real world, services which might be semantically distanced from each other are glued together using manual coding. In this article, we propose a new retrieval model for semantic Web services, with the objective of simplifying service discovery for human users. The model relies on simple and extensible keyword-based query language and enables efficient retrieval of approximate results, including approximate service compositions. Since representing all possible compositions and all approximate concept references can result in an exponentially-sized index, we investigate clustering methods to provide a scalable mechanism for service indexing. Results of experiments, designed to evaluate our indexing and query methods, show that satisfactory approximate search is feasible with efficient processing time.",
    "cited_by_count": 52,
    "openalex_id": "https://openalex.org/W2111685596",
    "type": "article"
  },
  {
    "title": "Analysis of single and networked auctions",
    "doi": "https://doi.org/10.1145/1516539.1516543",
    "publication_date": "2009-05-01",
    "publication_year": 2009,
    "authors": "Erol Gelenbe",
    "corresponding_authors": "Erol Gelenbe",
    "abstract": "Web-based computerized auctions are increasingly present in the Internet. We can imagine that in the future this trend will actually be extended to situations where virtual buyer and seller agents will conduct automated transactions across the network, and that large sectors of the economy may be strucured in this manner. The purpose of this article is to model automated bidders and sellers which interact through a network. We model the bidding process as a random arrival process while the price attained by a good is modeled as a discrete random variable. We obtain analytical solutions allowing us to compute the income from a single auction, or the income per unit time from a repeated sequence of auctions. A variety of single-auction models are studied, including English and Vickrey auctions, and the income per unit time is derived as a function of other parameters, including the rate of arrival of bids, the seller's decision time, the value of the good, and the “rest time” of the seller between successive auctions. We illustrate the results via numerical examples. We also introduce a model for networked auctions where bidders can circulate among a set of interconnected auctions which we call the Mobile Bidder Model (MBM). We obtain an analytical solution for the MBM under the assumption,which we call the “active bidders assumption,” that activities that are internal to an auction (bids and sales) are much more frequent than changes that occur in the number of bidders at each auction.",
    "cited_by_count": 51,
    "openalex_id": "https://openalex.org/W2073227755",
    "type": "article"
  },
  {
    "title": "A peer-to-peer recommender system based on spontaneous affinities",
    "doi": "https://doi.org/10.1145/1462159.1462163",
    "publication_date": "2009-02-01",
    "publication_year": 2009,
    "authors": "Giancarlo Ruffo; Rossano Schifanella",
    "corresponding_authors": "",
    "abstract": "Network analysis has proved to be very useful in many social and natural sciences, and in particular Small World topologies have been exploited in many application fields. In this article, we focus on P2P file sharing applications, where spontaneous communities of users are studied and analyzed. We define a family of structures that we call “Affinity Networks” (or even Graphs) that show self-organized interest-based clusters. Empirical evidence proves that affinity networks are small worlds and shows scale-free features. The relevance of this finding is augmented with the introduction of a proactive recommendation scheme, namely DeHinter , that exploits this natural feature. The intuition behind this scheme is that a user would trust her network of “elective affinities” more than anonymous and generic suggestions made by impersonal entities. The accuracy of the recommendation is evaluated by way of a 10-fold cross validation, and a prototype has been implemented for further feedbacks from the users.",
    "cited_by_count": 49,
    "openalex_id": "https://openalex.org/W2078722472",
    "type": "article"
  },
  {
    "title": "Crowd-Sourced Data Collection for Urban Monitoring via Mobile Sensors",
    "doi": "https://doi.org/10.1145/3093895",
    "publication_date": "2017-10-26",
    "publication_year": 2017,
    "authors": "Antonella Longo; Marco Zappatore; Mario A. Bochicchio; Shamkant B. Navathe",
    "corresponding_authors": "",
    "abstract": "A considerable amount of research has addressed Internet of Things and connected communities. It is possible to exploit the sensing capabilities of connected communities, by leveraging the continuously growing use of cloud computing solutions and mobile devices. The pervasiveness of mobile sensors also enables the Mobile Crowd Sensing (MCS) paradigm, which aims at using mobile-embedded sensors to extend monitoring of multiple (environmental) phenomena in expansive urban areas. In this article, we discuss our approach with a cloud-based platform to pave the way for applying crowd sensing in urban scenarios. We have implemented a complete solution for environmental monitoring of several pollutants, like noise, air, electromagnetic fields, and so on in an urban area based on this paradigm. Through extensive experimentation, specifically on noise pollution, we show how the proposed infrastructure exhibits the ability to collect data from connected communities, and enables a seamless support of services needed for improving citizens’ quality of life and eventually helps city decision makers in urban planning.",
    "cited_by_count": 41,
    "openalex_id": "https://openalex.org/W2766747128",
    "type": "article"
  },
  {
    "title": "Quantify Resilience Enhancement of UTS through Exploiting Connected Community and Internet of Everything Emerging Technologies",
    "doi": "https://doi.org/10.1145/3137572",
    "publication_date": "2017-10-26",
    "publication_year": 2017,
    "authors": "Emanuele Bellini; Paolo Ceravolo; Paolo Nesi",
    "corresponding_authors": "",
    "abstract": "This work aims at investigating and quantifying the Urban Transport System (UTS) resilience enhancement enabled by the adoption of emerging technology such as Internet of Everything (IoE) and the new trend of the Connected Community (CC). A conceptual extension of Functional Resonance Analysis Method (FRAM) and its formalization have been proposed and used to model UTS complexity. The scope is to identify the system functions and their interdependencies with a particular focus on those that have a relation and impact on people and communities. Network analysis techniques have been applied to the FRAM model to identify and estimate the most critical community-related functions. The notion of Variability Rate (VR) has been defined as the amount of output variability generated by an upstream function that can be tolerated/absorbed by a downstream function, without significantly increasing of its subsequent output variability. A fuzzy-based quantification of the VR based on expert judgment has been developed when quantitative data are not available. Our approach has been applied to a critical scenario as flash flooding considering two cases: when UTS has CC and IoE implemented or not. However, the method can be applied in different scenarios and critical infrastructures. The results show a remarkable VR enhancement if CC and IoE are deployed.",
    "cited_by_count": 40,
    "openalex_id": "https://openalex.org/W2750490489",
    "type": "article"
  },
  {
    "title": "MARSA",
    "doi": "https://doi.org/10.1145/2883611",
    "publication_date": "2016-05-20",
    "publication_year": 2016,
    "authors": "Tien-Dung Cao; Tran-Vu Pham; Quang-Hieu Vu; Hong‐Linh Truong; Duc-Hung Le; Schahram Dustdar",
    "corresponding_authors": "",
    "abstract": "This article introduces a dynamic cloud-based marketplace of near-realtime human sensing data (MARSA) for different stakeholders to sell and buy near-realtime data. MARSA is designed for environments where information technology (IT) infrastructures are not well developed but the need to gather and sell near-realtime data is great. To this end, we present techniques for selecting data types and managing data contracts based on different cost models, quality of data, and data rights. We design our MARSA platform by leveraging different data transferring solutions to enable an open and scalable communication mechanism between sellers (data providers) and buyers (data consumers). To evaluate MARSA, we carry out several experiments with the near-realtime transportation data provided by people in Ho Chi Minh City, Vietnam, and simulated scenarios in multicloud environments.",
    "cited_by_count": 39,
    "openalex_id": "https://openalex.org/W2405895814",
    "type": "article"
  },
  {
    "title": "Preserving Privacy as Social Responsibility in Online Social Networks",
    "doi": "https://doi.org/10.1145/3158373",
    "publication_date": "2018-04-24",
    "publication_year": 2018,
    "authors": "Dilara Keküllüoğlu; Nadin Kökciyan; Pınar Yolum",
    "corresponding_authors": "",
    "abstract": "Online social networks provide an environment for their users to share content with others, where the user who shares a content item is put in charge, generally ignoring others that might be affected by it. However, a content that is shared by one user can very well violate the privacy of other users. To remedy this, ideally, all users who are related to a content should get a say in how the content should be shared. Recent approaches advocate the use of agreement technologies to enable stakeholders of a post to discuss the privacy configurations of a post. This allows related individuals to express concerns so that various privacy violations are avoided up front. Existing techniques try to establish an agreement on a single post. However, most of the time, agreement should be established over multiple posts such that the user can tolerate slight breaches of privacy in return of a right to share posts themselves in future interactions. As a result, users can help each other preserve their privacy, viewing this as their social responsibility. This article develops a reciprocity-based negotiation for reaching privacy agreements among users and introduces a negotiation architecture that combines semantic privacy rules with utility functions. We evaluate our approach over multiagent simulations with software agents that mimic users based on a user study.",
    "cited_by_count": 39,
    "openalex_id": "https://openalex.org/W2802698622",
    "type": "article"
  },
  {
    "title": "Modelling the Role of Trust in Social Relationships",
    "doi": "https://doi.org/10.1145/2815620",
    "publication_date": "2015-11-26",
    "publication_year": 2015,
    "authors": "Alistair﻿ Sutcliffe﻿; Di Wang; Robin Dunbar",
    "corresponding_authors": "",
    "abstract": "A social trust model is presented for investigating social relationships and social networks in the real world and in social media. The results demonstrate that multilevel social structures, with a few strong relationships, more medium ties, and large numbers of weak ties, emerge in an evolutionary simulation when well-being and alliances are rewarded with high levels of social interaction. ‘Favour-the-few’ trust strategies were more competitive than others under a wide range of fitness conditions, suggesting that the development of complex, multilevel social structures depends on capacity for high investment in social time and preferential social interaction strategies.",
    "cited_by_count": 35,
    "openalex_id": "https://openalex.org/W2196828480",
    "type": "article"
  },
  {
    "title": "Mitigating Data Sparsity Using Similarity Reinforcement-Enhanced Collaborative Filtering",
    "doi": "https://doi.org/10.1145/3062179",
    "publication_date": "2017-06-27",
    "publication_year": 2017,
    "authors": "Yan Hu; Weisong Shi; Hong Li; Xiaohui Hu",
    "corresponding_authors": "",
    "abstract": "The data sparsity problem has attracted significant attention in collaborative filtering-based recommender systems. To alleviate data sparsity, several previous efforts employed hybrid approaches that incorporate auxiliary data sources into recommendation techniques, like content, context, or social relationships. However, due to privacy and security concerns, it is generally difficult to collect such auxiliary information. In this article, we focus on the pure collaborative filtering methods without relying on any auxiliary data source. We propose an improved memory-based collaborative filtering approach enhanced by a novel similarity reinforcement mechanism. It can discover potential similarity relationships between users or items by making better use of known but limited user-item interactions, thus to extract plentiful historical rating information from similar neighbors to make more reliable and accurate rating predictions. This approach integrates user similarity reinforcement and item similarity reinforcement into a comprehensive framework and lets them enhance each other. Comprehensive experiments conducted on several public datasets demonstrate that, in the face of data sparsity, our approach achieves a significant improvement in prediction accuracy when compared with the state-of-the-art memory-based and model-based collaborative filtering algorithms.",
    "cited_by_count": 35,
    "openalex_id": "https://openalex.org/W2725103782",
    "type": "article"
  },
  {
    "title": "Fog-based Secure Communications for Low-power IoT Devices",
    "doi": "https://doi.org/10.1145/3284554",
    "publication_date": "2019-03-28",
    "publication_year": 2019,
    "authors": "Luca Ferretti; Mirco Marchetti; Michele Colajanni",
    "corresponding_authors": "",
    "abstract": "Designing secure, scalable, and resilient IoT networks is a challenging task because of resource-constrained devices and no guarantees of reliable network connectivity. Fog computing improves the resiliency of IoT, but its security model assumes that fog nodes are fully trusted. We relax this latter constraint by proposing a solution that guarantees confidentiality of messages exchanged through semi-honest fog nodes thanks to a lightweight proxy re-encryption scheme. We demonstrate the feasibility of the solution by applying it to IoT networks of low-power devices through experiments on microcontrollers and ARM-based architectures.",
    "cited_by_count": 34,
    "openalex_id": "https://openalex.org/W2935047029",
    "type": "article"
  },
  {
    "title": "A Hybrid Feature Selection Algorithm Based on a Discrete Artificial Bee Colony for Parkinson's Diagnosis",
    "doi": "https://doi.org/10.1145/3397161",
    "publication_date": "2020-07-07",
    "publication_year": 2020,
    "authors": "Haolun Li; Chi‐Man Pun; Feng Xu; Longsheng Pan; Rui Zong; Hao Gao; Huimin Lu",
    "corresponding_authors": "",
    "abstract": "Parkinson's disease is a neurodegenerative disease that affects millions of people around the world and cannot be cured fundamentally. Automatic identification of early Parkinson's disease on feature data sets is one of the most challenging medical tasks today. Many features in these datasets are useless or suffering from problems like noise, which affect the learning process and increase the computational burden. To ensure the optimal classification performance, this article proposes a hybrid feature selection algorithm based on an improved discrete artificial bee colony algorithm to improve the efficiency of feature selection. The algorithm combines the advantages of filters and wrappers to eliminate most of the uncorrelated or noisy features and determine the optimal subset of features. In the filter, three different variable ranking methods are employed to pre-rank the candidate features, then the population of artificial bee colony is initialized based on the significance degree of the re-rank features. In the wrapper part, the artificial bee colony algorithm evaluates individuals (feature subsets) based on the classification accuracy of the classifier to achieve the optimal feature subset. In addition, for the first time, we introduce a strategy that can automatically select the best classifier in the search framework more quickly. By comparing with several publicly available datasets, the proposed method achieves better performance than other state-of-the-art algorithms and can extract fewer effective features.",
    "cited_by_count": 34,
    "openalex_id": "https://openalex.org/W3041618506",
    "type": "article"
  },
  {
    "title": "Design and Implementation of BCI-based Intelligent Upper Limb Rehabilitation Robot System",
    "doi": "https://doi.org/10.1145/3392115",
    "publication_date": "2020-07-07",
    "publication_year": 2020,
    "authors": "Tae-Yeun Kim; Sung-Hwan Kim; Hoon Ko",
    "corresponding_authors": "",
    "abstract": "The present study aimed to use the proposed system to measure and analyze brain waves of users to allow intelligent upper limb rehabilitation and to optimize the system using a genetic algorithm. The study used EPOC Neuroheadset for Emotiv with EEG electrodes attached as a non-invasive method for measuring brain waves. The brain waves were measured according to the EEG 10-20 standard electrode layout, which allows measurement of signals from each spot where electrodes are attached based on EEG characteristics. The measured data were added in a database. In the intelligent neuro-fuzzy model, wave transform was used for extracting brain wave characteristics according to user intentions and to eliminate noise from the signals in an effort to increase reliability. Moreover, to construct the option rules of the neuro-fuzzy system, FCM technique and optimal cluster evaluation method were used. Furthermore, the asymmetric Gaussian membership function was used to improve performance, whereas SD and WF divided into left and right sides were used to express the chromosomes. Optimal EEG electrode locations were found, and comparative analysis was performed on the differences based on membership function, number of clusters, and number of learning generations, learning algorithm, and wavelet settings. The performance evaluation results showed that the optimal EEG electrode locations were F7, F8, FC5, and FC6, whereas the accuracy of learning and test data of user-intention recognition was found to be 94.2% and 92.3%, respectively, which suggests that the proposed system can be used to recognize user intention for specific behavior. The system proposed in the present study can allow continued rehabilitation exercise in everyday living according to user intentions, which is expected to help improve the user's willingness to participate in rehabilitation and his or her quality of life.",
    "cited_by_count": 34,
    "openalex_id": "https://openalex.org/W3083581995",
    "type": "article"
  },
  {
    "title": "DM2-ECOP",
    "doi": "https://doi.org/10.1145/3241666",
    "publication_date": "2019-04-03",
    "publication_year": 2019,
    "authors": "Houssemeddine Mazouzi; Nadjib Achir; Khaled Boussetta",
    "corresponding_authors": "",
    "abstract": "Mobile Edge Computing is a promising paradigm that can provide cloud computing capabilities at the edge of the network to support low latency mobile services. The fundamental concept relies on bringing cloud computation closer to users by deploying cloudlets or edge servers, which are small clusters of servers that are mainly located on existing wireless Access Points (APs), set-top boxes, or Base Stations (BSs). In this article, we focus on computation offloading over a heterogeneous cloudlet environment. We consider several users with different energy—and latency-constrained tasks that can be offloaded over cloudlets with differentiated system and network resources capacities. We investigate offloading policies that decide which tasks should be offloaded and select the assigned cloudlet, accordingly with network and system resources. The objective is to minimize an offloading cost function, which we defined as a combination of tasks’ execution time and mobiles’ energy consumption. We formulate this problem as a Mixed-Binary Programming. Since the centralized optimal solution is NP-hard, we propose a distributed linear relaxation-based heuristic approach that relies on the Lagrangian decomposition method. To solve the subproblems, we also propose a greedy heuristic algorithm that computes the best cloudlet selection and bandwidth allocation following tasks’ offloading costs. Numerical results show that our offloading policy achieves a good solution quickly. We also discuss the performances of our approach for large-scale scenarios and compare it to state-of-the-art approaches from the literature.",
    "cited_by_count": 32,
    "openalex_id": "https://openalex.org/W2934940064",
    "type": "article"
  },
  {
    "title": "Cognitive Wearable Robotics for Autism Perception Enhancement",
    "doi": "https://doi.org/10.1145/3450630",
    "publication_date": "2021-07-22",
    "publication_year": 2021,
    "authors": "Min Chen; Wenjing Xiao; Long Hu; Yujun Ma; Yin Zhang⋆; Guangming Tao",
    "corresponding_authors": "",
    "abstract": "Autism spectrum disorder (ASD) is a serious hazard to the physical and mental health of children, which limits the social activities of patients throughout their lives and places a heavy burden on families and society. The developments of communication techniques and artificial intelligence (AI) have provided new potential methods for the treatment of autism. The existing treatment systems based on AI for children with ASD focus on detecting health status and developing social skills. However, the contradiction between the terminal interaction capability and availability cannot meet the needs for real application scenarios. At the same time, the lack of diverse data cannot provide individualized care for autistic children. To explore this robot-based approach, a novel AI-based first-view-robot architecture is proposed in this article. By providing care from the first-person perspective, the proposed wearable robot overcomes the difficulty of the absence of cognitive ability in the third-view of traditional robotics and improves the social interaction ability of children with ASD. The first-view-robot architecture meets the requirements of dynamic, individualized, and highly immersed interaction services for autistic children. First, the multi-modal and multi-scene data collection processes of standard, static, and dynamic datasets are introduced in detail. Then, to comprehensively evaluate the learning ability of children with ASD through mental states and external performances, a learning assessment model with emotion correction is proposed. Besides, a wearable robot-assisted environment perception and expression enhancement mechanism for children with ASD is realized by reinforcement learning, which can be adapted to interactive environments with optimal action policies. An interactive testbed for children with ASD treatments is demonstrated and experimental cases for test subjects are presented. Last, three open issues are discussed from data processing, robot designing, and service responding perspectives.",
    "cited_by_count": 27,
    "openalex_id": "https://openalex.org/W3184123949",
    "type": "article"
  },
  {
    "title": "Malware Classification Based on Multilayer Perception and Word2Vec for IoT Security",
    "doi": "https://doi.org/10.1145/3436751",
    "publication_date": "2021-09-14",
    "publication_year": 2021,
    "authors": "Yanchen Qiao; Weizhe Zhang; Xiaojiang Du; Mohsen Guizani",
    "corresponding_authors": "",
    "abstract": "With the construction of smart cities, the number of Internet of Things (IoT) devices is growing rapidly, leading to an explosive growth of malware designed for IoT devices. These malware pose a serious threat to the security of IoT devices. The traditional malware classification methods mainly rely on feature engineering. To improve accuracy, a large number of different types of features will be extracted from malware files in these methods. That brings a high complexity to the classification. To solve these issues, a malware classification method based on Word2Vec and Multilayer Perception (MLP) is proposed in this article. First, for one malware sample, Word2Vec is used to calculate a word vector for all bytes of the binary file and all instructions in the assembly file. Second, we combine these vectors into a 256x256x2-dimensional matrix. Finally, we designed a deep learning network structure based on MLP to train the model. Then the model is used to classify the testing samples. The experimental results prove that the method has a high accuracy of 99.54%.",
    "cited_by_count": 27,
    "openalex_id": "https://openalex.org/W3200046392",
    "type": "article"
  },
  {
    "title": "Short-term Load Forecasting by Using Improved GEP and Abnormal Load Recognition",
    "doi": "https://doi.org/10.1145/3447513",
    "publication_date": "2021-07-16",
    "publication_year": 2021,
    "authors": "Song Deng; Fulin Chen; Xia Dong; Guangwei Gao; Xindong Wu",
    "corresponding_authors": "",
    "abstract": "Load forecasting in short term is very important to economic dispatch and safety assessment of power system. Although existing load forecasting in short-term algorithms have reached required forecast accuracy, most of the forecasting models are black boxes and cannot be constructed to display mathematical models. At the same time, because of the abnormal load caused by the failure of the load data collection device, time synchronization, and malicious tampering, the accuracy of the existing load forecasting models is greatly reduced. To address these problems, this article proposes a Short-Term Load Forecasting algorithm by using Improved Gene Expression Programming and Abnormal Load Recognition (STLF-IGEP_ALR). First, the Recognition algorithm of Abnormal Load based on Probability Distribution and Cross Validation is proposed. By analyzing the probability distribution of rows and columns in load data, and using the probability distribution of rows and columns for cross-validation, misjudgment of normal load in abnormal load data can be better solved. Second, by designing strategies for adaptive generation of population parameters, individual evolution of populations and dynamic adjustment of genetic operation probability, an Improved Gene Expression Programming based on Evolutionary Parameter Optimization is proposed. Finally, the experimental results on two real load datasets and one open load dataset show that compared with the existing abnormal data detection algorithms, the algorithm proposed in this article have higher advantages in missing detection rate, false detection rate and precision rate, and STLF-IGEP_ALR is superior to other short-term load forecasting algorithms in terms of the convergence speed, MAE, MAPE, RSME, and R 2 .",
    "cited_by_count": 26,
    "openalex_id": "https://openalex.org/W3186723494",
    "type": "article"
  },
  {
    "title": "ISDNet: AI-enabled Instance Segmentation of Aerial Scenes for Smart Cities",
    "doi": "https://doi.org/10.1145/3418205",
    "publication_date": "2021-08-10",
    "publication_year": 2021,
    "authors": "Prateek Garg; Anirudh Chakravarthy; Murari Mandal; Pratik Narang; Vinay Chamola; Mohsen Guizani",
    "corresponding_authors": "",
    "abstract": "Aerial scenes captured by UAVs have immense potential in IoT applications related to urban surveillance, road and building segmentation, land cover classification, and so on, which are necessary for the evolution of smart cities. The advancements in deep learning have greatly enhanced visual understanding, but the domain of aerial vision remains largely unexplored. Aerial images pose many unique challenges for performing proper scene parsing such as high-resolution data, small-scaled objects, a large number of objects in the camera view, dense clustering of objects, background clutter, and so on, which greatly hinder the performance of the existing deep learning methods. In this work, we propose ISDNet (Instance Segmentation and Detection Network), a novel network to perform instance segmentation and object detection on visual data captured by UAVs. This work enables aerial image analytics for various needs in a smart city. In particular, we use dilated convolutions to generate improved spatial context, leading to better discrimination between foreground and background features. The proposed network efficiently reuses the segment-mask features by propagating them from early stages using residual connections. Furthermore, ISDNet makes use of effective anchors to accommodate varying object scales and sizes. The proposed method obtains state-of-the-art results in the aerial context.",
    "cited_by_count": 26,
    "openalex_id": "https://openalex.org/W3193164413",
    "type": "article"
  },
  {
    "title": "SkillBot: Identifying Risky Content for Children in Alexa Skills",
    "doi": "https://doi.org/10.1145/3539609",
    "publication_date": "2022-05-30",
    "publication_year": 2022,
    "authors": "Tu Le; Danny Yuxing Huang; Noah Apthorpe; Yuan Tian",
    "corresponding_authors": "",
    "abstract": "Many households include children who use voice personal assistants (VPA) such as Amazon Alexa. Children benefit from the rich functionalities of VPAs and third-party apps but are also exposed to new risks in the VPA ecosystem. In this paper, we first investigate \"risky\" child-directed voice apps that contain inappropriate content or ask for personal information through voice interactions. We build SkillBot - a natural language processing (NLP)-based system to automatically interact with VPA apps and analyze the resulting conversations. We find 28 risky child-directed apps and maintain a growing dataset of 31,966 non-overlapping app behaviors collected from 3,434 Alexa apps. Our findings suggest that although child-directed VPA apps are subject to stricter policy requirements and more intensive vetting, children remain vulnerable to inappropriate content and privacy violations. We then conduct a user study showing that parents are concerned about the identified risky apps. Many parents do not believe that these apps are available and designed for families/kids, although these apps are actually published in Amazon's \"Kids\" product category. We also find that parents often neglect basic precautions such as enabling parental controls on Alexa devices. Finally, we identify a novel risk in the VPA ecosystem: confounding utterances, or voice commands shared by multiple apps that may cause a user to interact with a different app than intended. We identify 4,487 confounding utterances, including 581 shared by child-directed and non-child-directed apps. We find that 27% of these confounding utterances prioritize invoking a non-child-directed app over a child-directed app. This indicates that children are at real risk of accidentally invoking non-child-directed apps due to confounding utterances.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W3128281363",
    "type": "article"
  },
  {
    "title": "Emerging Trends of ICT in Airborne Disease Prevention",
    "doi": "https://doi.org/10.1145/3564783",
    "publication_date": "2022-09-29",
    "publication_year": 2022,
    "authors": "Sandeep K. Sood; Keshav Singh Rawat; Dheeraj Kumar",
    "corresponding_authors": "",
    "abstract": "Information and Communication Technologies (ICT) are becoming indispensable nowadays for the healthcare industry. The utilization of ICT in healthcare services has accelerated even faster after the commencement of the COVID-19 outbreak. This study aims to perform a scientometric analysis of scholarly literature on airborne diseases in the discipline of science and technology. It explores the recent advancement of internet technologies in healthcare to control the prevalence of deadly airborne illnesses by applying analytical approaches. It presents publication trends, citation structure, influential sources, co-citation, and co-occurrence network analysis using the CiteSpace tool. It identifies the important research topics, current research hotspots, most active research areas, and leading technologies in this scientific knowledge domain. It inferred significant results from analyses that will benefit researchers and the academic fraternity across the globe to understand the evolving paths and recent scientific progress of ICT in airborne disease management.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W4297999761",
    "type": "article"
  },
  {
    "title": "Distributed Computation Offloading and Power Control for UAV-Enabled Internet of Medical Things",
    "doi": "https://doi.org/10.1145/3652513",
    "publication_date": "2024-03-16",
    "publication_year": 2024,
    "authors": "Jiakun Gao; Xiaolong Xu; Lianyong Qi; Wanchun Dou; Xiaoyu Xia; Xiaokang Zhou",
    "corresponding_authors": "",
    "abstract": "The advancement of the Internet of Medical Things (IoMT) has led to the emergence of various health and emotion care services, e.g., health monitoring. To cater to increasing computational requirements of IoMT services, Mobile Edge Computing (MEC) has emerged as an indispensable technology in smart health. Benefiting from the cost-effectiveness of deployment, unmanned aerial vehicles (UAVs) equipped with MEC servers in Non-Orthogonal Multiple Access (NOMA) have emerged as a promising solution for providing smart health services in proximity to medical devices (MDs). However, the escalating number of MDs and the limited availability of communication resources of UAVs give rise to a significant increase in transmission latency. Moreover, due to the limited communication range of UAVs, the geographically-distributed MDs lead to workload imbalance of UAVs, which deteriorates the service response delay. To this end, this paper proposes a UAV-enabled Distributed computation Offloading and Power control method with Multi-Agent, named DOPMA, for NOMA-based IoMT environment. Specifically, this paper introduces computation and transmission queue models to analyze the dynamic characteristics of task execution latency and energy consumption. Moreover, a credit assignment scheme-based reward function is designed considering both system-level rewards and rewards tailored to each MD, and an improved multi-agent deep deterministic policy gradient algorithm is developed to derive offloading and power control decisions independently. Extensive simulations demonstrate that the proposed method outperforms existing schemes, achieving \\(7.1\\% \\) reduction in energy consumption and \\(16\\% \\) decrease in average delay.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4392885572",
    "type": "article"
  },
  {
    "title": "Navigating the Metaverse: A Comprehensive Analysis of Consumer Electronics Prospects and Challenges",
    "doi": "https://doi.org/10.1145/3680545",
    "publication_date": "2024-07-24",
    "publication_year": 2024,
    "authors": "Siva Sai; Akshat Garg; Vinay Chamola",
    "corresponding_authors": "",
    "abstract": "Rapid innovation in consumer electronics has made our lives more comfortable. Consumer electronics serve as the primary platform for the Metaverse (MV), offering users an immersive and interactive medium that connects the digital and real worlds. Consumer electronics play a crucial role in ensuring the accessibility and the user experience within the Metaverse. Despite the vital role of consumer electronics in enabling an immersive metaverse experience, a detailed survey has yet to cover different facets. Addressing this research gap, we present a comprehensive review covering several applications, case studies, and challenges of consumer electronics in Metaverse. We present the role and scope of different consumer electronics devices like VR(Virtual Reality) headsets, AR(Augmented Reality) headsets, haptic feedback devices, and smartphones in Metaverse applications. We present an illustrative case study on how consumer electronics assist education in the Metaverse. Several device-specific challenges include restricted field of view, latency issues, synchronization issues, and non-device-specific challenges like interoperability, scalability, and data privacy. Our survey shall help researchers explore more prospects for making this integration stronger.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4400955716",
    "type": "article"
  },
  {
    "title": "Communication-Efficient Federated Learning for Heterogeneous Clients",
    "doi": "https://doi.org/10.1145/3716870",
    "publication_date": "2025-02-11",
    "publication_year": 2025,
    "authors": "Ying Li; Xingwei Wang; Haodong Li; Praveen Kumar Donta; Min Huang; Schahram Dustdar",
    "corresponding_authors": "",
    "abstract": "Federated learning stands out as a promising approach within the domain of edge computing, providing a framework for collaborative training on distributed datasets without necessitating data sharing. However, federated learning involves the frequent transmission of machine learning model updates between the server and clients, resulting in high communication costs. Additionally, heterogeneous clients can further complicate the Federated Learning process and deteriorate performance. To address these challenges, we propose adaptive self-knowledge distillation-based quality- and reputation-aware cross-device federated learning (ASDQR) - an efficient communication and inference framework designed for heterogeneous clients. ASDQR initiates the process by selecting high-reputation and high-quality clients to be involved in federated learning, significantly impacting communication efficiency and inference effectiveness. ASDQR also introduces a model of adaptive local self-knowledge distillation that incorporates multiple local personalized historical knowledge for more accurate inference, allowing the historical level to be dynamically adjusted across time. Finally, we present an inference-effective aggregation scheme that assigns higher weights to important and reliable local model updates based on clients’ contribution degrees when performing global model aggregation. ASDQR consistently outperforms baseline methods across all datasets and communication rounds, achieving 9.0% higher accuracy than FedAvg, 6.59% higher than MOON, 0.29% higher than FedProx, 0.2% higher than PFedSD, and 0.08% higher than FedMD on the MNIST dataset at 100 communication rounds. Similar improvements are observed on CIFAR, HAR, and WISDM datasets, demonstrating the robustness and efficiency of ASDQR in federated learning with non-IID data.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4407373857",
    "type": "article"
  },
  {
    "title": "Predicting Diabetes with Federated Learning: A Digital Twin and Medical Fog-based IoT Framework",
    "doi": "https://doi.org/10.1145/3711859",
    "publication_date": "2025-02-17",
    "publication_year": 2025,
    "authors": "Kaushik Mishra; Umashankar Ghugar; Goluguri N. V. Rajareddy; Kshira Sagar Sahoo; Sourav Kumar Bhoi; Monowar Bhuyan; Amir H. Gandomi",
    "corresponding_authors": "",
    "abstract": "In today's world, maintaining good health has become increasingly paramount. The global prevalence of diabetes has surged due to the stress of modern life and unhealthy dietary habits. Detecting diabetes at an early stage has become imperative. Leveraging advancements in Cloud and Fog computing, we can create an Internet-enabled Medical Fog framework that incorporates Machine Learning (ML) techniques to predict and diagnose diabetes at its inception. This early prediction and diagnosis would enable remote medical assistance for individuals living far from immediate medical facilities. The Internet of Medical Things allows patient data to be gathered via sensors, analyzed using ML techniques, and stored in the Cloud, providing direct access for healthcare professionals. Therefore, the current study introduces a Digital Twin (DT)-enabled Internet of Medical Fog framework, supported by Federated Learning (FL) and the SaJAYA-ANFIS ML approach for diabetes prediction. FL ensures patient data privacy is upheld while fostering a seamless, intelligent healthcare ecosystem that bridges the gap between patients and doctors through DT. Data collection begins at the Internet of Things (IoT) layer through sensors, followed by processing at the Fog layer, comprising diverse computing nodes with specific pre-processing tools and the SaJAYA-ANFIS model for diabetes prediction. Predicted outcomes are then stored in the Cloud for analysis by medical professionals. The proposed framework addresses privacy concerns through Federated Learning (FL). The proposed method has been validated with a UCI diabetes dataset and compared with state-of-the-art FL-supported ML and DT-supported ML techniques for various performance metrics (Accuracy, Precision, Specificity, Recall and Fβ-measure). The results demonstrate that our method outperforms other baselines, achieving 93.5% accuracy and 92% Fβ-measure, respectively. Fog computing, Cloud computing, Healthcare",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4407654617",
    "type": "article"
  },
  {
    "title": "Accurate Bandwidth and Delay Prediction for 5G Cellular Networks",
    "doi": "https://doi.org/10.1145/3703629",
    "publication_date": "2025-02-18",
    "publication_year": 2025,
    "authors": "Jiamei Lv; Yuxiang Lin; Minghui Hou; Yeming Li; Yi Gao; Wei Dong",
    "corresponding_authors": "",
    "abstract": "The fifth-generation (5G) has empowerd various applications. Effective bandwidth and delay prediction in 5G cellular networks are essential for many applications, such as virtual reality and holographic video streaming. However, accurate bandwidth and delay prediction in 5G networks remains a challenging task due to the short-distance coverage and frequent handover properties of 5G base stations. In this paper, we propose HYPER, a hybrid bandwidth and delay prediction approach that uses an Auto Regressive Moving Average (ARMA) time series predictive model for intra-cell prediction and a Random Forest (RF) regression model for cross-cell prediction. Our ARMA model takes prior information as its input, while the RF model further uses related network and physical features to predict future performance. We conduct a measurement study in commercial 5G networks to analyze the relationship between these features and bandwidth/delay. Moreover, we also propose a handover window adaptation algorithm to automatically adjust the handover window size and determine which model to use during handover for accurate bandwidth and delay prediction. We use commercial 5G smartphones for data collection and conducted extensive experiments in diverse urban environments. Experimental results show that HYPER can reduce the prediction error by more than 13% compared to state-of-the-art prediction approaches.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4407675067",
    "type": "article"
  },
  {
    "title": "The Blockchain Warfare: Investigating the Ecosystem of Sniper Bots on Ethereum and BNB Smart Chain",
    "doi": "https://doi.org/10.1145/3736763",
    "publication_date": "2025-06-07",
    "publication_year": 2025,
    "authors": "Federico Cernera; Massimo La Morgia; Alessandro Mei; Alberto Maria Mongardini; Francesco Sassi",
    "corresponding_authors": "",
    "abstract": "In the world of cryptocurrencies, the public listing of a new token often generates significant hype. In many cases, the price of the token skyrockets in a few seconds, and timing is crucial to determine the success or failure of an investment opportunity. In this work, we present an in-depth analysis of sniper bots, automated tools designed to buy tokens as soon as they are listed on the market. We leverage GitHub open-source repositories of sniper bots to analyze their features and how they are implemented. Then, we build a dataset of Ethereum and BNB Smart Chain (BSC) liquidity pools to identify operations performed using sniper bots. Our findings reveal 352,413 sniping operations on Ethereum and 1,716,917 on BSC for a total turnaround of $155,630,184 and $137,548,859, respectively. We find that Ethereum operations have a higher success rate but require a larger investment. Finally, we analyze possible countermeasures and mechanisms used in token smart contracts that can reduce the negative impact of sniper bots.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4411121396",
    "type": "article"
  },
  {
    "title": "Optimizing Communication Efficiency through Training Potential in Multi-Modal Federated Learning",
    "doi": "https://doi.org/10.1145/3747590",
    "publication_date": "2025-07-05",
    "publication_year": 2025,
    "authors": "Yinghao Zhang; Jianxiong Guo; Xingjian Ding; Zhiqing Tang; Tian Wang; Weili Wu; Weijia Jia",
    "corresponding_authors": "",
    "abstract": "Multi-modal Federated Learning (FL) is a type of FL that considers utilizing multiple modalities of data to improve overall performance. While multi-modal data brings richer information, it also introduces more significant communication overhead. Reducing this overhead hinges on two key strategies: increasing the convergence speed of the training or reducing the communication overhead in each communication round. However, few studies have considered these two strategies simultaneously and formed a unified optimization framework. Thus, we propose a joint client and modality selection framework to reduce communication overhead. Modality selection executed on each client assigns weights to modalities based on their contribution to training potential, aiming to accelerate the convergence. Client selection executed on the server assigns weights to clients by considering different metrics, especially total training potential after the modality selection. We validate our proposed method on the five widely used open-source datasets, achieving satisfactory accuracy while reducing the total communication overhead to 2.43%-14.24% compared to without selection on different datasets, significantly outperforming existing state-of-the-art (SOTA) methods. Code is available at https://github.com/1643204431/OCETPMMFL.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4412046526",
    "type": "article"
  },
  {
    "title": "Lightweight Two-level Collaborative Network Traffic Measurement for Data Center Networks",
    "doi": "https://doi.org/10.1145/3757320",
    "publication_date": "2025-07-30",
    "publication_year": 2025,
    "authors": "Zhiquan Qiu; Yang Du; He Huang; Yu-E Sun; Guoju Gao",
    "corresponding_authors": "",
    "abstract": "Network traffic measurement is crucial for the effective management of data center networks. Collaborative measurement solutions distribute measurement tasks to switches based on flow-level or packet-level granularity to alleviate the measurement load on each switch. However, flow-level solutions often experience severe imbalances in measurement overhead between switches measuring large or small flows, and face scalability challenges due to the costly optimization of collaborative plans. Additionally, packet-level solutions do not adequately reduce hash collisions in sketches and fail to significantly enhance measurement accuracy. In this paper, we present the Lightweight Two-level Collaborative Measurement (LTCM) that synergies flow-level and packet-level strategy to optimize measurement load balancing, reduce overall measurement overhead, and enhance measurement accuracy. We first design a Lightweight Flow-level Measurement (FCM) framework that balances the number of flows measured by each switch, incorporating a novel interval-matching technique that significantly lowers the computational costs of collaborative strategies. Based on FCM, LTCM implements our measurement load balancing strategy selector at ingress switches to detect flows whose number of packets entering the network exceeds a given threshold and evenly distribute their subsequent packets across all switches for measurement. To further improve measurement accuracy and speed, we design a two-layer collaborative sketch that reduces hash collisions between large and small flows. We implement LTCM on a Tofino-based programmable switch. Experimental results based on real Internet traces show that LTCM achieves highly efficient flow-level and packet-level measurement load balancing, improving accuracy by up to 96.6% and throughput by up to 112.79%. All related implementations are open-sourced.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4412777077",
    "type": "article"
  },
  {
    "title": "Literature-based discovery on the World Wide Web",
    "doi": "https://doi.org/10.1145/604596.604597",
    "publication_date": "2002-11-01",
    "publication_year": 2002,
    "authors": "Michael Gordon; Robert Lindsay; Weiguo Fan",
    "corresponding_authors": "",
    "abstract": "Previous research has shown that researchers can generate medical hypotheses by using computers to analyze several, seemingly unrelated, medical literatures. In this work we suggest broader application for the ideas of literature-based discovery. Specifically, we suggest that literature-based discovery can be fruitful in areas other than medicine; that in addition to finding \"cures\" for \"problems,\" literature-based discovery offers the possibility of finding new problems for existing technologies; that the analysis of a single literature may be sufficient for literature-based discovery; and that literature-based discovery can support individuals seeking to draw together ideas from various areas of inquiry, even if such connections have been previously made by others.We describe literature-based discovery experiments conducted on the World Wide Web that support these ideas.",
    "cited_by_count": 60,
    "openalex_id": "https://openalex.org/W2069366497",
    "type": "article"
  },
  {
    "title": "A multi-agent infrastructure for developing personalized web-based systems",
    "doi": "https://doi.org/10.1145/1052934.1052936",
    "publication_date": "2005-02-01",
    "publication_year": 2005,
    "authors": "Liliana Ardissono; Anna Goy; Giovanna Petrone; Marino Segnan",
    "corresponding_authors": "",
    "abstract": "Although personalization and ubiquity are key properties for on-line services, they challenge the development of these systems due to the complexity of the required architectures. In particular, the current infrastructures for the development of personalized, ubiquitous services are not flexible enough to accommodate the configuration requirements of the various application domains. To address such issues, highly configurable infrastructures are needed.In this article, we describe Seta2000, an infrastructure for the development of recommender systems that support personalized interactions with their users and are accessible from different types of devices (e.g., desktop computers and mobile phones). The Seta2000 infrastructure offers a built-in recommendation engine, based on a multi-agent architecture. Moreover, the infrastructure supports the integration of heterogeneous software and the development of agents that can be configured to offer specialized facilities within a recommender system, but also to dynamically enable and disable such facilities, depending on the requirements of the application domain. The Seta2000 infrastructure has been exploited to develop two prototypes: SeTA is an adaptive Web store personalizing the recommendation and presentation of products in the Web. INTRIGUE is a personalized, ubiquitous information system suggesting attractions to possibly heterogeneous tourist groups.",
    "cited_by_count": 58,
    "openalex_id": "https://openalex.org/W2039296460",
    "type": "article"
  },
  {
    "title": "The &lt;bigwig&gt; project",
    "doi": "https://doi.org/10.1145/514183.514184",
    "publication_date": "2002-05-01",
    "publication_year": 2002,
    "authors": "Claus Brabrand; Anders Møller; Michael I. Schwartzbach",
    "corresponding_authors": "",
    "abstract": "We present the results of the &lt;bigwig&gt; project, which aims to design and implement a high-level domain-specific language for programming interactive Web services. A fundamental aspect of the development of the World Wide Web during the last decade is the gradual change from static to dynamic generation of Web pages. Generating Web pages dynamically in dialog with the client has the advantage of providing up-to-date and tailor-made information. The development of systems for constructing such dynamic Web services has emerged as a whole new research area. The &lt;bigwig&gt; language is designed by analyzing its application domain and identifying fundamental aspects of Web services inspired by problems and solutions in existing Web service development languages. The core of the design consists of a session-centered service model together with a flexible template-based mechanism for dynamic Web page construction. Using specialized program analyses, certain Web-specific properties are verified at compile time, for instance that only valid HTML 4.01 is ever shown to the clients. In addition, the design provides high-level solutions to form field validation, caching of dynamic pages, and temporal-logic based concurrency control, and it proposes syntax macros for making highly domain-specific languages. The language is implemented via widely available Web technologies, such as Apache on the server-side and JavaScript and Java Applets on the client-side. We conclude with experience and evaluation of the project.",
    "cited_by_count": 58,
    "openalex_id": "https://openalex.org/W4235415159",
    "type": "article"
  },
  {
    "title": "Flash crowd mitigation via adaptive admission control based on application-level observations",
    "doi": "https://doi.org/10.1145/1084772.1084776",
    "publication_date": "2005-08-01",
    "publication_year": 2005,
    "authors": "Xuan Chen; John Heidemann",
    "corresponding_authors": "",
    "abstract": "We design an adaptive admission control mechanism, network early warning system (NEWS), to protect servers and networks from flash crowds and maintain high performance for end-users. NEWS detects flash crowds from performance degradation in responses and mitigates flash crowds by admitting incoming requests adaptively. We evaluate NEWS performance with both simulations and testbed experiments. We first investigate a network-limited scenarion in simulations. We find that NEWS detects flash crowds within 20 seconds. By discarding 32% of incoming requests, NEWS protects the target server and networks from overloading, reducing the response packet drop rate from 25% to 2%. For admitted requests, NEWS increases their response rate by two times. This performance is similar to the best static rate limiter deployed in the same scenario. We also investigate the impact of detection intervals on NEWS performance, showing it affects both detection delay and false alarm rate. We further consider a server memory-limited scenario in testbed experiments, confirming that NEWS is also effective in this case. We also examine the runtime cost of NEWS traffic monitoring in practice and find that it consumes little CPU time and relatively small memory. Finally, we show NEWS effectively protects bystander traffic from flash crowds.",
    "cited_by_count": 57,
    "openalex_id": "https://openalex.org/W2006579059",
    "type": "article"
  },
  {
    "title": "Recovery guarantees for Internet applications",
    "doi": "https://doi.org/10.1145/1013202.1013205",
    "publication_date": "2004-08-01",
    "publication_year": 2004,
    "authors": "Roger Barga; David Lomet; German Shegalov; Gerhard Weikum",
    "corresponding_authors": "",
    "abstract": "Internet-based e-services require application developers to deal explicitly with failures of the underlying software components, for example web servers, servlets, browser sessions, and so forth. This complicates application programming, and may expose failures to end users. This paper presents a framework for an application-independent infrastructure that provides recovery guarantees and masks almost all system failures, thus relieving the application programmer from having to deal with these failures---by making applications \"stateless.\" The main concept is an interaction contract between two components regarding message and state preservation. The framework provides comprehensive recovery encompassing data, messages, and the states of application components. We describe techniques to reduce logging cost, allow effective log truncation, and permit independent recovery for critical components. We illustrate the framework's utility via web-based e-services scenarios. Its feasibility is demonstrated by our prototype implementation of interaction contracts based on the Apache web server and the PHP servlet engine. Finally, we discuss industrial relevance for middleware architectures such as. Net or J2EE.",
    "cited_by_count": 56,
    "openalex_id": "https://openalex.org/W2166389164",
    "type": "article"
  },
  {
    "title": "Optimal methods for coordinated enroute web caching for tree networks",
    "doi": "https://doi.org/10.1145/1084772.1084774",
    "publication_date": "2005-08-01",
    "publication_year": 2005,
    "authors": "Keqiu Li; Hong Shen; Francis Y. L. Chin; S. Q. Zheng",
    "corresponding_authors": "",
    "abstract": "Web caching is an important technology for improving the scalability of Web services. One of the key problems in coordinated enroute Web caching is to compute the locations for storing copies of an object among the enroute caches so that some specified objectives are achieved. In this article, we address this problem for tree networks, and formulate it as a maximization problem. We consider this problem for both unconstrained and constrained cases. The constrained case includes constraints on the cost gain per node and on the number of object copies to be placed. We present dynamic programming-based solutions to this problem for different cases and theoretically show that the solutions are either optimal or convergent to optimal solutions. We derive efficient algorithms that produce these solutions. Based on our mathematical model, we also present a solution to coordinated enroute Web caching for autonomous systems as a natural extension of the solution for tree networks. We implement our algorithms and evaluate our model on different performance metrics through extensive simulation experiments. The implementation results show that our methods outperform the existing algorithms of either coordinated enroute Web caching for linear topology or object placement (replacement) at individual nodes only.",
    "cited_by_count": 55,
    "openalex_id": "https://openalex.org/W2041137953",
    "type": "article"
  },
  {
    "title": "A mobile computing middleware for location- and context-aware internet data services",
    "doi": "https://doi.org/10.1145/1183463.1183465",
    "publication_date": "2006-11-01",
    "publication_year": 2006,
    "authors": "Paolo Bellavista; Antonio Corradi; Rebecca Montanari; Cesare Stefanelli",
    "corresponding_authors": "",
    "abstract": "The widespread diffusion of mobile computing calls for novel services capable of providing results that depend on both the current physical position of users (location) and the logical set of accessible resources, subscribed services, preferences, and requirements (context). Leaving the burden of location/context management to applications complicates service design and development. In addition, traditional middleware solutions tend to hide location/context visibility to the application level and are not suitable for supporting novel adaptive services for mobile computing scenarios. The article proposes a flexible middleware for the development and deployment of location/context-aware services for heterogeneous data access in the Internet. A primary design choice is to exploit a high-level policy framework to simplify the specification of services that the middleware dynamically adapts to the client location/context. In addition, the middleware adopts the mobile agent technology to effectively support autonomous, asynchronous, and local access to data resources, and is particularly suitable for temporarily disconnected clients. The article also presents the case study of a museum guide assistant service that provides visitors with location/context-dependent artistic data. The case study points out the flexibility and usability of the proposed middleware that permits automatic service reconfiguration with no impact on the implementation of the application logic.",
    "cited_by_count": 54,
    "openalex_id": "https://openalex.org/W2004315268",
    "type": "article"
  },
  {
    "title": "Learning to find answers to questions on the Web",
    "doi": "https://doi.org/10.1145/990301.990303",
    "publication_date": "2004-05-01",
    "publication_year": 2004,
    "authors": "Eugene Agichtein; Steve Lawrence; Luis Gravano",
    "corresponding_authors": "",
    "abstract": "We introduce a method for learning to find documents on the Web that contain answers to a given natural language question. In our approach, questions are transformed into new queries aimed at maximizing the probability of retrieving answers from existing information retrieval systems. The method involves automatically learning phrase features for classifying questions into different types, automatically generating candidate query transformations from a training set of question/answer pairs, and automatically evaluating the candidate transformations on target information retrieval systems such as real-world general purpose search engines. At run-time, questions are transformed into a set of queries, and reranking is performed on the documents retrieved. We present a prototype search engine, Tritus , that applies the method to Web search engines. Blind evaluation on a set of real queries from a Web search engine log shows that the method significantly outperforms the underlying search engines, and outperforms a commercial search engine specializing in question answering. Our methodology cleanly supports combining documents retrieved from different search engines, resulting in additional improvement with a system that combines search results from multiple Web search engines.",
    "cited_by_count": 54,
    "openalex_id": "https://openalex.org/W2156368555",
    "type": "article"
  },
  {
    "title": "Characterizing a national community web",
    "doi": "https://doi.org/10.1145/1084772.1084775",
    "publication_date": "2005-08-01",
    "publication_year": 2005,
    "authors": "Daniel Gomes; Mário J. Silva",
    "corresponding_authors": "",
    "abstract": "This article presents a characterization of the community Web of the people of Portugal. We defined criteria for delimiting this Web based on our past experience of crawling pages related to Portugal and collected over 3.2 million documents from 46,000 sites satisfying those criteria. Our characterization was derived from this crawl. We describe the rules that we established for defining the boundaries of this community Web and the methodology used to gather statistics. Statistics cover the number and domain distribution of sites; the number, type and size distribution of text documents; and the linkage structure of this Web. We also show how crawling constraints and abnormal situations on the Web can influence the statistics.",
    "cited_by_count": 53,
    "openalex_id": "https://openalex.org/W2019194162",
    "type": "article"
  },
  {
    "title": "Internet content filtering using isotonic separation on content category ratings",
    "doi": "https://doi.org/10.1145/1189740.1189741",
    "publication_date": "2007-02-01",
    "publication_year": 2007,
    "authors": "Varghese S. Jacob; Ramayya Krishnan; Young U. Ryu",
    "corresponding_authors": "",
    "abstract": "The World Wide Web has enabled anybody with a low cost Internet connection to access vast information repositories. Some of these repositories contain information (e.g., hate speech and pornography) that is considered objectionable, especially for children to view. Several efforts---legal and technical---are underway to protect children and the generic public from accessing this type of content. We propose a technical approach utilizing a recently proposed technique called isotonic separation for filtering with content metadata if they satisfy monotone conditions. We illustrate this approach using a category rating method of PICS. In essence, we formulate the Internet content filtering problem as a classification problem on content metadata and report on experiments we conducted with the isotonic separation technique.",
    "cited_by_count": 48,
    "openalex_id": "https://openalex.org/W1963860163",
    "type": "article"
  },
  {
    "title": "The Web as a graph",
    "doi": "https://doi.org/10.1145/1189740.1189744",
    "publication_date": "2007-02-01",
    "publication_year": 2007,
    "authors": "Debora Donato; Luigi Laura; Stefano Leonardi; Stefano Millozzi",
    "corresponding_authors": "",
    "abstract": "In this article we present an experimental study of the properties of webgraphs. We study a large crawl from 2001 of 200M pages and about 1.4 billion edges, made available by the WebBase project at Stanford, as well as several synthetic ones generated according to various models proposed recently. We investigate several topological properties of such graphs, including the number of bipartite cores and strongly connected components, the distribution of degrees and PageRank values and some correlations; we present a comparison study of the models against these measures.Our findings are that (i) the WebBase sample differs slightly from the (older) samples studied in the literature, and (ii) despite the fact that these models do not catch all of its properties, they do exhibit some peculiar behaviors not found, for example, in the models from classical random graph theory.Moreover we developed a software library able to generate and measure massive graphs in secondary memory; this library is publicy available under the GPL licence. We discuss its implementation and some computational issues related to secondary memory graph algorithms.",
    "cited_by_count": 46,
    "openalex_id": "https://openalex.org/W2077317318",
    "type": "article"
  },
  {
    "title": "Flexible provisioning of web service workflows",
    "doi": "https://doi.org/10.1145/1462159.1462161",
    "publication_date": "2009-02-01",
    "publication_year": 2009,
    "authors": "Sebastian Stein; Terry R. Payne; Nicholas R. Jennings",
    "corresponding_authors": "",
    "abstract": "Web services promise to revolutionize the way computational resources and business processes are offered and invoked in open, distributed systems, such as the Internet. These services are described using machine-readable metadata, which enables consumer applications to automatically discover and provision suitable services for their workflows at run-time. However, current approaches have typically assumed service descriptions are accurate and deterministic, and so have neglected to account for the fact that services in these open systems are inherently unreliable and uncertain. Specifically, network failures, software bugs and competition for services may regularly lead to execution delays or even service failures. To address this problem, the process of provisioning services needs to be performed in a more flexible manner than has so far been considered, in order to proactively deal with failures and to recover workflows that have partially failed. To this end, we devise and present a heuristic strategy that varies the provisioning of services according to their predicted performance. Using simulation, we then benchmark our algorithm and show that it leads to a 700% improvement in average utility, while successfully completing up to eight times as many workflows as approaches that do not consider service failures.",
    "cited_by_count": 46,
    "openalex_id": "https://openalex.org/W2104140093",
    "type": "article"
  },
  {
    "title": "A model of process documentation to determine provenance in mash-ups",
    "doi": "https://doi.org/10.1145/1462159.1462162",
    "publication_date": "2009-02-01",
    "publication_year": 2009,
    "authors": "Paul Groth; Simon Miles; Luc Moreau",
    "corresponding_authors": "",
    "abstract": "Through technologies such as RSS (Really Simple Syndication), Web Services, and AJAX (Asynchronous JavaScript and XML), the Internet has facilitated the emergence of applications that are composed from a variety of services and data sources. Through tools such as Yahoo Pipes, these “mash-ups” can be composed in a dynamic, just-in-time manner from components provided by multiple institutions (i.e., Google, Amazon, your neighbor). However, when using these applications, it is not apparent where data comes from or how it is processed. Thus, to inspire trust and confidence in mash-ups, it is critical to be able to analyze their processes after the fact. These trailing analyses , in particular the determination of the provenance of a result (i.e., the process that led to it), are enabled by process documentation , which is documentation of an application's past process created by the components of that application at execution time. In this article, we define a generic conceptual data model that supports the autonomous creation of attributable, factual process documentation for dynamic multi-institutional applications. The data model is instantiated using two Internet formats, OWL and XML, and is evaluated with respect to questions about the provenance of results generated by a complex bioinformatics mash-up.",
    "cited_by_count": 45,
    "openalex_id": "https://openalex.org/W2007561161",
    "type": "article"
  },
  {
    "title": "Optimal design of english auctions with discrete bid levels",
    "doi": "https://doi.org/10.1145/1239971.1239976",
    "publication_date": "2007-05-01",
    "publication_year": 2007,
    "authors": "Esther David; Alex Rogers; Nicholas R. Jennings; Jeremy Schiff; Sarit Kraus; Michael H. Rothkopf",
    "corresponding_authors": "",
    "abstract": "This article considers a canonical auction protocol that forms the basis of nearly all current online auctions. Such discrete bid auctions require that the bidders submit bids at predetermined discrete bid levels, and thus, there exists a minimal increment by which the bid price may be raised. In contrast, the academic literature of optimal auction design deals almost solely with continuous bid auctions. As a result, there is little practical guidance as to how an auctioneer, seeking to maximize its revenue, should determine the number and value of these discrete bid levels, and it is this omission that is addressed here. To this end, a model of an ascending price English auction with discrete bid levels is considered. An expression for the expected revenue of this auction is derived and used to determine numerical and analytical solutions for the optimal bid levels in the case of uniform and exponential bidder's valuation distributions. Finally, in order to develop an intuitive understanding of how these optimal bid levels are distributed, the limiting case where the number of discrete bid levels is large is considered, and an analytical expression for their distribution is derived.",
    "cited_by_count": 45,
    "openalex_id": "https://openalex.org/W2044311282",
    "type": "article"
  },
  {
    "title": "Anomaly Detection in Dynamic Systems Using Weak Estimators",
    "doi": "https://doi.org/10.1145/1993083.1993086",
    "publication_date": "2011-07-01",
    "publication_year": 2011,
    "authors": "Justin Zhan; B. John Oommen; Johanna Crisostomo",
    "corresponding_authors": "",
    "abstract": "Anomaly detection involves identifying observations that deviate from the normal behavior of a system. One of the ways to achieve this is by identifying the phenomena that characterize “normal” observations. Subsequently, based on the characteristics of data learned from the “normal” observations, new observations are classified as being either “normal” or not. Most state-of-the-art approaches, especially those which belong to the family of parameterized statistical schemes, work under the assumption that the underlying distributions of the observations are stationary. That is, they assume that the distributions that are learned during the training (or learning) phase, though unknown, are not time-varying. They further assume that the same distributions are relevant even as new observations are encountered. Although such a “stationarity” assumption is relevant for many applications, there are some anomaly detection problems where stationarity cannot be assumed. For example, in network monitoring, the patterns which are learned to represent normal behavior may change over time due to several factors such as network infrastructure expansion, new services, growth of user population, and so on. Similarly, in meteorology, identifying anomalous temperature patterns involves taking into account seasonal changes of normal observations. Detecting anomalies or outliers under these circumstances introduces several challenges. Indeed, the ability to adapt to changes in nonstationary environments is necessary so that anomalous observations can be identified even with changes in what would otherwise be classified as “normal” behavior. In this article we propose to apply a family of weak estimators for anomaly detection in dynamic environments. In particular, we apply this theory to spam email detection. Our experimental results demonstrate that our proposal is both feasible and effective for the detection of such anomalous emails.",
    "cited_by_count": 39,
    "openalex_id": "https://openalex.org/W2027192235",
    "type": "article"
  },
  {
    "title": "Vulnerabilities and countermeasures in context-aware social rating services",
    "doi": "https://doi.org/10.1145/2078316.2078319",
    "publication_date": "2012-01-01",
    "publication_year": 2012,
    "authors": "Qinyuan Feng; Ling Liu; Yafei Dai",
    "corresponding_authors": "",
    "abstract": "Social trust and recommendation services are the most popular social rating systems today for service providers to learn about the social opinion or popularity of a product, item, or service, such as a book on Amazon, a seller on eBay, a story on Digg or a movie on Netflix. Such social rating systems are very convenient and offer alternative learning environments for decision makers, but they open the door for attackers to manipulate the social rating systems by selfishly promoting or maliciously demoting certain items. Although a fair amount of effort has been made to understand various risks and possible defense mechanisms to counter such attacks, most of the existing work to date has been devoted to studying specific types of attacks and their countermeasures. In this article, we argue that vulnerabilities in social rating systems and their countermeasures should be examined and analyzed in a systematic manner. We first give an overview of the common vulnerabilities and attacks observed in some popular social rating services. Next, we describe three types of attack strategies in two types of social rating systems, including a comprehensive theoretical analysis of their attack effectiveness and attack costs. Three context-aware countermeasures are then presented: (i) hiding user-item relationships, (ii) using confidence weight to distinguish popular and unpopular items, and (iii) incorporating time windows in trust establishment. We also provide an in-depth discussion on how these countermeasures can be used effectively to improve the robustness and trustworthiness of the social rating services.",
    "cited_by_count": 34,
    "openalex_id": "https://openalex.org/W2017085583",
    "type": "article"
  },
  {
    "title": "Integrating Social and Auxiliary Semantics for Multifaceted Topic Modeling in Twitter",
    "doi": "https://doi.org/10.1145/2651403",
    "publication_date": "2014-12-17",
    "publication_year": 2014,
    "authors": "Jan Vosecky; Di Jiang; Kenneth Wai-Ting Leung; Kai Xing; Wilfred Ng",
    "corresponding_authors": "",
    "abstract": "Microblogging platforms, such as Twitter, have already played an important role in recent cultural, social and political events. Discovering latent topics from social streams is therefore important for many downstream applications, such as clustering, classification or recommendation. However, traditional topic models that rely on the bag-of-words assumption are insufficient to uncover the rich semantics and temporal aspects of topics in Twitter. In particular, microblog content is often influenced by external information sources, such as Web documents linked from Twitter posts, and often focuses on specific entities, such as people or organizations. These external sources provide useful semantics to understand microblogs and we generally refer to these semantics as auxiliary semantics . In this article, we address the mentioned issues and propose a unified framework for Multifaceted Topic Modeling from Twitter streams. We first extract social semantics from Twitter by modeling the social chatter associated with hashtags. We further extract terms and named entities from linked Web documents to serve as auxiliary semantics during topic modeling. The Multifaceted Topic Model (MfTM) is then proposed to jointly model latent semantics among the social terms from Twitter, auxiliary terms from the linked Web documents and named entities. Moreover, we capture the temporal characteristics of each topic. An efficient online inference method for MfTM is developed, which enables our model to be applied to large-scale and streaming data. Our experimental evaluation shows the effectiveness and efficiency of our model compared with state-of-the-art baselines. We evaluate each aspect of our framework and show its utility in the context of tweet clustering.",
    "cited_by_count": 34,
    "openalex_id": "https://openalex.org/W2089631096",
    "type": "article"
  },
  {
    "title": "Approximation Algorithms for Secondary Spectrum Auctions",
    "doi": "https://doi.org/10.1145/2663496",
    "publication_date": "2014-10-28",
    "publication_year": 2014,
    "authors": "Martin Hoefer; Thomas Keßelheim; Berthold Vöcking",
    "corresponding_authors": "",
    "abstract": "We study combinatorial auctions for secondary spectrum markets, where short-term communication licenses are sold to wireless nodes. Channels can be assigned to multiple bidders according to interference constraints captured by a conflict graph. We suggest a novel approach to such combinatorial auctions using a graph parameter called inductive independence number. We achieve good approximation results by showing that interference constraints for wireless networks imply a bounded inductive independence number. For example, in the physical model the factor becomes O (√ k log 2 n ) for n bidders and k channels. Our algorithms can be turned into incentive-compatible mechanisms for bidders with arbitrary valuations.",
    "cited_by_count": 33,
    "openalex_id": "https://openalex.org/W2039570968",
    "type": "article"
  },
  {
    "title": "Using Argumentation to Improve Classification in Natural Language Problems",
    "doi": "https://doi.org/10.1145/3017679",
    "publication_date": "2017-07-12",
    "publication_year": 2017,
    "authors": "Lucas Carstens; Francesca Toni",
    "corresponding_authors": "",
    "abstract": "Argumentation has proven successful in a number of domains, including Multi-Agent Systems and decision support in medicine and engineering. We propose its application to a domain yet largely unexplored by argumentation research: computational linguistics. We have developed a novel classification methodology that incorporates reasoning through argumentation with supervised learning. We train classifiers and then argue about the validity of their output. To do so, we identify arguments that formalise prototypical knowledge of a problem and use them to correct misclassifications. We illustrate our methodology on two tasks. On the one hand, we address cross-domain sentiment polarity classification , where we train classifiers on one corpus, for example, Tweets, to identify positive/negative polarity and classify instances from another corpus, for example, sentences from movie reviews. On the other hand, we address a form of argumentation mining that we call Relation-based Argumentation Mining , where we classify pairs of sentences based on whether the first sentence attacks or supports the second or whether it does neither. Whenever we find that one sentence attacks/supports the other, we consider both to be argumentative, irrespective of their stand-alone argumentativeness. For both tasks, we improve classification performance when using our methodology, compared to using standard classifiers only.",
    "cited_by_count": 32,
    "openalex_id": "https://openalex.org/W2589020727",
    "type": "article"
  },
  {
    "title": "Real-Time Traffic Event Detection From Social Media",
    "doi": "https://doi.org/10.1145/3122982",
    "publication_date": "2017-11-04",
    "publication_year": 2017,
    "authors": "Di Wang; Ahmad Alrubaie; Sandra Stinčić Clarke; John Davies",
    "corresponding_authors": "",
    "abstract": "Smart communities are composed of groups, organizations, and individuals who share information and make use of that shared information for better decision making. Shared information can come from many sources, particularly, but not exclusively, from sensors and social media. Social media has become an important source of near-instantaneous user-generated information that can be shared and analyzed to support better decision making. One domain where social media data can add value is transportation and traffic management. This article looks at the exploitation of Twitter data in the traffic reporting domain. A key challenge is how to identify relevant information from a huge amount of user-generated data and then analyze the relevant data for automatic geocoded incident detection. The article proposes an instant traffic alert and warning system based on a novel latent Dirichlet allocation (LDA) approach (“tweet-LDA”). The system is evaluated and shown to perform better than related approaches.",
    "cited_by_count": 32,
    "openalex_id": "https://openalex.org/W2767603490",
    "type": "article"
  },
  {
    "title": "Negotiating Premium Peering Prices",
    "doi": "https://doi.org/10.1145/2883610",
    "publication_date": "2016-04-14",
    "publication_year": 2016,
    "authors": "Costas Courcoubetis; László Gyarmati; Nikolaos Laoutaris; Pablo Rodríguez; Kostas Sdrolias",
    "corresponding_authors": "",
    "abstract": "We have developed a novel methodology for deriving bandwidth prices for premium direct peering between Access ISPs (A-ISPs) and Content and Service Providers (CSPs) that want to deliver content and services in premium quality. Our methodology establishes a direct link between service profitability, for example, from advertising, user and subscriber loyalty, interconnection costs, and finally bandwidth price for peering. Unlike existing work in both the networking and economics literature, our resulting computational model, built around Nash bargaining, can be used for deriving quantitative results comparable to actual market prices. We analyze the U.S. market and derive prices for video, that compare favorably with existing prices for transit and paid peering. We also observe that the fair prices returned by the model for high-profit/low-volume services such as search, are orders of magnitude higher than current bandwidth prices. This implies that resolving existing (fierce) interconnection tussles may require per service, instead of wholesale, peering between A-ISPs and CSPs. Our model can be used for deriving initial benchmark prices for such negotiations.",
    "cited_by_count": 30,
    "openalex_id": "https://openalex.org/W2342201355",
    "type": "article"
  },
  {
    "title": "SSL-SVD",
    "doi": "https://doi.org/10.1145/3369390",
    "publication_date": "2020-01-29",
    "publication_year": 2020,
    "authors": "Zhengdi Hu; Guangquan Xu; Xi Zheng; Jiang Liu; Zhangbing Li; Quan Z. Sheng; Wenjuan Lian; Hequn Xian",
    "corresponding_authors": "",
    "abstract": "Recommendation systems have been widely used in large e-commerce websites, but cold start and data sparsity seriously affect the accuracy of recommendation. To solve these problems, we propose SSL-SVD, which works to mine the sparse trust between users and improve the performance of the recommendation system. Specifically, we mine sparse trust relationships by decomposing trust impact into fine-grained factors and employing the Transductive Support Vector Machine algorithm to combine these factors. Then, we incorporate both social trust and sparse trust information into the SVD++ model, which can effectively utilize the explicit and implicit influence of trust for rating prediction in the recommendation system. Experiments show that our SSL-SVD increases the trust density degree of each dataset by more than 65% and improves the recommendation accuracy by up to 4.3%.",
    "cited_by_count": 29,
    "openalex_id": "https://openalex.org/W3003213456",
    "type": "article"
  },
  {
    "title": "DAN-SNR",
    "doi": "https://doi.org/10.1145/3430504",
    "publication_date": "2020-12-22",
    "publication_year": 2020,
    "authors": "Liwei Huang; Yutao Ma; Yanbo Liu; Keqing He",
    "corresponding_authors": "",
    "abstract": "Next (or successive) point-of-interest (POI) recommendation has attracted increasing attention in recent years. Most of the previous studies attempted to incorporate the spatiotemporal information and sequential patterns of user check-ins into recommendation models to predict the target user's next move. However, none of these approaches utilized the social influence of each user's friends. In this study, we discuss a new topic of next POI recommendation and present a deep attentive network for social-aware next POI recommendation called DAN-SNR. In particular, the DAN-SNR makes use of the self-attention mechanism instead of the architecture of recurrent neural networks to model sequential influence and social influence in a unified manner. Moreover, we design and implement two parallel channels to capture short-term user preference and long-term user preference as well as social influence, respectively. By leveraging multi-head self-attention, the DAN-SNR can model long-range dependencies between any two historical check-ins efficiently and weigh their contributions to the next destination adaptively. Also, we carried out a comprehensive evaluation using large-scale real-world datasets collected from two popular location-based social networks, namely Gowalla and Brightkite. Experimental results indicate that the DAN-SNR outperforms seven competitive baseline approaches regarding recommendation performance and is of high efficiency among six neural-network- and attention-based methods.",
    "cited_by_count": 29,
    "openalex_id": "https://openalex.org/W3117746347",
    "type": "article"
  },
  {
    "title": "Practical Privacy-preserving High-order Bi-Lanczos in Integrated Edge-Fog-Cloud Architecture for Cyber-Physical-Social Systems",
    "doi": "https://doi.org/10.1145/3230641",
    "publication_date": "2019-03-28",
    "publication_year": 2019,
    "authors": "Jun Feng; Laurence T. Yang; Ronghao Zhang",
    "corresponding_authors": "",
    "abstract": "Smart environments, also referred to as cyber-physical-social systems (CPSSs), are expected to significantly benefit from the integration of edge, fog, and cloud for intelligence service flexibility, efficiency, and cost saving. High-order Bi-Lanczos method has emerged as a powerful tool serving as multi-dimensional data processing, such as prevailing feature extraction, classification, and clustering of high-order data, in CPSSs. However, integrated edge-fog-cloud architecture is open and users have very limited control; how to carry out big data processing without compromising the security and privacy is a challenging issue in edge-fog-cloud-assisted smart applications. In this work, we propose a novel and practical privacy-preserving high-order Bi-Lanczos scheme in integrated edge-fog-cloud architectural paradigm for smart environments. More precisely, we first propose a privacy-preserving big data processing model using the synergy of edge, fog, and cloud. The proposed model enables edge, fog, and cloud to cooperatively complete big data processing without compromising users’ privacy for large-scale tensor data in CPSSs. Subsequently, making use of the model, we present a privacy-preserving high-order Bi-Lanczos scheme. Finally, we theoretically and empirically analyze the security and efficiency of the proposed privacy-preserving high-order Bi-Lanczos scheme based on an intelligent surveillance system case study. And the results demonstrate that the proposed scheme provides a privacy-preserving and efficient way of computations in integrated edge-fog-cloud paradigm for smart environments.",
    "cited_by_count": 28,
    "openalex_id": "https://openalex.org/W2929004104",
    "type": "article"
  },
  {
    "title": "Trust Prediction via Matrix Factorisation",
    "doi": "https://doi.org/10.1145/3323163",
    "publication_date": "2019-09-19",
    "publication_year": 2019,
    "authors": "Pasquale De Meo",
    "corresponding_authors": "Pasquale De Meo",
    "abstract": "In this article, we propose the PTP-MF (Pairwise Trust Prediction through Matrix Factorisation) algorithm, an approach to predicting the intensity of trust and distrust relations in Online Social Networks (OSNs). Our algorithm maps each OSN user i onto two low-dimensional vectors, namely, the trustor profile (describing her/his inclination to trust others) and the trustee profile (modelling how others perceive i as trustworthy) and it computes the trust a user i places in a user j as the dot product of trustor profile of i and the trustee profile of j . The PTP-MF algorithm incorporates also biases in trustor and trustee behaviour to make more accurate predictions. Experiments on four real-life datasets indicate that the PTP-MF algorithm significantly outperforms other methods in accuracy and it showcases a high scalability.",
    "cited_by_count": 28,
    "openalex_id": "https://openalex.org/W2998228178",
    "type": "article"
  },
  {
    "title": "Five Challenges in Cloud-enabled Intelligence and Control",
    "doi": "https://doi.org/10.1145/3366021",
    "publication_date": "2020-02-10",
    "publication_year": 2020,
    "authors": "Tarek Abdelzaher; Yifan Hao; Kasthuri Jayarajah; Archan Misra; Per Skarin; Shuochao Yao; Dulanga Weerakoon; Karl-Erik Årzén",
    "corresponding_authors": "",
    "abstract": "The proliferation of connected embedded devices, or the Internet of Things (IoT), together with recent advances in machine intelligence, will change the profile of future cloud services and introduce a variety of new research problems, both in cloud applications and infrastructure layers. These problems are centered around empowering individually resource-limited devices to exhibit intelligent behavior, both in sensing and control, thanks to a judicious utilization of cloud resources. Cloud services will enable learning from data, perform inference, and execute control, all with assurances on outcomes. This article discusses such emerging services and outlines five resulting new research directions towards enabling and optimizing intelligent, cloud-assisted sensing and control in the age of the Internet of Things.",
    "cited_by_count": 27,
    "openalex_id": "https://openalex.org/W2996318927",
    "type": "article"
  },
  {
    "title": "A Novel Multiobjective GDWCN-PSO Algorithm and Its Application to Medical Data Security",
    "doi": "https://doi.org/10.1145/3397679",
    "publication_date": "2020-07-07",
    "publication_year": 2020,
    "authors": "Vandana Bharti; Bhaskar Biswas; K.K. Shukla",
    "corresponding_authors": "",
    "abstract": "Nature-inspired optimization is one of the most prevalent research domains with a confounding history that fascinates the research communities. Particle Swarm Optimization is one of the well-known optimizers that belongs to the family of nature-inspired algorithms. It often suffers from premature convergence leading to a local optimum. To address this, several methods were presented using different network topologies of the particles, but either lacked accuracy or were slow. To solve these problems, an improved version of the Directed Weighted Complex Network Particle Swarm Optimization using the Genetic Algorithm (GDWCN-PSO) is presented. This method uses the concept of the Genetic Algorithm after each update to enhance convergence and diversity. Since most of the real-world applications and complex optimization problems involve more than one objective function so to suit this problem, a multiobjective version of GDWCN-PSO is also proposed and validated on standard benchmarks. To demonstrate its applicability in real-world applications, GDWCN-PSO is applied to solve the optimal key-based medical image encryption. It is one of the most challenging problems in health IoTs for protecting sensitive and confidential patient data as well as addressing the major concern of integrity and security of data in today’s advanced digital world.",
    "cited_by_count": 26,
    "openalex_id": "https://openalex.org/W3041308951",
    "type": "article"
  },
  {
    "title": "Multimodal Brain Tumor Segmentation Based on an Intelligent UNET-LSTM Algorithm in Smart Hospitals",
    "doi": "https://doi.org/10.1145/3450519",
    "publication_date": "2021-06-16",
    "publication_year": 2021,
    "authors": "Hexuan Hu; Wenjie Mao; Zhen-Zhou Lin; Qiang Hu; Ye Zhang",
    "corresponding_authors": "",
    "abstract": "Smart hospitals are important components of smart cities. An intelligent medical system for brain tumor segmentation is required to construct smart hospitals. To achieve intelligent brain tumor segmentation, morphological variety and serious category imbalance must be managed effectively. Conventional deep neural networks have difficulty in predicting high-accuracy segmentation images due to these issues. To solve these problems, we propose using multimodal brain tumor images combined with the UNET and LSTM models to construct a new network structure with a mixed loss function to solve sample imbalance and describe an intelligent segmentation process to identify brain tumors. To verify the practicability of this algorithm, we used the open source Brain Tumor Segmentation Challenge dataset to train and verify the proposed network. We obtained DSCs of 0.91, 0.82, and 0.80; sensitivities of 0.93, 0.85, and 0.82; and specificities of 0.99, 0.99, and 0.98 in three tumor regions, including the whole tumor ( WT ), tumor core ( TC ), and enhanced tumor ( ET ). We also compared the results of the proposed network with those of other brain tumor segmentation methods, and the results showed that the proposed algorithm could segment different tumor lesions more accurately, highlighting its potential application value in the clinical diagnosis of brain tumors.",
    "cited_by_count": 25,
    "openalex_id": "https://openalex.org/W3168737150",
    "type": "article"
  },
  {
    "title": "Enabling User-centered Privacy Controls for Mobile Applications",
    "doi": "https://doi.org/10.1145/3434777",
    "publication_date": "2021-01-30",
    "publication_year": 2021,
    "authors": "Tanusree Sharma; Hunter A. Dyer; Masooda Bashir",
    "corresponding_authors": "",
    "abstract": "Mobile apps have transformed many aspects of clinical practice and are becoming a commonplace in healthcare settings. The recent COVID-19 pandemic has provided the opportunity for such apps to play an important role in reducing the spread of the virus. Several types of COVID-19 apps have enabled healthcare professionals and governments to communicate with the public regarding the pandemic spread, coronavirus awareness, and self-quarantine measures. While these apps provide immense benefits for the containment of the spread, privacy and security of these digital tracing apps are at the center of public debate. To address this gap, we conducted an online survey of a midwestern region in the United State to assess people’s attitudes toward such apps and to examine their privacy and security concerns and preferences. Survey results from 1,550 participants indicate that privacy/security protections and trust play a vital role in people’s adoption of such apps. Furthermore, results reflect users’ preferences wanting to have control over their personal information and transparency on how their data is handled. In addition, personal data protection priorities selected by the participants were surprising and yet revealing of the disconnect between technologists and users. In this article, we present our detailed survey results as well as design guidelines for app developers to develop innovative human-centered technologies that are not only functional but also respectful of social norms and protections of civil liberties. Our study examines users’ preferences for COVID-19 apps and integrates important factors of trust, willingness, and preferences in the context of app development. Through our research findings, we suggest mechanisms for designing inclusive apps’ privacy and security measures that can be put into practice for healthcare-related apps, so that timely adoption is made possible.",
    "cited_by_count": 24,
    "openalex_id": "https://openalex.org/W3126931089",
    "type": "article"
  },
  {
    "title": "Epilepsy Diagnosis Using Multi-view &amp; Multi-medoid Entropy-based Clustering with Privacy Protection",
    "doi": "https://doi.org/10.1145/3404893",
    "publication_date": "2021-05-24",
    "publication_year": 2021,
    "authors": "Yuanpeng Zhang; Yizhang Jiang; Lianyong Qi; Md Zakirul Alam Bhuiyan; Pengjiang Qian",
    "corresponding_authors": "",
    "abstract": "Using unsupervised learning methods for clinical diagnosis is very meaningful. In this study, we propose an unsupervised multi-view &amp; multi-medoid variant-entropy-based fuzzy clustering (M 2 VEFC) method for epilepsy EEG signals detecting. Comparing with existing related studies, M 2 VEFC has four main merits and contributions: (1) Features in original EEG data are represented from different perspectives that can provide more pattern information for epilepsy signals detecting. (2) During multi-view modeling, multi-medoids are used to capture the structure of clusters in each view. Furthermore, we assume that the medoids in a cluster observed from different views should keep invariant, which is taken as one of the collaborative learning mechanisms in this study. (3) A variant entropy is designed as another collaborative learning mechanism in which view weight learning is controlled by a user-free parameter. The parameter is derived from the distribution of samples in each view such that the learned weights have more discrimination. (4) M 2 VEFC does not need original data as its input—it only needs a similarity matrix and feature statistical information. Therefore, the original data are not exposed to users and hence the privacy is protected. We use several different kinds of feature extraction techniques to extract several groups of features as multi-view data from original EEG data to test the proposed method M 2 VEFC. Experimental results indicate M 2 VEFC achieves a promising performance that is better than benchmarking models.",
    "cited_by_count": 24,
    "openalex_id": "https://openalex.org/W3165541792",
    "type": "article"
  },
  {
    "title": "Intelligent Traffic Signal Control Based on Reinforcement Learning with State Reduction for Smart Cities",
    "doi": "https://doi.org/10.1145/3418682",
    "publication_date": "2021-07-22",
    "publication_year": 2021,
    "authors": "Li Kuang; Jianbo Zheng; Kemu Li; Honghao Gao",
    "corresponding_authors": "",
    "abstract": "Efficient signal control at isolated intersections is vital for relieving congestion, accidents, and environmental pollution caused by increasing numbers of vehicles. However, most of the existing studies not only ignore the constraint of the limited computing resources available at isolated intersections but also the matching degree between the signal timing and the traffic demand, leading to high complexity and reduced learning efficiency. In this article, we propose a traffic signal control method based on reinforcement learning with state reduction. First, a reinforcement learning model is established based on historical traffic flow data, and we propose a dual-objective reward function that can reduce vehicle delay and improve the matching degree between signal time allocation and traffic demand, allowing the agent to learn the optimal signal timing strategy quickly. Second, the state and action spaces of the model are preliminarily reduced by selecting a proper control phase combination; then, the state space is further reduced by eliminating rare or nonexistent states based on the historical traffic flow. Finally, a simplified Q-table is generated and used to optimize the complexity of the control algorithm. The results of simulation experiments show that our proposed control algorithm effectively improves the capacity of isolated intersections while reducing the time and space costs of the signal control algorithm.",
    "cited_by_count": 24,
    "openalex_id": "https://openalex.org/W3186708693",
    "type": "article"
  },
  {
    "title": "Machine Learning-based Mist Computing Enabled Internet of Battlefield Things",
    "doi": "https://doi.org/10.1145/3418204",
    "publication_date": "2021-09-01",
    "publication_year": 2021,
    "authors": "Huniya Shahid; Munam Ali Shah; Ahmad Almogren; Hasan Ali Khattak; Ikram Ud Din; Neeraj Kumar; Carsten Maple",
    "corresponding_authors": "",
    "abstract": "The rapid advancement in information and communication technology has revolutionized military departments and their operations. This advancement also gave birth to the idea of the Internet of Battlefield Things (IoBT). The IoBT refers to the fusion of the Internet of Things (IoT) with military operations on the battlefield. Various IoBT-based frameworks have been developed for the military. Nonetheless, many of these frameworks fail to maintain a high Quality of Service (QoS) due to the demanding and critical nature of IoBT. This study makes the use of mist computing while leveraging machine learning. Mist computing places computational capabilities on the edge itself (mist nodes), e.g., on end devices, wearables, sensors, and micro-controllers. This way, mist computing not only decreases latency but also saves power consumption and bandwidth as well by eliminating the need to communicate all data acquired, produced, or sensed. A mist-based version of the IoTNetWar framework is also proposed in this study. The mist-based IoTNetWar framework is a four-layer structure that aims at decreasing latency while maintaining QoS. Additionally, to further minimize delays, mist nodes utilize machine learning. Specifically, they use the delay-based K nearest neighbour algorithm for device-to-device communication purposes. The primary research objective of this work is to develop a system that is not only energy, time, and bandwidth-efficient, but it also helps military organizations with time-critical and resources-critical scenarios to monitor troops. By doing so, the system improves the overall decision-making process in a military campaign or battle. The proposed work is evaluated with the help of simulations in the EdgeCloudSim. The obtained results indicate that the proposed framework can achieve decreased network latency of 0.01 s and failure rate of 0.25% on average while maintaining high QoS in comparison to existing solutions.",
    "cited_by_count": 24,
    "openalex_id": "https://openalex.org/W3198442084",
    "type": "article"
  },
  {
    "title": "Alexa, Who Am I Speaking To?: Understanding Users’ Ability to Identify Third-Party Apps on Amazon Alexa",
    "doi": "https://doi.org/10.1145/3446389",
    "publication_date": "2021-09-14",
    "publication_year": 2021,
    "authors": "David Major; Danny Yuxing Huang; Marshini Chetty; Nick Feamster",
    "corresponding_authors": "",
    "abstract": "Many Internet of Things devices have voice user interfaces. One of the most popular voice user interfaces is Amazon’s Alexa, which supports more than 50,000 third-party applications (“skills”). We study how Alexa’s integration of these skills may confuse users. Our survey of 237 participants found that users do not understand that skills are often operated by third parties, that they often confuse third-party skills with native Alexa functions, and that they are unaware of the functions that the native Alexa system supports. Surprisingly, users who interact with Alexa more frequently are more likely to conclude that a third-party skill is a native Alexa function. The potential for misunderstanding creates new security and privacy risks: attackers can develop third-party skills that operate without users’ knowledge or masquerade as native Alexa functions. To mitigate this threat, we make design recommendations to help users better distinguish native functionality and third-party skills, including audio and visual indicators of native and third-party contexts, as well as a consistent design standard to help users learn what functions are and are not possible on Alexa.",
    "cited_by_count": 24,
    "openalex_id": "https://openalex.org/W3199832317",
    "type": "article"
  },
  {
    "title": "Serving at the Edge: An Edge Computing Service Architecture Based on ICN",
    "doi": "https://doi.org/10.1145/3464428",
    "publication_date": "2021-10-15",
    "publication_year": 2021,
    "authors": "Zhenyu Fan; Wang Yang; Fan Wu; Jing Cao; Weisong Shi",
    "corresponding_authors": "",
    "abstract": "Different from cloud computing, edge computing moves computing away from the centralized data center and closer to the end-user. Therefore, with the large-scale deployment of edge services, it becomes a new challenge of how to dynamically select the appropriate edge server for computing requesters based on the edge server and network status. In the TCP/IP architecture, edge computing applications rely on centralized proxy servers to select an appropriate edge server, which leads to additional network overhead and increases service response latency. Due to its powerful forwarding plane, Information-Centric Networking (ICN) has the potential to provide more efficient networking support for edge computing than TCP/IP. However, traditional ICN only addresses named data and cannot well support the handle of dynamic content. In this article, we propose an edge computing service architecture based on ICN, which contains the edge computing service session model, service request forwarding strategies, and service dynamic deployment mechanism. The proposed service session model can not only keep the overhead low but also push the results to the computing requester immediately once the computing is completed. However, the service request forwarding strategies can forward computing requests to an appropriate edge server in a distributed manner. Compared with the TCP/IP-based proxy solution, our forwarding strategy can avoid unnecessary network transmissions, thereby reducing the service completion time. Moreover, the service dynamic deployment mechanism decides whether to deploy an edge service on an edge server based on service popularity, so that edge services can be dynamically deployed to hotspot, further reducing the service completion time.",
    "cited_by_count": 24,
    "openalex_id": "https://openalex.org/W3205419154",
    "type": "article"
  },
  {
    "title": "Machine Learning in Mobile Crowd Sourcing: A Behavior-Based Recruitment Model",
    "doi": "https://doi.org/10.1145/3451163",
    "publication_date": "2021-11-09",
    "publication_year": 2021,
    "authors": "Menatalla Abououf; Shakti Singh; Hadi Otrok; Rabeb Mizouni; Ernesto Damiani",
    "corresponding_authors": "",
    "abstract": "With the advent of mobile crowd sourcing (MCS) systems and its applications, the selection of the right crowd is gaining utmost importance. The increasing variability in the context of MCS tasks makes the selection of not only the capable but also the willing workers crucial for a high task completion rate. Most of the existing MCS selection frameworks rely primarily on reputation-based feedback mechanisms to assess the level of commitment of potential workers. Such frameworks select workers having high reputation scores but without any contextual awareness of the workers, at the time of selection, or the task. This may lead to an unfair selection of workers who will not perform the task. Hence, reputation on its own only gives an approximation of workers’ behaviors since it assumes that workers always behave consistently regardless of the situational context. However, following the concept of cross-situational consistency, where people tend to show similar behavior in similar situations and behave differently in disparate ones, this work proposes a novel recruitment system in MCS based on behavioral profiling. The proposed approach uses machine learning to predict the probability of the workers performing a given task, based on their learned behavioral models. Subsequently, a group-based selection mechanism, based on the genetic algorithm, uses these behavioral models in complementation with a reputation-based model to recruit a group of workers that maximizes the quality of recruitment of the tasks. Simulations based on a real-life dataset show that considering human behavior in varying situations improves the quality of recruitment achieved by the tasks and their completion confidence when compared with a benchmark that relies solely on reputation.",
    "cited_by_count": 24,
    "openalex_id": "https://openalex.org/W3213618436",
    "type": "article"
  },
  {
    "title": "Privacy Care",
    "doi": "https://doi.org/10.1145/3430506",
    "publication_date": "2021-02-02",
    "publication_year": 2021,
    "authors": "Vikram Mehta; Daniel Gooch; Arosha K. Bandara; Blaine Price; Bashar Nuseibeh",
    "corresponding_authors": "",
    "abstract": "The emergence of ubiquitous computing (UbiComp) environments has increased the risk of undesired access to individuals’ physical space or their information, anytime and anywhere, raising potentially serious privacy concerns. Individuals lack awareness and control of the vulnerabilities in everyday contexts and need support and care in regulating disclosures to their physical and digital selves. Existing GUI-based solutions, however, often feel physically interruptive, socially disruptive, time-consuming and cumbersome. To address such challenges, we investigate the user interaction experience and discuss the need for more tangible and embodied interactions for effective and seamless natural privacy management in everyday UbiComp settings. We propose the Privacy Care interaction framework, which is rooted in the literature of privacy management and tangible computing. Keeping users at the center, Awareness and Control are established as the core parts of our framework. This is supported with three interrelated interaction tenets: Direct, Ready-to-Hand, and Contextual . Direct refers to intuitiveness through metaphor usage. Ready-to-Hand supports granularity, non-intrusiveness, and ad hoc management, through periphery-to-center style attention transitions. Contextual supports customization through modularity and configurability. Together, they aim to provide experience of an embodied privacy care with varied interactions that are calming and yet actively empowering. The framework provides designers of such care with a basis to refer to, to generate effective tangible tools for privacy management in everyday settings. Through five semi-structured focus groups, we explore the privacy challenges faced by a sample set of 15 older adults (aged 60+) across their cyber-physical-social spaces. The results show conformity to our framework, demonstrating the relevance of the facets of the framework to the design of privacy management tools in everyday UbiComp contexts.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W3119567370",
    "type": "article"
  },
  {
    "title": "Dynamic Scheduling Algorithm in Cyber Mimic Defense Architecture of Volunteer Computing",
    "doi": "https://doi.org/10.1145/3408291",
    "publication_date": "2021-06-09",
    "publication_year": 2021,
    "authors": "Qianmu Li; Shunmei Meng; Xiaonan Sang; Hanrui Zhang; Shoujin Wang; Ali Kashif Bashir; Keping Yu; Usman Tariq",
    "corresponding_authors": "",
    "abstract": "Volunteer computing uses computers volunteered by the general public to do distributed scientific computing. Volunteer computing is being used in high-energy physics, molecular biology, medicine, astrophysics, climate study, and other areas. These projects have attained unprecedented computing power. However, with the development of information technology, the traditional defense system cannot deal with the unknown security problems of volunteer computing . At the same time, Cyber Mimic Defense (CMD) can defend the unknown attack behavior through its three characteristics: dynamic, heterogeneous, and redundant. As an important part of the CMD, the dynamic scheduling algorithm realizes the dynamic change of the service centralized executor, which can enusre the security and reliability of CMD of volunteer computing . Aiming at the problems of passive scheduling and large scheduling granularity existing in the existing scheduling algorithms, this article first proposes a scheduling algorithm based on time threshold and task threshold and realizes the dynamic randomness of mimic defense from two different dimensions; finally, combining time threshold and random threshold, a dynamic scheduling algorithm based on multi-level queue is proposed. The experiment shows that the dynamic scheduling algorithm based on multi-level queue can take both security and reliability into account, has better dynamic heterogeneous redundancy characteristics, and can effectively prevent the transformation rule of heterogeneous executors from being mastered by attackers.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W3171382520",
    "type": "article"
  },
  {
    "title": "An Incentive-based Mechanism for Volunteer Computing Using Blockchain",
    "doi": "https://doi.org/10.1145/3419104",
    "publication_date": "2021-07-22",
    "publication_year": 2021,
    "authors": "Ismaeel Al Ridhawi; Moayad Aloqaily; Yaser Jararweh",
    "corresponding_authors": "",
    "abstract": "The rise of fast communication media both at the core and at the edge has resulted in unprecedented numbers of sophisticated and intelligent wireless IoT devices. Tactile Internet has enabled the interaction between humans and machines within their environment to achieve revolutionized solutions both on the move and in real-time. Many applications such as intelligent autonomous self-driving, smart agriculture and industrial solutions, and self-learning multimedia content filtering and sharing have become attainable through cooperative, distributed, and decentralized systems, namely, volunteer computing. This article introduces a blockchain-enabled resource sharing and service composition solution through volunteer computing. Device resource, computing, and intelligence capabilities are advertised in the environment to be made discoverable and available for sharing with the aid of blockchain technology. Incentives in the form of on-demand service availability are given to resource and service providers to ensure fair and balanced cooperative resource usage. Blockchains are formed whenever a service request is initiated with the aid of fog and mobile edge computing (MEC) devices to ensure secure communication and service delivery for the participants. Using both volunteer computing techniques and tactile internet architectures, we devise a fast and reliable service provisioning framework that relies on a reinforcement learning technique. Simulation results show that the proposed solution can achieve high reward distribution, increased number of blockchain formations, reduced delays, and balanced resource usage among participants, under the premise of high IoT device availability.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W3183708237",
    "type": "article"
  },
  {
    "title": "A Multi-graph Convolutional Network Framework for Tourist Flow Prediction",
    "doi": "https://doi.org/10.1145/3424220",
    "publication_date": "2021-07-22",
    "publication_year": 2021,
    "authors": "Wei Wang; Junyang Chen; Yushu Zhang; Zhiguo Gong; Neeraj Kumar; Wei Wei",
    "corresponding_authors": "",
    "abstract": "With the advancement of Cyber Physic Systems and Social Internet of Things, the tourism industry is facing challenges and opportunities. We can now able to collect, store, and analyze large amounts of travel data. With the help of data science and artificial intelligence, smart tourism enables tourists with great autonomy and convenience for an intelligent trip. It is of great significance to make full use of these massive data to provide better services for smart tourism. However, due to the skewed and imbalanced visiting for point of interest located at different places, it is of great significance to predict the tourist flow of each place, which can help the service providers for designing a better schedule visiting strategy in advance. Against this background, this article proposes a multi-graph convolutional network framework, named AMOUNT, for tourist flow prediction. To capture the diverse relationships among POIs, AMOUNT first constructs three subgraphs, including the geographical graph, interaction graph, and the co-relation graph. Then, a multi-graph convolution network is utilized to predict the future tourist flow. Experimental results on two real-world datasets indicate that the proposed AMOUNT model outperforms all other baseline tourist flow prediction approaches.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W3184765348",
    "type": "article"
  },
  {
    "title": "An Empirical View on Consolidation of the Web",
    "doi": "https://doi.org/10.1145/3503158",
    "publication_date": "2022-02-12",
    "publication_year": 2022,
    "authors": "Trinh Viet Doan; Roland van Rijswijk-Deij; Oliver Hohlfeld; Vaibhav Bajpai",
    "corresponding_authors": "",
    "abstract": "The majority of Web content is delivered by only a few companies that provide Content Delivery Infrastructuress (CDIss) such as Content Delivery Networkss (CDNss) and cloud hosts. Due to increasing concerns about trends of centralization, empirical studies on the extent and implications of resulting Internet consolidation are necessary. Thus, we present an empirical view on consolidation of the Web by leveraging datasets from two different measurement platforms. We first analyze Web consolidation around CDIs at the level of landing webpages, before narrowing down the analysis to a level of embedded page resources. The datasets cover 1(a) longitudinal measurements of DNS records for 166.5 M Web domains over five years, 1(b) measurements of DNS records for Alexa Top 1 M over a month and (2) measurements of page loads and renders for 4.3 M webpages, which include data on 392.3 M requested resources. We then define CDIs penetration as the ratio of CDI-hosted objects to all measured objects, which we use to quantify consolidation around CDIs. We observe that CDI penetration has close to doubled since 2015, reaching a lower bound of 15% for all .com , .net , and .org Web domains as of January 2020. Overall, we find a set of six CDIss to deliver the majority of content across all datasets, with these six CDIss being responsible for more than 80% of all 221.9 M CDI-delivered resources (56.6% of all resources in total). We find high dependencies of Web content on a small group of CDIss, in particular, for fonts, ads, and trackers, as well as JavaScript resources such as jQuery. We further observe CDIss to play important roles in rolling out IPv6 and TLS 1.3 support. Overall, these observations indicate a potential oligopoly, which brings both benefits but also risks to the future of the Web.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W4211053822",
    "type": "article"
  },
  {
    "title": "Token-Based Authorization and Authentication for Secure Internet of Vehicles Communication",
    "doi": "https://doi.org/10.1145/3491202",
    "publication_date": "2022-08-16",
    "publication_year": 2022,
    "authors": "Gunasekaran Manogaran; Bharat S. Rawal; Vijayalakshmi Saravanan; M. K. Priyan; Qin Xin; P. Mohamed Shakeel",
    "corresponding_authors": "",
    "abstract": "The Internet of Vehicles (IoV) communication platform provides seamless information exchange facilities in a dynamic mobile city environment. Heterogeneous communication is a common medium for information exchange through autonomous resources distributed and accessed using infrastructure units. Cyber-security is a primary concern in accessing autonomous information from the distributed resources due to anonymity and different types of targeted adversaries. This article proposes token-based authorization and authentication (TAA) for securing IoV communications. The proposed method relies on blockchain technology and random forest learning for authorization and key management for authentication, respectively. In this process, frequent change in tokens and key update features are restricted in a view to maximize the seamlessness in information exchange. Authentication is preceded by knowledge of the data classification without errors to prevent additional overhead. Blockchain-based authorization helps to update specific fields of the tokens to retain the communication ratio by reducing vehicle-to-vehicle losses. The performance of the proposed method is assessed using appropriate simulations for these metrics by varying vehicle density, error rate, and classification sets.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W3213203497",
    "type": "article"
  },
  {
    "title": "Deep Learning-Based Network Traffic Prediction for Secure Backbone Networks in Internet of Vehicles",
    "doi": "https://doi.org/10.1145/3433548",
    "publication_date": "2022-02-03",
    "publication_year": 2022,
    "authors": "Xiaojie Wang; Laisen Nie; Zhaolong Ning; Lei Guo; Guoyin Wang; Xinbo Gao; Neeraj Kumar",
    "corresponding_authors": "",
    "abstract": "Internet of Vehicles (IoV), as a special application of Internet of Things (IoT), has been widely used for Intelligent Transportation System (ITS), which leads to complex and heterogeneous IoV backbone networks. Network traffic prediction techniques are crucial for efficient and secure network management, such as routing algorithm, network planning, and anomaly and intrusion detection. This article studies the problem of end-to-end network traffic prediction in IoV backbone networks, and proposes a deep learning-based method. The constructed system considers the spatio-temporal feature of network traffic, and can capture the long-range dependence of network traffic. Furthermore, a threshold-based update mechanism is put forward to improve the real-time performance of the designed method by using Q-learning. The effectiveness of the proposed method is evaluated by a real network traffic dataset.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W4210623586",
    "type": "article"
  },
  {
    "title": "Measuring and characterizing end-to-end Internet service performance",
    "doi": "https://doi.org/10.1145/945846.945849",
    "publication_date": "2003-11-01",
    "publication_year": 2003,
    "authors": "Ludmila Cherkasova; Yun Fu; Wenting Tang; Amin Vahdat",
    "corresponding_authors": "",
    "abstract": "Fundamental to the design of reliable, high-performance network services is an understanding of the performance characteristics of the service as perceived by the client population as a whole. Understanding and measuring such end-to-end service performance is a challenging task. Current techniques include periodic sampling of service characteristics from strategic locations in the network and instrumenting Web pages with code that reports client-perceived latency back to a performance server. Limitations to these approaches include potentially nonrepresentative access patterns in the first case and determining the location of a performance bottleneck in the second.This paper presents EtE monitor, a novel approach to measuring Web site performance. Our system passively collects packet traces from a server site to determine service performance characteristics. We introduce a two-pass heuristic and a statistical filtering mechanism to accurately reconstruct different client page accesses and to measure performance characteristics integrated across all client accesses. Relative to existing approaches, EtE monitor offers the following benefits: i) a latency breakdown between the network and server overhead of retrieving a Web page, ii) longitudinal information for all client accesses, not just the subset probed by a third party, iii) characteristics of accesses that are aborted by clients, iv) an understanding of the performance breakdown of accesses to dynamic, multitiered services, and v) quantification of the benefits of network and browser caches on server performance. Our initial implementation and performance analysis across three different commercial Web sites confirm the utility of our approach.",
    "cited_by_count": 56,
    "openalex_id": "https://openalex.org/W2052328895",
    "type": "article"
  },
  {
    "title": "Engineering web cache consistency",
    "doi": "https://doi.org/10.1145/572326.572329",
    "publication_date": "2002-08-01",
    "publication_year": 2002,
    "authors": "Jian Yin; Lorenzo Alvisi; Mike Dahlin; Arun Iyengar",
    "corresponding_authors": "",
    "abstract": "Server-driven consistency protocols can reduce read latency and improve data freshness for a given network and server overhead, compared to the traditional consistency protocols that rely on client polling. Server-driven consistency protocols appear particularly attractive for large-scale dynamic Web workloads because dynamically generated data can change rapidly and unpredictably. However, there have been few reports on engineering server-driven consistency for such workloads. This article reports our experience in engineering server-driven consistency for a sporting and event Web site hosted by IBM, one of the most popular sites on the Internet for the duration of the event. We also examine an e-commerce site for a national retail store. Our study focuses on scalability and cachability of dynamic content. To assess scalability, we measure both the amount of state that a server needs to maintain to ensure consistency and the bursts of load in sending out invalidation messages when a popular object is modified. We find that server-driven protocols can cap the size of the server's state to a given amount without significant performance costs, and can smooth the bursts of load with minimal impact on the consistency guarantees. To improve performance, we systematically investigate several design issues for which prior research has suggested widely different solutions, including whether servers should send invalidations to idle clients. Finally, we quantify the performance impact of caching dynamic data with server-driven consistency protocols and the benefits of server-driven consistency protocols for large-scale dynamic Web services. We find that (i) caching dynamically generated data can increase cache hit rates by up to 10%, compared to the systems that do not cache dynamically generated data; and (ii) server-driven consistency protocols can increase cache hit rates by a factor of 1.5-3 for large-scale dynamic Web services, compared to client polling protocols. We have implemented a prototype of a server-driven consistency protocol based on our findings by augmenting the popular Squid cache.",
    "cited_by_count": 54,
    "openalex_id": "https://openalex.org/W2004484769",
    "type": "article"
  },
  {
    "title": "Efficient scheduling of Internet banner advertisements",
    "doi": "https://doi.org/10.1145/945846.945848",
    "publication_date": "2003-11-01",
    "publication_year": 2003,
    "authors": "Ali Amiri; Syam Menon",
    "corresponding_authors": "",
    "abstract": "Despite the slowdown in the economy, advertisement revenue remains a significant source of income for many Internet-based organizations. Banner advertisements form a critical component of this income, accounting for 40 to 50 percent of the total revenue. There are considerable gains to be realized through the efficient scheduling of banner advertisements. This problem has been observed to be intractable via traditional optimization techniques, and has received only limited attention in the literature. This paper presents a procedure to generate advertisement schedules under the most commonly used advertisement pricing scheme---the CPM model. The solution approach is based on Lagrangean decomposition and is seen to provide extremely good advertisement schedules in a relatively short period of time, taking only a few hundred seconds of elapsed time on a 450 MHz PC compared to a few thousand seconds of CPU time on a workstation that other approaches need. Additionally, this approach can be incorporated into an actual implementation with minimal alterations and hence is of particular interest.",
    "cited_by_count": 52,
    "openalex_id": "https://openalex.org/W1991134250",
    "type": "article"
  },
  {
    "title": "The platform for privacy preference as a social protocol",
    "doi": "https://doi.org/10.1145/604596.604598",
    "publication_date": "2002-11-01",
    "publication_year": 2002,
    "authors": "Harry Hochheiser",
    "corresponding_authors": "Harry Hochheiser",
    "abstract": "As a \"social protocol\" aimed at providing a technological means to address concerns over Internet privacy, the Platform for Privacy Preferences (P3P) has been controversial since its announcement in 1997. In the U.S., critics have decried P3P as an industry attempt to avoid meaningful privacy legislation, while developers have portrayed the proposal as a tool for helping users make informed decisions about the impact of their Web surfing choices. This dispute touches upon the privacy model underlying P3P, the U.S. political context regarding privacy, and the technical components of the protocol. This article presents an examination of these factors, with an eye towards distilling lessons for developers of future social protocols.",
    "cited_by_count": 51,
    "openalex_id": "https://openalex.org/W2046875106",
    "type": "article"
  },
  {
    "title": "Performance and overhead of semantic cache management",
    "doi": "https://doi.org/10.1145/1151087.1151091",
    "publication_date": "2006-08-01",
    "publication_year": 2006,
    "authors": "Björn Þór Jónsson; María Arinbjarnar; Bjarnsteinn Þórsson; Michael J. Franklin; Divesh Srivastava",
    "corresponding_authors": "",
    "abstract": "The emergence of query-based online data services and e-commerce applications has prompted much recent research on data caching. This article studies semantic caching , a caching architecture for such applications, that caches the results of selection queries. The primary contribution of this article is to revisit the performance and overhead of semantic caching using a modern database server and modern hardware. Initially, the performance study focuses on simple workloads and demonstrates several benefits of semantic caching, including low overhead, insensitivity to the physical layout of the database, reduced network traffic, and the ability to answer some queries without contacting the server. With moderately complex workloads, careful coding of remainder queries is required to maintain efficient query processing at the server. Using very complex workloads, we demonstrate that semantic caching works well in a range of applications, especially in network-constrained environments.",
    "cited_by_count": 47,
    "openalex_id": "https://openalex.org/W2038298228",
    "type": "article"
  },
  {
    "title": "Answering queries using views",
    "doi": "https://doi.org/10.1145/1013202.1013204",
    "publication_date": "2004-08-01",
    "publication_year": 2004,
    "authors": "François Goasdoué; Marie-Christine Rousset",
    "corresponding_authors": "",
    "abstract": "In this article, we investigate a first step towards the long-term vision of the Semantic Web by studying the problem of answering queries posed through a mediated ontology to multiple information sources whose content is described as views over the ontology relations. The contributions of this paper are twofold. We first offer a uniform logical setting which allows us to encompass and to relate the existing work on answering and rewriting queries using views. In particular, we make clearer the connection between the problem of rewriting queries using views and the problem of answering queries using extensions of views. Then we focus on an instance of the problem of rewriting conjunctive queries using views through an ontology expressed in a description logic, for which we exhibit a complete algorithm.",
    "cited_by_count": 46,
    "openalex_id": "https://openalex.org/W2154023463",
    "type": "article"
  },
  {
    "title": "Defending against an Internet-based attack on the physical world",
    "doi": "https://doi.org/10.1145/1013202.1013203",
    "publication_date": "2004-08-01",
    "publication_year": 2004,
    "authors": "Simon Byers; Aviel D. Rubin; David Kormann",
    "corresponding_authors": "",
    "abstract": "We discuss the dangers that scalable Internet functionality may present to the real world, focusing upon an attack that is simple, yet can have great impact, which we believe may occur quite soon. We offer and critique various solutions to this class of attack and hope to provide a warning to the Internet community of what is currently possible. The attack is, to some degree, a consequence of the availability of private information on the Web, and the increase in the amount of personal information that users must reveal to obtain Web services.",
    "cited_by_count": 45,
    "openalex_id": "https://openalex.org/W2138574741",
    "type": "article"
  },
  {
    "title": "Defeating DDoS attacks by fixing the incentive chain",
    "doi": "https://doi.org/10.1145/1189740.1189745",
    "publication_date": "2007-02-01",
    "publication_year": 2007,
    "authors": "Yun Huang; Xianjun Geng; Andrew B. Whinston",
    "corresponding_authors": "",
    "abstract": "Cooperative technological solutions for Distributed Denial-of-Service (DDoS) attacks are already available, yet organizations in the best position to implement them lack incentive to do so, and the victims of DDoS attacks cannot find effective methods to motivate them. In this article we discuss two components of the technological solutions to DDoS attacks: cooperative filtering and cooperative traffic smoothing by caching. We then analyze the broken incentive chain in each of these technological solutions. As a remedy, we propose usage-based pricing and Capacity Provision Networks, which enable victims to disseminate enough incentive along attack paths to stimulate cooperation against DDoS attacks.",
    "cited_by_count": 41,
    "openalex_id": "https://openalex.org/W2071231410",
    "type": "article"
  },
  {
    "title": "Personalizing access to learning networks",
    "doi": "https://doi.org/10.1145/1323651.1323654",
    "publication_date": "2008-02-01",
    "publication_year": 2008,
    "authors": "Peter Dolog; Bernd Simon; Wolfgang Nejdl; Tomaž Klobučar",
    "corresponding_authors": "",
    "abstract": "In this article, we describe a Smart Space for Learning™ (SS4L) framework and infrastructure that enables personalized access to distributed heterogeneous knowledge repositories. Helping a learner to choose an appropriate learning resource or activity is a key problem which we address in this framework, enabling personalized access to federated learning repositories with a vast number of learning offers. Our infrastructure includes personalization strategies both at the query and the query results level. Query rewriting is based on learning and language preferences; rule-based and ranking-based personalization improves these results further. Rule-based reasoning techniques are supported by formal ontologies we have developed based on standard information models for learning domains; ranking-based recommendations are supported through ensuring minimal sets of predicates appearing in query results. Our evaluation studies show that the implemented solution enables learners to find relevant learning resources in a distributed environment and through goal-based personalization improves relevancy of results.",
    "cited_by_count": 40,
    "openalex_id": "https://openalex.org/W1999570522",
    "type": "article"
  },
  {
    "title": "Introduction to intelligent techniques for Web personalization",
    "doi": "https://doi.org/10.1145/1278366.1278367",
    "publication_date": "2007-10-01",
    "publication_year": 2007,
    "authors": "Sarabjot Singh Anand; Bamshad Mobasher",
    "corresponding_authors": "",
    "abstract": "introduction Introduction to intelligent techniques for Web personalization Authors: Sarabjot Singh Anand University of Warwick University of WarwickView Profile , Bamshad Mobasher DePaul University DePaul UniversityView Profile Authors Info & Claims ACM Transactions on Internet TechnologyVolume 7Issue 4pp 18–eshttps://doi.org/10.1145/1278366.1278367Published:01 October 2007Publication History 22citation1,347DownloadsMetricsTotal Citations22Total Downloads1,347Last 12 Months8Last 6 weeks2 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteGet Access",
    "cited_by_count": 38,
    "openalex_id": "https://openalex.org/W2005394158",
    "type": "article"
  },
  {
    "title": "Investigating Users’ Perspectives of Web Single Sign-On",
    "doi": "https://doi.org/10.1145/2532639",
    "publication_date": "2013-11-01",
    "publication_year": 2013,
    "authors": "San-Tsai Sun; E Pospísil; Ildar Muslukhov; Nuray Dindar; Kirstie Hawkey; Konstantin Beznosov",
    "corresponding_authors": "",
    "abstract": "OpenID and OAuth are open and simple Web SSO protocols that have been adopted by major service providers, and millions of supporting Web sites. However, the average user’s perception of Web SSO is still poorly understood. Through several user studies, this work investigates users’ perceptions and concerns when using Web SSO for authentication. We found that our participants had several misconceptions and concerns that impeded their adoption. This ranged from their inadequate mental models of Web SSO, to their concerns about personal data exposure, and a reduction in perceived Web SSO value due to the employment of password management practices. Informed by our findings, we offer a Web SSO technology acceptance model, and suggest design improvements.",
    "cited_by_count": 28,
    "openalex_id": "https://openalex.org/W2086147103",
    "type": "article"
  },
  {
    "title": "The Relevance of Categories for Trusting Information Sources",
    "doi": "https://doi.org/10.1145/2803175",
    "publication_date": "2015-12-07",
    "publication_year": 2015,
    "authors": "Rino Falcone; Alessandro Sapienza; Cristiano Castelfranchi",
    "corresponding_authors": "",
    "abstract": "In this article, we are interested in the fact that relevance and trustworthiness of information acquired by an agent X from a source F strictly depends and derives from X's trust in F with respect to the kind of information. In particular, we are interested in analyzing the relevance of F's category as indicator for its trustworthiness with respect to the specific informative goals of X. In this article, we analyze an interactive cognitive model for searching information in a world in which each agent can be considered as belonging to a specific agent's category. We also consider variability within the canonical categorical behavior and consequent influence on the trustworthiness of provided information. The introduced interactive cognitive model also allows evaluation of the trustworthiness of a source both on the basis of its category and on past direct experience with it, thus selecting the more adequate source with respect to the informative goals to achieve. We present a computational approach based on fuzzy sets and some selected simulation scenarios together with the discussion of their more interesting results.",
    "cited_by_count": 28,
    "openalex_id": "https://openalex.org/W2207814383",
    "type": "article"
  },
  {
    "title": "When Amazon Meets Google",
    "doi": "https://doi.org/10.1145/2492690",
    "publication_date": "2013-07-01",
    "publication_year": 2013,
    "authors": "Meng Wang; Guangda Li; Zheng Lu; Yue Gao; Tat‐Seng Chua",
    "corresponding_authors": "",
    "abstract": "Product visualization is able to help users easily get knowledge about the visual appearance of a product. It is useful in many application and commercialization scenarios. However, the existing product image search on e-commerce Web sites or general search engines usually get insufficient search results or return images that are redundant and not relevant enough. In this article, we present a novel product visualization approach that automatically collects a set of diverse and relevant product images by exploring multiple Web sources. Our approach simultaneously leverages Amazon and Google image search engines, which represent domain-specific knowledge resource and general Web information collection, respectively. We propose a conditional clustering approach that is formulated as an affinity propagation problem regarding the Amazon examples as information prior. The ranking information of Google image search results is also explored. In this way, a set of exemplars can be found from the Google search results and they are provided together with the Amazon example images for product visualization. Experiments demonstrate the feasibility and effectiveness of our approach.",
    "cited_by_count": 27,
    "openalex_id": "https://openalex.org/W2124044528",
    "type": "article"
  },
  {
    "title": "Dynamic and Efficient Private Keyword Search over Inverted Index--Based Encrypted Data",
    "doi": "https://doi.org/10.1145/2940328",
    "publication_date": "2016-08-12",
    "publication_year": 2016,
    "authors": "Rui Zhang; Rui Xue; Ting Yu; Ling Liu",
    "corresponding_authors": "",
    "abstract": "Querying over encrypted data is gaining increasing popularity in cloud-based data hosting services. Security and efficiency are recognized as two important and yet conflicting requirements for querying over encrypted data. In this article, we propose an efficient private keyword search (EPKS) scheme that supports binary search and extend it to dynamic settings (called DEPKS ) for inverted index--based encrypted data. First, we describe our approaches of constructing a searchable symmetric encryption (SSE) scheme that supports binary search. Second, we present a novel framework for EPKS and provide its formal security definitions in terms of plaintext privacy and predicate privacy by modifying Shen et al.’s security notions [Shen et al. 2009]. Third, built on the proposed framework, we design an EPKS scheme whose complexity is logarithmic in the number of keywords. The scheme is based on the groups of prime order and enjoys strong notions of security, namely statistical plaintext privacy and statistical predicate privacy. Fourth, we extend the EPKS scheme to support dynamic keyword and document updates. The extended scheme not only maintains the properties of logarithmic-time search efficiency and plaintext privacy and predicate privacy but also has fewer rounds of communications for updates compared to existing dynamic search encryption schemes. We experimentally evaluate the proposed EPKS and DEPKS schemes and show that they are significantly more efficient in terms of both keyword search complexity and communication complexity than existing randomized SSE schemes.",
    "cited_by_count": 27,
    "openalex_id": "https://openalex.org/W2514175126",
    "type": "article"
  },
  {
    "title": "A Commitment-Based Infrastructure for Programming Socio-Technical Systems",
    "doi": "https://doi.org/10.1145/2677206",
    "publication_date": "2014-12-17",
    "publication_year": 2014,
    "authors": "Matteo Baldoni; Cristina Baroglio; Federico Capuzzimati",
    "corresponding_authors": "",
    "abstract": "Socio-Technical Systems demand an evolution of computing into social computing, with a transition from an individualistic to a societal view. As such, they seem particularly suitable to realize multiparty, cross-organizational systems. Multi-Agent Systems are a natural candidate to realize Socio-Technical Systems. However, while Socio-Technical Systems envisage an explicit layer that contains the regulations that all parties must respect in their interaction, and thus preserve the agents' autonomy, current frameworks and platforms require to hard-code the coordination requirements inside the agents. We propose to explicitly represent the missing layer of Socio-Technical Systems in terms of social relationships among the involved parties, that is, in terms of a set of normatively defined relationships among two or more parties, subject to social control by monitoring the observable behaviour. In our proposal, social relationships are resources, available to agents, who use them in their practical reasoning. Both agents and social relationships are first-class entities of the model. The work also describes 2COMM4JADE, a framework that realizes the proposal by extending the well-known JADE and CArtAgO. The impact of the approach on programming is explained both conceptually and with the help of an example.",
    "cited_by_count": 26,
    "openalex_id": "https://openalex.org/W2076749338",
    "type": "article"
  },
  {
    "title": "Detecting Influencers in Multiple Online Genres",
    "doi": "https://doi.org/10.1145/3014164",
    "publication_date": "2017-03-23",
    "publication_year": 2017,
    "authors": "Sara Rosenthal; Kathleen McKeown",
    "corresponding_authors": "",
    "abstract": "Social media has become very popular and mainstream, leading to an abundance of content. This wealth of content contains many interactions and conversations that can be analyzed for a variety of information. One such type of information is analyzing the roles people take in a conversation. Detecting influencers, one such role, can be useful for political campaigning, successful advertisement strategies, and detecting terrorist leaders. We explore influence in discussion forums, weblogs, and micro-blogs through the development of learned language analysis components to recognize known indicators of influence. Our components are author traits, agreement, claims, argumentation, persuasion, credibility, and certain dialog patterns. Each of these components is motivated by social science through Robert Cialdini’s “Weapons of Influence” [Cialdini 2007]. We classify influencers across five online genres and analyze which features are most indicative of influencers in each genre. First, we describe a rich suite of features that were generated using each of the system components. Then, we describe our experiments and results, including using domain adaptation to exploit the data from multiple online genres.",
    "cited_by_count": 26,
    "openalex_id": "https://openalex.org/W2600654634",
    "type": "article"
  },
  {
    "title": "An Efficient Angle-based Universum Least Squares Twin Support Vector Machine for Classification",
    "doi": "https://doi.org/10.1145/3387131",
    "publication_date": "2020-07-07",
    "publication_year": 2020,
    "authors": "Bharat Richhariya; M. Tanveer",
    "corresponding_authors": "",
    "abstract": "Universum-based support vector machine incorporates prior information about the distribution of data in training of the classifier. This leads to better generalization performance but with increased computation cost. Various twin hyperplane-based models are proposed to reduce the computation cost of universum-based algorithms. In this work, we present an efficient angle-based universum least squares twin support vector machine (AULSTSVM) for classification. This is a novel approach of incorporating universum in the formulation of least squares-based twin SVM model. First, the proposed AULSTSVM constructs a universum hyperplane, which is proximal to universum data points. Then, the classifying hyperplane is constructed by minimizing the angle with the universum hyperplane. This gives prior information about data distribution to the classifier. In addition to the quadratic loss, we introduce linear loss in the optimization problem of the proposed AULSTSVM, which leads to lesser computation cost of the model. Numerical experiments are performed on several benchmark synthetic, real-world, and large-scale datasets. The results show that proposed AULSTSVM performs better than existing algorithms w.r.t. generalization performance as well as computation time. Moreover, an application to Alzheimer’s disease is presented, where AULSTSVM obtains accuracy of 95% for classification of healthy and Alzheimers subjects. The results imply that the proposed AULSTSVM is a better alternative for classification of large-scale datasets and biomedical applications.",
    "cited_by_count": 25,
    "openalex_id": "https://openalex.org/W3041326615",
    "type": "article"
  },
  {
    "title": "RTChain",
    "doi": "https://doi.org/10.1145/3430502",
    "publication_date": "2020-12-17",
    "publication_year": 2020,
    "authors": "You Sun; Rui Xue; Rui Zhang; Qianqian Su; Sheng Gao",
    "corresponding_authors": "",
    "abstract": "Blockchain technology, whose most successful application is Bitcoin, enables non-repudiation and non-tamperable online transactions without the participation of a trusted central party. As a global ledger, the blockchain achieves the consistency of replica stored on each node through a consensus mechanism. A well-designed consensus mechanism, on one hand, needs to be efficient to meet the high frequency of online transactions. For example, the existing electronic payment systems can handle over 50,000 transactions per second (TPS), while Bitcoin can only handle an average of about 3TPS. On the other hand, it needs to have good security and high fault tolerance; that is, in the case when some nodes are captured by adversaries, the network can still operate normally. In this article, we establish a reputation system, called RTChain, to be integrated into the e-commerce blockchain to achieve a distributed consensus and transaction incentives. The proposed scheme has the following advantages. First, an incentive mechanism is used to influence the consensus behavior of nodes and the transaction behavior of users, which in turn influence the reputation scores of both nodes and users. That is, when a node correctly processes a transaction, it will receive the corresponding reputation value as a reward, and the reputation value will be reduced as punishment not only when the node is dishonest and violates the consensus agreement but also the transaction is not completed as required. Just like electronic transactions in the real world, the higher the reputation of the user, the more likely it is to be selected as the transaction partner. A user with a low reputation will be gradually eliminated in our system because it is difficult to complete the transaction. Second, RTChain uses a verifiable random function to generate the leader in each round, which guarantees fairness for all participants and, unlike PoW, does not consume a large amount of computing resources. Then our consensus mechanism selects the nodes with high reputation scores to reduce the number of nodes participating in the consensus, thus improving the consensus efficiency, so that RTChain’s throughput can reach 4,000TPS. Third, we built a reputation chain to implement the distributed storage and management of reputation. Finally, our consensus mechanism is secure against existing attacks, such as flash attacks, selfish mining attacks, eclipse attacks, and double spending attacks, and allows nodes that participate in the consensus to fail, as long as the reputation of the failure node does not exceed one-third of the total reputation. We build a prototype of RTChain, and the experimental results show that RTChain is promising and deployable for e-commerce blockchains.",
    "cited_by_count": 25,
    "openalex_id": "https://openalex.org/W3111458001",
    "type": "article"
  },
  {
    "title": "Cloud, Fog, or Mist in IoT? That Is the Question",
    "doi": "https://doi.org/10.1145/3309709",
    "publication_date": "2019-03-28",
    "publication_year": 2019,
    "authors": "Danilo Vasconcelos; Rossana M. C. Andrade; Valdenir Severino; José Neuman de Souza",
    "corresponding_authors": "",
    "abstract": "Internet of Things (IoT) has been commercially explored as Platforms as a Services (PaaS). The standard solution for this kind of service is to combine the Cloud computing infrastructure with IoT software, services, and protocols also known as CoT (Cloud of Things). However, the use of CoT in latency-sensitive applications has been shown to be unfeasible due to the inherent latency of cloud computing services. One proposal to solve this problem is the use of the computational resources available at the edge of the network, which is called Fog computing. Fog computing solves the problem of latency but adds complexity to the use of these resources due to the dynamism and heterogeneity of the IoT. An even more accentuated form of fog computing is Mist computing, where the use of the computational resources is limited to the close neighborhood of the client device. The decision of what computing infrastructure (Fog, Mist, or Cloud computing) is the best to provide computational resources is not always simple, especially in cases where latency requirements should be met by CoT. This work proposes an algorithm for selecting the best physical infrastructure to use the computational resource (Fog, Mist, or Cloud computing) based on cost, bandwidth, and latency criteria defined by the client device, resource availability, and topology of the network. The article also introduces the concept of feasible Fog that limits the growth of device search time in the neighborhood of the client device. Simulation results suggest the algorithm’s choice adequately attends the client’s device requirements and that the proposed method can be used in IoT environment located on the edge of the network.",
    "cited_by_count": 24,
    "openalex_id": "https://openalex.org/W2934330215",
    "type": "article"
  },
  {
    "title": "DuroNet",
    "doi": "https://doi.org/10.1145/3432249",
    "publication_date": "2021-01-05",
    "publication_year": 2021,
    "authors": "Kaixi Hu; Lin Li; Jianquan Liu; Daniel Sun",
    "corresponding_authors": "",
    "abstract": "Urban crime is an ongoing problem in metropolitan development and attracts general concern from the international community. As an effective means of defending urban safety, crime prediction plays a crucial role in patrol force allocation and public safety. However, urban crime data is a macro result of crime patterns overlapped by various irrelevant factors that cause inhomogeneous noises—local outliers and irregular waves. These noises might obstruct the learning process of crime prediction models and result in a deviation of performance. To tackle the problem, we propose a novel paradigm of &lt;underline&gt;Du&lt;/underline&gt;al-&lt;underline&gt;ro&lt;/underline&gt;bust Enhanced Spatial-temporal Learning &lt;underline&gt;Net&lt;/underline&gt;work (DuroNet), an encoder-decoder architecture that possesses an adaptive robustness for reducing the effect of outliers and waves. The robustness is mainly reflected on two aspects. One is a locality enhanced module that employs local temporal context information to smooth the deviation of outliers and dynamic spatial information to assist in understanding normal points. The other is a self-attention-based pattern representation module to weaken the effect of irregular waves by learning attentive weights. Finally, extensive experiments are conducted on two real-world crime datasets before and after adding Gaussian noises. The results demonstrate the superior performance of our DuroNet over the state-of-the-art methods.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W3119224633",
    "type": "article"
  },
  {
    "title": "IP Geolocation through Reverse DNS",
    "doi": "https://doi.org/10.1145/3457611",
    "publication_date": "2021-10-15",
    "publication_year": 2021,
    "authors": "Ovidiu Dan; Vaibhav Parikh; Brian D. Davison",
    "corresponding_authors": "",
    "abstract": "IP Geolocation databases are widely used in online services to map end-user IP addresses to their geographical location. However, they use proprietary geolocation methods, and in some cases they have poor accuracy. We propose a systematic approach to use reverse DNS hostnames for geolocating IP addresses, with a focus on end-user IP addresses as opposed to router IPs. Our method is designed to be combined with other geolocation data sources. We cast the task as a machine learning problem where, for a given hostname, we first generate a list of potential location candidates, and then we classify each hostname and candidate pair using a binary classifier to determine which location candidates are plausible. Finally, we rank the remaining candidates by confidence (class probability) and break ties by population count. We evaluate our approach against three state-of-the-art academic baselines and two state-of-the-art commercial IP geolocation databases. We show that our work significantly outperforms the academic baselines and is complementary and competitive with commercial databases. To aid reproducibility, we open source our entire approach and make it available to the academic community.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W3205909056",
    "type": "article"
  },
  {
    "title": "A COVID-19 Detection Algorithm Using Deep Features and Discrete Social Learning Particle Swarm Optimization for Edge Computing Devices",
    "doi": "https://doi.org/10.1145/3453170",
    "publication_date": "2021-12-30",
    "publication_year": 2021,
    "authors": "Chaonan Shen; Kai Zhang; Jinshan Tang",
    "corresponding_authors": "",
    "abstract": "COVID-19 has been spread around the world and has caused a huge number of deaths. Early detection of this disease is the most efficient way to prevent its rapid spread. Due to the development of internet technology and edge intelligence, developing an early detection system for COVID-19 in the medical environment of the Internet of Things (IoT) can effectively alleviate the spread of the disease. In this paper, a detection algorithm is developed, which can detect COVID-19 effectively by utilizing the features from Chest X-ray (CXR) images. First, a pre-trained model (ResNet18) is adopted for feature extraction. Then, a discrete social learning particle swarm optimization algorithm (DSLPSO) is proposed for feature selection. By filtering redundant and irrelevant features, the dimensionality of the feature vector is reduced. Finally, the images are classified by a Support Vector Machine (SVM) for COVID-19 detection. Experimental results show that the proposed algorithm can achieve competitive performance with fewer features, which is suitable for edge computing devices with lower computation power.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W4200229613",
    "type": "article"
  },
  {
    "title": "A Language-independent Network to Analyze the Impact of COVID-19 on the World via Sentiment Analysis",
    "doi": "https://doi.org/10.1145/3475867",
    "publication_date": "2021-09-14",
    "publication_year": 2021,
    "authors": "Ashima Yadav; Dinesh Kumar Vishwakarma",
    "corresponding_authors": "",
    "abstract": "Towards the end of 2019, Wuhan experienced an outbreak of novel coronavirus, which soon spread worldwide, resulting in a deadly pandemic that infected millions of people around the globe. The public health agencies followed many strategies to counter the fatal virus. However, the virus severely affected the lives of the people. In this paper, we study the sentiments of people from the top five worst affected countries by the virus, namely the USA, Brazil, India, Russia, and South Africa. We propose a deep language-independent Multilevel Attention-based Conv-BiGRU network (MACBiG-Net) , which includes embedding layer, word-level encoded attention, and sentence-level encoded attention mechanisms to extract the positive, negative, and neutral sentiments. The network captures the subtle cues in a document by focusing on the local characteristics of text along with the past and future context information for the sentiment classification. We further develop a COVID-19 Sentiment Dataset by crawling the tweets from Twitter and applying topic modeling to extract the hidden thematic structure of the document. The classification results demonstrate that the proposed model achieves an accuracy of 85%, which is higher than other well-known algorithms for sentiment classification. The findings show that the topics which evoked positive sentiments were related to frontline workers, entertainment, motivation, and spending quality time with family. The negative sentiments were related to socio-economic factors like racial injustice, unemployment rates, fake news, and deaths. Finally, this study provides feedback to the government and health professionals to handle future outbreaks and highlight future research directions for scientists and researchers.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W3200879986",
    "type": "article"
  },
  {
    "title": "Task Offloading with Task Classification and Offloading Nodes Selection for MEC-Enabled IoV",
    "doi": "https://doi.org/10.1145/3475871",
    "publication_date": "2021-10-22",
    "publication_year": 2021,
    "authors": "Rui Zhang; Libing Wu; Shuqin Cao; Xinrong Hu; Shan Xue; Dan Wu; Qingan Li",
    "corresponding_authors": "",
    "abstract": "The Mobile Edge Computing (MEC)-based task offloading in the Internet of Vehicles (IoV) scenario, which transfers computational tasks to mobile edge nodes and fixed edge nodes with available computing resources, has attracted interest in recent years. The MEC-based task offloading can achieve low latency and low operational cost under the tasks delay constraints. However, most existing research generally focuses on how to divide and migrate these tasks to the other devices. This research ignores delay constraints and offloading node selection for different tasks. In this article, we design the MEC-enabled IoV architecture, in which all vehicles and MEC servers act as offloading nodes. Mobile offloading nodes (i.e., vehicles) and fixed offloading nodes (i.e., MEC servers) provide low latency offloading services cooperatively through roadside units. Then we propose the task offloading scheme that considers task classification and offloading nodes selection (TO-TCONS). Our goal is to minimize the total execution time of tasks. In TO-TCONS Scheme, we divide the task offloading into the same region offloading mode and cross-region offloading mode, which is based on the delay constraints of tasks and the travel time of the target vehicle. Moreover, we propose the mobile offloading nodes selection strategy to select offloading nodes for each task, which evaluates offloading candidates for each task based on computing resources and transmission rates. Simulation results demonstrate that TO-TCONS Scheme is indeed capable of reducing total latency of tasks execution under the delay constraints in MEC-enabled IoV.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W3209471084",
    "type": "article"
  },
  {
    "title": "Securing Low-Power Blockchain-enabled IoT Devices against Energy Depletion Attack",
    "doi": "https://doi.org/10.1145/3511903",
    "publication_date": "2022-03-28",
    "publication_year": 2022,
    "authors": "Amjad Alsirhani; Muhammad Ali Khan; Abdullah Alomari; Sauda Maryam; Aiman Younas; Muddesar Iqbal; Muhammad Hameed Siqqidi; Amjad Ali",
    "corresponding_authors": "",
    "abstract": "Blockchain-enabled Internet of Things (IoT) envisions a world with rapid development and implementations to change our everyday lives based on smart devices. These devices are attached to the internet that can communicate with each other without human interference. A well-known wireless network in blockchain-enabled IoT frameworks is the Low Power and Lossy Network (LLN) that uses a novel protocol known as Routing protocol for low power and lossy networks (RPL) to provide effective and energy-efficient routing. LLNs that run on RPL are inherently prone to multiple Denial of Service (DoS) attacks due to the low cost, shared medium, and resource-constrained nature of blockchain-enabled IoT devices. A Spam DODAG Information Solicitation (DIS) attack is one of the novel attacks that drains the energy source of legitimate nodes and ends up causing the legitimate nodes to suffer from DoS. To address this problem, a mitigation scheme named DIS Spam Attack Mitigation (DISAM) is proposed. The proposed scheme effectively mitigates the effects of the Spam DIS attack on the network’s performance. The experimental results show that DISAM detects and mitigates the attack quickly and efficiently.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W4220770429",
    "type": "article"
  },
  {
    "title": "Identity-Based Public Auditing for Cloud Storage of Internet-of-Vehicles Data",
    "doi": "https://doi.org/10.1145/3433543",
    "publication_date": "2022-03-09",
    "publication_year": 2022,
    "authors": "Hui Tian; Fang Peng; Hanyu Quan; Chin‐Chen Chang",
    "corresponding_authors": "",
    "abstract": "The Internet of Vehicles (IoV) , with the help of cloud computing, can provide rich and powerful application services for vehicles and drivers by sharing and analysing various IoV data. However, how to ensure the integrity of IoV data with multiple sources and diversity outsourced in the cloud is still an open challenge. To address this concern, this paper first presents an identity-based public auditing scheme for cloud storage of IoV data, which can fully achieve the essential function and security requirements, such as classified auditing, multi-source auditing and privacy protection. Particularly, we design a new authenticated data structure, called data mapping table, to track the distribution of each type of IoV data to ensure fine and rapid audits. Moreover, our scheme can reduce the overheads for both the key management and the generation of block tags. We formally prove the security of the presented scheme and evaluate its performance by comprehensive comparisons with the state-of-the-art schemes designed for traditional scenarios. The theoretical analyses and experimental results demonstrate that our scheme can securely and efficiently realize public auditing for IoV data, and outperforms the previous ones in both the computation and communication overheads in most cases.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W4220712077",
    "type": "article"
  },
  {
    "title": "DECENT: A Decentralized Configurator for Controlling Elasticity in Dynamic Edge Networks",
    "doi": "https://doi.org/10.1145/3530692",
    "publication_date": "2022-04-13",
    "publication_year": 2022,
    "authors": "Ilir Murturi; Schahram Dustdar",
    "corresponding_authors": "",
    "abstract": "Recent advancements in distributed systems have enabled deploying low-latency and highly resilient edge applications close to the IoT domain at the edge of the network. The broad range of edge application requirements combined with heterogeneous, resource-constrained, and dynamic edge networks make it particularly challenging to configure and deploy them. Besides that, missing elastic capabilities on the edge makes it difficult to operate such applications under dynamic workloads. To this end, this article proposes a lightweight, self-adaptive, and decentralized mechanism (DECENT) for (1) deploying edge applications on edge resources and on premises of Edge-Cloud infrastructure and (2) controlling elasticity requirements. DECENT enables developers to characterize their edge applications by specifying elasticity requirements, which are automatically captured, interpreted, and enforced by our decentralized elasticity interpreters. In response to dynamic workloads, edge applications automatically adapt in compliance with their elasticity requirements. We discuss the architecture, processes of the approach, and the experiment conducted on a real-world testbed to validate its feasibility on low-powered edge devices. Furthermore, we show performance and adaptation aspects through an edge safety application and its evolution in elasticity space (i.e., cost, resource, and quality).",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W4223968117",
    "type": "article"
  },
  {
    "title": "Personalized Individual Semantics Learning to Support a Large-Scale Linguistic Consensus Process",
    "doi": "https://doi.org/10.1145/3533432",
    "publication_date": "2022-05-06",
    "publication_year": 2022,
    "authors": "Yucheng Dong; Qin Ran; Xiangrui Chao; Cong‐Cong Li; Shui Yu",
    "corresponding_authors": "",
    "abstract": "When making decisions, individuals often express their preferences linguistically. The computing with words methodology is a key basis for supporting linguistic decision making, and the words in that methodology may mean different things to different individuals. Thus, in this article, we propose a continual personalized individual semantics learning model to support a consensus-reaching process in large-scale linguistic group decision making. Specifically, we first derive personalized numerical scales from the data of linguistic preference relations. We then perform a clustering ensemble method to divide large-scale group and conduct consensus management. Finally, we present a case study of intelligent route optimization in shared mobility to illustrate the usability of our proposed model. We also demonstrate its effectiveness and feasibility through a comparative analysis.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W4229027091",
    "type": "article"
  },
  {
    "title": "On balancing the load in a clustered web farm",
    "doi": "https://doi.org/10.1145/502152.502155",
    "publication_date": "2001-11-01",
    "publication_year": 2001,
    "authors": "Joel L. Wolf; Philip S. Yu",
    "corresponding_authors": "",
    "abstract": "In this article we propose a novel, yet practical, scheme which attempts to optimally balance the load on the servers of a clustered Web farm. The goal in solving this performance problem is to achieve minimal average response time for customer requests, and thus ultimately achieve maximal customer throughput. The article decouples the overall problem into two related but distinct mathematical subproblems, one static and one dynamic. We believe this natural decoupling is one of the major contributions of our article. The static component algorithm determines good assignments of sites to potentially overlapping servers. These cluster assignments, which, due to overhead, cannot be changed too frequently, have a major effect on achievable response time. Additionally, these assignments must be palatable to the sites themselves. The dynamic component algorithm is designed to handle real-time load balancing by routing customer requests from the network dispatcher to the servers. This algorithm must react to fluctuating customer request load while respecting the assignments of sites to servers determined by the static component. The static and dynamic components both employ in various contexts the same so-called goal setting algorithm. This algorithm determines the theoretically optimal load on each server, given hypothetical cluster assignments and site activity. We demonstrate the effectiveness of the overall load-balancing scheme via a number of simulation experiments.",
    "cited_by_count": 43,
    "openalex_id": "https://openalex.org/W1996359191",
    "type": "article"
  },
  {
    "title": "Architecture and performance of server-directed transcoding",
    "doi": "https://doi.org/10.1145/945846.945850",
    "publication_date": "2003-11-01",
    "publication_year": 2003,
    "authors": "Björn Knutsson; Honghui Lu; Jeffrey C. Mogul; Bryan Hopkins",
    "corresponding_authors": "",
    "abstract": "Proxy-based transcoding adapts Web content to be a better match for client capabilities (such as screen size and color depth) and last-hop bandwidths. Traditional transcoding breaks the end-to-end model of the Web, because the proxy does not know the semantics of the content. Server-directed transcoding preserves end-to-end semantics while supporting aggressive content transformations.We show how server-directed transcoding can be integrated into the HTTP protocol and into the implementation of a proxy. We discuss several useful transformations for image content, and present measurements of the performance impacts. Our results demonstrate that server-directed transcoding is a natural extension to HTTP, can be implemented without great complexity, and can provide good performance when carefully implemented.",
    "cited_by_count": 43,
    "openalex_id": "https://openalex.org/W2051063627",
    "type": "article"
  },
  {
    "title": "SouthamptonTAC",
    "doi": "https://doi.org/10.1145/857166.857168",
    "publication_date": "2003-08-01",
    "publication_year": 2003,
    "authors": "Minghua He; Nicholas R. Jennings",
    "corresponding_authors": "",
    "abstract": "Software agents are increasingly being used to represent humans in on-line auctions. Such agents have the advantages of being able to systematically monitor a wide variety of auctions and then make rapid decisions about what bids to place in what auctions. They can do this continuously and repetitively without losing concentration. Moreover, in complex multiple auction settings, agents may need to modify their behavior in one auction depending on what is happening in another. To provide a means of evaluating and comparing (benchmarking) research methods in this area, the Trading Agent Competition (TAC) was established. This competition involves a number of agents bidding against one another in a number of related auctions (operating different protocols) to purchase travel packages for customers. Against this background, this artcle describes the design, implementation and evaluation of our adaptive autonomous trading agent, SouthamptonTAC, one of the most successful participants in TAC 2002.",
    "cited_by_count": 43,
    "openalex_id": "https://openalex.org/W2156370517",
    "type": "article"
  },
  {
    "title": "PageCluster",
    "doi": "https://doi.org/10.1145/990301.990305",
    "publication_date": "2004-05-01",
    "publication_year": 2004,
    "authors": "Jianhan Zhu; Jun Hong; John G. Hughes",
    "corresponding_authors": "",
    "abstract": "User traversals on hyperlinks between Web pages can reveal semantic relationships between these pages. We use user traversals on hyperlinks as weights to measure semantic relationships between Web pages. On the basis of these weights, we propose a novel method to put Web pages on a Web site onto different conceptual levels in a link hierarchy. We develop a clustering algorithm called PageCluster, which clusters conceptually-related pages on each conceptual level of the link hierarchy based on their in-link and out-link similarities. Clusters are then used to construct a conceptual link hierarchy, which is visualized in a prototype called Online Navigation Explorer (ONE) for adaptive Web site navigation. Our experiments show that our method can put Web pages onto conceptual levels of a link hierarchy more accurately than both the breadth-first search method and the shortest-weighted-path method, and PageCluster can cluster conceptually-related pages more accurately than the bibliographic analysis method. Our user study also shows that the conceptual link hierarchy visualized in ONE can help users find information more effectively and efficiently as the task of finding information becomes less specific and involves more Web pages on multiple conceptual levels.",
    "cited_by_count": 41,
    "openalex_id": "https://openalex.org/W1974181006",
    "type": "article"
  },
  {
    "title": "Requirements for scalable access control and security management architectures",
    "doi": "https://doi.org/10.1145/1239971.1239972",
    "publication_date": "2007-05-01",
    "publication_year": 2007,
    "authors": "Angelos D. Keromytis; Jonathan M. Smith",
    "corresponding_authors": "",
    "abstract": "Maximizing local autonomy by delegating functionality to end nodes when possible (the end-to-end design principle) has led to a scalable Internet. Scalability and the capacity for distributed control have unfortunately not extended well to resource access-control policies and mechanisms. Yet management of security is becoming an increasingly challenging problem in no small part due to scaling up of measures such as number of users, protocols, applications, network elements, topological constraints, and functionality expectations. In this article, we discuss scalability challenges for traditional access-control mechanisms at the architectural level and present a set of fundamental requirements for authorization services in large-scale networks. We show why existing mechanisms fail to meet these requirements and investigate the current design options for a scalable access-control architecture. We argue that the key design options to achieve scalability are the choice of the representation of access control policy, the distribution mechanism for policy, and the choice of the access-rights revocation scheme. Although these ideas have been considered in the past, current access-control systems in use continue to use simpler but restrictive architectural models. With this article, we hope to influence the design of future access-control systems towards more decentralized and scalable mechanisms.",
    "cited_by_count": 34,
    "openalex_id": "https://openalex.org/W2162599785",
    "type": "article"
  },
  {
    "title": "Implications of Internet architecture on net neutrality",
    "doi": "https://doi.org/10.1145/1516539.1516540",
    "publication_date": "2009-05-01",
    "publication_year": 2009,
    "authors": "Scott Jordan",
    "corresponding_authors": "Scott Jordan",
    "abstract": "Net neutrality represents the idea that Internet users are entitled to service that does not discriminate on the basis of source, destination, or ownership of Internet traffic. The United States Congress is considering legislation on net neutrality, and debate over the issue has generated intense lobbying. Congressional action will substantially affect the evolution of the Internet and of future Internet research. In this article, we argue that neither the pro nor anti net neutrality positions are consistent with the philosophy of Internet architecture. We develop a net neutrality policy founded on a segmentation of Internet services into infrastructure services and application services, based on the Internet's layered architecture. Our net neutrality policy restricts an Internet service Provider's ability to engage in anticompetitive behavior while simultaneously ensuring that it can use desirable forms of network management. We illustrate the effect of this policy by discussing acceptable and unacceptable uses of network management.",
    "cited_by_count": 32,
    "openalex_id": "https://openalex.org/W2112387267",
    "type": "article"
  },
  {
    "title": "A market-based bandwidth charging framework",
    "doi": "https://doi.org/10.1145/1667067.1667068",
    "publication_date": "2010-02-01",
    "publication_year": 2010,
    "authors": "David Turner; Vassilis Prevelakis; Angelos D. Keromytis",
    "corresponding_authors": "",
    "abstract": "The increasing demand for high-bandwidth applications such as video-on-demand and grid computing is reviving interest in bandwidth reservation schemes. Earlier attempts did not catch on for a number of reasons, notably lack of interest on the part of the bandwidth providers. This, in turn, was partially caused by the lack of an efficient way of charging for bandwidth. Thus, the viability of bandwidth reservation depends on the existence of an efficient market where bandwidth-related transactions can take place. For this market to be effective, it must be efficient for both the provider (seller) and the user (buyer) of the bandwidth. This implies that: (a) the buyer must have a wide choice of providers that operate in a competitive environment, (b) the seller must be assured that a QoS transaction will be paid by the customer, and (c) the QoS transaction establishment must have low overheads so that it may be used by individual customers without a significant burden to the provider. In order to satisfy these requirements, we propose a framework that allows customers to purchase bandwidth using an open market where providers advertise links and capacities and customers bid for these services. The model is close to that of a commodities market that offers both advance bookings (futures) and a spot market. We explore the mechanisms that can support such a model.",
    "cited_by_count": 28,
    "openalex_id": "https://openalex.org/W2074614677",
    "type": "article"
  },
  {
    "title": "When Amazon Meets Google",
    "doi": "https://doi.org/10.1145/2499926.2492690",
    "publication_date": "2013-07-01",
    "publication_year": 2013,
    "authors": "Meng Wang; Guangda Li; Zheng Lu; Yue Gao; Tat‐Seng Chua",
    "corresponding_authors": "",
    "abstract": "Product visualization is able to help users easily get knowledge about the visual appearance of a product. It is useful in many application and commercialization scenarios. However, the existing product image search on e-commerce Web sites or general search engines usually get insufficient search results or return images that are redundant and not relevant enough. In this article, we present a novel product visualization approach that automatically collects a set of diverse and relevant product images by exploring multiple Web sources. Our approach simultaneously leverages Amazon and Google image search engines, which represent domain-specific knowledge resource and general Web information collection, respectively. We propose a conditional clustering approach that is formulated as an affinity propagation problem regarding the Amazon examples as information prior. The ranking information of Google image search results is also explored. In this way, a set of exemplars can be found from the Google search results and they are provided together with the Amazon example images for product visualization. Experiments demonstrate the feasibility and effectiveness of our approach.",
    "cited_by_count": 25,
    "openalex_id": "https://openalex.org/W4247620520",
    "type": "article"
  },
  {
    "title": "Minersoft",
    "doi": "https://doi.org/10.1145/2220352.2220354",
    "publication_date": "2012-06-01",
    "publication_year": 2012,
    "authors": "Marios D. Dikaiakos; Asterios Katsifodimos; George Pallis",
    "corresponding_authors": "",
    "abstract": "One of the main goals of Cloud and Grid infrastructures is to make their services easily accessible and attractive to end-users. In this article we investigate the problem of supporting keyword-based searching for the discovery of software files that are installed on the nodes of large-scale, federated Grid and Cloud computing infrastructures. We address a number of challenges that arise from the unstructured nature of software and the unavailability of software-related metadata on large-scale networked environments. We present Minersoft, a harvester that visits Grid/Cloud infrastructures, crawls their file systems, identifies and classifies software files, and discovers implicit associations between them. The results of Minersoft harvesting are encoded in a weighted, typed graph, called the Software Graph. A number of information retrieval (IR) algorithms are used to enrich this graph with structural and content associations, to annotate software files with keywords and build inverted indexes to support keyword-based searching for software. Using a real testbed, we present an evaluation study of our approach, using data extracted from production-quality Grid and Cloud computing infrastructures. Experimental results show that Minersoft is a powerful tool for software search and discovery.",
    "cited_by_count": 24,
    "openalex_id": "https://openalex.org/W2023116651",
    "type": "article"
  },
  {
    "title": "Using Argumentative Structure to Interpret Debates in Online Deliberative Democracy and eRulemaking",
    "doi": "https://doi.org/10.1145/3032989",
    "publication_date": "2017-07-09",
    "publication_year": 2017,
    "authors": "John Lawrence; Joonsuk Park; Katarzyna Budzyńska; Claire Cardie; Barbara Konat; Chris Reed",
    "corresponding_authors": "",
    "abstract": "Governments around the world are increasingly utilising online platforms and social media to engage with, and ascertain the opinions of, their citizens. Whilst policy makers could potentially benefit from such enormous feedback from society, they first face the challenge of making sense out of the large volumes of data produced. In this article, we show how the analysis of argumentative and dialogical structures allows for the principled identification of those issues that are central, controversial, or popular in an online corpus of debates. Although areas such as controversy mining work towards identifying issues that are a source of disagreement, by looking at the deeper argumentative structure, we show that a much richer understanding can be obtained. We provide results from using a pipeline of argument-mining techniques on the debate corpus, showing that the accuracy obtained is sufficient to automatically identify those issues that are key to the discussion, attracting proportionately more support than others, and those that are divisive, attracting proportionately more conflicting viewpoints.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W2735971074",
    "type": "article"
  },
  {
    "title": "Toward Formal Modeling of Affective Agents in a BDI Architecture",
    "doi": "https://doi.org/10.1145/3001584",
    "publication_date": "2017-01-04",
    "publication_year": 2017,
    "authors": "Bexy Alfonso; Emilio Vivancos; Vicente Botti",
    "corresponding_authors": "",
    "abstract": "Affective characteristics are crucial factors that influence human behavior, and often, the prevalence of either emotions or reason varies on each individual. We aim to facilitate the development of agents’ reasoning considering their affective characteristics. We first identify core processes in an affective BDI agent, and we integrate them into an affective agent architecture ( GenIA 3 ). These tasks include the extension of the BDI agent reasoning cycle to be compliant with the architecture, the extension of the agent language (Jason) to support affect-based reasoning, and the adjustment of the equilibrium between the agent’s affective and rational sides.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W2569707177",
    "type": "article"
  },
  {
    "title": "Improving Vaccine Safety Using Blockchain",
    "doi": "https://doi.org/10.1145/3388446",
    "publication_date": "2020-07-07",
    "publication_year": 2020,
    "authors": "Laizhong Cui; Zhe Xiao; Jiahao Wang; Fei Chen; Yi Pan; Hua Dai; Jing Qin",
    "corresponding_authors": "",
    "abstract": "In recent years, vaccine incidents occurred around the world, which endangers people’s lives. In the technical respect, these incidents are partially due to the fact that existing vaccine management systems are distributively managed by different entities in the vaccine supply chain. This architecture makes it relatively easy to modify or even delete the vaccine circulation data maliciously, which makes tracing problematic vaccine hard and identifying the responsibility for a vaccine accident hard. To solve these issues, this article presents a blockchain-based solution to protect the whole process of vaccine circulation. We first propose a model to supervise the vaccine circulation process by incorporating existing regulatory practices. Then, we propose a blockchain-based tracing system to implement this model. The proposed system takes the blockchain as a global, unique, and verifiable database to store all the circulation data. Through data insertions and queries on the global and unique database, the proposed system achieves the protection of vaccine circulation. We also implement a proof-of-concept prototype of the proposed system. Experimental results confirm that the proposed system is beneficial.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W3041030525",
    "type": "article"
  },
  {
    "title": "Cloud-based Enabling Mechanisms for Container Deployment and Migration at the Network Edge",
    "doi": "https://doi.org/10.1145/3380955",
    "publication_date": "2020-06-26",
    "publication_year": 2020,
    "authors": "Zakaria Benomar; Francesco Longo; Giovanni Merlino; Antonio Puliafito",
    "corresponding_authors": "",
    "abstract": "In recent years, a new trend of advanced applications with huge demands in terms of Quality of Service (QoS) is gaining ground. Even though Cloud computing provides mature management facilities with ubiquitous capabilities, novel requirements and workloads, foisted by new services, start to expose its weaknesses. In this context, a new Information and Communication Technologies (ICT) trend aims at pushing computation from the Cloud to be much close as possible to data sources, raising in the evolution of new paradigms namely Fog and Mist computing. Specifically, the Fog computing paradigm exploits powerful nodes such as servers, routers, and cloudlets that are coupled with the end devices or their access networks accordingly; they are ”relatively” close by the data sources. Whereas Mist computing, which is a lightweight form of Fog computing, pushes the resources even closer. Precisely, Mist computing uses particular nodes that could reside within the same network (e.g., Local Area Network (LAN)) as the end-devices. Considering the advancement that the hardware is knowing nowadays, Fog and Mist nodes are seen suitable to provide resources such as processing, storage, and networking in the proximity of data sources; thereby, the requirements of the new services could be met. Together with the Cloud, the Fog and Mist paradigms introduce a stacked architecture for data processing where a data pre-processing could be performed at the Mist level, then offloaded vertically to the upper layers (i.e., Fog nodes or the Cloud). In these circumstances, it is fundamental to build a management system able to provision efficiently the Fog/Mist-based applications. For this purpose, the Operating System (OS)-level virtualization using containerization technologies, considering its light footprint, fits as a suitable solution to provide Fog/Mist services. The industrial-grade Cloud middlewares, such as OpenStack, which is a reference architecture for Infrastructure-as-a-Service solutions, are still far away from incorporating this new trend. This article proposes an OpenStack-based middleware platform through which containers can be deployed/managed at the Fog/Mist levels.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W3042004637",
    "type": "article"
  },
  {
    "title": "Multiobjective Optimization for Brokering of Multicloud Service Composition",
    "doi": "https://doi.org/10.1145/2870634",
    "publication_date": "2016-04-15",
    "publication_year": 2016,
    "authors": "Alba Amato; Salvatore Venticinque",
    "corresponding_authors": "",
    "abstract": "The choice of cloud providers whose offers best fit the requirements of a particular application is a complex issue due to the heterogeneity of the services in terms of resources, costs, technology, and service levels that providers ensure. This article investigates the effectiveness of multiobjective genetic algorithms to resolve a multicloud brokering problem. Experimental results provide clear evidence about how such a solution improves the choice made manually by users returning in real time optimal alternatives. It also investigates how the optimality depends on different genetic algorithms and parameters, problem type, and time constraints.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W2340902680",
    "type": "article"
  },
  {
    "title": "Achieving Secure Search over Encrypted Data for e-Commerce",
    "doi": "https://doi.org/10.1145/3408309",
    "publication_date": "2020-12-08",
    "publication_year": 2020,
    "authors": "Zhitao Guan; Naiyu Wang; Xunfeng Fan; Xueyan Liu; Longfei Wu; Shaohua Wan",
    "corresponding_authors": "",
    "abstract": "The advances of Internet technology has resulted in the rapid and pervasive development of e-commerce, which has not only changed the production and operation mode of many enterprises, but also affected the economic development mode of the whole society. This trend has incurred a strong need to store and process large amounts of sensitive data. The traditional data storage and search solutions cannot meet such requirements. To tackle this problem, in this article, we proposed Consortium Blockchain-based Distributed Secure Search (CBDSS) Scheme over encrypted data in e-Commerce environment. By integrating the blockchain and searchable encryption model, sensitive data can be effectively protected. The consortium blockchain can ensure that only authorized nodes can join the system. To fairly assign nodes for the search tasks, we developed an endorsement strategy in which two agent roles are set up to divide and match the search tasks with the virtual resources according to the load capacity of each node. The security analysis and experiments are conducted to evaluate the performance of our proposed scheme. The evaluation results have proved the reliability and security of our scheme over existing methods.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W3110733327",
    "type": "article"
  },
  {
    "title": "Mobile Pervasive Augmented Reality Systems—MPARS",
    "doi": "https://doi.org/10.1145/3375458",
    "publication_date": "2020-02-07",
    "publication_year": 2020,
    "authors": "Rui Miguel Pascoal; Ana de Almeida; Rute C. Sofia",
    "corresponding_authors": "",
    "abstract": "After briefly introducing aspects concerning Mobile Augmented Reality Systems, this article delves into the evolution of these systems as pervasive technology. The work debates also on acceptance of this technology in the context of outdoor applications. The need to develop context-aware, close-to-real-time feedback mechanisms that take into consideration a continuous measurement of Quality of Experience is also discussed. For this purpose, the work goes over how to integrate user preferences into context-aware feedback systems, proposing a theoretical model for measuring Quality of Experience. The model is derived from an analysis of previous technology adoption models and incorporates the knowledge of user preferences. This knowledge has been gathered via a public questionnaire.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W2983509304",
    "type": "article"
  },
  {
    "title": "Optimal Receiver Placement for <i>K</i> -barrier Coverage in Passive Bistatic Radar Sensor Networks",
    "doi": "https://doi.org/10.1145/3377402",
    "publication_date": "2020-07-07",
    "publication_year": 2020,
    "authors": "Jiaoyan Chen; Laurence T. Yang; Xianjun Deng; Xianggong Hong; Lingzhi Yi",
    "corresponding_authors": "",
    "abstract": "The improvement of coverage quality in the construction of multiple-barrier coverage is a critical problem in a wireless sensor network. In this article, we investigate the K -barrier coverage construction problem in passive bistatic radar sensor networks. In contrast to traditional bistatic radar networks, the transmitters in a passive bistatic radar network are predeployed and noncooperative. To construct K barriers, we need to deploy receivers that couple with predeployed transmitters to build continuous barriers. In this work, we focus on the minimum number of receivers problem of constructing K -barrier coverage, where the minimum number of receivers is based on the predeployed transmitters. To handle this problem, we first investigate the optimal placement of receivers between adjacent transmitters for a sub-barrier formation and then determine the optimal placement of receivers for the one-barrier construction. For multiple-barrier coverage construction, we introduce a weighted transmitter graph (WTG) to describe the relation among different transmitters, where the weight in the graph is the minimum number of receivers needed for these two transmitters for a sub-barrier formation. Based on WTG, the minimum receivers problem changes to a problem of how to find K -disjoint paths with the minimum total weight in the graph. For large-scale networks, we also propose two efficient heuristic algorithms to solve the corresponding problem. Finally, we conduct extensive experiments to validate the correctness and the efficiency of the proposed algorithms.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W3041037634",
    "type": "article"
  },
  {
    "title": "A Deep Learning Approach for Voice Disorder Detection for Smart Connected Living Environments",
    "doi": "https://doi.org/10.1145/3433993",
    "publication_date": "2021-10-15",
    "publication_year": 2021,
    "authors": "Laura Verde; Nadia Brancati; Giuseppe De Pietro; Maria Frucci; Giovanna Sannino",
    "corresponding_authors": "",
    "abstract": "Edge Analytics and Artificial Intelligence are important features of the current smart connected living community. In a society where people, homes, cities, and workplaces are simultaneously connected through various devices, primarily through mobile devices, a considerable amount of data is exchanged, and the processing and storage of these data are laborious and difficult tasks. Edge Analytics allows the collection and analysis of such data on mobile devices, such as smartphones and tablets, without involving any cloud-centred architecture that cannot guarantee real-time responsiveness. Meanwhile, Artificial Intelligence techniques can constitute a valid instrument to process data, limiting the computation time, and optimising decisional processes and predictions in several sectors, such as healthcare. Within this field, in this article, an approach able to evaluate the voice quality condition is proposed. A fully automatic algorithm, based on Deep Learning, classifies a voice as healthy or pathological by analysing spectrogram images extracted by means of the recording of vowel /a/, in compliance with the traditional medical protocol. A light Convolutional Neural Network is embedded in a mobile health application in order to provide an instrument capable of assessing voice disorders in a fast, easy, and portable way. Thus, a straightforward mobile device becomes a screening tool useful for the early diagnosis, monitoring, and treatment of voice disorders. The proposed approach has been tested on a broad set of voice samples, not limited to the most common voice diseases but including all the pathologies present in three different databases achieving F1-scores, over the testing set, equal to 80%, 90%, and 73%. Although the proposed network consists of a reduced number of layers, the results are very competitive compared to those of other “cutting edge” approaches constructed using more complex neural networks, and compared to the classic deep neural networks, for example, VGG-16 and ResNet-50.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W3206949821",
    "type": "article"
  },
  {
    "title": "Blockchain-Based Power Energy Trading Management",
    "doi": "https://doi.org/10.1145/3409771",
    "publication_date": "2021-03-08",
    "publication_year": 2021,
    "authors": "Hao Wang; Shenglan Ma; Chaonian Guo; Yulei Wu; Hong‐Ning Dai; D. Y. Wu",
    "corresponding_authors": "",
    "abstract": "Distributed peer-to-peer power energy markets are emerging quickly. Due to central governance and lack of effective information aggregation mechanisms, energy trading cannot be efficiently scheduled and tracked. We devise a new distributed energy transaction system over the energy Industrial Internet of Things based on predictive analytics, blockchain, and smart contract technologies. We propose a solution for scheduling distributed energy sources based on the Minimum Cut Maximum Flow theory. Blockchain is used to record transactions and reach consensus. Payment clearing for the actual power consumption is executed via smart contracts. Experimental results on real data show that our solution is practical and achieves a lower total cost for power energy consumption.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W3133504101",
    "type": "article"
  },
  {
    "title": "A Hybrid Siamese Neural Network for Natural Language Inference in Cyber-Physical Systems",
    "doi": "https://doi.org/10.1145/3418208",
    "publication_date": "2021-03-15",
    "publication_year": 2021,
    "authors": "Pin Ni; Yuming Li; Gangmin Li; Victor Chang",
    "corresponding_authors": "",
    "abstract": "Cyber-Physical Systems (CPS), as a multi-dimensional complex system that connects the physical world and the cyber world, has a strong demand for processing large amounts of heterogeneous data. These tasks also include Natural Language Inference (NLI) tasks based on text from different sources. However, the current research on natural language processing in CPS does not involve exploration in this field. Therefore, this study proposes a Siamese Network structure that combines Stacked Residual Long Short-Term Memory (bidirectional) with the Attention mechanism and Capsule Network for the NLI module in CPS, which is used to infer the relationship between text/language data from different sources. This model is mainly used to implement NLI tasks and conduct a detailed evaluation in three main NLI benchmarks as the basic semantic understanding module in CPS. Comparative experiments prove that the proposed method achieves competitive performance, has a certain generalization ability, and can balance the performance and the number of trained parameters.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W3137280539",
    "type": "article"
  },
  {
    "title": "Spatio-temporal Bayesian Learning for Mobile Edge Computing Resource Planning in Smart Cities",
    "doi": "https://doi.org/10.1145/3448613",
    "publication_date": "2021-06-09",
    "publication_year": 2021,
    "authors": "Laha Ale; Ning Zhang; Scott A. King; Jose Guardiola",
    "corresponding_authors": "",
    "abstract": "A smart city improves operational efficiency and comfort of living by harnessing techniques such as the Internet of Things (IoT) to collect and process data for decision making. To better support smart cities, data collected by IoT should be stored and processed appropriately. However, IoT devices are often task-specialized and resource-constrained, and thus, they heavily rely on online resources in terms of computing and storage to accomplish various tasks. Moreover, these cloud-based solutions often centralize the resources and are far away from the end IoTs and cannot respond to users in time due to network congestion when massive numbers of tasks offload through the core network. Therefore, by decentralizing resources spatially close to IoT devices, mobile edge computing (MEC) can reduce latency and improve service quality for a smart city, where service requests can be fulfilled in proximity. As the service demands exhibit spatial-temporal features, deploying MEC servers at optimal locations and allocating MEC resources play an essential role in efficiently meeting service requirements in a smart city. In this regard, it is essential to learn the distribution of resource demands in time and space. In this work, we first propose a spatio-temporal Bayesian hierarchical learning approach to learn and predict the distribution of MEC resource demand over space and time to facilitate MEC deployment and resource management. Second, the proposed model is trained and tested on real-world data, and the results demonstrate that the proposed method can achieve very high accuracy. Third, we demonstrate an application of the proposed method by simulating task offloading. Finally, the simulated results show that resources allocated based upon our models' predictions are exploited more efficiently than the resources are equally divided into all servers in unobserved areas.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W3139063192",
    "type": "article"
  },
  {
    "title": "Sentence Semantic Matching Based on 3D CNN for Human–Robot Language Interaction",
    "doi": "https://doi.org/10.1145/3450520",
    "publication_date": "2021-07-16",
    "publication_year": 2021,
    "authors": "Wenpeng Lü; Rui Yu; Shoujin Wang; Can Wang; Ping Jian; Heyan Huang",
    "corresponding_authors": "",
    "abstract": "The development of cognitive robotics brings an attractive scenario where humans and robots cooperate to accomplish specific tasks. To facilitate this scenario, cognitive robots are expected to have the ability to interact with humans with natural language, which depends on natural language understanding ( NLU ) technologies. As one core task in NLU, sentence semantic matching ( SSM ) has widely existed in various interaction scenarios. Recently, deep learning–based methods for SSM have become predominant due to their outstanding performance. However, each sentence consists of a sequence of words, and it is usually viewed as one-dimensional ( 1D ) text, leading to the existing available neural models being restricted into 1D sequential networks. A few researches attempt to explore the potential of 2D or 3D neural models in text representation. However, it is hard for their works to capture the complex features in texts, and thus the achieved performance improvement is quite limited. To tackle this challenge, we devise a novel 3D CNN-based SSM ( 3DSSM ) method for human–robot language interaction. Specifically, first, a specific architecture called feature cube network is designed to transform a 1D sentence into a multi-dimensional representation named as semantic feature cube. Then, a 3D CNN module is employed to learn a semantic representation for the semantic feature cube by capturing both the local features embedded in word representations and the sequential information among successive words in a sentence. Given a pair of sentences, their representations are concatenated together to feed into another 3D CNN to capture the interactive features between them to generate the final matching representation. Finally, the semantic matching degree is judged with the sigmoid function by taking the learned matching representation as the input. Extensive experiments on two real-world datasets demonstrate that 3DSSM is able to achieve comparable or even better performance over the state-of-the-art competing methods.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W3184218698",
    "type": "article"
  },
  {
    "title": "Towards Semantic Management of On-Device Applications in Industrial IoT",
    "doi": "https://doi.org/10.1145/3510820",
    "publication_date": "2022-02-03",
    "publication_year": 2022,
    "authors": "Haoyu Ren; Darko Anicic; Thomas A. Runkler",
    "corresponding_authors": "",
    "abstract": "The Internet of Things (IoT) is revolutionizing the industry. Powered by pervasive embedded devices, the Industrial IoT (IIoT) provides a unique solution for retrieving and analyzing data near the source in real-time. Many emerging techniques, such as Tiny Machine Learning (TinyML) and Complex Event Processing (CEP) , are actively being developed to support decision making at the edge, shifting the paradigm from centralized processing to distributed computing. However, distributed computing presents management challenges, as IoT devices are diverse and constrained, and their number is growing exponentially. The situation is even more challenging when various on-device applications (so-called artifacts) are deployed across decentralized IoT networks. Questions to be addressed include how to discover an appropriate function, whether that function can be executed on a certain device, and how to orchestrate a cross-platform service. To tackle these challenges, we propose an approach for the scalable management of on-device applications among distributed IoT devices. By leveraging the W3C Web of Things (WoT) , the capabilities of each IoT device, or more precisely, its interaction patterns, can be semantically expressed in a Thing Description (TD) . In addition, we introduce semantic modeling of on-device applications to supplement an TD with additional information regarding applications on the device. Specifically, we demonstrate two examples of semantic modeling: neural networks (NN) and CEP rules. The ontologies are evaluated by answering a set of competency questions. By hosting the enriched semantic knowledge of the entire IoT system in a Knowledge Graph (KG) , we can discover and interoperate edge devices and artifacts across the decentralized network. This can reduce fragmentation and increase the reusability of IoT components. We demonstrate the feasibility of our concept on an industrial workstation consisting of a conveyor belt and several IoT devices. Finally, the requirements for constructing an IoT semantic management system are discussed.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W4210623388",
    "type": "article"
  },
  {
    "title": "Uncertainty-Aware Personal Assistant for Making Personalized Privacy Decisions",
    "doi": "https://doi.org/10.1145/3561820",
    "publication_date": "2022-09-16",
    "publication_year": 2022,
    "authors": "Gönül Aycı; Murat Şensoy; Arzucan Özgür; Pınar Yolum",
    "corresponding_authors": "",
    "abstract": "Many software systems, such as online social networks, enable users to share information about themselves. Although the action of sharing is simple, it requires an elaborate thought process on privacy: what to share, with whom to share, and for what purposes. Thinking about these for each piece of content to be shared is tedious. Recent approaches to tackle this problem build personal assistants that can help users by learning what is private over time and recommending privacy labels such as private or public to individual content that a user considers sharing. However, privacy is inherently ambiguous and highly personal . Existing approaches to recommend privacy decisions do not address these aspects of privacy sufficiently. Ideally, a personal assistant should be able to adjust its recommendation based on a given user, considering that user’s privacy understanding. Moreover, the personal assistant should be able to assess when its recommendation would be uncertain and let the user make the decision on her own. Accordingly, this article proposes a personal assistant that uses evidential deep learning to classify content based on its privacy label. An important characteristic of the personal assistant is that it can model its uncertainty in its decisions explicitly, determine that it does not know the answer, and delegate from making a recommendation when its uncertainty is high. By factoring in the user’s own understanding of privacy, such as risk factors or own labels, the personal assistant can personalize its recommendations per user. We evaluate our proposed personal assistant using a well-known dataset. Our results show that our personal assistant can accurately identify uncertain cases, personalize them to its user’s needs, and thus helps users preserve their privacy well.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W4295979748",
    "type": "article"
  },
  {
    "title": "Concept Drift in Software Defect Prediction: A Method for Detecting and Handling the Drift",
    "doi": "https://doi.org/10.1145/3589342",
    "publication_date": "2023-03-27",
    "publication_year": 2023,
    "authors": "Arvind Kumar Gangwar; Sandeep Kumar",
    "corresponding_authors": "",
    "abstract": "Software Defect Prediction (SDP) is crucial towards software quality assurance in software engineering. SDP analyzes the software metrics data for timely prediction of defect prone software modules. Prediction process is automated by constructing defect prediction classification models using machine learning techniques. These models are trained using metrics data from historical projects of similar types. Based on the learned experience, models are used to predict defect prone modules in currently tested software. These models perform well if the concept is stationary in a dynamic software development environment. But their performance degrades unexpectedly in the presence of change in concept (Concept Drift). Therefore, concept drift (CD) detection is an important activity for improving the overall accuracy of the prediction model. Previous studies on SDP have shown that CD may occur in software defect data and the used defect prediction model may require to be updated to deal with CD. This phenomenon of handling the CD is known as CD adaptation. It is observed that still efforts need to be done in this direction in the SDP domain. In this article, we have proposed a pair of paired learners (PoPL) approach for handling CD in SDP. We combined the drift detection capabilities of two independent paired learners and used the paired learner (PL) with the best performance in recent time for next prediction. We experimented on various publicly available software defect datasets garnered from public data repositories. Experimentation results showed that our proposed approach performed better than the existing similar works and the base PL model based on various performance measures.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W4361003492",
    "type": "article"
  },
  {
    "title": "i-DarkVec: Incremental Embeddings for Darknet Traffic Analysis",
    "doi": "https://doi.org/10.1145/3595378",
    "publication_date": "2023-05-03",
    "publication_year": 2023,
    "authors": "Luca Gioacchini; Luca Vassio; Marco Mellia; Idílio Drago; Zied Ben Houidi; Dario Rossi",
    "corresponding_authors": "",
    "abstract": "Darknets are probes listening to traffic reaching IP addresses that host no services. Traffic reaching a darknet results from the actions of internet scanners, botnets, and possibly misconfigured hosts. Such peculiar nature of the darknet traffic makes darknets a valuable instrument to discover malicious online activities, e.g., identifying coordinated actions performed by bots or scanners. However, the massive amount of packets and sources that darknets observe makes it hard to extract meaningful insights, calling for scalable tools to automatically identify and group sources that share similar behaviour. We here present i-DarkVec, a methodology to learn meaningful representations of Darknet traffic. i-DarkVec leverages Natural Language Processing techniques (e.g., Word2Vec) to capture the co-occurrence patterns that emerge when scanners or bots launch coordinated actions. As in NLP problems, the embeddings learned with i-DarkVec enable several new machine learning tasks on the darknet traffic, such as identifying clusters of senders engaged in similar activities. We extensively test i-DarkVec and explore its design space in a case study using real darknets. We show that with a proper definition of services , the learned embeddings can be used to (i) solve the classification problem to associate unknown sources’ IP addresses to the correct classes of coordinated actors and (ii) automatically identify clusters of previously unknown sources performing similar attacks and scans, easing the security analyst’s job. i-DarkVec leverages a novel incremental embedding learning approach that is scalable and robust to traffic changes, making it applicable to dynamic and large-scale scenarios.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W4367847704",
    "type": "article"
  },
  {
    "title": "Atrial Fibrillation Detection from Compressed ECG Measurements for Wireless Body Sensor Network",
    "doi": "https://doi.org/10.1145/3637440",
    "publication_date": "2024-01-10",
    "publication_year": 2024,
    "authors": "Yongyong Chen; Junxin Chen; Shuang Sun; Jingyong Su; Qiankun Li; Zhihan Lyu",
    "corresponding_authors": "",
    "abstract": "Recent years have witnessed an increasing prevalence of wearable devices in the public, where atrial fibrillation (AF) detection is a popular application in these devices. Generally, AF detection is performed on cloud whereas this paper describes an on-device AF detection method. Technically, compressed sensing (CS) is first used for electrocardiograph (ECG) acquisition. Then QRS detection is proposed to be performed directly on the compressed CS measurements, rather than on the reconstructed signals on the powerful cloud server. Based on the extracted QRS information, AF is determined by quantitatively analyzing the ( RR , dRR ) plot. Databases with ECG samples collected from both medical-level (MIT-BIH afdb) and wearable ECG devices (Physionet Challenge 2017) are introduced for performance validation. The experiment results well demonstrate that our on-device AF detection algorithm can approach the performance of those implemented on the raw signals. Our proposal is suitable for AF screening directly on the wearable devices, without the support of the data center for signal reconstruction and intelligent analysis.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4390722125",
    "type": "article"
  },
  {
    "title": "ADTO: A Trust Active Detecting-based Task Offloading Scheme in Edge Computing for Internet of Things",
    "doi": "https://doi.org/10.1145/3640013",
    "publication_date": "2024-01-12",
    "publication_year": 2024,
    "authors": "Xuezheng Yang; Zhiwen Zeng; Anfeng Liu; Naixue Xiong; Shaobo Zhang",
    "corresponding_authors": "",
    "abstract": "In edge computing, Internet of Things devices with weak computing power offload tasks to nearby edge servers for execution, so the task completion time can be reduced and delay-sensitive tasks can be facilitated. However, if the task is offloaded to malicious edge servers, then the system will suffer losses. Therefore, it is significant to identify the trusted edge servers and offload tasks to trusted edge servers, which can improve the performance of edge computing. However, it is still challenging. In this article, a trust Active Detecting-based Task Offloading (ADTO) scheme is proposed to maximize revenue in edge computing. The main innovation points of our work are as follows: (a) The ADTO scheme innovatively proposes a method to actively get trust by trust detection. This method offloads microtasks to edge servers whose trust needs to be identified, and then quickly identifies the trust of edge servers according to the completion of tasks by edge servers. Based on the identification of the trust, tasks can be offloaded to trusted edge servers, to improve the success rate of tasks. (b) Although the trust of edge servers can be identified by our detection, it needs to pay a price. Therefore, to maximize system revenue, searching the most suitable number of trusted edge servers for various conditions is transformed into an optimization problem. Finally, theoretical and experimental analysis shows the effectiveness of the proposed strategy, which can effectively identify the trusted and untrusted edge servers. The task offloading strategy based on trust detection proposed in this article greatly improves the success rate of tasks, compared with the strategy without trust detection, the task success rate is increased by 40.27%, and there is a significant increase in revenue, which fully demonstrates the effectiveness of the strategy.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4390824884",
    "type": "article"
  },
  {
    "title": "SDN-enabled Quantized LQR for Smart Traffic Light Controller to Optimize Congestion",
    "doi": "https://doi.org/10.1145/3641104",
    "publication_date": "2024-01-16",
    "publication_year": 2024,
    "authors": "Anuj Sachan; Neetesh Kumar",
    "corresponding_authors": "",
    "abstract": "Existing intersection management systems, in urban cities, lack in meeting the current requirements of self-configuration, lightweight computing, and software-defined control, which are necessarily required for congested road-lane networks. To satisfy these requirements, this work proposes effective, scalable, multi-input and multi-output, and congestion prevention-enabled intersection management system utilizing a software-defined control interface that not only regularly monitors the traffic to prevent congestion for minimizing queue length and waiting time but also offers a computationally efficient solution in real-time. For effective intersection management, a modified linear-quadratic regulator, i.e., Quantized Linear Quadratic Regulator (QLQR), is designed along with Software-defined Networking (SDN)-enabled control interface to maximize throughput and vehicles speed and minimize queue length and waiting time at the intersection. Experimental results prove that the proposed SDN-QLQR improves the comparative performance in the interval of 24.94%–49.07%, 35.78%–68.86%, 36.67%–59.08%, and 29.94%–57.87% for various performance metrics, i.e., average queue length, average waiting time, throughput, and average speed, respectively.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4390918645",
    "type": "article"
  },
  {
    "title": "OTI-IoT: A Blockchain-based Operational Threat Intelligence Framework for Multi-vector DDoS Attacks",
    "doi": "https://doi.org/10.1145/3664287",
    "publication_date": "2024-05-11",
    "publication_year": 2024,
    "authors": "Aswani Devi Aguru; E. Suresh Babu",
    "corresponding_authors": "",
    "abstract": "The Internet of Things (IoT) refers to a complex network comprising interconnected devices that transmit their data via the Internet. Due to their open environment, limited computation power, and absence of built-in security, IoT environments are susceptible to various cyberattacks. Denial of service (DDoS) attacks are among the most destructive types of threats. The Multi-vector DDoS attack is a contemporary and formidable form of DDoS wherein the attacker employs a collection of compromised IoT devices as zombies to initiate numerous DDoS attacks against a target server. A Blockchain-based Operational Threat Intelligence framework, OTI-IoT, is proposed in this article to counter multi-vector DDoS attacks in IoT networks. A “Prevent-then-Detect” methodology was utilized to deploy the OTI-IoT framework in two distinct stages. During Phase 1, the consortium Blockchain network validators employ the IPS module, composed of a smart contract for attack prevention and access control, and Proof of Voting consensus, to thwart attacks. Validators are outfitted with deep learning-based IDS instances to detect multi-vector DDoS attacks during Phase 2. Alert messages are generated by the IDS module’s alert generation and propagation smart contract in response to identifying malicious IoT sources. The feedback loop from the IDS module to the IPS module prevents incoming traffic from malicious sources. The proposed OTI framework capabilities are realized as an outcome of combining and storing the outcomes of the IDS and IPS modules on the consortium Blockchain. Each validator maintains a shared ledger containing information regarding threat sources to ensure robust security, transparency, and integrity. The operational execution of OTI-IoT occurs on an individual Ethereum Blockchain. The empirical findings indicate that our proposed framework is most suitable for real-time applications due to its ability to lower attack detection time, decreased block validation time, and higher attack prevention rate.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4396833771",
    "type": "article"
  },
  {
    "title": "Using Reinforcement Learning and Error Models for Drone Precision Landing",
    "doi": "https://doi.org/10.1145/3670997",
    "publication_date": "2024-06-04",
    "publication_year": 2024,
    "authors": "Sepehr Saryazdi; Balsam Alkouz; Athman Bouguettaya; Abdallah Lakhdari",
    "corresponding_authors": "",
    "abstract": "We propose a novel framework for achieving precision landing in drone services. The proposed framework consists of two distinct decoupled modules, each designed to address a specific aspect of landing accuracy. The first module is concerned with intrinsic errors, where new error models are introduced. This includes a spherical error model that takes into account the orientation of the drone. Additionally, we propose a live position correction algorithm that employs the error models to correct for intrinsic errors in real time. The second module focuses on external wind forces and presents an aerodynamics model with wind generation to simulate the drone’s physical environment. We utilize reinforcement learning to train the drone in simulation with the goal of landing precisely under dynamic wind conditions. Experimental results, conducted through simulations and validated in the physical world, demonstrate that our proposed framework significantly increases landing accuracy while maintaining a low onboard computational cost.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4399320584",
    "type": "article"
  },
  {
    "title": "Model-Driven Development Towards Distributed Intelligent Systems",
    "doi": "https://doi.org/10.1145/3687472",
    "publication_date": "2024-08-20",
    "publication_year": 2024,
    "authors": "Arturo Barriga; José A. Barriga; Miguel A. Pérez; Pedro J. Clemente",
    "corresponding_authors": "",
    "abstract": "A Distributed Intelligent System (DIS) encompasses a set of intelligent subsystems and components that collaborate to perform tasks and solve problems. Given the advancements of paradigms such as the Internet of Things, along with the advancements of technologies such as Machine Learning and Digital Twins, DISs are on the rise. These systems are increasingly integrating components that perform intelligent functions, and these intelligent functions are increasingly heterogeneous and varied. Moreover, there is no standardized framework to help researchers and practitioners adequately address DISs. As a result, the complexity, interoperability issues, and development time and costs of these systems are growing. However, Model-Driven Development (MDD) can help to address these challenges by providing a Domain-Specific Language (DSL) for developing DISs. In this work, a DSL for the design, validation, generation, and deployment of DISs is proposed. Firstly, the proposed DSL captures in a metamodel the key and high-level abstract concepts of the distinct DISs documented in the literature. Then, it allows modeling of DISs conforming to this metamodel. Subsequently, the DSL enables formal validation of the modeled systems. Lastly, it allows the generation and deployment of all DISs into production. Therefore, the work undertaken in this communication provides a methodological, formal, and standardized approach to defining and developing DISs from a high level of abstraction. This work allows users to address DISs by facilitating agility, minimizing manual tasks, and reducing the number of defects introduced in their development. To illustrate the applicability of the proposed DSL, a real case study of an agricultural digital twin is presented.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4401897912",
    "type": "article"
  },
  {
    "title": "Market-based recommendation",
    "doi": "https://doi.org/10.1145/1031114.1031118",
    "publication_date": "2004-11-01",
    "publication_year": 2004,
    "authors": "Sander M. Bohté; Enrico Gerding; Han La Poutré",
    "corresponding_authors": "",
    "abstract": "The amount of attention space available for recommending suppliers to consumers on e-commerce sites is typically limited. We present a competitive distributed recommendation mechanism based on adaptive software agents for efficiently allocating the \"consumer attention space,\" or banners. In the example of an electronic shopping mall, the task is delegated to the individual shops, each of which evaluates the information that is available about the consumer and his or her interests (e.g. keywords, product queries, and available parts of a profile). Shops make a monetary bid in an auction where a limited amount of \"consumer attention space\" for the arriving consumer is sold. Each shop is represented by a software agent that bids for each consumer. This allows shops to rapidly adapt their bidding strategy to focus on consumers interested in their offerings. For various basic and simple models for on-line consumers, shops, and profiles, we demonstrate the feasibility of our system by evolutionary simulations as in the field of agent-based computational economics (ACE). We also develop adaptive software agents that learn bidding-strategies, based on neural networks and strategy exploration heuristics. Furthermore, we address the commercial and technological advantages of this distributed market-based approach. The mechanism we describe is not limited to the example of the electronic shopping mall, but can easily be extended to other domains.",
    "cited_by_count": 38,
    "openalex_id": "https://openalex.org/W1978727873",
    "type": "article"
  },
  {
    "title": "An open architecture for next-generation telecommunication services",
    "doi": "https://doi.org/10.1145/967030.967034",
    "publication_date": "2004-02-01",
    "publication_year": 2004,
    "authors": "Gregory W. Bond; Eric Cheung; K. Hal Purdy; Pamela Zave; J. Christopher Ramming",
    "corresponding_authors": "",
    "abstract": "An open (in the sense of extensible and programmable) architecture for IP telecommunications must be based on a comprehensive strategy for managing feature interaction. We describe our experience with BoxOS, an IP telecommunication platform that implements the DFC technology for feature composition. We present solutions to problems, common to all efforts in IP telecommunications, of feature distribution, interoperability, and media management. We also explain how BoxOS addresses many deficiencies in SIP, including how BoxOS can be used as a SIP application server.",
    "cited_by_count": 38,
    "openalex_id": "https://openalex.org/W2061475652",
    "type": "article"
  },
  {
    "title": "An embedded domain-specific language for type-safe server-side web scripting",
    "doi": "https://doi.org/10.1145/1052934.1052935",
    "publication_date": "2005-02-01",
    "publication_year": 2005,
    "authors": "Peter Thiemann",
    "corresponding_authors": "Peter Thiemann",
    "abstract": "WASH/CGI is an embedded domain-specific language for server-side Web scripting. Due to its reliance on the strongly typed, purely functional programming language Haskell as a host language, it is highly flexible and---at the same time---it provides extensive guarantees due to its pervasive use of type information.WASH/CGI can be structured into a number of sublanguages addressing different aspects of the application. The document sublanguage provides tools for the generation of parameterized XHTML documents and forms. Its typing guarantees that almost all generated documents are valid XHTML documents. The session sublanguage provides a session abstraction with a transparent notion of session state and allows the composition of documents and Web forms to entire interactive scripts. Both are integrated with the widget sublanguage which describes the communication (parameter passing) between client and server. It imposes a simple type discipline on the parameters that guarantees that forms posted by the client are always understood by the server. That is, the server never asks for data not submitted by the client and the data submitted by the client has the type requested by the server. In addition, parameters are received in their typed internal representation, not as strings. Finally, the persistence sublanguage deals with managing shared state on the server side as well as individual state on the client side. It presents shared state as an abstract data type, where the script can control whether it wants to observe mutations due to concurrently executing scripts. It guarantees that states from different interaction threads cannot be confused.",
    "cited_by_count": 37,
    "openalex_id": "https://openalex.org/W2151186348",
    "type": "article"
  },
  {
    "title": "What makes the differences: benchmarking XML database implementations",
    "doi": "https://doi.org/10.1145/1052934.1052940",
    "publication_date": "2005-02-01",
    "publication_year": 2005,
    "authors": "Hongjun Lü; Jeffrey Xu Yu; Guoren Wang; Shihui Zheng; Haifeng Jiang; Ge Yu; Aoying Zhou",
    "corresponding_authors": "",
    "abstract": "XML is emerging as a major standard for representing data on the World Wide Web. Recently, many XML storage models have been proposed to manage XML data. In order to assess an XML database's abilities to deal with XML queries, several benchmarks have also been proposed, including XMark and XMach. However, no reported studies using those benchmarks were found that can provide users with insights on the impacts of a variety of storage models on XML query performance. In this article, we report our first set of results on benchmarking a set of XML database implementations using two XML benchmarks. The selected implementations represent a wide range of approaches, including RDBMS-based systems with document-independent and document-dependent XML-relational schema mapping approaches, and XML native engines based on an Object-Oriented Model and the Document Object Model. Comprehensive experiments were conducted to study relative performance of different approaches and the important issues that affect XML query performance, such as path expression query processing, effectiveness of various partitioning, label-path, and indexing structures.",
    "cited_by_count": 35,
    "openalex_id": "https://openalex.org/W1994593080",
    "type": "article"
  },
  {
    "title": "A fragment-based approach for efficiently creating dynamic web content",
    "doi": "https://doi.org/10.1145/1064340.1064343",
    "publication_date": "2005-05-01",
    "publication_year": 2005,
    "authors": "Jim Challenger; Paul Dantzig; Arun Iyengar; Karen Witting",
    "corresponding_authors": "",
    "abstract": "This article presents a publishing system for efficiently creating dynamic Web content. Complex Web pages are constructed from simpler fragments. Fragments may recursively embed other fragments. Relationships between Web pages and fragments are represented by object dependence graphs. We present algorithms for efficiently detecting and updating Web pages affected after one or more fragments change. We also present algorithms for publishing sets of Web pages consistently; different algorithms are used depending upon the consistency requirements.Our publishing system provides an easy method for Web site designers to specify and modify inclusion relationships among Web pages and fragments. Users can update content on multiple Web pages by modifying a template. The system then automatically updates all Web pages affected by the change. Our system accommodates both content that must be proofread before publication and is typically from humans as well as content that has to be published immediately and is typically from automated feeds.We discuss some of our experiences with real deployments of our system as well as its performance. We also quantitatively present characteristics of fragments used at a major deployment of our publishing system including fragment sizes, update frequencies, and inclusion relationships.",
    "cited_by_count": 35,
    "openalex_id": "https://openalex.org/W2007224838",
    "type": "article"
  },
  {
    "title": "Motion prediction for caching and prefetching in mouse-driven DVE navigation",
    "doi": "https://doi.org/10.1145/1052934.1052937",
    "publication_date": "2005-02-01",
    "publication_year": 2005,
    "authors": "Addison Chan; Rynson W. H. Lau; Beatrice Ng",
    "corresponding_authors": "",
    "abstract": "A distributed virtual environment (DVE) allows geographically separated users to participate in a shared virtual environment via connected networks. However, when the users are connected by the Internet, bandwidth limitation and network latency may seriously affect the performance and the interactivity of the system. This explains why there are very few DVE applications for the Internet. To address these shortcomings, caching and prefetching techniques are usually employed. Unfortunately, the effectiveness of these techniques depends largely on the accuracy of the prediction method used. Although there are a few methods proposed for predicting 3D motion, most of them are primarily designed for predicting the motion of specific objects by assuming certain object motion behaviors. We notice that in desktop DVE applications, such as virtual walkthrough and network gaming, the 2D mouse is still the most popular device used for navigation input. Through studying the motion behavior of a mouse during 3D navigation, we have developed a hybrid motion model for predicting the mouse motion during such navigation---a linear model for prediction at low-velocity motion and an elliptic model for prediction at high-velocity motion. The predicted mouse motion velocity is then mapped to the 3D environment for predicting the user's 3D motion. We describe how this prediction method can be integrated into the caching and prefetching mechanisms of our DVE prototype. We also demonstrate the effectiveness of the method and the resulting caching and prefetching mechanisms through extensive experiments.",
    "cited_by_count": 34,
    "openalex_id": "https://openalex.org/W2162164327",
    "type": "article"
  },
  {
    "title": "A multimedia broker to support accessible and mobile learning through learning objects adaptation",
    "doi": "https://doi.org/10.1145/1323651.1323655",
    "publication_date": "2008-02-01",
    "publication_year": 2008,
    "authors": "Paola Salomoni; Silvia Mirri; Stefano Ferretti; Marco Roccetti",
    "corresponding_authors": "",
    "abstract": "The large diffusion of e-learning technologies represents a great opportunity for underserved segments of population. This is particularly true for people with disabilities for whom digital barriers should be overstepped with the aim of reengaging them back into society to education. In essence, before a mass of learners can be engaged in a collective educational process, each single member should be put in the position to enjoy accessible and customized educational experiences, regardless of the wide diversity of their personal characteristics and technological equipment. To respond to this demand, we developed LOT (Learning Object Transcoder), a distributed PHP-based service-oriented system designed to deliver flexible and customized educational services for a multitude of learners, each with his/her own diverse preferences and needs. The main novelty of LOT amounts to a broking service able to manage the transcoding activities needed to convert multimedia digital material into the form which better fits a given student profile. Transcoding activities are performed based on the use of Web service technologies. Experimental results gathered from several field trials with LOT (available online at http://137.204.74.83/∼lot/) have confirmed the viability of our approach.",
    "cited_by_count": 29,
    "openalex_id": "https://openalex.org/W1973549796",
    "type": "article"
  },
  {
    "title": "A Framework for Large-Scale Detection of Web Site Defacements",
    "doi": "https://doi.org/10.1145/1852096.1852098",
    "publication_date": "2010-10-01",
    "publication_year": 2010,
    "authors": "Alberto Bartoli; Giorgio Davanzo; Eric Medvet",
    "corresponding_authors": "",
    "abstract": "Web site defacement, the process of introducing unauthorized modifications to a Web site, is a very common form of attack. In this paper we describe and evaluate experimentally a framework that may constitute the basis for a defacement detection service capable of monitoring thousands of remote Web sites systematically and automatically. In our framework an organization may join the service by simply providing the URLs of the resources to be monitored along with the contact point of an administrator. The monitored organization may thus take advantage of the service with just a few mouse clicks, without installing any software locally or changing its own daily operational processes. Our approach is based on anomaly detection and allows monitoring the integrity of many remote Web resources automatically while remaining fully decoupled from them, in particular, without requiring any prior knowledge about those resources. We evaluated our approach over a selection of dynamic resources and a set of publicly available defacements. The results are very satisfactory: all attacks are detected while keeping false positives to a minimum. We also assessed performance and scalability of our proposal and we found that it may indeed constitute the basis for actually deploying the proposed service on a large scale.",
    "cited_by_count": 25,
    "openalex_id": "https://openalex.org/W2162273167",
    "type": "article"
  },
  {
    "title": "Understanding Quota Dynamics in Wireless Networks",
    "doi": "https://doi.org/10.1145/2663494",
    "publication_date": "2014-10-28",
    "publication_year": 2014,
    "authors": "Matthew Andrews; Glenn Bruns; Mustafa K. Doğru; Hyoseop Lee",
    "corresponding_authors": "",
    "abstract": "In designing new service plans, network service providers need to understand how consumption of voice or data service will change in response to pricing signals. It is difficult to acquire such information from customer usage data because voice minutes and data bandwidth are typically sold in the form of large quotas. We address this issue by studying how end-users consume their quotas, both in a prepaid setting (where users pay in advance and refill as needed) and a postpaid setting (where users pay each month for a fixed amount of quota). Our presentation has three main parts. In the first we present data on quota usage for prepaid voice/text services and show that users reduce their voice usage when their balances become low. Moreover, when balances are low there is a tendency to shift from voice to SMS. In the second part, we provide descriptive models of both prepaid and postpaid services. The main feature of these models is that there is a background level of potential demand and the rate at which this potential demand is realized depends on the amount of quota balance available. In the third part, we propose utility maximizing models that can account for this type of behavior. In the prepaid case the main feature of the model is a discount function that represents the perceived cost to the user of a quota refill that will occur sometime in the future. In the postpaid case, where the end-user is attempting to get the maximum amount of utility from his monthly quota, we present a dynamic programming formulation in which utility functions are time varying and not known to the user in advance.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W1980885840",
    "type": "article"
  },
  {
    "title": "Resolvers Revealed",
    "doi": "https://doi.org/10.1145/2499926.2499928",
    "publication_date": "2013-07-01",
    "publication_year": 2013,
    "authors": "Craig A. Shue; Andrew J. Kalafut",
    "corresponding_authors": "",
    "abstract": "The Domain Name System (DNS) allows clients to use resolvers, sometimes called caches, to query a set of authoritative servers to translate host names into IP addresses. Prior work has proposed using the interaction between these DNS resolvers and the authoritative servers as an access control mechanism. However, while prior work has examined the DNS from many angles, the resolver component has received little scrutiny. Essential factors for using a resolver in an access control system, such as whether a resolver is part of an ISP’s infrastructure or running on an end-user’s system, have not been examined. In this study, we examine DNS resolver behavior and usage, from query patterns and reactions to nonstandard responses to passive association techniques to pair resolvers with their client hosts. In doing so, we discover evidence of security protocol support, misconfigured resolvers, techniques to fingerprint resolvers, and features for detecting automated clients. These measurements can influence the implementation and design of these resolvers and DNS-based access control systems.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W2109588465",
    "type": "article"
  },
  {
    "title": "Show Me You Care",
    "doi": "https://doi.org/10.1145/2996188",
    "publication_date": "2017-02-25",
    "publication_year": 2017,
    "authors": "Jahna Otterbacher; Chee Siang Ang; Marina Litvak; David C. Atkins",
    "corresponding_authors": "",
    "abstract": "Linguistic mimicry, the adoption of another’s language patterns, is a subconscious behavior with pro-social benefits. However, some professions advocate its conscious use in empathic communication. This involves mutual mimicry; effective communicators mimic their interlocutors, who also mimic them back. Since mimicry has often been studied in face-to-face contexts, we ask whether individuals with empathic dispositions have unique communication styles and/or elicit mimicry in mediated communication on Facebook. Participants completed Davis’s Interpersonal Reactivity Index and provided access to Facebook activity. We confirm that dispositional empathy is correlated to the use of particular stylistic features. In addition, we identify four empathy profiles and find correlations to writing style. When a linguistic feature is used, this often “triggers” use by friends. However, the presence of particular features, rather than participant disposition, best predicts mimicry. This suggests that machine-human communications could be enhanced based on recently used features, without extensive user profiling.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W2530032339",
    "type": "article"
  },
  {
    "title": "Processing Affect in Social Media",
    "doi": "https://doi.org/10.1145/2996187",
    "publication_date": "2017-01-04",
    "publication_year": 2017,
    "authors": "Rosa Meo; Emilio Sulis",
    "corresponding_authors": "",
    "abstract": "Emotion analysis in social media is challenging. While most studies focus on positive and negative sentiments, the differentiation between emotions is more difficult. We investigate the problem as a collection of binary classification tasks on the basis of four opposing emotion pairs provided by Plutchik. We processed the content of messages by three alternative methods: structural and lexical features, latent factors, and natural language processing. The final prediction is suggested by classifiers deriving from the state of the art in machine learning. Results are convincing in the possibility to distinguish the emotions pairs in social media.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W2568257901",
    "type": "article"
  },
  {
    "title": "Dual Structure Constrained Multimodal Feature Coding for Social Event Detection from Flickr Data",
    "doi": "https://doi.org/10.1145/3015463",
    "publication_date": "2017-03-27",
    "publication_year": 2017,
    "authors": "Zhenguo Yang; Qing Li; Zheng Lu; Yun Ma; Zhiguo Gong; Wenyin Liu",
    "corresponding_authors": "",
    "abstract": "In this work, a three-stage social event detection (SED) framework is proposed to discover events from Flickr-like data. First, multiple bipartite graphs are constructed for the heterogeneous feature modalities to achieve fused features. Furthermore, considering the geometrical structures of dictionary and data, a dual structure constrained multimodal feature coding model is designed to learn discriminative feature codes by incorporating corresponding regularization terms into the objective. Finally, clustering models utilizing density or label knowledge and data recovery residual models are devised to discover real-world events. The proposed SED approach achieves the highest performance on the MediaEval 2014 SED dataset.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W2600467916",
    "type": "article"
  },
  {
    "title": "Debating Technology for Dialogical Argument",
    "doi": "https://doi.org/10.1145/3007210",
    "publication_date": "2017-06-12",
    "publication_year": 2017,
    "authors": "John Lawrence; Mark Snaith; Barbara Konat; Katarzyna Budzyńska; Chris Reed",
    "corresponding_authors": "",
    "abstract": "Debating technologies, a newly emerging strand of research into computational technologies to support human debating, offer a powerful way of providing naturalistic, dialogue-based interaction with complex information spaces. The full potential of debating technologies for dialogical argument can, however, only be realized once key technical and engineering challenges are overcome, namely data structure, data availability, and interoperability between components. Our aim in this article is to show that the Argument Web, a vision for integrated, reusable, semantically rich resources connecting views, opinions, arguments, and debates online, offers a solution to these challenges. Through the use of a running example taken from the domain of citizen dialogue, we demonstrate for the first time that different Argument Web components focusing on sensemaking, engagement, and analytics can work in concert as a suite of debating technologies for rich, complex, dialogical argument.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W2625365207",
    "type": "article"
  },
  {
    "title": "Interest-Aware Content Discovery in Peer-to-Peer Social Networks",
    "doi": "https://doi.org/10.1145/3176247",
    "publication_date": "2018-05-25",
    "publication_year": 2018,
    "authors": "Yonghong Guo; Lu Liu; Yan Wu; James Hardy",
    "corresponding_authors": "",
    "abstract": "With the increasing popularity and rapid development of Online Social Networks (OSNs), OSNs not only bring fundamental changes to information and communication technologies, but also make an extensive and profound impact on all aspects of our social life. Efficient content discovery is a fundamental challenge for large-scale distributed OSNs. However, the similarity between social networks and online social networks leads us to believe that the existing social theories are useful for improving the performance of social content discovery in online social networks. In this article, we propose an interest-aware social-like peer-to-peer (IASLP) model for social content discovery in OSNs by mimicking ten different social theories and strategies. In the IASLP network, network nodes with similar interests can meet, help each other, and co-operate autonomously to identify useful contents. The presented model has been evaluated and simulated in a dynamic environment with an evolving network. The experimental results show that the recall of IASLP is 20% higher than the existing method SESD while the overhead is 10% lower. The IASLP can generate higher flexibility and adaptability and achieve better performance than the existing methods.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W2803753235",
    "type": "article"
  },
  {
    "title": "Economic Model-Driven Cloud Service Composition",
    "doi": "https://doi.org/10.1145/2651420",
    "publication_date": "2014-10-28",
    "publication_year": 2014,
    "authors": "Zhen Ye; Athman Bouguettaya; Xiaofang Zhou",
    "corresponding_authors": "",
    "abstract": "This article considers cloud service composition from a decision analysis perspective. Traditional QoS-aware composition techniques usually consider the qualities available at the time of the composition because compositions are usually immediately consumed. This is fundamentally different in the cloud environment where the cloud service composition typically lasts for a relatively long period of time. The two most important drivers when composing cloud service are the long-term nature of the composition and the economic motivation for outsourcing tasks to the cloud. We propose an economic model, which we represent as a Bayesian network, to select and compose cloud services. We then leverage influence diagrams to model the cloud service composition. We further extend the traditional influence diagram problem to a hybrid one and adopt an extended Shenoy-Shafer architecture to solve such hybrid influence diagrams that include deterministic chance nodes. In addition, analytical and simulation results are presented to show the performance of the proposed composition approach.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W2077869322",
    "type": "article"
  },
  {
    "title": "Recommendation and Weaving of Reusable Mashup Model Patterns for Assisted Development",
    "doi": "https://doi.org/10.1145/2663500",
    "publication_date": "2014-10-28",
    "publication_year": 2014,
    "authors": "Soudip Roy Chowdhury; Florian Daniel; Fabio Casati",
    "corresponding_authors": "",
    "abstract": "With this article, we give an answer to one of the open problems of mashup development that users may face when operating a model-driven mashup tool, namely the lack of modeling expertise . Although commonly considered simple applications, mashups can also be complex software artifacts depending on the number and types of Web resources (the components) they integrate. Mashup tools have undoubtedly simplified mashup development, yet the problem is still generally nontrivial and requires intimate knowledge of the components provided by the mashup tool, its underlying mashup paradigm, and of how to apply such to the integration of the components. This knowledge is generally neither intuitive nor standardized across different mashup tools and the consequent lack of modeling expertise affects both skilled programmers and end-user programmers alike. In this article, we show how to effectively assist the users of mashup tools with contextual, interactive recommendations of composition knowledge in the form of reusable mashup model patterns. We design and study three different recommendation algorithms and describe a pattern weaving approach for the one-click reuse of composition knowledge. We report on the implementation of three pattern recommender plugins for different mashup tools and demonstrate via user studies that recommending and weaving contextual mashup model patterns significantly reduces development times in all three cases.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W2089508500",
    "type": "article"
  },
  {
    "title": "Taming the Costs of Trustworthy Provenance through Policy Reduction",
    "doi": "https://doi.org/10.1145/3062180",
    "publication_date": "2017-09-09",
    "publication_year": 2017,
    "authors": "Adam Bates; Dave Tian; Grant Hernandez; Thomas Moyer; Kevin Butler; Trent Jaeger",
    "corresponding_authors": "",
    "abstract": "Provenance is an increasingly important tool for understanding and even actively preventing system intrusion, but the excessive storage burden imposed by automatic provenance collection threatens to undermine its value in practice. This situation is made worse by the fact that the majority of this metadata is unlikely to be of interest to an administrator, instead describing system noise or other background activities that are not germane to the forensic investigation. To date, storing data provenance in perpetuity was a necessary concession in even the most advanced provenance tracking systems in order to ensure the completeness of the provenance record for future analyses. In this work, we overcome this obstacle by proposing a policy-based approach to provenance filtering , leveraging the confinement properties provided by Mandatory Access Control (MAC) systems in order to identify and isolate subdomains of system activity for which to collect provenance. We introduce the notion of minimal completeness for provenance graphs, and design and implement a system that provides this property by exclusively collecting provenance for the trusted computing base of a target application. In evaluation, we discover that, while the efficacy of our approach is domain dependent, storage costs can be reduced by as much as 89% in critical scenarios such as provenance tracking in cloud computing data centers. To the best of our knowledge, this is the first policy-based provenance monitor to appear in the literature.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W2755094099",
    "type": "article"
  },
  {
    "title": "SHARE",
    "doi": "https://doi.org/10.1145/3137571",
    "publication_date": "2018-03-07",
    "publication_year": 2018,
    "authors": "Sushil Jajodia; Noseong Park; Edoardo Serra; V. S. Subrahmanian",
    "corresponding_authors": "",
    "abstract": "A “noisy-rich” (NR) cyber-attacker (Lippmann et al. 2012) is one who tries all available vulnerabilities until he or she successfully compromises the targeted network. We develop an adversarial foundation, based on Stackelberg games, for how NR-attackers will explore an enterprise network and how they will attack it, based on the concept of a system vulnerability dependency graph. We develop a mechanism by which the network can be modified by the defender to induce deception by placing honey nodes and apparent vulnerabilities into the network to minimize the expected impact of the NR-attacker’s attacks (according to multiple measures of impact). We also consider the case where the adversary learns from blocked attacks using reinforcement learning. We run detailed experiments with real network data (but with simulated attack data) and show that Stackelberg Honey-based Adversarial Reasoning Engine performs very well, even when the adversary deviates from the initial assumptions made about his or her behavior. We also develop a method for the attacker to use reinforcement learning when his or her activities are stopped by the defender. We propose two stopping policies for the defender: Stop Upon Detection allows the attacker to learn about the defender’s strategy and (according to our experiments) leads to significant damage in the long run, whereas Stop After Delay allows the defender to introduce greater uncertainty into the attacker, leading to better defendability in the long run.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W2791310119",
    "type": "article"
  },
  {
    "title": "An Incentive Mechanism for Crowdsourcing Systems with Network Effects",
    "doi": "https://doi.org/10.1145/3347514",
    "publication_date": "2019-09-19",
    "publication_year": 2019,
    "authors": "Yanjiao Chen; Xu Wang; Baochun Li; Qian Zhang",
    "corresponding_authors": "",
    "abstract": "In a crowdsourcing system, it is important for the crowdsourcer to engineer extrinsic rewards to incentivize the participants. With mobile social networking, a user enjoys an intrinsic benefit when she aligns her behavior with the behavior of others. Referred to as network effects , such an intrinsic benefit becomes more significant as more users join and contribute to the crowdsourcing system. But should a crowdsourcer design her extrinsic rewards differently when such network effects are taken into consideration? In this article, we incorporate network effects as a contributing factor to intrinsic rewards, and study its influence on the design of extrinsic rewards. We show that the number of participating users and their contributions to the crowdsourcing system evolve to a steady equilibrium, thanks to subtle interactions between intrinsic rewards due to network effects and extrinsic rewards offered by the crowdsourcer. Taken network effects into consideration, we design progressively more sophisticated extrinsic reward mechanisms, and propose new and optimal strategies for a crowdsourcer to obtain a higher utility. Through simulations and examples, we demonstrate that with our new strategies, a crowdsourcer is able to attract more participants with higher contributed efforts; and the participants gain higher utilities from both intrinsic and extrinsic rewards.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W2974078292",
    "type": "article"
  },
  {
    "title": "Web Service Compositions with Fuzzy Preferences",
    "doi": "https://doi.org/10.1145/2576231",
    "publication_date": "2014-07-01",
    "publication_year": 2014,
    "authors": "Karim Benouaret; Djamal Benslimane; Allel Hadjali; Mahmoud Barhamgi; Zakaria Maamar; Quan Z. Sheng",
    "corresponding_authors": "",
    "abstract": "Data-driven Web services build on service-oriented technologies to provide an interoperable method of interacting with data sources on top of the Web. Data Web services composition has emerged as a flexible solution to answer users’ complex queries on the fly. However, as the number of Web services on the Web grows quickly, a large number of candidate compositions that would use different (most likely competing) services may be used to answer the same query. User preferences are a key factor that can be used to rank candidate services/compositions and retain only the best ones. In this article, we present a novel approach for computing the top- k data service compositions based on user preferences. In our approach, we model user preferences using fuzzy sets and incorporate them into the composition query. We use an efficient RDF query rewriting algorithm to determine the relevant services that may be used to answer the composition query. We match the (fuzzy) constraints of the relevant services to those of the query and determine their matching degrees using a set of matching methods. We then rank-order the candidate services based on a fuzzification of Pareto dominance and compute the top- k data service compositions. In addition, we introduce a new method for increasing the diversity of returned top- k compositions while maintaining as much as possible the compositions with the highest scores. Finally, we describe the architecture of our system and present a thorough experimental study of our proposed techniques and algorithms. The experimental study demonstrates the efficiency and the effectiveness of our techniques in different settings.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W2143294456",
    "type": "article"
  },
  {
    "title": "Secure Data-Centric Access Control for Smart Grid Services Based on Publish/Subscribe Systems",
    "doi": "https://doi.org/10.1145/3007190",
    "publication_date": "2016-12-07",
    "publication_year": 2016,
    "authors": "Li Duan; Dongxi Liu; Yang Zhang; Shiping Chen; Ren Ping Liu; Bo Cheng; Junliang Chen",
    "corresponding_authors": "",
    "abstract": "The communication systems in existing smart grids mainly take the request/reply interaction model, in which data access is under the direct control of data producers. This tightly controlled interaction model is not scalable to support complex interactions among smart grid services. On the contrary, the publish/subscribe system features a loose coupling communication infrastructure and allows indirect, anonymous and multicast interactions among smart grid services. The publish/subscribe system can thus support scalable and flexible collaboration among smart grid services. However, the access is not under the direct control of data producers, it might not be easy to implement an access control scheme for a publish/subscribe system. In this article, we propose a Data-Centric Access Control Framework (DCACF) to support secure access control in a publish/subscribe model. This framework helps to build scalable smart grid services, while keeping features of service interactions and data confidentiality at the same time. The data published in our DCACF is encrypted with a fully homomorphic encryption scheme, which allows in-grid homomorphic aggregation of the encrypted data. The encrypted data is accompanied by bloom-filter encoded control policies and access credentials to enable indirect access control. We have analyzed the correctness and security of our DCACF and evaluated its performance in a distributed environment.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W2560286535",
    "type": "article"
  },
  {
    "title": "Crowdsourced Mobile Data Transfer with Delay Bound",
    "doi": "https://doi.org/10.1145/2939376",
    "publication_date": "2016-12-22",
    "publication_year": 2016,
    "authors": "Ngoc Do; Ye Zhao; Cheng-Hsin Hsu; Nalini Venkatasubramanian",
    "corresponding_authors": "",
    "abstract": "In this article, we design a crowdsourcing system, CrowdMAC, where mobile devices form a local community or marketplace to share network access and transfer data for each other. CrowdMAC enables (i) mobile clients to select and exploit multiple mobile hotspots in its vicinity for data transfer and (ii) mobile hotspots to open their cellular connectivity to admit/serve delay-bounded requests from mobile users for a fee. The evaluations of CrowdMAC indicate that (i) mobile clients can tune preferred trade-offs between cost and delay through a control knob, (ii) mobile hotspots comply with all delay bounds, and (iii) the system ensures stable and efficient transfer.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W2566100006",
    "type": "article"
  },
  {
    "title": "Incentive-Driven Computation Offloading in Blockchain-Enabled E-Commerce",
    "doi": "https://doi.org/10.1145/3397160",
    "publication_date": "2020-07-07",
    "publication_year": 2020,
    "authors": "Shuiguang Deng; Guanjie Cheng; Hailiang Zhao; Honghao Gao; Jianwei Yin",
    "corresponding_authors": "",
    "abstract": "Blockchain is regarded as one of the most promising technologies to upgrade e-commerce. This article analyzes the challenges that current e-commerce is facing and introduces a new scenario of e-commerce enabled by blockchain. A framework is proposed for mining tasks in this scenario offloaded onto edge servers based on mobile edge computing. Then, the offloading issue is modeled as a multi-constrained optimization problem, and evolutionary algorithms are utilized and re-designed as solvers. The experimental results validate the efficiency of the framework and algorithms and also show that the lower bound of computation resources exists to obtain the maximum overall revenue.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W3088055217",
    "type": "article"
  },
  {
    "title": "Optimally Self-Healing IoT Choreographies",
    "doi": "https://doi.org/10.1145/3386361",
    "publication_date": "2020-07-07",
    "publication_year": 2020,
    "authors": "Jan Seeger; Arne Bröring; Georg Carle",
    "corresponding_authors": "",
    "abstract": "In the industrial Internet of Things domain, applications are moving from the Cloud into the Edge, closer to the devices producing and consuming data. This means that applications move from the scalable and homogeneous Cloud environment into a potentially constrained heterogeneous Edge network. Making Edge applications reliable enough to fulfill Industry 4.0 use cases remains an open research challenge. Maintaining operation of an Edge system requires advanced management techniques to mitigate the failure of devices. This article tackles this challenge with a twofold approach: (1) a policy-enabled failure detector that enables adaptable failure detection and (2) an allocation component for the efficient selection of failure mitigation actions. The parameters and performance of the failure detection approach are evaluated, and the performance of an energy-efficient allocation technique is measured. Finally, a vision for a complete system and an example use case are presented.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W3041188700",
    "type": "article"
  },
  {
    "title": "An Efficient Service Function Chaining Placement Algorithm in Mobile Edge Computing",
    "doi": "https://doi.org/10.1145/3388241",
    "publication_date": "2020-07-07",
    "publication_year": 2020,
    "authors": "Meng Wang; Bo Cheng; Junliang Chen",
    "corresponding_authors": "",
    "abstract": "Mobile Edge Computing (MEC) is a promising network architecture that pushes network control and mobile computing to the network edge. Recent studies propose to deploy MEC applications in the Network Function Virtualization (NFV) environment. The mobile network service in NFV is deployed as a Service Function Chaining (SFC). In the dynamic and resource-limited mobile network, SFC placement aiming at optimizing resource utilization is a challenging problem. In this article, we solve the SFC placement problem in the MEC-NFV environment. We formulate the SFC placement problem as a weighted graph matching problem, including two sub-problems: a graph matching problem and an SFC mapping problem. To efficiently solve the graph matching problem, we propose a Linear Programming–(LP) based approach to calculate the similarity between VNFs and physical nodes. Based on the similarity, we design a Hungarian-based algorithm to solve the SFC mapping problem. Evaluation results show that our proposed LP-based solutions outperform the heuristic algorithms in terms of execution time and resource utilization.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W3046901049",
    "type": "article"
  },
  {
    "title": "Low-cost Security for Next-generation IoT Networks",
    "doi": "https://doi.org/10.1145/3406280",
    "publication_date": "2020-08-31",
    "publication_year": 2020,
    "authors": "Nikolaos Athanasios Anagnostopoulos; Saad Ahmad; Tolga Arul; Daniel Steinmetzer; Matthias Hollick; Stefan Katzenbeisser",
    "corresponding_authors": "",
    "abstract": "In recent years, the ubiquitous nature of Internet-of-Things (IoT) applications as well as the pervasive character of next-generation communication protocols, such as the 5G technology, have become widely evident. In this work, we identify the need for low-cost security in current and next-generation IoT networks and address this demand through the implementation, testing, and validation of an intrinsic low-cost and low-overhead hardware-based security primitive within an inherent network component. In particular, an intrinsic Physical Unclonable Function (PUF) is implemented in the peripheral network module of a tri-band commercial off-the-shelf router. Subsequently, we demonstrate the robustness of this PUF to ambient temperature variations and to limited natural aging, and examine in detail its potential for securing the next generation of IoT networks and other applications. Finally, the security of the proposed PUF-based schemes is briefly assessed and discussed.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W3083277790",
    "type": "article"
  },
  {
    "title": "PANOLA: A Personal Assistant for Supporting Users in Preserving Privacy",
    "doi": "https://doi.org/10.1145/3471187",
    "publication_date": "2021-09-14",
    "publication_year": 2021,
    "authors": "Onuralp Ulusoy; Pınar Yolum",
    "corresponding_authors": "",
    "abstract": "Privacy is the right of individuals to keep personal information to themselves. When individuals use online systems, they should be given the right to decide what information they would like to share and what to keep private. When a piece of information pertains only to a single individual, preserving privacy is possible by providing the right access options to the user. However, when a piece of information pertains to multiple individuals, such as a picture of a group of friends or a collaboratively edited document, deciding how to share this information and with whom is challenging. The problem becomes more difficult when the individuals who are affected by the information have different, possibly conflicting privacy constraints. Resolving this problem requires a mechanism that takes into account the relevant individuals’ concerns to decide on the privacy configuration of information. Because these decisions need to be made frequently (i.e., per each piece of shared content), the mechanism should be automated. This article presents a personal assistant to help end-users with managing the privacy of their content. When some content that belongs to multiple users is about to be shared, the personal assistants of the users employ an auction-based privacy mechanism to regulate the privacy of the content. To do so, each personal assistant learns the preferences of its user over time and produces bids accordingly. Our proposed personal assistant is capable of assisting users with different personas and thus ensures that people benefit from it as they need it. Our evaluations over multiagent simulations with online social network content show that our proposed personal assistant enables privacy-respecting content sharing.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W3199318068",
    "type": "article"
  },
  {
    "title": "A Novel Memory-hard Password Hashing Scheme for Blockchain-based Cyber-physical Systems",
    "doi": "https://doi.org/10.1145/3408310",
    "publication_date": "2021-03-08",
    "publication_year": 2021,
    "authors": "Ye Luo; Zehai Su; Wei Zheng; Zhaobin Chen; Fuqin Wang; Zhemin Zhang; Jinjun Chen",
    "corresponding_authors": "",
    "abstract": "There has been an increasing interest of integrating blockchain into cyber-physical systems (CPS). The design of password hashing schemes (PHSs) is in the core of blockchain security. However, no existing PHS seems to meet both the requirements of sufficient security and small code size for blockchain-based CPSs. In this article, a novel memory-hard PHS based on the classic PBKDF2 is proposed. Evaluation results show that the proposed scheme is promising for blockchain-based CPS, as it manages to provide enhanced security in comparison to PBKDF2 with limited increase in code size.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W3135413188",
    "type": "article"
  },
  {
    "title": "A Green Stackelberg-game Incentive Mechanism for Multi-service Exchange in Mobile Crowdsensing",
    "doi": "https://doi.org/10.1145/3421506",
    "publication_date": "2021-10-22",
    "publication_year": 2021,
    "authors": "Jianfeng Lu; Zhao Zhang; Jiangtao Wang; Ruixuan Li; Shaohua Wan",
    "corresponding_authors": "",
    "abstract": "Although mobile crowdsensing (MCS) has become a green paradigm of collecting, analyzing, and exploiting massive amounts of sensory data, existing incentive mechanisms are not effective to stimulate users’s active participation and service contribution in multi-service exchange in MCS due to its specific features: a large number of heterogeneous users have asymmetric service requirements, workers have the freedom to choose sensing tasks as well as participation levels, and multiple sensing tasks have heterogeneous values which may be untruthful declared by the corresponding requesters. To address this issue, this article develops a green Stackelberg-game incentive mechanism to achieve selective fairness, truthfulness, and bounded efficiency while reducing the burden on the platform. First, we model the multi-service exchange problem as a Stackelberg multi-service exchange game consisting of multi-leader and multi-follower, in which each requester as a leader first chooses the reward declaration strategy and thus the payment for each sensing task, each worker as a follower then chooses the sensing plan strategy to maximize her own utility. We next introduce the concept of virtual currency to maintain the selective fairness to balance service request and service provision between users, in which a user earns/consumes virtual currency for providing/receiving services, and thus no one can always get services without providing services. Then, we present two novel algorithms to compute the unique Nash equilibrium for the sensing plan determination game and the reward declaration determination game, respectively, which together forms a unique Stackelberg equilibrium for the proposed game. Afterwards, we theoretically prove that the proposed green Stackelberg-game incentive mechanism achieves the desirable properties of selective fairness, truthfulness, bounded efficiency. Finally, extensive evaluation results are provided to support the validity and effectiveness of our mechanism compared with both baseline and theoretical optimal approaches.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W3210597116",
    "type": "article"
  },
  {
    "title": "Reaching for the Sky: Maximizing Deep Learning Inference Throughput on Edge Devices with AI Multi-Tenancy",
    "doi": "https://doi.org/10.1145/3546192",
    "publication_date": "2022-07-04",
    "publication_year": 2022,
    "authors": "Jianwei Hao; Piyush Subedi; Lakshmish Ramaswamy; In Kee Kim",
    "corresponding_authors": "",
    "abstract": "The wide adoption of smart devices and Internet-of-Things (IoT) sensors has led to massive growth in data generation at the edge of the Internet over the past decade. Intelligent real-time analysis of such a high volume of data, particularly leveraging highly accurate deep learning (DL) models, often requires the data to be processed as close to the data sources (or at the edge of the Internet) to minimize the network and processing latency. The advent of specialized, low-cost, and power-efficient edge devices has greatly facilitated DL inference tasks at the edge. However, limited research has been done to improve the inference throughput (e.g., number of inferences per second) by exploiting various system techniques. This study investigates system techniques, such as batched inferencing, AI multi-tenancy, and cluster of AI accelerators, which can significantly enhance the overall inference throughput on edge devices with DL models for image classification tasks. In particular, AI multi-tenancy enables collective utilization of edge devices’ system resources (CPU, GPU) and AI accelerators (e.g., Edge Tensor Processing Units; EdgeTPUs). The evaluation results show that batched inferencing results in more than 2.4× throughput improvement on devices equipped with high-performance GPUs like Jetson Xavier NX. Moreover, with multi-tenancy approaches, e.g., concurrent model executions (CME) and dynamic model placements (DMP), the DL inference throughput on edge devices (with GPUs) and EdgeTPU can be further improved by up to 3× and 10×, respectively. Furthermore, we present a detailed analysis of hardware and software factors that change the DL inference throughput on edge devices and EdgeTPUs, thereby shedding light on areas that could be further improved to achieve high-performance DL inference at the edge.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W4283810142",
    "type": "article"
  },
  {
    "title": "Dynamic Personalized POI Sequence Recommendation with Fine-Grained Contexts",
    "doi": "https://doi.org/10.1145/3583687",
    "publication_date": "2023-02-13",
    "publication_year": 2023,
    "authors": "Jing Chen; Wenjun Jiang; Jie Wu; Kenli Li; Keqin Li",
    "corresponding_authors": "",
    "abstract": "The Point Of Interest (POI) sequence recommendation is the key task in itinerary and travel route planning. Existing works usually consider the temporal and spatial factors in travel planning. However, the external environment, such as the weather, is usually overlooked. In fact, the weather is an important factor because it can affect a user’s check-in behaviors. Furthermore, most of the existing research is based on a static environment for POI sequence recommendation. While the external environment (e.g., the weather) may change during travel, it is difficult for existing works to adjust the POI sequence in time. What’s more, people usually prefer the attractive routes when traveling. To address these issues, we first conduct comprehensive data analysis on two real-world check-in datasets to study the effects of weather and time, as well as the features of the POI sequence. Based on this, we propose a model of Dynamic Personalized POI Sequence Recommendation with fine-grained contexts ( DPSR for short). It extracts user interest and POI popularity with fine-grained contexts and captures the attractiveness of the POI sequence. Next, we apply the Monte Carlo Tree Search model (MCTS for short) to simulate the process of recommending POI sequence in the dynamic environment, i.e., the weather and time change after visiting a POI. What’s more, we consider different speeds to reflect the fact that people may take different transportation to transfer between POIs. To validate the efficacy of DPSR , we conduct extensive experiments. The results show that our model can improve the accuracy of the recommendation significantly. Furthermore, it can better meet user preferences and enhance experiences.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W4320497607",
    "type": "article"
  },
  {
    "title": "LinkSelector",
    "doi": "https://doi.org/10.1145/990301.990306",
    "publication_date": "2004-05-01",
    "publication_year": 2004,
    "authors": "Xiao Fang; Olivia R. Liu Sheng",
    "corresponding_authors": "",
    "abstract": "As the size and complexity of Web sites expands dramatically, it has become increasingly challenging to design Web sites where Web surfers can easily find the information they seek. In this article, we address the design of the portal page of a Web site, which serves as the homepage of a Web site or a default Web portal. We define an important research problem---hyperlink selection: selecting from a large set of hyperlinks in a given Web site, a limited number of hyperlinks for inclusion in a portal page. The objective of hyperlink selection is to maximize the efficiency, effectiveness, and usage of a Web site's portal page. We propose a heuristic approach to hyperlink selection, LinkSelector, which is based on relationships among hyperlinks---structural relationships that can be extracted from an existing Web site and access relationships that can be discovered from a Web log. We compared the performance of LinkSelector with that of the current practice of hyperlink selection (i.e., manual hyperlink selection by domain experts), using data obtained from the University of Arizona Web site. Results showed that LinkSelector outperformed the current manual selection method.",
    "cited_by_count": 30,
    "openalex_id": "https://openalex.org/W1974467206",
    "type": "article"
  },
  {
    "title": "Supporting intelligent Web search",
    "doi": "https://doi.org/10.1145/1278366.1278369",
    "publication_date": "2007-10-01",
    "publication_year": 2007,
    "authors": "Maurice Coyle; Barry Smyth",
    "corresponding_authors": "",
    "abstract": "Search engines continue to struggle to provide everyday users with a service capable of delivering focussed results that are relevant to their information needs. Moreover, traditional search engines really only provide users with a starting point for their information search. That is, upon selecting a page from a search result list, the interaction between user and search engine is effectively over and the user must continue their search alone. In this article, we argue that a comprehensive search service needs to provide the user with more help, both at the result list level and beyond, and we outline some recommendations for intelligent Web search support. We introduce the SearchGuide Web search support system and we describe how it fulfils the requirements for a search support system, providing evaluation results where applicable.",
    "cited_by_count": 26,
    "openalex_id": "https://openalex.org/W2005200579",
    "type": "article"
  },
  {
    "title": "Introduction to special issue on semantic Web services",
    "doi": "https://doi.org/10.1145/1294148.1294149",
    "publication_date": "2007-11-01",
    "publication_year": 2007,
    "authors": "Brahim Medjahed; Athman Bouguettaya; Boualem Benatallah",
    "corresponding_authors": "",
    "abstract": "introduction Introduction to special issue on semantic Web services Editors: Brahim Medjahed View Profile , Athman Bouguettaya View Profile , Boualem Benatallah View Profile Authors Info & Claims ACM Transactions on Internet TechnologyVolume 8Issue 1pp 1–eshttps://doi.org/10.1145/1294148.1294149Published:01 November 2007Publication History 3citation881DownloadsMetricsTotal Citations3Total Downloads881Last 12 Months1Last 6 weeks0 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteGet Access",
    "cited_by_count": 26,
    "openalex_id": "https://openalex.org/W2035236050",
    "type": "article"
  },
  {
    "title": "Nearcast",
    "doi": "https://doi.org/10.1145/1323651.1323653",
    "publication_date": "2008-02-01",
    "publication_year": 2008,
    "authors": "Xuping Tu; Hai Jin; Xiaofei Liao; Jiannong Cao",
    "corresponding_authors": "",
    "abstract": "Peer-to-peer (P2P) live video streaming has been widely used in distance education applications to deliver the captured video courses to a large number of online students. By allowing peers serving each other in the network, P2P technology overcomes many limitations in the traditional client-server paradigm to achieve user and bandwidth scalabilities. However, existing systems do not perform well when the number of online students increases, and the system performance degrades seriously. One of the reasons is that the construction of the peer overlay in existing P2P systems has not considered the underlying physical network topology and can cause serious topology mismatch between the P2P overlay network and the physical network. The topology mismatch problem brings great link stress (unnecessary traffic) in the Internet infrastructure and greatly degrades the system performance. In this article, we address this problem and propose a locality-aware P2P overlay construction method, called Nearcast , which builds an efficient overlay multicast tree by letting each peer node choose physically closer nodes as its logical children. We have conducted extensive simulations to evaluate the performance of Nearcast in comparison with the existing RTT and NICE protocols. Also, Nearcast has been deployed on a wide-area network testbed to delivery video coursed to about 7200 users distributed across 100 collages in 32 cities in China. The experimental results show that Nearcast leads to lower link stress and shorter end-to-end latencies compared with the RTT and NICE protocols.",
    "cited_by_count": 25,
    "openalex_id": "https://openalex.org/W2041073832",
    "type": "article"
  },
  {
    "title": "A framework for personalizing web search with concept-based user profiles",
    "doi": "https://doi.org/10.1145/2109211.2109214",
    "publication_date": "2008-03-23",
    "publication_year": 2008,
    "authors": "Kenneth Wai-Ting Leung; Dik Lun Lee; Wilfred Ng; Hing Yuet Fung",
    "corresponding_authors": "",
    "abstract": "Personalized search is an important means to improve the performance of a search engine. In this article, we propose a framework that supports mining a user's conceptual preferences from users' clickthrough data resulting from Web search. The discovered preferences are utilized to adapt a search engine's ranking function. In this framework, an extended set of conceptual preferences was derived for a user based on the concepts extracted from the search results and the clickthrough data. Then, a concept-based user profile (CUP) representing the user profile as a concept ontology tree is generated. Finally, the CUP is input to a support vector machine (SVM) to learn a concept preference vector for adapting a personalized ranking function that reranks the search results. In order to achieve more flexible personalization, the framework allows a user to control the amount of specific CUP ontology information to be exposed to the personalized search engine. We study various parameters, such as conceptual relationships and concept features, arising from CUP that affect the ranking quality. Experiments confirm that our approach is able to significantly improve the retrieval effectiveness for the user. Further, our proposed control parameters of CUP information can adjust the exposed user information more smoothly and maintain better ranking quality than the existing methods.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W1972076305",
    "type": "article"
  },
  {
    "title": "Retrieving XML data from heterogeneous sources through vague querying",
    "doi": "https://doi.org/10.1145/1516539.1516542",
    "publication_date": "2009-05-01",
    "publication_year": 2009,
    "authors": "Bettina Fazzinga; Sergio Flesca; Andrea Pugliese",
    "corresponding_authors": "",
    "abstract": "We propose a framework for querying heterogeneous XML data sources. The framework ensures high autonomy to participating sources as it does not rely on a global schema or on semantic mappings between schemas. The basic intuition is that of extending traditional approaches for approximate query evaluation, by providing techniques for combining partial answers coming from different sources, possibly on the basis of limited knowledge about the local schemas (i.e., key constraints). We define a query language and its associated semantics, that allows us to collect as much information as possible from several heterogeneous XML sources. We provide algorithms for query evaluation and characterize the complexity of the query language. Finally, we validate the approach in a medical application scenario.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W2024730542",
    "type": "article"
  },
  {
    "title": "Context-aware web search in ubiquitous sensor environments",
    "doi": "https://doi.org/10.1145/2078316.2078320",
    "publication_date": "2012-01-01",
    "publication_year": 2012,
    "authors": "Takuya Maekawa; Yutaka Yanagisawa; Yasushi Sakurai; Yasue Kishino; Koji Kamei; Takeshi Okadome",
    "corresponding_authors": "",
    "abstract": "This article proposes a new concept for a context-aware Web search method that automatically retrieves a webpage related to the daily activity that a user currently is engaged in and displays the page on nearby Internet-connected home appliances such as televisions. For example, when a user is washing a coffeemaker, a webpage is retrieved that includes tips such as “cleaning a coffee maker with vinegar removes stains well,” and the page is displayed on a nearby appliance. In this article, we design and implement a Web search method that employs ubiquitous sensors to monitor a user's daily life. Our proposed method automatically searches for a webpage related to a daily activity by using a query constructed from the use of daily objects employed in the activity that is detected with object-attached sensors. We evaluate the search method with real datasets collected from vast numbers of sensors and achieve very accurate webpage retrieval. We then investigate the usefulness and effectiveness of a daily life Web search with Wizard-of-Oz (WOz)-like experiments. We confirm that the presentation of webpages related to daily activities improves participants' future daily lives and triggers communication among the participants in the experiment.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W2009694489",
    "type": "article"
  },
  {
    "title": "Duplicate Detection in Programming Question Answering Communities",
    "doi": "https://doi.org/10.1145/3169795",
    "publication_date": "2018-04-17",
    "publication_year": 2018,
    "authors": "Wei Emma Zhang; Quan Z. Sheng; Jey Han Lau; Ermyas Abebe; Wenjie Ruan",
    "corresponding_authors": "",
    "abstract": "Community-based Question Answering (CQA) websites are attracting increasing numbers of users and contributors in recent years. However, duplicate questions frequently occur in CQA websites and are currently manually identified by the moderators. Automatic duplicate detection, on one hand, alleviates this laborious effort for moderators before taking close actions, and, on the other hand, helps question issuers quickly find answers. A number of studies have looked into related problems, but very limited works target Duplicate Detection in Programming CQA (PCQA), a branch of CQA that is dedicated to programmers. Existing works framed the task as a supervised learning problem on the question pairs and relied on only textual features. Moreover, the issue of selecting candidate duplicates from large volumes of historical questions is often un-addressed. To tackle these issues, we model duplicate detection as a two-stage “ranking-classification” problem over question pairs. In the first stage, we rank the historical questions according to their similarities to the newly issued question and select the top ranked ones as candidates to reduce the search space. In the second stage, we develop novel features that capture both textual similarity and latent semantics on question pairs, leveraging techniques in deep learning and information retrieval literature. Experiments on real-world questions about multiple programming languages demonstrate that our method works very well; in some cases, up to 25% improvement compared to the state-of-the-art benchmarks.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W2802763641",
    "type": "article"
  },
  {
    "title": "Grouping Peers Based on Complementary Degree and Social Relationship using Genetic Algorithm",
    "doi": "https://doi.org/10.1145/3193180",
    "publication_date": "2018-10-16",
    "publication_year": 2018,
    "authors": "Timothy K. Shih; W. K. T. M. Gunarathne; Ankhtuya Ochirbat; Huang-Ming Su",
    "corresponding_authors": "",
    "abstract": "The aim of this article is to propose a new innovative grouping approach using the genetic algorithm (GA) to enhance the interaction and collaboration among peers by considering the complementary degree of students’ learning status and their social relationships. In order to validate our approach, experiments were designed with a group of students and the outcomes were tested with an e-Learning system. The auto-grouping mechanism is developed using GA for better learning results, which is justified based on the performance of students tested on the e-Learning system. The outcomes clearly indicate that the proposed approach can generate a high degree of heterogeneous grouping and encourage students to learn better. The technical contribution of this article can be implemented in any massive open online course platforms with thousands of students, with regard to identifying peers for collaborative works.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W2896232181",
    "type": "article"
  },
  {
    "title": "Context-aware services engineering",
    "doi": "https://doi.org/10.1145/2078316.2078318",
    "publication_date": "2012-01-01",
    "publication_year": 2012,
    "authors": "Dhaminda B. Abeywickrama; Sita Ramakrishnan",
    "corresponding_authors": "",
    "abstract": "Context-aware Web services are identified as an important technology to support new applications on the future Internet. Context information has several qualities that make the development of these services challenging, compared to conventional, Web services. Therefore, sound software engineering practices are needed during their development and execution. This article discusses a novel software engineering-based approach, which leverages the benefits of model-driven architecture, aspect-oriented modeling, and formal model checking, for modeling and verifying context-aware services. The approach is explored using a real-world case study in intelligent transport. An evaluation framework is established to validate the main methods and tools employed.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W1978310632",
    "type": "article"
  },
  {
    "title": "Efficient Stream Provenance via Operator Instrumentation",
    "doi": "https://doi.org/10.1145/2633689",
    "publication_date": "2014-07-15",
    "publication_year": 2014,
    "authors": "Boris Glavic; Kyumars Sheykh Esmaili; Peter M. Fischer; Nesime Tatbul",
    "corresponding_authors": "",
    "abstract": "Managing fine-grained provenance is a critical requirement for data stream management systems (DSMS), not only for addressing complex applications that require diagnostic capabilities and assurance, but also for providing advanced functionality, such as revision processing or query debugging. This article introduces a novel approach that uses operator instrumentation, that is, modifying the behavior of operators, to generate and propagate fine-grained provenance through several operators of a query network. In addition to applying this technique to compute provenance eagerly during query execution, we also study how to decouple provenance computation from query processing to reduce runtime overhead and avoid unnecessary provenance retrieval. Our proposals include computing a concise superset of the provenance (to allow lazily replaying a query and reconstruct its provenance) as well as lazy retrieval (to avoid unnecessary reconstruction of provenance). We develop stream-specific compression methods to reduce the computational and storage overhead of provenance generation and retrieval. Ariadne, our provenance-aware extension of the Borealis DSMS implements these techniques. Our experiments confirm that Ariadne manages provenance with minor overhead and clearly outperforms query rewrite, the current state of the art.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W2067082584",
    "type": "article"
  },
  {
    "title": "Event Recognition Challenges and Techniques",
    "doi": "https://doi.org/10.1145/2632220",
    "publication_date": "2014-07-15",
    "publication_year": 2014,
    "authors": "Alexander Artikis; Avigdor Gal; Vana Kalogeraki; Matthias Weidlich",
    "corresponding_authors": "",
    "abstract": "research-article Free Access Share on Event Recognition Challenges and Techniques: Guest Editors' Introduction Authors: Alexander Artikis NCSR \"Demokritos\", Greece NCSR \"Demokritos\", GreeceView Profile , Avigdor Gal Technion -- Israel Institute of Technology, Israel Technion -- Israel Institute of Technology, IsraelView Profile , Vana Kalogeraki Athens University of Ecenomics and Business, Greece Athens University of Ecenomics and Business, GreeceView Profile , Matthias Weidlich Imperial College London, UK Imperial College London, UKView Profile Authors Info & Claims ACM Transactions on Internet TechnologyVolume 14Issue 1July 2014 Article No.: 1pp 1–9https://doi.org/10.1145/2632220Published:07 August 2014Publication History 8citation511DownloadsMetricsTotal Citations8Total Downloads511Last 12 Months31Last 6 weeks4 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my Alerts New Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W2074394551",
    "type": "article"
  },
  {
    "title": "Interaction-Based Recommendations for Online Communities",
    "doi": "https://doi.org/10.1145/2774974",
    "publication_date": "2015-06-24",
    "publication_year": 2015,
    "authors": "‪Surya Nepal‬; Cécile Paris; Payam Aghaei Pour; Jill Freyne; Sanat Kumar Bista",
    "corresponding_authors": "",
    "abstract": "A key challenge in online communities is that of keeping a community active and alive. All online communities work hard to keep their members through various initiatives, such as personalisation and recommendation technologies. In online communities aimed at supporting behavioural change, that is, in domains such as diet, lifestyle, or the environment, the main reason for participation is not to connect with real-world friends for sharing and communicating, but to meet and gain support from like-minded people in an online environment. Introducing personalisation and recommendation features in these networks is challenging, as traditional approaches leverage the densely populated friendship relations found in typical social networks, and these are not present in these new community types. We address this challenge by looking beyond the articulated friendships of a community for evidence of relationships. In particular, we look at the interactions of members of an online community with other members and resources. In this article, we present a social behaviour model and apply it to two types of recommendation systems, a people recommender and a content recommender system. We evaluate our systems using the interaction logs of an online diet and lifestyle community in which 5,000 Australians participated in a 12-week programme. Our results show that our social behaviour-based recommendation algorithms outperform baselines, friendship-based, and link-prediction algorithms.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W2243017609",
    "type": "article"
  },
  {
    "title": "It Is an Equal Failing to Trust Everybody and to Trust Nobody",
    "doi": "https://doi.org/10.1145/3338855",
    "publication_date": "2019-09-13",
    "publication_year": 2019,
    "authors": "Teng-Chieh Huang; Razieh Nokhbeh Zaeem; K. Suzanne Barber",
    "corresponding_authors": "",
    "abstract": "Social media are providing a huge amount of information, in scales never possible before. Sentiment analysis is a powerful tool that uses social media information to predict various target domains (e.g., the stock market). However, social media information may or may not come from trustworthy users. To utilize this information, a very first critical problem to solve is to filter credible and trustworthy information from contaminated data, advertisements, or scams. We investigate different aspects of a social media user to score his/her trustworthiness and credibility. Furthermore, we provide suggestions on how to improve trustworthiness on social media by analyzing the contribution of each trust score. We apply trust scores to filter the tweets related to the stock market as an example target domain. While social media sentiment analysis has been on the rise over the past decade, our trust filters enhance conventional sentiment analysis methods and provide more accurate prediction of the target domain, here, the stock market. We argue that while it is a failing to ignore the information social media provide, effectively trusting nobody, it is an equal failing to trust everybody on social media too: Our filters seek to identify whom to trust.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W2973080893",
    "type": "article"
  },
  {
    "title": "Strategic Formation of Credit Networks",
    "doi": "https://doi.org/10.1145/2700058",
    "publication_date": "2015-03-12",
    "publication_year": 2015,
    "authors": "Pranav Dandekar; Ashish Goel; Michael P. Wellman; Bryce Wiedenbeck",
    "corresponding_authors": "",
    "abstract": "Credit networks are an abstraction for modeling trust among agents in a network. Agents who do not directly trust each other can transact through exchange of IOUs (obligations) along a chain of trust in the network. Credit networks are robust to intrusion, can enable transactions between strangers in exchange economies, and have the liquidity to support a high rate of transactions. We study the formation of such networks when agents strategically decide how much credit to extend each other. We find strong positive network formation results for the simplest theoretical model. When each agent trusts a fixed set of other agents and transacts directly only with those it trusts, all pure-strategy Nash equilibria are social optima. However, when we allow transactions over longer paths, the price of anarchy may be unbounded. On the positive side, when agents have a shared belief about the trustworthiness of each agent, simple greedy dynamics quickly converge to a star-shaped network, which is a social optimum. Similar star-like structures are found in equilibria of heuristic strategies found via simulation studies. In addition, we simulate environments where agents may have varying information about each others’ trustworthiness based on their distance in a social network. Empirical game analysis of these scenarios suggests that star structures arise only when defaults are relatively rare, and otherwise, credit tends to be issued over short social distances conforming to the locality of information. Overall, we find that networks formed by self-interested agents achieve a high fraction of available value, as long as this potential value is large enough to enable any network to form.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W2043446118",
    "type": "article"
  },
  {
    "title": "PADUA",
    "doi": "https://doi.org/10.1145/2633685",
    "publication_date": "2014-07-15",
    "publication_year": 2014,
    "authors": "Cristian Molinaro; Vincenzo Moscato; Antonio Picariello; Andrea Pugliese; Antonino Rullo; V. S. Subrahmanian",
    "corresponding_authors": "",
    "abstract": "There are numerous applications (e.g., video surveillance, fraud detection, cybersecurity) in which we wish to identify unexplained sets of events. Most related past work has been domain-dependent (e.g., video surveillance, cybersecurity) and has focused on the valuable class of statistical anomalies in which statistically unusual events are considered. In contrast, suppose there is a set A of known activity models (both harmless and harmful) and a log L of time-stamped observations. We define a part L '⊆ L of the log to represent an unexplained situation when none of the known activity models can explain L ' with a score exceeding a user-specified threshold. We represent activities via probabilistic penalty graphs (PPGs) and show how a set of PPGs can be combined into one Super-PPG for which we define an index structure. Given a compute cluster of ( K + 1) nodes (one of which is a master node), we show how to split a Super-PPG into K subgraphs, each of which can be independently processed by a compute node. We provide algorithms for the individual compute nodes to ensure seamless handoffs that maximally leverage parallelism. PADUA is domain-independent and can be applied to many domains (perhaps with some specialization). We conducted detailed experiments with PADUA on two real-world datasets—the ITEA CANDELA video surveillance dataset and a network traffic dataset appropriate for cybersecurity applications. PADUA scales extremely well with the number of processors and significantly outperforms past work both in accuracy and time. Thus, PADUA represents the first parallel architecture and algorithm for identifying unexplained situations in observation data, offering both scalability and accuracy.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W2049463731",
    "type": "article"
  },
  {
    "title": "ODIN",
    "doi": "https://doi.org/10.1145/3137573",
    "publication_date": "2017-10-26",
    "publication_year": 2017,
    "authors": "Moreno Ambrosin; Paolo Braca; Mauro Conti; Riccardo Lazzeretti",
    "corresponding_authors": "",
    "abstract": "The large spread of sensors and smart devices in urban infrastructures are motivating research in the area of the Internet of Things (IoT) to develop new services and improve citizens’ quality of life. Sensors and smart devices generate large amounts of measurement data from sensing the environment, which is used to enable services such as control of power consumption or traffic density. To deal with such a large amount of information and provide accurate measurements, service providers can adopt information fusion, which given the decentralized nature of urban deployments can be performed by means of consensus algorithms. These algorithms allow distributed agents to (iteratively) compute linear functions on the exchanged data, and take decisions based on the outcome, without the need for the support of a central entity. However, the use of consensus algorithms raises several security concerns, especially when private or security critical information is involved in the computation. In this article we propose ODIN, a novel algorithm allowing information fusion over encrypted data. ODIN is a privacy-preserving extension of the popular consensus gossip algorithm, which prevents distributed agents from having direct access to the data while they iteratively reach consensus; agents cannot access even the final consensus value but can only retrieve partial information (e.g., a binary decision). ODIN uses efficient additive obfuscation and proxy re-encryption during the update steps and garbled circuits to make final decisions on the obfuscated consensus. We discuss the security of our proposal and show its practicability and efficiency on real-world resource-constrained devices, developing a prototype implementation for Raspberry Pi devices.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W2545726756",
    "type": "article"
  },
  {
    "title": "Implementing and Evaluating a Laughing Virtual Character",
    "doi": "https://doi.org/10.1145/2998571",
    "publication_date": "2017-02-25",
    "publication_year": 2017,
    "authors": "Maurizio Mancini; Béatrice Biancardi; Florian Pécune; Giovanna Varni; Yu Ding; Catherine Pélachaud; Gualtiero Volpe; Antonio Camurri",
    "corresponding_authors": "",
    "abstract": "Laughter is a social signal capable of facilitating interaction in groups of people: it communicates interest, helps to improve creativity, and facilitates sociability. This article focuses on: endowing virtual characters with computational models of laughter synthesis, based on an expressivity-copying paradigm; evaluating how the physically co-presence of the laughing character impacts on the user’s perception of an audio stimulus and mood. We adopt music as a means to stimulate laughter. Results show that the character presence influences the user’s perception of music and mood. Expressivity-copying has an influence on the user’s perception of music, but does not have any significant impact on mood.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W2594814318",
    "type": "article"
  },
  {
    "title": "FinPrivacy: A Privacy-preserving Mechanism for Fingerprint Identification",
    "doi": "https://doi.org/10.1145/3387130",
    "publication_date": "2020-07-07",
    "publication_year": 2020,
    "authors": "Tao Wang; Zhigao Zheng; Ali Kashif Bashir; Alireza Jolfaei; Yanyan Xu",
    "corresponding_authors": "",
    "abstract": "Fingerprint provides an extremely convenient way of identification for a wide range of real-life applications owing to its universality, uniqueness, collectability, and invariance. However, digitized fingerprints may reveal the privacy of individuals. Differential privacy is a promising privacy-preserving solution that is enforced by injecting random noise into preserved objects, such that an adversary with arbitrary background knowledge cannot infer private input from the noisy results. This study proposes FinPrivacy, a privacy-preserving mechanism for fingerprint identification. This mechanism utilizes the low-rank matrix approximation to reduce the dimensionality of fingerprint and the exponential mechanism to carefully determine the value of the optimal rank. Thereafter, FinPrivacy injects Laplace noise to the singular values of the approximated singular matrix, thereby trading off between privacy and utility. Analytic proofs and results of the comparative experiments demonstrate that FinPrivacy can simultaneously enforce ɛ-differential privacy and maintain an efficient fingerprint recognition.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W3025146032",
    "type": "article"
  },
  {
    "title": "IoT Architecture for Urban Data-Centric Services and Applications",
    "doi": "https://doi.org/10.1145/3396850",
    "publication_date": "2020-07-07",
    "publication_year": 2020,
    "authors": "Marcin Luckner; Maciej Grzenda; Robert Kunicki; Jarosław Legierski",
    "corresponding_authors": "",
    "abstract": "In this work, we describe an urban Internet of Things (IoT) architecture, grounded in big data patterns and focused on the needs of cities and their key stakeholders. First, the architecture of the dedicated platform USE4IoT (Urban Service Environment for the Internet of Things), which gathers and processes urban big data and extends the Lambda architecture, is proposed. We describe how the platform was used to make IoT an enabling technology for intelligent transport planning. Moreover, key data processing components vital to provide high-quality IoT data streams in a near-real-time manner are defined. Furthermore, tests showing how the IoT platform described in this study provides a low-latency analytical environment for smart cities are included.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W3041416885",
    "type": "article"
  },
  {
    "title": "The Influence of Trust Score on Cooperative Behavior",
    "doi": "https://doi.org/10.1145/3329250",
    "publication_date": "2019-09-13",
    "publication_year": 2019,
    "authors": "Claudia‐Lavinia Ignat; Quang-Vinh Dang; Valerie L. Shalin",
    "corresponding_authors": "",
    "abstract": "The assessment of trust between users is essential for collaboration. General reputation and ID mechanisms may support users’ trust assessment. However, these mechanisms lack sensitivity to pairwise interactions and specific experience such as betrayal over time. Moreover, they place an interpretation burden that does not scale to dynamic, large-scale systems. While several pairwise trust mechanisms have been proposed, no empirical research examines trust score influence on participant behavior. We study the influence of showing a partner trust score and/or ID on participants’ behavior in a small-group collaborative laboratory experiment based on the trust game. We show that trust score availability has the same effect as an ID to improve cooperation as measured by sending behavior and receiver response. Excellent models based on the trust score predict sender behavior and document participant sensitivity to the provision of partner information. Models based on the trust score for recipient behavior have some predictive ability regarding trustworthiness, but suggest the need for more complex functions relating experience to participant response. We conclude that the parameters of a trust score, including pairwise interactions and betrayal, influence the different roles of participants in the trust game differently, but complement traditional ID and have the advantage of scalability.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W3123567294",
    "type": "article"
  },
  {
    "title": "A User-Centric Mechanism for Sequentially Releasing Graph Datasets under Blowfish Privacy",
    "doi": "https://doi.org/10.1145/3431501",
    "publication_date": "2021-02-17",
    "publication_year": 2021,
    "authors": "Elie Chicha; Béchara Al Bouna; Mohamed Nassar; Richard Chbeir; Ramzi A. Haraty; Mourad Oussalah; Djamal Benslimane; Mansour Naser Alraja",
    "corresponding_authors": "",
    "abstract": "In this article, we present a privacy-preserving technique for user-centric multi-release graphs. Our technique consists of sequentially releasing anonymized versions of these graphs under Blowfish Privacy. To do so, we introduce a graph model that is augmented with a time dimension and sampled at discrete time steps. We show that the direct application of state-of-the-art privacy-preserving Differential Private techniques is weak against background knowledge attacker models. We present different scenarios where randomizing separate releases independently is vulnerable to correlation attacks. Our method is inspired by Differential Privacy (DP) and its extension Blowfish Privacy (BP). To validate it, we show its effectiveness as well as its utility by experimental simulations.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W3131395855",
    "type": "article"
  },
  {
    "title": "An Effective Hyperparameter Optimization Algorithm for DNN to Predict Passengers at a Metro Station",
    "doi": "https://doi.org/10.1145/3410156",
    "publication_date": "2021-03-30",
    "publication_year": 2021,
    "authors": "Chun‐Wei Tsai; Zhi-Yan Fang",
    "corresponding_authors": "",
    "abstract": "As one of the public transportation systems, metro is certainly an indispensable part in urban areas of a metropolis today. Several successful results have shown that deep learning technologies might provide an effective way to predict the number of passengers at a metro station. However, most information systems based on deep learning technologies are usually designed and tuned manually by using domain knowledge and trial-and-error; thus, how to find out a set of suitable hyperparameters for a deep neural network (DNN) has become a critical research issue. To deal with the problem of hyperparameter setting for a DNN in solving the prediction of passengers at a metro station, a novel metaheuristic algorithm called search economics for hyperparameter optimization is presented to improve the accuracy rate of such a prediction system. The basic idea of the proposed algorithm is to divide the solution space into a set of subspaces first and then assign a different number of search agents to each subspace based on the “potential of each subspace.” The potential is estimated based on the objective values of the searched solutions, the objective values of the probe solutions, and the computation time invested in each subspace. The proposed method is compared with Bayesian, random forest, support vector regression, DNN, and DNN with different hyperparameter search algorithms, namely, grid search, simulated annealing, and particle swarm optimization. The simulation results using the data provided by the government of Taipei city, Taiwan, indicate that the proposed method outperforms all the other forecasting methods compared in this article in terms of the mean absolute percentage error.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W3146806684",
    "type": "article"
  },
  {
    "title": "A Novel Cloud-Assisted Secure Deep Feature Classification Framework for Cancer Histopathology Images",
    "doi": "https://doi.org/10.1145/3424221",
    "publication_date": "2021-06-02",
    "publication_year": 2021,
    "authors": "Abhinav Kumar; Sanjay Kumar Singh; K. Lakshmanan; Sonal Saxena; Sameer Shrivastava",
    "corresponding_authors": "",
    "abstract": "The advancements in the Internet of Things (IoT) and cloud services have enabled the availability of smart e-healthcare services in a distant and distributed environment. However, this has also raised major privacy and efficiency concerns that need to be addressed. While sharing clinical data across the cloud that often consists of sensitive patient-related information, privacy is a major challenge. Adequate protection of patients’ privacy helps to increase public trust in medical research. Additionally, DL-based models are complex, and in a cloud-based approach, efficient data processing in such models is complicated. To address these challenges, we propose an efficient and secure cancer diagnostic framework for histopathological image classification by utilizing both differential privacy and secure multi-party computation. For efficient computation, instead of performing the whole operation on the cloud, we decouple the layers into two modules: one for feature extraction using the VGGNet module at the user side and the remaining layers for private prediction over the cloud. The efficacy of the framework is validated on two datasets composed of histopathological images of the canine mammary tumor and human breast cancer. The application of differential privacy preserving to the proposed model makes the model secure and capable of preserving the privacy of sensitive data from any adversary, without significantly compromising the model accuracy. Extensive experiments show that the proposed model efficiently achieves the trade-off between privacy and model performance.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W3173102465",
    "type": "article"
  },
  {
    "title": "QoS–aware Mesh-based Multicast Routing Protocols in Edge Ad Hoc Networks: Concepts and Challenges",
    "doi": "https://doi.org/10.1145/3428150",
    "publication_date": "2021-09-14",
    "publication_year": 2021,
    "authors": "Gaurav Singal; Vijay Laxmi; Manoj Singh Gaur; Dushyant Rao; Riti Kushwaha; Deepak Garg; Neeraj Kumar",
    "corresponding_authors": "",
    "abstract": "Multicast communication plays a pivotal role in Edge based Mobile Ad hoc Networks (MANETs). MANETs can provide low-cost self-configuring devices for multimedia data communication that can be used in military battlefield, disaster management, connected living, and public safety networks. A Multicast communication should increase the network performance by decreasing the bandwidth consumption, battery power, and routing overhead. In recent years, a number of multicast routing protocols (MRPs) have been proposed to resolve above listed challenges. Some of them are used for dynamic establishment of reliable route for multimedia data communication. This article provides a detailed survey of the merits and demerits of the recently developed techniques. An ample study of various Quality of Service (QoS) techniques and enhancement is also presented. Later, mesh topology-based MRPs are classified according to enhancement in routing mechanism and QoS modification. This article covers the most recent, robust, and reliable QoS-aware mesh based MRPs, classified on the basis of their operational features, and pros and cons. Finally, a comparative study has been presented on the basis of their performance parameters on the proposed protocols.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W3201543172",
    "type": "article"
  },
  {
    "title": "A Flexible and Privacy-Preserving Collaborative Filtering Scheme in Cloud Computing for VANETs",
    "doi": "https://doi.org/10.1145/3425708",
    "publication_date": "2021-10-22",
    "publication_year": 2021,
    "authors": "Huijie Yang; Jian Shen; Tianqi Zhou; Sai Ji; Pandi Vijayakumar",
    "corresponding_authors": "",
    "abstract": "The vehicular ad hoc network (VANET) has become a hot topic in recent years. With the development of VANETs, how to achieve secure and efficient machine learning in VANETs is an urgent problem to be solved. Besides, how to ensure that users obtain the accurate results of machine learning is also a challenge. Based on the homomorphic encryption and secure multiparty computing technology, a flexible and privacy-preserving collaborative filtering scheme is proposed to accomplish the personalized recommendation for users, which is based on users’ interests and locations. On the one hand, the data can be updated by users flexibly to ensure the freshness and accuracy of the dataset of interest. On the other hand, the weighted values of user interest can be safely sorted to improve the accuracy of collaborative filtering effectively. Moreover, a novel collaborative filtering algorithm based on the homomorphic encryption technology is designed, which can guarantee that the calculated decryption result by machine learning is the same as the plaintext. Note that the privacy of user data can be preserved during machine learning in this algorithm. Both theoretical and experimental analyses demonstrate that the proposed scheme is secure and efficient for collaborative filtering in cloud computing in VANETs.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W3208037160",
    "type": "article"
  },
  {
    "title": "DANCE: Distributed Generative Adversarial Networks with Communication Compression",
    "doi": "https://doi.org/10.1145/3458929",
    "publication_date": "2021-10-22",
    "publication_year": 2021,
    "authors": "Xiongtao Zhang; Xiaomin Zhu; Ji Wang; Weidong Bao; Laurence T. Yang",
    "corresponding_authors": "",
    "abstract": "Generative adversarial networks (GANs) have shown great success in deep representations learning, data generation, and security enhancement. With the development of the Internet of Things, 5th generation wireless systems (5G), and other technologies, the large volume of data collected at the edge of networks provides a new way to improve the capabilities of GANs. Due to privacy, bandwidth, and legal constraints, it is not appropriate to upload all the data to the cloud or servers for processing. Therefore, this article focuses on deploying and training GANs at the edge rather than converging edge data to the central node. To address this problem, we designed a novel distributed learning architecture for GANs, called DANCE. DANCE can adaptively perform communication compression based on the available bandwidth, while supporting both data and model parallelism training of GANs. In addition, inspired by the gossip mechanism and Stackelberg game, a compatible algorithm, AC-GAN is proposed. The theoretical analysis guarantees the convergence of the model and the existence of approximate equilibrium in AC-GAN. Both simulation and prototype system experiments show that AC-GAN can achieve better training effectiveness with less communication overhead than the SOTA algorithms, i.e., FL-GAN and MD-GAN.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W3209917595",
    "type": "article"
  },
  {
    "title": "Data-Driven Prediction and Optimization of Energy Use for Transit Fleets of Electric and ICE Vehicles",
    "doi": "https://doi.org/10.1145/3433992",
    "publication_date": "2021-10-25",
    "publication_year": 2021,
    "authors": "Afiya Ayman; Amutheezan Sivagnanam; Michael Wilbur; Philip Pugliese; Abhishek Dubey; Áron Lászka",
    "corresponding_authors": "",
    "abstract": "Due to the high upfront cost of electric vehicles, many public transit agencies can afford only mixed fleets of internal combustion and electric vehicles. Optimizing the operation of such mixed fleets is challenging because it requires accurate trip-level predictions of electricity and fuel use as well as efficient algorithms for assigning vehicles to transit routes. We present a novel framework for the data-driven prediction of trip-level energy use for mixed-vehicle transit fleets and for the optimization of vehicle assignments, which we evaluate using data collected from the bus fleet of CARTA, the public transit agency of Chattanooga, TN. We first introduce a data collection, storage, and processing framework for system-level and high-frequency vehicle-level transit data, including domain-specific data cleansing methods. We train and evaluate machine learning models for energy prediction, demonstrating that deep neural networks attain the highest accuracy. Based on these predictions, we formulate the problem of minimizing energy use through assigning vehicles to fixed-route transit trips. We propose an optimal integer program as well as efficient heuristic and meta-heuristic algorithms, demonstrating the scalability and performance of these algorithms numerically using the transit network of CARTA.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W3211065143",
    "type": "article"
  },
  {
    "title": "A Highly Stable Fusion Positioning System of Smartphone under NLoS Acoustic Indoor Environment",
    "doi": "https://doi.org/10.1145/3589765",
    "publication_date": "2023-04-13",
    "publication_year": 2023,
    "authors": "Hucheng Wang; Zhi Wang; Lei Zhang; Xiaonan Luo; Xinheng Wang",
    "corresponding_authors": "",
    "abstract": "Fusion positioning technology requires stable and effective positioning data, but this is often challenging to achieve in complex Non-Line-of-Sight (NLoS) environments. This paper proposes a fusion positioning method that can achieve stable and no hop points by adjusting parameters and predicting trends, even with a one-sided lack of fusion data. The method combines acoustic signal and Inertial Measurement Unit (IMU) data, exploiting their respective advantages. The fusion is achieved using the Kalman filter and Bayesian parameter estimation is performed for tuning IMU parameters and predicting motion trends. The proposed method overcomes the problem of fusion failure caused by long-term unilateral data loss in traditional fusion positioning. The positioning trajectory and error distribution analysis show that the proposed method performs optimally in severe NLoS experiments.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W4365447127",
    "type": "article"
  },
  {
    "title": "Unpaired Self-supervised Learning for Industrial Cyber-Manufacturing Spectrum Blind Deconvolution",
    "doi": "https://doi.org/10.1145/3590963",
    "publication_date": "2023-05-03",
    "publication_year": 2023,
    "authors": "Lizhen Deng; Guoxia Xu; Jiaqi Pi; Hu Zhu; Xiaokang Zhou",
    "corresponding_authors": "",
    "abstract": "Cyber-Manufacturing combines industrial big data with intelligent analysis to find and understand the intangible problems in decision-making, which requires a systematic method to deal with rich signal data. With the development of spectral detection and photoelectric imaging technology, spectral blind deconvolution has achieved remarkable results. However, spectral processing is limited by one-dimensional signal, and there is no available structural information with few training samples. Moreover, in the majority of practical applications, it is entirely feasible to gather unpaired spectrum dataset for training. This training method of unpaired learning is practical and valuable. Therefore, a two-stage deconvolution scheme combining self supervised learning and feature extraction is proposed in this paper, which generates two complementary paired sets through self supervised learning to extract the final deconvolution network. In addition, a new deconvolution network is designed for feature extraction. The spectrum is pre-trained through spectral feature extraction and noise estimation network to improve the training efficiency and meet the assumed noise characteristics. Experimental results show that this method is effective in dealing with different types of synthetic noise.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W4367848139",
    "type": "article"
  },
  {
    "title": "RESP: A Recursive Clustering Approach for Edge Server Placement in Mobile Edge Computing",
    "doi": "https://doi.org/10.1145/3666091",
    "publication_date": "2024-05-27",
    "publication_year": 2024,
    "authors": "Ali Akbar Vali; Sadoon Azizi; Mohammad Shojafar",
    "corresponding_authors": "",
    "abstract": "With the rapid advancement of the Internet of Things and 5G networks in smart cities, the inevitable generation of massive amounts of data, commonly known as big data, has introduced increased latency within the traditional cloud computing paradigm. In response to this challenge, Mobile Edge Computing (MEC) has emerged as a viable solution, offloading a portion of mobile device workloads to nearby edge servers equipped with ample computational resources. Despite significant research in MEC systems, optimizing the placement of edge servers in smart cities to enhance network performance has received little attention. In this article, we propose RESP , a novel Recursive clustering technique for Edge Server Placement in MEC environments. RESP operates based on the median of each cluster determined by the number of base transceiver stations, strategically placing edge servers to achieve workload balance and minimize network traffic between them. Our proposed clustering approach substantially improves load balancing compared to existing methods and demonstrates superior performance in handling traffic dynamics. Through experimental evaluation with real-world data from Shanghai Telecom’s base station dataset, our approach outperforms several representative techniques in terms of workload balancing and network traffic optimization. By addressing the ESP problem and introducing an advanced recursive clustering technique, this work makes a substantial contribution to optimizing mobile edge computing networks in smart cities. The proposed algorithm outperforms alternative methodologies, demonstrating a 10% average improvement in optimizing network traffic. Moreover, it achieves a 53% more suitable result in terms of computational load.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4399054629",
    "type": "article"
  },
  {
    "title": "Learning algorithms for single-instance electronic negotiations using the time-dependent behavioral tactic",
    "doi": "https://doi.org/10.1145/1052934.1052941",
    "publication_date": "2005-02-01",
    "publication_year": 2005,
    "authors": "Wilson Wai Ho Mok; R. P. Sundarraj",
    "corresponding_authors": "",
    "abstract": "Negotiator often rely on learning an opponent's behavior and on then using the knowledge gained to arrive at a better deal. However, in an electronic negotiation setting in which the parties involved are often unknown to (and therefore lack information about) each other, this learning has to be accomplished with only the bid offers submitted during an ongoing negotiation. In this article, we consider such a scenario and develop learning algorithms for electronic agents that use a common negotiation tactic, namely, the time-dependent tactic (TDT), in which the values of the negotiating issues are dependent on the time elapsed in the negotiation. Learning algorithms for this tactic have not been proposed in the literature. Our approach is based on using the derivatives of the Taylor's series approximation of the TDT function in a three-phase algorithm that enumerates over a partial discretized version of the solution space. Computational results with our algorithms are encouraging.",
    "cited_by_count": 26,
    "openalex_id": "https://openalex.org/W2006221031",
    "type": "article"
  },
  {
    "title": "Optimizing result prefetching in web search engines with segmented indices",
    "doi": "https://doi.org/10.1145/967030.967032",
    "publication_date": "2004-02-01",
    "publication_year": 2004,
    "authors": "Ronny Lempel; Shlomo Moran",
    "corresponding_authors": "",
    "abstract": "We study the process in which search engines with segmented indices serve queries. In particular, we investigate the number of result pages that search engines should prepare during the query processing phase.Search engine users have been observed to browse through very few pages of results for queries that they submit. This behavior of users suggests that prefetching many results upon processing an initial query is not efficient, since most of the prefetched results will not be requested by the user who initiated the search. However, a policy that abandons result prefetching in favor of retrieving just the first page of search results might not make optimal use of system resources either.We argue that for a certain behavior of users, engines should prefetch a constant number of result pages per query. We define a concrete query processing model for search engines with segmented indices, and analyze the cost of such prefetching policies. Based on these costs, we show how to determine the constant that optimizes the prefetching policy. Our results are mostly applicable to local index partitions of the inverted files, but are also applicable to processing short queries in global index architectures.",
    "cited_by_count": 26,
    "openalex_id": "https://openalex.org/W2132107871",
    "type": "article"
  },
  {
    "title": "Design and implementation of the Web-enabled NIST design repository",
    "doi": "https://doi.org/10.1145/1125274.1125278",
    "publication_date": "2006-02-01",
    "publication_year": 2006,
    "authors": "Simon Szykman; Ram D. Sriram",
    "corresponding_authors": "",
    "abstract": "This article describes the design and development of a design repository software system. This system is a prototype implementation intended to demonstrate the role of design repositories as part of a vision for the next generation of product development software systems. This research involves not only the creation of a prototype software system, but is part of a broader effort that also includes the development of a core product knowledge representation and that seeks to address terminological and semantic issues associated with computer-aided product development. This article focuses on the interfaces that have been developed to support authoring and navigation of the product models stored in design repositories as well as the software architecture and associated rationale that provide the framework on which the system is built.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W1989551928",
    "type": "article"
  },
  {
    "title": "Firewall policy change-impact analysis",
    "doi": "https://doi.org/10.1145/2109211.2109212",
    "publication_date": "2008-03-23",
    "publication_year": 2008,
    "authors": "Alex X. Liu",
    "corresponding_authors": "Alex X. Liu",
    "abstract": "Firewalls are the cornerstones of the security infrastructure for most enterprises. They have been widely deployed for protecting private networks. The quality of the protection provided by a firewall directly depends on the quality of its policy (i.e., configuration). Due to the lack of tools for analyzing firewall policies, many firewalls used today have policy errors. A firewall policy error either creates security holes that will allow malicious traffic to sneak into a private network or blocks legitimate traffic and disrupts normal business processes, which in turn could lead to irreparable, if not tragic, consequences. A major cause of policy errors are policy changes. Firewall policies often need to be changed as networks evolve and new threats emerge. Users behind a firewall often request the firewall administrator to modify rules to allow or protect the operation of some services. In this article, we first present the theory and algorithms for firewall policy change-impact analysis. Our algorithms take as input a firewall policy and a proposed change, then output the accurate impact of the change. Thus, a firewall administrator can verify a proposed change before committing it. We implemented our firewall change-impact analysis algorithms, and tested them on both real-life and synthetic firewall policies. The experimental results show that our algorithms are effective in terms of ensuring firewall policy correctness and efficient in terms of computing the impact of policy changes. Thus, our tool can be practically used in the iterative process of firewall policy design and maintenance. Although the focus of this article is on firewalls, the change-impact analysis algorithms proposed in this article are not limited to firewalls. Rather, they can be applied to other rule-based systems, such as router access control lists (ACLs), as well.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W2096050295",
    "type": "article"
  },
  {
    "title": "Security analysis of Internet technology components enabling globally distributed workplaces—a framework",
    "doi": "https://doi.org/10.1145/1391949.1391951",
    "publication_date": "2008-09-01",
    "publication_year": 2008,
    "authors": "Manish Gupta; Shamik Banerjee; Manish Agrawal; H. Raghav Rao",
    "corresponding_authors": "",
    "abstract": "As organizations increasingly operate, compete, and cooperate in a global context, business processes are also becoming global to propagate the benefits from coordination and standardization across geographical boundaries. In this context, security has gained significance due to increased threats, as well as legislation and compliance issues. This article presents a framework for assessing the security of Internet technology components that support a globally distributed workplace. Four distinct information flow and design architectures are identified based on location sensitivities and placements of the infrastructure components. Using a combination of scenarios, architectures, and technologies, the article presents the framework of a development tool for information security officers to evaluate the security posture of an information system. To aid managers in better understanding their options to improve security of the system, we also propose a three-dimensional representation, based on the framework, for embedding solution alternatives. To demonstrate its use in a real-world context, the article also applies the framework to assess a globally distributed workforce application at a northeast financial institution.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W2041533584",
    "type": "article"
  },
  {
    "title": "Introduction to special issue internet technologies for distance education",
    "doi": "https://doi.org/10.1145/1323651.1323652",
    "publication_date": "2008-02-01",
    "publication_year": 2008,
    "authors": "Qing Li; Rynson W. H. Lau; Timothy K. Shih; Dennis McLeod",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W2056197999",
    "type": "article"
  },
  {
    "title": "Using a fuzzy classification approach to assess e-commerce Web sites",
    "doi": "https://doi.org/10.1145/1552291.1552295",
    "publication_date": "2009-07-01",
    "publication_year": 2009,
    "authors": "Duanning Zhou; Wayne Huang",
    "corresponding_authors": "",
    "abstract": "E-commerce Web site assessment helps determine whether a corporation's Web site is effectively designed to meet its business needs and whether the investment in Web sites is well justified. Due to the complexity of commercial Web sites that may include hundreds of Web pages for many big corporations, there may inevitably exist uncertainties when human assessors express their subjective judgments in assessing e-commerce Web sites. Fuzzy set theory is widely used to model uncertain and imprecise information in applications. Prior studies in e-commerce Web site assessment identified some key factors to assess commercial Web sites by using a numeric assessment scale that may not be effective and efficient in modeling uncertainty. This study intends to propose an e-commerce Web site assessment framework using a fuzzy classification approach. Based on this framework, a Web-based e-commerce assessment system was designed and developed, which can provide online assessment services to corporations on evaluating their commercial Web sites. An empirical investigation into assessing commercial Web sites of the top 120 Fortune Corporations of the USA was conducted using the developed online assessment system to demonstrate the usefulness of the proposed framework. Research findings and implications are discussed.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W2039212677",
    "type": "article"
  },
  {
    "title": "Providing Users’ Anonymity in Mobile Hybrid Networks",
    "doi": "https://doi.org/10.1145/2461321.2461322",
    "publication_date": "2013-05-01",
    "publication_year": 2013,
    "authors": "Claudio A. Ardagna; Sushil Jajodia; Pierangela Samarati; Angelos Stavrou",
    "corresponding_authors": "",
    "abstract": "We present a novel hybrid communication protocol that guarantees mobile users’ anonymity against a wide-range of adversaries by exploiting the capability of handheld devices to connect to both WiFi and cellular networks. Unlike existing anonymity schemes, we consider all parties that can intercept communications between a mobile user and a server as potential privacy threats. We formally quantify the privacy exposure and the protection of our system in the presence of malicious neighboring peers, global WiFi eavesdroppers, and omniscient mobile network operators, which possibly collude to breach user’s anonymity or disrupt the communication. We also describe how a micropayment scheme that suits our mobile scenario can provide incentives for peers to collaborate in the protocol. Finally, we evaluate the network overhead and attack resiliency of our protocol using a prototype implementation deployed in Emulab and Orbit, and our probabilistic model.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W2112966950",
    "type": "article"
  },
  {
    "title": "Load Balancing and Range Queries in P2P Systems Using P-Ring",
    "doi": "https://doi.org/10.1145/1944339.1944343",
    "publication_date": "2011-03-01",
    "publication_year": 2011,
    "authors": "Adina Crainiceanu; Prakash Linga; Ashwin Machanavajjhala; Johannes Gehrke; Jayavel Shanmugasundaram",
    "corresponding_authors": "",
    "abstract": "In peer-to-peer (P2P) systems, computers from around the globe share data and can participate in distributed computation. P2P became famous, and infamous, due to file-sharing systems like Napster. However, the scalability and robustness of these systems make them appealing to a wide range of applications. This article introduces P-Ring, a new peer-to-peer index structure. P-Ring is fully distributed, fault tolerant, and provides load balancing and logarithmic search performance while supporting both equality and range queries. Our theoretical analysis as well as experimental results, obtained both in a simulated environment and on PlanetLab, show the performance of our system.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W1993535908",
    "type": "article"
  },
  {
    "title": "A Context-Based Approach to Reconciling Data Interpretation Conflicts in Web Services Composition",
    "doi": "https://doi.org/10.1145/2532638",
    "publication_date": "2013-11-01",
    "publication_year": 2013,
    "authors": "Xitong Li; Stuart Madnick; Hongwei Zhu",
    "corresponding_authors": "",
    "abstract": "We present a comprehensive classification of data misinterpretation problems and develop an approach to automatic detection and reconciliation of data interpretation conflicts in Web services composition. The approach uses a lightweight ontology augmented with modifiers, contexts, and atomic conversions between the contexts. The WSDL descriptions of Web services are annotated to establish correspondences to the ontology. Given the naive Business Process Execution Language (BPEL) specification of the desired Web services composition with data interpretation conflicts, the approach can automatically detect the conflicts and produce the corresponding mediated BPEL. Finally, we develop a prototype to validate and evaluate the approach.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W2026689988",
    "type": "article"
  },
  {
    "title": "Juno",
    "doi": "https://doi.org/10.1145/2390209.2390210",
    "publication_date": "2012-12-01",
    "publication_year": 2012,
    "authors": "Gareth Tyson; Andreas Mauthe; Sebastian Kaune; Paul Grace; Adel Taweel; Thomas Plagemann",
    "corresponding_authors": "",
    "abstract": "This article proposes a new delivery-centric abstraction which extends the existing content-centric networking API. A delivery-centric abstraction allows applications to generate content requests agnostic to location or protocol, with the additional ability to stipulate high-level requirements regarding such things as performance, security, and resource consumption. Fulfilling these requirements, however, is complex as often the ability of a provider to satisfy requirements will vary between different consumers and over time. Therefore, we argue that it is vital to manage this variance to ensure an application fulfils its needs. To this end, we present the Juno middleware, which implements delivery-centric support using a reconfigurable software architecture to: (i) discover multiple sources of an item of content; (ii) model each source’s ability to provide the content; then (iii) adapt to interact with the source(s) that can best fulfil the application’s requirements. Juno therefore utilizes existing providers in a backwards compatible way, supporting immediate deployment. This article evaluates Juno using Emulab to validate its ability to adapt to its environment.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W2124689071",
    "type": "article"
  },
  {
    "title": "Adaptive Speculative Processing of Out-of-Order Event Streams",
    "doi": "https://doi.org/10.1145/2633686",
    "publication_date": "2014-07-15",
    "publication_year": 2014,
    "authors": "Christopher Mutschler; Michæl Philippsen",
    "corresponding_authors": "",
    "abstract": "Distributed event-based systems are used to detect meaningful events with low latency in high data-rate event streams that occur in surveillance, sports, finances, etc. However, both known approaches to dealing with the predominant out-of-order event arrival at the distributed detectors have their shortcomings: buffering approaches introduce latencies for event ordering, and stream revision approaches may result in system overloads due to unbounded retraction cascades. This article presents an adaptive speculative processing technique for out-of-order event streams that enhances typical buffering approaches. In contrast to other stream revision approaches developed so far, our novel technique encapsulates the event detector, uses the buffering technique to delay events but also speculatively processes a portion of it, and adapts the degree of speculation at runtime to fit the available system resources so that detection latency becomes minimal. Our technique outperforms known approaches on both synthetical data and real sensor data from a realtime locating system (RTLS) with several thousands of out-of-order sensor events per second. Speculative buffering exploits system resources and reduces latency by 40% on average.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W2145574899",
    "type": "article"
  },
  {
    "title": "Reasoning About Property Preservation in Adaptive Case Management",
    "doi": "https://doi.org/10.1145/3177778",
    "publication_date": "2019-01-25",
    "publication_year": 2019,
    "authors": "Rik Eshuis; Richard Hull; Mengfei Yi",
    "corresponding_authors": "",
    "abstract": "Adaptive Case Management (ACM) has emerged as a key BPM technology for supporting the unstructured business process. A key problem in ACM is that case schemas need to be changed to best fit the case at hand. Such changes are ad hoc, and may result in schemas that do not reflect the intended logic or properties. This article presents a formal approach for reasoning about which properties of a case schema are preserved after a modification, and describes change operations that are guaranteed to preserve certain properties. The approach supports reasoning about rollbacks. The Case Management model used here is a variant of the Guard-Stage-Milestone model for declarative business artifacts. A real-life example illustrates applicability.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W2194457074",
    "type": "article"
  },
  {
    "title": "Incentive-Based Crowdsourcing of Hotspot Services",
    "doi": "https://doi.org/10.1145/3229047",
    "publication_date": "2019-01-29",
    "publication_year": 2019,
    "authors": "Azadeh Ghari Neiat; Athman Bouguettaya; Sajib Mistry",
    "corresponding_authors": "",
    "abstract": "We present a new spatio-temporal incentive-based approach to achieve a geographically balanced coverage of crowdsourced services. The proposed approach is based on a new spatio-temporal incentive model that considers multiple parameters including location entropy, time of day, and spatio-temporal density to encourage the participation of crowdsourced service providers. We present a greedy network flow algorithm that offers incentives to redistribute crowdsourced service providers to improve the crowdsourced coverage balance within an area. A novel participation probability model is also introduced to estimate the expected number of crowdsourced service providers’ movement based on spatio-temporal features. Experimental results validate the efficiency and effectiveness of the proposed approach.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W2810024799",
    "type": "article"
  },
  {
    "title": "Understanding the Influences of Past Experience on Trust in Human-agent Teamwork",
    "doi": "https://doi.org/10.1145/3324300",
    "publication_date": "2019-09-13",
    "publication_year": 2019,
    "authors": "Feyza Merve Hafızoğlu; Sandip Sen",
    "corresponding_authors": "",
    "abstract": "People use the knowledge acquired from past experiences in assessing the trustworthiness of a trustee. In a time where the agents are being increasingly accepted as partners in collaborative efforts and activities, it is critical to understand all aspects of human trust development in agent partners. For human-agent virtual ad hoc teams to be effective, humans must be able to trust their agent counterparts. To earn the humans’ trust, agents need to quickly develop an understanding of the expectation of human team members and adapt accordingly. This study empirically investigates the impact of past experience on human trust in and reliance on agent teammates. To do so, we developed a team coordination game, the Game of Trust (GoT), in which two players repeatedly cooperate to complete team tasks without prior assignment of subtasks. The effects of past experience on human trust are evaluated by performing an extensive set of controlled experiments with participants recruited from Amazon Mechanical Turk, a crowdsourcing marketplace. We collect both teamwork performance data as well as surveys to gauge participants’ trust in their agent teammates. The results show that positive (negative) past experience increases (decreases) human trust in agent teammates; lack of past experience leads to higher trust levels compared to positive past experience; positive (negative) past experience facilitates (hinders) reliance on agent teammates; the relationship between trust in and reliance on agent teammates is not always correlated. These findings provide clear and significant evidence of the influence of key factors on human trust in virtual agent teammates and enhance our understanding of the changes in human trust in peer-level agent teammates with respect to past experience.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W3009244173",
    "type": "article"
  },
  {
    "title": "SESAME",
    "doi": "https://doi.org/10.1145/2677209",
    "publication_date": "2014-12-17",
    "publication_year": 2014,
    "authors": "Dingqi Yang; Daqing Zhang; Zhiyong Yu; Zhiwen Yu; Djamal Zeghlache",
    "corresponding_authors": "",
    "abstract": "With the recent popularity of social network services, a significant volume of heterogeneous social media data is generated by users, in the form of texts, photos, videos and collections of points of interest, etc. Such social media data provides users with rich resources for exploring content, such as looking for an interesting video or a favorite point of interest. However, the rapid growth of social media causes difficulties for users to efficiently retrieve their desired media items. Fortunately, users' digital footprints on social networks such as comments massively reflect individual's fine-grained preference on media items, that is, preference on different aspects of the media content, which can then be used for personalized social media search. In this article, we propose SESAME, a fine-grained preference-aware social media search framework leveraging user digital footprints on social networks. First, we collect users' direct feedback on media content from their social networks. Second, we extract users' sentiment about the media content and the associated keywords from their comments to characterize their fine-grained preference. Third, we propose a parallel multituple based ranking tensor factorization algorithm to perform the personalized media item ranking by incorporating two unique features, viz., integrating an enhanced bootstrap sampling method by considering user activeness and adopting stochastic gradient descent parallelization techniques. We experimentally evaluate the SESAME framework using two datasets collected from Foursquare and YouTube, respectively. The results show that SESAME can subtly capture user preference on social media items and consistently outperform baseline approaches by achieving better personalized ranking quality.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2053059199",
    "type": "article"
  },
  {
    "title": "Password-Authenticated Group Key Exchange",
    "doi": "https://doi.org/10.1145/2955095",
    "publication_date": "2016-12-09",
    "publication_year": 2016,
    "authors": "Yuexin Zhang; Yang Xiang; Xinyi Huang",
    "corresponding_authors": "",
    "abstract": "Two-party password-authenticated key exchange (2PAKE) protocols provide a natural mechanism for secret key establishment in distributed applications, and they have been extensively studied in past decades. However, only a few efforts have been made so far to design password-authenticated group key exchange (GPAKE) protocols. In a 2PAKE or GPAKE protocol, it is assumed that short passwords are preshared among users. This assumption, however, would be impractical in certain applications. Motivated by this observation, this article presents a GPAKE protocol without the password sharing assumption. To obtain the passwords, wireless devices, such as smart phones, tablets, and laptops, are used to extract short secrets at the physical layer. Using the extracted secrets, users in our protocol can establish a group key at higher layers with light computation consumptions. Thus, our GPAKE protocol is a cross-layer design. Additionally, our protocol is a compiler, that is, our protocol can transform any provably secure 2PAKE protocol into a GPAKE protocol with only one more round of communications. Besides, the proposed protocol is proved secure in the standard model.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2560199134",
    "type": "article"
  },
  {
    "title": "Other-Condemning Moral Emotions",
    "doi": "https://doi.org/10.1145/2998570",
    "publication_date": "2017-01-04",
    "publication_year": 2017,
    "authors": "Mehdi Dastani; Alexander Pankov",
    "corresponding_authors": "",
    "abstract": "This article studies and analyzes three other-condemning moral emotions: anger, contempt, and disgust. We utilize existing psychological theories—appraisal theories of emotion and the CAD triad hypothesis—and incorporate them into a unified framework. A semiformal specification of the elicitation conditions and prototypical coping strategies for the other-condemning emotions are proposed. The appraisal conditions are specified in terms of cognitive and social concepts such as goals, beliefs, actions, control and accountability, while coping strategies are classified as belief-, goal- and intention-affecting strategies, and specified in terms of action specifications. Our conceptual analysis and semiformal specification of the three other-condemning moral emotions are illustrated by means of an example of trolling in the domain of social media.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2570755748",
    "type": "article"
  },
  {
    "title": "Anonymous or Not? Understanding the Factors Affecting Personal Mobile Data Disclosure",
    "doi": "https://doi.org/10.1145/3017431",
    "publication_date": "2017-03-23",
    "publication_year": 2017,
    "authors": "Christos Perentis; Michele Vescovi; Chiara Leonardi; Corrado Moiso; Mirco Musolesi; Fabio Pianesi; Bruno Lepri",
    "corresponding_authors": "",
    "abstract": "The wide adoption of mobile devices and social media platforms have dramatically increased the collection and sharing of personal information. More and more frequently, users are called to make decisions concerning the disclosure of their personal information. In this study, we investigate the factors affecting users’ choices toward the disclosure of their personal data, including not only their demographic and self-reported individual characteristics, but also their social interactions and their mobility patterns inferred from months of mobile phone data activity. We report the findings of a field study conducted with a community of 63 subjects provided with (i) a smart-phone and (ii) a Personal Data Store (PDS) enabling them to control the disclosure of their data. We monitor the sharing behavior of our participants through the PDS and evaluate the contribution of different factors affecting their disclosing choices of location and social interaction data. Our analysis shows that social interaction inferred by mobile phones is an important factor revealing willingness to share, regardless of the data type. In addition, we provide further insights on the individual traits relevant to the prediction of sharing behavior.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2585258179",
    "type": "article"
  },
  {
    "title": "Rotten Apples or Bad Harvest? What We Are Measuring When We Are Measuring Abuse",
    "doi": "https://doi.org/10.1145/3122985",
    "publication_date": "2018-08-07",
    "publication_year": 2018,
    "authors": "Samaneh Tajalizadehkhoob; Rainer Böhme; Carlos Gañán; Maciej Korczyński; Michel van Eeten",
    "corresponding_authors": "",
    "abstract": "Internet security and technology policy research regularly uses technical indicators of abuse to identify culprits and to tailor mitigation strategies. As a major obstacle, current inferences from abuse data that aim to characterize providers with poor security practices often use a naive normalization of abuse (abuse counts divided by network size) and do not take into account other inherent or structural properties of providers. Even the size estimates are subject to measurement errors relating to attribution, aggregation, and various sources of heterogeneity. More precise indicators are costly to measure at Internet scale. We address these issues for the case of hosting providers with a statistical model of the abuse data generation process, using phishing sites in hosting networks as a case study. We decompose error sources and then estimate key parameters of the model, controlling for heterogeneity in size and business model. We find that 84% of the variation in abuse counts across 45,358 hosting providers can be explained with structural factors alone. Informed by the fitted model, we systematically select and enrich a subset of 105 homogeneous “statistical twins” with additional explanatory variables, unreasonable to collect for all hosting providers. We find that abuse is positively associated with the popularity of websites hosted and with the prevalence of popular content management systems. Moreover, hosting providers who charge higher prices (after controlling for level differences between countries) witness less abuse. These structural factors together explain a further 77% of the remaining variation. This calls into question premature inferences from raw abuse indicators about the security efforts of actors, and suggests the adoption of similar analysis frameworks in all domains where network measurement aims at informing technology policy.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2593848643",
    "type": "article"
  },
  {
    "title": "Privacy-Preserving Publishing of Multilevel Utility-Controlled Graph Datasets",
    "doi": "https://doi.org/10.1145/3125622",
    "publication_date": "2018-02-22",
    "publication_year": 2018,
    "authors": "Balaji Palanisamy; Ling Liu; Yang Zhou; Qingyang Wang",
    "corresponding_authors": "",
    "abstract": "Conventional private data publication schemes are targeted at publication of sensitive datasets either after the k -anonymization process or through differential privacy constraints. Typically these schemes are designed with the objective of retaining as much utility as possible for the aggregate queries while ensuring the privacy of the individual records. Such an approach, though suitable for publishing aggregate information as public datasets, is inapplicable when users have different levels of access to the same data. We argue that existing schemes either result in increased disclosure of private information or lead to reduced utility when some users have more access privileges than the others. In this article, we present an anonymization framework for publishing large datasets with the goals of providing different levels of utility to the users based on their access privilege levels. We design and implement our proposed multilevel utility-controlled anonymization schemes in the context of large association graphs considering three levels of user utility, namely, (1) users having access to only the graph structure, (2) users having access to the graph structure and aggregate query results, and (3) users having access to the graph structure, aggregate query results, and individual associations. Our experiments on real large association graphs show that the proposed techniques are effective and scalable and yield the required level of privacy and utility for each user privacy and access privilege level.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2792704806",
    "type": "article"
  },
  {
    "title": "Measuring Performance in Knowledge-intensive Processes",
    "doi": "https://doi.org/10.1145/3289180",
    "publication_date": "2019-02-06",
    "publication_year": 2019,
    "authors": "Bedilia Estrada-Torres; Pedro H. Piccoli Richetti; Adela del–Río–Ortega; Fernanda Baião; Manuel Resinas; Flávia Maria Santoro; Antonio Ruiz–Cortés",
    "corresponding_authors": "",
    "abstract": "Knowledge-intensive Processes (KIPs) are processes whose execution is heavily dependent on knowledge workers performing various interconnected knowledge-intensive decision-making tasks. Among other characteristics, KIPs are usually non-repeatable, collaboration-oriented, unpredictable, and, in many cases, driven by implicit knowledge, derived from the capabilities and previous experiences of participants. Despite the growing body of research focused on understanding KIPs and on proposing systems to support these KIPs, the research question on how to define performance measures thereon remains open. In this article, we address this issue with a proposal to enable the performance management of KIPs. Our approach comprises an ontology that allows us to define process performance indicators (PPIs) in the context of KIPs, and a methodology that builds on the ontology and the concepts of lead and lag indicators to provide process participants with actionable guidelines that help them conduct the KIP in a way that fulfills a set of performance goals. Both the ontology and the methodology have been applied to a case study of a real organization in Brazil to manage the performance of an Incident Troubleshooting Process within an ICT (Information and Communications Technology) Outsourcing Company.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2913196464",
    "type": "article"
  },
  {
    "title": "Achieving Business Process Improvement via Ubiquitous Decision-Aware Business Processes",
    "doi": "https://doi.org/10.1145/3298986",
    "publication_date": "2019-01-21",
    "publication_year": 2019,
    "authors": "Alaaeddine Yousfi; Kimon Batoulis; Mathias Weske",
    "corresponding_authors": "",
    "abstract": "Business process improvement is an endless challenge for many organizations. As long as there is a process, it must be improved. Nowadays, improvement initiatives are driven by professionals. This is no longer practical because people cannot perceive the enormous data of current business environments. Here, we introduce ubiquitous decision-aware business processes. They pervade the physical space, analyze the ever-changing environments, and make decisions accordingly. We explain how they can be built and used for improvement. Our approach can be a valuable improvement option to alleviate the workload of participants by helping focus on the crucial rather than the menial tasks.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2913568326",
    "type": "article"
  },
  {
    "title": "A Smartphone-based Network Architecture for Post-disaster Operations Using WiFi Tethering",
    "doi": "https://doi.org/10.1145/3372145",
    "publication_date": "2020-02-10",
    "publication_year": 2020,
    "authors": "Amitangshu Pal; Mayank Raj; Krishna Kant; Sajal K. Das",
    "corresponding_authors": "",
    "abstract": "Electronic communication is crucial for monitoring the rescue-relief operations and providing assistance to the affected people during and after disasters. Given the ubiquity of smartphones, we envision that smartphones with lost connection (due to damage) to the communications infrastructure are nevertheless integrated seamlessly into the network as far as possible. To achieve this, we propose to build ad hoc subnetworks of disconnected smartphones using the WiFi tethering technology and ultimately connect them to either the emergency communication equipment deployed in the disaster area or to other smartphones that have still the network connectivity. The proposed architecture for such integration and a defined software-based control through the emergency control center (ECC) enables battery aware collection of critical data through smartphone sensors. The developed solution supports mobility of all smartphones, including those that have lost direct cellular connectivity as well as those that have not and are willing to act as gateways. We demonstrate how the proposed scheme can be tied to the standardized wireless emergency alert service and how it can effectively handle mobility tolerant device discovery and data transfer.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W3014451567",
    "type": "article"
  },
  {
    "title": "Privacy-preserving Network Path Validation",
    "doi": "https://doi.org/10.1145/3372046",
    "publication_date": "2020-02-07",
    "publication_year": 2020,
    "authors": "Binanda Sengupta; Yingjiu Li; Kai Bu; Robert H. Deng",
    "corresponding_authors": "",
    "abstract": "The end-users communicating over a network path currently have no control over the path. For a better quality of service, the source node often opts for a superior (or premium) network path to send packets to the destination node. However, the current Internet architecture provides no assurance that the packets indeed follow the designated path. Network path validation schemes address this issue and enable each node present on a network path to validate whether each packet has followed the specific path so far. In this work, we introduce two notions of privacy— path privacy and index privacy —in the context of network path validation. We show that, in case a network path validation scheme does not satisfy these two properties, the scheme is vulnerable to certain practical attacks (that affect the privacy, reliability, neutrality and quality of service offered by the underlying network). To the best of our knowledge, ours is the first work that addresses privacy issues related to network path validation. We design PrivNPV, a privacy-preserving network path validation protocol, that satisfies both path privacy and index privacy. We discuss several attacks related to network path validation and how PrivNPV defends against these attacks. Finally, we discuss the practicality of PrivNPV based on relevant parameters.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W3004615344",
    "type": "article"
  },
  {
    "title": "Emo2Vec",
    "doi": "https://doi.org/10.1145/3372152",
    "publication_date": "2020-04-17",
    "publication_year": 2020,
    "authors": "Shuo Wang; Aishan Maoliniyazi; Xinle Wu; Xiaofeng Meng",
    "corresponding_authors": "",
    "abstract": "Sentiment analysis or opinion mining for subject information extraction from the text has become more and more dependent on natural language processing, especially for business and healthcare, since the online products and service reviews affect the consuming behaviors. Word embeddings that can map the words to low-dimensional vector representations have been widely used in natural language processing tasks. But the word embeddings based on context such as Word2Vec and GloVe fail to capture the sentiment information. Most of existing sentiment analysis methods incorporate emotional polarity (positive and negative) to improve the sentiment embeddings for the emotion classification. This article takes advantage of an emotional psychology model to learn the emotional embeddings in Chinese first. In order to combine the semantic space and an emotional space, we present two different purifying models from local (LPM) and global (GPM) perspectives based on Plutchik's wheel of emotions to add the emotional information into word vectors. The two models aim to improve the word vectors so that not only the semantically similar words but also the sentimentally similar words can be closer than before. The Plutchik's wheel of emotions model can give eight-dimensional vector for one word in emotional space that can capture more sentiment information than the binary polarity labels. The obvious advantage of the local purifying model is that it can be fit for any pretrained word embeddings. For the global purifying model, we can get the final emotional embeddings at once. These models have been extended to handle English texts. The experimental results on Chinese and English datasets show that our purifying model can improve the conventional word embeddings and some proposed sentiment embeddings for sentiment classification and multi-emotion classification.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W3021411204",
    "type": "article"
  },
  {
    "title": "Trustworthy and Transparent Third-party Authority",
    "doi": "https://doi.org/10.1145/3386262",
    "publication_date": "2020-07-07",
    "publication_year": 2020,
    "authors": "Runhua Xu; James Joshi",
    "corresponding_authors": "",
    "abstract": "Recent advances in cryptographic approaches, such as Functional Encryption and Attribute-based Encryption and their variants, have shown significant promise for enabling public clouds to provide secure computation and storage services for users’ sensitive data. A crucial component of these approaches is a third-party authority (TPA) that must be trusted to set up public parameters, provide private key service, and so on. Components of deployed cryptographic mechanisms such as the certificate authorities (CAs) , which are the TPAs of the underlying PKI for the SSL/TLS protocol, have faced several types of attacks (e.g., stealthy targeted and censorship attacks), and certificate mis-issuance problems. Such practical challenges indicate that the successful deployment of newer emerging cryptographic schemes will also significantly depend on the trustworthiness of the TPAs. Furthermore, recently proposed decentralized TPA approaches that lower the threshold on the conditions required for an entity to become an authority can make the trust issue much worse. To address this issue, we propose an authority transparency framework to ensure the trustworthiness of TPAs of recent and emerging advanced cryptographic schemes. The framework includes a formal model and a secure logging -based approach to implement the framework. Further, to address the issues related to privacy, we also present a privacy-preserving authority transparency approach. We present security analysis and performance evaluation to show that authority transparency achieves the security and performance goals.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W3096377490",
    "type": "article"
  },
  {
    "title": "Energy-Efficient Computation Offloading for UAV-Assisted MEC: A Two-Stage Optimization Scheme",
    "doi": "https://doi.org/10.1145/3430503",
    "publication_date": "2021-10-15",
    "publication_year": 2021,
    "authors": "Weiwei Lin; Tiansheng Huang; Xin Li; Fang Shi; Xiumin Wang; Ching‐Hsien Hsu",
    "corresponding_authors": "",
    "abstract": "In addition to the stationary mobile edge computing (MEC) servers, a few MEC surrogates that possess a certain mobility and computation capacity, e.g., flying unmanned aerial vehicles (UAVs) and private vehicles, have risen as powerful counterparts for service provision. In this article, we design a two-stage online scheduling scheme, targeting computation offloading in a UAV-assisted MEC system. On our stage-one formulation, an online scheduling framework is proposed for dynamic adjustment of mobile users' CPU frequency and their transmission power, aiming at producing a socially beneficial solution to users. But the major impediment during our investigation lies in that users might not unconditionally follow the scheduling decision released by servers as a result of their individual rationality. In this regard, we formulate each step of online scheduling on stage one into a non-cooperative game with potential competition over the limited radio resource. As a solution, a centralized online scheduling algorithm, called ONCCO, is proposed, which significantly promotes social benefit on the basis of the users' individual rationality. On our stage-two formulation, we are working towards the optimization of UAV computation resource provision, aiming at minimizing the energy consumption of UAVs during such a process, and correspondingly, another algorithm, called WS-UAV, is given as a solution. Finally, extensive experiments via numerical simulation are conducted for an evaluation purpose, by which we show that our proposed algorithms achieve satisfying performance enhancement in terms of energy conservation and sustainable service provision.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W3207104615",
    "type": "article"
  },
  {
    "title": "<i>Deep-Confidentiality</i> : An IoT-Enabled Privacy-Preserving Framework for Unstructured Big Biomedical Data",
    "doi": "https://doi.org/10.1145/3421509",
    "publication_date": "2021-11-10",
    "publication_year": 2021,
    "authors": "Syed Atif Moqurrab; Adeel Anjum; Abid Khan; Mansoor Ahmed; Awais Ahmad; Gwanggil Jeon",
    "corresponding_authors": "",
    "abstract": "Due to the Internet of Things evolution, the clinical data is exponentially growing and using smart technologies. The generated big biomedical data is confidential, as it contains a patient’s personal information and findings. Usually, big biomedical data is stored over the cloud, making it convenient to be accessed and shared. In this view, the data shared for research purposes helps to reveal useful and unexposed aspects. Unfortunately, sharing of such sensitive data also leads to certain privacy threats. Generally, the clinical data is available in textual format (e.g., perception reports). Under the domain of natural language processing, many research studies have been published to mitigate the privacy breaches in textual clinical data. However, there are still limitations and shortcomings in the current studies that are inevitable to be addressed. In this article, a novel framework for textual medical data privacy has been proposed as Deep-Confidentiality . The proposed framework improves Medical Entity Recognition (MER) using deep neural networks and sanitization compared to the current state-of-the-art techniques. Moreover, the new and generic utility metric is also proposed, which overcomes the shortcomings of the existing utility metric. It provides the true representation of sanitized documents as compared to the original documents. To check our proposed framework’s effectiveness, it is evaluated on the i2b2-2010 NLP challenge dataset, which is considered one of the complex medical data for MER. The proposed framework improves the MER with 7.8% recall, 7% precision, and 3.8% F1-score compared to the existing deep learning models. It also improved the data utility of sanitized documents up to 13.79%, where the value of the k is 3.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W3214266528",
    "type": "article"
  },
  {
    "title": "Leveraging Data Augmentation for Service QoS Prediction in Cyber-physical Systems",
    "doi": "https://doi.org/10.1145/3425795",
    "publication_date": "2021-03-08",
    "publication_year": 2021,
    "authors": "Yuyu Yin; Haoran Xu; Tingting Liang; Manman Chen; Honghao Gao; Antonella Longo",
    "corresponding_authors": "",
    "abstract": "With the fast-developing domain of cyber-physical systems (CPS), constructing the CPS with high-quality services becomes an imperative task. As one of the effective solutions for information overload in CPS construction, quality of service (QoS)-aware service recommendation has drawn much attention in academia and industry. However, the lack of most QoS values limits the recommendation performance and it is time-consuming for users to get the QoS values by invoking all the services. Therefore, a powerful prediction model is required to predict the unobserved QoS values. Considering the fact that most existing QoS prediction models are unable to effectively address the data-sparsity problem, a novel two-stage framework called AgQ is proposed for QoS prediction. Specifically, a data augmentation strategy is designed in the first stage to enlarge the training set by drawing additional virtual instances. In the second stage, a prediction model is applied that considers both virtual and factual instances during the training procedure. We conduct extensive experiments on the WSDream dataset to demonstrate the effectiveness of the our QoS prediction framework and verify that the data augmentation strategy can indeed alleviate the data-sparsity problem. In terms of mean absolute error, taking the Multilayer Perceptron model as an example, the maximum improvement achieves 5% under 5% sparsity.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W3135842075",
    "type": "article"
  },
  {
    "title": "Machine Learning Empowered IoT for Intelligent Vehicle Location in Smart Cities",
    "doi": "https://doi.org/10.1145/3448612",
    "publication_date": "2021-08-10",
    "publication_year": 2021,
    "authors": "Liangtian Wan; Mingyue Zhang; Lu Sun; Xianpeng Wang",
    "corresponding_authors": "",
    "abstract": "Intelligent Transportation System (ITS) can boost the development of smart cities, and artificial intelligence and edge computing are key technologies that support the implementation of ITS. Vehicle localization is critical for ITS since the safety driving and location-aware serves highly depend on the accurate location information. In this article, we construct a vehicle localization system architecture composed of multiple Internet of Things (IoT) with arbitrary array configuration and a large amount of vehicles in smart cities. In order to deal with the coexisting of circular and non-circular signals transmitted by vehicles, we proposed several vehicle number estimation methods for non-circular signals. Based on the machine learning technique, we extend the vehicle number estimation method into mixed signals in more complex scenario of smart cities. Then the DOA estimation method for non-circular signals based on IoT is proposed, and then the performance of this method is analyzed as well. Simulation outcomes verify the excellent performance of the proposed vehicle number estimation methods and the DOA estimation method in smart cities, and the vehicle positions can be achieved with high estimation accuracy.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W3191329231",
    "type": "article"
  },
  {
    "title": "Secure Distributed Mobile Volunteer Computing with Android",
    "doi": "https://doi.org/10.1145/3428151",
    "publication_date": "2021-09-14",
    "publication_year": 2021,
    "authors": "Iram Bibi; Adnan Akhunzada; Jahanzaib Malik; Muhammad Khurram Khan; Muhammad Dawood",
    "corresponding_authors": "",
    "abstract": "Volunteer Computing provision of seamless connectivity that enables convenient and rapid deployment of greener and cheaper computing infrastructure is extremely promising to complement next-generation distributed computing systems. Undoubtedly, without tactile Internet and secure VC ecosystems, harnessing its full potentials and making it an alternative viable and reliable computing infrastructure is next to impossible. Android-enabled smart devices, applications, and services are inevitable for Volunteer computing. Contrarily, the progressive developments of sophisticated Android malware may reduce its exponential growth. Besides, Android malwares are considered the most potential and persistent cyber threat to mobile VC systems. To secure Android-based mobile volunteer computing, the authors proposed MulDroid, an efficient and self-learning autonomous hybrid (Long-Short-Term Memory, Convolutional Neural Network, Deep Neural Network) multi-vector Android malware threat detection framework. The proposed mechanism is highly scalable with well-coordinated infrastructure and self-optimizing capabilities to proficiently tackle fast-growing dynamic variants of sophisticated malware threats and attacks with 99.01% detection accuracy. For a comprehensive evaluation, the authors employed current state-of-the-art malware datasets (Android Malware Dataset, Androzoo) with standard performance evaluation metrics. Moreover, MulDroid is compared with our constructed contemporary hybrid DL-driven architectures and benchmark algorithms. Our proposed mechanism outperforms in terms of detection accuracy with a trivial tradeoff speed efficiency. Additionally, a 10-fold cross-validation is performed to explicitly show unbiased results.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W3199374084",
    "type": "article"
  },
  {
    "title": "Cloud-based Network Virtualization in IoT with OpenStack",
    "doi": "https://doi.org/10.1145/3460818",
    "publication_date": "2021-09-14",
    "publication_year": 2021,
    "authors": "Zakaria Benomar; Francesco Longo; Giovanni Merlino; Antonio Puliafito",
    "corresponding_authors": "",
    "abstract": "In Cloud computing deployments, specifically in the Infrastructure-as-a-Service (IaaS) model, networking is one of the core enabling facilities provided for the users. The IaaS approach ensures significant flexibility and manageability, since the networking resources and topologies are entirely under users’ control. In this context, considerable efforts have been devoted to promoting the Cloud paradigm as a suitable solution for managing IoT environments. Deep and genuine integration between the two ecosystems, Cloud and IoT, may only be attainable at the IaaS level. In light of extending the IoT domain capabilities’ with Cloud-based mechanisms akin to the IaaS Cloud model, network virtualization is a fundamental enabler of infrastructure-oriented IoT deployments. Indeed, an IoT deployment without networking resilience and adaptability makes it unsuitable to meet user-level demands and services’ requirements. Such a limitation makes the IoT-based services adopted in very specific and statically defined scenarios, thus leading to limited plurality and diversity of use cases. This article presents a Cloud-based approach for network virtualization in an IoT context using the de-facto standard IaaS middleware, OpenStack, and its networking subsystem, Neutron. OpenStack is being extended to enable the instantiation of virtual/overlay networks between Cloud-based instances (e.g., virtual machines, containers, and bare metal servers) and/or geographically distributed IoT nodes deployed at the network edge.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W3200674364",
    "type": "article"
  },
  {
    "title": "The <scp>SemIoTic</scp> Ecosystem: A Semantic Bridge between IoT Devices and Smart Spaces",
    "doi": "https://doi.org/10.1145/3527241",
    "publication_date": "2022-03-28",
    "publication_year": 2022,
    "authors": "Roberto Yus; Georgios Bouloukakis; Sharad Mehrotra; Nalini Venkatasubramanian",
    "corresponding_authors": "",
    "abstract": "Smart space administration and application development is challenging in part due to the semantic gap that exists between the high-level requirements of users and the low-level capabilities of IoT devices. The stakeholders in a smart space are required to deal with communicating with specific IoT devices, capturing data, processing it, and abstracting it out to generate useful inferences. Additionally, this makes reusability of smart space applications difficult, since they are developed for specific sensor deployments. In this article, we present a holistic approach to IoT smart spaces, the SemIoTic ecosystem, to facilitate application development, space management, and service provision to its inhabitants. The ecosystem is based on a centralized repository, where developers can advertise their space-agnostic applications, and a SemIoTic system deployed in each smart space that interacts with those applications to provide them with the required information. SemIoTic applications are developed using a metamodel that defines high-level concepts abstracted from the smart space about the space itself and the people within it. Application requirements can be expressed then in terms of user-friendly high-level concepts, which are automatically translated by SemIoTic into sensor/actuator commands adapted to the underlying device deployment in each space. We present a reference implementation of the ecosystem that has been deployed at the University of California, Irvine and is abstracting data from hundreds of sensors in the space and providing applications to campus members.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W4220838552",
    "type": "article"
  },
  {
    "title": "Secure and Efficient Hybrid Data Deduplication in Edge Computing",
    "doi": "https://doi.org/10.1145/3537675",
    "publication_date": "2022-05-14",
    "publication_year": 2022,
    "authors": "Hyungjune Shin; Dongyoung Koo; Junbeom Hur",
    "corresponding_authors": "",
    "abstract": "As an extension of cloud computing, edge computing introduces additional intermediate devices, called edge nodes near clients, providing computing services on behalf of the central cloud more efficiently. Although edge computing brings several benefits such as low latency and bandwidth savings on the edge side, rapid increase in the amount of data transmitted to the central cloud hinders efficient utilization of the storage system on the central cloud side especially when the data from edge devices are encrypted. To mitigate this issue in a privacy-preserving manner, data deduplication techniques for encrypted data have been extensively studied to enhance both the security and efficiency in the conventional cloud system with two different approaches. A server-side secure deduplication approach protects data privacy but impairs network efficiency by allowing duplicate uploads, while a client-side one improves network efficiency but suffers from potential information leakage due to its vulnerability to the side-channel attack. In this article, we propose a hybrid secure deduplication scheme for edge computing, which guarantees both advantages of the aforementioned two approaches. Specifically, our scheme guarantees data privacy by applying the server-side deduplication technique between the client and the edge nodes and maximizes network efficiency through the client-side deduplication technique between the edge nodes and the cloud. In addition, we devise a novel additively homomorphic encryption for efficient deduplication operations in the resource-limited edge nodes. Based on our experimental results, the proposed scheme reduces the communication costs by approximately 2.5 times for a storage server when the duplicate ratio is 50%, and the response time is reduced by about 2 times when the data size is 16 MB.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W4280525015",
    "type": "article"
  },
  {
    "title": "Designing and Developing a Weed Detection Model for California Thistle",
    "doi": "https://doi.org/10.1145/3544491",
    "publication_date": "2022-07-18",
    "publication_year": 2022,
    "authors": "Hossein Chegini; Fernando Beltrán; Aniket Mahanti",
    "corresponding_authors": "",
    "abstract": "With a great percentage of farms in New Zealand as pastures, they are mainly important in contributing to the milk and meat industries. Pasture quality is highly affected by weeds. Weeds grow fast and invade pastures by seed pollination. They consume the nutrients, water, and other minerals, and once they are bitter, cattle do not eat them. Therefore, dairy farmers have to allocate a significant portion of their budget and time to monitor and clean weeds. Unfortunately, most weed management tasks are manual with no consistent technology. Thus, the motivation behind this article was to design an object detection model for weed monitoring and control in pastures. The model was designed and tested on California thistle, a dominant and widespread weed on New Zealand pastures. Our study is one of the major model designs for identifying weeds in an in-pasture environment, one of the most complicated environments for any object detection model. A synthetic methodology was used to create three types of datasets: plant-based, leaf-based, and mixed. The trained model based on the leaf-based dataset is one of the major contributions of our work and has not been conducted by any other weed detection models. After models had been trained, tuning experimentation was undertaken to improve the model’s performance. This involved studying the model’s hyperparameters in various ranges and then recording their values at the optimum points. The improved model showed a 93% mAP accuracy in the detection of training images and over 95% accuracy for testing images. The experimentation showed that the leaf-based model was slightly better than other models. The model can automate highly any weed management system. The use of this model will save farmers time and money and help them reduce the errors of manual work.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W4285730868",
    "type": "article"
  },
  {
    "title": "Taming Internet of Things Application Development with the IoTvar Middleware",
    "doi": "https://doi.org/10.1145/3586010",
    "publication_date": "2023-03-05",
    "publication_year": 2023,
    "authors": "Pedro Victor Borges; Chantal Taconet; Sophie Chabridon; Denis Conan; Everton Cavalcante; Thaı́s Batista",
    "corresponding_authors": "",
    "abstract": "In the last years, Internet of Things (IoT) platforms have been designed to provide IoT applications with various services such as device discovery, context management, and data filtering. The lack of standardization has led each IoT platform to propose its own abstractions, APIs, and data models. As a consequence, programming interactions between an IoT consuming application and an IoT platform is time-consuming, is error prone, and depends on the developers’ level of knowledge about the IoT platform. To address these issues, this article introduces IoTvar , a middleware library deployed on the IoT consumer application that manages all its interactions with IoT platforms. IoTvar relies on declaring variables automatically mapped to sensors whose values are transparently updated with sensor observations through proxies on the client side. This article presents the IoTvar architecture and shows how it has been integrated into the FIWARE, OM2M, and muDEBS platforms. We also report the results of experiments performed to evaluate IoTvar, showing that it reduces the effort required to declare and manage IoT variables and has no considerable impact on CPU, memory, and energy consumption.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4323262302",
    "type": "article"
  },
  {
    "title": "Malicious Account Identification in Social Network Platforms",
    "doi": "https://doi.org/10.1145/3625097",
    "publication_date": "2023-09-20",
    "publication_year": 2023,
    "authors": "Loredana Caruccio; Gaetano Cimino; Stefano Cirillo; Domenico Desiato; Giuseppe Polese; Genoveffa Tortora",
    "corresponding_authors": "",
    "abstract": "Today, people of all ages are increasingly using Web platforms for social interaction. Consequently, many tasks are being transferred over social networks, like advertisements, political communications, and so on, yielding vast volumes of data disseminated over the network. However, this raises several concerns regarding the truthfulness of such data and the accounts generating them. Malicious users often manipulate data to gain profit. For example, malicious users often create fake accounts and fake followers to increase their popularity and attract more sponsors, followers, and so on, potentially producing several negative implications that impact the whole society. To deal with these issues, it is necessary to increase the capability to properly identify fake accounts and followers. By exploiting automatically extracted data correlations characterizing meaningful patterns of malicious accounts, in this article we propose a new feature engineering strategy to augment the social network account dataset with additional features, aiming to enhance the capability of existing machine learning strategies to discriminate fake accounts. Experimental results produced through several machine learning models on account datasets of both the Twitter and the Instagram platforms highlight the effectiveness of the proposed approach toward the automatic discrimination of fake accounts. The choice of Twitter is mainly due to its strict privacy laws, and because its the only social network platform making data of their accounts publicly available.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4386896804",
    "type": "article"
  },
  {
    "title": "EtherShield: Time-interval Analysis for Detection of Malicious Behavior on Ethereum",
    "doi": "https://doi.org/10.1145/3633514",
    "publication_date": "2023-11-23",
    "publication_year": 2023,
    "authors": "Bofeng Pan; Natalia Stakhanova; Zhongwen Zhu",
    "corresponding_authors": "",
    "abstract": "Advances in blockchain technology have attracted significant attention across the world. The practical blockchain applications emerging in various domains, ranging from finance, healthcare, and entertainment, have quickly become attractive targets for adversaries. The novelty of the technology coupled with the high degree of anonymity it provides made malicious activities even less visible in the blockchain environment. This made their robust detection challenging. This article presents EtherShield, a novel approach for identifying malicious activity on the Ethereum blockchain. By combining temporal transaction information and contract code characteristics, EtherShield can detect various types of threats and provide insight into the behavior of contracts. The time-interval-based analysis used by EtherShield enables expedited detection, achieving comparable accuracy to other approaches with significantly less data. Our validation analysis, which involved over 15,000 Ethereum accounts, demonstrated that EtherShield can significantly expedite the detection of malicious activity while maintaining high accuracy levels (86.52% accuracy with 1 hour of transaction history data and 91.33% accuracy with 1 year of transaction history data).",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4388946146",
    "type": "article"
  },
  {
    "title": "An IoT and Deep Learning-Based Smart Healthcare Framework for Thyroid Cancer Detection",
    "doi": "https://doi.org/10.1145/3637062",
    "publication_date": "2023-12-11",
    "publication_year": 2023,
    "authors": "Rohit Sharma; G. K. Mahanti; Chinmay Chakraborty; Ganapati Panda; Adyasha Rath",
    "corresponding_authors": "",
    "abstract": "A world of healthcare possibilities has been opened with the development of the Internet of Medical Things and related machine learning, deep learning, and artificial intelligence approaches. It has a broad range of uses: when linked to the Internet, common medical equipment and sensors may gather important data; deep learning and artificial intelligence algorithms use this data to understand symptoms and patterns and allow remote healthcare. There are a large number of people affected by thyroid disorders across the world. The ultrasound-based thyroid nodule detection using traditional methods increased the burden on the expertise. Therefore, alternate methods are required to overcome this problem. In order to facilitate early thyroid disorder detection, this research aims to offer an IoT-based ensemble learning framework. In the proposed ensemble model, three pre-trained models DeiT, Mixer-MLP and Swin Transformer, are used for feature extraction. The mRMR technique is used for relevant feature selection. A total of 24 machine learning models have been trained, and weighted average ensemble learning is employed using the Improved Jaya optimization algorithm and Coronavirus Herd Immunity optimization algorithm. The ensemble model with the improved Jaya optimization algorithm achieved excellent results. The best value for accuracy, precision, sensitivity, specificity, F2-score and ROC-AUC score are 92.83%, 87.76%, 97.66%, 88.89%, 0.9551 and 0.9357, respectively. The main focus of this research is to increase the specificity. A poor value of specificity can lead to a high false positive rate. This situation can increase anxiety and emotionally weaken the patient. The proposed ensemble model with the Improved Jaya optimization algorithm outperformed state-of-the-art techniques and can assist medical experts.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4389563248",
    "type": "article"
  },
  {
    "title": "AI-assisted Blockchain-enabled Smart and Secure E-prescription Management Framework",
    "doi": "https://doi.org/10.1145/3641279",
    "publication_date": "2024-01-23",
    "publication_year": 2024,
    "authors": "Siva Sai; Vinay Chamola",
    "corresponding_authors": "",
    "abstract": "Traditional medical prescriptions based on physical paper-based documents are prone to manipulation, errors, and unauthorized reproduction due to their format. Addressing the limitations of the traditional prescription system, e-prescription systems have been introduced in several countries. However, e-prescription systems lead to several concerns like the risk of privacy loss, the problem of double-spending prescriptions, lack of interoperability, and single point of failure, all of which need to be addressed immediately. We propose an AI-assisted blockchain-enabled smart and secure e-prescription management framework to address these issues. Our proposed system overcomes the problems of the centralized e-prescription systems and enables efficient consent management to access prescriptions by incorporating blockchain-based smart contracts. Our work incorporates the Umbral proxy re-encryption scheme in the proposed system, avoiding the need for repeated encryption and decryption of the prescriptions when transferred between different entities in the network. In our work, we employ two different machine learning models(Random Forest classifier and LightGBM classifier) to assist the doctor in prescribing medicines. One is a drug recommendation model, which is aimed at providing drug recommendations considering the medical history of the patients and the general prescription pattern for the particular ailment of the patient. We have fine-tuned the SciBERT model for adverse drug reaction detection. The extensive experimentation and results show that the proposed e-prescription framework is secure, scalable, and interoperable. Further, the proposed machine learning models produce results higher than 95%.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4391145663",
    "type": "article"
  },
  {
    "title": "Data management for continuous learning in EHR systems",
    "doi": "https://doi.org/10.1145/3660634",
    "publication_date": "2024-05-07",
    "publication_year": 2024,
    "authors": "Valerio Bellandi; Paolo Ceravolo; Jonatan Maggesi; Samira Maghool",
    "corresponding_authors": "",
    "abstract": "To gain a comprehensive understanding of a patient’s health, advanced analytics must be applied to the data collected by electronic health record (EHR) systems. However, managing and curating this data requires carefully designed workflows. While digitalization and standardization enable continuous health monitoring, missing data values and technical issues can compromise the consistency and timeliness of the data. In this paper, we propose a workflow for developing prognostic models that leverages the SMART BEAR infrastructure and the capabilities of the Big Data Analytics (BDA) engine to homogenize and harmonize data points. Our workflow improves the quality of the data by evaluating different imputation algorithms and selecting one that maintains the distribution and correlation of features similar to the raw data. We applied this workflow to a subset of the data stored in the SMART BEAR repository and examined its impact on the prediction of emerging health states such as cardiovascular disease and mild depression. We also discussed the possibility of model validation by clinicians in the SMART BEAR project, the transmission of subsequent actions in the decision support system, and the estimation of the required number of data points.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4396695484",
    "type": "article"
  },
  {
    "title": "FedGK: Communication-Efficient Federated Learning through Group-Guided Knowledge Distillation",
    "doi": "https://doi.org/10.1145/3674973",
    "publication_date": "2024-06-26",
    "publication_year": 2024,
    "authors": "W.M. Zhang; Xiaoli Liu; Sasu Tarkoma",
    "corresponding_authors": "",
    "abstract": "Federated learning (FL) empowers a cohort of participating devices to contribute collaboratively to a global neural network model, ensuring that their training data remains private and stored locally. Despite its advantages in computational efficiency and privacy preservation, FL grapples with the challenge of non-IID (not independent and identically distributed) data from diverse clients, leading to discrepancies between local and global models and potential performance degradation. In this article, we propose FedGK, an innovative communication-efficient Group-Guided FL framework designed for heterogeneous data distributions. FedGK employs a localized-guided framework that enables the client to effectively assimilate key knowledge from teachers and peers while minimizing extraneous peer information in FL scenarios. We conduct an in-depth analysis of the dynamic similarities among clients over successive communication rounds and develop a novel clustering approach that accurately groups clients with diverse heterogeneities. We implement FedGK on public datasets with an innovative data transformation pattern called “cluster-shift non-IID”, which mirrors the more prevalent data distributions in real-world settings and could be grouped into clusters with similar data distributions. Extensive experimental results on public datasets demonstrate that the proposed approach FedGK improves accuracy by up to 32.89% and saves up to 53.33% communication cost over state-of-the-art baselines.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4400047176",
    "type": "article"
  },
  {
    "title": "A New Layer Structure of Cyber-Physical Systems under the Era of Digital Twin",
    "doi": "https://doi.org/10.1145/3674974",
    "publication_date": "2024-06-29",
    "publication_year": 2024,
    "authors": "Cheng Qian; Yifan Guo; Adamu Hussaini; Abubakar Ahmad Musa; Akshita Maradapu Vera Venkata Sai; Wei Yu",
    "corresponding_authors": "",
    "abstract": "Cyber-Physical Systems (CPS) are new systems designed to support and synthesize sensing, communication, and computing components that interact with physical objects so that the system can sense, monitor, control, and respond to changes occurring in their operating environments. With developing Internet of Things (IoT), edge/cloud computing, and Artificial Intelligence (AI), another new paradigm - Digital Twin (DT), as an enabler for realizing the Metaverse of CPS has emerged recently. The DT provides a virtual replica of the physical world, allowing for real-time monitoring, control, and analysis of safety-critical systems like the CPS. Even though many CPS-related problems can be addressed using DT concepts, it is critical to define DT’s integration clearly to leverage its features to the best possible extent. This paper introduces a new layer called the data layer in the CPS layer architecture to support different DT functionalities. Like the layer and abstract design paradigm of modern operation systems and computer networks, the data layer serves as an abstraction layer, providing immense flexibility and interchangeability of various data sources, supporting applications, and adapting to other components and environments. This also accelerates the growth of smart-world systems and their integration in different application domains (smart grid, smart transportation, smart manufacturing, smart cities, smart healthcare, etc.). To this end, this paper presents a new data layer structure to support CPS applications and the integration of multiple CPS. We propose a hierarchical architecture to synthesize DT techniques as an independent layer in our architecture, deeply integrated into existing CPS. We discuss key issues: leveraging the data layer to support applications in various CPS, incorporating the data layer and physical layer, and building a data layer using distributed computing, naming services, etc. Finally, the paper outlines future research directions based on the presented new data layer architecture for CPS.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4400151680",
    "type": "article"
  },
  {
    "title": "Adaptive Compression-Aware Split Learning and Inference for Enhanced Network Efficiency",
    "doi": "https://doi.org/10.1145/3687471",
    "publication_date": "2024-08-13",
    "publication_year": 2024,
    "authors": "Akrit Mudvari; Antero Vainio; Iason Ofeidis; Sasu Tarkoma; Leandros Tassiulas",
    "corresponding_authors": "",
    "abstract": "The growing number of AI-driven applications in mobile devices has led to solutions that integrate deep learning models with the available edge-cloud resources. Due to multiple benefits such as reduction in on-device energy consumption, improved latency, improved network usage, and certain privacy improvements, split learning, where deep learning models are split away from the mobile device and computed in a distributed manner, has become an extensively explored topic. Incorporating compression-aware methods (where learning adapts to compression level of the communicated data) has made split learning even more advantageous. This method could even offer a viable alternative to traditional methods, such as federated learning techniques. In this work, we develop an adaptive compression-aware split learning method (“deprune”) to improve and train deep learning models so that they are much more network-efficient, which would make them ideal to deploy in weaker devices with the help of edge-cloud resources. This method is also extended (“prune”) to very quickly train deep learning models through a transfer learning approach, which tradesoff little accuracy for much more network-efficient inference abilities. We show that the “deprune” method can reduce network usage by 4× when compared with a split-learning approach (that does not use our method) without loss of accuracy, while also improving accuracy over compression-aware split-learning by up to 4 percent. Lastly, we show that the “prune” method can reduce the training time for certain models by up to 6× without affecting the accuracy when compared against a compression-aware split-learning approach.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4401545278",
    "type": "article"
  },
  {
    "title": "Malicious Participants and Fake Task Detection Incorporating Gaussian Bias",
    "doi": "https://doi.org/10.1145/3696419",
    "publication_date": "2024-09-19",
    "publication_year": 2024,
    "authors": "Jian Wang; Delei Zhao; Guosheng Zhao",
    "corresponding_authors": "",
    "abstract": "Mobile crowdsensing (MCS) is a combination of crowdsourcing ideas and mobile sensing devices, designed to enable rational allocation of resources at scale. However, the MCS platform is highly vulnerable to injection attacks from malicious participants and fake tasks that interfere with platform service capabilities and sensing activities. To this end, the participant and task submission process is modeled as a multivariate time series, and a detection model for malicious participants and fake tasks (MP-FTD) with a Gaussian prior on the attentional mechanism and a two-stage adversarial training process is proposed. The attention mechanism was corrected using Gaussian bias, and then the corrected attention mechanism was used to obtain the correlation discrepancies between the data. Using the adversarial training method of Generative Adversarial Networks (GAN), the output of the correlation discrepancy reconstruction phase is transformed into a focus score, to amplify the reconstruction error in the output of the focus score reconstruction phase, and to improve the differentiation between the injected data and normal data of malicious attackers. The detection of these malicious attackers will effectively improve the robustness of the sensing platform. Experiments on six real-world datasets showed that the average F1-score reached 93.44%, outperforming the current baseline method, and resulting in an average 12.07% improvement in participant assignment accuracy and an average 12.25% improvement in task assignment accuracy in task assignment experiments.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4402644289",
    "type": "article"
  },
  {
    "title": "Quality of service in an information economy",
    "doi": "https://doi.org/10.1145/945846.945847",
    "publication_date": "2003-11-01",
    "publication_year": 2003,
    "authors": "Reinhard Braumandl; A. Kemper; Donald Kossmann",
    "corresponding_authors": "",
    "abstract": "Accessing and processing distributed data sources have become important factors for businesses today. This is especially true for the emerging virtual enterprises with their data and processing capabilities spread across the Internet. Unfortunately, however, query processing on the Internet is not predictable and robust enough to meet the requirements of many business applications. For instance, the response time of a query can be unexpectedly high; or the monetary cost might be too high if the partners charge for the usage of their data or processing capabilities; or the result of the query might be useless because it is based on outdated data or only on parts (rather than all) of the available data. In this work, we show how a distributed query processor can be extended in order to support quality of service (QoS) guarantees. We propose ways to integrate QoS management into the various phases of query processing: (1) Query optimization uses a multi-dimensional assessment (cost, time and result quality) of query plans, (2) query plan instantiation comprises an admission control for sub-plans, and (3) during query plan execution the QoS of the query is monitored and a fuzzy controller initiates repairing actions if needed. The goal of our work is to provide an initial step towards QoS management in distributed query processing systems and do significantly better than current distributed database systems, which are based on a best-effort policy.",
    "cited_by_count": 26,
    "openalex_id": "https://openalex.org/W2004145258",
    "type": "article"
  },
  {
    "title": "Fighting the spam wars",
    "doi": "https://doi.org/10.1145/967030.967031",
    "publication_date": "2004-02-01",
    "publication_year": 2004,
    "authors": "Paweł Gburzyński; Jacek Maitan",
    "corresponding_authors": "",
    "abstract": "We present an effective method of eliminating unsolicited electronic mail (so-called spam ) and discuss its publicly accessible prototype implementation. A subscriber to our system is able to obtain an unlimited number of aliases of his/her permanent (protected) E-Mail address to be handed out to parties willing to communicate with the subscriber. It is also possible to set up publishable aliases, which can be used by human correspondents to contact the subscriber, while being useless to harvesting robots and spammers. The validity of an alias can be easily restricted to a specific duration in time, a specific number of received messages, a specific population of senders, and/or in other ways. The system is fully compatible with the existing E-Mail infrastructure and can be immediately accessed via any standard E-Mail client software (MUA). It can be easily deployed at any institution or organization running its private E-Mail server (MTA) with a trivial modification to that server. Our system offers a simple method to salvage the existing population of E-Mail addresses while eliminating all spam aimed at them.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W2063875363",
    "type": "article"
  },
  {
    "title": "A heuristic bidding strategy for buying multiple goods in multiple english auctions",
    "doi": "https://doi.org/10.1145/1183463.1183469",
    "publication_date": "2006-11-01",
    "publication_year": 2006,
    "authors": "Minghua He; Nicholas R. Jennings; Adam Prügel‐Bennett",
    "corresponding_authors": "",
    "abstract": "This paper presents the design, implementation, and evaluation of a novel bidding algorithm that a software agent can use to obtain multiple goods from multiple overlapping English auctions. Specifically, an Earliest Closest First heuristic algorithm is proposed that uses neurofuzzy techniques to predict the expected closing prices of the auctions and to adapt the agent's bidding strategy to reflect the type of environment in which it is situated. This algorithm first identifies the set of auctions that are most likely to give the agent the best return and then, according to its attitude to risk, it bids in some other auctions that have approximately similar expected returns, but which finish earlier than those in the best return set. We show through empirical evaluation against a number of methods proposed in the multiple auction literature that our bidding strategy performs effectively and robustly in a wide range of scenarios.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W2146206270",
    "type": "article"
  },
  {
    "title": "Adapting Web information extraction knowledge via mining site-invariant and site-dependent features",
    "doi": "https://doi.org/10.1145/1189740.1189746",
    "publication_date": "2007-02-01",
    "publication_year": 2007,
    "authors": "Tak-Lam Wong; Wai Lam",
    "corresponding_authors": "",
    "abstract": "We develop a novel framework that aims at automatically adapting previously learned information extraction knowledge from a source Web site to a new unseen target site in the same domain. Two kinds of features related to the text fragments from the Web documents are investigated. The first type of feature is called, a site-invariant feature. These features likely remain unchanged in Web pages from different sites in the same domain. The second type of feature is called a site-dependent feature. These features are different in the Web pages collected from different Web sites, while they are similar in the Web pages originating from the same site. In our framework, we derive the site-invariant features from previously learned extraction knowledge and the items previously collected or extracted from the source Web site. The derived site-invariant features will be exploited to automatically seek a new set of training examples in the new unseen target site. Both the site-dependent features and the site-invariant features of these automatically discovered training examples will be considered in the learning of new information extraction knowledge for the target site. We conducted extensive experiments on a set of real-world Web sites collected from three different domains to demonstrate the performance of our framework. For example, by just providing training examples from one online book catalog Web site, our approach can automatically extract information from ten different book catalog sites achieving an average precision and recall of 71.9% and 84.0% respectively without any further manual intervention.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W1994382199",
    "type": "article"
  },
  {
    "title": "Web site personalization based on link analysis and navigational patterns",
    "doi": "https://doi.org/10.1145/1278366.1278370",
    "publication_date": "2007-10-01",
    "publication_year": 2007,
    "authors": "Magdalini Eirinaki; Michalis Vazirgiannis",
    "corresponding_authors": "",
    "abstract": "The continuous growth in the size and use of the World Wide Web imposes new methods of design and development of online information services. The need for predicting the users' needs in order to improve the usability and user retention of a Web site is more than evident and can be addressed by personalizing it. Recommendation algorithms aim at proposing “next” pages to users based on their current visit and past users' navigational patterns. In the vast majority of related algorithms, however, only the usage data is used to produce recommendations, disregarding the structural properties of the Web graph. Thus important—in terms of PageRank authority score—pages may be underrated. In this work, we present UPR , a PageRank-style algorithm which combines usage data and link analysis techniques for assigning probabilities to Web pages based on their importance in the Web site's navigational graph. We propose the application of a localized version of UPR ( l-UPR ) to personalized navigational subgraphs for online Web page ranking and recommendation. Moreover, we propose a hybrid probabilistic predictive model based on Markov models and link analysis for assigning prior probabilities in a hybrid probabilistic model. We prove, through experimentation, that this approach results in more objective and representative predictions than the ones produced from the pure usage-based approaches.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W1999874211",
    "type": "article"
  },
  {
    "title": "A framework for service-oriented computing with C and C++ Web service components",
    "doi": "https://doi.org/10.1145/1361186.1361188",
    "publication_date": "2008-05-01",
    "publication_year": 2008,
    "authors": "Robert A. van Engelen",
    "corresponding_authors": "Robert A. van Engelen",
    "abstract": "Service-oriented architectures use loosely coupled software services to support the requirements of business processes and software users. Several software engineering challenges have to be overcome to expose legacy C and C++ applications and specialized system resources as XML-based software services. It is critical to devise effective bindings between XML and C/C++ data to efficiently interoperate with other XML-based services. Binding application data to XML has many software solutions, ranging from generic document object models to idiosyncratic type mappings. A safe binding must conform to XML validation constraints, guarantee type safety, and should preserve the structural integrity of communicated application data. However, tight XML bindings impose mapping constraints that can hamper interoperability between services. This paper presents a framework for constructing loosely coupled C/C++ services based on a programming model that integrates XML bindings into the C and C++ syntax. The concepts behind the bindings are generic, which makes the approach applicable to other programming languages.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W2081406395",
    "type": "article"
  },
  {
    "title": "Improving Web search using image snippets",
    "doi": "https://doi.org/10.1145/1391949.1391955",
    "publication_date": "2008-09-01",
    "publication_year": 2008,
    "authors": "Xiaobing Xue; Zhi‐Hua Zhou; Zhongfei Zhang",
    "corresponding_authors": "",
    "abstract": "The Web has become the largest information repository in the world; thus, effectively and efficiently searching the Web becomes a key challenge. Interactive Web search divides the search process into several rounds, and for each round the search engine interacts with the user for more knowledge of the user's information requirement. Previous research mainly uses the text information on Web pages, while little attention is paid to other modalities. This article shows that Web search performance can be significantly improved if imagery is considered in interactive Web search. Compared with text, imagery has its own advantage: the time for “reading” an image is as little as that for reading one or two words, while the information brought by an image is as much as that conveyed by a whole passage of text. In order to exploit the advantages of imagery, a novel interactive Web search framework is proposed, where image snippets are first extracted from Web pages and then provided, along with the text snippets, to the user for result presentation and relevance feedback, as well as being presented alone to the user for image suggestion. User studies show that it is more convenient for the user to identify the Web pages he or she expects and to reformulate the initial query. Further experiments demonstrate the promise of introducing multimodal techniques into the proposed interactive Web search framework.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W2104841644",
    "type": "article"
  },
  {
    "title": "QoS-Aware service management for component-based distributed applications",
    "doi": "https://doi.org/10.1145/1361186.1361190",
    "publication_date": "2008-05-01",
    "publication_year": 2008,
    "authors": "Jingwen Jin; Klara Nahrstedt",
    "corresponding_authors": "",
    "abstract": "Component-based software development has evolved from a tightly coupled style to a loosely coupled style in the recent few years. The paradigm shift will eventually allow heterogeneous systems to interoperate in open networks such as the Internet and will make software development more of a management task than a development task. Envisioning that future applications may comprise dynamically aggregated component services possibly distributed widely, we develop a Quality of Service (QoS)-aware service management framework in the middleware layer to make the component services infrastructure transparent to the applications. Specifically, we manage services not only as individuals, but more importantly as meaningful aggregated entities based on the logical compositional needs coming from the applications, by composing services properly according to QoS requirements at application setup time, and performing continuous maintenance at application runtime seamlessly. Our service management framework is scalable in two dimensions: network size and application's client population size. Specifically, the framework employs a decentralized management solution that scales to large network size, and explores resource sharing in one-to-many group-based applications by means of multicasting mechanisms. Moreover, it incorporates local adaptation operations and distributed failure detection, reporting, and recovery mechanisms to deal with runtime resource fluctuations and failures.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W2155875925",
    "type": "article"
  },
  {
    "title": "Impact of XML Schema Evolution",
    "doi": "https://doi.org/10.1145/1993083.1993087",
    "publication_date": "2011-07-01",
    "publication_year": 2011,
    "authors": "Pierre Genevès; Nabil Layaïda; Vincent Quint",
    "corresponding_authors": "",
    "abstract": "We consider the problem of XML Schema evolution. In the ever-changing context of the web, XML schemas continuously change in order to cope with the natural evolution of the entities they describe. Schema changes have important consequences. First, existing documents valid with respect to the original schema are no longer guaranteed to fulfill the constraints described by the evolved schema. Second, the evolution also impacts programs, manipulating documents whose structure is described by the original schema. We propose a unifying framework for determining the effects of XML Schema evolution both on the validity of documents and on queries. The system is very powerful in analyzing various scenarios in which forward/backward compatibility of schemas is broken, and in which the result of a query may no longer be what was expected. Specifically, the system offers a predicate language that allows one to formulate properties related to schema evolution. The system then relies on exact reasoning techniques to perform a fine-grained analysis. This yields either a formal proof of the property or a counter-example that can be used for debugging purposes. The system has been fully implemented and tested with real-world use cases, in particular with the main standard document formats used on the web, as defined by W3C. The system precisely identifies compatibility relations between document formats. In case these relations do not hold, the system can identify queries that must be reformulated in order to produce the expected results across successive schema versions.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W1977074715",
    "type": "article"
  },
  {
    "title": "A Framework for Classification of Traffic Management Practices as Reasonable or Unreasonable",
    "doi": "https://doi.org/10.1145/1852096.1852100",
    "publication_date": "2010-10-01",
    "publication_year": 2010,
    "authors": "Scott Jordan; Arijit Ghosh",
    "corresponding_authors": "",
    "abstract": "Traffic management practices of ISPs are an issue of public concern. We propose a framework for classification of traffic management practices as reasonable or unreasonable. We present a survey of traffic management techniques and examples of how these techniques are used by ISPs. We suggest that whether a traffic management practice is reasonable rests on the answers to four questions regarding the techniques and practices used. We propose a framework that classifies techniques as unreasonable if they are unreasonably anticompetitive, cause undue harm to consumers, or unreasonably impair free speech. We propose alternatives to unreasonable or borderline congestion management practices.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W1995478475",
    "type": "article"
  },
  {
    "title": "Achieving Data Consistency by Contextualization in Web-Based Collaborative Applications",
    "doi": "https://doi.org/10.1145/1944339.1944340",
    "publication_date": "2011-03-01",
    "publication_year": 2011,
    "authors": "Haifeng Shen; Chengzheng Sun",
    "corresponding_authors": "",
    "abstract": "Recent years have witnessed the emergence and rapid development of collaborative Web-based applications exemplified by Web-based office productivity applications. One major challenge in building these applications is maintaining data consistency while meeting the requirements of fast local response, total work preservation, unconstrained interaction, and customizable collaboration mode. These requirements are important in determining users’ experiences in interaction and collaboration, and in meeting users’ diverse needs under complex and dynamic collaboration and networking environments; but none of existing solutions is able to meet all of them. In this article, we present a data consistency maintenance solution capable of meeting these requirements for collaborative Web-based applications. Major technical contributions include an efficient sequence-based operation transformation control algorithm based on the concept of contextualization, an operation broadcast protocol for supporting a variety of collaboration modes, an operation replaying algorithm for ensuring fast local response and efficient remote operation replay, and a set of communication protocols for managing the integrity of collaborative Web-based sessions. The proposed solution has been implemented in a prototype collaborative Web-based editor WRACE and the correctness of the solution is formally verified in the article.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2057196866",
    "type": "article"
  },
  {
    "title": "A Multi-Dimensional Smart Community Discovery Scheme for IoT-Enriched Smart Homes",
    "doi": "https://doi.org/10.1145/3062178",
    "publication_date": "2017-10-26",
    "publication_year": 2017,
    "authors": "Taehun Kim; Junsung Lim; Heesuk Son; Byoungheon Shin; Dongman Lee; Soon J. Hyun",
    "corresponding_authors": "",
    "abstract": "The proliferation of the Internet into every household has provided more opportunities for residents to become closer to each other than before. However, solid structural barrier is raised and social relationships within such neighborhoods are weak compared to those in traditional towns. Accordingly, activating communities and ultimately enhancing a sense of community through constructive participation and communal sharing of labor among residents has currently emerged as a challenging issue in a contemporary housing complex. In an effort to activate those communities, a notion of smart community is presented in which multiple smart homes are equipped with Internet of Things and interconnected with each other. Beyond the unadorned smart community composed by physical proximity, it is essential to discover a human-centric community that achieves communal benefits and enables residents to maximize individual economic gain by leveraging collective intelligence. In this article, we present a multi-dimensional smart community discovery scheme that enables householders to find human-centric community considering multi-dimensional factors in terms of physical, social, and economical aspects. We conduct experiments with 30 real households by applying a community-based energy saving scenario. Experiment results show that the proposed scheme performs better when compared to the physical proximity-based one in energy consumption and user satisfaction.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W2766833882",
    "type": "article"
  },
  {
    "title": "IoT Data Prefetching in Indoor Navigation SOAs",
    "doi": "https://doi.org/10.1145/3177777",
    "publication_date": "2018-11-30",
    "publication_year": 2018,
    "authors": "Andreas Konstantinidis; Panagiotis Irakleous; Zacharias Georgiou; Demetrios Zeinalipour-Yazti; Panos K. Chrysanthis",
    "corresponding_authors": "",
    "abstract": "Internet-based Indoor Navigation Service-Oriented Architectures (IIN-SOA) organize signals collected by IoT-based devices to enable a wide range of novel applications indoors, where people spend 80--90% of their time. In this article, we study the problem of prefetching (or hoarding) the most important IoT data from an IIN-SOA to a mobile device, without knowing its user’s destination during navigation . Our proposed Grap (Graph Prefetching) framework structurally analyzes building topologies to identify important areas that become virtual targets to an online heuristic search algorithm we developed. We tested Grap with datasets from a real IIN-SOA and found it to be impressively accurate.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W2902254883",
    "type": "article"
  },
  {
    "title": "Context-Driven and Real-Time Provisioning of Data-Centric IoT Services in the Cloud",
    "doi": "https://doi.org/10.1145/3151006",
    "publication_date": "2018-11-30",
    "publication_year": 2018,
    "authors": "Amir Taherkordi; Frank Eliassen; Michael McDonald; Geir Horn",
    "corresponding_authors": "",
    "abstract": "The convergence of Internet of Things (IoT) and the Cloud has significantly facilitated the provision and management of services in large-scale applications, such as smart cities. With a huge number of IoT services accessible through clouds, it is very important to model and expose cloud-based IoT services in an efficient manner, promising easy and real-time delivery of cloud-based, data-centric IoT services. The existing work in this area has adopted a uniform and flat view to IoT services and their data, making it difficult to achieve the above goal. In this article, we propose a software framework, Context-driven And Real-time IoT (CARIoT) for real-time provisioning of cloud-based IoT services and their data, driven by their contextual properties. The main idea behind the proposed framework is to structure the description of data-centric IoT services and their real-time and historical data in a hierarchical form in accordance with the end-user application’s context model. CARIoT features design choices and software services to realize this service provisioning model and the supporting data structures for hierarchical IoT data access. Using this approach, end-user applications can access IoT services and subscribe to their real-time and historical data in an efficient manner at different contextual levels, e.g., from a municipal district to a street in smart city use cases. We leverage a popular cloud-based data storage platform, called Firebase, to implement the CARIoT framework and evaluate its efficiency. The evaluation results show that CARIoT’s hierarchical structure imposes no additional overhead with less data notification delay as compared to existing flat structures.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W2902471021",
    "type": "article"
  },
  {
    "title": "BPMS-RA",
    "doi": "https://doi.org/10.1145/3232677",
    "publication_date": "2019-02-18",
    "publication_year": 2019,
    "authors": "Shaya Pourmirza; Sander Peters; Remco Dijkman; Paul Grefen",
    "corresponding_authors": "",
    "abstract": "A growing number of business process management systems is under development both in academia and in practice. These systems typically are based on modern system engineering principles, such as service-oriented architecture. At the same time, the advent of big data analytics has changed the scope of these systems, including functionality such as data mining. However, existing reference architectures for business process management systems date back 20 years and, consequently, are not up-to-date with these modern developments. To fill the gap, this article proposes an up-to-date reference architecture, called BPMS-RA, for modern business process management systems. BPMS-RA is based on analysis of recent literature and of existing commercial implementations. This reference architecture aims to provide a guideline template for the development of modern-day business process management systems by specifying functions and interfaces that need to be provided by these systems as well as a set of quality criteria that they need to meet.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W2916898754",
    "type": "article"
  },
  {
    "title": "An Anonymous Delegatable Attribute-based Credential Scheme for a Collaborative E-health Environment",
    "doi": "https://doi.org/10.1145/3338854",
    "publication_date": "2019-08-31",
    "publication_year": 2019,
    "authors": "Harsha S. Gardiyawasam Pussewalage; Vladimir Oleshchuk",
    "corresponding_authors": "",
    "abstract": "We propose an efficient anonymous, attribute-based credential scheme capable of provisioning multi-level credential delegations. It is integrated with a mechanism to revoke the anonymity of credentials for resolving access disputes and making users accountable for their actions. The proposed scheme has a lower end-user computational complexity in comparison to existing credential schemes with delegatability and has a comparable level of performance with the credential standards of U-Prove and Idemix. Furthermore, we demonstrate how the proposed scheme can be applied to a collaborative e-health environment to provide its users with the necessary anonymous access with delegation capabilities.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W2971756154",
    "type": "article"
  },
  {
    "title": "JCloudScale",
    "doi": "https://doi.org/10.1145/2792980",
    "publication_date": "2015-07-28",
    "publication_year": 2015,
    "authors": "Rostyslav Zabolotnyi; Philipp Leitner; Waldemar Hummer; Schahram Dustdar",
    "corresponding_authors": "",
    "abstract": "Building Infrastructure-as-a-Service (IaaS) applications today is a complex, repetitive, and error-prone endeavor, as IaaS does not provide abstractions on top of virtual machines. This article presents JC loud S cale , a Java-based middleware for moving elastic applications to IaaS clouds, with minimal adjustments to the application code. We discuss the architecture and technical features, as well as evaluate our system with regard to user acceptance and performance overhead. Our user study reveals that JC loud S cale allows many participants to build IaaS applications more efficiently, compared to industrial Platform-as-a-Service (PaaS) solutions. Additionally, unlike PaaS, JC loud S cale does not lead to a control loss and vendor lock-in.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2064628664",
    "type": "article"
  },
  {
    "title": "A Proxy View of Quality of Domain Name Service, Poisoning Attacks and Survival Strategies",
    "doi": "https://doi.org/10.1145/2461321.2461324",
    "publication_date": "2013-05-01",
    "publication_year": 2013,
    "authors": "Lihua Yuan; Chao-Chih Chen; Prasant Mohapatra; Chen‐Nee Chuah; Krishna Kant",
    "corresponding_authors": "",
    "abstract": "The Domain Name System (DNS) provides a critical service for the Internet -- mapping of user-friendly domain names to their respective IP addresses. Yet, there is no standard set of metrics quantifying the Quality of Domain Name Service (QoDNS), let alone a thorough evaluation of it. This article attempts to fill this gap from the perspective of a DNS proxy/cache, which is the bridge between clients and authoritative servers. We present an analytical model of DNS proxy operations that offers insights into the design trade-offs of DNS infrastructure and the selection of critical DNS parameters. Due to the critical role DNS proxies play in QoDNS, they are the focus of attacks including cache poisoning attack. We extend the analytical model to study DNS cache poisoning attacks and their impact on QoDNS metrics. This analytical study prompts us to present Domain Name Cross-Referencing (DoX), a peer-to-peer systems for DNS proxies to cooperatively defend cache poisoning attacks. Based on QoDNS, we compare DoX with the cryptography-based DNS Security Extension (DNSSEC) to understand their relative merits.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2148906017",
    "type": "article"
  },
  {
    "title": "Integrating Multi-level Tag Recommendation with External Knowledge Bases for Automatic Question Answering",
    "doi": "https://doi.org/10.1145/3319528",
    "publication_date": "2019-05-07",
    "publication_year": 2019,
    "authors": "Eduardo Lima; Weishi Shi; Xumin Liu; Qi Yu",
    "corresponding_authors": "",
    "abstract": "We focus on using natural language unstructured textual Knowledge Bases (KBs) to answer questions from community-based Question-and-Answer (Q8A) websites. We propose a novel framework that integrates multi-level tag recommendation with external KBs to retrieve the most relevant KB articles to answer user posted questions. Different from many existing efforts that primarily rely on the Q8A sites’ own historical data (e.g., user answers), retrieving answers from authoritative external KBs (e.g., online programming documentation repositories) has the potential to provide rich information to help users better understand the problem, acquire the knowledge, and hence avoid asking similar questions in future. The proposed multi-level tag recommendation best leverages the rich tag information by first categorizing them into different semantic levels based on their usage frequencies. A post-tag co-clustering model, augmented by a two-step tag recommender, is used to predict tags at different levels for a given user posted question. A KB article retrieval component leverages the recommended multi-level tags to select the appropriate KBs and search/rank the matching articles thereof. We conduct extensive experiments using real-world data from a Q8A site and multiple external KBs to demonstrate the effectiveness of the proposed question-answering framework.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2944008584",
    "type": "article"
  },
  {
    "title": "Blockchain-based Data Sharing System for Sensing-as-a-Service in Smart Cities",
    "doi": "https://doi.org/10.1145/3397202",
    "publication_date": "2020-07-07",
    "publication_year": 2020,
    "authors": "Chao Lin; Debiao He; Sherali Zeadally; Xinyi Huang; Zhe Liu",
    "corresponding_authors": "",
    "abstract": "The sensing-as-a-service (SaaS) model has been explored to address the challenge of intractability of managing a large number of sensors faced by future smart cities. However, how to effectively share sensor data without compromising confidentiality, privacy protection, and fair trading without third parties is one of critical issues that must be solved in the SaaS in smart cities. While blockchain shows promise in solving these issues, the existing blockchain-based data sharing (BBDS) systems are difficult to apply to SaaS in smart cities because of many unresolved issues such as requiring a customized blockchain, huge storage, communication and computation costs, and dependence on a third party to achieve fair trading. We propose a BBDS system model with its security requirements before we present a concrete construction by combining <?TeX $\\Sigma$?> -protocol, Paillier encryption scheme, and any secure symmetrical encryption and signature schemes. To demonstrate the utility of our proposed BBDS system, we present a security analysis and compare our system with other solutions. We implement the prototype in Remix to analyze the gas cost, and we conduct experiments to evaluate the communication and computation costs of the BBDS system using symmetric encryption (advanced encryption standard (AES)) and a signature scheme (elliptic curve digital signature algorithm (ECDSA)).",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W3040639011",
    "type": "article"
  },
  {
    "title": "Large-Scale Least Squares Twin SVMs",
    "doi": "https://doi.org/10.1145/3398379",
    "publication_date": "2020-07-07",
    "publication_year": 2020,
    "authors": "M. Tanveer; Sweta Sharma; Khan Muhammad",
    "corresponding_authors": "",
    "abstract": "In the last decade, twin support vector machine (TWSVM) classifiers have achieved considerable emphasis on pattern classification tasks. However, the TWSVM formulation still suffers from the following two shortcomings: (1) TWSVM deals with the inverse matrix calculation in the Wolfe-dual problems, which is intractable for large-scale datasets with numerous features and samples, and (2) TWSVM minimizes the empirical risk instead of the structural risk in its formulation. With the advent of huge amounts of data today, these disadvantages render TWSVM an ineffective choice for pattern classification tasks. In this article, we propose an efficient large-scale least squares twin support vector machine (LS-LSTSVM) for pattern classification that rectifies all the aforementioned shortcomings. The proposed LS-LSTSVM introduces different Lagrangian functions to eliminate the need for calculating inverse matrices. The proposed LS-LSTSVM also does not employ kernel-generated surfaces for the non-linear case, and thus uses the kernel trick directly. This ensures that the proposed LS-LSTSVM model is superior to the original TWSVM and LSTSVM. Lastly, the structural risk is minimized in LS-LSTSVM. This exhibits the essence of statistical learning theory, and consequently, classification accuracy on datasets can be improved due to this change. The proposed LS-LSTSVM is solved using the sequential minimal optimization (SMO) technique, making it more suitable for large-scale problems. We further proved the convergence of the proposed LS-LSTSVM. Exhaustive experiments on several real-world benchmarks and NDC-based large-scale datasets demonstrate that the proposed LS-LSTSVM is feasible for large datasets and, in most cases, performed better than existing algorithms.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W3042185344",
    "type": "article"
  },
  {
    "title": "EPRT: An Efficient Privacy-Preserving Medical Service Recommendation and Trust Discovery Scheme for eHealth System",
    "doi": "https://doi.org/10.1145/3397678",
    "publication_date": "2020-07-07",
    "publication_year": 2020,
    "authors": "Cong Peng; Debiao He; Jianhua Chen; Neeraj Kumar; Muhammad Khurram Khan",
    "corresponding_authors": "",
    "abstract": "As one of the essential applications of health information technology, the eHealth system plays a significant role in enabling various internet medicine service scenes, most of which primarily rely on service recommendation or an evaluation mechanism. To avoid privacy leakage, some privacy-preserving mechanisms must be adopted to protect raters’ privacy and make evaluation trust reliable. To tackle this challenge, this article proposes an efficient service recommendation and evaluation scheme, called EPRT , which is based on a similarity calculation and trust discovery method. This scheme uses homomorphic encryption technology to encrypt the sensitive data and combines the threshold mechanism and double-trap mechanism to realize the secure computing on the encrypted data, so as to ensure that the plaintexts of the final calculation results (e.g., recommendation value and evaluation truth) are only obtained by the authorized subject. In addition, a detailed security analysis shows that the proposed EPRT scheme can achieve the expected security. In addition, performance comparison results are carried out, demonstrating its effectiveness and accuracy.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W3083748269",
    "type": "article"
  },
  {
    "title": "Ontology-Based Query Answering with Group Preferences",
    "doi": "https://doi.org/10.1145/2677207",
    "publication_date": "2014-12-17",
    "publication_year": 2014,
    "authors": "Thomas Lukasiewicz; María Vanina Martínez; Gerardo I. Simari; Oana Tifrea-Marciuska",
    "corresponding_authors": "",
    "abstract": "The Web has recently been evolving into a system that is in many ways centered on social interactions and is now more and more becoming what is called the Social Semantic Web. One of the many implications of such an evolution is that the ranking of search results no longer depends solely on the structure of the interconnections among Web pages—instead, the social components must also come into play. In this article, we argue that such rankings can be based on ontological background knowledge and on user preferences. Another aspect that has become increasingly important in recent times is that of uncertainty management, since uncertainty can arise due to many uncontrollable factors. To combine these two aspects, we propose extensions of the Datalog+/-- family of ontology languages that both allow for the management of partially ordered preferences of groups of users as well as uncertainty, which is represented via a probabilistic model. We focus on answering k -rank queries in this context, presenting different strategies to compute group preferences as an aggregation of the preferences of a collection of single users. We also study merging operators that are useful for combining the preferences of the users with those induced by the values obtained from the probabilistic model. We then provide algorithms to answer k -rank queries for DAQs (disjunctions of atomic queries) under these group preferences and uncertainty that generalizes top- k queries based on the iterative computation of classical skyline answers. We show that such DAQ answering in Datalog+/-- can be done in polynomial time in the data complexity, under certain reasonable conditions, as long as query answering can also be done in polynomial time (in the data complexity) in the underlying classical ontology. Finally, we present a prototype implementation of the query answering system, as well as experimental results (on the running time of our algorithms and the quality of their results) obtained from real-world ontological data and preference models, derived from information gathered from real users, showing in particular that our approach is feasible in practice.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2036555103",
    "type": "article"
  },
  {
    "title": "Virtual Reality Aided High-Quality 3D Reconstruction by Remote Drones",
    "doi": "https://doi.org/10.1145/3458930",
    "publication_date": "2021-09-14",
    "publication_year": 2021,
    "authors": "Di Zhang; Feng Xu; Chi‐Man Pun; Yang Yang; Rushi Lan; Liejun Wang; Yujie Li; Hao Gao",
    "corresponding_authors": "",
    "abstract": "Artificial intelligence including deep learning and 3D reconstruction methods is changing the daily life of people. Now, an unmanned aerial vehicle that can move freely in the air and avoid harsh ground conditions has been commonly adopted as a suitable tool for 3D reconstruction. The traditional 3D reconstruction mission based on drones usually consists of two steps: image collection and offline post-processing. But there are two problems: one is the uncertainty of whether all parts of the target object are covered, and another is the tedious post-processing time. Inspired by modern deep learning methods, we build a telexistence drone system with an onboard deep learning computation module and a wireless data transmission module that perform incremental real-time dense reconstruction of urban cities by itself. Two technical contributions are proposed to solve the preceding issues. First, based on the popular depth fusion surface reconstruction framework, we combine it with a visual-inertial odometry estimator that integrates the inertial measurement unit and allows for robust camera tracking as well as high-accuracy online 3D scan. Second, the capability of real-time 3D reconstruction enables a new rendering technique that can visualize the reconstructed geometry of the target as navigation guidance in the HMD. Therefore, it turns the traditional path-planning-based modeling process into an interactive one, leading to a higher level of scan completeness. The experiments in the simulation system and our real prototype demonstrate an improved quality of the 3D model using our artificial intelligence leveraged drone system.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W3198994958",
    "type": "article"
  },
  {
    "title": "IoT-based Cloud Service for Secured Android Markets using PDG-based Deep Learning Classification",
    "doi": "https://doi.org/10.1145/3418206",
    "publication_date": "2021-10-22",
    "publication_year": 2021,
    "authors": "Farhan Ullah; Muhammad Rashid Naeem; Abdullah Bajahzar; Fadi Al‐Turjman",
    "corresponding_authors": "",
    "abstract": "Software piracy is an act of illegal stealing and distributing commercial software either for revenue or identify theft. Pirated applications on Android app stores are harming developers and their users by clone scammers. The scammers usually generate pirated versions of the same applications and publish them in different open-source app stores. There is no centralized system between these app stores to prevent scammers from publishing pirated applications. As most of the app stores are hosted on cloud storage, therefore a cloud-based interaction system can prevent scammers from publishing pirated applications. In this paper, we proposed IoT-based cloud architecture for clone detection using program dependency analysis. First, the newly submitted APK and possible original files are selected from app stores. The APK Extractor and JDEX decompiler extract APK and DEX files for Java source code analysis. The dependency graphs of Java files are generated to extract a set of weighted features. The Stacked-Long Short-Term Memory (S-LSTM) deep learning model is designed to predict possible clones. Experimental results have shown that the proposed approach can achieve an average accuracy of 95.48% among clones from different application stores.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W3209663641",
    "type": "article"
  },
  {
    "title": "Efficient Cryptographic Hardware for Safety Message Verification in Internet of Connected Vehicles",
    "doi": "https://doi.org/10.1145/3431499",
    "publication_date": "2022-02-03",
    "publication_year": 2022,
    "authors": "Ali Mehrabi; Alireza Jolfaei",
    "corresponding_authors": "",
    "abstract": "An important security requirement in automotive networks is to authenticate, sign, and verify thousands of short messages per second by each vehicle. This requirement mandates the use of a high speed Elliptic Curve Cryptography (ECC) hardware. The Residue Number Systems (RNS) provide a natural parallelism and carry-free operations that could speed-up long integer arithmetics of cryptographic algorithms. In this article, we propose a high-speed RNS Montgomery modular reduction units with parallel computing to reduce the latency of the field modular operations. We propose a fully RNS-based ECC scalar multiplication co-processor for NIST-P256r1 and Brainpool256r1 standard curves and improved the scalar multiplication speed using NAF and DBC numbering systems. Compared to the literature, our scheme provides faster computation without compromising the security level. The performance of our fully RNS-ECC point multiplication meets the requirements of the automotive industry.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W4210693158",
    "type": "article"
  },
  {
    "title": "Optimal Energy-Centric Resource Allocation and Offloading Scheme for Green Internet of Things Using Machine Learning",
    "doi": "https://doi.org/10.1145/3431500",
    "publication_date": "2022-05-14",
    "publication_year": 2022,
    "authors": "Gunasekaran Manogaran; Bharat S. Rawal; Houbing Song; Huihui Wang; Ching‐Hsien Hsu; Vijayalakshmi Saravanan; Seifedine Kadry; P. Mohamed Shakeel",
    "corresponding_authors": "",
    "abstract": "Resource allocation and offloading in green Internet of Things (IoT) relies on the multi-level heterogeneous platforms. The energy expenses of the platform determine the reliability of green IoT based services and applications. This manuscript introduces a decisive energy management scheme for optimal resource allocation and offloading along with energy constraints. This scheme handles both the allocation and energy-cost in a balanced manner through deterministic task offloading. In particular, resource allocation solution for non-delay tolerant green IoT applications is focused by confining the failures of discrete tasks through neural learning. The dropout process augmented with the learning process improves the feasible conditions for resource handling and task offloading among the active IoT service providers. Through extensive simulations the performance of the proposed scheme is analyzed and energy consumption, failure rate, processing, and completion time metrics are used for a comparative study. Further, the optimal utilization and on-demand dissipation of such stored resources help to improve the sustainability of green power and communication technologies in the smart city environment.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W4280502195",
    "type": "article"
  },
  {
    "title": "L2DART: A Trust Management System Integrating Blockchain and Off-Chain Computation",
    "doi": "https://doi.org/10.1145/3561386",
    "publication_date": "2022-09-19",
    "publication_year": 2022,
    "authors": "Andrea De Salve; Luca Franceschi; Andrea Lisi; Paolo Mori; Laura Ricci",
    "corresponding_authors": "",
    "abstract": "The blockchain technology has been gaining an increasing popularity for the last years, and smart contracts are being used for a growing number of applications in several scenarios. The execution of smart contracts on public blockchains can be invoked by any user with a transaction, although in many scenarios there would be the need for restricting the right of executing smart contracts only to a restricted set of users. To help deal with this issue, this article proposes a system based on a popular access control framework called RT, Role-based Trust Management, to regulate smart contracts execution rights. The proposed system, called Layer 2 DecentrAlized Role-based Trust management (L2DART), implements the RT framework on a public blockchain, and it is designed as a layer-2 technology that involves both on-chain and off-chain functionalities to reduce the blockchain costs while keeping blockchain auditability, i.e., immutability and transparency. The on-chain costs of L2DART have been evaluated on Ethereum and compared with a previous solution implementing on-chain all the functionalities. The results show that the on-chain costs of L2DART are relatively low, making the system deployable in real-world scenarios.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W4296368437",
    "type": "article"
  },
  {
    "title": "Optimizing WebAssembly Bytecode for IoT Devices Using Deep Reinforcement Learning",
    "doi": "https://doi.org/10.1145/3731451",
    "publication_date": "2025-04-19",
    "publication_year": 2025,
    "authors": "Kaijie Gong; R. X. Yang; Haoyu Li; Yi Gao; Wei Dong",
    "corresponding_authors": "",
    "abstract": "WebAssembly has shown promising potential on various IoT devices to achieve the desired features such as multi-language support and seamless device-cloud integration. The execution performance of WebAssembly bytecode is directly influenced by compilation sequences. While existing research has explored the optimization of compilation sequences for native code, these approaches are not suitable to WebAssembly bytecode due to its unique instruction format and control flow graph structure. In this work, we propose WasmRL, a novel efficient deep reinforcement learning (DRL)-based compiler optimization framework tailored for WebAssembly bytecode. We conduct a fine-grained analysis of the characteristics of WebAssembly instructions and associated compilation flags. We observe that the same compilation sequence may yield contrasting performance outcomes in WebAssembly and native code. Motivated by our observation, we introduce a WebAssembly-specific DRL state representation that simultaneously captures the impact of various compilation sequences on the WebAssembly bytecode and its runtime performance. To enhance the training efficiency of the DRL model, we propose a tree-based action space refinement method. Furthermore, we develop a pluggable cross-platform training strategy to optimize WebAssembly bytecode across different IoT devices. We evaluate the performance of WasmRL extenssively on PolybenchC, MiBench, Shootout public datasets and real-world IoT applications. Experimental results show: (1) The DRL model trained on a specific device achieves 1.4x/1.1x speedups over -O3 for seen/unseen programs; (2) The DRL model trained on different devices simultaneously achieves 1.21x/1.06x improvements respectively. The code has been available at https://github.com/CarrollAdmin/WasmRL.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4409591329",
    "type": "article"
  },
  {
    "title": "Challenges and Experiences in Data Integration to Support Research on Nonprofit Organizations",
    "doi": "https://doi.org/10.1145/3727877",
    "publication_date": "2025-05-20",
    "publication_year": 2025,
    "authors": "Calton Pu; Mirae Kim; Teresa Derrick-Mills; Lewis Faulk",
    "corresponding_authors": "",
    "abstract": "Nonprofit organizations are important contributors to the US economy and social well-being. The Nonprofit Organization Research Panel Project (NORPP) Manager has been developing and sharing datasets and software tools to facilitate data-driven research on nonprofit organizations. The project has two major thrusts: (1) large-scale survey panels, e.g., the Annual National Survey of Nonprofit Trends and Impacts, from 2021 to the current (2024); and (2) NORPP Analytics Integration Platform (NAIP) to collect, process, and query a wide range of socioeconomic indicator datasets, such as IRS 990 form and census data. Technical challenges that include data heterogeneity, data quality, and protection of sensitive data have made the expansion and maintenance of NAIP datasets both labor-intensive and time-consuming. We are currently exploring new technologies, including Large Language Models such as GPT series, to automate database query generation, schema adaptation, and data quality assurance processes.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4410519471",
    "type": "article"
  },
  {
    "title": "TrafficDiary: User Attribute Inference Based on Smart Home Traffic Traces",
    "doi": "https://doi.org/10.1145/3736762",
    "publication_date": "2025-05-22",
    "publication_year": 2025,
    "authors": "Yunhao Yao; Jiahui Hou; Mu Yuan; H. Y. Zhang; Zhengyuan Xu; Xiang‐Yang Li",
    "corresponding_authors": "",
    "abstract": "Smart home technology has found wide-ranging applications in daily life, from enhancing energy efficiency to simplifying daily tasks and providing greater convenience. However, recent works have found that smart home devices are vulnerable to passive network observers (i.e., adversaries). While adversaries have demonstrated the ability to infer device events (e.g., whether a lamp is turned on) from the encrypted smart home traffic, we believe this only represents a less critical aspect of smart home privacy risks. Further analysis of demographic attributes presents greater risks to user privacy. Besides, from our deployment experience of real-world smart homes, we found that existing event inference methods can be greatly interfered with by event-unrelated traffic. Experiments show that this interference can result in up to a 10% drop in inference accuracy. Furthermore, it is challenging to infer finer-grained demographic attributes, due to the insufficient accuracy of event inference. Therefore, in this work, we propose a novel event inference model extracting multi-dimensional features that reduces the interference of event-unrelated traffic by analyzing packet length distribution and statistical properties. In addition, we design a dual-channel neural network to extract spatial and temporal relationships among triggered events to infer demographic attributes of smart home users, such as age group and career stage. Combining the above designs, we present TrafficDiary, the first user attribute inference approach based on smart home traffic traces. We prototype TrafficDiary and evaluate it in real-world smart homes. Experimental results show that TrafficDiary achieves 98.68% accuracy with a zero false positive rate in event inference and a high level of accuracy in user attribute inference, even when 16, 362 groups of event-unrelated traffic exist. TrafficDiary also performs well in terms of efficiency, with an inference latency of only 1.82 ms on a Raspberry Pi 4B device.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4410600974",
    "type": "article"
  },
  {
    "title": "Where are We in Audio Deepfake Detection? A Systematic Analysis over Generative and Detection Models",
    "doi": "https://doi.org/10.1145/3736765",
    "publication_date": "2025-05-26",
    "publication_year": 2025,
    "authors": "Xiang Li; Pin‐Yu Chen; Wenqi Wei",
    "corresponding_authors": "",
    "abstract": "Recent advances in Text-to-Speech (TTS) and Voice-Conversion (VC) using generative Artificial Intelligence (AI) technology have made it possible to generate high-quality and realistic human-like audio. This introduces significant challenges to distinguishing AI-synthesized speech from the authentic human voice and could raise potential issues of misuse for malicious purposes such as impersonation and fraud, spreading misinformation, deepfakes, and scams. However, existing detection techniques for AI-synthesized audio have not kept pace and often exhibit poor generalization across diverse datasets. In this paper, we introduce SONAR, a s ynthetic AI-Audi o Detectio n Fr a mework and Benchma r k, aiming to provide a comprehensive evaluation for distinguishing cutting-edge AI-synthesized auditory content. SONAR includes a novel evaluation dataset sourced from 9 diverse audio synthesis platforms, including leading TTS providers and state-of-the-art TTS models. It is the first framework to uniformly benchmark AI-audio detection across both traditional and foundation model-based deepfake detection systems. Through extensive experiments, (1) we reveal the generalization limitations of existing detection methods and demonstrate that foundation models exhibit stronger generalization capabilities, which can be attributed to their model size and the scale and quality of pretraining data. (2) Our evaluation of the generalization across languages suggests that speech foundation models demonstrate robust cross-lingual generalization capabilities, maintaining strong performance across diverse languages despite being fine-tuned solely on English speech data. This finding also suggests that the primary challenges in audio deepfake detection are more closely tied to the realism and quality of synthetic audio rather than language-specific characteristics. (3) We also explore the effectiveness and efficiency of few-shot fine-tuning in improving generalization, highlighting its potential for tailored applications, such as personalized detection systems for specific entities or individuals. Code and dataset are available at https://github.com/Jessegator/SONAR .",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4410748035",
    "type": "article"
  },
  {
    "title": "Wielding Blockchain Transactions for Capture-Replay Testing of Upgradeable Smart Contracts",
    "doi": "https://doi.org/10.1145/3737699",
    "publication_date": "2025-05-29",
    "publication_year": 2025,
    "authors": "Morena Barboni; Guglielmo De Angelis; Andrea Morichetta; Andrea Polini",
    "corresponding_authors": "",
    "abstract": "Blockchain technology is increasingly adopted in scenarios requiring trust and data integrity. On the Ethereum blockchain, the proxy pattern has become increasingly popular because it allows smart contract code to evolve while preserving stored data. However, a key challenge remains ensuring that such upgrades do not introduce breaking changes or cause disruptions to other contracts and off-chain systems. In this paper we introduce Catana , a framework that leverages historical transactions for Capture-Replay testing of proxy-based Upgradeable Smart Contracts (USCs). Catana assesses the potential impact of an upgrade by comparing the outcomes of replayed transactions with those from the previous version deployed on the main network. Additionally, it extracts and decodes contract state variables, providing deeper insights into how code changes affect the contract state, and helping developers mitigate issues before deployment. Experiments demonstrate that analyzing storage data accounts for the majority (about 86.5%) of detected disruptive upgrades. We also evaluate different policies for building replay test suites from historical transactions. Results identify a strategy that maximizes effectiveness while requiring a small number of replay test executions. Even a test suite containing just one transaction per each invoked method achieved good effectiveness (about \\(60\\% \\) ) in detecting disruptive upgrades.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4410863547",
    "type": "article"
  },
  {
    "title": "DeepSDN: Deep Learning Based Software Defined Network Model for Cyberthreat Detection in IoT Network",
    "doi": "https://doi.org/10.1145/3737875",
    "publication_date": "2025-05-29",
    "publication_year": 2025,
    "authors": "Korsten Hendrikus H.M.; K. Srinivasa Reddy",
    "corresponding_authors": "",
    "abstract": "The Internet of Things (IoT) presents new challenges to traditional communication models, particularly in terms of security, which are exacerbated by the rapid evolution of cyberthreats. Traditional security methods, especially those using Machine Learning models, often struggle with the limited computational resources available, making it difficult to detect attacks across the entire network. Software-defined networks (SDN) offer a solution by centralizing security policies, enabling more effective implementation and enforcement. The study investigates the SDN architecture from a security perspective. This paper proposes a Deep Learning-based SDN architecture for IoT security which can significantly enhance real-time cyberthreat detection. Specifically, a secure communication channel is first designed using a blockchain-based authentication to resist well-known intruders. Second, a deep learning convergence model using an adaptive threshold scoring method that stops all local model training and allows edge models to contribute to the cloud model until a specified accuracy is achieved. To achieve low CPU usage and provide real-time services, SDN is next used as a cloud-based system security administrator to protect IoT networks from zero-day attacks by sending requests from edge devices to a cloud SDN controller. The efficiency of the proposed framework is demonstrated using simulations with two different network datasets E-IIoT and ToN-IoT against various attacks and the results are compared with similar works. The proposed model effectively detects and mitigates cyberthreats such as DDoS, Black-Sink-Worm hole, MitM, and Ransomware. It achieves high performance with 99.15% accuracy, 99.31% precision, 98.97% recall, and a 99.14% F1 score, on an average while using less CPU power for real-time IoT network protection.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4410863764",
    "type": "article"
  },
  {
    "title": "An End to End Analysis of Crypto Scams on Ethereum",
    "doi": "https://doi.org/10.1145/3737874",
    "publication_date": "2025-05-29",
    "publication_year": 2025,
    "authors": "Jadyn Kimber; Enrico Branca; Andrei Natadze; Natalia Stakhanova",
    "corresponding_authors": "",
    "abstract": "The increasing number of Ethereum scams is causing significant concern within the blockchain community, costing users millions of dollars annually. Yet, our understanding of how these scams operate remains limited. In this study, we present the first end-to-end analysis of crypto scams using a large set of malicious Ethereum accounts as a case study. We examine the tactics these scams employ on social media platforms to deceive users and convince them to transfer funds to malicious accounts. Our analysis explores the full life cycle of these scams, considering both their distribution through social media and their activity on the Ethereum blockchain. We identify several unique aspects of Ethereum phishing scams that have not been documented in prior literature and find that these scams generally persist significantly longer and result in greater financial losses compared to traditional phishing scams studied in earlier research.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4410863842",
    "type": "article"
  },
  {
    "title": "Discovering NFT Rug Pulls: Matching Behavior Patterns Using Graph Isomorphism Networks",
    "doi": "https://doi.org/10.1145/3744561",
    "publication_date": "2025-06-11",
    "publication_year": 2025,
    "authors": "Trishie Sharma; Sandeep K. Shukla",
    "corresponding_authors": "",
    "abstract": "Amid the surge of Non-Fungible Tokens (NFTs) in blockchain, this study introduces a meticulous methodology focusing on transaction behaviors to unveil rug pulls — a critical issue impacting financial security and trust in the NFT landscape. Using a Graph Isomorphism Network (GIN) model with 6 behavioral patterns obtained from transaction sequences, we create a ‘Rug Pull Pattern Matcher’ model. We provide a comprehensive analysis by applying the model on two datasets — creator’s transactions from 50 reputable NFT projects and 32 reported rug pulls. Our work utilizes automated labeling to categorize addresses and our analysis reveals several interconnected NFT creator activities. We present an in-depth mapping of fund flows and creator interactions exposing suspicious behaviors like artificial inflation and intricate network collaborations among creators. The results of our proposed model demonstrate the efficacy of our methodology’s with 75.4% accuracy and 85.9% precision on the dataset of reported rug pulls. This work provides comparative analyses of genuine and malicious creator networks to elucidate their structural differences, helping to identify genuine and potentially fraudulent NFT activities.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4411213978",
    "type": "article"
  },
  {
    "title": "Analysis of the Behavior of Ethereum Accounts During an Economic Impact Event",
    "doi": "https://doi.org/10.1145/3745773",
    "publication_date": "2025-06-25",
    "publication_year": 2025,
    "authors": "Pedro Henrique Filgueiras dos Santos Oliveira; Daniel Muller Rezende; Saulo Moraes Villela; Heder S. Bernardino; Alex Borges Vieira; Glauber Dias Gonçalves",
    "corresponding_authors": "",
    "abstract": "One of the main events involving the world economy in 2022 was the beginning of the war between Russia and Ukraine. This event offers an opportunity to analyze how a large-magnitude world event can affect the use of cryptocurrencies. Ethereum is one of the most prominent and widely used cryptocurrency platforms and, as such, provides a valuable case study for this scenario. This work investigates the behavior of accounts and their transactions on the Ethereum network during this event. For this purpose, we collect all Ethereum transactions during two distinct periods: (i) during the month the conflict began, and (ii) during the previous year. We organized a dataset with the accounts involved in these transactions and the subset of these accounts that interacted with a service within Ethereum named Flashbots Auction. Flashbots Auction is crucial as it addresses issues regarding transaction ordering and miners exploiting that ordering to make profit. Then, we model temporal graphs in which each vertex represents an account, and each edge represents a transaction between two accounts. We analyzed the behavior of these accounts via graph metrics for both groups during each observed time window. The results show changes in account behavior and activity, as well as variations in daily transaction volume.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4411652466",
    "type": "article"
  },
  {
    "title": "Assessing and Mitigating Heterogeneity-Driven Security Threats in the Cloud",
    "doi": "https://doi.org/10.1145/3746228",
    "publication_date": "2025-07-02",
    "publication_year": 2025,
    "authors": "Chongzhou Fang; Najmeh Nazari; Behnam Omidi; Han Wang; Aditya Puri; Manish Arora; Setareh Rafatirad; Houman Homayoun; Khaled N. Khasawneh",
    "corresponding_authors": "",
    "abstract": "Cloud computing has become crucial for the commercial world due to its computational capacity, storage capabilities, scalability, software integration, and billing convenience. Initially, clouds were relatively homogeneous, but now diverse machine configurations in heterogeneous clouds are recognized for their improved application performance and energy efficiency. This shift is driven by the integration of various hardware to accommodate diverse user applications. However, alongside these advancements, security threats like micro-architectural attacks are increasing concerns for cloud providers and users. Studies like Repttack and Cloak &amp; Co-locate highlight the vulnerability of heterogeneous clouds to co-location attacks, where attacker and victim instances are placed together. The ease of these attacks isn’t solely linked to heterogeneity but also correlates with how heterogeneous the target systems are. Despite this, no numerical metrics exist to quantify cloud heterogeneity. This paper introduces the Heterogeneity Score (HeteroScore) to evaluate server setups and instances. HeteroScore significantly correlates with co-location attack security. The paper also proposes strategies to balance diversity and security. This study pioneers the quantitative analysis connecting cloud heterogeneity and infrastructure security.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4411927100",
    "type": "article"
  },
  {
    "title": "Integrated User Scheduling and Beam Steering in Over-the-Air Federated Learning for Mobile IoT",
    "doi": "https://doi.org/10.1145/3747348",
    "publication_date": "2025-07-04",
    "publication_year": 2025,
    "authors": "Shengheng Liu; Ningning Fu; Zhonghao Zhang; Yongming Huang; Tony Q. S. Quek",
    "corresponding_authors": "",
    "abstract": "The rising popularity of Internet of things (IoT) has spurred technological advancements in mobile internet and interconnected systems. While offering flexible connectivity and intelligent applications across various domains, IoT service providers must gather vast amounts of sensitive data from users, which nonetheless concomitantly raises concerns about privacy breaches. Federated learning (FL) has emerged as a promising decentralized training paradigm to tackle this challenge. This work focuses on enhancing the aggregation efficiency of distributed local models by introducing over-the-air computation into the FL framework. Due to radio resource scarcity in large-scale networks, only a subset of users can participate in each training round. This highlights the need for effective user scheduling and model transmission strategies to optimize communication efficiency and inference accuracy. To address this, we propose an integrated approach to user scheduling and receive beam steering, subject to constraints on the number of selected users and transmit power. Leveraging the difference-of-convex technique, we decompose the primal non-convex optimization problem into two sub-problems, yielding an iterative solution. While effective, the computational load of the iterative method hampers its practical implementation. To overcome this, we further propose a low-complexity user scheduling policy based on characteristic analysis of the wireless channel to directly determine the user subset without iteration. Extensive experiments validate the superiority of the proposed method in terms of aggregation error and learning performance over existing approaches.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4412035823",
    "type": "article"
  },
  {
    "title": "Enhancing Privacy-Preserving Knowledge Graph Embeddings with Federated Learning for IoT Services",
    "doi": "https://doi.org/10.1145/3747351",
    "publication_date": "2025-07-04",
    "publication_year": 2025,
    "authors": "Hongliang Sun; Xiaofeng Bi; Zhiying Tu; Bohai Zhao; Kai Zhang; Dianhui Chu; Xiaofei Xu",
    "corresponding_authors": "",
    "abstract": "As a structured representation of real-world facts, knowledge graphs (KGs) play a vital role in IoT applications, due to their strong reasoning capabilities and interpretability. However, private user IoT KG data often needs to be centrally collected for embedding training, which poses significant privacy risks and limits the scalability of knowledge-driven downstream applications in distributed IoT environments. Federated learning (FL) has emerged as a promising solution for decentralized model training, eliminating the need for direct data collection. However, existing federated knowledge graph embedding (KGE) methods often struggle to preserve the inherent graph structure of entities and relations, leading to fragmented and incomplete representations. Additionally, they struggle to effectively capture diverse relational dependencies within personal KGs. To address these challenges, this paper proposes an enhanced federated KG embedding method for personal knowledge sharing (FPKS) to enable privacy-preserving KGE training. The FPKS framework consists of a central server and multiple federated clients. To enhance entity and relationship alignment across clients, FPKS maintains separate embedding tables for entities and relationships on the server. Moreover, to capture the structural and contextual information of personal KGs, we introduce a local encoder-decoder architecture that employs a graph convolutional network (GCN) variant as an encoder and a KGE scoring function as a decoder. Furthermore, we propose a bidirectional composite operator for GCN (BiDGCN) to enhance multi-relational information aggregation. Extensive experiments on two widely used KG datasets demonstrate that FPKS significantly outperforms existing methods, improving the quality of learned embeddings while ensuring data privacy. Our approach facilitates decentralized personal knowledge sharing, marking an advancement in secure and efficient IoT knowledge-driven services.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4412035824",
    "type": "article"
  },
  {
    "title": "Achieving Resilient and Self-Adaptive Topology Configuration in 3D UAV Networks",
    "doi": "https://doi.org/10.1145/3747350",
    "publication_date": "2025-07-07",
    "publication_year": 2025,
    "authors": "Jhih‐Liang Huang; Mingzhe Chen; Yuchen Liu",
    "corresponding_authors": "",
    "abstract": "3D networks with unmanned aerial vehicles (UAVs) are emerging as a cornerstone of next-generation communication infrastructure, offering flexibility and enhanced coverage in challenging environments. However, prior works predominantly focus on UAV-specific optimizations and high-throughput strategies, often overlooking the critical aspect of network reliability when incorporating these movable entities in the infrastructure. Resilience is paramount in such networks, as it ensures stable performance and connectivity in the face of dynamic conditions, such as mobile edges, transient ground devices, and significant signal interference from urban environments. To address this gap, this paper proposes a topology-driven scheme from a holistic view of the 3D networks, leveraging comprehensive scene-based information to enable real-time network adaptability through topological (re)configuration. We decompose this reliability problem into three intertwined stages: topological resilience quantification, UAV self-positioning, and learning-based connectivity optimization. This framework ensures network resilience from a functional perspective, emphasizing the ability to consistently deliver high-quality performance while mitigating connectivity interruptions, essential for reliability of next-generation 3D communication infrastructure. Experimental results validate the effectiveness of our approach, demonstrating significant improvements over traditional methods in terms of bandwidth allocation to ground devices and load balancing among UAVs. Notably, our system excels in highly dynamic scenarios, where it adapts to network instability and connectivity failures on-demand, ensuring consistent and reliable communication performance.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4412091623",
    "type": "article"
  },
  {
    "title": "BlockEdge: A Hybrid Blockchain Framework for Secure and Efficient Collaboration in EEC Environments",
    "doi": "https://doi.org/10.1145/3747349",
    "publication_date": "2025-07-09",
    "publication_year": 2025,
    "authors": "Wangbo Shen; Weiwei Lin; Tiansheng Huang; Xinyi Hu; Mian Guo; Haijie Wu",
    "corresponding_authors": "",
    "abstract": "In End-Edge-Cloud (EEC) computing environments, the diversity of devices often requires cloud-trained models to be adapted for end/edge devices, complicating decentralized project management. To address this, end/edge devices are increasingly using local model sharing instead of traditional cloud solutions. Popular platforms like GitHub and DockerHub lack the necessary data authenticity and security for high-stakes applications. While blockchain can ensure secure data sharing, permissioned blockchains struggle with the dynamic nature of EEC devices. To solve this, we propose BlockEdge, a hybrid blockchain architecture combining a permissioned blockchain with Practical Byzantine Fault Tolerance (PBFT) for cloud-based data management and a permissionless blockchain with Proof of Work (PoW) for decentralized model sharing at the end/edge. We enhance the PoW process with a dynamic mining algorithm and a lazy-loading Merkle tree structure, improving energy efficiency and computational performance. Experimental results show that BlockEdge reduces energy consumption by over 50% and cuts data update time by 91.73%, effectively addressing the energy and time inefficiencies of mainstream consensus mechanisms.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4412119420",
    "type": "article"
  },
  {
    "title": "A Constraint-Based Approach to Optimise QoS- and Energy-Aware Cloud-Edge Application Deployments",
    "doi": "https://doi.org/10.1145/3757061",
    "publication_date": "2025-07-30",
    "publication_year": 2025,
    "authors": "Simone Gazza; Roberto Amadini; Antonio Brogi; Andrea D'Iapico; Stefano Forti; Saverio Giallorenzo; Pierluigi Plebani; Francisco Ponce; Jacopo Soldani; Monica Vitali; Gianluigi Zavattaro",
    "corresponding_authors": "",
    "abstract": "Cloud-Edge application deployment involves placing multiple software components on infrastructural topologies of heterogeneous nodes, ranging from Cloud servers to Internet-of-Things (IoT) edge devices. When multiple versions (or “ flavours ”) of a component are available, application managers must select a flavour for each deployed component, and assign these components to specific nodes, all while considering constraints such as dependencies, quality of service (QoS), budget, operational costs, and carbon emissions. In complex scenarios, finding the optimal deployment is often infeasible for human operators without automated tools to systematically explore the solution space. To address this challenge, we introduce FREEDA, a first constraint optimisation approach for deploying constrained and multi-flavoured applications on Cloud-Edge infrastructure topologies. We demonstrate the practical feasibility of FREEDA through experiments on a variety of realistic Cloud-Edge infrastructural topologies and component architectures. Furthermore, we benchmark FREEDA against Zephyrus, a comparable tool employing the same underlying solving technology. Empirical results show that FREEDA achieves strong scalability across a broad spectrum of realistic configurations and consistently outperforms Zephyrus.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4412777084",
    "type": "article"
  },
  {
    "title": "Securing Federated Learning Against Active Reconstruction Attacks",
    "doi": "https://doi.org/10.1145/3762639",
    "publication_date": "2025-08-25",
    "publication_year": 2025,
    "authors": "Tre’ R. Jeter; Truc Nguyen; Raed Alharbi; Jung Taek Seo; My T. Thai",
    "corresponding_authors": "",
    "abstract": "Federated Learning (FL) has amassed notable attention for its ability to preserve user privacy while emphasizing the retainment of model training efficiency. Due to this potential, FL has been integrated in many domains, such as healthcare, finance, law, and industrial engineering, where data cannot be easily exchanged due to sensitive information and strict privacy laws. However, current research has indicated that FL protocols are easily compromised by active data reconstruction attacks employed by actively dishonest servers. The malicious modification of global model parameters allows an actively dishonest server to obtain a direct copy of users’ private data via gradient inversion. This class of attacks is highly underexplored and continues to be a major challenge due to the intense threat model. In this paper, we propose OASIS as a scalable and modality-agnostic defense based on data augmentation that counteracts active data reconstruction attacks while preserving model performance. To generalize our defense, we uncover the intuition behind gradient inversion that enables these attacks and theoretically establish the conditions by which the defense can be considered robust regardless of attack design. From this, we formulate our defense with data augmentation that illustrates its ability to undermine the attack principle. We evaluate OASIS on five real-world datasets–two image-based (ImageNet and CIFAR100) and three text-based (Wikitext, Stack Overflow, and Shakespeare)–which span diverse uses cases such as vision tasks and language modeling. Comprehensive evaluations on these datasets exhibit the efficacy of OASIS and highlight its feasibility as a solution.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413521324",
    "type": "article"
  },
  {
    "title": "Cost-Optimized Periodic DAG-Structured Task Offloading in Multi-User MEC Systems Using Reinforcement Learning",
    "doi": "https://doi.org/10.1145/3762993",
    "publication_date": "2025-08-26",
    "publication_year": 2025,
    "authors": "Yan Wang; Yubin He; Gang Liu; Keqin Li",
    "corresponding_authors": "",
    "abstract": "Reinforcement Learning (RL) has emerged as a promising solution for task offloading due to its adaptability to dynamic environments and ability to reduce online computational overhead. Thereby, this paper explores RL for optimizing periodic Directed Acyclic Graph (DAG) task offloading in multi-user Mobile Edge Computing (MEC) systems, aiming to minimize overall costs, including user device energy consumption and server computational charges. A key contribution of this work is the explicit modeling of user competition for limited edge resources, where concurrent access leads to dynamic contention, significantly affecting offloading latency and energy usage. However, this optimization task faces two main challenges: the high dimensionality of task states and the large action space, both of which increase learning complexity. To address this, we propose a dynamic and distributed Proximal Policy Optimization (PPO)-based offloading framework. An encoder is employed to map DAG node features and structural information into a lower-dimensional representation, reducing computational overhead and improving learning efficiency. Additionally, we incorporate behavioral cloning to imitate greedy policies as the PPO agent’s initial behavior, effectively narrowing the action space and accelerating convergence. By combining representation learning and imitation-based initialization, our method enables the PPO agent to quickly adapt to environmental dynamics, leveraging both prior knowledge and real-time feedback to make informed offloading decisions. Simulation results confirm that our approach achieves rapid convergence and outperforms existing baselines in cost reduction, demonstrating its effectiveness for periodic task offloading in MEC scenarios. The source code and implementation details are available at: https://github.com/xiaolutihua/GAT/tree/master",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413696345",
    "type": "article"
  },
  {
    "title": "Poisoning-Resilient Federated Learning for MEC-IoT Environments Using Blockchain",
    "doi": "https://doi.org/10.1145/3767740",
    "publication_date": "2025-09-13",
    "publication_year": 2025,
    "authors": "Luis Miguel García-Sáez; Sergio Ruiz-Villafranca; José Roldán-Gómez; Javier Carrillo-Mondéjar; José Luis Martínez",
    "corresponding_authors": "",
    "abstract": "The rise of distributed architectures in Internet of Things (IoT) environments has significantly advanced both data processing and artificial intelligence. Notably, Multi-access Edge Computing (MEC) represents a distributed form of the Edge Computing paradigm, focussing on heterogeneous protocol management. In contrast, Federated Learning (FL) is an application-level framework designed to enable decentralised Machine Learning (ML) across devices without centralising data. Nevertheless, the combination of both technologies enables the creation of more efficient, scalable, and responsive systems. However, their integration into IoT brings substantial security challenges, including data poisoning, model manipulation, and the insertion of false nodes, all of which threaten the reliability of FL systems. Blockchain technology emerges as a promising solution to these challenges. It offers a decentralised, transparent, and immutable framework that ensures the authenticity and verification of data across the network. Through blockchain, node interactions are automated and secured, enhancing the integrity and trust in the learning process. This paper proposes a blockchain-based architecture for FL within MEC-IoT systems, designed to mitigate security threats. The architecture emphasises data integrity, secure node interactions, and transparent audit trails while maintaining optimal model performance and accuracy, even under attack. It highlights the low resource consumption and minimal time overhead of blockchain integration, ensuring efficiency is not compromised. This integrated approach improves data security, supports secure collaborative learning, and fosters a more resilient and trustworthy IoT ecosystem.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4414260658",
    "type": "article"
  },
  {
    "title": "SLO-aware Prioritization of Orchestration Times for Containerized Services",
    "doi": "https://doi.org/10.1145/3767329",
    "publication_date": "2025-09-13",
    "publication_year": 2025,
    "authors": "Marco Barletta; Marcello Cinque; Luigi De Simone",
    "corresponding_authors": "",
    "abstract": "In this paper, we present a timing analysis of orchestration times for containerized services, revealing the inability of current container orchestrators to fully prioritize services under concurrent requests. The analysis identifies the sources of orchestration delays that impact services to be prioritized potentially violating their Service Level Objectives (SLOs). Based on the findings of the timing analysis, we highlight three alternative SLO-aware orchestration system designs aimed at preventing and/or mitigating delays for high-priority services. We provide principles and guidelines that must drive the implementation of these designs. We then introduce Ulysses , a Kubernetes -based prototype embodying the simplest of the three designs. Ulysses modifies the core Kubernetes control plane components to manage events synchronously and with fixed priority. Through experiments conducted with both synthetic workloads and a containerized cloud-native 5G core network, we demonstrate that Ulysses ensures stable orchestration times for high-priority services, with a reduction of up to \\(78\\% \\) under high orchestration load.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4414260739",
    "type": "article"
  },
  {
    "title": "Malware Detection at the Edge with Lightweight LLMs: A Performance Evaluation",
    "doi": "https://doi.org/10.1145/3769681",
    "publication_date": "2025-09-27",
    "publication_year": 2025,
    "authors": "Christian Rondanini; Barbara Carminati; Elena Ferrari; Ashish Kundu; Antonio Gaudiano",
    "corresponding_authors": "",
    "abstract": "The rapid evolution of malware attacks calls for the development of innovative detection methods, especially in resource-constrained edge computing. Traditional detection techniques struggle to keep up with modern malware’s sophistication and adaptability, prompting a shift towards advanced methodologies like those leveraging Large Language Models (LLMs) for enhanced malware detection. However, deploying LLMs for malware detection directly at edge devices raises several challenges, including ensuring accuracy in constrained environments and addressing edge devices’ energy and computational limits. To tackle these challenges, this paper proposes an architecture leveraging lightweight LLMs’ strengths while addressing limitations like reduced accuracy and insufficient computational power. To evaluate the effectiveness of the proposed lightweight LLM-based approach for edge computing, we perform an extensive experimental evaluation using several state-of-the-art lightweight LLMs. We test them with several publicly available datasets specifically designed for edge and IoT scenarios, and different edge nodes with varying computational power and characteristics.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4414575275",
    "type": "article"
  },
  {
    "title": "PokéLLMon: A Grounding and Reasoning Benchmark for Large Language Models in Pokémon Battles",
    "doi": "https://doi.org/10.1145/3771095",
    "publication_date": "2025-10-07",
    "publication_year": 2025,
    "authors": "Sihao Hu; Tiansheng Huang; Guishan Liu; Ramana Rao Kompella; Ling Liu",
    "corresponding_authors": "",
    "abstract": "Developing grounding techniques for LLMs poses two requirements for interactive environments, i.e. , (i) the presence of rich knowledge beyond the scope of existing LLMs and (ii) the complexity of tasks that require strategic reasoning. Existing environments fail to meet both requirements due to their simplicity or reliance on commonsense knowledge already encoded in LLMs for interaction. In this paper, we present PokéLLMon, a new benchmark enriched with fictional game knowledge and characterized by the intense, dynamic, and adversarial gameplay of Pokémon battles, setting new challenges for the development of grounding and reasoning techniques in interactive environments. Empirical evaluations demonstrate that existing LLMs lack game knowledge and struggle in Pokémon battles. We investigate grounding techniques that leverage feedback and game knowledge, and provide a thorough analysis of reasoning methods from a new perspective of action consistency. Additionally, we introduce higher-level reasoning challenges when playing against human players. The implementation of our benchmark is released at: https://github.com/git-disl/PokeLLMon.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4414923175",
    "type": "article"
  },
  {
    "title": "LNNIDS: A Hybrid Liquid Neural Network based IDS for Known and Unknown IoT Attacks",
    "doi": "https://doi.org/10.1145/3771739",
    "publication_date": "2025-10-13",
    "publication_year": 2025,
    "authors": "Rakesh Kumar; Mayank Swarnkar; Manmeet Muskan",
    "corresponding_authors": "",
    "abstract": "The rapid expansion of Internet of Things (IoT) networks has introduced new cybersecurity risks, particularly due to their heterogeneous, dynamic, and resource-constrained nature. Intrusion Detection Systems (IDS) are commonly used to detect cyber threats in such environments, but traditional IDSs and many machine learning (ML) or deep learning (DL)-based methods face challenges. These include poor detection of unknown attacks, dependence on large datasets, static feature learning, and an inability to adapt to evolving traffic patterns without frequent retraining. Furthermore, while graph-based IDSs capture relational context, their high computational cost and difficulty in adapting to dynamic IoT networks hinder their scalability. To address these challenges, we propose LNNIDS , a novel IDS method that integrates spike encoding with a Hybrid Liquid Neural Network (HLLN) to capture the temporal evolution of IoT attack network traffic. To further enhance accuracy, we introduce DYNGraph , a dynamic graph-based method that performs n → 1 pattern clustering for scalable attack classification. This allows the LNNIDS to dynamically group related flow behaviors and adapt to new or unknown attacks without retraining. We evaluated LNNIDS on two public IoT datasets. This method achieved 99.50% accuracy and maintained robust performance with only 20% training data. Furthermore, we compared the LNNIDS with the seven recent state-of-the-art methods, and we found that LNNIDS outperformed them in the detection of known and unknown IoT attacks with 13.45% and 11.99% better accuracy, respectively.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4415104288",
    "type": "article"
  },
  {
    "title": "Supporting complex queries on multiversion XML documents",
    "doi": "https://doi.org/10.1145/1125274.1125277",
    "publication_date": "2006-02-01",
    "publication_year": 2006,
    "authors": "Shu-Yao Chien; Vassilis J. Tsotras; Carlo Zaniolo; Donghui Zhang",
    "corresponding_authors": "",
    "abstract": "Managing multiple versions of XML documents represents a critical requirement for many applications. Recently, there has been much work on supporting complex queries on XML data (e.g., regular path expressions, structural projections, etc.). In this article, we examine the problem of implementing efficiently such complex queries on multiversion XML documents. Our approach relies on a numbering scheme, whereby durable node numbers (DNNs) are used to preserve the order among the nodes of the XML tree while remaining invariant with respect to updates. Using the document's DNNs, we show that many complex queries are reduced to combinations of range version retrieval queries. We thus examine three alternative storage organizations/indexing schemes to efficiently evaluate range version retrieval queries in this environment. A thorough performance analysis is then presented to reveal the advantages of each scheme.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W2161789205",
    "type": "article"
  },
  {
    "title": "Automated gathering of Web information",
    "doi": "https://doi.org/10.1145/1183463.1183468",
    "publication_date": "2006-11-01",
    "publication_year": 2006,
    "authors": "Bernard J. Jansen; Tracy Mullen; Amanda Spink; Jan Pedersen",
    "corresponding_authors": "",
    "abstract": "The Web has become a worldwide repository of information which individuals, companies, and organizations utilize to solve or address various information problems. Many of these Web users utilize automated agents to gather this information for them. Some assume that this approach represents a more sophisticated method of searching. However, there is little research investigating how Web agents search for online information. In this research, we first provide a classification for information agent using stages of information gathering, gathering approaches, and agent architecture. We then examine an implementation of one of the resulting classifications in detail, investigating how agents search for information on Web search engines, including the session, query, term, duration and frequency of interactions. For this temporal study, we analyzed three data sets of queries and page views from agents interacting with the Excite and AltaVista search engines from 1997 to 2002, examining approximately 900,000 queries submitted by over 3,000 agents. Findings include: (1) agent sessions are extremely interactive, with sometimes hundreds of interactions per second (2) agent queries are comparable to human searchers, with little use of query operators, (3) Web agents are searching for a relatively limited variety of information, wherein only 18% of the terms used are unique, and (4) the duration of agent-Web search engine interaction typically spans several hours. We discuss the implications for Web information agents and search engines.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W2157551792",
    "type": "article"
  },
  {
    "title": "Equipping smart devices with public key signatures",
    "doi": "https://doi.org/10.1145/1189740.1189743",
    "publication_date": "2007-02-01",
    "publication_year": 2007,
    "authors": "Xuhua Ding; Daniele Mazzocchi; Gene Tsudik",
    "corresponding_authors": "",
    "abstract": "One of the major recent trends in computing has been towards so-called smart devices, such as PDAs, cell phones and sensors. Such devices tend to have a feature in common: limited computational capabilities and equally limited power, as most operate on batteries. This makes them ill-suited for public key signatures. This article explores practical and conceptual implications of using Server-Aided Signatures (SAS) for these devices. SAS is a signature method that relies on partially-trusted servers for generating (normally expensive) public key signatures for regular users. Although the primary goal is to aid small, resource-limited devices in signature generation, SAS also offers fast certificate revocation, signature causality and reliable timestamping. It also has some interesting features such as built-in attack detection for users and DoS resistance for servers. Our experimental results also validate the feasibility of deploying SAS on smart devices.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W2083258459",
    "type": "article"
  },
  {
    "title": "Pattern-based design of a service-oriented middleware for remote object federations",
    "doi": "https://doi.org/10.1145/1361186.1361191",
    "publication_date": "2008-05-01",
    "publication_year": 2008,
    "authors": "Uwe Zdun",
    "corresponding_authors": "Uwe Zdun",
    "abstract": "Service-oriented middleware architectures should enable the rapid realization of loosely coupled services. Unfortunately, existing technologies used for service-oriented middleware architectures, such as Web services, P2P systems, coordination and cooperation technologies, and spontaneous networking, do not fully support all requirements in the realm of loosely coupled business services yet. Typical problems that arise in many business domains are for instance missing central control, complex cooperation models, complex lookup models, or issues regarding dynamic deployment. We used a pattern-based approach to identify the well working solutions in the different technologies for loosely coupled services. Then we reused this design knowledge in our concept for a service-oriented middleware. This concept is centered around a controlled environment, called a federation. Each remote object (a peer service) is controlled in one or more federations, but within this environment peers can collaborate in a simple-to-use, loosely coupled, and ad hoc style of communication. A semantic lookup service is used to let the peers publish rich metadata about themselves to their fellow peers.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2104696757",
    "type": "article"
  },
  {
    "title": "Peeking Through the Cloud",
    "doi": "https://doi.org/10.1145/1852096.1852097",
    "publication_date": "2010-10-01",
    "publication_year": 2010,
    "authors": "Moheeb Abu Rajab; Fabian Monrose; Niels Provos",
    "corresponding_authors": "",
    "abstract": "Reliable network demographics are quickly becoming a much sought-after digital commodity. However, as the need for more refined Internet demographics has grown, so too has the tension between privacy and utility. Unfortunately, current techniques lean too much in favor of functional requirements over protecting the privacy of users. For example, the most prominent proposals for measuring the relative popularity of a Web site depend on the deployment of client-side measurement agents that are generally perceived as infringing on users’ privacy, thereby limiting their wide-scale adoption. Moreover, the client-side nature of these techniques also makes them susceptible to various manipulation tactics that undermine the integrity of their results. In this article, we propose a new estimation technique that uses DNS cache probing to infer the density of clients accessing a given service. Compared to earlier techniques, our scheme is less invasive as it does not reveal user-specific traits, and is more robust against manipulation. We demonstrate the flexibility of our approach through two important security applications. First, we illustrate how our scheme can be used as a lightweight technique for measuring and verifying the relative popularity rank of different Web sites. Second, using data from several hundred botnets, we apply our technique to indirectly measure the infected population of this increasing Internet phenomenon.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2091675753",
    "type": "article"
  },
  {
    "title": "CrowdService",
    "doi": "https://doi.org/10.1145/3108935",
    "publication_date": "2018-01-20",
    "publication_year": 2018,
    "authors": "Xin Peng; Jingxiao Gu; Tian Tan; Jun Sun; Yijun Yu; Bashar Nuseibeh; Wenyun Zhao",
    "corresponding_authors": "",
    "abstract": "Some user needs can only be met by leveraging the capabilities of others to undertake particular tasks that require intelligence and labor. Crowdsourcing such capabilities is one way to achieve this. But providing a service that leverages crowd intelligence and labor is a challenge, since various factors need to be considered to enable reliable service provisioning. For example, the selection of an optimal set of workers from those who bid to perform a task needs to be made based on their reliability, expected reward, and distance to the target locations. Moreover, for an application involving multiple services, the overall cost and time constraints must be optimally allocated to each involved service. In this article, we develop a framework, named C rowd S ervice , that supplies crowd intelligence and labor as publicly accessible crowd services via mobile crowdsourcing. The article extends our earlier work by providing an approach for constraints synthesis and worker selection. It employs a genetic algorithm to dynamically synthesize and update near-optimal cost and time constraints for each crowd service involved in a composite service and selects a near-optimal set of workers for each crowd service to be executed. We implement the proposed framework on Android platforms and evaluate its effectiveness, scalability, and usability in both experimental and user studies.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2728885230",
    "type": "article"
  },
  {
    "title": "Improving Verification Accuracy of CPS by Modeling and Calibrating Interaction Uncertainty",
    "doi": "https://doi.org/10.1145/3093894",
    "publication_date": "2018-01-22",
    "publication_year": 2018,
    "authors": "Wenhua Yang; Chang Xu; Minxue Pan; Xiaoxing Ma; Jian Lü",
    "corresponding_authors": "",
    "abstract": "Cyber-Physical Systems (CPS) intrinsically combine hardware and physical systems with software and network, which are together creating complex and correlated interactions. CPS applications often experience uncertainty in interacting with environment through unreliable sensors. They can be faulty and exhibit runtime errors if developers have not considered environmental interaction uncertainty adequately. Existing work in verifying CPS applications ignores interaction uncertainty and thus may overlook uncertainty-related faults. To improve verification accuracy, in this article we propose a novel approach to verifying CPS applications with explicit modeling of uncertainty arisen in the interaction between them and the environment. Our approach builds an Interactive State Machine network for a CPS application and models interaction uncertainty by error ranges and distributions. Then it encodes both the application and uncertainty models to Satisfiability Modulo Theories (SMT) formula to leverage SMT solvers searching for counterexamples that represent application failures. The precision of uncertainty model can affect the verification results. However, it may be difficult to model interaction uncertainty precisely enough at the beginning, because of the uncontrollable noise of sensors and insufficient data sample size. To further improve the accuracy of the verification results, we propose an approach to identifying and calibrating imprecise uncertainty models. We exploit the inconsistency between the counterexamples’ estimate and actual occurrence probabilities to identify possible imprecision in uncertainty models, and the calibration of imprecise models is to minimize the inconsistency, which is reduced to a Search-Based Software Engineering problem. We experimentally evaluated our verification and calibration approaches with real-world CPS applications, and the experimental results confirmed their effectiveness and efficiency.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2784446562",
    "type": "article"
  },
  {
    "title": "Quantifying Privacy Leakage in Multi-Agent Planning",
    "doi": "https://doi.org/10.1145/3133326",
    "publication_date": "2018-02-05",
    "publication_year": 2018,
    "authors": "Michal Štolba; Jan Tožička; Antonín Komenda",
    "corresponding_authors": "",
    "abstract": "Multi-agent planning using MA-STRIPS–related models is often motivated by the preservation of private information. Such a motivation is not only natural for multi-agent systems but also is one of the main reasons multi-agent planning problems cannot be solved with a centralized approach. Although the motivation is common in the literature, the formal treatment of privacy is often missing. In this article, we expand on a privacy measure based on information leakage introduced in previous work, where the leaked information is measured in terms of transition systems represented by the public part of the problem with regard to the information obtained during the planning process. Moreover, we present a general approach to computing privacy leakage of search-based multi-agent planners by utilizing search-tree reconstruction and classification of leaked superfluous information about the applicability of actions. Finally, we present an analysis of the privacy leakage of two well-known algorithms—multi-agent forward search (MAFS) and Secure-MAFS—both in general and on a particular example. The results of the analysis show that Secure-MAFS leaks less information than MAFS.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2787381105",
    "type": "article"
  },
  {
    "title": "Automatic Resolution of Normative Conflicts in Supportive Technology Based on User Values",
    "doi": "https://doi.org/10.1145/3158371",
    "publication_date": "2018-05-25",
    "publication_year": 2018,
    "authors": "Alex Kayal; Willem‐Paul Brinkman; Mark A. Neerincx; M. Birna van Riemsdijk",
    "corresponding_authors": "",
    "abstract": "Social commitments (SCs) provide a flexible, norm-based, governance structure for sharing and receiving data. However, users of data sharing applications can subscribe to multiple SCs, possibly producing opposing sharing and receiving requirements. We propose resolving such conflicts automatically through a conflict resolution model based on relevant user values such as privacy and safety. The model predicts a user’s preferred resolution by choosing the commitment that best supports the user’s values. We show through an empirical user study ( n = 396) that values, as well as recency and norm type, significantly improve a system’s ability to predict user preference in location sharing conflicts.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2804348963",
    "type": "article"
  },
  {
    "title": "A Hybrid Approach for Improving the Design Quality of Web Service Interfaces",
    "doi": "https://doi.org/10.1145/3226593",
    "publication_date": "2018-12-22",
    "publication_year": 2018,
    "authors": "Ali Ouni; Hanzhang Wang; Marouane Kessentini; Salah Bouktif; Katsuro Inoue",
    "corresponding_authors": "",
    "abstract": "A key success of a Web service is to appropriately design its interface to make it easy to consume and understand. In the context of service-oriented computing (SOC), the service’s interface is the main source of interaction with the consumers to reuse the service functionality in real-world applications. The SOC paradigm provides a collection of principles and guidelines to properly design services to provide best practice of third-party reuse. However, recent studies showed that service designers tend to pay little care to the design of their service interfaces, which often lead to several side effects known as antipatterns . One of the most common Web service interface antipatterns is to expose a large number of semantically unrelated operations, implementing different abstractions, in one single interface. Such bad design practices may have a significant impact on the service reusability, understandability, as well as the development and run-time characteristics. To address this problem, in this article, we propose a hybrid approach to improve the design quality of Web service interfaces and fix antipatterns as a combination of both deterministic and heuristic-based approaches. The first step consists of a deterministic approach using a graph partitioning-based technique to split the operations of a large service interface into more cohesive interfaces, each one representing a distinct abstraction. Then, the produced interfaces will be checked using a heuristic-based approach based on the non-dominated sorting genetic algorithm (NSGA-II) to correct potential antipatterns while reducing the interface design deviation to avoid taking the service away from its original design. To evaluate our approach, we conduct an empirical study on a benchmark of 26 real-world Web services provided by Amazon and Yahoo. Our experiments consist of a quantitative evaluation based on design quality metrics, as well as a qualitative evaluation with developers to assess its usefulness in practice. The results show that our approach significantly outperforms existing approaches and provides more meaningful results from a developer’s perspective.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2906600341",
    "type": "article"
  },
  {
    "title": "Affect and Interaction in Agent-Based Systems and Social Media",
    "doi": "https://doi.org/10.1145/3018980",
    "publication_date": "2017-02-28",
    "publication_year": 2017,
    "authors": "Chloé Clavel; Rossana Damiano; Viviana Patti; Paolo Rosso",
    "corresponding_authors": "",
    "abstract": "editorial Free Access Share on Affect and Interaction in Agent-Based Systems and Social Media: Guest Editors’ Introduction Authors: Chloé Clavel Institut-Mines-Telecom, TelecomParisTech, LTCI-CNRS, France Institut-Mines-Telecom, TelecomParisTech, LTCI-CNRS, FranceView Profile , Rossana Damiano Dipartimento di Informatica, University of Turin, Italy Dipartimento di Informatica, University of Turin, ItalyView Profile , Viviana Patti Dipartimento di Informatica, University of Turin, Italy Dipartimento di Informatica, University of Turin, ItalyView Profile , Paolo Rosso PRHLT Research Center, Universitat Politècnica de València, Spain PRHLT Research Center, Universitat Politècnica de València, SpainView Profile Authors Info & Claims ACM Transactions on Internet TechnologyVolume 17Issue 1February 2017 Article No.: 1pp 1–8https://doi.org/10.1145/3018980Published:02 March 2017Publication History 1citation323DownloadsMetricsTotal Citations1Total Downloads323Last 12 Months38Last 6 weeks1 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2594893895",
    "type": "article"
  },
  {
    "title": "Adaptive Speculation for Efficient Internetware Application Execution in Clouds",
    "doi": "https://doi.org/10.1145/3093896",
    "publication_date": "2018-01-20",
    "publication_year": 2018,
    "authors": "Xue Ouyang; Peter Garraghan; Bernhard Primas; David McKee; Paul Townend; Jie Xu",
    "corresponding_authors": "",
    "abstract": "Modern Cloud computing systems are massive in scale, featuring environments that can execute highly dynamic Internetware applications with huge numbers of interacting tasks. This has led to a substantial challenge—the straggler problem, whereby a small subset of slow tasks significantly impede parallel job completion. This problem results in longer service responses, degraded system performance, and late timing failures that can easily threaten Quality of Service (QoS) compliance. Speculative execution (or speculation) is the prominent method deployed in Clouds to tolerate stragglers by creating task replicas at runtime. The method detects stragglers by specifying a predefined threshold to calculate the difference between individual tasks and the average task progression within a job. However, such a static threshold debilitates speculation effectiveness as it fails to capture the intrinsic diversity of timing constraints in Internetware applications, as well as dynamic environmental factors, such as resource utilization. By considering such characteristics, different levels of strictness for replica creation can be imposed to adaptively achieve specified levels of QoS for different applications. In this article, we present an algorithm to improve the execution efficiency of Internetware applications by dynamically calculating the straggler threshold, considering key parameters including job QoS timing constraints, task execution progress, and optimal system resource utilization. We implement this dynamic straggler threshold into the YARN architecture to evaluate it’s effectiveness against existing state-of-the-art solutions. Results demonstrate that the proposed approach is capable of reducing parallel job response time by up to 20% compared to the static threshold, as well as a higher speculation success rate, achieving up to 66.67% against 16.67% in comparison to the static method.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2616391299",
    "type": "article"
  },
  {
    "title": "Extending the Outreach",
    "doi": "https://doi.org/10.1145/3140543",
    "publication_date": "2017-10-26",
    "publication_year": 2017,
    "authors": "Ernesto Damiani; Ryszard Kowalczyk; Gerard Parr",
    "corresponding_authors": "",
    "abstract": "Connected Communities (CCs) are socio-technical systems that rely on an information and communication technology (ICT) infrastructure to integrate people and organizations (companies, schools, hospitals, universities, local and national government agencies) willing to share information and perform joint decision-making to create sustainable and equitable work and living environments. We discuss a research agenda considering CCs from three distinct but complementary points of view: CC metaphors, models, and services.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2766986369",
    "type": "article"
  },
  {
    "title": "Decision Networks for Security Risk Assessment of Critical Infrastructures",
    "doi": "https://doi.org/10.1145/3137570",
    "publication_date": "2018-03-06",
    "publication_year": 2018,
    "authors": "Daniele Codetta‐Raiteri; Luigi Portinale",
    "corresponding_authors": "",
    "abstract": "We exploit Decision Networks (DN) for the analysis of attack/defense scenarios in critical infrastructures. DN extend Bayesian Networks (BN) with decision and value nodes. DN inherit from BN the possibility to naturally address uncertainty at every level, making possible the modeling of situations that are not limited to Boolean combinations of events. By means of decision nodes, DN can include the interaction level of attacks and countermeasures. Inference algorithms can be directly exploited for implementing a probabilistic analysis of both the risk and the importance of the attacks. Thanks to value nodes, a sound decision theoretic analysis has the goal of selecting the optimal set of countermeasures to activate.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2793232313",
    "type": "article"
  },
  {
    "title": "Local Concurrency Detection in Business Process Event Logs",
    "doi": "https://doi.org/10.1145/3289181",
    "publication_date": "2019-01-21",
    "publication_year": 2019,
    "authors": "Abel Armas-Cervantes; Marlon Dumas; Marcello La Rosa; Abderrahmane Maaradji",
    "corresponding_authors": "",
    "abstract": "Process mining techniques aim at analyzing records generated during the execution of a business process in order to provide insights on the actual performance of the process. Detecting concurrency relations between events is a fundamental primitive underpinning a range of process mining techniques. Existing approaches to this problem identify concurrency relations at the level of event types under a global interpretation. If two event types are declared to be concurrent, every occurrence of one event type is deemed to be concurrent to one occurrence of the other. In practice, this interpretation is too coarse-grained and leads to over-generalization. This article proposes a finer-grained approach, whereby two event types may be deemed to be in a concurrency relation relative to one state of the process, but not relative to other states. In other words, the detected concurrency relation holds locally, relative to a set of states. Experimental results both with artificial and real-life logs show that the proposed local concurrency detection approach improves the accuracy of existing concurrency detection techniques.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2911426928",
    "type": "article"
  },
  {
    "title": "Descriptions from the Customers",
    "doi": "https://doi.org/10.1145/3418202",
    "publication_date": "2020-10-06",
    "publication_year": 2020,
    "authors": "Slava Novgorodov; Ido Guy; Guy Elad; Kira Radinsky",
    "corresponding_authors": "",
    "abstract": "Product descriptions play an important role in the e-commerce ecosystem. Yet, on leading e-commerce websites product descriptions are often lacking or missing. In this work, we suggest to overcome these issues by generating product descriptions from user reviews. We identify the set of candidates using a supervised approach that extracts review sentences in their original form, diversifies them, and selects the top candidates. We present extensive analyses of the generated descriptions, including a comparison to the original descriptions and examination of review coverage. We also perform an A/B test that demonstrates the impact of presenting our descriptions on user traffic.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W3092618447",
    "type": "article"
  },
  {
    "title": "Characterization of Wireless Multidevice Users",
    "doi": "https://doi.org/10.1145/2955096",
    "publication_date": "2016-12-15",
    "publication_year": 2016,
    "authors": "Aveek Das; Parth H. Pathak; Chen‐Nee Chuah; Prasant Mohapatra",
    "corresponding_authors": "",
    "abstract": "The number of wireless-enabled devices owned by a user has had huge growth over the past few years. Over one third of adults in the United States currently own three wireless devices: a smartphone, laptop, and tablet. This article provides a study of the network usage behavior of today’s multidevice users. Using data collected from a large university campus, we provide a detailed multidevice user (MDU) measurement study of more than 30,000 users. The major objective of this work is to study how the presence of multiple wireless devices affects the network usage behavior of users. Specifically, we characterize the usage pattern of the different device types in terms of total and intermittent usage, how the usage of different devices overlap over time, and uncarried device usage statistics. We also study user preferences of accessing sensitive content and device-specific factors that govern the choice of WiFi encryption type. The study reveals several interesting findings about MDUs. We see how the use of tablets and laptops are interchangeable and how the overall multidevice usage is additive instead of being shared among the devices. We also observe how current DHCP configurations are oblivious to multiple devices, which results in inefficient utilization of available IP address space. All findings about multidevice usage patterns have the potential to be utilized by different entities, such as app developers, network providers, security researchers, and analytics and advertisement systems, to provide more intelligent and informed services to users who have at least two devices among a smartphone, tablet, and laptop.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2561873392",
    "type": "article"
  },
  {
    "title": "A Flow-based Multi-agent Data Exfiltration Detection Architecture for Ultra-low Latency Networks",
    "doi": "https://doi.org/10.1145/3419103",
    "publication_date": "2021-07-16",
    "publication_year": 2021,
    "authors": "Rafael Salema Marques; Gregory Epiphaniou; Haider Al‐Khateeb; Carsten Maple; Mohammad Hammoudeh; Paulo André Lima de Castro; Ali Dehghantanha; Kim‐Kwang Raymond Choo",
    "corresponding_authors": "",
    "abstract": "Modern network infrastructures host converged applications that demand rapid elasticity of services, increased security, and ultra-fast reaction times. The Tactile Internet promises to facilitate the delivery of these services while enabling new economies of scale for high fidelity of machine-to-machine and human-to-machine interactions. Unavoidably, critical mission systems served by the Tactile Internet manifest high demands not only for high speed and reliable communications but equally, the ability to rapidly identify and mitigate threats and vulnerabilities. This article proposes a novel Multi-Agent Data Exfiltration Detector Architecture (MADEX), inspired by the mechanisms and features present in the human immune system. MADEX seeks to identify data exfiltration activities performed by evasive and stealthy malware that hides malicious traffic from an infected host in low-latency networks. Our approach uses cross-network traffic information collected by agents to effectively identify unknown illicit connections by an operating system subverted. MADEX does not require prior knowledge of the characteristics or behavior of the malicious code or a dedicated access to a knowledge repository. We tested the performance of MADEX in terms of its capacity to handle real-time data and the sensitivity of our algorithm’s classification when exposed to malicious traffic. Experimental evaluation results show that MADEX achieved 99.97% sensitivity, 98.78% accuracy, and an error rate of 1.21% when compared to its best rivals. We created a second version of MADEX, called MADEX level 2, that further improves its overall performance with a slight increase in computational complexity. We argue for the suitability of MADEX level 1 in non-critical environments, while MADEX level 2 can be used to avoid data exfiltration in critical mission systems. To the best of our knowledge, this is the first article in the literature that addresses the detection of rootkits real-time in an agnostic way using an artificial immune system approach while it satisfies strict latency requirements.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W3084372349",
    "type": "article"
  },
  {
    "title": "Evolving Influence Maximization in Evolving Networks",
    "doi": "https://doi.org/10.1145/3409370",
    "publication_date": "2020-10-20",
    "publication_year": 2020,
    "authors": "Xudong Wu; Luoyi Fu; Zixin Zhang; Huan Long; Jingfan Meng; Xinbing Wang; Guihai Chen",
    "corresponding_authors": "",
    "abstract": "Influence Maximization (IM) aims to maximize the number of people that become aware of a product by finding the “best” set of “seed” users to initiate the product advertisement. Unlike most prior arts on the static networks containing fixed number of users, we study the evolving IM in more realistic evolving networks with temporally growing topology. The task of evolving IM, however, is far more challenging over static cases in the sense that the seed selection should consider its impact on future users who will join network during influence diffusion and the probabilities that users influence one another also evolve over time. We address the challenges brought by network evolution through EIM, a newly proposed bandit-based framework that alternates between seed nodes selection and knowledge (i.e., nodes’ growing speed and evolving activation probabilities) learning during network evolution. Remarkably, the EIM framework involves three novel components to handle the uncertainties brought by evolution: (1) A fully adaptive particle learning of nodes’ growing speed for accurately estimating future influenced size, with real growing behaviors delineated by a set of weighted particles. (2) A bandit-based refining method with growing arms to cope with the evolving activation probabilities via growing edges from previous influence diffusion feedbacks. (3) Evo-IMM , an evolving seed selection algorithm, which leverages the Influence Maximization via Martingale (IMM) framework, with the objective to maximize the influence spread to highly attractive users during evolution. Theoretically, the EIM framework returns a regret bound that provably maintains its sublinearity with respect to the growing network size. Empirically, the effectiveness of the EIM framework is also validated with three notable million-scale evolving network datasets possessing complete social relationships and nodes’ joining time. The results confirm the superiority of the EIM framework in terms of an up to 50% larger influenced size over four static baselines.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W3093583920",
    "type": "article"
  },
  {
    "title": "Intelligent Mediator-based Enhanced Smart Contract for Privacy Protection",
    "doi": "https://doi.org/10.1145/3404892",
    "publication_date": "2021-01-05",
    "publication_year": 2021,
    "authors": "Junho Kim; Mucheol Kim",
    "corresponding_authors": "",
    "abstract": "With the development of ICT technology, users are actively participated in content creation and sharing. Service providers have provided more diverse and extensive information services. With the recent evolution to a customized service, the demand for the use of personal information is increasing. However, it affects the efficiency and convenience of service provision, as social problems and security threats such as personal information leakage, human trafficking, and misuse increase. In this article, we proposed an intelligent mediator-based enhanced smart contract for privacy protection. The proposed approach performs the tasks, which are mediation transactions, authorization, and transaction record management, with blockchain-based personal information management. Then it is possible to prevent misuse of personal information and to support rational decision-making on the transparency of information and the use of personal information by autonomously performing personal information management.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W3119689028",
    "type": "article"
  },
  {
    "title": "Efficient Distributed Decryption Scheme for IoT Gateway-based Applications",
    "doi": "https://doi.org/10.1145/3414475",
    "publication_date": "2021-01-05",
    "publication_year": 2021,
    "authors": "Cong Peng; Jianhua Chen; Pandi Vijayakumar; Neeraj Kumar; Debiao He",
    "corresponding_authors": "",
    "abstract": "With the evolvement of the Internet of things (IoT), privacy and security have become the primary indicators for users to deploy IoT applications. In the gateway-based IoT architecture, gateways aggregate data collected by perception-layer devices and upload message packets to platforms, while platforms automatically push different categories of data to different applications. However, security in processes of data transmission via gateways, storage in platforms, access by applications is the major challenge for user privacy protection. To tackle this challenge, this article presents a secure IoT scheme based on a fine-grained multi-receive signcryption scheme to realize end-to-end secure transmission and data access control. To enhance the security of online application decryption keys, we design a distributed threshold decryption scheme based on secret-sharing. Moreover, from the provable security perspective, we demonstrate that the scheme can achieve the expected IND-CCA security and EUF-CMA security. After the performance analysis, evaluation results show that the computational performance is efficient and linearly subject to the number of messages and the number of receivers.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W3120170659",
    "type": "article"
  },
  {
    "title": "Multilateral Personal Portfolio Authentication System Based on Hyperledger Fabric",
    "doi": "https://doi.org/10.1145/3423554",
    "publication_date": "2021-01-05",
    "publication_year": 2021,
    "authors": "Junho Jeong; Donghyo Kim; Sun-Young Ihm; Yangsun Lee; Yunsik Son",
    "corresponding_authors": "",
    "abstract": "Korean education-related evaluation agencies utilize a centralized system that directly manages learner data. This leaves the intellectual property of the organizations and the personal information of the students vulnerable to leakage should the central server be attacked. In this study, the researchers propose a multilateral personal portfolio authentication system that guarantees the reliability, integrity, and transparency of the data such as learner's schooling history. The system uses the features of blockchain in a distributed network wherein a learner submits schooling data to a peer in the network. The data is then verified through an agreement among the peers and recorded in a chronologically encrypted ledger. The proposed system is implemented based on Hyperledger Fabric and the analysis thereof conducted by evaluating its processing speed, capacity, and security. The analysis indicates that the system is able to successfully intercept the transactions of unvalidated users, thereby preventing the recording of incorrect data by an unauthorized user. Furthermore, it provides a record of previously made changes to a learner's profile, thus improving the integrity and reliability of the data. This system provides a platform to share learner information safely and promptly among schools, certification authorities, and higher learning institutions.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W3121053166",
    "type": "article"
  },
  {
    "title": "Blockchain-enabled Tensor-based Conditional Deep Convolutional GAN for Cyber-physical-Social Systems",
    "doi": "https://doi.org/10.1145/3404890",
    "publication_date": "2021-06-21",
    "publication_year": 2021,
    "authors": "Jun Feng; Laurence T. Yang; Yuxiang Zhu; Nicholaus J. Gati; Yijun Mo",
    "corresponding_authors": "",
    "abstract": "Deep learning techniques have shown significant success in cyber-physical-social systems (CPSS). As an instance of deep learning models, generative adversarial nets (GAN) model enables powerful and flexible image augmentation, image generation, and classification, thus can be applied to real-world CPSS settings. GAN model training needs a large collection of cyber-physical-social data originating from various CPSS devices. Numerous prevailing GAN models depend on a tacit assumption that several cyber-physical-social data providers present a reliable source to collect training data, which is seldom the case in real CPSS. The existing GAN models also fail to consider multi-dimensional latent structure. In our work, we put forward a novel blockchain-enabled tensor-based conditional deep convolutional GAN (TCDC-GAN) model for cyber-physical-social systems. The blockchain is employed to develop a decentralized and reliable cyber-physical-social data-sharing platform between numerous cyber-physical-social data providers, such that the training data and the model are documented on a ledger that is distributed. Furthermore, a tensor-based generator and a tensor-based discriminator are well designed by employing the tensor model. The results of extensive simulation experiments show the efficacy of the proposed TCDC-GAN model. Compared with the state-of-the-art models, our model gains superior estimation performance.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W3175691375",
    "type": "article"
  },
  {
    "title": "Big Data Processing on Volunteer Computing",
    "doi": "https://doi.org/10.1145/3409801",
    "publication_date": "2021-07-22",
    "publication_year": 2021,
    "authors": "Zhihan Lv; Dongliang Chen; Amit Kumar Singh",
    "corresponding_authors": "",
    "abstract": "In order to calculate the node big data contained in complex networks and realize the efficient calculation of complex networks, based on voluntary computing, taking ICE middleware as the communication medium, the loose coupling distributed framework DCBV based on voluntary computing is proposed. Then, the Master, Worker, and MiddleWare layers in the framework, and the development structure of a DCBV framework are designed. The task allocation and recovery strategy, message passing and communication mode, and fault tolerance processing are discussed. Finally, to calculate and verify parameters such as the average shortest path of the framework and shorten calculation time, an improved accurate shortest path algorithm, the N-SPFA algorithm, is proposed. Under different datasets, the node calculation and performance of the N-SPFA algorithm are explored. The algorithm is compared with four approximate shortest-path algorithms: Combined Link and Attribute (CLA), Lexicographic Breadth First Search (LBFS), Approximate algorithm of shortest path length based on center distance of area division (CDZ), and Hub Vertex of area and Core Expressway (HEA-CE). The results show that when the number of CPU threads is 4, the computation time of the DCBV framework is the shortest (514.63 ms). As the number of CPU cores increases, the overall computation time of the framework decreases gradually. For every 2 additional CPU cores, the number of tasks increases by 1. When the number of Worker nodes is 8 and the number of nodes is 1, the computation time of the framework is the shortest (210,979 ms), and the IO statistics data increase with the increase of Worker nodes. When the datasets are Undirected01 and Undirected02, the computation time of the N-SPFA algorithm is the shortest, which is 4520 ms and 7324 ms, respectively. However, the calculation time in the ca-condmat_undirected dataset is 175,292 ms, and the performance is slightly worse. Overall, however, the performance of the N-SPFA and SPFA algorithms is good. Therefore, the two algorithms are combined. For networks with less complexity, the computational scale coefficient of the SPFA algorithm can be set to 0.06, and for general networks, 0.2. When compared with other algorithms in different datasets, the pretreatment time, average query time, and overall query time of N-SPFA algorithm are the shortest, being 49.67 ms, 5.12 ms, and 94,720 ms, respectively. The accuracy (1.0087) and error rate (0.024) are also the best. In conclusion, voluntary computing can be applied to the processing of big data, which has a good reference significance for the distributed analysis of large-scale complex networks.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W3184408564",
    "type": "article"
  },
  {
    "title": "Towards Anomalous Diffusion Sources Detection in a Large Network",
    "doi": "https://doi.org/10.1145/2806889",
    "publication_date": "2016-01-18",
    "publication_year": 2016,
    "authors": "Peng Zhang; Jing He; Guodong Long; Guangyan Huang; Chengqi Zhang",
    "corresponding_authors": "",
    "abstract": "Witnessing the wide spread of malicious information in large networks, we develop an efficient method to detect anomalous diffusion sources and thus protect networks from security and privacy attacks. To date, most existing work on diffusion sources detection are based on the assumption that network snapshots that reflect information diffusion can be obtained continuously. However, obtaining snapshots of an entire network needs to deploy detectors on all network nodes and thus is very expensive. Alternatively, in this article, we study the diffusion sources locating problem by learning from information diffusion data collected from only a small subset of network nodes. Specifically, we present a new regression learning model that can detect anomalous diffusion sources by jointly solving five challenges, that is, unknown number of source nodes, few activated detectors, unknown initial propagation time, uncertain propagation path and uncertain propagation time delay. We theoretically analyze the strength of the model and derive performance bounds. We empirically test and compare the model using both synthetic and real-world networks to demonstrate its performance.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2297703471",
    "type": "article"
  },
  {
    "title": "rSYBL",
    "doi": "https://doi.org/10.1145/2925990",
    "publication_date": "2016-08-12",
    "publication_year": 2016,
    "authors": "Georgiana Copil; Daniel Moldovan; Hong‐Linh Truong; Schahram Dustdar",
    "corresponding_authors": "",
    "abstract": "Cloud applications can benefit from the on-demand capacity of cloud infrastructures, which offer computing and data resources with diverse capabilities, pricing, and quality models. However, state-of-the-art tools mainly enable the user to specify “if-then-else” policies concerning resource usage and size, resulting in a cumbersome specification process that lacks expressiveness for enabling the control of complex multilevel elasticity requirements. In this article, first we propose SYBL, a novel language for specifying elasticity requirements at multiple levels of abstraction. Second, we design and develop the rSYBL framework for controlling cloud services at multiple levels of abstractions. To enforce user-specified requirements, we develop a multilevel elasticity control mechanism enhanced with conflict resolution. rSYBL supports different cloud providers and is highly extensible, allowing service providers or developers to define their own connectors to the desired infrastructures or tools. We validate it through experiments with two distinct services, evaluating rSYBL over two distinct cloud infrastructures, and showing the importance of multilevel elasticity control.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2480347628",
    "type": "article"
  },
  {
    "title": "A Novel Approach to Enhance the End-to-End Quality of Service for Avionic Wireless Sensor Networks",
    "doi": "https://doi.org/10.1145/3520441",
    "publication_date": "2022-02-23",
    "publication_year": 2022,
    "authors": "Yevhenii Shudrenko; Daniel Plöger; Koojana Kuladinithi; Andreas Timm‐Giel",
    "corresponding_authors": "",
    "abstract": "Going wireless is one of the key industrial trends, which assists the emergence of new manufacturing and maintenance processes by reducing the complexity and cost of physical equipment. However, the adoption of Wireless Sensor Networks (WSNs) in production environments is limited due to the strict Quality of Service (QoS) requirements of industrial applications. In particular, Wireless Avionics Intra-Communication (WAIC) systems operating in 4.3 GHz band are designed for intra-aircraft use cases with considerable restrictions on the transmission power of sensors, which results in multi-hop topologies, complicating a guaranteed QoS. The Internet Engineering Task Force (IETF) has developed the protocol stack IPv6 over the Time Slotted Channel Hopping (TSCH) mode of IEEE 802.15.4 (6TiSCH) based on the IEEE 802.15.4 Standard for Low-Rate Wireless Networks, which combines the TSCH reliability with ubiquitous IPv6 connectivity and with the robust Routing Protocol for Low-Power and Lossy Networks (RPL). The Scheduling Function (SF) is a core IPv6 over the TSCH mode of IEEE 802.15.4 (6TiSCH) component, but the specification of the SF is an open research topic: numerous scientific articles investigated how QoS for a wide range of applications can be met by developing specialized SFs. However, no full-scale information exchange between the layers of the 6TiSCH stack was considered to optimize the SFs and to improve the network performance. In this work, we propose a novel solution named 6TiSCH-CLX to satisfy demanding QoS requirements using cross-layer communication. It is an extension of the 6TiSCH framework at the network and Medium Access Control (MAC) layers, addressing latency and reliability challenges agnostic of the physical layer. 6TiSCH-CLX is evaluated both analytically and in simulations for several safety-critical avionic intra-communication use cases in WAIC. Preliminary results indicate considerable improvements to latency, while maintaining almost 100% Packet Delivery Ratio (PDR) without retransmissions and they highlight the capability of the cross-layer approach compared to existing solutions.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W4213389530",
    "type": "article"
  },
  {
    "title": "EECDN: Energy-efficient Cooperative DNN Edge Inference in Wireless Sensor Networks",
    "doi": "https://doi.org/10.1145/3544969",
    "publication_date": "2022-06-23",
    "publication_year": 2022,
    "authors": "Long Chen; Mianyang Yao; Yalan Wu; Jigang Wu",
    "corresponding_authors": "",
    "abstract": "Multi-access edge computing (MEC) is emerging to improve the quality of experience of mobile devices including internet of things sensors by offloading computing intensive tasks to MEC servers. Existing MEC-enabled cooperative computation offloading works focus on the optimization of total energy consumption but fail to exploit multi-relay diversity and min-max fairness of energy consumption on participated sensors. We explore a typical wireless sensor network with multi-source, multi-relay, and one edge server, where relay nodes can provide both cooperative communication and computation services. We divide the energy efficiency optimization problem into two sub-problems: One is to minimize the weighted average total energy consumption per time slot, and the other is to minimize the maximum weighted energy consumption. For the first sub-problem, we propose an optimal algorithm named as optimal weighted average total energy consumption algorithm (OTCA) based on bipartite matching. For the second sub-problem, greedy algorithm for fairness guarantee (GAF) is proposed with an approximation ratio of (1 + ε), where ε is a small positive constant. Extensive numerical results show that OTCA outperforms the baseline algorithms by 26.7–77.4% on the average total weighted energy consumption while GAF outperforms benchmark algorithms by 30.7–84.4%. NS-3 simulation experiments comply with numerical results.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W4283329734",
    "type": "article"
  },
  {
    "title": "MWPoW+: A Strong Consensus Protocol for Intra-Shard Consensus in Blockchain Sharding",
    "doi": "https://doi.org/10.1145/3584020",
    "publication_date": "2023-02-13",
    "publication_year": 2023,
    "authors": "Yibin Xu; Jianhua Shao; Tijs Slaats; Boris Düdder",
    "corresponding_authors": "",
    "abstract": "Blockchain sharding splits a blockchain into several shards where consensus is reached at the shard level rather than over the entire blockchain. It improves transaction throughput and reduces the computational resources required of individual nodes. But a derivation of trustworthy consensus within a shard becomes an issue as the longest chain based mechanisms used in conventional blockchains can no longer be used. Instead, a vote-based consensus mechanism must be employed. However, existing vote-based Byzantine fault tolerance consensus protocols do not offer sufficient security guarantees for sharded blockchains. First, when used to support consensus where only one block is allowed at a time (binary consensus), these protocols are susceptible to progress-hindering attacks (i.e., unable to reach a consensus). Second, when used to support a stronger type of consensus where multiple concurrent blocks are allowed (strong consensus), their tolerance of adversary nodes is low. This article proposes a new consensus protocol to address all these issues. We call the new protocol MWPoW+, as its basic framework is based on the existing Multiple Winners Proof of Work (MWPoW) protocol but includes new mechanisms to address the issues mentioned previously. MWPoW+ is a vote-based protocol for strong consensus, asynchronous in consensus derivation but synchronous in communication. We prove that it can tolerate up to f < n/2 adversary nodes in a n-node system as if using a binary consensus protocol and does not suffer from progress-hindering attacks.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4320490882",
    "type": "article"
  },
  {
    "title": "IRGA: An Intelligent Implicit Real-time Gait Authentication System in Heterogeneous Complex Scenarios",
    "doi": "https://doi.org/10.1145/3594538",
    "publication_date": "2023-04-26",
    "publication_year": 2023,
    "authors": "Li Yang; Xi Li; Zhuoru Ma; Lu Li; Naixue Xiong; Jianfeng Ma",
    "corresponding_authors": "",
    "abstract": "Gait authentication as a technique that can continuously provide identity recognition on mobile devices for security has been investigated by academics in the community for decades. However, most of the existing work achieves insufficient generalization to complex real-world environments due to the complexity of the noisy real-world gait data. To address this limitation, we propose an intelligent Implicit Real-time Gait Authentication (IRGA) system based on Deep Neural Networks (DNNs) for enhancing the adaptability of gait authentication in practice. In the proposed system, the gait data (whether with complex interference signals) will first be processed sequentially by the imperceptible collection module and data preprocessing module for improving data quality. In order to illustrate and verify the suitability of our proposal, we provide analysis of the impact of individual gait changes on data feature distribution. Finally, a fusion neural network composed of a Convolutional Neural Network (CNN) and Long Short-Term Memory (LSTM) is designed to perform feature extraction and user authentication. We evaluate the proposed IRGA system in heterogeneous complex scenarios and present start-of-the-art comparisons on three datasets. Extensive experiments demonstrate that the IRGA system achieves improved performance simultaneously in several different metrics.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4367050959",
    "type": "article"
  },
  {
    "title": "Exploring the Potential of Cyber Manufacturing System in the Digital Age",
    "doi": "https://doi.org/10.1145/3596602",
    "publication_date": "2023-05-08",
    "publication_year": 2023,
    "authors": "Usman Ahmed; Jerry Chun‐Wei Lin; Gautam Srivastava",
    "corresponding_authors": "",
    "abstract": "Cyber-manufacturing Systems (CMS) have been growing in popularity, transitioning from conventional manufacturing to an innovative paradigm that emphasizes innovation, automation, better customer service, and intelligent systems. A new manufacturing model can improve efficiency and productivity, and provide better customer service and response times. In addition, it may revolutionize the way products are produced, from design to completion. Therefore, it is likely that this new manufacturing model will become increasingly popular. By building new technologies on top of existing CMS, these systems will ensure that data exchange and integration between decentralized systems are reliable and secure. Recently published case studies from industry and the literature support this claim; some challenges remain to be overcome. In general, the use of CMS can revolutionize the manufacturing industry. This study comprehensively analyzes these systems and their potential applications and implications. An overview of the field is then given and various aspects of CMS are also explored with more details. A taxonomy of the most common and current approaches to CMS is presented, including networked cyber-manufacturing systems, distributed cyber-manufacturing systems, cloud-based cyber-manufacturing systems, and cyber-physical systems (CPS). Furthermore, our survey identifies several popular open-source software and datasets and discusses how these resources can reduce barriers to CMS research. In addition, we identify several important issues and research opportunities associated with CMS, including better integration between hardware and software, improved security and privacy protocols, communication protocols, and improved data management systems. In summary, this paper presents a comprehensive overview of current technology and valuable insights are provided for the potential impact of CMS on society and industry.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4375862755",
    "type": "article"
  },
  {
    "title": "Offering Two-way Privacy for Evolved Purchase Inquiries",
    "doi": "https://doi.org/10.1145/3599968",
    "publication_date": "2023-05-25",
    "publication_year": 2023,
    "authors": "Jan Pennekamp; Markus Dahlmanns; Frederik Fuhrmann; Timo Heutmann; Alexander Kreppein; Dennis Grunert; Christoph Lange; Robert Schmitt; Klaus Wehrle",
    "corresponding_authors": "",
    "abstract": "Dynamic and flexible business relationships are expected to become more important in the future to accommodate specialized change requests or small-batch production. Today, buyers and sellers must disclose sensitive information on products upfront before the actual manufacturing. However, without a trust relation, this situation is precarious for the involved companies as they fear for their competitiveness. Related work overlooks this issue so far: existing approaches protect the information of a single party only, hindering dynamic and on-demand business relationships. To account for the corresponding research gap of inadequately privacy-protected information and to deal with companies without an established trust relation, we pursue the direction of innovative privacy-preserving purchase inquiries that seamlessly integrate into today’s established supplier management and procurement processes. Utilizing well-established building blocks from private computing, such as private set intersection and homomorphic encryption, we propose two designs with slightly different privacy and performance implications to securely realize purchase inquiries over the Internet. In particular, we allow buyers to consider more potential sellers without sharing sensitive information and relieve sellers of the burden of repeatedly preparing elaborate yet discarded offers. We demonstrate our approaches’ scalability using two real-world use cases from the domain of production technology. Overall, we present deployable designs that offer two-way privacy for purchase inquiries and, in turn, fill a gap that currently hinders establishing dynamic and flexible business relationships. In the future, we expect significantly increasing research activity in this overlooked area to address the needs of an evolving production landscape.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4378217142",
    "type": "article"
  },
  {
    "title": "Collaborative Hotspot Data Collection with Drones and 5G Edge Computing in Smart City",
    "doi": "https://doi.org/10.1145/3617373",
    "publication_date": "2023-08-23",
    "publication_year": 2023,
    "authors": "Pei-Cheng Song; Jeng‐Shyang Pan; Han‐Chieh Chao; Shu‐Chuan Chu",
    "corresponding_authors": "",
    "abstract": "The construction and governance of smart cities require the collaboration of different systems and different regions. How to realize the monitoring of abnormal hot spots through the collaboration of subsystems with limited resources is related to the stability and efficiency of the city. This work constructs a hot data processing framework for drones and 5G edge computing infrastructure, as well as an Ensemble Multi-Objective Cooperative Learning method to process three different types of hot data. The data collection phase combines set operations with the 0-1 multi-knapsack model, and the cooperative learning phase realizes the degree of cooperation control while retaining the ability of independent optimization of the subsystem. Finally, the advantages of the framework are verified by hot data coverage and collaborative processing efficiency, resource use cost, and balance.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4386091346",
    "type": "article"
  },
  {
    "title": "ML-Based Identification of Neuromuscular Disorder Using EMG Signals for Emotional Health Application",
    "doi": "https://doi.org/10.1145/3637213",
    "publication_date": "2023-12-14",
    "publication_year": 2023,
    "authors": "Abdelouahad Achmamad; Mohamed El Fezazi; Abdellah Chehri; Imran Ahmed; Atman Jbari; Rachid Saadane",
    "corresponding_authors": "",
    "abstract": "Abstract: The electromyogram (EMG), also known as an EMG, is used to assess nerve impulses in motor nerves, sensory nerves, and muscles. EMS is a versatile tool used in various biomedical applications. It is commonly employed to determine physical health, but it also finds utility in evaluating emotional well-being, such as through facial electromyography. Classification of EMG signals has attracted the interest of scientists since it is crucial for identifying neuromuscular disorders (NMDs). Recent advances in the miniaturization of biomedical sensors enable the development of medical monitoring systems. This paper presents a portable and scalable architecture for machine learning modules designed for medical diagnostics. In particular, we provide a hybrid classification model for NMDs. The proposed method combines two supervised machine learning classifiers with the discrete wavelet transform (DWT). During the online testing phase, the class label of an EMG signal is predicted using the classifiers’ optimal models, which can be identified at this stage. The simulation results demonstrate that both classifiers have an accuracy of over 98%. Finally, the proposed method was implemented using an embedded CompactRIO-9035 real-time controller.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4389735284",
    "type": "article"
  },
  {
    "title": "Dynamic and Immersive Framework for Drone Delivery Services in Skyway Networks",
    "doi": "https://doi.org/10.1145/3708892",
    "publication_date": "2025-01-04",
    "publication_year": 2025,
    "authors": "Jiamin Lin; Balsam Alkouz; Athman Bouguettaya; Amani Abusafia",
    "corresponding_authors": "",
    "abstract": "We propose a novel dynamic and immersive 3D framework designed to facilitate the setup and customization of drone scheduling algorithms for evaluating service-based drone delivery systems. This framework features a robust system architecture that supports user-defined behavior logic . It also incorporates real-time data communication protocols for relaying timely instructions to the drones. Additionally, it integrates a comprehensive drone energy consumption model that accurately simulates the physics of drone operations and accounts for both internal and external factors affecting energy usage. The framework includes a sophisticated 3D visualization component, depicting drone deliveries from source to destination through a realistic skyway network within an interactive virtual urban environment. It also enables automated data tracking , which is crucial for testing algorithms and collecting data to support data-driven decisions and optimizations. We evaluate the framework by conducting a comprehensive usability test to assess its user interface and overall user experience. Additionally, we test the framework using a drone swarm to execute delivery requests under both simple and complex energy consumption models. The results show that the framework has a user-friendly interface and effectively supports drone delivery simulations under the complex physics-based energy consumption model.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4406053398",
    "type": "article"
  },
  {
    "title": "Editorial",
    "doi": "https://doi.org/10.1145/3715912",
    "publication_date": "2025-02-11",
    "publication_year": 2025,
    "authors": "Jaideep Vaidya",
    "corresponding_authors": "Jaideep Vaidya",
    "abstract": "Dear readers, in almost all editorials I talked about volunteers dropping out of our Editorial Board and new ones coming in. It may sound like a lot of fluctuation among the members of the Editorial Board, but it is not. Associate Editors start with a two-...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4407349533",
    "type": "editorial"
  },
  {
    "title": "Semantically Correct Policy Mining and Enforcement for Attribute Based Access Control",
    "doi": "https://doi.org/10.1145/3736764",
    "publication_date": "2025-05-23",
    "publication_year": 2025,
    "authors": "Gunjan Batra; Samir Talegaon; Vijayalakshmi Atluri; Jaideep Vaidya; Shamik Sural",
    "corresponding_authors": "",
    "abstract": "Attribute-Based Access Control (ABAC) is increasingly becoming popular due to its dynamic, flexible, portable, and scalable nature. Under ABAC, security policies (ABAC rules) are stated in terms of the attributes of the subject, the object and the environment. A subject is granted access to an object if their respective attribute values are satisfied against a set of ABAC rules. Typically hierarchical relationships exist among the subjects as well as the objects, where more specific subjects (objects) inherit the attributes from the general ones. As such, if a subject is allowed access to a general object, that subject is allowed to access all of its sub-types. This has been the general understanding and current ABAC enforcement and policy mining approaches follow this approach. However, in this article, we argue that the general understanding of the semantics of the ABAC is not always appropriate. Indeed, under certain semantics, the specific data may be more sensitive than that of its general counterpart. In that situation, if a subject is allowed access to a general type, it should not be allowed access to its sub-type, which is contrary to the current understanding and implementation. This paper is the first attempt in the literature to distinguish these two different ABAC semantics arising from the different semantics of object attributes themselves. We present concrete examples of these two semantics and demonstrate what can go wrong – both anecdotally as well as empirically – if one ignores the underlying semantics and inappropriately uses the existing enforcement and mining algorithms. We then present how existing algorithms can be modified so that no misconfigurations arise and security is ensured.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4410692795",
    "type": "article"
  },
  {
    "title": "AGF: Adaptive GNN Framework via Subgraph and Model Partitioning for Edge Analysis",
    "doi": "https://doi.org/10.1145/3744923",
    "publication_date": "2025-06-18",
    "publication_year": 2025,
    "authors": "Zimeng Fan; Min Peng",
    "corresponding_authors": "",
    "abstract": "AI has found extensive application in edge analytics, with Deep Neural Networks effectively processing and analyzing data. Some applications need to deal with unstructured data like graphs. This complexity and diversity of unstructured features pose challenges for traditional DNN models. Therefore, Graph Neural Networks have emerged as a significant solution. However, GNNs encounter two primary challenges in edge analytics scenarios: scalability and efficiency. These challenges arise primarily from significant structural differences among various graphs and models. To address these issues, we propose AGF, an Adaptive GNN Framework. AGF consists of three components: subgraph partitioning and model partitioning, scalable hardware architecture, and design space exploration. Subgraph partitioning and model partitioning transform complex and diverse GNNs into a uniform computing flow and subgraphs. These can be directly mapped onto the hardware kernel, leveraging GNN characteristics to achieve independent parallelism. The hardware architecture is based on a multi-level processing element structure, which can efficiently parallelize subgraphs and vertices based on the partitioning. The design space exploration selects kernel allocation strategies and setups based on the hardware, dataset, and model. We validated AGF using six datasets and three GNN models. The results demonstrate that our framework achieves an acceleration ranging from 4.54 to 53.17 × compared to the GPU-based GNN framework. When compared to other FPGA-based GNN accelerators, AGF achieves a latency reduction ranging from 1.16 to 33.6 × in model execution and from 1.09 to 2.37 × in end-to-end scenarios.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4411403545",
    "type": "article"
  },
  {
    "title": "Budget Inference Attacks and Countermeasures in Locally Differentially Private Data Collection",
    "doi": "https://doi.org/10.1145/3759250",
    "publication_date": "2025-08-06",
    "publication_year": 2025,
    "authors": "Berkay Kemal Balioglu; Mehmet Emre Gürsoy",
    "corresponding_authors": "",
    "abstract": "Local differential privacy (LDP) has recently become a popular notion for privacy-preserving data collection from user devices. It has been applied in numerous contexts related to the Internet of Things (IoT) and cyber-physical systems to enable privacy-preserving edge data analytics. The strength of privacy protection in LDP deployments depends on the privacy budget ε, and there are several scenarios in which it is desirable for the value of ε to remain hidden from untrusted third parties, or the inference of ε by an untrusted third party may constitute a privacy leakage. In this paper, we propose a new class of attacks called budget inference attacks (BIAs) which enable an adversary to infer the ε budget value from the outputs of an LDP protocol. We develop BIAs for two types of adversaries: informed adversaries who have knowledge of the statistical data distribution, and uninformed adversaries who do not. We apply our BIAs on five popular LDP protocols and experimentally evaluate them using multiple datasets, varying ε budgets, population sizes, and attack settings and parameters. Results show that our BIAs are highly effective, as they enable the adversary to infer the ε value with low errors. We also propose three potential countermeasures against our BIAs. Analyses show that while our countermeasures can be effective in reducing BIA accuracy, they also increase utility loss; therefore the tradeoff between BIA accuracy and utility loss needs to be carefully considered.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413023324",
    "type": "article"
  },
  {
    "title": "Incentivizing Cooperation for Handover Strategies in LEO Constellations via Fairness-guided MARL",
    "doi": "https://doi.org/10.1145/3760527",
    "publication_date": "2025-08-13",
    "publication_year": 2025,
    "authors": "Xiupu Lang; Lin Sun; Peiqi Huang; Jinming Liu; Boming Zhu; Xinchao Gao; Lin Gui; Haopeng Chen",
    "corresponding_authors": "",
    "abstract": "Handover (HO) is one of the pivotal technologies for mobility management in highly dynamic mega LEO Earth Orbit satellite constellations (MLSCs). Due to the lack of channel reservation under random access (RA) and the prohibitive overhead incurred by centralized HO scheduling, intense competition among massive connections (e.g., IoRT nodes) results in significant degradation of service continuity. To solve the above challenges, we propose a distributed fairness-guided handover strategy (DHO-F) to dynamically select the best HO target and sub-channel. Specifically, the DHO-F optimization problem is formulated based on max-min egalitarian fairness and further modeled as a multi-objective Markov decision process (MOMDP), where fairness is expressed by the social welfare function (SWF). To address MOMDP, the analytical form of the policy gradient to maximize fairness is derived. Subsequently, Multi-agent Proximal Policy Optimization (MAPPO) with distributed cooperation is exploited to achieve long-term maximization. The fairness-guided MAPPO (FG-MAPPO) features a hybrid network architecture that simultaneously takes into account maximizing individual link rates and fairness among UEs. It reconciles these two conflicting objectives through the collaboration between a throughput-oriented (TO) network and a fairness-oriented (FO) network. Additionally, a distributed training framework is implemented to improve the sample efficiency and data diversity for on-policy FG-MAPPO. FG-MAPPO is fully compatible with 3GPP’s conditional handover (CHO) framework, demonstrating that it can be implemented in real world. Extensive evaluations demonstrate that DHO-F demonstrates superior performance even compared to centralized algorithms, achieving an average improvement of 3.48% in SWF metric. Moreover, DHO-F establishes new SOTA performance in balancing fairness and rate maximization across medium-to-high load scenarios compared to IDQN, ISAC, and MAPPO.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413128552",
    "type": "article"
  },
  {
    "title": "<i>D-RecSys</i> : A Decentralized Recommendation Framework for Web 3.0-Based Content-Sharing Platforms",
    "doi": "https://doi.org/10.1145/3771093",
    "publication_date": "2025-10-07",
    "publication_year": 2025,
    "authors": "Utsa Roy; R. Mukhopadhyay; P. Sharma; Nirnay Ghosh",
    "corresponding_authors": "",
    "abstract": "The transition of the web from centralized to decentralized or distributed architectures offers numerous advantages but also introduces significant challenges. One of the key challenges is user profiling to provide personalization, particularly personalized content recommendations. Traditional centralized recommendation systems rely on aggregated user data and central servers, making them incompatible with the principles of decentralization in Web 3.0. To bridge this gap, we propose D-RecSys , a decentralized recommendation framework specifically designed for Web 3.0-based content-sharing dApps. D-RecSys combines federated learning and clustering algorithms to deliver personalized recommendations while preserving user privacy and anonymity. The framework leverages blockchain technology for trustless coordination, enabling the generation of a global model through a modified block structure and mining algorithm. This structure facilitates the aggregation of local models into intermediate block models and subsequently produces the global model. To validate the effectiveness of D-RecSys , we conducted a number of experiments in a simulated Web 3.0 environment. To ensure the generalization capability of the framework, we used three datasets from different domains, i.e., anime recommendation, e-commerce product recommendation, and cellphone recommendation. The results demonstrate that D-RecSys achieves performance levels comparable to centralized recommendation systems while adhering to the core principles of decentralization, user anonymity, and data privacy.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4414915042",
    "type": "article"
  },
  {
    "title": "Sharing Personal Data via Incentive-based Negotiation: Preference Modeling and Empirical Analysis",
    "doi": "https://doi.org/10.1145/3770751",
    "publication_date": "2025-10-10",
    "publication_year": 2025,
    "authors": "Emre Kuru; Reyhan Aydoğan; Pınar Öztürk; Yousef Razeghi",
    "corresponding_authors": "",
    "abstract": "In an age where data is a pivotal asset for businesses, the ethical acquisition and use of personal information has become increasingly more significant. Empowering data providers with greater autonomy over their personal data is more important than ever. To address this, we propose a novel negotiation-based information-sharing framework that empowers individuals to actively negotiate the terms of their data sharing, addressing privacy concerns and ethical data usage. The framework enables users to determine what personal information they share and under what conditions, fostering a more balanced and transparent data exchange process. Our system allows data consumer agents to negotiate with their human users and can operate fully automatically, with agents representing data providers negotiating based on elicited preferences and needs. We propose novel preference modeling approaches and a negotiation framework to facilitate the bilateral sharing of information and incentives between data consumers and providers. User experiments demonstrate the efficacy of our negotiation approach and the effectiveness of the proposed preference models. Empirical results validate the benefits of the proposed framework.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4415027135",
    "type": "article"
  },
  {
    "title": "Graphical query interfaces for semistructured data: the QURSED system",
    "doi": "https://doi.org/10.1145/1064340.1064344",
    "publication_date": "2005-05-01",
    "publication_year": 2005,
    "authors": "Michalis Petropoulos; Yannis Papakonstantinou; Vasilis Vassalos",
    "corresponding_authors": "",
    "abstract": "We describe the QURSED system for the declarative specification and automatic generation of Web-based query forms and reports ( QFR s) for semistructured XML data. In QURSED, a QFR is formally described by its query set specification ( QSS ) which captures the complex query and reporting capabilities of the QFR and the associations of the query set specification with visual elements that implement these capabilities on a Web page. The design-time component of QURSED, called QURSED Editor, semi-automates the development of the query set specification and its association with visual elements by translating intuitive visual actions taken by a developer into appropriate specification fragments . The run-time component of QURSED produces XQuery statements by synthesizing fragments from the query set specification that have been activated during the interaction of the end-user with the QFR and renders the query results in interactive reports as specified by the QSS . We describe the techniques and algorithms employed by QURSED with emphasis on how it accommodates the intricacies introduced by the semistructured nature of the underlying data. We present the formal model of the query set specification, as well as its generation via the QURSED Editor, and focus on the techniques and heuristics the Editor employs for translating visual designer input into meaningful specifications. We also present the algorithms QURSED employs for query generation and report generation. An online demonstration of the system is available at http://www.db.ucsd.edu/qursed/.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W2086021843",
    "type": "article"
  },
  {
    "title": "Computing customized page ranks",
    "doi": "https://doi.org/10.1145/1183463.1183466",
    "publication_date": "2006-11-01",
    "publication_year": 2006,
    "authors": "Ah Chung Tsoi; Markus Hagenbuchner; Franco Scarselli",
    "corresponding_authors": "",
    "abstract": "In this article, we present a new approach to page ranking. The page rank of a collection of Web pages can be represented in a parameterized model, and the user requirements can be represented by a set of constraints. For a particular parameterization, namely, a linear combination of the page ranks produced by different forcing functions, and user requirements represented by a set of linear constraints, the problem can be solved using a quadratic programming method. The solution to this problem produces a set of parameters which can be used for ranking all pages in the Web. We show that the method is suitable for building customized versions of PageRank which can be readily adapted to the needs of a vertical search engine or that of a single user.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W2043424547",
    "type": "article"
  },
  {
    "title": "Core algorithms in the CLEVER system",
    "doi": "https://doi.org/10.1145/1149121.1149123",
    "publication_date": "2006-05-01",
    "publication_year": 2006,
    "authors": "Ravi Kumar; Prabhakar Raghavan; Sridhar Rajagopalan; Andrew Tomkins",
    "corresponding_authors": "",
    "abstract": "This article describes the CLEVER search system developed at the IBM Almaden Research Center. We present a detailed and unified exposition of the various algorithmic components that make up the system, and then present results from two user studies.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W2133357323",
    "type": "article"
  },
  {
    "title": "An online blog reading system by topic clustering and personalized ranking",
    "doi": "https://doi.org/10.1145/1552291.1552292",
    "publication_date": "2009-07-01",
    "publication_year": 2009,
    "authors": "Xin Li; Jun Yan; Weiguo Fan; Ning Liu; Shuicheng Yan; Chen Zheng",
    "corresponding_authors": "",
    "abstract": "There is an increasing number of people reading, writing, and commenting on blogs. According to a recent survey made by Technorati, there are about 75,000 new blogs and 1.2 million new posts everyday. However, it is difficult and time consuming for a blog reader to find the most interesting posts in the huge and dynamic blog world. In this article, an online Personalized Blog Reader (PBR) system is proposed, which facilitates blog readers in browsing the coolest and newest blog posts of their interests by automatically clustering the most relevant stories. PBR aims to make a user's potential favorite topics always ranked higher than those nonfavorite ones. This is accomplished in the following steps. First, the system collects and provides a unified incremental index of posts coming from different blogs. Then, an incremental clustering algorithm with a flexible half-bounded window of observation is proposed to satisfy the requirements of online processing. It learns people's personalized reading preferences to present a user with a final reading list. The experimental results show that the proposed incremental clustering algorithm is effective and efficient, and the personalization of the PBR performs well.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2031209579",
    "type": "article"
  },
  {
    "title": "Forecasting Click-Through Rates Based on Sponsored Search Advertiser Bids and Intermediate Variable Regression",
    "doi": "https://doi.org/10.1145/1852096.1852099",
    "publication_date": "2010-10-01",
    "publication_year": 2010,
    "authors": "Ilya Gluhovsky",
    "corresponding_authors": "Ilya Gluhovsky",
    "abstract": "To participate in sponsored search online advertising, an advertiser bids on a set of keywords relevant to his/her product or service. When one of these keywords matches a user search string, the ad is then considered for display among sponsored search results. Advertisers compete for positions in which their ads appear, as higher slots typically result in more user clicks. All existing position allocating mechanisms charge more per click for a higher slot. Therefore, an advertiser must decide whether to bid high and receive more, but more expensive, clicks. In this work, we propose a novel methodology for building forecasting landscapes relating an individual advertiser bid to the expected click-through rate and/or the expected daily click volume. Displaying such landscapes is currently offered as a service to advertisers by all major search engine providers. Such landscapes are expected to be instrumental in helping the advertisers devise their bidding strategies. We propose a triply monotone regression methodology. We start by applying the current state-of-the-art monotone regression solution. We then propose to condition on the ad position and to estimate the bid-position and position-click effects separately. While the latter translates into a standard monotone regression problem, we devise a novel solution to the former based on approximate maximum likelihood. We show that our proposal significantly outperforms the standard monotone regression solution, while the latter similarly improves upon routinely used ad-hoc methods. Last, we discuss other e-commerce applications of the proposed intermediate variable regression methodology.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2112503436",
    "type": "article"
  },
  {
    "title": "Distributed application configuration, management, and visualization with plush",
    "doi": "https://doi.org/10.1145/2049656.2049658",
    "publication_date": "2011-12-01",
    "publication_year": 2011,
    "authors": "Jeannie Albrecht; Christopher A. Tuttle; Ryan Braud; Darren Dao; Nikolay Topilski; Alex C. Snoeren; Amin Vahdat",
    "corresponding_authors": "",
    "abstract": "Support for distributed application management in large-scale networked environments remains in its early stages. Although a number of solutions exist for subtasks of application deployment, monitoring, and maintenance in distributed environments, few tools provide a unified framework for application management. Many of the existing tools address the management needs of a single type of application or service that runs in a specific environment, and these tools are not adaptable enough to be used for other applications or platforms. To this end, we present the design and implementation of Plush, a fully configurable application management infrastructure designed to meet the general requirements of several different classes of distributed applications. Plush allows developers to specifically define the flow of control needed by their computations using application building blocks. Through an extensible resource management interface, Plush supports execution in a variety of environments, including both live deployment platforms and emulated clusters. Plush also uses relaxed synchronization primitives for improving fault tolerance and liveness in failure-prone environments. To gain an understanding of how Plush manages different classes of distributed applications, we take a closer look at specific applications and evaluate how Plush provides support for each.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2112831787",
    "type": "article"
  },
  {
    "title": "Adaptive Message Routing and Replication in Mobile Opportunistic Networks for Connected Communities",
    "doi": "https://doi.org/10.1145/3122984",
    "publication_date": "2017-10-26",
    "publication_year": 2017,
    "authors": "Haibo Zhang; Luming Wan; Yawen Chen; Laurence T. Yang; Lizhi Peng",
    "corresponding_authors": "",
    "abstract": "Mobile opportunistic networking is a promising technology that can supplement existing cellular and WiFi networks to provide desirable services for smart and connected communities. Message routing is the most compelling challenge in mobile opportunistic networks due to the lack of contemporaneous end-to-end paths and the resource constraints at mobile devices. To improve the probability of successful message delivery, most existing routing schemes use the past contact history to predict future contacts for message forwarding, and exploit message replication and redundancy for multicopy routing. However, most existing prediction-based routing schemes simply use the average pairwise contact probability as the routing metric and neglect the benefits of exploring fine-grained contact information such as pairwise repeated contact patterns to improve the accuracy of predicting future contacts. Moreover, there is no efficient mechanism that can adaptively control message replication in a decentralized manner to achieve both high probability of successful message delivery and low message overhead. To address these problems, we present FGAR, a routing protocol designed for mobile opportunistic networks by leveraging fine-grained contact characterization and adaptive message replication. In FGAR, contact history is characterized in a fine-grained manner with timing information using a sliding window mechanism, and future contacts are predicted based on the fine-grained contact information, thereby improving the accuracy of contact prediction. We further design an efficient message replication scheme in which message replication is controlled in a fully decentralized manner by taking into account the expected message delivery probability, the replication history, and the quality of the encountered device. A replica is generated only when it is necessary to fulfill the expected message delivery probability. We evaluate our scheme through trace-driven simulations, and the simulation results show that FGAR outperforms existing schemes. In comparison with PRoPHET, FGAR can achieve more than 20% improvement on average on successful message delivery, whereas the message overhead has been reduced by a factor up to 15.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2765369521",
    "type": "article"
  },
  {
    "title": "<i>i</i> - <i>Jacob</i>",
    "doi": "https://doi.org/10.1145/3093899",
    "publication_date": "2018-03-13",
    "publication_year": 2018,
    "authors": "Xuanzhe Liu; Meihua Yu; Yun Ma; Gang Huang; Hong Mei; Yunxin Liu",
    "corresponding_authors": "",
    "abstract": "Web browsing is always a key requirement of Internet users. Current mobile Web apps can contain computation-intensive JavaScript logics and thus affect browsing performance. Learning from our over-decade research and development experiences of the Internetware paradigm, we present the novel and generic i - Jacob approach to improving the performance of mobile Web browsing with effective JavaScript-code offloading. Our approach proposes a programming abstraction to make mobile Web situational and adaptive to contexts, by specifying the computation-intensive and “ offloadable ” code, and develops a platform-independent lightweight runtime spanning the mobile devices and the cloud. We demonstrate the efficiency of i - Jacob with some typical computation-intensive tasks over various combinations of hardware, operating systems, browsers, and network connections. The improvements can reach up to 49× speed-up in response time and 90% saving in energy.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2791125708",
    "type": "article"
  },
  {
    "title": "Policy Adaptation in Hierarchical Attribute-based Access Control Systems",
    "doi": "https://doi.org/10.1145/3323233",
    "publication_date": "2019-08-17",
    "publication_year": 2019,
    "authors": "Saptarshi Das; Shamik Sural; Jaideep Vaidya; Vijayalakshmi Atluri",
    "corresponding_authors": "",
    "abstract": "In Attribute-Based Access Control (ABAC), access to resources is given based on the attributes of subjects, objects, and environment. There is an imminent need for the development of efficient algorithms that enable migration to ABAC. However, existing policy mining approaches do not consider possible adaptation to the policy of a similar organization. In this article, we address the problem of automatically determining an optimal assignment of attribute values to subjects for enabling the desired accesses to be granted while minimizing the number of ABAC rules used by each subject or other appropriate metrics. We show the problem to be NP-Complete and propose a heuristic solution.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2969381679",
    "type": "article"
  },
  {
    "title": "Modeling Decentralized Reputation-Based Trust for Initial Transactions in Digital Environments",
    "doi": "https://doi.org/10.1145/2461321.2461323",
    "publication_date": "2013-05-01",
    "publication_year": 2013,
    "authors": "Ilung Pranata; Rukshan Athauda; Geoff Skinner",
    "corresponding_authors": "",
    "abstract": "The advent of digital environments has generated significant benefits for businesses, organizations, governments, academia and societies in general. Today, over millions of transactions take place on the Internet. Although the widespread use of digital environments has generally provided opportunities for societies, a number of threats have limited their adoption. The de-facto standard today is for certification authorities to authenticate the identity of service providers while trust on the provided services is implied. This approach has certain shortcomings, for example, single point of failure, implied trust rather than explicit trust and others. One approach for minimizing such threats is to introduce an effective and resilient trust mechanism that is capable of determining the trustworthiness of service providers in providing their services. Determining the trustworthiness of services reduces invalid transactions in digital environments and further encourages collaborations. Evaluating trustworthiness of a service provider without any prior historical transactions (i.e. the initial transaction) pose a number of challenging issues. This article presents TIDE - a decentralized reputation trust mechanism that determines the initial trustworthiness of entities in digital environments. TIDE improves the precision of trust computation by considering raters’ feedback, number of transactions, credibility, incentive to encourage raters’ participation, strategy for updating raters’ category, and safeguards against dynamic personalities. Furthermore, TIDE classifies raters into three categories and promotes the flexibility and customization through its parameters. Evaluation of TIDE against several attack vectors demonstrates its accuracy, robustness and resilience.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W1997621199",
    "type": "article"
  },
  {
    "title": "Properties and Evolution of Internet Traffic Networks from Anonymized Flow Data",
    "doi": "https://doi.org/10.1145/1944339.1944342",
    "publication_date": "2011-03-01",
    "publication_year": 2011,
    "authors": "Mark Meiss; Filippo Menczer; Alessandro Vespignani",
    "corresponding_authors": "",
    "abstract": "Many projects have tried to analyze the structure and dynamics of application overlay networks on the Internet using packet analysis and network flow data. While such analysis is essential for a variety of network management and security tasks, it is infeasible on many networks: either the volume of data is so large as to make packet inspection intractable, or privacy concerns forbid packet capture and require the dissociation of network flows from users’ actual IP addresses. Our analytical framework permits useful analysis of network usage patterns even under circumstances where the only available source of data is anonymized flow records. Using this data, we are able to uncover distributions and scaling relations in host-to-host networks that bear implications for capacity planning and network application design. We also show how to classify network applications based entirely on topological properties of their overlay networks, yielding a taxonomy that allows us to accurately identify the functions of unknown applications. We repeat this analysis on a more recent dataset, allowing us to demonstrate that the aggregate behavior of users is remarkably stable even as the population changes.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2036028847",
    "type": "article"
  },
  {
    "title": "Characterizing Intelligence Gathering and Control on an Edge Network",
    "doi": "https://doi.org/10.1145/1993083.1993085",
    "publication_date": "2011-07-01",
    "publication_year": 2011,
    "authors": "Martin Arlitt; Niklas Carlsson; Phillipa Gill; Aniket Mahanti; Carey Williamson",
    "corresponding_authors": "",
    "abstract": "There is a continuous struggle for control of resources at every organization that is connected to the Internet. The local organization wishes to use its resources to achieve strategic goals. Some external entities seek direct control of these resources, for purposes such as spamming or launching denial-of-service attacks. Other external entities seek indirect control of assets (e.g., users, finances), but provide services in exchange for them. Using a year-long trace from an edge network, we examine what various external organizations know about one organization. We compare the types of information exposed by or to external organizations using either active ( reconnaissance ) or passive ( surveillance ) techniques. We also explore the direct and indirect control external entities have on local IT resources.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2059978479",
    "type": "article"
  },
  {
    "title": "The Effect of Data Caps upon ISP Service Tier Design and Users",
    "doi": "https://doi.org/10.1145/2774973",
    "publication_date": "2015-06-24",
    "publication_year": 2015,
    "authors": "Wei Dai; Scott Jordan",
    "corresponding_authors": "",
    "abstract": "We model the design and impact of Internet pricing plans with data caps. We consider a monopoly ISP that maximizes its profit by setting tier prices, tier rates, network capacity, data caps, and overage charges. We show that when data caps are used to maximize profit, a monopoly ISP will keep the basic tier price the same, increase the premium tier rate, and decrease the premium tier price and the basic tier rate. We give analytical and numerical results to illustrate the increase in ISP profit, and the corresponding changes in user tier choices, user surplus, and social welfare.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2208621283",
    "type": "article"
  },
  {
    "title": "Behind the Myths of Citizen Participation",
    "doi": "https://doi.org/10.1145/3093892",
    "publication_date": "2017-11-04",
    "publication_year": 2017,
    "authors": "Claudia López; Rosta Farzan; Yu‐Ru Lin",
    "corresponding_authors": "",
    "abstract": "Various information systems have emerged to facilitate citizen participation in the life of their communities. However, there is a lack of robust understanding of what enables the sustainability of such systems. This work introduces a framework to identify and analyze various factors that influence the sustainability of “hyper-local” information systems. Using longitudinal observations of participation from 35 online neighborhood discussion forums over six years, we analyze the relationship between sustainability and online–offline community characteristics. Our results not only show patterns consistent with previous observations but reveal the dubious influences of member heterogeneity and network structure. Design insights are discussed.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2767834322",
    "type": "article"
  },
  {
    "title": "Source-Aware Crisis-Relevant Tweet Identification and Key Information Summarization",
    "doi": "https://doi.org/10.1145/3300229",
    "publication_date": "2019-08-27",
    "publication_year": 2019,
    "authors": "Xiaodong Ning; Lina Yao; Boualem Benatallah; Yihong Zhang; Quan Z. Sheng; Salil S. Kanhere",
    "corresponding_authors": "",
    "abstract": "Twitter is an important source of information that people frequently contribute to and rely on for emerging topics, public opinions, and event awareness. Crisis-relevant tweets can potentially avail a magnitude of applications such as helping authorities and governments become aware of situations and thus offer better responses. One major challenge toward crisis-awareness in Twitter is to identify those tweets that are relevant to unseen crises. In this article, we propose an automatic labeling approach to distinguishing crisis-relevant tweets while differentiating source types (e.g., government or personal accounts) simultaneously. We first analyze and identify tweet-specific linguistic, sentimental, and emotional features based on statistical topic modeling. Then, we design a novel correlative convolutional neural network which uses a shared hidden layer to learn effective representations of the multi-faceted features. The model can discover salient information while being robust to the variations and noises in tweets and sources. To obtain a bird’s-eye view of a crisis event, we further develop an approach to automatically summarize key information of identified tweets. Empirical evaluation on a real Twitter dataset demonstrates the feasibility of discerning relevant tweets for an unseen crisis. The applicability of our proposed approach is further demonstrated with a crisis aider system.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2970939965",
    "type": "article"
  },
  {
    "title": "Unsupervised Derivation of Keyword Summary for Short Texts",
    "doi": "https://doi.org/10.1145/3397162",
    "publication_date": "2020-07-07",
    "publication_year": 2020,
    "authors": "Bin Cao; Jiawei Wu; Sichao Wang; Honghao Gao; Jing Fan; Shuiguang Deng; Jianwei Yin; Xuan Liu",
    "corresponding_authors": "",
    "abstract": "Automatically summarizing a group of short texts that mainly share one topic is a fundamental task in many applications, e.g., summarizing the main symptoms for a disease based on a group of medical texts that are usually short, i.e., tens of words. Conventional unsupervised short text summarization techniques tend to find the most representative short text document. However, they may cause privacy issues, e.g., personal information in the medical texts may be exposed. Moreover, compared with the complete short text where some unimportant words may exist, a summary consisting of only a few keywords is more preferable by the user due to its clear and concise form. Due to the above reasons, in this article, we aim to solve the problem of unsupervised derivation of keyword summary for short texts. Existing keyword extraction methods such as Latent Dirichlet Allocation cannot be applied to solve this problem, since (1) the ordering relations among the extracted keywords are ignored, which causes troubles for people to capture the main idea of the event, and (2) short texts contain limited context, which makes it hard to find the optimal words for semantic coverage. Hence, we propose a simple but yet effective method named Frequent Closed Wordsets Ranking (FCWRank) to derive the keyword summary from a short text cluster. FCWRank is an unsupervised method that builds on the idea of frequent closed itemset mining in transaction database. FCWRank first mines all frequent closed wordsets from a cluster of short texts and then selects the most important wordset based on an importance model where the similarity between closed wordsets and the relation between the closed wordset and the short text document are considered simultaneously. To make the keywords within the wordset more understandable, FCWRank further unfolds the semantics behind them by sorting them. Experiments on real-world short text collections show that FCWRank outperforms the state-of-the-art baselines in terms of Recall-Oriented Understudy for Gisting Evaluation-Longest common subsequence F1, precision and recall scores.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W3097687554",
    "type": "article"
  },
  {
    "title": "Blockchain in eCommerce",
    "doi": "https://doi.org/10.1145/3445788",
    "publication_date": "2021-01-18",
    "publication_year": 2021,
    "authors": "Sabah Mohammed; Jinan Fiaidhi; Carlos Ramos; Tai-hoon Kim; Wai Chi Fang; Tarek Abdelzaher",
    "corresponding_authors": "",
    "abstract": "As blockchain technology is becoming a driving force in the global economy, it is also gaining critical acclaim in the e-commerce industry. Both the blockchain and e-commerce are inseparable as they involve transactions. Blockchain protect transactions and e-commerce activities rely on them. Blockchain technology enables a decentralized marketplace to support important business activities like secure payments, managing the supply chain and reducing the fraud to mention few. In this special issue editorial we are introducing 11 research articles in this hot area of research that were selected by our reviewers from over than 250 submissions. As blockchain technology is becoming a driving force in the global economy, it is also gaining critical acclaim in the e-commerce industry. Both the blockchain and e-commerce are inseparable as they involve transactions. Blockchain protect transactions and e-commerce activities rely on them. Blockchain technology enables a decentralized marketplace to support important business activities like secure payments, managing the supply chain and reducing the fraud to mention few. In this special issue editorial we are introducing 11 research articles in this hot area of research that were selected by our reviewers from over than 250 submissions.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W3121382405",
    "type": "article"
  },
  {
    "title": "A Multi-Threshold Ant Colony System-based Sanitization Model in Shared Medical Environments",
    "doi": "https://doi.org/10.1145/3408296",
    "publication_date": "2021-06-02",
    "publication_year": 2021,
    "authors": "Jimmy Ming‐Tai Wu; Gautam Srivastava; Jerry Chun‐Wei Lin; Qian Teng",
    "corresponding_authors": "",
    "abstract": "During the past several years, revealing some useful knowledge or protecting individual’s private information in an identifiable health dataset (i.e., within an Electronic Health Record) has become a tradeoff issue. Especially in this era of a global pandemic, security and privacy are often overlooked in lieu of usability. Privacy preserving data mining (PPDM) is definitely going to be have an important role to resolve this problem. Nevertheless, the scenario of mining information in an identifiable health dataset holds high complexity compared to traditional PPDM problems. Leaking individual private information in an identifiable health dataset has becomes a serious legal issue. In this article, the proposed Ant Colony System to Data Mining algorithm takes the multi-threshold constraint to secure and sanitize patents’ records in different lengths, which is applicable in a real medical situation. The experimental results show the proposed algorithm not only has the ability to hide all sensitive information but also to keep useful knowledge for mining usage in the sanitized database.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W3166777169",
    "type": "article"
  },
  {
    "title": "IBRDM: An Intelligent Framework for Brain Tumor Classification Using Radiomics- and DWT-based Fusion of MRI Sequences",
    "doi": "https://doi.org/10.1145/3434775",
    "publication_date": "2021-09-28",
    "publication_year": 2021,
    "authors": "Rahul Kumar; Ankur Gupta; Harkirat Singh Arora; Balasubramanian Raman",
    "corresponding_authors": "",
    "abstract": "Brain tumors are one of the critical malignant neurological cancers with the highest number of deaths and injuries worldwide. They are categorized into two major classes, high-grade glioma (HGG) and low-grade glioma (LGG), with HGG being more aggressive and malignant, whereas LGG tumors are less aggressive, but if left untreated, they get converted to HGG. Thus, the classification of brain tumors into the corresponding grade is a crucial task, especially for making decisions related to treatment. Motivated by the importance of such critical threats to humans, we propose a novel framework for brain tumor classification using discrete wavelet transform-based fusion of MRI sequences and Radiomics feature extraction. We utilized the Brain Tumor Segmentation 2018 challenge training dataset for the performance evaluation of our approach, and we extract features from three regions of interest derived using a combination of several tumor regions. We used wrapper method-based feature selection techniques for selecting a significant set of features and utilize various machine learning classifiers, Random Forest, Decision Tree, and Extra Randomized Tree for training the model. For proper validation of our approach, we adopt the five-fold cross-validation technique. We achieved state-of-the-art performance considering several performance metrics, 〈 Acc , Sens , Spec , F1-score , MCC , AUC 〉 ≡ 〈 98.60%, 99.05%, 97.33%, 99.05%, 96.42%, 98.19% 〉, where Acc , Sens , Spec , F1-score , MCC , and AUC represents the accuracy, sensitivity, specificity, F1-score, Matthews correlation coefficient, and area-under-the-curve, respectively. We believe our proposed approach will play a crucial role in the planning of clinical treatment and guidelines before surgery.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W3202671629",
    "type": "article"
  },
  {
    "title": "Agile Support Vector Machine for Energy-efficient Resource Allocation in IoT-oriented Cloud using PSO",
    "doi": "https://doi.org/10.1145/3433541",
    "publication_date": "2021-11-09",
    "publication_year": 2021,
    "authors": "Muhammad Junaid; Adnan Sohail; Fadi Al‐Turjman; Rashid Ali",
    "corresponding_authors": "",
    "abstract": "Over the years cloud computing has seen significant evolution in terms of improvement in infrastructure and resource provisioning. However the continuous emergence of new applications such as the Internet of Things (IoTs) with thousands of users put a significant load on cloud infrastructure. Load balancing of resource allocation in cloud-oriented IoT is a critical factor that has a significant impact on the smooth operation of cloud services and customer satisfaction. Several load balancing strategies for cloud environment have been proposed in the past. However the existing approaches mostly consider only a few parameters and ignore many critical factors having a pivotal role in load balancing leading to less optimized resource allocation. Load balancing is a challenging problem and therefore the research community has recently focused towards employing machine learning-based metaheuristic approaches for load balancing in the cloud. In this paper we propose a metaheuristics-based scheme Data Format Classification using Support Vector Machine (DFC-SVM), to deal with the load balancing problem. The proposed scheme aims to reduce the online load balancing complexity by offline-based pre-classification of raw-data from diverse sources (such as IoT) into different formats e.g. text images media etc. SVM is utilized to classify “n” types of data formats featuring audio video text digital images and maps etc. A one-to-many classification approach has been developed so that data formats from the cloud are initially classified into their respective classes and assigned to virtual machines through the proposed modified version of Particle Swarm Optimization (PSO) which schedules the data of a particular class efficiently. The experimental results compared with the baselines have shown a significant improvement in the performance of the proposed approach. Overall an average of 94% classification accuracy is achieved along with 11.82% less energy 16% less response time and 16.08% fewer SLA violations are observed.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W3214541931",
    "type": "article"
  },
  {
    "title": "Progressive Batch Medical Image Retrieval Processing in Mobile Wireless Networks",
    "doi": "https://doi.org/10.1145/2783437",
    "publication_date": "2015-08-14",
    "publication_year": 2015,
    "authors": "Yi Zhuang; Nan Jiang; Qing Li; Lei Chen; Chunhua Ju",
    "corresponding_authors": "",
    "abstract": "This article addresses a multi-query optimization problem for distributed medical image retrieval in mobile wireless networks by exploiting the dependencies in the derivation of a retrieval evaluation plan. To the best of our knowledge, this is the first work investigating batch medical image retrieval (BMIR) processing in a mobile wireless network environment. Four steps are incorporated in our BMIR algorithm. First, when a number of retrieval requests (i.e., m retrieval images and m radii) are simultaneously submitted by users, then a cost-based dynamic retrieval ( CDRS ) scheduling procedure is invoked to efficiently and effectively identify the correlation among the retrieval spheres (requests) based on a cost model. Next, an index-based image set reduction ( ISR ) is performed at the execution-node level in parallel. Then, a refinement processing of the candidate images is conducted to get the answers. Finally, at the transmission-node level, the corresponding image fragment (IF) replicas are chosen based on an adaptive multi-resolution ( AMR )-based IF replicas selection scheme, and transmitted to the user-node level by a priority-based IF replicas transmission ( PIFT ) scheme. The experimental results validate the efficiency and effectiveness of the algorithm in minimizing the response time and increasing the parallelism of I/O and CPU.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2037984112",
    "type": "article"
  },
  {
    "title": "Net Neutrality",
    "doi": "https://doi.org/10.1145/2700055",
    "publication_date": "2015-03-12",
    "publication_year": 2015,
    "authors": "Alissa Cooper; Ian Brown",
    "corresponding_authors": "",
    "abstract": "We analyze UK and US experiences as they relate to two central net neutrality questions: (1) whether competition serves as a deterrent to the discriminatory treatment of Internet traffic, and (2) whether discrimination creates barriers to application development and innovation. Relying on consumer switching behavior to provide more comprehensive competitive discipline was insufficient for a variety of reasons, including the presence of switching costs. The process of correcting errors in the technology used for application-specific management revealed that such management creates costs for application developers and innovators, regardless of whether their products are targeted for traffic management.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2076241708",
    "type": "article"
  },
  {
    "title": "Economic Viability of Paris Metro Pricing for Digital Services",
    "doi": "https://doi.org/10.1145/2663492",
    "publication_date": "2014-10-28",
    "publication_year": 2014,
    "authors": "Chi-Kin Chau; Qian Wang; Dah Ming Chiu",
    "corresponding_authors": "",
    "abstract": "Nowadays digital services, such as cloud computing and network access services, allow dynamic resource allocation and virtual resource isolation. This trend can create a new paradigm of flexible pricing schemes. A simple pricing scheme is to allocate multiple isolated service classes with differentiated prices, namely Paris Metro Pricing (PMP). The benefits of PMP are its simplicity and applicability to a wide variety of general digital services, without considering specific performance guarantees for different service classes. The central issue of our study is whether PMP is economically viable, namely whether it will produce more profit for the service provider and whether it will achieve more social welfare. Prior studies had only considered specific models and arrived at conflicting conclusions. In this article, we identify unifying principles in a general setting and derive general sufficient conditions that can guarantee the viability of PMP. We further apply the results to analyze various examples of digital services.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W3122412254",
    "type": "article"
  },
  {
    "title": "Masquerade: Verifiable Multi-Party Aggregation with Secure Multiplicative Commitments",
    "doi": "https://doi.org/10.1145/3705315",
    "publication_date": "2024-11-21",
    "publication_year": 2024,
    "authors": "Dimitris Mouris; Nektarios Georgios Tsoutsos",
    "corresponding_authors": "",
    "abstract": "In crowd-sourced data aggregation over the Internet, participants share their data points with curators. However, a lack of strong privacy guarantees may discourage participation, which motivates the need for privacy-preserving aggregation protocols. Moreover, existing solutions remain limited with respect to public auditing without revealing the participants’ data. In realistic applications, however, there is an increasing need for public verifiability (i.e., verifying the protocol correctness) while preserving the privacy of the participants’ inputs, since the participants do not always trust the data curators. At the same time, while publicly distributed ledgers may provide public auditing, these schemes are not designed to protect sensitive information. In this work, we introduce two protocols, dubbed Masquerade and zk-Masquerade, for computing private statistics, such as sum, average, and histograms, without revealing anything about participants’ data. We propose a tailored multiplicative commitment scheme to ensure the integrity of data aggregations and publish all the participants’ commitments on a ledger to provide public verifiability. zk-Masquerade detects malicious participants who attempt to poison the aggregation results by adopting two zero-knowledge proof protocols that ensure the validity of shared data points before being aggregated and enable a broad range of numerical and categorical studies. In our experiments, we use homomorphic ciphertexts and commitments for a variable number of participants and evaluate the runtime and the communication cost of our protocols.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W3205484337",
    "type": "article"
  },
  {
    "title": "Open Set Dandelion Network for IoT Intrusion Detection",
    "doi": "https://doi.org/10.1145/3639822",
    "publication_date": "2024-01-09",
    "publication_year": 2024,
    "authors": "Jiashu Wu; Hao Dai; Kenneth B. Kent; Jerome Yen; Chengzhong Xu; Yang Wang",
    "corresponding_authors": "",
    "abstract": "As Internet of Things devices become widely used in the real-world, it is crucial to protect them from malicious intrusions. However, the data scarcity of IoT limits the applicability of traditional intrusion detection methods, which are highly data-dependent. To address this, in this article, we propose the Open-Set Dandelion Network (OSDN) based on unsupervised heterogeneous domain adaptation in an open-set manner. The OSDN model performs intrusion knowledge transfer from the knowledge-rich source network intrusion domain to facilitate more accurate intrusion detection for the data-scarce target IoT intrusion domain. Under the open-set setting, it can also detect newly-emerged target domain intrusions that are not observed in the source domain. To achieve this, the OSDN model forms the source domain into a dandelion-like feature space in which each intrusion category is compactly grouped and different intrusion categories are separated, i.e., simultaneously emphasising inter-category separability and intra-category compactness. The dandelion-based target membership mechanism then forms the target dandelion. Then, the dandelion angular separation mechanism achieves better inter-category separability, and the dandelion embedding alignment mechanism further aligns both dandelions in a finer manner. To promote intra-category compactness, the discriminating sampled dandelion mechanism is used. Assisted by the intrusion classifier trained using both known and generated unknown intrusion knowledge, a semantic dandelion correction mechanism emphasises easily-confused categories and guides better inter-category separability. Holistically, these mechanisms form the OSDN model that effectively performs intrusion knowledge transfer to benefit IoT intrusion detection. Comprehensive experiments on several intrusion datasets verify the effectiveness of the OSDN model, outperforming three state-of-the-art baseline methods by 16.9%. The contribution of each OSDN constituting component, the stability and the efficiency of the OSDN model are also verified.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4390729825",
    "type": "article"
  },
  {
    "title": "Market Manipulation of Cryptocurrencies: Evidence from Social Media and Transaction Data",
    "doi": "https://doi.org/10.1145/3643812",
    "publication_date": "2024-01-30",
    "publication_year": 2024,
    "authors": "W D Li; Lingfeng Bao; Jiachi Chen; John Grundy; Xin Xia; Xiaohu Yang",
    "corresponding_authors": "",
    "abstract": "The cryptocurrency market cap has experienced a great increase in recent years. However, large price fluctuations demonstrate the need for governance structures and identify whether there are market manipulations. In this article, we conduct three analyses—social media data analysis, blockchain data analysis, and price bubble analysis—to investigate whether market manipulation exists on Bitcoin, Ethereum, and Dogecoin platforms. Social media data analysis aims to find the reasons for price fluctuations. Blockchain data analysis is used to find detailed behavior of the manipulators. Price bubble analysis is used to investigate the relation between price fluctuation and manipulators’ behavior. By using the three analyses, we show that market manipulation exists on Bitcoin, Ethereum, and Dogecoin. However, market manipulation of Bitcoin is limited, and for most of Bitcoin’s price fluctuations, we found other explanations. The price for Ethereum is the most sensitive to technical updates. Technical companies/teams usually hype some new concepts (e.g., ICO, DeFi), which causes a price spike. The price of Dogecoin has a high correlation with Elon Musk’s X (formerly known as Twitter) activity, showing that influential individuals have the ability to manipulate its prices. In addition, the poor monetary liquidity of Dogecoin allows some users to manipulate its price.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4391350320",
    "type": "article"
  },
  {
    "title": "Efficient Vertical Federated Unlearning via Fast Retraining",
    "doi": "https://doi.org/10.1145/3657290",
    "publication_date": "2024-04-10",
    "publication_year": 2024,
    "authors": "Zichen Wang; Xiangshan Gao; Cong Wang; Peng Cheng; Jiming Chen",
    "corresponding_authors": "",
    "abstract": "Vertical federated learning (VFL) revolutionizes privacy-preserved collaboration for small businesses that have distinct but complementary feature sets. However, as the scope of VFL expands, the constant entering and leaving of participants and the subsequent exercise of the “right to be forgotten” pose a great challenge in practice. The question of how to efficiently erase one’s contribution from the shared model remains largely unexplored in the context of VFL. In this article, we introduce a vertical federated unlearning framework, which integrates model checkpointing techniques with a hybrid, first-order optimization technique. The core concept is to reduce backpropagation time and improve convergence/generalization by combining the advantages of the existing optimizers. We provide in-depth theoretical analysis and time complexity to illustrate the effectiveness of the proposed design. We conduct extensive experiments on six public datasets and demonstrate that our method could achieve up to 6.3× speedup compared to the baseline, with negligible influence on the original learning task.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4394691969",
    "type": "article"
  },
  {
    "title": "Towards a Sustainable Blockchain: A Peer-to-Peer Federated Learning based Approach",
    "doi": "https://doi.org/10.1145/3680544",
    "publication_date": "2024-07-24",
    "publication_year": 2024,
    "authors": "Vidushi Agarwal; Shruti Mishra; Sujata Pal",
    "corresponding_authors": "",
    "abstract": "In the rapidly evolving digital world, blockchain technology is becoming the foundation for numerous applications, ranging from financial services to supply chain management. As the usage of blockchain is becoming more prevalent, the energy-intensive nature of this technology has raised concerns about its long-term sustainability and environmental footprint. To address this challenge, we explore the potential of Peer-to-Peer Federated Learning (P2P-FL), a distributed machine learning approach that allows multiple nodes to collaborate without sharing raw data. We present a novel integration of P2P-FL with blockchain technology, aimed at enhancing the sustainability and efficiency of blockchain networks. The basic idea of our approach is the use of distributed learning mechanisms to find the optimal performance parameters of blockchain without relying on centralized control. These parameters are then used by a load-balancing mechanism that prioritizes energy efficiency to distribute loads on different blockchains. Furthermore, we formulate a non-cooperative game theory model to align the individual node strategies with the collective objective of energy optimization, ensuring a balance between self-interest and overall network performance. Our work is exemplified through a case study in the renewable energy sector, demonstrating the application of our model in creating an efficient marketplace for energy trading. The experimentation and results indicate a significant improvement in the execution times and energy consumption of blockchain networks. Therefore, the overall sustainability of the network is enhanced, making our framework practical and applicable in real-world scenarios.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4400955397",
    "type": "article"
  },
  {
    "title": "Federated In-Network Machine Learning for Privacy-Preserving IoT Traffic Analysis",
    "doi": "https://doi.org/10.1145/3696354",
    "publication_date": "2024-09-26",
    "publication_year": 2024,
    "authors": "Mingyuan Zang; Changgang Zheng; Tomasz Koziak; Noa Zilberman; Lars Dittmann",
    "corresponding_authors": "",
    "abstract": "The expanding use of Internet-of-Things (IoT) has driven machine learning (ML)-based traffic analysis. 5G networks' standards, requiring low-latency communications for time-critical services, pose new challenges to traffic analysis. They necessitate fast analysis and response, preventing service disruption or security impact on network infrastructure. Distributed intelligence on IoT edge has been studied to analyze traffic, but introduces delays and raises privacy concerns. Federated learning can address privacy concerns, but does not meet latency requirements. In this article, we propose FLIP4: an efficient federated learning-based framework for in-network traffic analysis. Our solution introduces a lightweight federated tree-based model, offloaded and running within network devices. FLIP4 consumes less resources than previous solutions and reduces communication overheads, making it well-suited for IoT edge traffic analysis. It ensures prompt mitigation and minimal impact on services in the presence of false alerts using two approaches (metering and dropping), thereby balancing learning accuracy and privacy requirements.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4402870475",
    "type": "article"
  },
  {
    "title": "The architecture of robust publishing systems",
    "doi": "https://doi.org/10.1145/502152.502154",
    "publication_date": "2001-11-01",
    "publication_year": 2001,
    "authors": "Marc Waldman; Aviel D. Rubin; Lorrie Faith Cranor",
    "corresponding_authors": "",
    "abstract": "The Internet in its present form does not protect content from censorship. It is straightforward to trace any document back to a specific Web server, and usually directly to an individual. As we discuss below, there are valid reasons for publishing a document in a censorship-resistant manner. Unfortunately, few tools exist that facilitate this form of publishing. We describe the architecture of robust systems for publishing content on the Web. The discussion is in the context of Publius, as that system meets the most design goals of currently deployed systems. Publius has the property that it is very difficult for any adversary to censor or modify the content. In addition, the identity of the publisher is protected once the content is posted. The system differs from others in that tools are provided for updating or deleting published content, and users can browse the content in the normal point-and-click manner using a standard Web browser and a client-side proxy.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W1984504064",
    "type": "article"
  },
  {
    "title": "A compressor for effective archiving, retrieval, and updating of XML documents",
    "doi": "https://doi.org/10.1145/1151087.1151088",
    "publication_date": "2006-08-01",
    "publication_year": 2006,
    "authors": "Jun‐Ki Min; Myung-Jae Park; Chin‐Wan Chung",
    "corresponding_authors": "",
    "abstract": "Like HTML, many XML documents are resident on native file systems. Since XML data is irregular and verbose, the disk space and the network bandwidth are wasted. To overcome the verbosity problem, research on compressors for XML data has been conducted. Some XML compressors do not support querying compressed data, while other XML compressors which support querying compressed data blindly encode tags and data values using predefined encoding methods. Existing XML compressors do not provide the facility for updates on compressed XML data.In this article, we propose XPRESS, an XML compressor which supports direct updates and efficient evaluations of queries on compressed XML data. XPRESS adopts a novel encoding method called reverse arithmetic encoding , which encodes label paths of XML data and applies diverse encoding methods depending on the types of data values. Experimental results with real-life data sets show that XPRESS achieves significant improvements on query performance for compressed XML data and reasonable compression ratios. On average, the query performance of XPRESS is 2.13 times better than that of an existing XML compressor, and the compression ratio of XPRESS is about 71%. Additionally, we demonstrate the efficiency of the updates performed directly on compressed XML data.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W1991707383",
    "type": "article"
  },
  {
    "title": "Fast XML document filtering by sequencing twig patterns",
    "doi": "https://doi.org/10.1145/1592446.1592447",
    "publication_date": "2009-09-01",
    "publication_year": 2009,
    "authors": "Joonho Kwon; Praveen Rao; Bongki Moon; Sukho Lee",
    "corresponding_authors": "",
    "abstract": "XML-enabled publish-subscribe (pub-sub) systems have emerged as an increasingly important tool for e-commerce and Internet applications. In a typical pub-sub system, subscribed users specify their interests in a profile expressed in the XPath language. Each new data content is then matched against the user profiles so that the content is delivered only to the interested subscribers. As the number of subscribed users and their profiles can grow very large, the scalability of the service is critical to the success of pub-sub systems. In this article, we propose a novel scalable filtering system called iFiST that transforms user profiles of a twig pattern expressed in XPath into sequences using the Prüfer's method. Consequently, instead of breaking a twig pattern into multiple linear paths and matching them separately, FiST performs holistic matching of twig patterns with each incoming document in a bottom-up fashion. FiST organizes the sequences into a dynamic hash-based index for efficient filtering, and exploits the commonality among user profiles to enable shared processing during the filtering phase. We demonstrate that the holistic matching approach reduces filtering cost and memory consumption, thereby improving the scalability of FiST.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2127703157",
    "type": "article"
  },
  {
    "title": "An Autonomic Cognitive Pattern for Smart IoT-Based System Manageability",
    "doi": "https://doi.org/10.1145/3166070",
    "publication_date": "2018-11-30",
    "publication_year": 2018,
    "authors": "Emna Mezghani; Ernesto Expósito; Khalil Drira",
    "corresponding_authors": "",
    "abstract": "The adoption of the Internet of Things (IoT) drastically witnesses an increase in different domains and contributes to the fast digitalization of the universe. Henceforth, next generation of IoT-based systems are set to become more complex to design and manage. Collecting real-time IoT-generated data unleashes a new wave of opportunities for business to take more precise and accurate decisions at the right time. However, a set of challenges, including the design complexity of IoT-based systems and the management of the ensuing heterogeneous big data as well as the system scalability, need to be addressed for the development of flexible smart IoT-based systems. Consequently, we proposed a set of design patterns that diminish the system design complexity through selecting the appropriate combination of patterns based on the system requirements. These patterns identify four maturity levels for the design and development of smart IoT-based systems. In this article, we are mainly dealing with the system design complexity to manage the context changeability at runtime. Thus, we delineate the autonomic cognitive management pattern, which is at the most mature level. Based on the autonomic computing, this pattern identifies a combination of management processes able to continuously detect and manage the context changes. These processes are coordinated based on cognitive mechanisms that allow the system perceiving and understanding the meaning of the received data to make business decisions, as well as dynamically discovering new processes that meet the requirements evolution at runtime. We demonstrated the use of the proposed pattern with a use case from the healthcare domain; more precisely, the patient comorbidity management based on wearables.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2771744075",
    "type": "article"
  },
  {
    "title": "Exploiting Service Usage Information for Optimizing Server Resource Management",
    "doi": "https://doi.org/10.1145/1993083.1993084",
    "publication_date": "2011-07-01",
    "publication_year": 2011,
    "authors": "Alexander Totok; Vijay Karamcheti",
    "corresponding_authors": "",
    "abstract": "It is often difficult to tune the performance of modern component-based Internet services because: (1) component middleware are complex software systems that expose several independently tuned server resource management mechanisms; (2) session-oriented client behavior with complex data access patterns makes it hard to predict what impact tuning these mechanisms has on application behavior; and (3) component-based Internet services themselves exhibit complex structural organization with requests of different types having widely ranging execution complexity. In this article we show that exposing and using detailed information about how clients use Internet services enables mechanisms that achieve two interconnected goals: (1) providing improved QoS to the service clients, and (2) optimizing server resource utilization. To differentiate among levels of service usage (service access) information, we introduce the notion of the service access attribute and identify four related groups of service access attributes, encompassing different aspects of service usage information, ranging from the high-level structure of client web sessions to low-level fine-grained information about utilization of server resources by different requests. To show how the identified service usage information can be collected, we implement a request profiling infrastructure in the JBoss Java application server. In the context of four representative service management problems, we show how collected service usage information is used to improve service performance, optimize server resource utilization, or to achieve other problem-specific service management goals.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2005320886",
    "type": "article"
  },
  {
    "title": "Cyber-Physical Social Networks",
    "doi": "https://doi.org/10.1145/2996186",
    "publication_date": "2017-03-24",
    "publication_year": 2017,
    "authors": "Christian von der Weth; Ashraf Abdul; Mohan Kankanhalli",
    "corresponding_authors": "",
    "abstract": "In the offline world, getting to know new people is heavily influenced by people’s physical context, that is, their current geolocation. People meet in classes, bars, clubs, public transport, and so on. In contrast, first-generation online social networks such as Facebook or Google+ do not consider users’ context and thus mainly reflect real-world relationships (e.g., family, friends, colleagues). Location-based social networks, or second-generation social networks, such as Foursquare or Facebook Places, take the physical location of users into account to find new friends. However, with the increasing number and wide range of popular platforms and services on the Web, people spend a considerable time moving through the online worlds. In this article, we introduce cyber-physical social networks (CPSN) as the third generation of online social networks. Beside their physical locations, CPSN consider also users’ virtual locations for connecting to new friends. In a nutshell, we regard a web page as a place where people can meet and interact. The intuition is that a web page is a good indicator for a user’s current interest, likings, or information needs. Moreover, we link virtual and physical locations, allowing for users to socialize across the online and offline world. Our main contributions focus on the two fundamental tasks of creating meaningful virtual locations as well as creating meaningful links between virtual and physical locations, where “meaningful” depends on the application scenario. To this end, we present OneSpace, our prototypical implementation of a cyber-physical social network. OneSpace provides a live and social recommendation service for touristic venues (e.g., hotels, restaurants, attractions). It allows mobile users close to a venue and web users browsing online content about the venue to connect and interact in an ad hoc manner. Connecting users based on their shared virtual and physical locations gives way to a plethora of novel use cases for social computing, as we will illustrate. We evaluate our proposed methods for constructing and linking locations and present the results of a first user study investigating the potential impact of cyber-physical social networks.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2601933405",
    "type": "article"
  },
  {
    "title": "Utility-Based Decision Making for Migrating Cloud-Based Applications",
    "doi": "https://doi.org/10.1145/3140545",
    "publication_date": "2018-02-02",
    "publication_year": 2018,
    "authors": "Santiago Gómez Sáez; Vasilios Andrikopoulos; Marina Bitsaki; Frank Leymann; André van Hoorn",
    "corresponding_authors": "",
    "abstract": "Nowadays, cloud providers offer a broad catalog of services for migrating and distributing applications in the cloud. However, the existence of a wide spectrum of cloud services has become a challenge for deciding where to host applications, as these vary in performance and cost. This work addresses such a challenge, and provides a utility-based decision support model and method that evaluates and ranks during design time potential application distributions spanned among heterogeneous cloud services. The utility model is evaluated using the MediaWiki (Wikipedia) application, and shows an improved efficiency for selecting cloud services in comparison to other decision making approaches.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2786925899",
    "type": "article"
  },
  {
    "title": "Toward Efficient Short-Video Sharing in the YouTube Social Network",
    "doi": "https://doi.org/10.1145/3137569",
    "publication_date": "2018-03-06",
    "publication_year": 2018,
    "authors": "Haiying Shen; Harrison Chandler; Haoyu Wang",
    "corresponding_authors": "",
    "abstract": "The past few years have seen an explosion in the popularity of online short-video sharing in YouTube. As the number of users continue to grow, the bandwidth required to maintain acceptable quality of service (QoS) has greatly increased. Peer-to-peer (P2P) architectures have shown promise in reducing the bandwidth costs; however, the previous works build one P2P overlay for each video, which provides limited availability of video providers and produces high overlay maintenance overhead. To handle these problems, in this work, we novelly leverage the existing social network in YouTube, where a user subscribes to another user’s channel to track all his/her uploaded videos. The subscribers of a channel tend to watch the channel’s videos and common-interest nodes tend to watch the same videos. Also, the popularity of videos in one channel varies greatly. We study real trace data to confirm these properties. Based on these properties, we propose SocialTube, which builds the subscribers of one channel into a P2P overlay and also clusters common-interest nodes in a higher level. It also incorporates a prefetching algorithm that prefetches higher-popularity videos. To enhance the system performance, we further propose the demand/supply-based cache management scheme and reputation-based neighbor management scheme. Extensive trace-driven simulation results and PlanetLab real-world experimental results verify the effectiveness of SocialTube at reducing server load and overlay maintenance overhead and at improving QoS for users.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2789673046",
    "type": "article"
  },
  {
    "title": "Measuring Moral Acceptability in E-deliberation",
    "doi": "https://doi.org/10.1145/3183324",
    "publication_date": "2018-04-24",
    "publication_year": 2018,
    "authors": "Ilse Verdiesen; Virginia Dignum; Jeroen van den Hoven",
    "corresponding_authors": "",
    "abstract": "Current developments in governance and policy setting are challenging traditional top-down models of decision-making. Whereas, on the one hand, citizens are increasingly demanding and expected to participate directly on governance questions, social networking platforms are, on the other hand, increasingly providing podia for the spread of unfounded, extremist and/or harmful ideas. Participatory deliberation is a form of democratic policy making in which deliberation is central to decision-making using both consensus decision-making and majority rule. However, by definition, it will lead to socially accepted results rather than ensuring the moral acceptability of the result. In fact, participation per se offers no guidance regarding the ethics of the decisions taken, nor does it provide means to evaluate alternatives in terms of their moral “quality.” This article proposes an open participatory model, Massive Open Online Deliberation (MOOD), that can be used to solve some of the current policy authority deficits. MOOD taps on individual understanding and opinions by harnessing open, participatory, crowd-sourced, and wiki-like methodologies, effectively producing collective judgements regarding complex political and social issues in real time. MOOD offers the opportunity for people to develop and draft collective judgements on complex issues and crises in real time. MOOD is based on the concept of Ethics by Participation , a formalized and guided process of moral deliberation that extends deliberative democracy platforms to identify morally acceptable outcomes and enhance critical thinking and reflection among participants.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2799688552",
    "type": "article"
  },
  {
    "title": "On the Assessment of Systematic Risk in Networked Systems",
    "doi": "https://doi.org/10.1145/3166069",
    "publication_date": "2018-08-07",
    "publication_year": 2018,
    "authors": "Áron Lászka; Benjamin Johnson; Jens Großklags",
    "corresponding_authors": "",
    "abstract": "In a networked system, the risk of security compromises depends not only on each node’s security but also on the topological structure formed by the connected individuals, businesses, and computer systems. Research in network security has been exploring this phenomenon for a long time, with a variety of modeling frameworks predicting how many nodes we should expect to lose, on average, for a given network topology, after certain types of incidents. Meanwhile, the pricing of insurance contracts for risks related to information technology (better known as cyber-insurance) requires determining additional information, for example, the maximum number of nodes we should expect to lose within a 99.5% confidence interval. Previous modeling research in network security has not addressed these types of questions, while research on cyber-insurance pricing for networked systems has not taken into account the network’s topology. Our goal is to bridge that gap, by providing a mathematical basis for the assessment of systematic risk in networked systems. We define a loss-number distribution to be a probability distribution on the total number of compromised nodes within a network following the occurrence of a given incident, and we provide a number of modeling results that aim to be useful for cyber-insurers in this context. We prove NP-hardness for the general case of computing the loss-number distribution for an arbitrary network topology but obtain simplified computable formulas for the special cases of star topologies, ER-random topologies, and uniform topologies. We also provide a simulation algorithm that approximates the loss-number distribution for an arbitrary network topology and that appears to converge efficiently for many common classes of topologies. Scale-free network topologies have a degree distribution that follows a power law and are commonly found in real-world networks. We provide an example of a scale-free network in which a cyber-insurance pricing mechanism that relies naively on incidence reporting data will fail to accurately predict the true risk level of the entire system. We offer an alternative mechanism that yields an accurate forecast by taking into account the network topology, thus highlighting the lack/importance of topological data in security incident reporting. Our results constitute important steps toward the understanding of systematic risk and help to contribute to the emergence of a viable cyber-insurance market.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2887913328",
    "type": "article"
  },
  {
    "title": "Multi-objective Optimisation of Online Distributed Software Update for DevOps in Clouds",
    "doi": "https://doi.org/10.1145/3338851",
    "publication_date": "2019-08-27",
    "publication_year": 2019,
    "authors": "Daniel Sun; Shiping Chen; Guoqiang Li; Yuanyuan Zhang; Muhammad Atif",
    "corresponding_authors": "",
    "abstract": "This article studies synchronous online distributed software update, also known as rolling upgrade in DevOps, which in clouds upgrades software versions in virtual machine instances even when various failures may occur. The goal is to minimise completion time, availability degradation, and monetary cost for entire rolling upgrade by selecting proper parameters. For this goal, we propose a stochastic model and a novel optimisation method. We validate our approach to minimise the objectives through both experiments in Amazon Web Service (AWS) and simulations.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2970919627",
    "type": "article"
  },
  {
    "title": "Betweenness Centrality Based Software Defined Routing",
    "doi": "https://doi.org/10.1145/3355605",
    "publication_date": "2019-11-01",
    "publication_year": 2019,
    "authors": "Kai Wang; Wei Quan; Nan Cheng; Mingyuan Liu; Yu Liu; H. Anthony Chan",
    "corresponding_authors": "",
    "abstract": "Software-defined networking (SDN) enables routing control to program in the logically centralized controllers. It is expected to improve the routing efficiency even in highly dynamic situations. In this article, we make an in-depth observation of practical Internet datasets and investigate the relationship between betweenness centrality and network throughput . Furthermore, we propose a new routing observation factor, differential ratio of betweenness centrality (DRBC), to denote the varying amplitude of betweenness centrality to node degree. We reveal an interesting phenomenon that DRBC is proportional to the routing efficiency when the maximum betweenness centrality varies in a small range. Based on this, a DRBC-based routing scheme is proposed to improve routing efficiency. The experimental results verify that DRBC-based routing can improve the network throughput and accelerate the routing optimization.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2988292575",
    "type": "article"
  },
  {
    "title": "Semi-Direct Monocular Visual-Inertial Odometry Using Point and Line Features for IoV",
    "doi": "https://doi.org/10.1145/3432248",
    "publication_date": "2021-09-28",
    "publication_year": 2021,
    "authors": "Nan Jiang; De-Bin Huang; Jing Chen; Jie Wen; Heng Zhang; Honglong Chen",
    "corresponding_authors": "",
    "abstract": "The precise measuring of vehicle location has been a critical task in enhancing the autonomous driving in terms of intelligent decision making and safe transportation. Internet of Vehicles ( IoV ) is an important infrastructure in support of autonomous driving, allowing real-time road information exchanging and sharing for localizing vehicles. Global positioning System ( GPS ) is widely used in the traditional IoV system. GPS is unable to meet the key application requirements of autonomous driving due to meter level error and signal deterioration. In this article, we propose a novel solution, named Semi-Direct Monocular Visual-Inertial Odometry using Point and Line Features ( SDMPL-VIO ) for precise vehicle localization. Our SDMPL-VIO model takes advantage of a low-cost Inertial Measurement Unit ( IMU ) and monocular camera, using them as the sensor to acquire the surrounding environmental information. Visual-Inertial Odometry ( VIO ), taking into account both point and line features, is proposed, which is able to deal with both weak texture and dynamic environment. We use a semi-direct method to deal with keyframes and non-keyframes, respectively. Dual sliding window mechanisms can effectively fuse point-line and IMU information. To evaluate our SDMPL-VIO system model, we conduct extensive experiments on both an indoor dataset (i.e., EuRoC) and an outdoor dataset (i.e., KITTI) from the real-world applications, respectively. The experimental results show that the accuracy of SDMPL-VIO proposed by us is better than the mainstream VIO system at present. Especially in the weak texture of the datasets, fast-moving datasets, and other challenging datasets, SDMPL-VIO has a relatively high robustness.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W3204898179",
    "type": "article"
  },
  {
    "title": "Transfer Learning-powered Resource Optimization for Green Computing in 5G-Aided Industrial Internet of Things",
    "doi": "https://doi.org/10.1145/3434774",
    "publication_date": "2021-10-22",
    "publication_year": 2021,
    "authors": "Zhihan Lv; Ranran Lou; Amit K. Singh; Qingjun Wang",
    "corresponding_authors": "",
    "abstract": "Objective: Green computing meets the needs of a low-carbon society and it is an important aspect of promoting social sustainable development and technological progress. In the investigation, green computing for resource management and allocation issues is only discussed. Therefore, in the context of the 5G communication network, the investigation of the data classification and resource optimization of the Internet of Things are conducted. Method: The virtualization architecture of the heterogeneous wireless network resource based on 5G technology is designed. The related investigation is conducted based on 5G network and Internet of Things technology. Under the traditional method, the transfer learning is introduced to improve the AdaBoost (Adaptive Boosting) algorithm to classify the data. The investigated complete resource reuse method is used to optimize resources. A method that a sub-channel can be reused by a cellular link and any number of D2D links at the same time is proposed to conduct resource optimization investigation. Results: The investigation indicates that the classification accuracy of the algorithm is excellent for the data classification of the Internet of Things and has different advantages in various aspects compared with other algorithms. The designed algorithm can find a larger set of resource reuse and have a significant increase in spectrum utilization efficiency. Conclusion: The investigation can contribute to the boom in the Internet of Things in terms of data classification and resource optimization based on 5G.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W3208795336",
    "type": "article"
  },
  {
    "title": "A Taxonomy of Multimedia-based Graphical User Authentication for Green Internet of Things",
    "doi": "https://doi.org/10.1145/3433544",
    "publication_date": "2021-10-22",
    "publication_year": 2021,
    "authors": "Kamran Ahmad Awan; Ikram Ud Din; Abeer S. Almogren; Neeraj Kumar; Ahmad Almogren",
    "corresponding_authors": "",
    "abstract": "Authentication receives enormous consideration from the research community and is proven to be an interesting field in today’s era. User authentication is the major concern because people have their private data on devices. To strengthen user authentication, passwords have been introduced. In the past, the text-based password was the traditional way of authentication, but this method has particular shortcomings. The graphical password has been introduced as an alternative, which uses a picture or a set of pictures to generate a password. In the future, it is a requirement of such approaches to maintain robustness and consume fewer energy resources to become suitable for the Green Internet of Things (IoT). Similarly, diverse graphical password authentication mechanisms have been used to provide users with better security and usability. In this article, we conduct an extensive survey on the existing approaches of graphical password authentication to highlight the challenges required to be addressed for Green IoT. In comparison to other existing surveys, the objective is to consolidate the graphical password technique and to identify the problem associated with it. Besides, this survey will also identify the vulnerabilities of the graphical password against several potential attacks. We have also examined the strengths and weaknesses of each technique along with the future research directions. This study also evaluates the usability of each approach by considering learnability, memorability, and so forth and also presents a comparative analysis with security.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W3210025920",
    "type": "article"
  },
  {
    "title": "Using an Epidemiological Approach to Maximize Data Survival in the Internet of Things",
    "doi": "https://doi.org/10.1145/2812810",
    "publication_date": "2016-01-07",
    "publication_year": 2016,
    "authors": "Abdallah Makhoul; Christophe Guyeux; Mourad Hakem; Jacques M. Bahi",
    "corresponding_authors": "",
    "abstract": "The Internet of Things (IoT) has gained worldwide attention in recent years. It transforms the everyday objects that surround us into proactive actors of the Internet, generating and consuming information. An important issue related to the appearance of such a large-scale self-coordinating IoT is the reliability and the collaboration between the objects in the presence of environmental hazards. High failure rates lead to significant loss of data. Therefore, data survivability is a main challenge of the IoT. In this article, we have developed a compartmental e-Epidemic SIR (Susceptible-Infectious-Recovered) model to save the data in the network and let it survive after attacks. Furthermore, our model takes into account the dynamic topology of the network where natural death (crashing nodes) and birth are defined and analyzed. Theoretical methods and simulations are employed to solve and simulate the system of equations developed and to analyze the model.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2237766361",
    "type": "article"
  },
  {
    "title": "Improving Collaborative Filtering with Social Influence over Heterogeneous Information Networks",
    "doi": "https://doi.org/10.1145/3397505",
    "publication_date": "2020-10-15",
    "publication_year": 2020,
    "authors": "Yang Zhou; Ling Liu; Kisung Lee; Balaji Palanisamy; Qi Zhang",
    "corresponding_authors": "",
    "abstract": "The advent of social networks and activity networks affords us an opportunity of utilizing explicit social information and activity information to improve the quality of recommendation in the presence of data sparsity. In this article, we present a social-influence-based collaborative filtering (SICF) framework over heterogeneous information networks with three unique features. First, we integrate different types of entities, links, attributes, and activities from rating networks, social networks, and activity networks into a unified social-influence-based collaborative filtering model through the intra-network and inter-network social influence. Second, we propose three social-influence propagation models to capture three kinds of information propagation within heterogeneous information networks: user-based influence propagation on user rating networks, item-based influence propagation on user-rating activity networks, and term-based influence propagation on user-review activity networks, respectively. We compute three kinds of social-influence-based user similarity scores based on three social-influence propagation models, respectively. Third, a unified social-influence-based CF prediction model is proposed to infer rating tastes by incorporating three kinds of social-influence-based similarity measures with different weighting factors. We design a weight-learning algorithm, SICF, to refine the prediction result by quantifying the contribution of each kind of information propagation to make a good balance between prediction accuracy and data sparsity. Extensive evaluation on real datasets demonstrates that SICF outperforms existing representative collaborative filtering methods.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W3047958086",
    "type": "article"
  },
  {
    "title": "Improving Security of Internet of Vehicles Based on Post-quantum Signatures with Systolic Divisions",
    "doi": "https://doi.org/10.1145/3410445",
    "publication_date": "2022-02-03",
    "publication_year": 2022,
    "authors": "Haibo Yi; Ruinan Chi; Xin Huang; Xuejun Cai; Zhe Nie",
    "corresponding_authors": "",
    "abstract": "Internet of Things (IoT) techniques have been employed in many areas, e.g., vehicles, smart home, and medicine. Among the applications of IoTs, the Internet of Vehicles (IoV) is one of the most popular techniques. IoVs are protected by public key cryptographic systems, such as RSA and ECC. However, such systems are vulnerable to quantum computer attacks. Thus, we improve the security of IoV-based post-quantum signatures, which can resist quantum computer attacks. The key operations are divisions in a finite field. Hence, we improve the security of IoV-based post-quantum signatures with division by employing systolic architectures. We propose a systolic architecture for computing division in composite fields. After that, we improve the IoT security-based post-quantum signatures with systolic divisions. We test and verify our design on a Field-Programmable Gate Array (FPGA); the experimental results confirm our estimates. Furthermore, the optimized method proposed can be further applied to various applications like solving system of linear equations and cryptographic applications for IoT security.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W4210394607",
    "type": "article"
  },
  {
    "title": "Network Temperature: A Novel Statistical Index for Networks Measurement and Management",
    "doi": "https://doi.org/10.1145/3511093",
    "publication_date": "2022-02-01",
    "publication_year": 2022,
    "authors": "Changda Wang; Xiaowei Li; Elisa Bertino",
    "corresponding_authors": "",
    "abstract": "Being able to monitor each packet path is critical for effective measurement and management of networks. However, such detailed monitoring can be very expensive especially for large-scale networks. To address such problem, inspired by thermodynamics, which uses the statistical characteristics of a large number of molecules’ motion but not each molecule’s trajectory for analysis, we propose the new concept of network temperature together with the notions of network-specific heat and network temperature gradient . Our approach does not only provide a statistical view of the current network state consisting of all the active packet paths at each time instant, but can be used to represent transitions among network states. Our network temperature-based methods have a broad applicability, such as to DDoS detection, dynamic node importance ranking, network stability and robustness evaluation, reliable packets routing, provenance compression assessment, and so on. Numerical and/or the experimental results show that our methods are effective.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W4210520826",
    "type": "article"
  },
  {
    "title": "PoSSUM: An Entity-centric Publish/Subscribe System for Diverse Summarization in Internet of Things",
    "doi": "https://doi.org/10.1145/3507911",
    "publication_date": "2022-02-11",
    "publication_year": 2022,
    "authors": "Niki Pavlopoulou; Edward Curry",
    "corresponding_authors": "",
    "abstract": "Users are interested in entity information provided by multiple sensors in the Internet of Things. The challenges regarding this environment span from data-centric ones due to data integration, heterogeneity, and enrichment, to user-centric ones due to the need for high-level data interpretation and usability for non-expert users, to system-centric ones due to resource constraints. Publish/Subscribe systems (PSSs) are suitable schemes for large-scale applications, but they are limited in dealing with the data and user challenges. In this article, we propose PoSSUM, a novel entity-centric PSS that provides entity summaries for user-friendly subscriptions through data integration, a novel Density-Based VARiance Clustering (DBVARC) for diverse entity summarization that is parameter-free and partly incremental, reasoning rules, and a novel Triple2Rank scoring for top-k filtering based on importance, informativeness, and diversity. We introduce a novel evaluation methodology that creates ground truths and metrics that capture the quality of entity summaries. We compare our approach with a previous dynamic approach and a static diverse entity summarization approach that we adapted to dynamic environments. The evaluation results for two use cases, Healthcare and Smart Cities, show that when users are provided with less information, their data diversity desire could reach up to 80%. Summarization approaches achieve from 80% to 99% message reduction, with PoSSUM having the best-ranking quality for more than half of the entities by a significant margin. PoSSUM has the highest conceptual clustering F-score, ranging from 0.69 to 0.83, and a redundancy-aware F-score up to 0.95, with cases, where it is almost two times better than the other approaches. PoSSUM takes 50% or less clustering processing time and it performs scoring significantly faster for larger windows. It also has comparable end-to-end latency and throughput values, and it occupies a third of the memory compared to the second-best approach.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W4211089788",
    "type": "article"
  },
  {
    "title": "Governance of Autonomous Agents on the Web: Challenges and Opportunities",
    "doi": "https://doi.org/10.1145/3507910",
    "publication_date": "2022-02-03",
    "publication_year": 2022,
    "authors": "Timotheus Kampik; Adnane Mansour; Olivier Boissier; Sabrina Kirrane; Julián Padget; Terry R. Payne; Munindar P. Singh; Valentina Tamma; Antoine Zimmermann",
    "corresponding_authors": "",
    "abstract": "The study of autonomous agents has a long history in the Multiagent System and the Semantic Web communities, with applications ranging from automating business processes to personal assistants. More recently, the Web of Things (WoT), which is an extension of the Internet of Things (IoT) with metadata expressed in Web standards, and its community provide further motivation for pushing the autonomous agents research agenda forward. Although representing and reasoning about norms, policies, and preferences is crucial to ensuring that autonomous agents act in a manner that satisfies stakeholder requirements, normative concepts, policies, and preferences have yet to be considered as first-class abstractions in Web-based multiagent systems. Towards this end, this article motivates the need for alignment and joint research across the Multiagent Systems, Semantic Web, and WoT communities, introduces a conceptual framework for governance of autonomous agents on the Web, and identifies several research challenges and opportunities.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W4226106827",
    "type": "article"
  },
  {
    "title": "Facilitating Serverless Match-based Online Games with Novel Blockchain Technologies",
    "doi": "https://doi.org/10.1145/3565884",
    "publication_date": "2022-10-07",
    "publication_year": 2022,
    "authors": "Feijie Wu; Ho Yin Yuen; Henry C. B. Chan; Victor C. M. Leung; Wei Cai",
    "corresponding_authors": "",
    "abstract": "Applying peer-to-peer (P2P) architecture to online video games has already attracted both academic and industrial interests, since it removes the need for expensive server maintenance. However, there are two major issues preventing the use of a P2P architecture, namely how to provide an effective distributed data storage solution, and how to tackle potential cheating behaviors. Inspired by emerging blockchain techniques, we propose a novel consensus model called Proof-of-Play (PoP) to provide a decentralized data storage system that incorporates an anti-cheating mechanism for P2P games, by rewarding players that interact with the game as intended, along with consideration of security measures to address the Nothing-at-stake Problem and the Long-range Attack. To validate our design, we utilize a game-theory model to show that under certain assumptions, the integrity of the PoP system would not be undermined due to the best interests of any user. Then, as a proof-of-concept, we developed a P2P game ( Infinity Battle ) to demonstrate how a game can be integrated with PoP in practice. Finally, experiments were conducted to study PoP in comparison with Proof-of-Work (PoW) to show its advantages in various aspects.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W4303427402",
    "type": "article"
  },
  {
    "title": "DisguisedNets: Secure Image Outsourcing for Confidential Model Training in Clouds",
    "doi": "https://doi.org/10.1145/3609506",
    "publication_date": "2023-07-15",
    "publication_year": 2023,
    "authors": "Keke Chen; Yuechun Gu; Sagar Sharma",
    "corresponding_authors": "",
    "abstract": "Large training data and expensive model tweaking are standard features of deep learning with images. As a result, data owners often utilize cloud resources to develop large-scale complex models, which also raises privacy concerns. Existing cryptographic solutions for training deep neural networks (DNNs) are too expensive, cannot effectively utilize cloud GPU resources, and also put a significant burden on client-side pre-processing. This article presents an image disguising approach: DisguisedNets, which allows users to securely outsource images to the cloud and enables confidential, efficient GPU-based model training. DisguisedNets uses a novel combination of image blocktization, block-level random permutation, and block-level secure transformations: random multidimensional projection (RMT) or AES pixel-level encryption (AES) to transform training data. Users can use existing DNN training methods and GPU resources without any modification to training models with disguised images. We have analyzed and evaluated the methods under a multi-level threat model and compared them with another similar method—InstaHide. We also show that the image disguising approach, including both DisguisedNets and InstaHide, can effectively protect models from model-targeted attacks.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4384407428",
    "type": "article"
  },
  {
    "title": "Providing Realtime Support for Containerized Edge Services",
    "doi": "https://doi.org/10.1145/3617123",
    "publication_date": "2023-09-04",
    "publication_year": 2023,
    "authors": "Wenzhao Zhang; Yi Gao; Wei Dong",
    "corresponding_authors": "",
    "abstract": "Containers have emerged as a popular technology for edge computing platforms. Although there are varieties of container orchestration frameworks, e.g., Kubernetes to provide high-reliable services for cloud infrastructure, providing real-time support at the containerized edge systems (CESs) remains a challenge. In this paper, we propose EdgeMan , a holistic edge service management framework for CESs, which consists of (1) a model-assisted event-driven lightweight online scheduling algorithm to provide request-level execution plans; (2) a bottleneck-metric-aware progressive resource allocation mechanism to improve resource efficiency. We then build a testbed that installed three containerized services with different latency sensitivities for concrete evaluation. Additionally, we adopt real-world data traces from Alibaba and Twitter for large-scale emulations. Extensive experiments demonstrate that the deadline miss ratio of time-sensitive services run with EdgeMan is reduced by 85.9% on average compared with that of existing methods in both industry and academia.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4386421981",
    "type": "article"
  },
  {
    "title": "UNION: Fault-tolerant Cooperative Computing in Opportunistic Mobile Edge Cloud",
    "doi": "https://doi.org/10.1145/3617994",
    "publication_date": "2023-09-20",
    "publication_year": 2023,
    "authors": "Wenhua Xiao; Xudong Fang; Bixin Liu; Ji Wang; Xiaomin Zhu",
    "corresponding_authors": "",
    "abstract": "Opportunistic Mobile Edge Cloud in which opportunistically connected mobile devices run in a cooperative way to augment the capability of a single device has become a timely and essential topic due to its widespread prospect under resource-constrained scenarios (e.g., disaster rescue). Because of the mobility of devices and the uncertainty of environments, it is inevitable that failures occur among the mobile nodes. Being different from existing studies that mainly focus on either data offloading or computing offloading among mobile devices in an ideal environment, we concentrate on how to guarantee the reliability of the task execution with the consideration of both data offloading and computing offloading under opportunistically connected mobile edge cloud. To this end, an optimization of mobile task offloading when considering reliability is formulated. Then, we propose a probabilistic model for task offloading and a reliability model for task execution, which estimates the probability of successful execution for a specific opportunistic path and describes the dynamic reliability of the task execution. Based on these models, a heuristic algorithm UNION (Fa u lt-Tolera n t Cooperat i ve C o mputi n g) is proposed to solve this NP-hard problem. Theoretical analysis shows that the complexity of UNION is 𝒪(|ℐ| 2 +|𝒩|) with guaranteeing the reliability of 0.99. Also, extensive experiments on real-world traces validate the superiority of the proposed algorithm UNION over existing typical strategies.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4386889791",
    "type": "article"
  },
  {
    "title": "A stochastic model for the evolution of the Web allowing link deletion",
    "doi": "https://doi.org/10.1145/1149121.1149122",
    "publication_date": "2006-05-01",
    "publication_year": 2006,
    "authors": "Trevor Fenner; Mark Levene; George Loizou",
    "corresponding_authors": "",
    "abstract": "Recently several authors have proposed stochastic evolutionary models for the growth of the Web graph and other networks that give rise to power-law distributions. These models are based on the notion of preferential attachment, leading to the “rich get richer” phenomenon. We present a generalization of the basic model by allowing deletion of individual links and show that it also gives rise to a power-law distribution. We derive the mean-field equations for this stochastic model and show that, by examining a snapshot of the distribution at the steady state of the model, we are able to determine the extent to which link deletion has taken place and estimate the probability of deleting a link. Applying our model to actual Web graph data provides evidence of the extent to which link deletion has occurred. We also discuss a problem that frequently arises in estimating the power-law exponent from empirical data and a few possible methods for dealing with this, indicating our preferred approach. Using this approach our analysis of the data suggests a power-law exponent of approximately 2.15 for the distribution of inlinks in the Web graph, rather than the widely published value of 2.1.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2081272202",
    "type": "article"
  },
  {
    "title": "Impact of Internet-based distributed monitoring systems on offshore sourcing of services",
    "doi": "https://doi.org/10.1145/1275505.1275509",
    "publication_date": "2007-08-01",
    "publication_year": 2007,
    "authors": "Ravi Aron; Siddarth Jayanty; Praveen Pathak",
    "corresponding_authors": "",
    "abstract": "The use of Internet-based distributed monitoring systems has allowed firms to source services globally that were hitherto thought of as being too risky or complex to execute offshore. These systems enable buyers of such services (clients) to monitor the execution of processes in real-time and exert a degree of managerial control over information workers of another firm located in a distant region. Our research shows that process codifiability plays a key role in determining output quality. Further, we show that the efforts made by the client and the provider in monitoring work via Internet-based monitoring mechanisms have a significant impact on output quality. Finally, we show that these monitoring mechanisms enable clients and providers of services to focus on those processes that are best managed by each entity. This scheme of optimal allocation of monitoring effort is termed by us as the efficient monitoring frontier.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2017531135",
    "type": "article"
  },
  {
    "title": "ACCENT",
    "doi": "https://doi.org/10.1145/2049656.2049659",
    "publication_date": "2011-12-01",
    "publication_year": 2011,
    "authors": "Ki-Woong Park; Kyu Ho Park",
    "corresponding_authors": "",
    "abstract": "Emerging cloud services, including mobile offices, Web-based storage services, and content delivery services, run diverse workloads under various device platforms, networks, and cloud service providers. They have been realized on top of SSL/TLS, which is the de facto protocol for end-to-end secure communication over the Internet. In an attempt to achieve a cognitive SSL/TLS with heterogeneous environments (device, network, and cloud) and workload awareness, we thoroughly analyze SSL/TLS-based data communication and identify three critical mismatches in a conventional SSL/TLS-based data transmission. The first mismatch is the performance of loosely coupled encryption-compression and communication routines that lead to underutilized computation and communication resources. The second mismatch is that the conventional SSL/TLS only provides a static compression mode, irrespective of the dynamically changing status of each SSL/TLS connection and the computing power gap between the cloud service provider and diverse device platforms. The third is the memory allocation overhead due to frequent compression switching in the SSL/TLS. As a remedy to these rudimentary operations, we present a system called an Adaptive Cryptography Plugged Compression Network (ACCENT) for SSL/TLS-based cloud services. It is comprised of the following three novel mechanisms, each of which aims to provide an optimal SSL/TLS communication and maximize the network transfer performance of an SSL/TLS protocol stack: tightly-coupled threaded SSL/TLS coding, floating scale-based adaptive compression negotiation, and unified memory allocation for seamless compression switching. We implemented and tested the mechanisms in OpenSSL-1.0.0. ACCENT is integrated into the Web-interface layer and SSL/TLS-based secure storage service within a real cloud computing service, called iCubeCloud , as the key primitive for SSL/TLS-based data delivery over the Internet.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2143703674",
    "type": "article"
  },
  {
    "title": "Eliciting Structured Knowledge from Situated Crowd Markets",
    "doi": "https://doi.org/10.1145/3007900",
    "publication_date": "2017-03-27",
    "publication_year": 2017,
    "authors": "Jorge Gonçalves; Simo Hosio; Vassilis Kostakos",
    "corresponding_authors": "",
    "abstract": "We present a crowdsourcing methodology to elicit highly structured knowledge for arbitrary questions. The method elicits potential answers (“options”), criteria against which those options should be evaluated, and a ranking of the top “options.” Our study shows that situated crowdsourcing markets can reliably elicit/moderate knowledge to generate a ranking of options based on different criteria that correlate with established online platforms. Our evaluation also shows that local crowds can generate knowledge that is missing from online platforms and on how a local crowd perceives a certain issue. Finally, we discuss the benefits and challenges of eliciting structured knowledge from local crowds.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2579878149",
    "type": "article"
  },
  {
    "title": "A Universal Model for Discourse-Level Argumentation Analysis",
    "doi": "https://doi.org/10.1145/2957757",
    "publication_date": "2017-06-12",
    "publication_year": 2017,
    "authors": "Henning Wachsmuth; Benno Stein",
    "corresponding_authors": "",
    "abstract": "The argumentative structure of texts is increasingly exploited for analysis tasks, for example, for stance classification or the assessment of argumentation quality. Most existing approaches, however, model only the local structure of single arguments. This article considers the question of how to capture the global discourse-level structure of a text for argumentation-related analyses. In particular, we propose to model the global structure as a flow of “task-related rhetorical moves,” such as discourse functions or aspect-based sentiment. By comparing the flow of a text to a set of common flow patterns, we map the text into the feature space of global structures, thus capturing its discourse-level argumentation. We show how to identify different types of flow patterns, and we provide evidence that they generalize well across different domains of texts. In our evaluation for two analysis tasks, the classification of review sentiment and the scoring of essay organization, the features derived from flow patterns prove both effective and more robust than strong baselines. We conclude with a discussion of the universality of modeling flow for discourse-level argumentation analysis.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2625924563",
    "type": "article"
  },
  {
    "title": "Are We There Yet? IPv6 in Australia and China",
    "doi": "https://doi.org/10.1145/3158374",
    "publication_date": "2018-02-07",
    "publication_year": 2018,
    "authors": "Sebastian Zander; Xuequn Wang",
    "corresponding_authors": "",
    "abstract": "IP (Internet Protocol) version 6 (IPv6) was standardised in 1998 to address the expected runout of IP version 4 (IPv4) addresses. However, the transition from IPv4 to IPv6 has been very slow in many countries. We investigate the state of IPv6 deployment in Australian and Chinese organisations based on a survey of organisations’ IT staff. Compared to earlier studies, IPv6 deployment has advanced markedly, but it is still years away for a significant portion of organisations. We provide insights into the deployment problems, arguments for deploying IPv6, and how to speed up the transition, which are relevant for many countries.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2791057254",
    "type": "article"
  },
  {
    "title": "Cross-Browser Differences Detection Based on an Empirical Metric for Web Page Visual Similarity",
    "doi": "https://doi.org/10.1145/3140544",
    "publication_date": "2018-04-17",
    "publication_year": 2018,
    "authors": "Zhen Xu; James Miller",
    "corresponding_authors": "",
    "abstract": "This article aims to develop a method to detect visual differences introduced into web pages when they are rendered in different browsers. To achieve this goal, we propose an empirical visual similarity metric by mimicking human mechanisms of perception. The Gestalt laws of grouping are translated into a computer compatible rule set. A block tree is then parsed by the rules for similarity calculation. During the translation of the Gestalt laws, experiments are performed to obtain metrics for proximity, color similarity, and image similarity. After a validation experiment, the empirical metric is employed to detect cross-browser differences. Experiments and case studies on the world’s most popular web pages provide positive results for this methodology.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2803075657",
    "type": "article"
  },
  {
    "title": "Should Credit Card Issuers Reissue Cards in Response to a Data Breach?",
    "doi": "https://doi.org/10.1145/3122983",
    "publication_date": "2018-09-30",
    "publication_year": 2018,
    "authors": "James T. Graves; Alessandro Acquisti; Nicolas Christin",
    "corresponding_authors": "",
    "abstract": "When card data is exposed in a data breach but has not yet been used to attempt fraud, the overall social costs of that breach depend on whether the financial institutions that issued those cards immediately cancel them and issue new cards or instead wait until fraud is attempted. This article empirically investigates the social costs and benefits of those options. We use a parameterized model and Monte Carlo simulation to compare the cost of reissuing cards to the total expected cost of fraud if cards are not reissued. The ranges and distributions in our model are informed by publicly available information, from which we extrapolate estimates of the number of credit card records historically exposed in data breaches, the probability that a card exposed in a breach will be used for fraud, and the associated expected cost of existing-account credit card fraud. We find that automatically reissuing cards may have lower social costs than the costs of waiting until fraud is attempted, although the range of results is considerably broad.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2895278285",
    "type": "article"
  },
  {
    "title": "Constructing Novel Block Layouts for Webpage Analysis",
    "doi": "https://doi.org/10.1145/3326457",
    "publication_date": "2019-07-10",
    "publication_year": 2019,
    "authors": "Zexun Jiang; Hao Yin; Yulei Wu; Yongqiang Lyu; Geyong Min; Xu Zhang",
    "corresponding_authors": "",
    "abstract": "Webpage segmentation is the basic building block for a wide range of webpage analysis methods. The rapid development of Web technologies results in more dynamic and complex webpages, which bring new challenges to this area. To improve the performance of webpage segmentation, we propose a two-stage segmentation method that can combine visual, logic, and semantic features of the contents on a webpage. Specifically, we devise a new model to measure the similarities of the elements on webpages based on both visual layout and logic organization in the first stage, and we propose a novel block regrouping method using semantic statistics and visual positions in the second stage. This two-stage method can effectively conduct webpage segmentation on complicated and dynamic webpages. The performance and accuracy of the method are verified by comparing with two existing webpage segmentation methods. The experiment results show that the proposed method significantly outperforms the existing state of the art in terms of higher precision, recall, and accuracy.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2957505564",
    "type": "article"
  },
  {
    "title": "Adaptive Multi-Task Dual-Structured Learning with Its Application on Alzheimer’s Disease Study",
    "doi": "https://doi.org/10.1145/3398728",
    "publication_date": "2020-07-07",
    "publication_year": 2020,
    "authors": "Shijie Hao; Tao Chen; Yang Wang; Yanrong Guo; Meng Wang",
    "corresponding_authors": "",
    "abstract": "Multi-task learning has been widely applied to Alzheimer’s Disease (AD) studies due to its capability of simultaneously rating the disease severity (classification) and predicting corresponding clinical scores (regression). In this article, we propose a novel technique of Adaptive Multi-task Dual-Structured Learning, named AMDSL, by mutually exploring the dual manifold structure for the label and regression score of the disease data under joint classification and regression tasks, while learning an adaptive shared similarity measure and corresponding feature mapping among these two tasks. We encode both the reconstructed label representation and regression score adaptive to the ideal similarity measure on disease data to achieve the ideal performance on these two joint tasks. The alternating algorithm is proposed to optimize the above objective. We theoretically prove the convergence of the optimization algorithm. The superiority of AMDSL is experimentally validated under joint classification and regression as per various evaluation metrics against the most authoritative Alzheimer’s disease data.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W3042199522",
    "type": "article"
  },
  {
    "title": "SMig-RL",
    "doi": "https://doi.org/10.1145/3414840",
    "publication_date": "2020-10-06",
    "publication_year": 2020,
    "authors": "Hongshuai Ren; Yang Wang; Chengzhong Xu; Xi Chen",
    "corresponding_authors": "",
    "abstract": "Service migration is an often-used approach in cloud computing to minimize the access cost by moving the service close to most users. Although it is effective in a certain sense, the service migration in existing research still suffers from some deficiencies in its evolutionary abilities in scalability , sensitivity , and adaptability to effectively react to the dynamically changing environments. This article proposes an evolutionary framework based on deep reinforcement learning for virtual service migration in large-scale mobile cloud centers. To enhance the spatio-temporal sensitivity of the algorithm, we design a scalable reward function for virtual service migration, redefine the input state, and add a Recurrent Neural Network ( RNN ) to the learning framework. Additionally, in order to enhance the adaptability of the algorithm, we also decompose the action space and exploit the network cost to adjust the number of virtual machine (VMs). The experimental results show that, compared with the existing results, the migration strategy generated by the algorithm can not only significantly reduce the total service cost and achieve the load balancing at the same time, but also address the burst situations with low cost in dynamic environments.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W3092280114",
    "type": "article"
  },
  {
    "title": "Beyond Frequency",
    "doi": "https://doi.org/10.1145/3425498",
    "publication_date": "2021-01-05",
    "publication_year": 2021,
    "authors": "Wensheng Gan; Jerry Chun‐Wei Lin; Philippe Fournier‐Viger; Han‐Chieh Chao; Philip S. Yu",
    "corresponding_authors": "",
    "abstract": "Utility-oriented mining which integrates utility theory and data mining is a useful tool for understanding economic consumer behavior. Traditional algorithms for mining high-utility patterns (HUPs) applies a single/uniform minimum high-utility threshold (minutil) to obtain the set of HUPs, but in some real-life circumstances, some specific products may bring lower utilities compared with others, but their profit may offer some vital information. However, if minutil is set high, the patterns with low minutil are missed; if minutil is set low, the number of patterns becomes unmanageable. In this paper, an efficient one-phase utility-oriented pattern mining algorithm, called HIMU, is proposed for mining HUPs with varied item-specific minimum utility. A novel tree structure called a multiple item utility set-enumeration tree (MIU-tree), the global sorted and the conditional downward closure properties are introduced in HIMU. In addition, we extended the compact utility-list structure to keep the necessary information, and thus this one-phase HIMU model greatly reduces the computational costs and memory requirements. Moreover, two pruning strategies are then extended to enhance the performance. We conducted extensive experiments in several synthetic and real-world datasets; the results indicates that the designed one-phase HIMU algorithm can address the \"rare item problem\" and has better performance than the state-of-the-art algorithms in terms of runtime, memory usage, and scalability. Furthermore, the enhanced algorithms outperform the non-optimized HIMU approach.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W3120576909",
    "type": "article"
  },
  {
    "title": "A Polishing Robot Force Control System Based on Time Series Data in Industrial Internet of Things",
    "doi": "https://doi.org/10.1145/3419469",
    "publication_date": "2021-03-08",
    "publication_year": 2021,
    "authors": "Chen Zhang; Zhuo Tang; Kenli Li; Jianzhong Yang; Li Yang",
    "corresponding_authors": "",
    "abstract": "Installing a six-dimensional force/torque sensor on an industrial arm for force feedback is a common robotic force control strategy. However, because of the high price of force/torque sensors and the closedness of an industrial robot control system, this method is not convenient for industrial mass production applications. Various types of data generated by industrial robots during the polishing process can be saved, transmitted, and applied, benefiting from the growth of the industrial internet of things (IIoT). Therefore, we propose a constant force control system that combines an industrial robot control system and industrial robot offline programming software for a polishing robot based on IIoT time series data. The system mainly consists of four parts, which can achieve constant force polishing of industrial robots in mass production. (1) Data collection module. Install a six-dimensional force/torque sensor at a manipulator and collect the robot data (current series data, etc.) and sensor data (force/torque series data). (2) Data analysis module. Establish a relationship model based on variant long short-term memory which we propose between current time series data of the polishing manipulator and data of the force sensor. (3) Data prediction module. A large number of sensorless polishing robots of the same type can utilize that model to predict force time series. (4) Trajectory optimization module. The polishing trajectories can be adjusted according to the prediction sequences. The experiments verified that the relational model we proposed has an accurate prediction, small error, and a manipulator taking advantage of this method has a better polishing effect.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W3134387241",
    "type": "article"
  },
  {
    "title": "Chinese Emotional Dialogue Response Generation via Reinforcement Learning",
    "doi": "https://doi.org/10.1145/3446390",
    "publication_date": "2021-07-22",
    "publication_year": 2021,
    "authors": "Rushi Lan; Wang Jing; Wenming Huang; Zhenrong Deng; Xiyan Sun; Zhuo Chen; Xiaonan Luo",
    "corresponding_authors": "",
    "abstract": "In an open-domain dialogue system, recognition and expression of emotions are the key factors for success. Most of the existing research related to Chinese dialogue systems aims at improving the quality of content but ignores the expression of human emotions. In this article, we propose a Chinese emotional dialogue response generation algorithm based on reinforcement learning that can generate responses not only according to content but also according to emotion. In the proposed method, a multi-emotion classification model is first used to add emotion labels to the corpus of post-response pairs. Then, with the help of reinforcement learning, the reward function is constructed based on two aspects, namely, emotion and content. Among the generated candidates, the system selects the one with long-term success as the best reply. At the same time, to avoid safe responses and diversify dialogue, a diversity beam search algorithm is applied in the decoding process. The comparative experiments demonstrate that the proposed model achieves satisfactory results according to both automatic and human evaluations.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W3184197775",
    "type": "article"
  },
  {
    "title": "Automated Security Assessment Framework for Wearable BLE-enabled Health Monitoring Devices",
    "doi": "https://doi.org/10.1145/3448649",
    "publication_date": "2021-09-14",
    "publication_year": 2021,
    "authors": "Ghazale Amel Zendehdel; Ratinder Kaur; Inderpreet Chopra; Natalia Stakhanova; Erik Scheme",
    "corresponding_authors": "",
    "abstract": "The growth of IoT technology, increasing prevalence of embedded devices, and advancements in biomedical technology have led to the emergence of numerous wearable health monitoring devices (WHMDs) in clinical settings and in the community. The majority of these devices are Bluetooth Low Energy (BLE) enabled. Though the advantages offered by BLE-enabled WHMDs in tracking, diagnosing, and intervening with patients are substantial, the risk of cyberattacks on these devices is likely to increase with device complexity and new communication protocols. Furthermore, vendors face risk and financial tradeoffs between speed to market and ensuring device security in all situations. Previous research has explored the security and privacy of such devices by manually testing popular BLE-enabled WHMDs in the market and generally discussed categories of possible attacks, while mostly focused on IP devices. In this work, we propose a new semi-automated framework that can be used to identify and discover both known and unknown vulnerabilities in WHMDs. To demonstrate its implementation, we validate it with a number of commercially available BLE-enabled enabled wearable devices. Our results show that the devices are vulnerable to a number of attacks, including eavesdropping, data manipulation, and denial of service attacks. The proposed framework could therefore be used to evaluate potential devices before adoption into a secure network or, ideally, during the design and implementation of new devices.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W3200029738",
    "type": "article"
  },
  {
    "title": "Multi-criteria Web Services Selection: Balancing the Quality of Design and Quality of Service",
    "doi": "https://doi.org/10.1145/3446388",
    "publication_date": "2021-09-28",
    "publication_year": 2021,
    "authors": "Marwa Daaji; Ali Ouni; Mohamed Mohsen Gammoudi; Salah Bouktif; Mohamed Wiem Mkaouer",
    "corresponding_authors": "",
    "abstract": "Web service composition allows developers to create applications via reusing available services that are interoperable to each other. The process of selecting relevant Web services for a composite service satisfying the developer requirements is commonly acknowledged to be hard and challenging, especially with the exponentially increasing number of available Web services on the Internet. The majority of existing approaches on Web Services Selection are merely based on the Quality of Service (QoS) as a basic criterion to guide the selection process. However, existing approaches tend to ignore the service design quality, which plays a crucial role in discovering, understanding, and reusing service functionalities. Indeed, poorly designed Web service interfaces result in service anti-patterns, which are symptoms of bad design and implementation practices. The existence of anti-pattern instances in Web service interfaces typically complicates their reuse in real-world service-based systems and may lead to several maintenance and evolution problems. To address this issue, we introduce a new approach based on the Multi-Objective and Optimization on the basis of Ratio Analysis method (MOORA) as a multi-criteria decision making (MCDM) method to select Web services based on a combination of their (1) QoS attributes and (2) QoS design. The proposed approach aims to help developers to maintain the soundness and quality of their service composite development processes. We conduct a quantitative and qualitative empirical study to evaluate our approach on a Quality of Web Service dataset. We compare our MOORA-based approach against four commonly used MCDM methods as well as a recent state-of-the-art Web service selection approach. The obtained results show that our approach outperforms state-of-the-art approaches by significantly improving the service selection quality of top- k selected services while providing the best trade-off between both service design quality and desired QoS values. Furthermore, we conducted a qualitative evaluation with developers. The obtained results provide evidence that our approach generates a good trade-off for what developers need regarding both QoS and quality of design. Our selection approach was evaluated as “relevant” from developers point of view, in improving the service selection task with an average score of 3.93, compared to an average of 2.62 for the traditional QoS-based approach.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W3201714466",
    "type": "article"
  },
  {
    "title": "Privacy-Preserving Distributed Multi-Task Learning against Inference Attack in Cloud Computing",
    "doi": "https://doi.org/10.1145/3426969",
    "publication_date": "2021-10-22",
    "publication_year": 2021,
    "authors": "Xindi Ma; Jianfeng Ma; Saru Kumari; Fushan Wei; Mohammad Shojafar; Mamoun Alazab",
    "corresponding_authors": "",
    "abstract": "Because of the powerful computing and storage capability in cloud computing, machine learning as a service (MLaaS) has recently been valued by the organizations for machine learning training over some related representative datasets. When these datasets are collected from different organizations and have different distributions, multi-task learning (MTL) is usually used to improve the generalization performance by scheduling the related training tasks into the virtual machines in MLaaS and transferring the related knowledge between those tasks. However, because of concerns about privacy breaches (e.g., property inference attack and model inverse attack), organizations cannot directly outsource their training data to MLaaS or share their extracted knowledge in plaintext, especially the organizations in sensitive domains. In this article, we propose a novel privacy-preserving mechanism for distributed MTL, namely NOInfer, to allow several task nodes to train the model locally and transfer their shared knowledge privately. Specifically, we construct a single-server architecture to achieve the private MTL, which protects task nodes’ local data even if n-1 out of n nodes colluded. Then, a new protocol for the Alternating Direction Method of Multipliers (ADMM) is designed to perform the privacy-preserving model training, which resists the inference attack through the intermediate results and ensures that the training efficiency is independent of the number of training samples. When releasing the trained model, we also design a differentially private model releasing mechanism to resist the membership inference attack. Furthermore, we analyze the privacy preservation and efficiency of NOInfer in theory. Finally, we evaluate our NOInfer over two testing datasets and evaluation results demonstrate that NOInfer efficiently and effectively achieves the distributed MTL.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W3210115810",
    "type": "article"
  },
  {
    "title": "Predictive Analytics of Energy Usage by IoT-Based Smart Home Appliances for Green Urban Development",
    "doi": "https://doi.org/10.1145/3426970",
    "publication_date": "2021-11-10",
    "publication_year": 2021,
    "authors": "Mohammad Shorfuzzaman; M. Shamim Hossain",
    "corresponding_authors": "",
    "abstract": "Green IoT primarily focuses on increasing IoT sustainability by reducing the large amount of energy required by IoT devices. Whether increasing the efficiency of these devices or conserving energy, predictive analytics is the cornerstone for creating value and insight from large IoT data. This work aims at providing predictive models driven by data collected from various sensors to model the energy usage of appliances in an IoT-based smart home environment. Specifically, we address the prediction problem from two perspectives. Firstly, an overall energy consumption model is developed using both linear and non-linear regression techniques to identify the most relevant features in predicting the energy consumption of appliances. The performances of the proposed models are assessed using a publicly available dataset comprising historical measurements from various humidity and temperature sensors, along with total energy consumption data from appliances in an IoT-based smart home setup. The prediction results comparison show that LSTM regression outperforms other linear and ensemble regression models by showing high variability ( R 2 ) with the training (96.2%) and test (96.1%) data for selected features. Secondly, we develop a multi-step time-series model using the auto regressive integrated moving average (ARIMA) technique to effectively forecast future energy consumption based on past energy usage history. Overall, the proposed predictive models will enable consumers to minimize the energy usage of home appliances and the energy providers to better plan and forecast future energy demand to facilitate green urban development.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W3211428058",
    "type": "article"
  },
  {
    "title": "MEC-Based Jamming-Aided Anti-Eavesdropping with Deep Reinforcement Learning for WBANs",
    "doi": "https://doi.org/10.1145/3453186",
    "publication_date": "2021-12-06",
    "publication_year": 2021,
    "authors": "Guihong Chen; Xi Liu; Mohammad Shorfuzzaman; Ali Karime; Yonghua Wang; Yuanhang Qi",
    "corresponding_authors": "",
    "abstract": "Wireless body area network (WBAN) suffers secure challenges, especially the eavesdropping attack, due to constraint resources. In this article, deep reinforcement learning (DRL) and mobile edge computing (MEC) technology are adopted to formulate a DRL-MEC-based jamming-aided anti-eavesdropping (DMEC-JAE) scheme to resist the eavesdropping attack without considering the channel state information. In this scheme, a MEC sensor is chosen to send artificial jamming signals to improve the secrecy rate of the system. Power control technique is utilized to optimize the transmission power of both the source sensor and the MEC sensor to save energy. The remaining energy of the MEC sensor is concerned to ensure routine data transmission and jamming signal transmission. Additionally, the DMEC-JAE scheme integrates with transfer learning for a higher learning rate. The performance bounds of the scheme concerning the secrecy rate, energy consumption, and the utility are evaluated. Simulation results show that the DMEC-JAE scheme can approach the performance bounds with high learning speed, which outperforms the benchmark schemes.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W4200084599",
    "type": "article"
  },
  {
    "title": "Is the Price of Anarchy the Right Measure for Load-Balancing Games?",
    "doi": "https://doi.org/10.1145/2663498",
    "publication_date": "2014-10-28",
    "publication_year": 2014,
    "authors": "Josu Doncel; Urtzi Ayesta; Olivier Brun; Balakrishna Prabhu",
    "corresponding_authors": "",
    "abstract": "Price of anarchy is an oft-used worst-case measure of the inefficiency of noncooperative decentralized architectures. For a noncooperative load-balancing game with two classes of servers and for a finite or infinite number of dispatchers, we show that the price of anarchy is an overly pessimistic measure that does not reflect the performance obtained in most instances of the problem. We explicitly characterize the worst-case traffic conditions for the efficiency of noncooperative load-balancing schemes and show that, contrary to a common belief, the worst inefficiency is in general not achieved in heavy traffic.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2005708290",
    "type": "article"
  },
  {
    "title": "P-DONAS",
    "doi": "https://doi.org/10.1145/2808229",
    "publication_date": "2015-09-16",
    "publication_year": 2015,
    "authors": "Peter Danielis; Vlado Altmann; Jan Skodzik; Tim Wegner; Achim Koerner; Dirk Timmermann",
    "corresponding_authors": "",
    "abstract": "The domain name system (DNS) includes infrastructures deployed by Internet service providers (ISPs) and third-party suppliers to ensure high responsiveness, resilience, and load sharing. This equipment implies high effort and energy for 24/7 operation. To facilitate cost reductions in this regard, P-DONAS—a peer-to-peer (P2P)-based DNS—organizes access nodes (ANs) of an ISP’s access network, which possess available resources, into a decentralized, self-organizing distributed hash table--based P2P network. Each AN acts as traditional DNS server and solely stores a piece of DNS data. DNS requests issued to an AN are resolved via P2P lookups while maintaining full compatibility with traditional DNS. The article discusses the application of P-DONAS as both a complement and an alternative to traditional DNS. Results from both simulations and a practical test arrangement prove P-DONAS’ high scalability and its performance comparable to that of a commercial DNS name server relieving this name server by 53% to 75% of DNS traffic.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2396036502",
    "type": "article"
  },
  {
    "title": "Federated Route Leak Detection in Inter-domain Routing with Privacy Guarantee",
    "doi": "https://doi.org/10.1145/3561051",
    "publication_date": "2022-09-01",
    "publication_year": 2022,
    "authors": "Man Zeng; Dandan Li; Pei Zhang; Kun Xie; Xiaohong Huang",
    "corresponding_authors": "",
    "abstract": "In the inter-domain network, route leaks can disrupt the Internet traffic and cause large outages. The accurate detection of route leaks requires the sharing of AS business relationship information. However, the business relationship information between ASes is confidential. ASes are usually unwilling to reveal this information to the other ASes, especially their competitors. In this paper, we propose a method named FL-RLD to detect route leaks while maintaining the privacy of business relationships between ASes by using a blockchain-based federated learning framework, where ASes can collaboratively train a global detection model without directly disclosing their specific business relationships. To mitigate the lack of ground-truth validation data in route leaks, FL-RLD provides a self-validation scheme by labeling AS triples with local routing policies. We evaluate FL-RLD under a variety of datasets including imbalanced and balanced datasets, and examine different deployment strategies of FL-RLD under different topologies. According to the results, FL-RLD performs better in detecting route leaks than the single AS detection, whether the datasets are balanced or imbalanced. Additionally, the results indicate that selecting ASes with the most peers to first deploy FL-RLD brings more significant benefits in detecting route leaks than selecting ASes with the most providers and customers.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W3207878839",
    "type": "article"
  },
  {
    "title": "PCAM: A Data-driven Probabilistic Cyber-alert Management Framework",
    "doi": "https://doi.org/10.1145/3511101",
    "publication_date": "2022-01-22",
    "publication_year": 2022,
    "authors": "Haipeng Chen; Andrew Duncklee; Sushil Jajodia; Rui Liu; Sean McNamara; V. S. Subrahmanian",
    "corresponding_authors": "",
    "abstract": "We propose PCAM , a Probabilistic Cyber-Alert Management framework, that enables chief information security officers to better manage cyber-alerts. Workers in Cyber Security Operation Centers usually work in 8- or 12-hour shifts. Before a shift, PCAM analyzes data about all past alerts and true alerts during the shift time-frame to schedule a given set of analysts in accordance with workplace constraints so that the expected number of “uncovered” true alerts (i.e., true alerts not shown to an analyst) is minimized. PCAM achieves this by formulating the problem as a bi-level non-linear optimization problem and then shows how to linearize and solve this complex problem. We have tested PCAM extensively. Using statistics derived from 44 days of real-world alert data, we are able to minimize the expected number of true alerts that are not manually examined by a team consisting of junior, senior, and principal analysts. We are also able to identify the optimal mix of junior, senior, and principal analysts needed during both day and night shifts given a budget, outperforming some reasonable baselines. We tested PCAM ’s proposed schedule (from statistics on 44 days) on a further 6 days of data, using an off-the-shelf false alarm classifier to predict which alerts are real and which ones are false. Moreover, we show experimentally that PCAM is robust to various kinds of errors in the statistics used.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4206985935",
    "type": "article"
  },
  {
    "title": "Providing Reliable Service for Parked-vehicle-assisted Mobile Edge Computing",
    "doi": "https://doi.org/10.1145/3514242",
    "publication_date": "2022-02-04",
    "publication_year": 2022,
    "authors": "Ao Zhou; Xiao Ma; Siyi Gao; Shangguang Wang",
    "corresponding_authors": "",
    "abstract": "Nowadays, a growing number of computation-intensive applications appear in our daily life. Those applications make the loads of both the core network and the mobile devices, in terms of energy and bandwidth, hugely increase. Offloading computation-intensive tasks to edge cloud is proposed to address this issue. Since edge clouds have limited computation resources compared with the remote cloud, they would get over-loaded because of the heavy computation burden. Parked-vehicle-assisted mobile edge computing becomes one of the promising solutions for this problem. However, several critical issues in parked-vehicle-assisted mobile edge computing would result in low reliable edge service. The open environment would bring about uncertainty, and the data privacy is hard to ensure. In addition, different from edge cloud, each parked vehicle only has limited parking duration and can leave unexpectedly for personal reasons. Moreover, edge cloud and vehicle adopt different execution models of computation and communication. The heterogeneous environment may result in negative effect on cooperativeness. Ignoring those issues can result in substantial performance degradation. To tackle this challenge and explore the benefits of parked-vehicle-assisted offloading, we study the task offloading and resource-allocation problem by fully considering the above issues. First, we propose a resource-management scheme to address the privacy issue. Second, we review the execution model of computation and communication in parked-vehicle-assisted computation offloading. Then, we formulate the problem into a mixed-integer nonlinear programming. The problem is hard to tackle due to its non-convex nature, which means that the time complexity of finding global optimal solution is unaffordable. Finally, we decompose the original problem into two sub-problems with lower complexity, and related algorithms are given to deal with the sub-problems. Simulation results demonstrate the effectiveness of the proposed solution.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4210304171",
    "type": "article"
  },
  {
    "title": "CARES: Context-Aware Trust Estimation for Realtime Crowdsensing Services in Vehicular Edge Networks",
    "doi": "https://doi.org/10.1145/3514243",
    "publication_date": "2022-02-22",
    "publication_year": 2022,
    "authors": "Si Young Jang; Sung Kyu Park; Jin-Hee Cho; Dongman Lee",
    "corresponding_authors": "",
    "abstract": "The growing number of smart vehicles makes it possible to envision a crowdsensing service where vehicles can share video data of their surroundings for seeking out traffic conditions and car accidents ahead. However, the service may need to deal with situations like malicious vehicles propagating false information to divert other vehicles to arrive at destinations earlier or lead them to dangerous locations. This article proposes a context-aware trust estimation scheme that can allow roadside units in a vehicular edge network to provide real-time crowdsensing services in a reliable manner by selectively using information from trustworthy sources. Our proposed scheme is novel in that its trust estimation does not require any prior knowledge of vehicles on roads but quickly obtains the accurate trust value of each vehicle by leveraging transfer learning. and its Q-learning-based dynamic adjustment scheme autonomously estimates trust levels of oncoming vehicles with the aim of detecting malicious vehicles and accordingly filtering out untrustworthy input from them. Based on an extensive simulation study, we prove that the proposed scheme outperforms existing ones in terms of malicious vehicle detection accuracy.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4212966194",
    "type": "article"
  },
  {
    "title": "V-Gas: Generating High Gas Consumption Inputs to Avoid Out-of-Gas Vulnerability",
    "doi": "https://doi.org/10.1145/3511900",
    "publication_date": "2022-04-18",
    "publication_year": 2022,
    "authors": "Fuchen Ma; Meng Ren; Ying Fu; Wanting Sun; Houbing Song; Heyuan Shi; Yu Jiang; Huizhong Li",
    "corresponding_authors": "",
    "abstract": "Out-of-gas errors occur when smart contract programs are provided with inputs that cause excessive gas consumption and which will be easily exploited to perform Denial-of-Service attacks. Various approaches have been proposed to estimate the gas limit of a function in smart contracts to avoid such error. However, underestimation often occurs when the contract is complex In this work, we propose V-Gas, which automatically generates inputs that maximize the gas cost and reduce underestimation. V-Gas is designed based on static analysis and feedback-directed mutational fuzz testing. First, V-Gas builds the gas weighted control flow graph of functions in smart contracts. Then, V-Gas develops gas consumption guided selection and mutation strategies to generate the input that maximize the gas consumption. For evaluation, we implement V-Gas based on js-evm, a widely used Ethereum virtual machine written in Javascript, and conduct experiments on 736 real-world transactions recorded on Ethereum. A total of 44.02% of the transactions would have out-of-gas errors based on the estimation results given by solc, meaning that the recorded real gas consumption for those transactions is larger than the gas limit estimated by solc. In comparison, V-Gas could reduce the underestimation ratio to 13.86%. To evaluate the performance of feedback-directed engine in V-Gas, we implemented other directed fuzzing engines and compared their performance with that of V-Gas. The results showed that V-Gas generates the same or higher gas estimation value on 97.8% of the transactions with less time, usually within 5 minutes. Furthermore, V-Gas has exposed 25 previously unknown out-of-gas vulnerabilities in widely used smart contracts, 6 of which have been assigned unique CVE identifiers in the U.S. National Vulnerability Database.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4224131832",
    "type": "article"
  },
  {
    "title": "A Multi-type Classifier Ensemble for Detecting Fake Reviews Through Textual-based Feature Extraction",
    "doi": "https://doi.org/10.1145/3568676",
    "publication_date": "2022-10-21",
    "publication_year": 2022,
    "authors": "Gregorius Satia Budhi; Raymond Chiong",
    "corresponding_authors": "",
    "abstract": "The financial impact of online reviews has prompted some fraudulent sellers to generate fake consumer reviews for either promoting their products or discrediting competing products. In this study, we propose a novel ensemble model—the Multi-type Classifier Ensemble (MtCE) —combined with a textual-based featuring method, which is relatively independent of the system, to detect fake online consumer reviews. Unlike other ensemble models that utilise only the same type of single classifier, our proposed ensemble utilises several customised machine learning classifiers (including deep learning models) as its base classifiers. The results of our experiments show that the MtCE can adequately detect fake reviews, and that it outperforms other single and ensemble methods in terms of accuracy and other measurements for all the relevant public datasets used in this study. Moreover, if set correctly, the parameters of MtCE, such as base-classifier types, the total number of base classifiers, bootstrap, and the method to vote on output (e.g., majority or priority), can further improve the performance of the proposed ensemble.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4307169119",
    "type": "article"
  },
  {
    "title": "An optimal strategy for sellers in an online auction",
    "doi": "https://doi.org/10.1145/503334.503335",
    "publication_date": "2002-02-01",
    "publication_year": 2002,
    "authors": "Xin Guo",
    "corresponding_authors": "Xin Guo",
    "abstract": "We consider an online auction setting where the seller attempts to sell an item. Bids arrive over time and the seller has to make an instant decision to either accept this bid and close the auction or reject it and move on to the next bid, with the hope of higher gains. What should be the seller's strategy to maximize gains? Using techniques from convex analysis, we provide an explicit closed-form optimal solution (and hence a simple optimum online algorithm) for the seller.Our methodology is attractive to online auction systems that have to make an instant decision, especially when it is not humanly possible to evaluate each bid individually, when the number of bids is large or unknown ahead of time, and when the bidders are unwilling to wait.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W2050071617",
    "type": "article"
  },
  {
    "title": "Agent trade servers in financial exchange systems",
    "doi": "https://doi.org/10.1145/1013202.1013206",
    "publication_date": "2004-08-01",
    "publication_year": 2004,
    "authors": "David Lybäck; Magnus Boman",
    "corresponding_authors": "",
    "abstract": "New services based on the best-effort paradigm could complement the current deterministic services of an electronic financial exchange. Four crucial aspects of such systems would benefit from a hybrid stance: proper use of processing resources, bandwidth management, fault tolerance, and exception handling. We argue that a more refined view on Quality-of-Service control for exchange systems, in which the principal ambition of upholding a fair and orderly marketplace is left uncompromised, would benefit all interested parties.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2083130760",
    "type": "article"
  },
  {
    "title": "Effective Web browsing through content delivery adaptation",
    "doi": "https://doi.org/10.1145/1111627.1111628",
    "publication_date": "2005-11-01",
    "publication_year": 2005,
    "authors": "Kaname Harumoto; Tadashi Nakano; Shinya Fukumura; Shinji Shimojo; Shojiro Nishio",
    "corresponding_authors": "",
    "abstract": "This article presents a Web content adaptation and delivery mechanism based on application-level quality of service (QoS) policies. To realize effective Web content delivery for users, two kinds of application-level QoS policies, transmission time and transmission order of inline objects, are introduced. Next, we define a language to specify these policies. We show that transmission order control can be implemented using HTTP/1.1 pipelined requests in which a client recognizes the transmission order description in a Web page and simulates parallel transmission of inline objects by HTTP/1.1 range requests. Experimental results show that our proposed mechanism realizes effective content delivery to a diverse group of Internet users. Finally, we introduce two methods to specify application-level QoS policies, one by content authors, and the other by end users.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W1978438942",
    "type": "article"
  },
  {
    "title": "Web services discovery in secure collaboration environments",
    "doi": "https://doi.org/10.1145/1294148.1294153",
    "publication_date": "2007-11-01",
    "publication_year": 2007,
    "authors": "Mohamed Shehab; Kamal Bhattacharya; Arif Ghafoor",
    "corresponding_authors": "",
    "abstract": "Multidomain application environments where distributed domains interoperate with each other is a reality in Web-services-based infrastructures. Collaboration enables domains to effectively share resources; however, it introduces several security and privacy challenges. In this article, we use the current web service standards such as SOAP and UDDI to enable secure interoperability in a service-oriented mediator-free environment. We propose a multihop SOAP messaging protocol that enables domains to discover secure access paths to access roles in different domains. Then we propose a path authentication mechanism based on the encapsulation of SOAP messages and the SOAP-DISG standard. Furthermore, we provide a service discovery protocol that enables domains to discover service descriptions stored in private UDDI registries.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2061406556",
    "type": "article"
  },
  {
    "title": "Formation and Reciprocation of Dyadic Trust",
    "doi": "https://doi.org/10.1145/2996184",
    "publication_date": "2017-03-24",
    "publication_year": 2017,
    "authors": "Atanu Singha Roy; Ayush Singhal; Jaideep Srivastava",
    "corresponding_authors": "",
    "abstract": "This paper reports a detailed empirical study of interpersonal trust in a multi-relational online social network. This study addresses two main aspects of interpersonal trust: formation and reciprocation. Computational models developed, using multi-relational networks, for these processes provide interesting insights about online social interactions. Our findings for trust formation (initiation) indicate a strong role of lower familiarity interactions before trust(high familiarity relationship) is formed. Similarly, trust reciprocation is not automatic, but strongly depends on enough lower familiarity interactions. This study is the first quantification of the “scaffolding role” played by lower familiarity interactions, in formation of high familiarity relationships.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2603268606",
    "type": "article"
  },
  {
    "title": "<i>PROV</i> <sub>2R</sub>",
    "doi": "https://doi.org/10.1145/3062176",
    "publication_date": "2017-08-18",
    "publication_year": 2017,
    "authors": "Manolis Stamatogiannakis; Ηλίας Αθανασόπουλος; Herbert Bos; Paul Groth",
    "corresponding_authors": "",
    "abstract": "Information produced by Internet applications is inherently a result of processes that are executed locally. Think of a web server that makes use of a CGI script, or a content management system where a post was first edited using a word processor. Given the impact of these processes to the content published online, a consumer of that information may want to understand what those impacts were. For example, understanding from where text was copied and pasted to make a post, or if the CGI script was updated with the latest security patches, may all influence the confidence on the published content. Capturing and exposing this information provenance is thus important to ascertaining trust to online content. Furthermore, providers of internet applications may wish to have access to the same information for debugging or audit purposes. For processes following a rigid structure (such as databases or workflows), disclosed provenance systems have been developed that efficiently and accurately capture the provenance of the produced data. However, accurately capturing provenance from unstructured processes, for example, user-interactive computing used to produce web content, remains a problem to be tackled. In this article, we address the problem of capturing and exposing provenance from unstructured processes. Our approach, called PROV 2R ( PROV enance R ecord and R eplay) is composed of two parts: (a) the decoupling of provenance analysis from its capture; and (b) the capture of high-fidelity provenance from unmodified programs. We use techniques originating in the security and reverse engineering communities, namely, record and replay and taint tracking . Taint tracking fundamentally addresses the data provenance problem but is impractical to apply at runtime due to extremely high overhead. With a number of case studies, we demonstrate that PROV 2R enables the use of taint analysis for high-fidelity provenance capture, while keeping the runtime overhead at manageable levels. In addition, we show how captured information can be represented using the W3C PROV provenance model for exposure on the Web.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2746973212",
    "type": "article"
  },
  {
    "title": "A Learning-Based Framework for Improving Querying on Web Interfaces of Curated Knowledge Bases",
    "doi": "https://doi.org/10.1145/3155806",
    "publication_date": "2018-02-05",
    "publication_year": 2018,
    "authors": "Wei Emma Zhang; Quan Z. Sheng; Lina Yao; Kerry Taylor; Ali Shemshadi; Yongrui Qin",
    "corresponding_authors": "",
    "abstract": "Knowledge Bases (KBs) are widely used as one of the fundamental components in Semantic Web applications as they provide facts and relationships that can be automatically understood by machines. Curated knowledge bases usually use Resource Description Framework (RDF) as the data representation model. To query the RDF-presented knowledge in curated KBs, Web interfaces are built via SPARQL Endpoints. Currently, querying SPARQL Endpoints has problems like network instability and latency, which affect the query efficiency. To address these issues, we propose a client-side caching framework, SPARQL Endpoint Caching Framework (SECF), aiming at accelerating the overall querying speed over SPARQL Endpoints. SECF identifies the potential issued queries by leveraging the querying patterns learned from clients’ historical queries and prefecthes/caches these queries. In particular, we develop a distance function based on graph edit distance to measure the similarity of SPARQL queries. We propose a feature modelling method to transform SPARQL queries to vector representation that are fed into machine-learning algorithms. A time-aware smoothing-based method, Modified Simple Exponential Smoothing (MSES), is developed for cache replacement. Extensive experiments performed on real-world queries showcase the effectiveness of our approach, which outperforms the state-of-the-art work in terms of the overall querying speed.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2783204634",
    "type": "article"
  },
  {
    "title": "easIE",
    "doi": "https://doi.org/10.1145/3155807",
    "publication_date": "2018-04-24",
    "publication_year": 2018,
    "authors": "Vasiliki Gkatziaki; Symeon Papadopoulos; Richard Mills; Sotiris Diplaris; Ioannis Tsampoulatidis; Ioannis Kompatsiaris",
    "corresponding_authors": "",
    "abstract": "Public awareness of and concerns about companies’ social and environmental impacts have seen a marked increase over recent decades. In parallel, the quantity of relevant information has increased, as states pass laws requiring certain forms of reporting, researchers investigate companies’ performance, and companies themselves seek to gain a competitive advantage by being seen to operate fairly and transparently. However, this information is typically dispersed and non-standardized, making it complicated to collect and analyze. To address this challenge, the WikiRate platform aims to collect this information and store it in a standardized format within a centralized public repository, making it much more amenable to analysis. In the context of WikiRate, this article introduces easIE, an easy-to-use information extraction (IE) framework that leverages general Web IE principles for building datasets with environmental, social, and governance information from the Web. To demonstrate the flexibility and value of easIE, we built a large-scale corporate social responsibility database comprising 654,491 metrics related to 49,009 companies spending less than 16 hours for data engineering, collection, and indexing. Finally, a data collection exercise involving 12 subjects was performed to showcase the ease of use of the developed framework.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2800009858",
    "type": "article"
  },
  {
    "title": "<i>Oops</i>",
    "doi": "https://doi.org/10.1145/3230642",
    "publication_date": "2019-03-28",
    "publication_year": 2019,
    "authors": "Farzad Samie; Vasileios Tsoutsouras; Lars Bauer; Sotirios Xydis; Dimitrios Soudris; Jörg Henkel",
    "corresponding_authors": "",
    "abstract": "The massive increase of IoT devices and their collected data raises the question of how to analyze all that data. Edge computing provides a suitable compromise, but the question remains: How much processing should be done locally vs. offloaded to other devices? The diverse application requirements and limited resources at the edge extend the challenges. We propose Oops , an optimization framework to adapt the resource management at runtime distributedly. It orchestrates the IoT devices and adapts their operation mode with respect to their constraints and the gateway’s limited shared resources. Oops reduces runtime overhead significantly while increasing user utility compared to state-of-the-art.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2930256823",
    "type": "article"
  },
  {
    "title": "Achieving Data Consistency by Contextualization in Collaborative Web-based Applications",
    "doi": null,
    "publication_date": "2011-01-01",
    "publication_year": 2011,
    "authors": "Haifeng Shen; Chengzheng Sun",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W3010037868",
    "type": "article"
  },
  {
    "title": "Sub-Population Specific Models of Couples’ Conflict",
    "doi": "https://doi.org/10.1145/3372045",
    "publication_date": "2020-03-14",
    "publication_year": 2020,
    "authors": "Krit Gupta; Aditya Gujral; Theodora Chaspari; Adela C. Timmons; Sohyun C. Han; Yehsong Kim; Sarah Barrett; Stassja Sichko; Gayla Margolin",
    "corresponding_authors": "",
    "abstract": "Interpersonal conflict between couples is a significant source of stress with long-lasting effects on partners’ physical and psychological health. Motivated by findings in psychological science, we study how couples with distinct relationship functioning characteristics experience conflict in real life. We propose sub-population specific machine learning models using hierarchical and adaptive learning frameworks to automatically detect interpersonal conflict through the ambulatory monitoring of couples’ physiological signals, audio samples, and linguistic indices. Results indicate that the proposed models outperform a general model learned for the entire population and separate models independently trained on each sub-population, providing a foundation toward personalized health applications.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W3011506732",
    "type": "article"
  },
  {
    "title": "Beyond Artificial Reality",
    "doi": "https://doi.org/10.1145/3374214",
    "publication_date": "2020-02-29",
    "publication_year": 2020,
    "authors": "Calton Pu; Abhijit Suprem; Rodrigo Alves Lima; Aibek Musaev; De Wang; Danesh Irani; Steve Webb; João Eduardo Ferreira",
    "corresponding_authors": "",
    "abstract": "With billions of active social media accounts and millions of live video cameras, live new big data offer many opportunities for smart applications. However, the main consumers of the new big data have been humans. We envision the research on live knowledge , to automatically acquire real-time, validated, and actionable information. Live knowledge presents two significant and diverging technical challenges: big noise and concept drift. We describe the EBKA (evidence-based knowledge acquisition) approach, illustrated by the LITMUS landslide information system. LITMUS achieves both high accuracy and wide coverage, demonstrating the feasibility and promise of EBKA approach to achieve live knowledge.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W3014377569",
    "type": "article"
  },
  {
    "title": "Cracking Channel Hopping Sequences and Graph Routes in Industrial TSCH Networks",
    "doi": "https://doi.org/10.1145/3372881",
    "publication_date": "2020-07-07",
    "publication_year": 2020,
    "authors": "Xia Cheng; Junyang Shi; Mo Sha",
    "corresponding_authors": "",
    "abstract": "Industrial networks typically connect hundreds or thousands of sensors and actuators in industrial facilities, such as manufacturing plants, steel mills, and oil refineries. Although the typical industrial Internet of Things (IoT) applications operate at low data rates, they pose unique challenges because of their critical demands for reliable and real-time communication in harsh industrial environments. IEEE 802.15.4-based wireless sensor-actuator networks (WSANs) technology is appealing for use to construct industrial networks because it does not require wired infrastructure and can be manufactured inexpensively. Battery-powered wireless modules easily and inexpensively retrofit existing sensors and actuators in industrial facilities without running cables for communication and power. To address the stringent real-time and reliability requirements, WSANs made a set of unique design choices such as employing the Time-Synchronized Channel Hopping (TSCH) technology. These designs distinguish WSANs from traditional wireless sensor networks (WSNs) that require only best effort services. The function-based channel hopping used in TSCH simplifies the network operations at the cost of security. Our study shows that an attacker can reverse engineer the channel hopping sequences and graph routes by silently observing the transmission activities and put the network in danger of selective jamming attacks. The cracked knowledge on the channel hopping sequences and graph routes is an important prerequisite for launching selective jamming attacks to TSCH networks. To our knowledge, this article represents the first systematic study that investigates the security vulnerability of TSCH channel hopping and graph routing under realistic settings. In this article, we demonstrate the cracking process, present two case studies using publicly accessible implementations (developed for Orchestra and WirelessHART), and provide a set of insights.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W3041193434",
    "type": "article"
  },
  {
    "title": "Incremental Group-Level Popularity Prediction in Online Social Networks",
    "doi": "https://doi.org/10.1145/3461839",
    "publication_date": "2021-09-14",
    "publication_year": 2021,
    "authors": "Jingjing Wang; Wenjun Jiang; Kenli Li; Guojun Wang; Keqin Li",
    "corresponding_authors": "",
    "abstract": "Predicting the popularity of web contents in online social networks is essential for many applications. However, existing works are usually under non-incremental settings. In other words, they have to rebuild models from scratch when new data occurs, which are inefficient in big data environments. It leads to an urgent need for incremental prediction, which can update previous results with new data and conduct prediction incrementally. Moreover, the promising direction of group-level popularity prediction has not been well treated, which explores fine-grained information while keeping a low cost. To this end, we identify the problem of incremental group-level popularity prediction, and propose a novel model IGPP to address it. We first predict the group-level popularity incrementally by exploiting the incremental CANDECOMP/PARAFCAC (CP) tensor decomposition algorithm. Then, to reduce the cumulative error by incremental prediction, we propose three strategies to restart the CP decomposition. To the best of our knowledge, this is the first work that identifies and solves the problem of incremental group-level popularity prediction. Extensive experimental results show significant improvements of the IGPP method over other works both in the prediction accuracy and the efficiency.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W3200287668",
    "type": "article"
  },
  {
    "title": "Adoption of Bundled Services with Network Externalities and Correlated Affinities",
    "doi": "https://doi.org/10.1145/2663493",
    "publication_date": "2014-10-28",
    "publication_year": 2014,
    "authors": "R. Guérin; Jaudelice C. de Oliveira; Steven Weber",
    "corresponding_authors": "",
    "abstract": "The goal of this article is to develop a principled understanding of when it is beneficial to bundle technologies or services whose value is heavily dependent on the size of their user base, that is, exhibits positive exernalities. Of interest is how the joint distribution, and in particular the correlation, of the values users assign to components of a bundle affect its odds of success. The results offer insight and guidelines for deciding when bundling new Internet technologies or services can help improve their overall adoption. In particular, successful outcomes appear to require a minimum level of value correlation. Categories and Subject Descriptors (2012): Networks -- Network Algorithms -- Network economics; Networks -- Network properties -- Network dynamics; Information systems -- Information systems applications -- Collaborative and social computing systems and tools; Security and privacy -- Human and societal aspects of security and privacy; Human-centered computing -- Collaborative and social computing theory, concepts and paradigms",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2004968765",
    "type": "article"
  },
  {
    "title": "Regulation of Off-Network Pricing in a Nonneutral Network",
    "doi": "https://doi.org/10.1145/2663491",
    "publication_date": "2014-10-28",
    "publication_year": 2014,
    "authors": "Eitan Altman; Manjesh K. Hanawal; Rajesh Sundaresan",
    "corresponding_authors": "",
    "abstract": "Representatives of several Internet service providers (ISPs) have expressed their wish to see a substantial change in the pricing policies of the Internet. In particular, they would like to see content providers (CPs) pay for use of the network, given the large amount of resources they use. This would be in clear violation of the “network neutrality” principle that had characterized the development of the wireline Internet. Our first goal in this article is to propose and study possible ways of implementing such payments and of regulating their amount. We introduce a model that includes the users' behavior, the utilities of the ISP and of the CPs, and, the monetary flow that involves the content users, the ISP and CP, and, in particular, the CP's revenues from advertisements. We consider various game models and study the resulting equilibria; they are all combinations of a noncooperative game (in which the ISPs and CPs determine how much they will charge the users) with a “cooperative” one on how the CP and the ISP share the payments. We include in our model a possible asymmetric weighting parameter (that varies between zero to one). We also study equilibria that arise when one of the CPs colludes with the ISP. We also study two dynamic game models as well as the convergence of prices to the equilibrium values.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2039647654",
    "type": "article"
  },
  {
    "title": "Bottom-Up Fault Management in Service-Based Systems",
    "doi": "https://doi.org/10.1145/2739045",
    "publication_date": "2015-06-24",
    "publication_year": 2015,
    "authors": "Amal Alhosban; Khayyam Hashmi; Zaki Malik; Brahim Medjahed; Salima Benbernou",
    "corresponding_authors": "",
    "abstract": "Service Oriented Architecture (SOA) enables the creation of distributed applications from independently developed and deployed services. As with any component-based system, the overall performance and quality of the system is an aggregate function of its component services. In this article, we present a novel approach for managing bottom-up faults in service-based systems. Bottom-up faults are a special case of system-wide exceptions that are defined as abnormal conditions or defects occurring in component services, which if not detected and/or managed, may lead to runtime failures. Examples of bottom-up faults include network outage, server disruption, and changes to service provisioning (e.g., new operation parameter required) that may have an impact on the way component services are consumed. We propose a soft-state signaling-based approach to propagate these faults from participants to composite services. Soft-state refers to a class of protocols where the state of a service is constantly refreshed by periodic messages, and user/service takes up the responsibility of communicating and maintaining its state. Soft-state-based protocols have a number of advantages including implicit error recovery and easier fault management, resulting in high availability for systems. Although soft-state has been widely used in various Internet protocols, this work is the first (to the best of our knowledge) to adopt soft-state for fault management in composite services. The proposed approach includes protocols for fault propagation (pure soft-state and soft-state with explicit removal) and fault reaction (rule-based). We also present experiment results to assess the performance and applicability of our approach.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2220931428",
    "type": "article"
  },
  {
    "title": "Chasing Offensive Conduct in Social Networks",
    "doi": "https://doi.org/10.1145/2797139",
    "publication_date": "2015-12-07",
    "publication_year": 2015,
    "authors": "Santiago Pina Ros; Ángel Pina Canelles; Manuel Gil Pérez; Félix Gómez Mármol; Gregorio Martínez Pérez",
    "corresponding_authors": "",
    "abstract": "Social network users take advantage of anonymity to share rumors or gossip about others, making it important to provide means to report offensive conduct. This article presents a proposal to automatically manage these reports. We consider not only the users’ public behavior, but also private messages between users. The automatic approach is based, in both cases, on the reporters’ reputation along with other metrics intrinsic to social networks. Promising results from adopting the proposed reporting methods on Frisber, a geolocalized social network in production, are presented as well as some experiments based on real data extracted from Frisber.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2295492026",
    "type": "article"
  },
  {
    "title": "Cognitive Robotics on 5G Networks",
    "doi": "https://doi.org/10.1145/3414842",
    "publication_date": "2021-07-16",
    "publication_year": 2021,
    "authors": "Zhihan Lv; Liang Qiao; Qingjun Wang",
    "corresponding_authors": "",
    "abstract": "Emotional cognitive ability is a key technical indicator to measure the friendliness of interaction. Therefore, this research aims to explore robots with human emotion cognitively. By discussing the prospects of 5G technology and cognitive robots, the main direction of the study is cognitive robots. For the emotional cognitive robots, the analysis logic similar to humans is difficult to imitate; the information processing levels of robots are divided into three levels in this study: cognitive algorithm, feature extraction, and information collection by comparing human information processing levels. In addition, a multi-scale rectangular direction gradient histogram is used for facial expression recognition, and robust principal component analysis algorithm is used for facial expression recognition. In the pictures where humans intuitively feel smiles in sad emotions, the proportion of emotions obtained by the method in this study are as follows: calmness accounted for 0%, sadness accounted for 15.78%, fear accounted for 0%, happiness accounted for 76.53%, disgust accounted for 7.69%, anger accounted for 0%, and astonishment accounted for 0%. In the recognition of micro-expressions, humans intuitively feel negative emotions such as surprise and fear, and the proportion of emotions obtained by the method adopted in this study are as follows: calmness accounted for 32.34%, sadness accounted for 34.07%, fear accounted for 6.79%, happiness accounted for 0%, disgust accounted for 0%, anger accounted for 13.91%, and astonishment accounted for 15.89%. Therefore, the algorithm explored in this study can realize accuracy in cognition of emotions. From the preceding research results, it can be seen that the research method in this study can intuitively reflect the proportion of human expressions, and the recognition methods based on facial expressions and micro-expressions have good recognition effects, which is in line with human intuitive experience.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W3184176971",
    "type": "article"
  },
  {
    "title": "Game-Theoretic Strategic Coordination and Navigation of Multiple Wheeled Robots",
    "doi": "https://doi.org/10.1145/3450521",
    "publication_date": "2021-07-16",
    "publication_year": 2021,
    "authors": "Buddhadeb Pradhan; Nirmal Baran Hui; Diptendu Sinha Roy; Gautam Srivastava; Jerry Chun‐Wei Lin",
    "corresponding_authors": "",
    "abstract": "Multiple robots negotiating in a dynamic workspace may lead to collisions. To avoid such issues, multi-robot navigation and coordination becomes necessary but is computationally very challenging, particularly when there are many robots. This article addresses the problem of multi-robot navigation where individual robots require coordination. Although a few such attempts for modeling multi-robot coordination and navigation have been studied, this work proposes a game-theoretic coordination strategy, also referred to as strategic coordination. We make use of a genetic algorithm tuned fuzzy logic–based motion planner. The proposed strategic coordination strategy has been pitted against a basic potential field-based motion planner, also referred to as the heuristic method, for performance comparison. Results are compared through computer simulation with 8 to 17 robots at different rounds. From the obtained results, it was observed that the proposed coordination scheme’s efficacy is strong for a larger number of robots. In addition, the proposed strategic coordination scheme with the genetic-fuzzy-based motion planner was found to outperform other combinations as far as the quality of solutions and time to reach the goal positions. The computational complexity of different methods has also been compared and presented.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W3186571616",
    "type": "article"
  },
  {
    "title": "Collusion-free for Cloud Verification toward the View of Game Theory",
    "doi": "https://doi.org/10.1145/3423558",
    "publication_date": "2021-11-11",
    "publication_year": 2021,
    "authors": "Hongyang Yan; Nan Jiang; Kang Li; Yilei Wang; Guoyu Yang",
    "corresponding_authors": "",
    "abstract": "At present, clients can outsource lots of complex and abundant computation, e.g., Internet of things (IoT), tasks to clouds by the “pay as you go” model. Outsourcing computation can save costs for clients and fully utilize the existing cloud infrastructures. However, it is hard for clients to trust the clouds even if blockchain is used as the trusted platform. In this article, we utilize the verification method as SETI@home by only two rational clouds, who hope to maximize their utilities. Utilities are defined as the incomes of clouds when they provide computation results to clients. More specifically, one client outsources two jobs to two clouds and each job contains n tasks, which include k identical sentinels. Two clouds can either honestly compute each task or collude on the identical sentinel tasks by agreeing on random values. If the results of identical sentinels are identical, then client regards the jobs as correctly computed without verification. Obviously, rational clouds have incentives to deviate by collusion and provide identical random results for a higher income. We discuss how to prevent collusion by using deposits, e.g., bit-coins. Furthermore, utilities for each cloud can be automatically assigned by a smart contract. We prove that, given proper parameters, two rational clouds will honestly send correct results to the client without collusion.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W3212177898",
    "type": "article"
  },
  {
    "title": "A Lossless Data-Hiding based IoT Data Authenticity Model in Edge-AI for Connected Living",
    "doi": "https://doi.org/10.1145/3453171",
    "publication_date": "2021-12-06",
    "publication_year": 2021,
    "authors": "Mohammad Saidur Rahman; Ibrahim Khalil; Xun Yi; Mohammed Atiquzzaman; Elisa Bertino",
    "corresponding_authors": "",
    "abstract": "Edge computing is an emerging technology for the acquisition of Internet-of-Things (IoT) data and provisioning different services in connected living. Artificial Intelligence (AI) powered edge devices (edge-AI) facilitate intelligent IoT data acquisition and services through data analytics. However, data in edge networks are prone to several security threats such as external and internal attacks and transmission errors. Attackers can inject false data during data acquisition or modify stored data in the edge data storage to hamper data analytics. Therefore, an edge-AI device must verify the authenticity of IoT data before using them in data analytics. This article presents an IoT data authenticity model in edge-AI for a connected living using data hiding techniques. Our proposed data authenticity model securely hides the data source’s identification number within IoT data before sending it to edge devices. Edge-AI devices extract hidden information for verifying data authenticity. Existing data hiding approaches for biosignal cannot reconstruct original IoT data after extracting the hidden message from it (i.e., lossy) and are not usable for IoT data authenticity. We propose the first lossless IoT data hiding technique in this article based on error-correcting codes (ECCs). We conduct several experiments to demonstrate the performance of our proposed method. Experimental results establish the lossless property of the proposed approach while maintaining other data hiding properties.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W4200554730",
    "type": "article"
  },
  {
    "title": "A Canonical Form for PROV Documents and Its Application to Equality, Signature, and Validation",
    "doi": "https://doi.org/10.1145/3032990",
    "publication_date": "2017-08-18",
    "publication_year": 2017,
    "authors": "Luc Moreau",
    "corresponding_authors": "Luc Moreau",
    "abstract": "We present a canonical form for prov that is a normalized way of representing prov documents as mathematical expressions. As opposed to the normal form specified by the prov-constraints recommendation, the canonical form we present is defined for all prov documents, irrespective of their validity, and it can be serialized in a unique way. The article makes the case for a canonical form for prov and its potential uses, namely comparison of prov documents in different formats, validation, and signature of prov documents. A signature of a prov document allows the integrity and the author of provenance to be ascertained; since the signature is based on the canonical form, these checks are not tied to a particular encoding, but can be performed on any representation of prov .",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2594359443",
    "type": "article"
  },
  {
    "title": "Dissecting Darknets",
    "doi": "https://doi.org/10.1145/2611527",
    "publication_date": "2014-05-01",
    "publication_year": 2014,
    "authors": "Xiaowen Chu; Xiaowei Chen; Adele Lu Jia; Johan Pouwelse; Dick Epema",
    "corresponding_authors": "",
    "abstract": "BitTorrent (BT) plays an important role in Internet content distribution. Because public BTs suffer from the free-rider problem, Darknets are becoming increasingly popular, which use Sharing Ratio Enforcement to increase their efficiency. We crawled and traced 17 Darknets from September 2009 to February 2011, and obtained datasets about over 5 million torrents. We conducted a broad range of measurements, including traffic, sites, torrents, and users activities. We found that some of the features of Darknets are noticeably different from public BTs. The results of our study reflect both macroscopic and microscopic aspects of the overall ecosystem of BitTorrent Darknets.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W1966244052",
    "type": "article"
  },
  {
    "title": "Distributed Content Curation on the Web",
    "doi": "https://doi.org/10.1145/2663489",
    "publication_date": "2014-10-28",
    "publication_year": 2014,
    "authors": "Zeinab Abbassi; Nidhi Hegde; Laurent Massoulié",
    "corresponding_authors": "",
    "abstract": "In recent years there has been an explosive growth of digital content in the form of news feeds, videos, and original content on online platforms such as blogs and social networks. Indeed, such platforms have been used as a means of sharing and republishing information, leading to a large collection of content that users must sift through. We consider the problem of curating this vast catalogue of content such that aggregators or publishers can offer readers content that is of interest to them, with minimal spam. Under a game-theoretic model we obtain several results on the optimal content selection and on the efficiency of distributed curation.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2106697603",
    "type": "article"
  },
  {
    "title": "Secure Team Composition to Thwart Insider Threats and Cyber-Espionage",
    "doi": "https://doi.org/10.1145/2663499",
    "publication_date": "2014-10-28",
    "publication_year": 2014,
    "authors": "Áron Lászka; Benjamin Johnson; Pascal Schöttle; Jens Großklags; Rainer Böhme",
    "corresponding_authors": "",
    "abstract": "We develop a formal nondeterministic game model for secure team composition to counter cyber-espionage and to protect organizational secrets against an attacker who tries to sidestep technical security mechanisms by offering a bribe to a project team member. The game captures the adversarial interaction between the attacker and the project manager who has a secret she wants to protect but must share with a team of individuals selected from within her organization. Our interdisciplinary work is important in the face of the multipronged approaches utilized by well-motivated attackers to circumvent the fortifications of otherwise well-defended targets.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2145811653",
    "type": "article"
  },
  {
    "title": "Quality-Based Online Data Reconciliation",
    "doi": "https://doi.org/10.1145/2806888",
    "publication_date": "2016-02-01",
    "publication_year": 2016,
    "authors": "Asma Abboura; Soror Sahri; Latifa Baba-Hamed; Mourad Ouziri; Salima Benbernou",
    "corresponding_authors": "",
    "abstract": "One of the main challenges in data matching and data cleaning, in highly integrated systems, is duplicates detection . While the literature abounds of approaches detecting duplicates corresponding to the same real-world entity, most of these approaches tend to eliminate duplicates (wrong information) from the sources, hence leading to what is called data repair. In this article, we propose a framework that automatically detects duplicates at query time and effectively identifies the consistent version of the data, while keeping inconsistent data in the sources. Our framework uses matching dependencies (MDs) to detect duplicates through the concept of data reconciliation rules (DRR) and conditional function dependencies (CFDs) to assess the quality of different attribute values. We also build a duplicate reconciliation index ( DRI ), based on clusters of duplicates detected by a set of DRRs to speed up the online data reconciliation process. Our experiments of a real-world data collection show the efficiency and effectiveness of our framework.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2257216439",
    "type": "article"
  },
  {
    "title": "sCARE",
    "doi": "https://doi.org/10.1145/2792979",
    "publication_date": "2016-02-17",
    "publication_year": 2016,
    "authors": "Zaki Malik; Brahim Medjahed; Abdelmounaam Rezgui",
    "corresponding_authors": "",
    "abstract": "In this article, we propose a Statistical Cloud-Assisted Reputation Estimation (sCARE) approach for service-oriented environments in uncertain situations. sCARE uses the ratings from cooperating service consumers to uniformly describe the randomness and fuzziness of the different submitted ratings and their associated relationships in quantitative terms. We also define discriminant functions to model the honesty (or lack thereof) of the service raters. Experiment results show that our proposed model performs in a fairly accurate manner for a number of real-world scenarios. A comparison study with similar existing works is also provided to asses sCARE’s performance.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2293009724",
    "type": "article"
  },
  {
    "title": "On Optimizing Transaction Fees in Bitcoin using AI: Investigation on Miners Inclusion Pattern",
    "doi": "https://doi.org/10.1145/3528669",
    "publication_date": "2022-04-09",
    "publication_year": 2022,
    "authors": "Enrico Tedeschi; Tor-Arne S. Nordmo; Dag Johansen; Håvard D. Johansen",
    "corresponding_authors": "",
    "abstract": "The transaction-rate bottleneck built into popular proof-of-work (PoW)-based cryptocurrencies, like Bitcoin and Ethereum, leads to fee markets where transactions are included according to a first-price auction for block space. Many attempts have been made to adjust and predict the fee volatility, but even well-formed transactions sometimes experience unexpected delays and evictions unless a substantial fee is offered. In this article, we propose a novel transaction inclusion model that describes the mechanisms and patterns governing miners decisions to include individual transactions in the Bitcoin system. Using this model we devise a Machine Learning (ML) approach to predict transaction inclusion. We evaluate our predictions method using historical observations of the Bitcoin network from a five month period that includes more than 30 million transactions and 120 million entries. We find that our Machine Learning (ML) model can predict fee volatility with an accuracy of up to 91%. Our findings enable Bitcoin users to improve their fee expenses and the approval time for their transactions.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4225674040",
    "type": "article"
  },
  {
    "title": "Special Issue on Foundations of Social Computing",
    "doi": "https://doi.org/10.1145/2700057",
    "publication_date": "2015-03-12",
    "publication_year": 2015,
    "authors": "Nicolas Kourtellis; Jeremy Blackburn; Cristian Borcea; Adriana Iamnitchi",
    "corresponding_authors": "",
    "abstract": "An unprecedented information wealth produced by online social networks, further augmented by location/collocation data, is currently fragmented across different proprietary services. Combined, it can accurately represent the social world and enable novel socially-aware applications. We present Prometheus, a socially-aware peer-to-peer service that collects social information from multiple sources into a multigraph managed in a decentralized fashion on user-contributed nodes, and exposes it through an interface implementing non-trivial social inferences while complying with user-defined access policies. Simulations and experiments on PlanetLab with emulated application workloads show the system exhibits good end-to-end response time, low communication overhead and resilience to malicious attacks.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4299332662",
    "type": "article"
  },
  {
    "title": "Attacking DoH and ECH: Does Server Name Encryption Protect Users’ Privacy?",
    "doi": "https://doi.org/10.1145/3570726",
    "publication_date": "2022-11-09",
    "publication_year": 2022,
    "authors": "Martino Trevisan; Francesca Soro; Marco Mellia; Idílio Drago; Ricardo Morla",
    "corresponding_authors": "",
    "abstract": "Privacy on the Internet has become a priority, and several efforts have been devoted to limit the leakage of personal information. Domain names, both in the TLS Client Hello and DNS traffic, are among the last pieces of information still visible to an observer in the network. The Encrypted Client Hello extension for TLS, DNS over HTTPS or over QUIC protocols aim to further increase network confidentiality by encrypting the domain names of the visited servers. In this article, we check whether an attacker able to passively observe the traffic of users could still recover the domain name of websites they visit even if names are encrypted. By relying on large-scale network traces, we show that simplistic features and off-the-shelf machine learning models are sufficient to achieve surprisingly high precision and recall when recovering encrypted domain names. We consider three attack scenarios, i.e., recovering the per-flow name, rebuilding the set of visited websites by a user, and checking which users visit a given target website. We next evaluate the efficacy of padding-based mitigation, finding that all three attacks are still effective, despite resources wasted with padding. We conclude that current proposals for domain encryption may produce a false sense of privacy, and more robust techniques should be envisioned to offer protection to end users.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4308650955",
    "type": "article"
  },
  {
    "title": "Securing Scalable Real-time Multiparty Communications with Hybrid Information-centric Networking",
    "doi": "https://doi.org/10.1145/3593585",
    "publication_date": "2023-04-19",
    "publication_year": 2023,
    "authors": "Luca Muscariello; Michele Papalini; Olivier Roques; Mauro Sardara; Arthur Tran Van",
    "corresponding_authors": "",
    "abstract": "In this article, we consider security aspects of online meeting applications based on protocols such as WebRTC that leverage the Information-centric Networking (ICN) architecture to make the system fundamentally more scalable. If the scalability properties provided by ICN have been proved in recent literature, the security challenges and implications for real-time applications have not been reviewed. We show that this class of applications can benefit from strong security and scalability jointly without any major tradeoff and with significant performance improvements over traditional WebRTC systems. To achieve this goal, some modifications to the current ICN architecture must be implemented in the way integrity and authentication are verified. Extensive performance analysis of the architecture based on the open source implementation of Hybrid-ICN proves that real-time applications can greatly benefit from this novel network architecture in terms of strong security and scalable communications.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4366407853",
    "type": "article"
  },
  {
    "title": "Polarized Communities Search via Co-guided Random Walk in Attributed Signed Networks",
    "doi": "https://doi.org/10.1145/3613449",
    "publication_date": "2023-10-07",
    "publication_year": 2023,
    "authors": "Fanyi Yang; Huifang Ma; Cairui Yan; Zhixin Li; Liang Chang",
    "corresponding_authors": "",
    "abstract": "Polarized communities search aims at locating query-dependent communities, in which mostly nodes within each community form intensive positive connections, while mostly nodes across two communities are connected by negative links. Current approaches towards polarized communities search typically model the network topology, while the key factor of node, i.e., the attributes, are largely ignored. Existing studies have shown that community formation is strongly influenced by node attributes and the formation of communities are determined by both network topology and node attributes simultaneously. However, it is nontrivial to incorporate node attributes for polarized communities search. Firstly, it is hard to handle the heterogeneous information from node attributes. Secondly, it is difficult to model the complex relations between network topology and node attributes in identifying polarized communities. To address the above challenges, we propose a novel method Co-guided Random Walk in Attributed signed networks (CoRWA) for polarized communities search by equipping with reasonable attribute setting. For the first challenge, we devise an attribute-based signed network to model the auxiliary relation between nodes and a weight assignment mechanism is designed to measure the reliability of the edges in the signed network. As to the second challenge, a co-guided random walk scheme in two signed networks is designed to explicitly model the relations between topology-based signed network and attribute-based signed network so as to enhance the search result of each other. Finally, we can identify polarized communities by a well-designed Rayleigh quotient in the signed network. Extensive experiments on three real-world datasets demonstrate the effectiveness of the proposed CoRWA. Further analysis reveals the significance of node attributes for polarized communities search.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4387426038",
    "type": "article"
  },
  {
    "title": "Positional Encoding-based Resident Identification in Multi-resident Smart Homes",
    "doi": "https://doi.org/10.1145/3631353",
    "publication_date": "2023-11-02",
    "publication_year": 2023,
    "authors": "Zhiyi Song; Dipankar Chaki; Abdallah Lakhdari; Athman Bouguettaya",
    "corresponding_authors": "",
    "abstract": "We propose a novel resident identification framework to identify residents in a multi-occupant smart environment. The proposed framework employs a feature extraction model based on the concepts of positional encoding. The feature extraction model considers the locations of homes as a graph. We design a novel algorithm to build such graphs from layout maps of smart environments. The Node2Vec algorithm is used to transform the graph into high-dimensional node embeddings. A Long Short-Term Memory model is introduced to predict the identities of residents using temporal sequences of sensor events with the node embeddings. Extensive experiments show that our proposed scheme effectively identifies residents in a multi-occupant environment. Evaluation results on two real-world datasets demonstrate that our proposed approach achieves 94.5% and 87.9% accuracy, respectively.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4388229949",
    "type": "article"
  },
  {
    "title": "DxHash: A Memory-saving Consistent Hashing Algorithm",
    "doi": "https://doi.org/10.1145/3631708",
    "publication_date": "2023-11-03",
    "publication_year": 2023,
    "authors": "Chao Dong; Fang Wang; Dan Feng",
    "corresponding_authors": "",
    "abstract": "Consistent Hashing (CH) algorithms are widely adopted in networks and distributed systems for their ability to achieve load balancing and minimize disruptions. However, the rise of the Internet of Things (IoT) has introduced new challenges for existing CH algorithms, characterized by high memory usage and update overhead. This article presents DxHash, a novel CH algorithm based on repeated pseudo-random number generation. DxHash offers significant benefits, including a remarkably low memory footprint, high lookup throughput, and minimal update overhead. Additionally, we introduce a weighted variant of DxHash, enabling adaptable weight adjustments to handle heterogeneous load distribution. Through extensive evaluation, we demonstrate that DxHash outperforms AnchorHash, a state-of-the-art CH algorithm, in terms of the reduction of up to 98.4% in memory footprint and comparable performance in lookup and update.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4388281995",
    "type": "article"
  },
  {
    "title": "The Internet's role in offshored services",
    "doi": "https://doi.org/10.1145/1275505.1275508",
    "publication_date": "2007-08-01",
    "publication_year": 2007,
    "authors": "Rafiq Dossani; Nathan Denny",
    "corresponding_authors": "",
    "abstract": "Using India as a case study, this article analyzes how the Internet influenced its export-oriented software industry. We show that prior to the Internet, domestic entrepreneurship was the key factor for the industry's origin and growth. The industry suffered from relatively low value-addition. As a result, domestic firms, though they were industry leaders within India, were followers of the global leadership provided by transnational firms. With the arrival of the Internet, there was a rise in the level of domain expertise. We show that the Internet facilitated the transfer of domain expertise for foreign firms more than it helped the acquisition of domain expertise by domestic firms. While the value-addition of the industry increased as a result, industry leadership began to pass to foreign firms. The strategic lesson for other countries trying to rapidly develop an export-oriented software industry is unambiguous: exclusive reliance on domestic entrepreneurship will usually result in the domestic industry falling behind its global competitors, while granting unrestricted entry to transnational firms will lead to the domestic firms losing industry leadership in most cases.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2060082796",
    "type": "article"
  },
  {
    "title": "Towards the taxonomy-oriented categorization of yellow pages queries",
    "doi": "https://doi.org/10.1145/2109211.2109213",
    "publication_date": "2008-03-23",
    "publication_year": 2008,
    "authors": "Zhisheng Li; Xiangye Xiao; Meng Wang; Chong Wang; Xufa Wang; Xing Xie",
    "corresponding_authors": "",
    "abstract": "Yellow pages search is a popular service that provides a means for finding businesses close to particular locations. The efficient search of yellow pages is becoming a rapidly evolving research area. The underlying data maintained in yellow pages search engines are typically labeled according to Standard Industry Classification (SIC) categories, and users can search yellow pages with categories according to their interests. Categorizing yellow pages queries into a subset of topical categories can help to improve search experience and quality. However, yellow pages queries are usually short and ambiguous. In addition, a yellow pages query taxonomy is typically organized by a hierarchy of a fairly large number of categories. These characteristics make automatic yellow pages query categorization difficult and challenging. In this article, we propose a flexible yellow pages query categorization approach. The proposed technique is built based on a TF-IDF similarity taxonomy matching scheme that is able to provide more accurate query categorization than previous keyword-based matching schemes. To further improve the categorization performance, we design several filtering schemes. Through extensive experimentation, we demonstrate encouraging results. We obtain F1 measures of about 0.5 and 0.3 for categorizing yellow pages queries into 19 coarse categories and 244 finer categories, respectively. We investigate different components in the proposed approach and also demonstrate the superiority of our approach over a hierarchical support vector machine classifier.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2027754581",
    "type": "article"
  },
  {
    "title": "Multi-Objective Optimization of Deployment Topologies for Distributed Applications",
    "doi": "https://doi.org/10.1145/3106158",
    "publication_date": "2018-01-20",
    "publication_year": 2018,
    "authors": "Felix Willnecker; Helmut Krcmar",
    "corresponding_authors": "",
    "abstract": "Modern applications are typically implemented as distributed systems comprising several components. Deciding where to deploy which component is a difficult task that today is usually assisted by logical topology recommendations. Choosing inefficient topologies allocates the wrong amount of resources, leads to unnecessary operation costs, or results in poor performance. Testing different topologies to find good solutions takes a lot of time and might delay productive operations. Therefore, this work introduces a software-based deployment topology optimization approach for distributed applications. We use an enhanced performance model generator that extracts models from operational monitoring data of running applications. The extracted model is used to simulate performance metrics (e.g., resource utilization, response times, throughput) and runtime costs of distributed applications. Subsequently, we introduce a deployment topology optimizer, which selects an optimized topology for a specified workload and considers on-premise, cloud, and hybrid topologies. The following three optimization goals are presented in this work: (i) minimum response time for an optimized user experience, (ii) approximate resource utilization around certain peaks, and (iii) minimum cost for running the application. To evaluate the approach, we use the SPECjEnterpriseNEXT industry benchmark as distributed application in an on-premise and in a cloud/on-premise hybrid environment. The evaluation demonstrates the accuracy of the simulation compared to the actual deployment by deploying an optimized topology and comparing measurements with simulation results.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2783573548",
    "type": "article"
  },
  {
    "title": "Genetic Algorithms for Solving Problems of Access Control Design and Reconfiguration in Computer Networks",
    "doi": "https://doi.org/10.1145/3093898",
    "publication_date": "2018-03-06",
    "publication_year": 2018,
    "authors": "Igor Saenko; Igor Kotenko",
    "corresponding_authors": "",
    "abstract": "To create solutions for providing the required access control in computer networks it is not sufficient to have only tools and protocols in the network that are needed for it. It is necessary to create corresponding configuration, or scheme, of such tools, which will allow us to satisfy the existing security requirements. At the same time, the problems of creating an access control scheme, as a rule, are NP-complete and require heuristic models for their solving. In this article, we propose a unified approach to creation of control access schemes, based on usage of genetic algorithms. The approach is applied not only to original schemes configuration but to reconfiguration as well. Successful testing of the suggested approach on RBAC, VLAN, and VPN schemes allows us to suppose that it may be applied to other types of access control schemes as well. Experimental testing of suggested genetic algorithms, performed on a specially designed test bed, showed their sufficiently high efficiency.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2791324781",
    "type": "article"
  },
  {
    "title": "Enhanced Audit Strategies for Collaborative and Accountable Data Sharing in Social Networks",
    "doi": "https://doi.org/10.1145/3134439",
    "publication_date": "2018-04-24",
    "publication_year": 2018,
    "authors": "Leila Bahri; Barbara Carminati; Elena Ferrari; Andrea Bianco",
    "corresponding_authors": "",
    "abstract": "Data sharing and access control management is one of the issues still hindering the development of decentralized online social networks (DOSNs), which are now gaining more research attention with the recent developments in P2P computing, such as the secure public ledger–based protocols (Blockchains) for monetary systems. In a previous work, we proposed an initial audit–based model for access control in DOSNs. In this article, we focus on enhancing the audit strategies and the privacy issues emerging from records kept for audit purposes. We propose enhanced audit and collaboration strategies, for which experimental results, on a real online social network graph with simulated sharing behavior, show an improvement in the detection rate of bad behavior of more than 50% compared to the basic model. We also provide an analysis of the related privacy issues and discuss possible privacy-preserving alternatives.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2799462542",
    "type": "article"
  },
  {
    "title": "Providing Geo-Elasticity in Geographically Distributed Clouds",
    "doi": "https://doi.org/10.1145/3169794",
    "publication_date": "2018-04-17",
    "publication_year": 2018,
    "authors": "Tian Guo; Prashant Shenoy",
    "corresponding_authors": "",
    "abstract": "Geographically distributed cloud platforms are well suited for serving a geographically diverse user base. However, traditional cloud provisioning mechanisms that make local scaling decisions are not adequate for delivering the best possible performance for modern web applications that observe both temporal and spatial workload fluctuations. We propose GeoScale, a system that provides geo-elasticity by combining model-driven proactive and agile reactive provisioning approaches. GeoScale can dynamically provision server capacity at any location based on workload dynamics. We conduct a detailed evaluation of GeoScale on Amazon’s geo-distributed cloud and show up to 40% improvement in the 95th percentile response time when compared to traditional elasticity techniques.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2799524990",
    "type": "article"
  },
  {
    "title": "Fine-grained Emotion Role Detection Based on Retweet Information",
    "doi": "https://doi.org/10.1145/3191820",
    "publication_date": "2018-10-16",
    "publication_year": 2018,
    "authors": "Zhiwen Yu; Fei Yi; Chao Ma; Zhu Wang; Bin Guo; Liming Chen",
    "corresponding_authors": "",
    "abstract": "User behaviors in online social networks convey not only literal information but also one’s emotional attitudes towards the information. To compute this attitude, we define the concept of emotion role as the concentrated reflection of a user’s online emotional characteristics. Emotion role detection aims to better understand the structure and sentiments of online social networks and support further analysis, e.g., revealing public opinions, providing personalized recommendations, and detecting influential users. In this article, we first introduce the definition of a fine-grained emotion role, which consists of two dimensions: emotion orientation (i.e., positive, negative, and neutral) and emotion influence (i.e., leader and follower). We then propose a Multi-dimensional Emotion Role Mining model (MERM) to determine a user’s emotion role in online social networks. Specifically, we tend to identify emotion roles by combining a set of features that reflect a user’s online emotional status, including degree of emotional characteristics, accumulated emotion preference, structural factor, temporal factor, and emotion change factor. Experiment results on a real-life micro-blog reposting dataset show that the classification accuracy of the proposed model can achieve up to 90.1%.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2800931784",
    "type": "article"
  },
  {
    "title": "Making Constrained Things Reachable",
    "doi": "https://doi.org/10.1145/3230640",
    "publication_date": "2018-10-05",
    "publication_year": 2018,
    "authors": "Oscar Novo",
    "corresponding_authors": "Oscar Novo",
    "abstract": "The widespread adoption of the Internet of Things (IoT) has created a demand for ubiquitous connectivity of IoT devices into the Internet. While end-to-end connectivity for IoT requires in practice IPv6, a vast majority of nodes in Internet are only IPv4-capable. To address this issue, the use of Network Address Translation (NAT) at the IoT network boundary becomes necessary. However, the constrained nature of the IoT devices hinders the integration of traditional NAT traversal architectures through IoT networks. In this article, we introduce a novel transition mechanism that transparently enables IoT devices behind NATs to connect across different network-layer infrastructures. Our mechanism adopts the IoT standards to provide a global connectivity solution in a transparent, secure, and elegant way. Additionally, we revisit the NAT solutions for IoT and describe and evaluate our current implementation.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2895442027",
    "type": "article"
  },
  {
    "title": "CAN-TM",
    "doi": "https://doi.org/10.1145/3341732",
    "publication_date": "2019-09-19",
    "publication_year": 2019,
    "authors": "Manel Mrabet; Yosra Ben Saied; Leı̈la Azouz Saı̈dane",
    "corresponding_authors": "",
    "abstract": "The increasing proliferation of Cloud Services (CSs) has made the reliable CS selection problem a major challenge. To tackle this problem, this article introduces a new trust model called Chain Augmented Naïve Bayes-based Trust Model (CAN-TM). This model leverages the correlation that may exist among QoS attributes to solve many issues in reliable CS selection challenge, such as predicting missing assessments and improving accuracy of trust computing. This is achieved by combining both the n-gram Markov model and the Naïve Bayes model. Experiments are conducted to validate that our proposed CAN-TM outperforms state-of-the-art approaches.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2973280498",
    "type": "article"
  },
  {
    "title": "Secure DNA Motif-Finding Method Based on Sampling Candidate Pruning",
    "doi": "https://doi.org/10.1145/3382078",
    "publication_date": "2020-07-07",
    "publication_year": 2020,
    "authors": "Kaijian Xia; Xiang Wu; Yaqing Mao; Huanhuan Wang",
    "corresponding_authors": "",
    "abstract": "With the continuous exploration of genetic research, gradually exposed privacy issues become the bottleneck that limits its development. DNA motif finding is an important study to understand the regulation of gene expression; however, the existing methods generally ignore the potential sensitive information that may be exposed in the process. In this work, we utilize the <?TeX $\\varepsilon $?> -differential privacy model to provide provable privacy guarantees which is independent of attackers’ background knowledge. Our method makes use of sample databases to prune the generated candidate motifs to lower the magnitude of added noise. Furthermore, to improve the utility of mining results, a strategy of threshold modification is designed to reduce the propagation and random sampling errors in the mining process. Extensive experiments on actual DNA databases confirm that our approach can privately find DNA motifs with high utility and efficiency.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W3041095024",
    "type": "article"
  },
  {
    "title": "Overexposure-Aware Influence Maximization",
    "doi": "https://doi.org/10.1145/3408315",
    "publication_date": "2020-10-06",
    "publication_year": 2020,
    "authors": "Grigorios Loukides; Robert Gwadera; Shing‐Wan Chang",
    "corresponding_authors": "",
    "abstract": "Viral marketing campaigns are often negatively affected by overexposure. Overexposure occurs when users become less likely to favor a promoted product after receiving information about the product from too large a fraction of their friends. Yet, existing influence diffusion models do not take overexposure into account, effectively overestimating the number of users who favor the product and diffuse information about it. In this work, we propose the first influence diffusion model that captures overexposure. In our model, Latency Aware Independent Cascade Model with Overexposure (LAICO), the activation probability of a node representing a user is multiplied (discounted) by an overexposure score, which is calculated based on the ratio between the estimated and the maximum possible number of attempts performed to activate the node. We also study the influence maximization problem under LAICO. Since the spread function in LAICO is non-submodular, algorithms for submodular maximization are not appropriate to address the problem. Therefore, we develop an approximation algorithm that exploits monotone submodular upper and lower bound functions of spread, and a heuristic that aims to maximize a proxy function of spread iteratively. Our experiments show the effectiveness and efficiency of our algorithms.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W3092513036",
    "type": "article"
  },
  {
    "title": "Design and Implementation of a Compressed Certificate Status Protocol",
    "doi": "https://doi.org/10.1145/3392096",
    "publication_date": "2020-07-07",
    "publication_year": 2020,
    "authors": "Michalis Pachilakis; Antonios A. Chariton; Panagiotis Papadopoulos; Panagiotis Ilia; Eirini Degkleri; Evangelos P. Markatos",
    "corresponding_authors": "",
    "abstract": "Trust in Secure Sockets Layer–based communications is traditionally provided by Certificate (or Certification) Authorities (CAs) in the form of signed certificates. Checking the validity of a certificate involves three steps: (i) checking its expiration date, (ii) verifying its signature, and (iii) ensuring that it is not revoked. Currently, such certificate revocation checks (i.e., step (iii) above) are done either via Certificate Revocation Lists (CRLs), or Online Certificate Status Protocol (OCSP) servers. Unfortunately, despite the existence of these revocation checks, sophisticated cyber-attackers can still trick web browsers to trust a revoked certificate, believing that it is still valid. Although frequently updated , nonced , and timestamped certificates can reduce the frequency and impact of such cyber-attacks, they add a huge burden to the CAs and OCSP servers. Indeed, CAs and/or OCSP servers need to timestamp and sign on a regular basis all the responses, for every certificate they have issued, resulting in a very high overhead. To mitigate this and provide a solution to the described cyber-attacks, we present CCSP : a new approach to provide timely information regarding the status of certificates, which capitalizes on a newly introduced notion called Signed Collections . In this article, we present in detail the notion of Signed Collections and the complete design, implementation, and evaluation of our approach. Performance evaluation shows that CCSP (i) reduces space requirements by more than an order of magnitude, (ii) lowers the number of signatures required by six orders of magnitude compared to OCSP-based methods, and (iii) adds only a few milliseconds of overhead in the overall user latency.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W3108502598",
    "type": "article"
  },
  {
    "title": "DataOps for Cyber-Physical Systems Governance: The Airport Passenger Flow Case",
    "doi": "https://doi.org/10.1145/3432247",
    "publication_date": "2021-05-03",
    "publication_year": 2021,
    "authors": "Martín Garriga; Koen Aarns; Christos Tsigkanos; Damian A. Tamburri; Wjan Van Den Heuvel",
    "corresponding_authors": "",
    "abstract": "Recent advancements in information technology have ushered a new wave of systems integrating Internet technology with sensing, wireless communication, and computational resources over existing infrastructures. As a result, myriad complex, non-traditional Cyber-Physical Systems (CPS) have emerged, characterized by interaction among people, physical facilities, and embedded sensors and computers, all generating vast amounts of complex data. Such a case is encountered within a contemporary airport hall setting: passengers roaming, information systems governing various functions, and data being generated and processed by cameras, phones, sensors, and other Internet of Things technology. This setting has considerable potential of contributing to goals entertained by the CPS operators, such as airlines, airport operators/owners, technicians, users, and more. We model the airport setting as an instance of such a complex, data-intensive CPS where multiple actors and data sources interact, and generalize a methodology to support it and other similar systems. Furthermore, this article instantiates the methodology and pipeline for predictive analytics for passenger flow, as a characteristic manifestation of such systems requiring a tailored approach. Our methodology also draws from DataOps principles, using multi-modal and real-life data to predict the underlying distribution of the passenger flow on a flight-level basis (improving existing day-level predictions), anticipating when and how the passengers enter the airport and move through the check-in and baggage drop-off process. This allows to plan airport resources more efficiently while improving customer experience by avoiding passenger clumping at check-in and security. We demonstrate results obtained over a case from a major international airport in the Netherlands, improving up to 60% upon predictions of daily passenger flow currently in place.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W3157251419",
    "type": "article"
  },
  {
    "title": "Introduction to the Special Issue on Decentralized Blockchain Applications and Infrastructures for Next Generation Cyber-Physical Systems",
    "doi": "https://doi.org/10.1145/3464768",
    "publication_date": "2021-06-15",
    "publication_year": 2021,
    "authors": "Kim‐Kwang Raymond Choo; Uttam Ghosh; Deepak K. Tosh; Reza M. Parizi; Ali Dehghantanha",
    "corresponding_authors": "",
    "abstract": "introduction Introduction to the Special Issue on Decentralized Blockchain Applications and Infrastructures for Next Generation Cyber-Physical Systems Share on Editors: Kim Kwang Raymond Choo University of Texas at San Antonio University of Texas at San AntonioView Profile , Uttam Ghosh Vanderbilt University Vanderbilt UniversityView Profile , Deepak Tosh University of Texas El Paso University of Texas El PasoView Profile , Reza M. Parizi Kennesaw State University Kennesaw State UniversityView Profile , Ali Dehghantanha University of Guelph University of GuelphView Profile Authors Info & Claims ACM Transactions on Internet TechnologyVolume 21Issue 2June 2021 Article No.: 38epp 1–3https://doi.org/10.1145/3464768Online:15 June 2021Publication History 0citation68DownloadsMetricsTotal Citations0Total Downloads68Last 12 Months68Last 6 weeks5 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteGet Access",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W3172529863",
    "type": "article"
  },
  {
    "title": "Adaptive Management of Volatile Edge Systems at Runtime With Satisfiability",
    "doi": "https://doi.org/10.1145/3470658",
    "publication_date": "2021-09-14",
    "publication_year": 2021,
    "authors": "Cosmin Avasalcai; Christos Tsigkanos; Schahram Dustdar",
    "corresponding_authors": "",
    "abstract": "Edge computing offers the possibility of deploying applications at the edge of the network. To take advantage of available devices’ distributed resources, applications often are structured as microservices, often having stringent requirements of low latency and high availability. However, a decentralized edge system that the application may be intended for is characterized by high volatility, due to devices making up the system being unreliable or leaving the network unexpectedly. This makes application deployment and assurance that it will continue to operate under volatility challenging. We propose an adaptive framework capable of deploying and efficiently maintaining a microservice-based application at runtime, by tackling two intertwined problems: (i) finding a microservice placement across device hosts and (ii) deriving invocation paths that serve it. Our objective is to maintain correct functionality by satisfying given requirements in terms of end-to-end latency and availability, in a volatile edge environment. We evaluate our solution quantitatively by considering performance and failure recovery.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W3201267215",
    "type": "article"
  },
  {
    "title": "Introduction to the Special Section on Cognitive Robotics on 5G/6G Networks",
    "doi": "https://doi.org/10.1145/3476466",
    "publication_date": "2021-09-28",
    "publication_year": 2021,
    "authors": "Huimin Lu; Liao Wu; Giancarlo Fortino; Schahram Dustdar",
    "corresponding_authors": "",
    "abstract": "introduction Share on Introduction to the Special Section on Cognitive Robotics on 5G/6G Networks Authors: Huimin Lu Kyushu Institute of Technology, Japan Kyushu Institute of Technology, JapanView Profile , Liao Wu University of New South Wales, Australia University of New South Wales, AustraliaView Profile , Giancarlo Fortino University of Calabria (Unical), Italy University of Calabria (Unical), ItalyView Profile , Schahram Dustdar Vienna University of Technology, Austria Vienna University of Technology, AustriaView Profile Authors Info & Claims ACM Transactions on Internet TechnologyVolume 21Issue 4November 2021 Article No.: 91epp 1–3https://doi.org/10.1145/3476466Published:28 September 2021Publication History 1citation36DownloadsMetricsTotal Citations1Total Downloads36Last 12 Months26Last 6 weeks2 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my Alerts New Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteGet Access",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W3204526566",
    "type": "article"
  },
  {
    "title": "A Novel Real-time Anti-spam Framework",
    "doi": "https://doi.org/10.1145/3423153",
    "publication_date": "2021-09-28",
    "publication_year": 2021,
    "authors": "Di Wu; Wei Shi; Xiangyu Ma",
    "corresponding_authors": "",
    "abstract": "As one of the most pervasive current modes of communication, email needs to be fast and reliable. However, spammers and attackers use it as a primary channel to conduct illegal activities. Although many approaches have been developed and evaluated for spam detection, they do not provide sufficient accuracy. This deficiency results in significant economic losses for organizations. In this article, we first propose a framework for creating novel spam filters using Keras to combine a Convolutional Neural Network (CNN) with Long Short-Term Memory (LSTM) classification models. We then use this framework to introduce a specific solution applicable to realistic scenarios involving dynamic incoming email data in real-time. This solution takes the form of a real-time content-based spam classifier. We evaluate its performance concerning accuracy, precision, recall, false-positive, and false-negative rates. Our experimental results show that our approach can significantly outperform existing solutions for real-time spam detection.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W3204617018",
    "type": "article"
  },
  {
    "title": "Progressive Random Indexing",
    "doi": "https://doi.org/10.1145/2996185",
    "publication_date": "2017-03-24",
    "publication_year": 2017,
    "authors": "Michał Ciesielczyk; Andrzej Szwabe; Mikołaj Morzy; Paweł Misiorek",
    "corresponding_authors": "",
    "abstract": "The vector space model is undoubtedly among the most popular data representation models used in the processing of large networks. Unfortunately, the vector space model suffers from the so-called curse of dimensionality, a phenomenon where data become extremely sparse due to an exponential growth of the data space volume caused by a large number of dimensions. Thus, dimensionality reduction techniques are necessary to make large networks represented in the vector space model available for analysis and processing. Most dimensionality reduction techniques tend to focus on principal components present in the data, effectively disregarding local relationships that may exist between objects. This behavior is a significant drawback of current dimensionality reduction techniques, because these local relationships are crucial for maintaining high accuracy in many network analysis tasks, such as link prediction or community detection. To rectify the aforementioned drawback, we propose Progressive Random Indexing, a new dimensionality reduction technique. Built upon Reflective Random Indexing, our method significantly reduces the dimensionality of the vector space model while retaining all important local relationships between objects. The key element of the Progressive Random Indexing technique is the use of the gain value at each reflection step, which determines how much information about local relationships should be included in the space of reduced dimensionality. Our experiments indicate that when applied to large real-world networks (Facebook social network, MovieLens movie recommendations), Progressive Random Indexing outperforms state-of-the-art methods in link prediction tasks.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2601049585",
    "type": "article"
  },
  {
    "title": "S <scp>pinel</scp>",
    "doi": "https://doi.org/10.1145/3041025",
    "publication_date": "2017-03-27",
    "publication_year": 2017,
    "authors": "Benjamin Billet; Valérie Issarny",
    "corresponding_authors": "",
    "abstract": "Nowadays, various static wireless sensor networks (WSN) are deployed in the environment for many purposes: traffic control, pollution monitoring, and so on. The willingness to open these legacy WSNs to the users is emerging, by integrating them to the Internet network as part of the future Internet of Things (IoT), for example, in the context of smart cities and open data policies. While legacy sensors cannot be directly connected to the Internet in general, emerging standards such as 6LoWPAN are aimed at solving this issue but require us to update or replace the existing devices. As a solution to connect legacy sensors to the IoT, we propose to take advantage of the multi-modal connectivity as well as the mobility of smartphones to use phones as opportunistic proxies , that is, mobile proxies that opportunistically discover closeby static sensors and act as intermediaries with the IoT, with the additional benefit of bringing fresh information about the environment to the smartphones’ owners. However, this requires us to monitor the smartphone’s mobility and further infer when to discover and register the sensors to guarantee the efficiency and reliability of opportunistic proxies. To that end, we introduce and evaluate an approach based on mobility analysis that uses a novel path prediction technique to predict when and where the user is not moving, and thereby serves to anticipate the registration of sensors within communication range. We show that this technique enables the deployment of low-cost resource-efficient mobile proxies to connect legacy WSNs with the IoT.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2601742950",
    "type": "article"
  },
  {
    "title": "Statistical Learning of Domain-Specific Quality-of-Service Features from User Reviews",
    "doi": "https://doi.org/10.1145/3053381",
    "publication_date": "2017-05-05",
    "publication_year": 2017,
    "authors": "Xumin Liu; Weishi Shi; Arpeet Kale; Chen Ding; Qi Yu",
    "corresponding_authors": "",
    "abstract": "With the fast increase of online services of all kinds, users start to care more about the Quality of Service (QoS) that a service provider can offer besides the functionalities of the services. As a result, QoS-based service selection and recommendation have received significant attention since the mid-2000s. However, existing approaches primarily consider a small number of standard QoS parameters, most of which relate to the response time, fee, availability of services, and so on. As online services start to diversify significantly over different domains, these small set of QoS parameters will not be able to capture the different quality aspects that users truly care about over different domains. Most existing approaches for QoS data collection depend on the information from service providers, which are sensitive to the trustworthiness of the providers. Some service monitoring mechanisms collect QoS data through actual service invocations but may be affected by actual hardware/software configurations. In either case, domain-specific QoS data that capture what users truly care about have not been successfully collected or analyzed by existing works in service computing. To address this demanding issue, we develop a statistical learning approach to extract domain-specific QoS features from user-provided service reviews. In particular, we aim to classify user reviews based on their sentiment orientations into either a positive or negative category. Meanwhile, statistical feature selection is performed to identify statistically nontrivial terms from review text, which can serve as candidate QoS features. We also develop a topic models-based approach that automatically groups relevant terms and returns the term groups to users, where each term group corresponds to one high-level quality aspect of services. We have conducted extensive experiments on three real-world datasets to demonstrates the effectiveness of our approach.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2612360215",
    "type": "article"
  },
  {
    "title": "Argumentation in Social Media",
    "doi": "https://doi.org/10.1145/3056539",
    "publication_date": "2017-06-27",
    "publication_year": 2017,
    "authors": "Iryna Gurevych; Marco Lippi; Paolo Torroni",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2724934507",
    "type": "article"
  },
  {
    "title": "Supporting ad-hoc resource sharing on the Web",
    "doi": "https://doi.org/10.1145/1239971.1239975",
    "publication_date": "2007-05-01",
    "publication_year": 2007,
    "authors": "Jing Zhou; Wendy Hall; David De Roure; Vijay Dialani",
    "corresponding_authors": "",
    "abstract": "The key element to support ad-hoc resource sharing on the Web is to discover resources of interest. The hypermedia paradigm provides a way of overlaying a set of resources with additional information in the form of links to help people find other resources. However, existing hypermedia approaches primarily develop mechanisms to enable resource sharing in a fairly static, centralized way. Recent developments in distributed computing, on the other hand, introduced peer-to-peer (P2P) computing that is notable for employing distributed resources to perform a critical function in a more dynamic and ad-hoc scenario. We investigate the feasibility and potential benefits of bringing together the P2P paradigm with the concept of hypermedia link services to implement ad-hoc resource sharing on the Web. This is accomplished by utilizing a web-based Distributed Dynamic Link Service (DDLS) as a testbed and addressing the issues arising from the design, implementation, and enhancement of the service. Our experimental result reveals the behavior and performance of the semantics-based resource discovery in DDLS and demonstrates that the proposed enhancing technique for DDLS, topology reorganization, is appropriate and efficient.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2134161914",
    "type": "article"
  },
  {
    "title": "Detection of corrupted schema mappings in XML data integration systems",
    "doi": "https://doi.org/10.1145/1592446.1592448",
    "publication_date": "2009-09-01",
    "publication_year": 2009,
    "authors": "Dario Colazzo; Carlo Sartiani",
    "corresponding_authors": "",
    "abstract": "In modern data integration scenarios, many remote data sources are located on the Web and are accessible only through forms or Web services, and no guarantee is given about their stability. In these contexts the detection of corrupted mappings, as a consequence of a change in the source or in the target schema, is a key problem. A corrupted mapping fails in matching the target or the source schema, hence it is not able to transform data conforming to a schema S into data conforming to a schema T, nor it can be used for effective query reformulation. This article describes a novel technique for maintaining schema mappings in XML data integration systems, based on a notion of mapping correctness relying on the denotational semantics of mappings.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W1978714923",
    "type": "article"
  },
  {
    "title": "Controlling entity state updates to maintain remote consistency within a distributed interactive application",
    "doi": "https://doi.org/10.1145/1592446.1592449",
    "publication_date": "2009-09-01",
    "publication_year": 2009,
    "authors": "Alan Kenny; Séamus McLoone; Tomás Ward",
    "corresponding_authors": "",
    "abstract": "One of the ongoing challenges for Distributed Interactive Applications (DIAs) is balancing the quality of service delivered to the end user with the operational costs involved. In particular the resultant network traffic should be minimized without affecting the end user experience where possible. This article proposes the use of remote feedback as a method of maintaining a desired consistency level within a peer-to-peer DIA. Though many existing techniques attempt to maintain consistency within a DIA, they operate in an open-loop manner and do not take error introduced into the system due to transmission delay into consideration. The goal of the work presented in this article is to transform this open-loop scheme into a closed-loop control system utilizing feedback from the remote users. By incorporating remote error into the systems update paradigm, the Protocol Data Unit (PDU) transmission rate can be dynamically altered to reflect changing network conditions. The performance of the resultant closed-loop control system is presented within.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W1993681597",
    "type": "article"
  },
  {
    "title": "A Provenance-Aware Multi-dimensional Reputation System for Online Rating Systems",
    "doi": "https://doi.org/10.1145/3183323",
    "publication_date": "2018-09-30",
    "publication_year": 2018,
    "authors": "Mohsen Rezvani; Aleksandar Ignjatović; Elisa Bertino",
    "corresponding_authors": "",
    "abstract": "Online rating systems are widely accepted as means for quality assessment on the web and users increasingly rely on these systems when deciding to purchase an item online. This makes such rating systems frequent targets of attempted manipulation by posting unfair rating scores. Therefore, providing useful, realistic rating scores as well as detecting unfair behavior are both of very high importance. Existing solutions are mostly majority based, also employing temporal analysis and clustering techniques. However, they are still vulnerable to unfair ratings. They also ignore distances between options, the provenance of information, and different dimensions of cast rating scores while computing aggregate rating scores and trustworthiness of users. In this article, we propose a robust iterative algorithm which leverages information in the profile of users and provenance of information, and which takes into account the distance between options to provide both more robust and informative rating scores for items and trustworthiness of users. We also prove convergence of iterative ranking algorithms under very general assumptions, which are satisfied by the algorithm proposed in this article. We have implemented and tested our rating method using both simulated data as well as four real-world datasets from various applications of reputation systems. The experimental results demonstrate that our model provides realistic rating scores even in the presence of a massive amount of unfair ratings and outperforms the well-known ranking algorithms.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2895211130",
    "type": "article"
  },
  {
    "title": "Guest Editors’ Introduction to the Special Issue on Fog, Edge, and Cloud Integration for Smart Environments",
    "doi": "https://doi.org/10.1145/3319404",
    "publication_date": "2019-04-12",
    "publication_year": 2019,
    "authors": "Francesco Longo; Antonio Puliafito; Omer Rana",
    "corresponding_authors": "",
    "abstract": "editorial Free Access Share on Guest Editors’ Introduction to the Special Issue on Fog, Edge, and Cloud Integration for Smart Environments Authors: Francesco Longo Università degli Studi di Messina, Italy Università degli Studi di Messina, ItalyView Profile , Antonio Puliafito Università degli Studi di Messina, Italy Università degli Studi di Messina, ItalyView Profile , Omer Rana Cardiff University, UK Cardiff University, UKView Profile Authors Info & Claims ACM Transactions on Internet TechnologyVolume 19Issue 2May 2019 Article No.: 17pp 1–4https://doi.org/10.1145/3319404Published:12 April 2019Publication History 4citation490DownloadsMetricsTotal Citations4Total Downloads490Last 12 Months56Last 6 weeks2 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteView all FormatsPDF",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2935942569",
    "type": "article"
  },
  {
    "title": "Social Network De-anonymization",
    "doi": "https://doi.org/10.1145/3310363",
    "publication_date": "2019-05-16",
    "publication_year": 2019,
    "authors": "Jianwei Qian; Xiang‐Yang Li; Taeho Jung; Fan Yang; Yu Wang; Shaojie Tang",
    "corresponding_authors": "",
    "abstract": "Previous works on social network de-anonymization focus on designing accurate and efficient de-anonymization methods. We attempt to investigate the intrinsic relationship between the attacker’s knowledge and the expected de-anonymization gain. A common intuition is that more knowledge results in more successful de-anonymization. However, our analysis shows this is not necessarily true if the attacker uses the full background knowledge for de-anonymization. Our findings leave intriguing implications for the attacker to make better use of the background knowledge for de-anonymization and for the data owners to better measure the privacy risk when releasing their data to third parties.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2964211797",
    "type": "article"
  },
  {
    "title": "To Transmit or Not to Transmit",
    "doi": "https://doi.org/10.1145/3369389",
    "publication_date": "2020-08-12",
    "publication_year": 2020,
    "authors": "Kakia Panagidi; Christos Anagnostopoulos; A. Chalvatzaras; Stathes Hadjiefthymiades",
    "corresponding_authors": "",
    "abstract": "The Mobile IoT domain has been significantly expanded with the proliferation of drones and unmanned robotic devices. In this new landscape, the communication between the resource-constrained device and the fixed infrastructure is similarly expanded to include new messages of varying importance, control, and monitoring. To efficiently and effectively control the exchange of such messages subject to the stochastic nature of the underlying wireless network, we design a time-optimized, dynamic, and distributed decision-making mechanism based on the principles of the Optimal Stopping and Change Detection theories. The findings from our experimentation platform are promising and solidly supportive to a vast spectrum of real-time and latency-sensitive applications with quality-of-service requirements in mobile IoT environments.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W3005925948",
    "type": "article"
  },
  {
    "title": "Cloud Deployment Tradeoffs for the Analysis of Spatially Distributed Internet of Things Systems",
    "doi": "https://doi.org/10.1145/3381452",
    "publication_date": "2020-05-03",
    "publication_year": 2020,
    "authors": "Christos Tsigkanos; Martín Garriga; Luciano Baresi; Carlo Ghezzi",
    "corresponding_authors": "",
    "abstract": "Internet-enabled devices operating in the physical world are increasingly integrated in modern distributed systems. We focus on systems where the dynamics of spatial distribution is crucial; in such cases, devices may need to carry out complex computations (e.g., analyses) to check satisfaction of spatial requirements. The requirements are partly global—as the overall system should achieve certain goals—and partly individual, as each entity may have different goals. Assurance may be achieved by keeping a model of the system at runtime, monitoring events that lead to changes in the spatial environment, and performing requirements analysis. However, computationally intensive runtime spatial analysis cannot be supported by resource-constrained devices and may be offloaded to the cloud. In such a scenario, multiple challenges arise regarding resource allocation, cost, performance, among other dimensions. In particular, when the workload is unknown at the system’s design time, it may be difficult to guarantee application-service-level agreements, e.g., on response times. To address and reason on these challenges, we first instantiate complex computations as microservices and integrate them to an IoT-cloud architecture. Then, we propose alternative cloud deployments for such an architecture—based on virtual machines, containers, and the recent Functions-as-a-Service paradigm. Finally, we assess the feasibility and tradeoffs of the different deployments in terms of scalability, performance, cost, resource utilization, and more. We adopt a workload scenario from a known dataset of taxis roaming in Beijing, and we derive other workloads to represent unexpected request peaks and troughs. The approach may be replicated in the design process of similar classes of spatially distributed IoT systems.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W3018058290",
    "type": "article"
  },
  {
    "title": "Fine-Grained Network Analysis for Modern Software Ecosystems",
    "doi": "https://doi.org/10.1145/3418209",
    "publication_date": "2020-12-10",
    "publication_year": 2020,
    "authors": "Paolo Boldi; Georgios Gousios",
    "corresponding_authors": "",
    "abstract": "Modern software development is increasingly dependent on components, libraries, and frameworks coming from third-party vendors or open-source suppliers and made available through a number of platforms (or forges ). This way of writing software puts an emphasis on reuse and on composition, commoditizing the services that modern applications require. On the other hand, bugs and vulnerabilities in a single library living in one such ecosystem can affect, directly or by transitivity, a huge number of other libraries and applications. Currently, only product-level information on library dependencies is used to contain this kind of danger, but this knowledge often reveals itself too imprecise to lead to effective (and possibly automated) handling policies. We will discuss how fine-grained function-level dependencies can greatly improve reliability and reduce the impact of vulnerabilities on the whole software ecosystem.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W3112266208",
    "type": "article"
  },
  {
    "title": "A Blockchain-based Iterative Double Auction Protocol Using Multiparty State Channels",
    "doi": "https://doi.org/10.1145/3389249",
    "publication_date": "2020-07-07",
    "publication_year": 2020,
    "authors": "Truc Nguyen; My T. Thai",
    "corresponding_authors": "",
    "abstract": "Although the iterative double auction has been widely used in many different applications, one of the major problems in its current implementations is that they rely on a trusted third party to handle the auction process. This imposes the risk of single point of failures, monopoly, and bribery. In this article, we aim to tackle this problem by proposing a novel decentralized and trustless framework for iterative double auction based on blockchain. Our design adopts the smart contract and state channel technologies to enable a double auction process among parties that do not need to trust each other, while minimizing the blockchain transactions. In specific, we propose an extension to the original concept of state channels that can support multiparty computation. Then, we provide a formal development of the proposed framework and prove the security of our design against adversaries. Finally, we develop a proof-of-concept implementation of our framework using Elixir and Solidity, on which we conduct various experiments to demonstrate its feasibility and practicality.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W3124316770",
    "type": "article"
  },
  {
    "title": "Influence of Search Neutrality on the Economics of Advertisement-Financed Content",
    "doi": "https://doi.org/10.1145/2663490",
    "publication_date": "2014-10-28",
    "publication_year": 2014,
    "authors": "Pierre Coucheney; Giuseppe D’Acquisto; Patrick Maillé; Maurizio Naldi; Bruno Tuffin",
    "corresponding_authors": "",
    "abstract": "The search neutrality debate questions the ranking methods of search engines. We analyze the issue when content providers offer content for free, but get revenues from advertising. We investigate the noncooperative game among competing content providers under different ranking policies. When the search engine is not involved with high-quality content providers, it should adopt neutral ranking, also maximizing user quality-of-experience. If the search engine controls high-quality content, favoring its ranking and adding advertisement yield a larger revenue. Though user perceived quality may not be impaired, the advertising revenues of the other content providers drastically decrease.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W1991928173",
    "type": "article"
  },
  {
    "title": "Context-sensitive user interfaces for semantic services",
    "doi": "https://doi.org/10.1145/2078316.2078322",
    "publication_date": "2012-01-01",
    "publication_year": 2012,
    "authors": "Wanita Sherchan; ‪Surya Nepal‬; Athman Bouguettaya; Shiping Chen",
    "corresponding_authors": "",
    "abstract": "Service-centric solutions usually require rich context to fully deliver and better reflect on the underlying applications. We present a novel use of context in the form of customized user interface services with the concept of User Interface as a Service (UIaaS). UIaaS takes user profiles as input to generate context-aware interface services. Such interface services can be used as context to augment semantic services with contextual information leading to UIaaS as a Context (UIaaSaaC). The added serendipitous benefit of the proposed concept is that the composition of a customized user interface with the requested service is performed by the service composition engine, as is the case with any other services. We use a special-purpose language (called User Interface Description Language (UIDL)) to model and realize user interfaces as services. We use a real-life e-government application, human services delivery for the citizens, as a proof-of-concept. We also present a comprehensive evaluation of the proposed approach using a functional evaluation and a nonfunctional evaluation consisting of an end user usability test and expert usability reviews.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2023831620",
    "type": "article"
  },
  {
    "title": "User-perceived quality assessment of streaming media using reduced feature sets",
    "doi": "https://doi.org/10.1145/2049656.2049660",
    "publication_date": "2011-12-01",
    "publication_year": 2011,
    "authors": "Amy Csizmar Dalal",
    "corresponding_authors": "Amy Csizmar Dalal",
    "abstract": "While subjective measurements are the most natural for assessing the user-perceived quality of a media stream, there are issues with their scalability and their context accuracy. We explore techniques to select application-layer measurements, collected by an instrumented media player, that most accurately predict the subjective quality rating that a user would assign to a stream. We consider three feature subset selection techniques that reduce the number of features (measurements) under consideration to ones most relevant to user-perceived stream quality. Two of the three techniques mathematically consider stream characteristics when selecting measurements, while the third is based on observation. We apply the reduced feature sets to two nearest-neighbor algorithms for predicting user-perceived stream quality. Our results demonstrate that there are clear strategies for estimating the quality rating that work well in specific circumstances such as video-on-demand services. The results also demonstrate that neither of the mathematically-based feature subset selection techniques identify a single set of features that is unambiguously influential on user-perceived stream quality, but that ultimately a combination of retransmitted and/or lost application-layer packets is most accurate for predicting stream quality.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2063240101",
    "type": "article"
  },
  {
    "title": "Introduction to special issue on context-aware web services for the future internet",
    "doi": "https://doi.org/10.1145/2078316.2078317",
    "publication_date": "2012-01-01",
    "publication_year": 2012,
    "authors": "Quan Z. Sheng; Schahram Dustdar",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2072386104",
    "type": "article"
  },
  {
    "title": "Neural Network Pruning by Recurrent Weights for Finance Market",
    "doi": "https://doi.org/10.1145/3433547",
    "publication_date": "2022-01-22",
    "publication_year": 2022,
    "authors": "Songwen Pei; Y. Wu; Jin Guo; Meikang Qiu",
    "corresponding_authors": "",
    "abstract": "Convolutional Neural Networks (CNNs) and deep learning technology are applied in current financial market to rapidly promote the development of finance market and Internet economy. The continuous development of neural networks with more hidden layers improves the performance but increases the computational complexity. Generally, channel pruning methods are useful to compact neural networks. However, typical channel pruning methods would remove layers by mistake due to the static pruning ratio of manual setting, which could destroy the whole structure of neural networks. It is difficult to improve the ratio of compressing neural networks only by pruning channels while maintaining good network structures. Therefore, we propose a novel neural Networks Pruning by Recurrent Weights ( NPRW ) that can repeatedly evaluate the significance of weights and adaptively adjust them to compress neural networks within acceptable loss of accuracy. The recurrent weights with low sensitivity are compulsorily set to zero by evaluating the magnitude of weights, and pruned network only uses a few significant weights. Then, we add the regularization to the scaling factors on neural networks, in which recurrent weights with high sensitivity can be dynamically updated and weights of low sensitivity stay at zero invariably. By this way, the significance of channels can be quantitatively evaluated by recurrent weights. It has been verified with typical neural networks of LeNet, VGGNet, and ResNet on multiple benchmark datasets involving stock index futures, digital recognition, and image classification. The pruned LeNet-5 achieves the 58.9% reduction amount of parameters with 0.29% loss of total accuracy for Shanghai and Shenzhen 300 stock index futures. As for the CIFAR-10, the pruned VGG-19 reduces more than 50% FLOPs, and the decrease of network accuracy is less than 0.5%. In addition, the pruned ResNet-164 tested on the SVHN reduces more than 58% FLOPs with relative improvement on accuracy by 0.11%.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4206960885",
    "type": "article"
  },
  {
    "title": "A Reputation-based Framework for Honest Provenance Reporting",
    "doi": "https://doi.org/10.1145/3507908",
    "publication_date": "2022-02-03",
    "publication_year": 2022,
    "authors": "Lina Barakat; Phillip Taylor; Nathan Griffiths; Simon Miles",
    "corresponding_authors": "",
    "abstract": "Given the distributed, heterogenous, and dynamic nature of service-based IoT systems, capturing circumstances data underlying service provisions becomes increasingly important for understanding process flow and tracing how outputs came about, thus enabling clients to make more informed decisions regarding future interaction partners. Whilst service providers are the main source of such circumstances data, they may often be reluctant to release it, e.g., due to the cost and effort required, or to protect their interests. In response, this article introduces a reputation-based framework, guided by intelligent software agents, to support the sharing of truthful circumstances information by providers. In this framework, assessor agents , acting on behalf of clients, rank and select service providers according to reputation, while provider agents , acting on behalf of service providers, learn from the environment and adjust provider’s circumstances provision policies in the direction that increases provider profit with respect to perceived reputation. The novelty of the reputation assessment model adopted by assessor agents lies in affecting provider reputation scores by whether or not they reveal truthful circumstances data underlying their service provisions, in addition to other factors commonly adopted by existing reputation schemes. The effectiveness of the proposed framework is demonstrated through an agent-based simulation including robustness against a number of attacks, with a comparative performance analysis against FIRE as a baseline reputation model.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4210537773",
    "type": "article"
  },
  {
    "title": "Conditional Identity Privacy-preserving Authentication Scheme Based on Cooperation of Multiple Fog Servers under Fog Computing-based IoVs",
    "doi": "https://doi.org/10.1145/3538381",
    "publication_date": "2022-05-18",
    "publication_year": 2022,
    "authors": "Zhuoqun Xia; Lingxuan Zeng; Ke Gu; Xiong Li; Weijia Jia",
    "corresponding_authors": "",
    "abstract": "Internet of vehicles (IoVs) is a variant of vehicular ad hoc network, which provides an efficient communication method for vehicles. However, some traffic messages usually include sensitive identity information, which is easy to bring about the leakage of vehicular identities during data communications. Further, if vehicular identities are fully protected, then it can lead to trusted authority cannot reveal the real identities of malicious vehicles, which incurs more security issues in IoVs. Therefore, in this article, we propose an efficient conditional identity privacy-preserving authentication scheme based on cooperation of multiple fog servers under fog computing-based IoVs, where fog servers are used to verify (authenticate) the legitimacy of vehicles without revealing their real identities. Further, an associated vehicular identity updating mechanism is constructed to solve the problem that some compromised fog servers may leak their stored verification information to pool real vehicular identities. Additionally, a malicious vehicular identity tracing mechanism is proposed to support related fog servers that receive signed false messages can trace the real identities of malicious vehicles. Compared with other related schemes, our scheme further improves its security. Experimental results show our scheme is efficient under fog computing-based IoVs.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4280512585",
    "type": "article"
  },
  {
    "title": "White Box: On the Prediction of Collaborative Filtering Recommendation Systems’ Performance",
    "doi": "https://doi.org/10.1145/3554979",
    "publication_date": "2022-08-12",
    "publication_year": 2022,
    "authors": "Iulia Paun; Yashar Moshfeghi; Nikos Ntarmos",
    "corresponding_authors": "",
    "abstract": "Collaborative Filtering (CF) recommendation algorithms are a popular solution to the information overload problem, aiding users in the item selection process. Relevant research has long focused on refining and improving these models to produce better (more effective) recommendations, and has converged on a methodology to predict their effectiveness on target datasets by evaluating them on random samples of the latter. However, predicting the efficiency of the solutions—especially with regard to their time- and resource-hungry training phase, whose requirements dwarf those of the prediction/recommendation phase—has received little to no attention in the literature. This article addresses this gap for a number of representative and highly popular CF models, including algorithms based on matrix factorization, k-nearest neighbors, co-clustering, and slope one schemes. To this end, we first study the computational complexity of the training phase of said CF models and derive time and space complexity equations. Then, using characteristics of the input and the aforementioned equations, we contribute a methodology for predicting the processing time and memory usage of their training phase. Our contributions further include an adaptive sampling strategy, to address the tradeoff between resource usage costs and prediction accuracy, and a framework that quantifies both the efficiency and effectiveness of CF. Finally, a systematic experimental evaluation demonstrates that our method outperforms state-of-the-art regression schemes by a considerable margin, with an overhead that is a small fraction of the overall requirements of CF training.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4291143771",
    "type": "article"
  },
  {
    "title": "Audio-Visual Event Localization using Multi-task Hybrid Attention Networks for Smart Healthcare Systems",
    "doi": "https://doi.org/10.1145/3653018",
    "publication_date": "2024-03-16",
    "publication_year": 2024,
    "authors": "Han Liang; Jincai Chen; Fazlullah Khan; Gautam Srivastava; Jiangfeng Zeng",
    "corresponding_authors": "",
    "abstract": "Human perception heavily relies on two primary senses: vision and hearing, which are closely inter-connected and capable of complementing each other. Consequently, various multimodal learning tasks have emerged, with audio-visual event localization (AVEL) being a prominent example. AVEL is a popular task within the realm of multimodal learning, with the primary objective of identifying the presence of events within each video segment and predicting their respective categories. This task holds significant utility in domains such as healthcare monitoring and surveillance, among others. Generally speaking, audio-visual co-learning offers a more comprehensive information landscape compared to single-modal learning, as it allows for a more holistic perception of ambient information, aligning with real-world applications. Nevertheless, the inherent heterogeneity of audio and visual data can introduce challenges related to event semantics inconsistency, potentially leading to incorrect predictions. To track these challenges, we propose a multi-task hybrid attention network (MHAN) to acquire high-quality representation for multimodal data. Specifically, our network incorporates hybrid attention of uni- and parallel cross-modal (HAUC) modules, which consists of a uni-modal attention block and a parallel cross-modal attention block, leveraging multimodal complementary and hidden information for better representation. Furthermore, we advocate for the use of a uni-modal visual task as auxiliary supervision to enhance the performance of multimodal tasks employing a multi-task learning strategy. Our proposed model has been proven to outperform the state-of-the-art results based on extensive experiments conducted on the AVE dataset.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4392885584",
    "type": "article"
  },
  {
    "title": "Multi-Think Transformer for Enhancing Emotional Health",
    "doi": "https://doi.org/10.1145/3652512",
    "publication_date": "2024-03-18",
    "publication_year": 2024,
    "authors": "Jiarong Wang; Jiaji Wu; Shaohong Chen; Xiangyu Han; Mingzhou Tan; Jianguo Yu",
    "corresponding_authors": "",
    "abstract": "The smart healthcare system not only focuses on physical health but also on emotional health. Music therapy, as a non-pharmacological treatment method, has been widely used in clinical treatment, but music selection and generation still require manual intervention. AI music generation technology can assist people in relieving stress and providing more personalized and efficient music therapy support. However, existing AI music generation highly relies on the note generated at the current time to produce the note at the next time. This will lead to disharmonious results. The first reason is the small errors being ignored at the current generated note. This error will accumulate and spread continuously, and finally make the music become random. To solve this problem, we propose a music selection module to filter the errors of generated note. The multi-think mechanism is proposed to filter the result multiple times, so that the generated note is as accurate as possible, eliminating the impact of the results on the next generation process. The second reason is that the results of multiple generation of each music clip are not the same or even do not follow the same music rules. Therefore, in the inference phase, a voting mechanism is proposed in this paper to select the note that follow the music rules that most experimental results follow as the final result. The subjective and objective evaluations demonstrate the superiority of our proposed model in generation of more smooth music that conforms to music rules. This model provides strong support for clinical music therapy, and provides new ideas for the research and practice of emotional health therapy based on the Internet of Things.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4392915630",
    "type": "article"
  },
  {
    "title": "VORTEX : Visual phishing detectiOns aRe Through EXplanations",
    "doi": "https://doi.org/10.1145/3654665",
    "publication_date": "2024-03-28",
    "publication_year": 2024,
    "authors": "Fabien Charmet; Tomohiro Morikawa; Akira Tanaka; Takeshi Takahashi",
    "corresponding_authors": "",
    "abstract": "Phishing attacks reached a record high in 2022, as reported by the Anti-Phishing Work Group, following an upward trend accelerated during the pandemic. Attackers employ increasingly sophisticated tools in their attempts to deceive unaware users into divulging confidential information. Recently, the research community has turned to the utilization of screenshots of legitimate and malicious websites to identify the brands that attackers aim to impersonate. In the field of Computer Vision, convolutional neural networks (CNNs) have been employed to analyze the visual rendering of websites, addressing the problem of phishing detection. However, along with the development of these new models, arose the need to understand their inner workings and the rationale behind each prediction. Answering the question, “How is this website attempting to steal the identity of a well-known brand?” becomes crucial when protecting end-users from such threats. In cybersecurity, the application of explainable AI (XAI) is an emerging approach that aims to answer such questions. In this article, we propose VORTEX, a phishing website detection solution equipped with the capability to explain how a screenshot attempts to impersonate a specific brand. We conduct an extensive analysis of XAI methods for the phishing detection problem and demonstrate that VORTEX provides meaningful explanations regarding the detection results. Additionally, we evaluate the robustness of our model against Adversarial Example attacks. We adapt these attacks to the VORTEX architecture and evaluate their efficacy across multiple models and datasets. Our results show that VORTEX achieves superior accuracy compared to previous models, and learns semantically meaningful patterns to provide actionable explanations about phishing websites. Finally, VORTEX demonstrates an acceptable level of robustness against adversarial example attacks.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4393278007",
    "type": "article"
  },
  {
    "title": "EdgeCI: Distributed Workload Assignment and Model Partitioning for CNN Inference on Edge Clusters",
    "doi": "https://doi.org/10.1145/3656041",
    "publication_date": "2024-05-06",
    "publication_year": 2024,
    "authors": "Yanming Chen; Tong Luo; Weiwei Fang; Naixue Xiong",
    "corresponding_authors": "",
    "abstract": "Deep learning technology has grown significantly in new application scenarios such as smart cities and driverless vehicles, but its deployment needs to consume a lot of resources. It is usually difficult to execute inference task solely on resource-constrained Intelligent Internet-of-Things (IoT) devices to meet strictly service delay requirements. CNN-based inference task is usually offloaded to the edge server or cloud. However, it may lead to unstable performance and privacy leaks. To address the above challenges, this article aims to design a low latency distributed inference framework, EdgeCI, which assigns inference tasks to locally idle, connected, and resource-constrained IoT device cluster networks. EdgeCI exploits two key optimization knobs, including: (1) Auction-based Workload Assignment Scheme (AWAS), which achieves the workload balance by assigning each workload partition to the more matching IoT device; (2) Fused-Layer parallelization strategy based on non-recursive Dynamic Programming (DPFL), which is aimed at further minimizing the inference time. We have implemented EdgeCI based on PyTorch and evaluated its performance with VGG-16 and ResNet-34 image recognition models. The experimental results prove that our proposed AWAS and DPFL outperform the typical state-of-the-art solutions. When they are well combined, EdgeCI can improve inference speed by 34.72% to 43.52%. EdgeCI outperforms the state-of-the art approaches on our edge cluster.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4393422150",
    "type": "article"
  },
  {
    "title": "Interpersonal Communication Interconnection in Media Convergence Metaverse",
    "doi": "https://doi.org/10.1145/3670998",
    "publication_date": "2024-06-05",
    "publication_year": 2024,
    "authors": "Xin Wei Wang; Jianhui Lv; Achyut Shankar; Carsten Maple; Keqin Li; Qing Li",
    "corresponding_authors": "",
    "abstract": "The metaverse aims to provide immersive virtual worlds connecting with the physical world. To enable real-time interpersonal communications between users across the globe, the metaverse places high demands on network performance, including low latency, high bandwidth, and fast network speeds. This paper proposes a novel Media Convergence Metaverse Network (MCMN) framework to address these challenges. Specifically, the META controller serves as MCMN's logically centralized control plane, responsible for holistic orchestration across edge sites and end-to-end path computation between metaverse users. We develop a model-free deep reinforcement learning-based metaverse traffic optimization algorithm that learns to route flows while satisfying the Quality of Service (QoS) boundaries. The network slicing engine leverages artificial intelligence and machine learning to create isolated, customized virtual networks tailored for metaverse traffic dynamics on demand. It employs unsupervised and reinforcement learning techniques using network telemetry from the META controller to understand application traffic patterns and train cognitive slicer agents to make quality of service -aware decisions accordingly. Optimized delivery of diverse concurrent media types necessitates routing intelligence to meet distinct requirements while mitigating clashes over a shared infrastructure. Media-aware routing enhances traditional shortest-path approaches by combining topological metrics with workflow sensitivities. We realize an edge-assisted rendering fabric to offload complex processing from bandwidth-constrained endpoints while retaining visual realism. Extensive simulations demonstrate MCMN's superior performance compared to conventional networking paradigms. MCMN shows great promise to enable seamless interconnectivity and ultra-high fidelity communications to unlock the true potential of the metaverse.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4399361326",
    "type": "article"
  },
  {
    "title": "DeGONet: Decentralized Group-Oriented Interconnection Network for IoT-enabled Metaverse",
    "doi": "https://doi.org/10.1145/3674972",
    "publication_date": "2024-06-27",
    "publication_year": 2024,
    "authors": "Sining Jiang; Xu Cheng; Hong‐Ning Dai; Shuo Zhao; Yujun Lan; Haoran Xie; Xiaohui Tao; Zhongwen Guo",
    "corresponding_authors": "",
    "abstract": "As a transformative technology across various industries, the metaverse has emerged to connect the physical world with the virtual world. During this process, the Internet of Things (IoT) has played a critical role in achieving effective cyber-physical interaction. However, its prevalent centralized interconnection architectures encounter challenges related to interoperability and data privacy, consequently limiting their full potential in human-to-human interactions. To address these challenges, this paper introduces a novel decentralized group-oriented data interconnection network for IoT systems, abbreviated as DeGONet. We propose a group-based trust management model to facilitate user adaptability in data-sharing practices. Additionally, we present a new interaction paradigm based on smart contracts and oracles. Recognizing the potential latency and scalability limitations of existing blockchain structures in large-scale data integration, we devise a novel blockchain structure called Direct Acyclic Graph Tree (DAG-Tree) and a novel consensus mechanism, Proof-of-Verification. These contributions enhance data security while mitigating the hardware and development costs associated with decentralized systems. Through rigorous performance analysis and comparative experiments, we validate the effectiveness and efficiency of our proposed framework in large-scale data interconnection scenarios.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4400089392",
    "type": "article"
  },
  {
    "title": "Exposing Stealthy Wash Trading on Automated Market Maker Exchanges",
    "doi": "https://doi.org/10.1145/3689631",
    "publication_date": "2024-08-23",
    "publication_year": 2024,
    "authors": "Rundong Gan; Le Wang; Liang Xue; Xiaodong Lin",
    "corresponding_authors": "",
    "abstract": "Decentralized Finance (DeFi), a pivotal component of the emerging Web3 landscape, is gaining popularity but remains vulnerable to market manipulations, such as wash trading. Wash trading is an illegal practice, where traders buy and sell assets to themselves within cryptocurrency exchanges to artificially inflate trading volumes and distort market perceptions. However, current research primarily focuses on traditional exchanges based on the Order-book mechanism (similar to stock markets), while ignoring the Automated Market Maker (AMM) exchanges, which dominate over 75% of the market and represent a significant innovation within the DeFi. This study utilizes entity recognition technology to detect wash trading on AMM exchanges within Ethereum-like systems, based on the understanding that colluding addresses (perceived as the same entity) must use ETH for transaction fees and exhibit direct or indirect ETH transfer links. We identify wash trading when addresses with transfer connections almost simultaneously buy and sell assets while their total asset holdings remain nearly constant. This comprehensive blockchain network analysis, compared to focusing solely on transactions within exchanges, unveils covert wash trading activities. Our detection method achieves a 95.9% recall and a 96.7% true negative rate in identifying pools affected by wash trading, demonstrating its superiority over existing methods. Furthermore, we apply our method to 98,945 pools from Uniswap V2 &amp; V3 (the most popular AMM exchanges on Ethereum) and identify 1,070,626 abnormal transactions, totaling $27.51 billion in trading volume. Analysis of these transactions uncovers insights into wash traders’ behaviors, including the utilization of multiple addresses and the dual roles of certain addresses as wash traders and liquidity providers. These insights are crucial for developing more effective strategies to combat fraudulent activities in the DeFi ecosystem and enhance financial scrutiny.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4401814899",
    "type": "article"
  },
  {
    "title": "RFL-LSU: A Robust Federated Learning Approach with Localized Stepwise Updates",
    "doi": "https://doi.org/10.1145/3690822",
    "publication_date": "2024-08-30",
    "publication_year": 2024,
    "authors": "Shuming Fan; Hongjian Shi; Chuanjia Wang; Ruhui Ma; Xiaoming Wang",
    "corresponding_authors": "",
    "abstract": "Distributed intelligence enables the widespread deployment of AI technology, greatly promoting the development of AI. Federated learning is a widely used distributed intelligence technology that allows iterative optimization of global model while protecting user data privacy. Currently, federated learning faces some security threats, as its open architecture provides attackers with opportunities to disrupt the learning process by submitting malicious updates or inserting backdoors. In this paper, we propose a robust federated learning method to defend against potential malicious attacks. Specifically, we enhance the algorithm’s performance and stability by implementing localized stepwise updates on the client side and element-wise anomaly detection on the server side. We conducted experiments in a more realistic non i.i.d. scenario and compared the results with other typical federated learning methods. Our results demonstrate that our approach exhibits strong robustness under non i.i.d. data distributions, outperforming other methods in terms of test accuracy and resilience to attacks.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4402059876",
    "type": "article"
  },
  {
    "title": "Conscious Task Recommendation via Cognitive Reasoning Computing in Mobile Crowd Sensing",
    "doi": "https://doi.org/10.1145/3694786",
    "publication_date": "2024-09-04",
    "publication_year": 2024,
    "authors": "Jia Liu; Jian Wang; Guosheng Zhao",
    "corresponding_authors": "",
    "abstract": "Mobile Crowd Sensing is a human-based data collection model, and the approach taken to recommend data collection tasks to users in order to maximize task acceptance rates is an important part of this research. Existing task recommendation methods are based only on intuitive data for unconscious analysis and decision-making, and lack the embodiment of cognitive intelligence. To address the above problem, a conscious task recommendation based on cognitive reasoning computing in Mobile Crowd Sensing has been proposed, using knowledge from cognitive science to simulate the human thinking process in order to achieve warm learning and conscious recommendation of sensing tasks. First, the task attributes are segmented into positive and negative attributes using a Kernel Density Estimation method based on bandwidth self-selection. Then, the user's attribute preferences are diagnosed by the Cognitive Diagnostic Method to obtain the user's preference vector. Finally, get the overall preference trend of users based on the Drift Diffusion Model, and make decisions according to whether the current task drift direction is consistent with the user preference trend. Simulation experiments were conducted using the Taobao dataset, MTurk dataset, and synthetic dataset, it was ultimately proven that conscious task recommendation combined with user cognitive ability effectively reduced RMSE and improved task acceptance rate. RMSE was 10.5%∼70.8% lower than other methods, and the task acceptance rate was basically over 80%, with most of the results being over 90%.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4402234790",
    "type": "article"
  },
  {
    "title": "Hybrid Algorithm Selection and Hyperparameter Tuning on Distribute Machine Learning Resources: Hierarchical Agent-based Approach",
    "doi": "https://doi.org/10.1145/3697834",
    "publication_date": "2024-09-26",
    "publication_year": 2024,
    "authors": "Ahmad Esmaeili; Julia Taylor Rayz; Eric T. Matson",
    "corresponding_authors": "",
    "abstract": "Algorithm selection and hyperparameter tuning are critical steps in both academic and applied machine learning. These steps are becoming increasingly delicate due to the extensive rise in the number, diversity, and distributed nature of machine learning resources. Multi-agent systems, when applied to the design of machine learning platforms, bring about several distinctive characteristics such as scalability, flexibility, and robustness, just to name a few. This paper proposes a fully automatic and collaborative agent-based mechanism for selecting distributed machine learning algorithms and simultaneously tuning their hyperparameters. Our method builds upon an existing agent-based hierarchical machine-learning platform and augments its query structure to support the aforementioned functionalities without being limited to specific learning, selection, and tuning mechanisms. We have conducted theoretical assessments, formal verification, and analytical study to demonstrate the correctness, resource utilization, and computational efficiency of our technique. According to the results, our solution is algorithmically correct and exhibits linear time and space complexity in relation to the size of available resources. To further verify its correctness and demonstrate its effectiveness and flexibility across a range of algorithmic options and datasets, the paper also presents a series of empirical results on a system comprised of 24 algorithms and 9 datasets. The findings not only highlight the efficiency and scalability of the proposed approach, but also show its flexibility and openness to respond to the dynamic and distributed ML ecosystem.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4402870588",
    "type": "article"
  },
  {
    "title": "Optimizing Effectiveness and Defense of Drone Surveillance Missions via Honey Drones",
    "doi": "https://doi.org/10.1145/3701233",
    "publication_date": "2024-10-25",
    "publication_year": 2024,
    "authors": "Zelin Wan; Jin-Hee Cho; Mu Zhu; Ahmed Hemida; Charles Kamhoua; Munindar P. Singh",
    "corresponding_authors": "",
    "abstract": "This work aims to develop a surveillance mission system using unmanned aerial vehicles (UAVs) or drones when Denial-of-Service (DoS) attacks are present to disrupt normal operations for mission systems. In particular, we introduce the concept of cyber deception using honey drones (HDs) to protect the mission system from DoS attacks. HDs exhibit fake vulnerabilities and employ stronger signal strengths to lure DoS attacks, unlike the legitimate drones called mission drones (MDs) deployed for mission execution. This research formulates an optimization problem to identify an optimal set of signal strengths of HDs and MDs to best prevent the system from DoS attacks while maximizing mission performance under the resource constraints of UAVs. To solve this optimization problem, we leverage deep reinforcement learning (DRL) to achieve these multiple objectives of the mission system concerning system security and performance. Particularly, for efficient and effective parallel processing in DRL, we utilize a DRL algorithm called the Asynchronous Advantage Actor-Critic (A3C) algorithm to model attack-defense interactions. We employ a physical engine-based simulation testbed to consider realistic scenarios and demonstrate valid findings from the realistic testbed. The extensive experiments proved that our HD-based approach could achieve up to a 32% increase in mission completion, a 20% reduction in energy consumption, and a 62% decrease in attack success rates compared to existing defense strategies.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4403748025",
    "type": "article"
  },
  {
    "title": "Affinity-based management of main memory database clusters",
    "doi": "https://doi.org/10.1145/604596.604599",
    "publication_date": "2002-11-01",
    "publication_year": 2002,
    "authors": "Minwen Ji",
    "corresponding_authors": "Minwen Ji",
    "abstract": "We study management strategies for main memory database clusters that are interposed between Internet applications and back-end databases as content caches. The task of management is to allocate data across individual cache databases and to route queries to the appropriate databases for execution. The goal is to maximize effective cache capacity and to minimize synchronization cost. We propose an affinity-based management system for main memory database cLUsters ( ALBUM ). ALBUM executes each query in two stages in order to take advantage of the query affinity that is observed in a wide range of applications. We evaluate the data/query distribution strategy in ALBUM with a set of trace-based simulations. The results show that ALBUM reduces cache miss ratio by a factor of 1.7 to 9 over alternative strategies. We have implemented a prototype of ALBUM, and compare its performance to that of an existing infrastructure: a fully replicated database with large buffer cache. The results show that ALBUM outperforms the existing infrastructure with the same number of server machines by a factor of 2 to 7, and that ALBUM with only 1/3 to 1/2 of the server machines achieves the same throughput as the existing infrastructure.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W1997687389",
    "type": "article"
  },
  {
    "title": "Evaluating the competitive effects of mergers of internet backbone providers",
    "doi": "https://doi.org/10.1145/572326.572327",
    "publication_date": "2002-08-01",
    "publication_year": 2002,
    "authors": "Stanley M. Besen; Jeffrey S. Spigel; Padmanabhan Srinagesh",
    "corresponding_authors": "",
    "abstract": "This article analyzes the usefulness of the traffic measurement methodologies used by the European Commission (EC) and the United States Department of Justice (DOJ) in assessing the competitive effects of mergers of Internet backbone providers. The analysis concludes that the traffic ratios used by the EC to estimate market shares when it reviewed the merger application of MCI and WorldCom, and by the EC and the DOJ when they reviewed the proposed merger of Sprint and MCI WorldCom, have significant limitations. In particular, the article shows that these measurements provide a potentially misleading picture of the effect of a merger of backbone providers, even under the assumption that the Internet is a rigid hierarchy, and that this problem is likely to become worse as the use of secondary peering, multihoming, and intelligent content distribution services become more widespread.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2048393641",
    "type": "article"
  },
  {
    "title": "Portlet syndication",
    "doi": "https://doi.org/10.1145/1111627.1111630",
    "publication_date": "2005-11-01",
    "publication_year": 2005,
    "authors": "Óscar Díaz; Juan J. Rodríguez",
    "corresponding_authors": "",
    "abstract": "A Portlet is a multistep, user-facing application delivered through a Web application (e.g., a portal). OASIS approved standard, WSRP, is an attempt to standardize the interface between the provider and the consumer of the Portlet. This initiative promotes Portlet interoperability, componentware practices, and the existence of a Portlet market. This work argues that the diversity of the settings where a Portlet might be syndicated recommends that Portlets be instrumented for variability, and this, in turn, demands a product-line approach. This work introduces a new source of variability, the “interaction lifecycle”, a description of the visible flow of a Portlet, and shows how this feature can be adapted to cater to the idiosyncrasies of the hosting application. Distinct variants are identified that permit the consumer to customize the presentation, content, and links of the Portlet markup in a controlled way. The use of product-line techniques allow the consumer to cope with this variability in a cost-effective manner. The article ends by illustrating how the extensible capabilities of WSRP are used to accomodate this process.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2069587868",
    "type": "article"
  },
  {
    "title": "Energy and SLA-driven MapReduce Job Scheduling Framework for Cloud-based Cyber-Physical Systems",
    "doi": "https://doi.org/10.1145/3409772",
    "publication_date": "2021-05-03",
    "publication_year": 2021,
    "authors": "Kuljeet Kaur; Sahil Garg; Georges Kaddoum; Neeraj Kumar",
    "corresponding_authors": "",
    "abstract": "Energy consumption minimization of cloud data centers (DCs) has attracted much attention from the research community in the recent years; particularly due to the increasing dependence of emerging Cyber-Physical Systems on them. An effective way to improve the energy efficiency of DCs is by using efficient job scheduling strategies. However, the most challenging issue in selection of efficient job scheduling strategy is to ensure service-level agreement (SLA) bindings of the scheduled tasks. Hence, an energy-aware and SLA-driven job scheduling framework based on MapReduce is presented in this article. The primary aim of the proposed framework is to explore task-to-slot/container mapping problem as a special case of energy-aware scheduling in deadline-constrained scenario. Thus, this problem can be viewed as a complex multi-objective problem comprised of different constraints. To address this problem efficiently, it is segregated into three major subproblems (SPs), namely, deadline segregation, map and reduce phase energy-aware scheduling. These SPs are individually formulated using Integer Linear Programming. To solve these SPs effectively, heuristics based on Greedy strategy along with classical Hungarian algorithm for serial and serial-parallel systems are used. Moreover, the proposed scheme also explores the potential of splitting Map/Reduce phase(s) into multiple stages to achieve higher energy reductions. This is achieved by leveraging the concepts of classical Greedy approach and priority queues. The proposed scheme has been validated using real-time data traces acquired from OpenCloud. Moreover, the performance of the proposed scheme is compared with the existing schemes using different evaluation metrics, namely, number of stages, total energy consumption, total makespan, and SLA violated. The results obtained prove the efficacy of the proposed scheme in comparison to the other schemes under different workload scenarios.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W3157190926",
    "type": "article"
  },
  {
    "title": "Product Quality Monitoring in Hydraulic Presses Using a Minimal Sample of Sensor and Actuator Data",
    "doi": "https://doi.org/10.1145/3436238",
    "publication_date": "2021-05-03",
    "publication_year": 2021,
    "authors": "Iris R. Weiss; Birgit Vogel‐Heuser; Emanuel Trunzer; Simon Kruppa",
    "corresponding_authors": "",
    "abstract": "Machine learning and artificial intelligence provide methods and algorithms to take advantage of sensor and actuator data in automated production systems. Product quality monitoring is one of the promising applications available for data-driven modeling, particularly in cases where the quality parameters cannot be measured with reasonable effort. This is the case for defects such as cracks in workpieces of hydraulic metal powder presses. However, the variety of shapes produced at a powder press requires training of individual models based on a minimal sample size of unlabeled data to adapt to changing settings. Therefore, this article proposes an unsupervised product quality monitoring approach based on dynamic time warping and non-linear regression to detect anomalies in unlabeled sensor and actuator data. A preprocessing step that isolates only the relevant intervals of the process is further introduced, facilitating efficient product quality monitoring. The evaluation on an industrial dataset with 37 samples, generated in test runs, shows a true-positive rate for detected product quality defects of 100% while preserving an acceptable accuracy. Moreover, the approach achieves the output within less than 10 seconds, assuring that the result is available before the next workpiece is processed. In this way, efficient product quality management is possible, reducing time- and cost-intensive quality inspections.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W3158653230",
    "type": "article"
  },
  {
    "title": "Robust Facial Image Super-Resolution by Kernel Locality-Constrained Coupled-Layer Regression",
    "doi": "https://doi.org/10.1145/3418462",
    "publication_date": "2021-06-09",
    "publication_year": 2021,
    "authors": "Guangwei Gao; Dong Zhu; Huimin Lu; Yi Yu; Heyou Chang; Dong Yue",
    "corresponding_authors": "",
    "abstract": "Super-resolution methods for facial image via representation learning scheme have become very effective methods due to their efficiency. The key problem for the super-resolution of facial image is to reveal the latent relationship between the low-resolution ( LR ) and the corresponding high-resolution ( HR ) training patch pairs. To simultaneously utilize the contextual information of the target position and the manifold structure of the primitive HR space, in this work, we design a robust context-patch facial image super-resolution scheme via a kernel locality-constrained coupled-layer regression (KLC2LR) scheme to obtain the desired HR version from the acquired LR image. Here, KLC2LR proposes to acquire contextual surrounding patches to represent the target patch and adds an HR layer constraint to compensate the detail information. Additionally, KLC2LR desires to acquire more high-frequency information by searching for nearest neighbors in the HR sample space. We also utilize kernel function to map features in original low-dimensional space into a high-dimensional one to obtain potential nonlinear characteristics. Our compared experiments in the noisy and noiseless cases have verified that our suggested methodology performs better than many existing predominant facial image super-resolution methods.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W3169949513",
    "type": "article"
  },
  {
    "title": "Deep Attentive Multimodal Network Representation Learning for Social Media Images",
    "doi": "https://doi.org/10.1145/3417295",
    "publication_date": "2021-06-16",
    "publication_year": 2021,
    "authors": "Feiran Huang; Chaozhuo Li; BoYu Gao; Yun Liu; Sattam Alotaibi; Hao Chen",
    "corresponding_authors": "",
    "abstract": "The analysis for social networks, such as the socially connected Internet of Things, has shown a deep influence of intelligent information processing technology on industrial systems for Smart Cities. The goal of social media representation learning is to learn dense, low-dimensional, and continuous representations for multimodal data within social networks, facilitating many real-world applications. Since social media images are usually accompanied by rich metadata (e.g., textual descriptions, tags, groups, and submitted users), simply modeling the image is not effective to learn the comprehensive information from social media images. In this work, we treat the image and its textual description as multimodal content, and transform other metainformation into the links between contents (such as two images marked by the same tag or submitted by the same user). Based on the multimodal content and social links, we propose a Deep Attentive Multimodal Graph Embedding model named DAMGE for more effective social image representation learning. We introduce both small- and large-scale datasets to conduct extensive experiments, of which the results confirm the superiority of the proposal on the tasks of social image classification and link prediction.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W3169983365",
    "type": "article"
  },
  {
    "title": "A Shared Two-way Cybersecurity Model for Enhancing Cloud Service Sharing for Distributed User Applications",
    "doi": "https://doi.org/10.1145/3430508",
    "publication_date": "2021-10-22",
    "publication_year": 2021,
    "authors": "Yasser D. Al‐Otaibi",
    "corresponding_authors": "Yasser D. Al‐Otaibi",
    "abstract": "Cloud services provide decentralized and pervasive access for resources to reduce the complex infrastructure requirements of the user. In decentralized service access, the implication of security is tedious to match the user requirements. Therefore, cloud services incorporate cybersecurity measures for administering standard resource access to users. In this paper, a shared two-way security model (STSM) is proposed to provide adaptable service security for the end-users. In this security model, a cooperative closed access session for information sharing between the cloud and end-user is designed with the help of cybersecurity features. This closed access provides less complex authentication for users and data that is capable of matching the verifications of the cloud services. A deep belief learning algorithm is used to differentiate the cooperative and non-cooperative secure sessions between the users and the cloud to ensure closed access throughout the data sharing time. The output of the belief network decides the actual session time between the user and the cloud, improving the span of the sharing session. Besides, the proposed model reduces false alarm, communication failures, under controlled complexity.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W3208730681",
    "type": "article"
  },
  {
    "title": "Adaptive Fuzzy Game-Based Energy-Efficient Localization in 3D Underwater Sensor Networks",
    "doi": "https://doi.org/10.1145/3406533",
    "publication_date": "2021-10-22",
    "publication_year": 2021,
    "authors": "Yali Yuan; Chencheng Liang; Xu Chen; Thar Baker; Xiaoming Fu",
    "corresponding_authors": "",
    "abstract": "Numerous applications in 3D underwater sensor networks (UWSNs), such as pollution detection, disaster prevention, animal monitoring, navigation assistance, and submarines tracking, heavily rely on accurate localization techniques. However, due to the limited batteries of sensor nodes and the difficulty for energy harvesting in UWSNs, it is challenging to localize sensor nodes successfully within a short sensor node lifetime in an unspecified underwater environment. Therefore, we propose the Adaptive Energy-Efficient Localization Algorithm (Adaptive EELA) to enable energy-efficient node localization while adapting to the dynamic environment changes. Adaptive EELA takes a fuzzy game-theoretic approach, whereby the Stackelberg game is used to model the interactions among sensor and anchor nodes in UWSNs and employs the adaptive neuro-fuzzy method to set the appropriate utility functions. We prove that a socially optimal Stackelberg–Nash equilibrium is achieved in Adaptive EELA. Through extensive numerical simulations under various environmental scenarios, the evaluation results show that our proposed algorithm accomplishes a significant energy reduction, e.g., 66% lower compared to baselines, while achieving a desired performance level in terms of localization coverage, error, and delay.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W3208809038",
    "type": "article"
  },
  {
    "title": "On the Neural Backdoor of Federated Generative Models in Edge Computing",
    "doi": "https://doi.org/10.1145/3425662",
    "publication_date": "2021-10-22",
    "publication_year": 2021,
    "authors": "Derui Wang; Sheng Wen; Alireza Jolfaei; Mohammad Sayad Haghighi; ‪Surya Nepal‬; Yang Xiang",
    "corresponding_authors": "",
    "abstract": "Edge computing, as a relatively recent evolution of cloud computing architecture, is the newest way for enterprises to distribute computational power and lower repetitive referrals to central authorities. In the edge computing environment, Generative Models (GMs) have been found to be valuable and useful in machine learning tasks such as data augmentation and data pre-processing. Federated learning and distributed learning refer to training machine learning models in the edge computing network. However, federated learning and distributed learning also bring additional risks to GMs since all peers in the network have access to the model under training. In this article, we study the vulnerabilities of federated GMs to data-poisoning-based backdoor attacks via gradient uploading. We additionally enhance the attack to reduce the required poisonous data samples and cope with dynamic network environments. Last but not least, the attacks are formally proven to be stealthy and effective toward federated GMs. According to the experiments, neural backdoors can be successfully embedded by including merely 5\\% poisonous samples in the local training dataset of an attacker.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W3210823571",
    "type": "article"
  },
  {
    "title": "Labeling Privacy Protection SVM Using Privileged Information for COVID-19 Diagnosis",
    "doi": "https://doi.org/10.1145/3475868",
    "publication_date": "2021-11-29",
    "publication_year": 2021,
    "authors": "Tongguang Ni; Jiaqun Zhu; Jia Qu; Jing Xue",
    "corresponding_authors": "",
    "abstract": "Edge/fog computing works at the local area network level or devices connected to the sensor or the gateway close to the sensor. These nodes are located in different degrees of proximity to the user, while the data processing and storage are distributed among multiple nodes. In healthcare applications in the Internet of things, when data is transmitted through insecure channels, its privacy and security are the main issues. In recent years, learning from label proportion methods, represented by inverse calibration (InvCal) method, have tried to predict the class label based on class label proportions in certain groups. For privacy protection, the class label of the sample is often sensitive and invisible. As a compromise, only the proportion of class labels in certain groups can be used in these methods. However, due to their weak labeling scheme, their classification performance is often unsatisfactory. In this article, a labeling privacy protection support vector machine using privileged information, called LPP-SVM-PI, is proposed to promote the accuracy of the classifier in infectious disease diagnosis. Based on the framework of the InvCal method, besides using the proportion information of the class label, the idea of learning using privileged information is also introduced to capture the additional information of groups. The slack variables in LPP-SVM-PI are represented as correcting function and projected into the correcting space so that the hidden information of training samples in groups is captured by relaxing the constraints of the classification model. The solution of LPP-SVM-PI can be transformed into a classic quadratic programming problem. The experimental dataset is collected from the Coronavirus disease 2019 (COVID-19) transcription polymerase chain reaction at Hospital Israelita Albert Einstein in Brazil. In the experiment, LPP-SVM-PI is efficiently applied for COVID-19 diagnosis.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4200512144",
    "type": "article"
  },
  {
    "title": "Improving the Efficiency of an Online Marketplace by Incorporating Forgiveness Mechanism",
    "doi": "https://doi.org/10.1145/2996189",
    "publication_date": "2017-01-20",
    "publication_year": 2017,
    "authors": "Ruchdee Binmad; Mingchu Li",
    "corresponding_authors": "",
    "abstract": "Reputation plays a key role in online marketplace communities improving trust among community members. Reputation works as a decision-making tool for understanding the behavior of the business partners. Success of any online business depends on the trust the business agents share with each other. However, untrustworthy agents have anno place in online marketplaces and are forced to leave the market even if they will potentially cooperate. In this study, we propose an exploration strategy based on a forgiveness mechanism for untrustworthy agents to recover their reputation. Furthermore, a number of experiments based on the NetLogo simulation are performed to validate the applicability of the proposed mechanism. The results show that the online marketplaces incorporating a forgiveness mechanism can be used with the existing reputation systems and improve the efficiency of online marketplaces.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2583038018",
    "type": "article"
  },
  {
    "title": "Managing Provenance of Implicit Data Flows in Scientific Experiments",
    "doi": "https://doi.org/10.1145/3053372",
    "publication_date": "2017-08-18",
    "publication_year": 2017,
    "authors": "Vitor C. Neves; Daniel de Oliveira; Kary Ocaña; Vanessa Braganholo; Leonardo Murta",
    "corresponding_authors": "",
    "abstract": "Scientific experiments modeled as scientific workflows may create, change, or access data products not explicitly referenced in the workflow specification, leading to implicit data flows. The lack of knowledge about implicit data flows makes the experiments hard to understand and reproduce. In this article, we present ProvMonitor, an approach that identifies the creation, change, or access to data products even within implicit data flows. ProvMonitor links this information with the workflow activity that generated it, allowing for scientists to compare data products within and throughout trials of the same workflow, identifying side effects on data evolution caused by implicit data flows. We evaluated ProvMonitor and observed that it could answer queries for scenarios that demand specific knowledge related to implicit provenance.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2748423587",
    "type": "article"
  },
  {
    "title": "Experimental Assessment of Aggregation Principles in Argumentation-Enabled Collective Intelligence",
    "doi": "https://doi.org/10.1145/3053371",
    "publication_date": "2017-06-12",
    "publication_year": 2017,
    "authors": "Edmond Awad; Jean‐François Bonnefon; Martin Caminada; Thomas W. Malone; Iyad Rahwan",
    "corresponding_authors": "",
    "abstract": "On the Web, there is always a need to aggregate opinions from the crowd (as in posts, social networks, forums, etc.). Different mechanisms have been implemented to capture these opinions such as \"Like\" in Facebook, \"Favorite\" in Twitter, thumbs-up/down, flagging, and so on. However, in more contested domains (e.g. Wikipedia, political discussion, and climate change discussion) these mechanisms are not sufficient since they only deal with each issue independently without considering the relationships between different claims. We can view a set of conflicting arguments as a graph in which the nodes represent arguments and the arcs between these nodes represent the defeat relation. A group of people can then collectively evaluate such graphs. To do this, the group must use a rule to aggregate their individual opinions about the entire argument graph. Here, we present the first experimental evaluation of different principles commonly employed by aggregation rules presented in the literature. We use randomized controlled experiments to investigate which principles people consider better at aggregating opinions under different conditions. Our analysis reveals a number of factors, not captured by traditional formal models, that play an important role in determining the efficacy of aggregation. These results help bring formal models of argumentation closer to real-world application.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W3125201708",
    "type": "article"
  },
  {
    "title": "Bandwidth Measurements within the Cloud",
    "doi": "https://doi.org/10.1145/3093893",
    "publication_date": "2017-08-18",
    "publication_year": 2017,
    "authors": "José Luis García‐Dorado",
    "corresponding_authors": "José Luis García‐Dorado",
    "abstract": "The search for availability, reliability, and quality of service has led cloud infrastructure customers to disseminate their services, contents, and data over multiple cloud data centers, often involving several Cloud service providers (CSPs). The consequence of this is that a large amount of data must be transmitted across the public Cloud. However, little is known about the bandwidth dynamics involved. To address this, we have conducted a measurement campaign for bandwidth between 18 data centers of four major CSPs. This extensive campaign allowed us to characterize the resulting time series of bandwidth as the addition of a stationary component and some infrequent excursions (typically downtimes). While the former provides a description of the bandwidth users can expect in the Cloud, the latter is closely related to the robustness of the Cloud (i.e., the occurrence of downtimes is correlated). Both components have been studied further by applying factor analysis, specifically analysis of variance, as a mechanism to formally compare data centers’ behaviors and extract generalities. The results show that the stationary process is closely related to the data center locations and CSPs involved in transfers that, fortunately, make the Cloud more predictable and allow the set of reported measurements to be extrapolated. On the other hand, although correlation in the Cloud is low, that is, only 10% of the measured pair of paths showed some correlation, we found evidence that such correlation depends on the particular relationships between pairs of data centers with little connection to more general factors. Positively, this implies that data centers either in the same area or within the same CSP do not show qualitatively more correlation than other data centers, which eases the deployment of robust infrastructures. On the downside, this metric is scarcely generalizable and, consequently, calls for exhaustive monitoring.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4300445061",
    "type": "article"
  },
  {
    "title": "Decentralized Fault-Tolerant Event Correlation",
    "doi": "https://doi.org/10.1145/2633687",
    "publication_date": "2014-07-15",
    "publication_year": 2014,
    "authors": "Gregory Aaron Wilkin; Patrick Eugster; K. R. Jayaram",
    "corresponding_authors": "",
    "abstract": "Despite the prognosed use of event correlation techniques for monitoring critical complex infrastructures or dealing with disasters in the physical world, little work exists on making event correlation systems themselves tolerant to failure. Existing systems either provide no guarantees on event deliveries, do not support multicast and thus provide no guarantees across individual processes, or then rely on centralized components or strong assumptions on the infrastructure. The FAIDECS system attempts to reconcile strong guarantees with practical performance in the presence of process crash failures. To that end, the FAIDECS system uses an overlay network with specific guarantees aligned with its proposed correlation language and guarantees. However, the language proposed lacks expressivity, and the system itself supports only very specific rigid semantics, incapable of supporting even fundamental features like sliding windows. After providing a comprehensive overview of the FAIDECS model and system, this article bridges the gap between strong guarantees and more established correlation languages and systems in several steps. First, we propose alternative semantics for several modules of the FAIDECS matching engine and revisit guarantees. Second, we pinpoint which guarantees are contradicted by which combinations of semantic options. Third, we investigate four correlation languages—StreamSQL, EQL, CEL, and TESLA—showing which semantic options their respective features correspond to in our model, and thus, ultimately, which guarantees of FAIDECS are maintained by which language features.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2012015802",
    "type": "article"
  },
  {
    "title": "Revenue Guarantees in the Generalized Second Price Auction",
    "doi": "https://doi.org/10.1145/2663497",
    "publication_date": "2014-10-28",
    "publication_year": 2014,
    "authors": "Ioannis Caragiannis; Christos Kaklamanis; Panagiotis Kanellopoulos; Maria Kyropoulou",
    "corresponding_authors": "",
    "abstract": "Sponsored search auctions are the main source of revenue for search engines. In such an auction, a set of utility maximizing advertisers competes for a set of ad slots. The assignment of advertisers to slots depends on the bids they submit; these bids may be different than the true valuations of the advertisers for the slots. Variants of the celebrated VCG auction mechanism guarantee that advertisers act truthfully and, under some assumptions, lead to revenue or social welfare maximization. Still, the sponsored search industry mostly uses generalized second price (GSP) auctions; these auctions are known to be nontruthful and suboptimal in terms of social welfare and revenue. In an attempt to explain this tradition, we study a Bayesian setting wherein the valuations of advertisers are drawn independently from a common regular probability distribution. In this setting, it is well known from the work of Myerson [1981] that the optimal revenue is obtained by the VCG mechanism with a particular reserve price that depends on the probability distribution. We show that, by appropriately setting the reserve price, the revenue over any Bayes-Nash equilibrium of the game induced by the GSP auction is at most a small constant factor away from the optimal revenue, improving previous results of Lucier et al. [2012]. Our analysis is based on the Bayes-Nash equilibrium conditions and the improved results are obtained by bounding the utility of each player at equilibrium using infinitely many deviating bids and also by developing novel prophet-like inequalities.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2041898479",
    "type": "article"
  },
  {
    "title": "Constructing Maintainable Semantic Relation Network from Ambiguous Concepts in Web Content",
    "doi": "https://doi.org/10.1145/2814568",
    "publication_date": "2016-02-11",
    "publication_year": 2016,
    "authors": "Kenneth Wai-Ting Leung; Di Jiang; Dik Lun Lee; Wilfred Ng",
    "corresponding_authors": "",
    "abstract": "The semantic network is a form of knowledge that represents various relationships between concepts with ambiguity. The knowledge can be employed to identify semantically related objects. It helps, for example, a recommender system to generate effective recommendations to the users. We propose to study a new semantic network, namely, the Concept Relation Network (CRN) , which is efficiently constructed and maintained using existing web search engines. CRN tackles the uncertainty and dynamics of web content, and thus is optimized for many important web applications, such as social networks and search engines. It is a large semantic network for the collection, analysis, and interpretation of web content, and serves as a cornerstone for applications such as web search engines, recommendation systems, and social networks that can benefit from a large-scale knowledge base. In this article, we present two applications for CRN: (1) search engine and web analytic and (2) semantic information retrieval. Experimental results show that CRN effectively enhances these applications by considering the heterogenous and polysemous nature of web content.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2268593888",
    "type": "article"
  },
  {
    "title": "<scp>Breaking Bad</scp>: Quantifying the Addiction of Web Elements to JavaScript",
    "doi": "https://doi.org/10.1145/3579846",
    "publication_date": "2023-01-12",
    "publication_year": 2023,
    "authors": "Romain Fouquet; Pierre Laperdrix; Romain Rouvoy",
    "corresponding_authors": "",
    "abstract": "While JavaScript established itself as a cornerstone of the modern web, it also constitutes a major tracking and security vector, thus raising critical privacy and security concerns. In this context, some browser extensions propose to systematically block scripts reported by crowdsourced trackers lists. However, this solution heavily depends on the quality of these built-in lists, which may be deprecated or incomplete, thus exposing the visitor to unknown trackers. In this paper, we explore a different strategy, by investigating the benefits of disabling JavaScript in the browser. More specifically, by adopting such a strict policy, we aim to quantify the JavaScript addiction of web elements composing a web page, through the observation of web breakages. As there is no standard mechanism for detecting such breakages, we introduce a framework to inspect several page features when blocking JavaScript, that we deploy to analyze 6,384 pages, including landing and internal web pages. We discover that 43% of web pages are not strictly dependent on JavaScript and that more than 67% of pages are likely to be usable as long as the visitor only requires the content from the main section of the page, for which the user most likely reached the page, while reducing the number of tracking requests by 85% on average. Finally, we discuss the viability of currently browsing the web without JavaScript and detail multiple incentives for websites to be kept usable without JavaScript.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4315706120",
    "type": "article"
  },
  {
    "title": "Movie Account Recommendation on Instagram",
    "doi": "https://doi.org/10.1145/3579852",
    "publication_date": "2023-01-14",
    "publication_year": 2023,
    "authors": "Yu-Jhen Wang; Anthony J.T. Lee",
    "corresponding_authors": "",
    "abstract": "With the increasing popularity of social networks, many businesses have started implementing their branding or targeted advertising strategies to reach potential customers through social media platforms. It is desirable and essential to help businesses to reach mass audiences and assist users to find favorite business accounts on social media platforms. In the movie industry, movie companies often create business accounts (movie accounts) to promote their movies and capture the attention of followers on Instagram. Instagram contains rich information about movies and user feedback, while IMDb, one of the most popular online databases, contains well-organized information related to movies. The features extracted from the data collected from Instagram and IMDb can complement each other. Therefore, in this study, we propose a framework for recommending movie accounts to users on Instagram by using the data collected from Instagram and IMDb platforms. The experiment results show that our proposed framework outperforms the comparing methods in terms of precision, recall, F1-score, and Normalized Discounted Cumulative Gain (NDCG) , and mitigates the effect of cold start problems. The proposed framework can help movie companies or businesses reach potential audiences and implement effective targeted advertising strategies.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4315977627",
    "type": "article"
  },
  {
    "title": "An End-to-end Trust Management Framework for Crowdsourced IoT Services",
    "doi": "https://doi.org/10.1145/3600232",
    "publication_date": "2023-06-01",
    "publication_year": 2023,
    "authors": "Mohammed Bahutair; Athman Bouguettaya",
    "corresponding_authors": "",
    "abstract": "We propose a novel end-to-end trust management framework for crowdsourced Internet of Things (IoT) services. The framework targets three main aspects: trust assessment , trust information credibility and accuracy , and trust information storage . We harness the usage patterns of IoT consumers to offer a trust assessment that adapts to IoT consumers’ uses. Additionally, our framework ascertains the credibility and accuracy of trust-related information before trust assessment. This is achieved by validating the data collected by IoT consumers and providers. In addition, our framework ensures the contextual fairness between IoT services and trust information. Moreover, we propose a blockchain-based trust information storage approach. Our proposed storage solution preserves the integrity and availability of trust information.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4379014791",
    "type": "article"
  },
  {
    "title": "Blockchain-based Zero Trust Cybersecurity in the Internet of Things",
    "doi": "https://doi.org/10.1145/3594535",
    "publication_date": "2023-08-21",
    "publication_year": 2023,
    "authors": "Shancang Li; ‪Surya Nepal‬; Theo Tryfonas; Hongwei Li",
    "corresponding_authors": "",
    "abstract": "introduction Share on Blockchain-based Zero Trust Cybersecurity in the Internet of Things Authors: Shancang Li UESTC, China & UWE Bristol, UK UESTC, China & UWE Bristol, UKSearch about this author , Surya Nepal CSIRO's Data61 Sydney, Australia CSIRO's Data61 Sydney, AustraliaSearch about this author , Theo Tryfonas University of Bristol Bristol BS8 1TR, UK University of Bristol Bristol BS8 1TR, UKSearch about this author , Hongwei Li University of Electronic Science and Technology of China Chengdu, China University of Electronic Science and Technology of China Chengdu, ChinaSearch about this author Authors Info & Claims ACM Transactions on Internet TechnologyVolume 23Issue 3Article No.: 36pp 1–3https://doi.org/10.1145/3594535Published:21 August 2023Publication History 0citation105DownloadsMetricsTotal Citations0Total Downloads105Last 12 Months105Last 6 weeks89 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteGet Access",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4386032574",
    "type": "article"
  },
  {
    "title": "Fine-Grained Access Control via Policy-Carrying Data",
    "doi": "https://doi.org/10.1145/3133324",
    "publication_date": "2018-02-05",
    "publication_year": 2018,
    "authors": "Julián Padget; Wamberto Vasconcelos",
    "corresponding_authors": "",
    "abstract": "We address the problem of associating access policies with datasets and how to monitor compliance via policy-carrying data. Our contributions are a formal model in first-order logic inspired by normative multi-agent systems to regulate data access, and a computational model for the validation of specific use cases and the verification of policies against criteria. Existing work on access policy identifies roles as a key enabler, with which we concur, but much of the rest focusses on authentication and authorization technology. Our proposal aims to address the normative principles put forward in Berners-Lee’s bill of rights for the internet, through human-readable but machine-processable access control policies.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2757652483",
    "type": "article"
  },
  {
    "title": "Exploiting Content Spatial Distribution to Improve Detection of Intrusions",
    "doi": "https://doi.org/10.1145/3143422",
    "publication_date": "2018-01-20",
    "publication_year": 2018,
    "authors": "Fabrizio Angiulli; Luciano Argento; Angelo Furfaro",
    "corresponding_authors": "",
    "abstract": "We present PCkAD, a novel semisupervised anomaly-based IDS (Intrusion Detection System) technique, detecting application-level content-based attacks. Its peculiarity is to learn legitimate payloads by splitting packets into chunks and determining the within-packet distribution of n-grams. This strategy is resistant to evasion techniques as blending. We prove that finding the right legitimate content is NP-hard in the presence of chunks. Moreover, it improves the false-positive rate for a given detection rate with respect to the case where the spatial information is not considered. Comparison with well-known IDSs using n-grams highlights that PCkAD achieves state-of-the-art performances.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2785123216",
    "type": "article"
  },
  {
    "title": "Accountable Protocols in Abductive Logic Programming",
    "doi": "https://doi.org/10.1145/3107936",
    "publication_date": "2018-04-24",
    "publication_year": 2018,
    "authors": "Marco Gavanelli; Marco Alberti; Evelina Lamma",
    "corresponding_authors": "",
    "abstract": "Finding the entity responsible for an unpleasant situation is often difficult, especially in artificial agent societies. S CIFF is a formalization of agent societies, including a language to describe rules and protocols, and an abductive proof procedure for compliance checking. However, how to identify the entity responsible for a violation is not always clear. In this work, a definition of accountability for artificial societies is formalized in S CIFF. Two tools are provided for the designer of interaction protocols: a guideline, in terms of syntactic features that ensure accountability of the protocol, and an algorithm (implemented in a software tool) to investigate if, for a given protocol, nonaccountability issues could arise.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2801446598",
    "type": "article"
  },
  {
    "title": "A Pure Visual Approach for Automatically Extracting and Aligning Structured Web Data",
    "doi": "https://doi.org/10.1145/3365376",
    "publication_date": "2019-11-01",
    "publication_year": 2019,
    "authors": "Fadwa Estuka; James Miller",
    "corresponding_authors": "",
    "abstract": "Database-driven websites and the amount of data stored in their databases are growing enormously. Web databases retrieve relevant information in response to users’ queries; the retrieved information is encoded in dynamically generated web pages as structured data records. Identifying and extracting retrieved data records is a fundamental task for many applications, such as competitive intelligence and comparison shopping. This task is challenging due to the complex underlying structure of such web pages and the existence of irrelevant information. Numerous approaches have been introduced to address this problem, but most of them are HTML-dependent solutions that may no longer be functional with the continuous development of HTML. Although a few vision-based techniques have been introduced, various issues exist that inhibit their performance. To overcome this, we propose a novel visual approach, i.e., programming-language-independent, for automatically extracting structured web data. The proposed approach makes full use of the natural human tendency of visual object perception and the Gestalt laws of grouping. The extraction system consists of two tasks: (1) data record extraction, where we apply three of the Gestalt laws (i.e., laws of continuity, proximity, and similarity), which are used to group the adjacently aligned visually similar data records on a web page; and (2) data item extraction and alignment, where we employ the Gestalt law of similarity, which is utilized to group the visually identical data items. Our experiments upon large-scale test sets show that the proposed system is highly effective and outperforms the two state-of-art vision-based approaches, ViDE and rExtractor. The experiments produce an average F1 score of 86.02%, which is approximately 55% and 36% better than that of ViDE and rExtractor for data record extraction, respectively; and an average F1 score of 86.19%, which is approximately 39% better than that of ViDE for data item extraction.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2808777947",
    "type": "article"
  },
  {
    "title": "Parameter Self-Adaptation for Industrial Wireless Sensor-Actuator Networks",
    "doi": "https://doi.org/10.1145/3388240",
    "publication_date": "2020-06-26",
    "publication_year": 2020,
    "authors": "Junyang Shi; Mo Sha",
    "corresponding_authors": "",
    "abstract": "Wireless sensor-actuator network (WSAN) technology is gaining rapid adoption by industrial Internet of Things applications in recent years. A WSAN typically connects sensors, actuators, and controllers in industrial facilities, such as steel mills, oil refineries, chemical plants, and infrastructures implementing complex monitoring and control processes. IEEE 802.15.4–based WSANs operate at low power and can be manufactured inexpensively, which makes them ideal where battery lifetime and costs are important. Recent studies have shown that the selection of network parameters has a significant effect on network performance. However, the current practice of parameter selection is largely based on experience and rules of thumb involving a coarse-grained analysis of expected network load and dynamics or measurements during a few field trials, resulting in non-optimal decisions in many cases. In this work, we develop P-SAFE (Parameter Selection and Adaptation FramEwork), which optimally selects the network parameters based on the application quality-of-service demands and adapts the parameter configuration at runtime to consistently satisfy the dynamic requirements. We implement P-SAFE and evaluate it on three physical testbeds. Experimental results show that our solution can significantly better meet the application quality-of-service demand compared to the state of the art.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W3066690370",
    "type": "article"
  },
  {
    "title": "Routing in Large-scale Dynamic Networks",
    "doi": "https://doi.org/10.1145/3407192",
    "publication_date": "2020-10-01",
    "publication_year": 2020,
    "authors": "Weichao Gao; James Nguyen; Yalong Wu; William G. Hatcher; Wei Yu",
    "corresponding_authors": "",
    "abstract": "The increasing volume of network-connected devices comprising Internet of Things and the variety of heterogeneous network architectures across these devices pose significant challenges to effective deployment and routing. In this article, we consider the adoption of probabilistic data structures to develop a novel Bloom Filter-based dual-layer inter-domain routing scheme. Our designed scheme implements internal and external routing layers in network gateways constructed upon the counting bloom filter and the original bloom filter. We first compare several representative structures in both theory and experimentation. We then propose our novel Bloom Filter-based dual-layer inter-domain routing scheme. In the design of the routing scheme, we consider issues related to the overall space cost and routing loop prevention, as well as present corresponding solutions. We also detail the principal structures and algorithms. Further, we conduct a theoretical analysis of the space efficiency of our proposed scheme compared to traditional routing with respect to the size of data packets and the size of routing tables, as well as in routing loop avoidance. Finally, via extensive performance evaluation, our experimental results demonstrate the effectiveness and efficiency of our proposed scheme.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W3091211936",
    "type": "article"
  },
  {
    "title": "An Intelligent Edge-centric Queries Allocation Scheme based on Ensemble Models",
    "doi": "https://doi.org/10.1145/3417297",
    "publication_date": "2020-10-15",
    "publication_year": 2020,
    "authors": "Kostas Kolomvatsos; Christos Anagnostopoulos",
    "corresponding_authors": "",
    "abstract": "The combination of Internet of Things (IoT) and Edge Computing (EC) can assist in the delivery of novel applications that will facilitate end-users’ activities. Data collected by numerous devices present in the IoT infrastructure can be hosted into a set of EC nodes becoming the subject of processing tasks for the provision of analytics. Analytics are derived as the result of various queries defined by end-users or applications. Such queries can be executed in the available EC nodes to limit the latency in the provision of responses. In this article, we propose a meta-ensemble learning scheme that supports the decision making for the allocation of queries to the appropriate EC nodes. Our learning model decides over queries’ and nodes’ characteristics. We provide the description of a matching process between queries and nodes after concluding the contextual information for each envisioned characteristic adopted in our meta-ensemble scheme. We rely on widely known ensemble models, combine them, and offer an additional processing layer to increase the performance. The aim is to result a subset of EC nodes that will host each incoming query. Apart from the description of the proposed model, we report on its evaluation and the corresponding results. Through a large set of experiments and a numerical analysis, we aim at revealing the pros and cons of the proposed scheme.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W3094251902",
    "type": "article"
  },
  {
    "title": "Serendipity-based Points-of-Interest Navigation",
    "doi": "https://doi.org/10.1145/3391197",
    "publication_date": "2020-07-07",
    "publication_year": 2020,
    "authors": "Xiaoyu Ge; Panos K. Chrysanthis; Konstantinos Pelechrinis; Demetrios Zeinalipour-Yazti; Mohamed A. Sharaf",
    "corresponding_authors": "",
    "abstract": "Traditional venue and tour recommendation systems do not necessarily provide a diverse set of recommendations and leave little room for serendipity . In this article, we design MPG, a Mobile Personal Guide that recommends: (i) a set of diverse yet surprisingly interesting venues that are aligned to user preferences and (ii) a set of routes, constructed from the recommended venues. We also introduce EPUI, an Experimental Platform for Urban Informatics. Our comparison with the state-of-the-art schemes indicates that MPG is capable of providing high-quality venues and route recommendations while incorporating seamlessly both the notion of diversity and that of serendipity.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W3094843125",
    "type": "article"
  },
  {
    "title": "SafeVchat",
    "doi": "https://doi.org/10.1145/2499926.2499927",
    "publication_date": "2013-07-01",
    "publication_year": 2013,
    "authors": "Yuli Liang; Xinyu Xing; Hanqiang Cheng; Jianxun Dang; Sui Huang; Richard Han; Xue Liu; Qin Lv; Shivakant Mishra",
    "corresponding_authors": "",
    "abstract": "Online video chat services such as Chatroulette, Omegle, and vChatter that randomly match pairs of users in video chat sessions are quickly becoming very popular, with over a million users per month in the case of Chatroulette. A key problem encountered in such systems is the presence of flashers and obscene content. This problem is especially acute given the presence of underage minors in such systems. This article presents SafeVchat, a novel solution to the problem of flasher detection that employs an array of image detection algorithms. A key contribution of the article concerns how the results of the individual detectors are fused together into an overall decision classifying a user as misbehaving or not, based on Dempster-Shafer theory. The article introduces a novel, motion-based skin detection method that achieves significantly higher recall and better precision. The proposed methods have been evaluated over real-world data and image traces obtained from Chatroulette.com. SafeVchat has been deployed in Chatroulette. A combination of SafeVchat with human moderation has resulted in banning as many as 50,000 inappropriate users per day on Chatoulette. Furthermore, offensive content on Chatoulette has dropped significantly from 33.08% (before SafeVchat installation) to 3.49% (after SafeVchat installation).",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2100589960",
    "type": "article"
  },
  {
    "title": "Using certified policies to regulate E-commerce transactions",
    "doi": "https://doi.org/10.1145/1052934.1052939",
    "publication_date": "2005-02-01",
    "publication_year": 2005,
    "authors": "Victoria Ungureanu",
    "corresponding_authors": "Victoria Ungureanu",
    "abstract": "E-commerce regulations are usually embedded in mutually agreed upon contracts. Generally, these contracts enumerate agents authorized to participate in transactions, and spell out such things like rights and obligations of each partner, and terms and conditions of the trade. An enterprise may be concurrently bound by a set of different contracts that regulate the trading relations with its various clients and suppliers. This set is dynamic because new contracts are constantly being established, and previously established contracts end, are annulled, or revised.We argue that existent access control mechanisms cannot adequately support the large number of regulations embedded in disparate, evolving contracts. To deal with this problem we propose to use certified policies. A certified policy (CP) is obtained by expressing contract terms regarding access and control regulations in a formal, interpretable language, and by having them digitally signed by a proper authority. In this framework, an agent making a request to a server presents to the server such a CP, together with other relevant credentials. A valid certified policy can then be used as the authorization policy for the request in question.It is the thesis of this article that this approach would make several aspects of contract enforcement more manageable and more efficient: (a) deployment---certified policies may be stored on certificate repositories from where they can be retrieved as needed, (b) annulment---if a contract is annulled, the corresponding CP should be invalidated; the latter can be conveniently supported by certificate revocation, and (c) revision---revision of contract terms can be done by publishing a new certified policy and by revoking the old one. The proposed approach is practical in that it does not require any modification of the current certificate infrastructure and only minor modifications to servers.In this article, we propose a language for stating contract terms and present several formal examples of certified policies. We describe the implementation of the enforcement mechanism and present experimental performance results.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2006546263",
    "type": "article"
  },
  {
    "title": "Introduction to the Special Section on Human-centered Security, Privacy, and Trust in the Internet of Things",
    "doi": "https://doi.org/10.1145/3445790",
    "publication_date": "2021-01-20",
    "publication_year": 2021,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "introduction Share on Introduction to the Special Section on Human-centered Security, Privacy, and Trust in the Internet of Things Editors: Mahmoud Barhamgi View Profile , Michael N. Huhns View Profile , Charith Perera View Profile , Pinar Yolum View Profile Authors Info & Claims ACM Transactions on Internet TechnologyVolume 21Issue 1February 2021 Article No.: 16pp 1–3https://doi.org/10.1145/3445790Online:20 January 2021Publication History 1citation157DownloadsMetricsTotal Citations1Total Downloads157Last 12 Months98Last 6 weeks8 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteGet Access",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W3121969727",
    "type": "article"
  },
  {
    "title": "Operating Systems for Resource-adaptive Intelligent Software: Challenges and Opportunities",
    "doi": "https://doi.org/10.1145/3425866",
    "publication_date": "2021-03-15",
    "publication_year": 2021,
    "authors": "Xuanzhe Liu; Shangguang Wang; Yun Ma; Ying Zhang; Qiaozhu Mei; Yunxin Liu; Gang Huang",
    "corresponding_authors": "",
    "abstract": "The past decades witnessed the fast and wide deployment of Internet. The Internet has bred the ubiquitous computing environment that is spanning the cloud, edge, mobile devices, and IoT. Software running over such a ubiquitous computing environment environment is eating the world. A recently emerging trend of Internet-based software systems is “ resource adaptive ,” i.e., software systems should be robust and intelligent enough to the changes of heterogeneous resources, both physical and logical, provided by their running environment. To keep pace of such a trend, we argue that some considerations should be taken into account for the future operating system design and implementation. From the structural perspective, rather than the “monolithic OS” that manages the aggregated resources on the single machine, the OS should be dynamically composed over the distributed resources and flexibly adapt to the resource and environment changes. Meanwhile, the OS should leverage advanced machine/deep learning techniques to derive configurations and policies and automatically learn to tune itself and schedule resources. This article envisions our recent thinking of the new OS abstraction, namely, ServiceOS , for future resource-adaptive intelligent software systems. The idea of ServiceOS is inspired by the delivery model of “ Software-as-a-Service ” that is supported by the Service-Oriented Architecture (SOA). The key principle of ServiceOS is based on resource disaggregation, resource provisioning as a service, and learning-based resource scheduling and allocation. The major goal of this article is not providing an immediately deployable OS. Instead, we aim to summarize the challenges and potentially promising opportunities and try to provide some practical implications for researchers and practitioners.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W3137566574",
    "type": "article"
  },
  {
    "title": "Using Social Media Data to Analyse Issue Engagement During the 2017 German Federal Election",
    "doi": "https://doi.org/10.1145/3467020",
    "publication_date": "2021-10-25",
    "publication_year": 2021,
    "authors": "Florian Meier; Alexander Bazo; David Elsweiler",
    "corresponding_authors": "",
    "abstract": "A fundamental tenet of democracy is that political parties present policy alternatives, such that the public can participate in the decision making process. Parties, however, strategically control public discussion by emphasising topics that they believe will highlight their strengths in voters’ minds. Political strategy has been studied for decades, mostly by manually annotating and analysing party statements, press coverage, or TV ads. Here we build on recent work in the areas of computational social science and eDemocracy, which studied these concepts computationally with social media. We operationalize issue engagement and related political science theories to measure and quantify politicians’ communication behavior using more than 366k Tweets posted by over 1000 prominent German politicians in the 2017 election year. To this end, we first identify issues in posted Tweets by utilising a hashtag-based approach well known in the literature. This method allows several prominent issues featuring in the political debate on Twitter that year to be identified. We show that different political parties engage to a larger or lesser extent with these issues. The findings reveal differing social media strategies by parties located at different sides of the political left-right scale, in terms of which issues they engage with, how confrontational they are and how their strategies evolve in the lead up to the election. Whereas previous work has analysed the general public’s use of Twitter or politicians’ communication in terms of cross-party polarisation, this is the first study of political science theories, relating to issue engagement, using politicians’ social media data.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W3166255413",
    "type": "article"
  },
  {
    "title": "Proof-of-Prestige: A Useful Work Reward System for Unverifiable Tasks",
    "doi": "https://doi.org/10.1145/3419483",
    "publication_date": "2021-06-15",
    "publication_year": 2021,
    "authors": "Michał Król; Alberto Sonnino; Mustafa Al-Bassam; Argyrios G. Tasiopoulos; Étienne Rivière; Ioannis Psaras",
    "corresponding_authors": "",
    "abstract": "As cryptographic tokens and altcoins are increasingly being built to serve as utility tokens, the notion of useful work consensus protocols is becoming ever more important. With useful work consensus protocols, users get rewards after they have carried out some specific tasks useful for the network. While in some cases the proof of some utility or service can be provided, the majority of tasks are impossible to verify reliably. To deal with such cases, we design “Proof-of-Prestige” (PoP)—a reward system that can run directly on Proof-of-Stake (PoS) blockchains or as a smart contract on top of Proof-of-Work (PoW) blockchains. PoP introduces “prestige,” which is a volatile resource that, in contrast to coins, regenerates over time. Prestige can be gained by performing useful work, spent when benefiting from services, and directly translates to users minting power. Our scheme allows us to reliably reward decentralized workers while keeping the system free for the end-users. PoP is resistant against Sybil and collusion attacks and can be used with a vast range of unverifiable tasks. We build a simulator to assess the cryptoeconomic behavior of the system and deploy a full prototype of a content dissemination platform rewarding its participants. We implement the blockchain component on both Ethereum (PoW) and Cosmos (PoS), provide a mobile application, and connect it with our scheme with a negligible memory footprint. Finally, we adapt a fair exchange protocol allowing us to atomically exchange files for rewards also in scenarios where not all the parties have Internet connectivity. Our evaluation shows that even for large Ethereum traces, PoP introduces sub-millisecond computational overhead for miners in Cosmos and less than 0.013$ smart contract invocation cost for users in Ethereum.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W3166996293",
    "type": "article"
  },
  {
    "title": "Random Graph-based Multiple Instance Learning for Structured IoT Smart City Applications",
    "doi": "https://doi.org/10.1145/3448611",
    "publication_date": "2021-06-09",
    "publication_year": 2021,
    "authors": "David Chiu; Tao Xu; Iker Gondra",
    "corresponding_authors": "",
    "abstract": "Because of the complex activities involved in IoT networks of a smart city, an important question arises: What are the core activities of the networks as a whole and its basic information flow structure? Identifying and discovering core activities and information flow is a crucial step that can facilitate the analysis. This is the question we are addressing—that is, to identify the core services as a common core substructure despite the probabilistic nature and the diversity of its activities. If this common substructure can be discovered, a systemic analysis and planning can then be performed and key policies related to the community can be developed. Here, a local IoT network can be represented as an attributed graph. From an ensemble of attributed graphs, identifying the common subgraph pattern is then critical in understanding the complexity. We introduce this as the common random subgraph (CRSG) modeling problem, aiming at identifying a subgraph pattern that is the structural “core” that conveys the probabilistically distributed graph characteristics. Given an ensemble of network samples represented as attributed graphs, the method generates a CRSG model that encompasses both structural and statistical characteristics from the related samples while excluding unrelated networks. In generating a CRSG model, our method using a multiple instance learning algorithm transforms an attributed graph (composed of structural elements as edges and their two endpoints) into a “bag” of instances in a vector space. Common structural components across positively labeled graphs are then identified as the common instance patterns among instances across different bags. The structure of the CRSG arises through the combining of common patterns. The probability distribution of the CRSG can then be estimated based on the connections and distributions from the common elements. Experimental results demonstrate that CRSG models are highly expressive in describing typical network characteristics.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W3167470018",
    "type": "article"
  },
  {
    "title": "Time-Efficient Ensemble Learning with Sample Exchange for Edge Computing",
    "doi": "https://doi.org/10.1145/3409265",
    "publication_date": "2021-06-16",
    "publication_year": 2021,
    "authors": "Wu Chen; Yong Yu; Keke Gai; Jiamou Liu; Kim‐Kwang Raymond Choo",
    "corresponding_authors": "",
    "abstract": "In existing ensemble learning algorithms (e.g., random forest), each base learner’s model needs the entire dataset for sampling and training. However, this may not be practical in many real-world applications, and it incurs additional computational costs. To achieve better efficiency, we propose a decentralized framework: Multi-Agent Ensemble. The framework leverages edge computing to facilitate ensemble learning techniques by focusing on the balancing of access restrictions (small sub-dataset) and accuracy enhancement. Specifically, network edge nodes (learners) are utilized to model classifications and predictions in our framework. Data is then distributed to multiple base learners who exchange data via an interaction mechanism to achieve improved prediction. The proposed approach relies on a training model rather than conventional centralized learning. Findings from the experimental evaluations using 20 real-world datasets suggest that Multi-Agent Ensemble outperforms other ensemble approaches in terms of accuracy even though the base learners require fewer samples (i.e., significant reduction in computation costs).",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W3169048238",
    "type": "article"
  },
  {
    "title": "Account Guarantee Scheme",
    "doi": "https://doi.org/10.1145/3406092",
    "publication_date": "2021-01-05",
    "publication_year": 2021,
    "authors": "Lichen Cheng; Jiqiang Liu; Yi Jin; Yidong Li; Wei Wang",
    "corresponding_authors": "",
    "abstract": "In blockchain networks, reaching effective supervision while maintaining anonymity to the public has been an ongoing challenge. In existing solutions, certification authorities need to record all pairs of identities and pseudonyms, which is demanding and costly. This article proposed an account guarantee scheme to realize feasible supervision for existing anonymous blockchain networks with lower storage costs. Users are able to guarantee anonymous accounts with account guarantee key pairs generated from certificated polynomial functions, which inherently maintains one-to-n mapping certifications. Single or limited account guarantee key pairs do not leak privacy. Victims are able to request TCs to screen a cheater or disclose a cheater with enough fraud transactions by themselves. Detailed security and privacy analysis showed that the account guarantee scheme preserves user privacy and realizes feasible supervision. Experimental results demonstrated that the account guarantee scheme is efficient and practical.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W3172478172",
    "type": "article"
  },
  {
    "title": "Introduction to the Special Section on Security and Privacy of Medical Data for Smart Healthcare",
    "doi": "https://doi.org/10.1145/3460870",
    "publication_date": "2021-06-09",
    "publication_year": 2021,
    "authors": "Amit Kumar Singh; Q. M. Jonathan Wu; Ali Al‐Haj; Calton Pu",
    "corresponding_authors": "",
    "abstract": "introduction Share on Introduction to the Special Section on Security and Privacy of Medical Data for Smart Healthcare Editors: Amit Kumar Singh National Institute of Technology Patna, India National Institute of Technology Patna, IndiaSearch about this author , Jonathan Wu University of Windsor, Canada University of Windsor, CanadaSearch about this author , Ali Al-Haj Princess Sumaya University for Technology, Jordan Princess Sumaya University for Technology, JordanSearch about this author , Calton Pu Georgia Institute of Technology, USA Georgia Institute of Technology, USASearch about this author Authors Info & Claims ACM Transactions on Internet TechnologyVolume 21Issue 3August 2021 Article No.: 53pp 1–4https://doi.org/10.1145/3460870Online:09 June 2021Publication History 3citation88DownloadsMetricsTotal Citations3Total Downloads88Last 12 Months88Last 6 weeks5 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteGet Access",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W3173052564",
    "type": "article"
  },
  {
    "title": "The Efficient Mining of Skyline Patterns from a Volunteer Computing Network",
    "doi": "https://doi.org/10.1145/3423557",
    "publication_date": "2021-07-16",
    "publication_year": 2021,
    "authors": "Jimmy Ming‐Tai Wu; Qian Teng; Gautam Srivastava; Matin Pirouz; Jerry Chun‐Wei Lin",
    "corresponding_authors": "",
    "abstract": "In the ever-growing world, the concepts of High-utility Itemset Mining (HUIM) as well as Frequent Itemset Mining (FIM) are fundamental works in knowledge discovery. Several algorithms have been designed successfully. However, these algorithms only used one factor to estimate an itemset. In the past, skyline pattern mining by considering both aspects of frequency and utility has been extensively discussed. In most cases, however, people tend to focus on purchase quantities of itemsets rather than frequencies. In this article, we propose a new knowledge called skyline quantity-utility pattern (SQUP) to provide better estimations in the decision-making process by considering quantity and utility together. Two algorithms, respectively, called SQU-Miner and SKYQUP are presented to efficiently mine the set of SQUPs. Moreover, the usage of volunteer computing is proposed to show the potential in real supermarket applications. Two new efficient utility-max structures are also mentioned for the reduction of the candidate itemsets, respectively, utilized in SQU-Miner and SKYQUP. These two new utility-max structures are used to store the upper-bound of utility for itemsets under the quantity constraint instead of frequency constraint, and the second proposed utility-max structure moreover applies a recursive updated process to further obtain strict upper-bound of utility. Our in-depth experimental results prove that SKYQUP has stronger performance when a comparison is made to SQU-Miner in terms of memory usage, runtime, and the number of candidates.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W3185092620",
    "type": "article"
  },
  {
    "title": "Merging Grid Maps in Diverse Resolutions by the Context-based Descriptor",
    "doi": "https://doi.org/10.1145/3403948",
    "publication_date": "2021-07-22",
    "publication_year": 2021,
    "authors": "Zhiyang Lin; Jihua Zhu; Zutao Jiang; Yujie Li; Yaochen Li; Zhongyu Li",
    "corresponding_authors": "",
    "abstract": "Building an accurate map is essential for autonomous robot navigation in the environment without GPS. Compared with single-robot, the multiple-robot system has much better performance in terms of accuracy, efficiency and robustness for the simultaneous localization and mapping (SLAM). As a critical component of multiple-robot SLAM, the problem of map merging still remains a challenge. To this end, this article casts it into point set registration problem and proposes an effective map merging method based on the context-based descriptors and correspondence expansion. It first extracts interest points from grid maps by the Harris corner detector. By exploiting neighborhood information of interest points, it automatically calculates the maximum response radius as scale information to compute the context-based descriptor, which includes eigenvalues and normals computed from local structures of each interest point. Then, it effectively establishes origin matches with low precision by applying the nearest neighbor search on the context-based descriptor. Further, it designs a scale-based corresponding expansion strategy to expand each origin match into a set of feature matches, where one similarity transformation between two grid maps can be estimated by the Random Sample Consensus algorithm. Subsequently, a measure function formulated from the trimmed mean square error is utilized to confirm the best similarity transformation and accomplish the coarse map merging. Finally, it utilizes the scaling trimmed iterative closest point algorithm to refine initial similarity transformation so as to achieve accurate merging. As the proposed method considers scale information in the context-based descriptor, it is able to merge grid maps in diverse resolutions. Experimental results on real robot datasets demonstrate its superior performance over other related methods on accuracy and robustness.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W3185743877",
    "type": "article"
  },
  {
    "title": "DADC: A Novel Duty-cycling Scheme for IEEE 802.15.4 Cluster-tree-based IoT Applications",
    "doi": "https://doi.org/10.1145/3409487",
    "publication_date": "2021-10-29",
    "publication_year": 2021,
    "authors": "Nikumani Choudhury; Rakesh Matam; Mithun Mukherjee; Jaime Lloret",
    "corresponding_authors": "",
    "abstract": "The IEEE 802.15.4 standard is one of the widely adopted specifications for realizing different applications of the Internet of Things. It defines several physical layer options and Medium Access Control (MAC) sub-layer for devices with low-power operating at low data rates. As devices implementing this standard are primarily battery-powered, minimizing their power consumption is a significant concern. Duty-cycling is one such power conserving mechanism that allows a device to schedule its active and inactive radio periods effectively, thus preventing energy drain due to idle listening. The standard specifies two parameters, beacon order and superframe order, which define the active and inactive period of a device. However, it does not specify a duty-cycling scheme to adapt these parameters for varying network conditions. Existing works in this direction are either based on superframe occupation ratio or buffer/queue length of devices. In this article, the particular limitations of both the approaches mentioned above are presented. Later, a novel duty-cycling mechanism based on MAC parameters is proposed. Also, we analyze the role of synchronization schemes in achieving efficient duty-cycles in synchronized cluster-tree network topologies. A Markov model has also been developed for the MAC protocol to estimate the delay and energy consumption during frame transmission.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W3209499442",
    "type": "article"
  },
  {
    "title": "Analysis of Trending Topics and Text-based Channels of Information Delivery in Cybersecurity",
    "doi": "https://doi.org/10.1145/3483332",
    "publication_date": "2021-10-29",
    "publication_year": 2021,
    "authors": "Tingmin Wu; Wanlun Ma; Sheng Wen; Xin Xia; Cécile Paris; ‪Surya Nepal‬; Yang Xiang",
    "corresponding_authors": "",
    "abstract": "Computer users are generally faced with difficulties in making correct security decisions. While an increasingly fewer number of people are trying or willing to take formal security training, online sources including news, security blogs, and websites are continuously making security knowledge more accessible. Analysis of cybersecurity texts from this grey literature can provide insights into the trending topics and identify current security issues as well as how cyber attacks evolve over time. These in turn can support researchers and practitioners in predicting and preparing for these attacks. Comparing different sources may facilitate the learning process for normal users by creating the patterns of the security knowledge gained from different sources. Prior studies neither systematically analysed the wide range of digital sources nor provided any standardisation in analysing the trending topics from recent security texts. Moreover, existing topic modelling methods are not capable of identifying the cybersecurity concepts completely and the generated topics considerably overlap. To address this issue, we propose a semi-automated classification method to generate comprehensive security categories to analyse trending topics. We further compare the identified 16 security categories across different sources based on their popularity and impact. We have revealed several surprising findings as follows: (1) The impact reflected from cybersecurity texts strongly correlates with the monetary loss caused by cybercrimes, (2) security blogs have produced the context of cybersecurity most intensively, and (3) websites deliver security information without caring about timeliness much.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W3210383695",
    "type": "article"
  },
  {
    "title": "Topic-aware Incentive Mechanism for Task Diffusion in Mobile Crowdsourcing through Social Network",
    "doi": "https://doi.org/10.1145/3487580",
    "publication_date": "2021-12-20",
    "publication_year": 2021,
    "authors": "Jia Xu; Yuanhang Zhou; Chen Gong-yu; Yuqing Ding; Dejun Yang; Linfeng Liu",
    "corresponding_authors": "",
    "abstract": "Crowdsourcing has become an efficient paradigm to utilize human intelligence to perform tasks that are challenging for machines. Many incentive mechanisms for crowdsourcing systems have been proposed. However, most of existing incentive mechanisms assume that there are sufficient participants to perform crowdsourcing tasks. In large-scale crowdsourcing scenarios, this assumption may be not applicable. To address this issue, we diffuse the crowdsourcing tasks in social network to increase the number of participants. To make the task diffusion more applicable to crowdsourcing system, we enhance the classic Independent Cascade model so the influence is strongly connected with both the types and topics of tasks. Based on the tailored task diffusion model, we formulate the Budget Feasible Task Diffusion ( BFTD ) problem for maximizing the value function of platform with constrained budget. We design a parameter estimation algorithm based on Expectation Maximization algorithm to estimate the parameters in proposed task diffusion model. Benefitting from the submodular property of the objective function, we apply the budget-feasible incentive mechanism, which satisfies desirable properties of computational efficiency, individual rationality, budget-feasible, truthfulness, and guaranteed approximation, to stimulate the task diffusers. The simulation results based on two real-world datasets show that our incentive mechanism can improve the number of active users and the task completion rate by 9.8% and 11%, on average.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4200302153",
    "type": "article"
  },
  {
    "title": "A programmable network address translator",
    "doi": "https://doi.org/10.1145/1667067.1667070",
    "publication_date": "2010-02-01",
    "publication_year": 2010,
    "authors": "Tzu-Chi Huang; Sherali Zeadally; Naveen Chilamkurti; Ce-Kuen Shieh",
    "corresponding_authors": "",
    "abstract": "Network Address Translation (NAT) alleviates the shortage of IPv4 addresses but incurs peer-to-peer communication, application functionality and packet integrity problems. To date, no approach has yet been proposed to solve these three problems. By exploiting mobile agent and active networking technologies, we propose a Programmable Network Address Translation (PNAT) implementation that enables peer-to-peer communication while maintaining application functionality and packet integrity. For peer-to-peer communication, our proposed PNAT approach works for various NAT types (including the Symmetric NAT) with simple APIs supported by our proposed NAT design. For application functionality, the PNAT uses the mobile code to update protocol information in packet payloads according to different application needs. For packet integrity, the PNAT allows applications to delay their data encryption until NAT begins to translate addresses and ports in packet headers. To validate our proposed PNAT approach, we implemented the PNAT design on Windows 2000, and we present an empirical performance evaluation of the implemented design.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2056451108",
    "type": "article"
  },
  {
    "title": "Towards Inferring Communication Patterns in Online Social Networks",
    "doi": "https://doi.org/10.1145/3093897",
    "publication_date": "2017-07-09",
    "publication_year": 2017,
    "authors": "Ero Balsa; Cristina Pérez‐Solà; Claudia Díaz",
    "corresponding_authors": "",
    "abstract": "The separation between the public and private spheres on online social networks is known to be, at best, blurred. On the one hand, previous studies have shown how it is possible to infer private attributes from publicly available data. On the other hand, no distinction exists between public and private data when we consider the ability of the online social network (OSN) provider to access them. Even when OSN users go to great lengths to protect their privacy, such as by using encryption or communication obfuscation, correlations between data may render these solutions useless. In this article, we study the relationship between private communication patterns and publicly available OSN data. Such a relationship informs both privacy-invasive inferences as well as OSN communication modelling, the latter being key toward developing effective obfuscation tools. We propose an inference model based on Bayesian analysis and evaluate, using a real social network dataset, how archetypal social graph features can lead to inferences about private communication. Our results indicate that both friendship graph and public traffic data may not be informative enough to enable these inferences, with time analysis having a non-negligible impact on their precision.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2734535397",
    "type": "article"
  },
  {
    "title": "GREENHOME: A Household Energy Consumption and CO <sub>2</sub> Footprint Metering Environment",
    "doi": "https://doi.org/10.1145/3505264",
    "publication_date": "2022-01-22",
    "publication_year": 2022,
    "authors": "Genoveva Vargas‐Solar; Maysaa Khalil; Javier A. Espinosa-Oviedo; José-Luis Zechinelli-Martini",
    "corresponding_authors": "",
    "abstract": "This article presents the GREENHOME environment, a toolkit providing several data analytical tools for metering household energy consumption and CO 2 footprint under different perspectives. GREENHOME enables a multi-perspective analysis of household energy consumption and CO 2 footprint using and combining several variables through various statistics and data mining algorithms. To test GREENHOME, the article reports on experiments conducted for modelling and forecasting energy consumption and CO 2 footprint in the context of the Triple-A European project.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4205735803",
    "type": "article"
  },
  {
    "title": "Resilient Distributed Constraint Reasoning to Autonomously Configure and Adapt IoT Environments",
    "doi": "https://doi.org/10.1145/3507907",
    "publication_date": "2022-02-03",
    "publication_year": 2022,
    "authors": "Pierre Rust; Gauthier Picard; Fano Ramparany",
    "corresponding_authors": "",
    "abstract": "In this article, we investigate multi-agent techniques to install autonomy and adaptation in IoT-based smart environment settings, like smart home scenarios. We particularly make use of the smart environment configuration problem (SECP) framework, and map it to a distributed optimization problem (DCOP). This consists in enabling smart objects to coordinate and self-configure as to meet both user-defined requirements and energy efficiency, by operating a distributed constraint reasoning process over a computation graph. As to cope with the dynamics of the environment and infrastructure (e.g., by adding or removing devices), we also specify the k -resilient distribution of graph-structured computations supporting agent decisions, over dynamic and physical multi-agent systems. We implement a self-organizing distributed repair method, based on a distributed constraint optimization algorithm to adapt the distribution as to ensure the system still performs collective decisions and remains resilient to upcoming changes. We provide a full stack of mechanisms to install resilience in operating stateless DCOP solution methods, which results in a robust approach using a fast DCOP algorithm to repair any stateless DCOP solution methods at runtime. We experimentally evaluate the performances of these techniques when operating stateless DCOP algorithms to solve SECP instances.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4210638385",
    "type": "article"
  },
  {
    "title": "Optimization-Based Predictive Congestion Control for the Tor Network: Opportunities and Challenges",
    "doi": "https://doi.org/10.1145/3520440",
    "publication_date": "2022-03-04",
    "publication_year": 2022,
    "authors": "Christoph Döpmann; Felix Fiedler; Sergio Lucia; Florian Tschorsch",
    "corresponding_authors": "",
    "abstract": "Based on the principle of onion routing, the Tor network achieves anonymity for its users by relaying user data over a series of intermediate relays. This approach makes congestion control in the network a challenging task. As of this writing, this results in higher latencies due to considerable backlog as well as unfair data rate allocation. In this article, we present a concept study of PredicTor, a novel approach to congestion control that tackles clogged overlay networks. Unlike traditional approaches, it is built upon the idea of distributed model predictive control, a recent advancement from the area of control theory. PredicTor is tailored to minimizing latency in the network and achieving max-min fairness. We contribute a thorough evaluation of its behavior in both toy scenarios to assess the optimizer and complex networks to assess its potential. For this, we conduct large-scale simulation studies and compare PredicTor to existing congestion control mechanisms in Tor. We show that PredicTor is highly effective in reducing latency and realizing fair rate allocations. In addition, we strive to bring the ideas of modern control theory to the networking community, enabling the development of improved, future congestion control. Thus, we demonstrate benefits and issues alike with this novel research direction.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4214877065",
    "type": "article"
  },
  {
    "title": "An Intent-driven DaaS Management Framework to Enhance User Quality of Experience",
    "doi": "https://doi.org/10.1145/3488586",
    "publication_date": "2022-03-23",
    "publication_year": 2022,
    "authors": "Chao Wu; Shingo Horiuchi; Kenji Murase; Hiroaki Kikushima; Kenichi Tayama",
    "corresponding_authors": "",
    "abstract": "Desktop as a Service (DaaS) has become widely used by enterprises. In 2020, the use of DaaS increased dramatically due to the demand to work remotely from home during the COVID-19 pandemic. The DaaS market is expected to continue growing rapidly [ 1 ]. The quality of experience (QoE) of a DaaS service has been one of the main factors to enhance DaaS user satisfaction. To ensure user QoE, the amount of cloud computation resources for a DaaS service must be appropriately designed. We propose an Intent-driven DaaS Management (IDM) framework to autonomously determine the cloud-resource-amount configurations for a given DaaS QoE requirement. IDM enables autonomous resource design by abstracting the knowledge about the dependency between DaaS workload, resource configuration, and performance from previous DaaS performance log data. To ensure the IDM framework's applicability to actual DaaS services, we analyzed five main challenges in applying the IDM framework to actual DaaS services: identifying the resource-design objective, quantifying DaaS QoE, addressing low log data availability, designing performance-inference models, and addressing low resource variations in the log data. We addressed these challenges through detailed designing of IDM modules. The effectiveness of the IDM framework was assessed from the aspects of DaaS performance-inference precision, DaaS resource design, and time and human-resource cost reduction.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4220998630",
    "type": "article"
  },
  {
    "title": "Joint Architecture Design and Workload Partitioning for DNN Inference on Industrial IoT Clusters",
    "doi": "https://doi.org/10.1145/3551638",
    "publication_date": "2022-07-28",
    "publication_year": 2022,
    "authors": "Weiwei Fang; Wenyuan Xu; Chongchong Yu; Naixue Xiong",
    "corresponding_authors": "",
    "abstract": "The advent of Deep Neural Networks (DNNs) has empowered numerous computer-vision applications. Due to the high computational intensity of DNN models, as well as the resource constrained nature of Industrial Internet-of-Things (IIoT) devices, it is generally very challenging to deploy and execute DNNs efficiently in the industrial scenarios. Substantial research has focused on model compression or edge-cloud offloading, which trades off accuracy for efficiency or depends on high-quality infrastructure support, respectively. In this article, we present EdgeDI, a framework for executing DNN inference in a partitioned, distributed manner on a cluster of IIoT devices. To improve the inference performance, EdgeDI exploits two key optimization knobs, including: (1) Model compression based on deep architecture design, which transforms the target DNN model into a compact one that reduces the resource requirements for IIoT devices without sacrificing accuracy; (2) Distributed inference based on adaptive workload partitioning, which achieves high parallelism by adaptively balancing the workload distribution among IIoT devices under heterogeneous resource conditions. We have implemented EdgeDI based on PyTorch, and evaluated its performance with the NEU-CLS defect classification task and two typical DNN models (i.e., VGG and ResNet) on a cluster of heterogeneous Raspberry Pi devices. The results indicate that the proposed two optimization approaches significantly outperform the existing solutions in their specific domains. When they are well combined, EdgeDI can provide scalable DNN inference speedups that are very close to or even much higher than the theoretical speedup bounds, while still maintaining the desired accuracy.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4288084599",
    "type": "article"
  },
  {
    "title": "Enabling Short-Term Energy Flexibility Markets Through Blockchain",
    "doi": "https://doi.org/10.1145/3542949",
    "publication_date": "2022-06-11",
    "publication_year": 2022,
    "authors": "Michell Boerger; Philipp Lämmel; Nikolay Tcholtchev; Manfred Hauswirth",
    "corresponding_authors": "",
    "abstract": "Climate change has put significant pressure on energy markets. Political decisions such as the plan of the German government to shut down coal power plants by 2038 are shifting electricity production towards renewable and distributed energy resources. The share of these resources will continue to grow significantly in the coming years. This trend changes the ways how energy markets work which mandates fundamental changes in the underlying IT infrastructure. In this paper, we propose a blockchain-based solution which enables an economically viable and grid-serving integration of distributed energy resources into the existing energy system. Our blockchain-based approach targets intraday and day-ahead operating reserve markets, on which energy grid operators and operators of distributed energy resources can trade flexibilities within the schedulable energy production and consumption of their resources. By utilizing these flexibilities as an operating reserve, renewable and climate-friendly technologies can contribute to maintaining the grid stability and security of supply while simultaneously creating economically interesting business models for their operators. We propose to define blockchain-based short-term energy markets by utilizing the concept of general-purpose smart contracts and cryptocurrencies. This enables direct and decentralized trading of energy flexibilities without any intermediary or central instance. We demonstrate the feasibility of our approach through an implementation of a prototype of the proposed markets based on the Ethereum blockchain and provide a detailed evaluation of its efficiency and scalability.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4293083920",
    "type": "article"
  },
  {
    "title": "A Low-code Development Framework for Cloud-native Edge Systems",
    "doi": "https://doi.org/10.1145/3563215",
    "publication_date": "2022-09-15",
    "publication_year": 2022,
    "authors": "Wenzhao Zhang; Yuxuan Zhang; Hongchang Fan; Yi Gao; Wei Dong",
    "corresponding_authors": "",
    "abstract": "Customizing and deploying an edge system are time-consuming and complex tasks because of hardware heterogeneity, third-party software compatibility, diverse performance requirements, and so on. In this article, we present TinyEdge, a holistic framework for the low-code development of edge systems. The key idea of TinyEdge is to use a top-down approach for designing edge systems. Developers select and configure TinyEdge modules to specify their interaction logic without dealing with the specific hardware or software. Taking the configuration as input, TinyEdge automatically generates the deployment package and estimates the performance with sufficient profiling. TinyEdge provides a unified development toolkit to specify module dependencies, functionalities, interactions, and configurations. We implement TinyEdge and evaluate its performance using real-world edge systems. Results show that: (1) TinyEdge achieves rapid customization of edge systems, reducing 44.15% of development time and 67.79% of lines of code on average compared with the state-of-the-art edge computing platforms; (2) TinyEdge builds compact modules and optimizes the latent circular dependency detection and message routing efficiency; (3) TinyEdge performance estimation has low absolute errors in various settings.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4296131544",
    "type": "article"
  },
  {
    "title": "Conco-ERNIE: Complex User Intent Detect Model for Smart Healthcare Cognitive Bot",
    "doi": "https://doi.org/10.1145/3574135",
    "publication_date": "2022-12-08",
    "publication_year": 2022,
    "authors": "Bolin Zhang; Zhiying Tu; Shaoshi Hang; Dianhui Chu; Xiaofei Xu",
    "corresponding_authors": "",
    "abstract": "The outbreak of Covid-19 has exposed the lack of medical resources, especially the lack of medical personnel. This results in time and space restrictions for medical services, and patients cannot obtain health information all the time and everywhere. Based on the medical knowledge graph, healthcare bots alleviate this burden effectively by providing patients with diagnosis guidance, pre-diagnosis, and post-diagnosis consultation services in the way of human-machine dialogue. However, the medical utterance is more complicated in language structure, and there are complex intention phenomena in semantics. It is a challenge to detect the single intent, multi-intent, and implicit intent of a patient’s utterance. To this end, we create a high-quality annotated Chinese Medical query (utterance) dataset, CMedQ (about 16.8k queries in medical domain which includes single, multiple, and implicit intents). It is hard to detect intent on such a complex dataset through traditional text classification models. Thus, we propose a novel detect model Conco-ERNIE , using concept co-occurrence patterns to enhance the representation of pre-trained model ERNIE. These patterns are mined using Apriori algorithm and will be embedded via Node2Vec. Their features will be aggregated with semantic features into Conco-ERNIE by using an attention module, which can catch user explicit intents and also predict user implicit intents. Experiments on CMedQ demonstrates that Conco-ERNIE achieves outstanding performance over baseline. Based on Conco-ERNIE, we develop an intelligent healthcare bot, MedicalBot . To provide knowledge support for MedicalBot , we also build a Chinese medical graph, CMedKG (about 45k entities and 283k relationships).",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4311938378",
    "type": "article"
  },
  {
    "title": "Introduction to the Special Section on Cyber Security in Internet of Vehicles",
    "doi": "https://doi.org/10.1145/3584746",
    "publication_date": "2022-11-30",
    "publication_year": 2022,
    "authors": "Ching‐Hsien Hsu; Amir H. Alavi; Mianxiong Dong",
    "corresponding_authors": "",
    "abstract": "introduction Share on Introduction to the Special Section on Cyber Security in Internet of Vehicles Authors: Ching-Hsien Hsu Department of Computer Science and Information Engineering, Asia University, Taiwan; Department of Medical Research, China Medical University Hospital, China Medical University, Wufeng, Taichung, Taiwan Department of Computer Science and Information Engineering, Asia University, Taiwan; Department of Medical Research, China Medical University Hospital, China Medical University, Wufeng, Taichung, Taiwan 0000-0002-2440-2771Search about this author , Amir H. Alavi Department of Civil and Environmental Engineering, University of Pittsburgh, Pittsburgh, PA, USA Department of Civil and Environmental Engineering, University of Pittsburgh, Pittsburgh, PA, USA 0000-0002-7593-8509Search about this author , Mianxiong Dong Department of Sciences and Informatics, Muroran Institute of Technology, Muroran, Hokkaido, Japan Department of Sciences and Informatics, Muroran Institute of Technology, Muroran, Hokkaido, Japan 0000-0002-2788-3451Search about this author Authors Info & Claims ACM Transactions on Internet TechnologyVolume 22Issue 4November 2022 Article No.: 81pp 1–6https://doi.org/10.1145/3584746Published:15 March 2023Publication History 0citation0DownloadsMetricsTotal Citations0Total Downloads0Last 12 Months0Last 6 weeks0 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteGet Access",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4327520642",
    "type": "article"
  },
  {
    "title": "A self-configuring and self-administering name system with dynamic address assignment",
    "doi": "https://doi.org/10.1145/503334.503336",
    "publication_date": "2002-02-01",
    "publication_year": 2002,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "In this article we present a distributed system that stores name-to-address bindings and provides name resolution to a network of computers. This name system consists of a network of name services that are individually self-configuring and self-administering. The name service consists of an agent program that works in conjunction with the current implementation of the Domain Name System (DNS) program. The DNS agent program automatically configures the Berkeley Internet Name Domain (BIND) process during start-up and dynamically reconfigures and administers the BIND process based on the changing state of the network. The proposed name system offers high scalability and fault-tolerance capabilities and communicates using standard Internet protocols.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W3124284039",
    "type": "article"
  },
  {
    "title": "ContextAiDe",
    "doi": "https://doi.org/10.1145/3301444",
    "publication_date": "2019-04-03",
    "publication_year": 2019,
    "authors": "Madhurima Pore; Vinaya Chakati; Ayan Banerjee; Sandeep K. S. Gupta",
    "corresponding_authors": "",
    "abstract": "Mobile crowd-sensing (MCS) enables development of context-aware applications by mining relevant information from a large set of devices selected in an ad hoc manner. For example, MCS has been used for real-time monitoring such as Vehicle ad hoc Networks-based traffic updates as well as offline data mining and tagging for future use in applications with location-based services. However, MCS could be potentially used for much more demanding applications such as real-time perpetrator tracking by online mining of images from nearby mobile users. A recent example is tracking the miscreant responsible for the Boston bombing. We present a new design approach for tracking using MCS for such complex processing in real time. Since MCS applications assume an unreliable underlying computational platform, most typically sample size for recruited devices is guided by concerns such as fault tolerance and reliability of information. As the real-time requirements get stricter coupled with increasing complexity of data-mining approaches, the communication and computation overheads can impose a very tight constraint on the sample size of devices needed for realizing real-time operation. This results in trade-off in acquiring context-relevant data and resource usage incurred while the real-time operation requirements get updated dynamically. Such effects have not been properly studied and optimized to enable real-time MCS applications such as perpetrator tracking. In this article, we propose ContextAiDe architecture, a combination of API, middleware, and optimization engine. The key innovation in ContextAiDe is context-optimized recruitment for execution of computation- and communication-heavy MCS applications in edge environment. ContextAiDe uses a notion of two types of contexts, exact (hard constraints), which have to be satisfied, and preferred (soft constraints), which may be satisfied to a certain degree. By adjusting the preferred contexts, ContextAiDe can optimize the operational overheads to enable real-time operation. ContextAiDe provides an API to specify contexts requirements and the code of MCS app, offload execution environment, a middleware that enables context-optimized and a fault-tolerant distributed execution. ContextAiDe evaluation using a real-time perpetrator tracking application shows reduced energy consumption of 37.8%, decrease in data transfer of 24.8%, and 43% less time compared to existing strategy. In spite of a small increase in the minimum distance from the perpetrator, iterations of optimization tracks the perpetrator successfully. Pro-actively learning the context and using stochastic optimization strategy minimizes the performance degradation caused due to uncertainty (&lt;20%) in usage-dependent contexts.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2928569208",
    "type": "article"
  },
  {
    "title": "On the Profitability of Bundling Sale Strategy for Online Service Markets With Network Effects",
    "doi": "https://doi.org/10.1145/3277667",
    "publication_date": "2019-05-03",
    "publication_year": 2019,
    "authors": "Ye Li; Weijie Wu; T. B. Richard; John C. S. Lui",
    "corresponding_authors": "",
    "abstract": "In recent years, we have witnessed a growing trend for online service companies to offer “bundling sales” to increase revenue. Bundling sale means that a company groups a set of products/services and charges this bundle at a fixed price, which is usually less than the total price of individual items in the bundle. In this work, our aim is to understand the underlying dynamics of bundling, particularly what is the optimal bundling sale strategy and under what situations it will be more attractive than the separate sales. We focus on online service markets that exhibit network effects . We formulate mathematical models to capture the interactions between buyers and sellers, analyze the market equilibrium and its stability, and provide an optimization framework to determine the optimal sale strategy for a service provider. We analyze the impact of various factors on the profitability of bundling, including the network effects, operating costs, and variance and correlation of customers’ valuations toward these services. We show that bundling is more profitable when the variance of customers’ valuations and the operational cost of the services are small. In addition, a positive network effect and a negative correlation among customers’ valuation on services increase the profitability of bundling, whereas the heterogeneity of services and the asymmetry of operating costs reduce its advantage.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2942750196",
    "type": "article"
  },
  {
    "title": "Threat Management in Data-centric IoT-Based Collaborative Systems",
    "doi": "https://doi.org/10.1145/3323232",
    "publication_date": "2019-08-27",
    "publication_year": 2019,
    "authors": "Muhamad Felemban; Emad Felemban; Jason Kobes; Arif Ghafoor",
    "corresponding_authors": "",
    "abstract": "In this article, we propose a threat management system (TMS) for Data-centric Internet-of-Things-based Collaborative Systems (DIoTCSs). In particular, we focus on tampering attacks that target shared databases and can affect the execution of the DIoTCS services. The novelty of the proposed system is to isolate the damage caused by tampering attacks into data partitions. We formulate the partitioning problem as a cost-driven optimization problem, prove its NP-hardness, and propose two polynomial-time heuristics. We evaluate a TMS experimentally and demonstrate that intelligent partitioning of the database improves the overall availability of the DIoTCS.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2970792650",
    "type": "article"
  },
  {
    "title": "Introduction to the Special Section on Trust and AI",
    "doi": "https://doi.org/10.1145/3365675",
    "publication_date": "2019-11-09",
    "publication_year": 2019,
    "authors": "Jie Zhang; Jamal Bentahar; Rino Falcone; Timothy J. Norman; Murat Şensoy",
    "corresponding_authors": "",
    "abstract": "editorial Free Access Share on Introduction to the Special Section on Trust and AI Editors: Jie Zhang NTU, Singapore NTU, SingaporeView Profile , Jamal Bentahar Concordia University, Canada Concordia University, CanadaView Profile , Rino Falcone ISTC-CNR, Italy ISTC-CNR, ItalyView Profile , Timothy J. Norman University of Southampton, UK University of Southampton, UKView Profile , Murat Şensoy Blue Prism Labs, UK Blue Prism Labs, UKView Profile Authors Info & Claims ACM Transactions on Internet TechnologyVolume 19Issue 4November 2019 Article No.: 44epp 1–3https://doi.org/10.1145/3365675Online:09 November 2019Publication History 0citation344DownloadsMetricsTotal Citations0Total Downloads344Last 12 Months114Last 6 weeks6 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my Alerts New Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteView all FormatsPDF",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W3000904849",
    "type": "article"
  },
  {
    "title": "Fine-Grained Control over Tracking to Support the Ad-Based Web Economy",
    "doi": "https://doi.org/10.1145/3158372",
    "publication_date": "2018-09-30",
    "publication_year": 2018,
    "authors": "Jagdish Prasad Achara; Javier Parra‐Arnau; Claude Castelluccia",
    "corresponding_authors": "",
    "abstract": "The intrusiveness of Web tracking and the increasing invasiveness of digital advertising have raised serious concerns regarding user privacy and Web usability, leading a substantial chunk of the populace to adopt ad-blocking technologies in recent years. The problem with these technologies, however, is that they are extremely limited and radical in their approach, and they completely disregard the underlying economic model of the Web, in which users get content free in return for allowing advertisers to show them ads. Nowadays, with around 200 million people regularly using such tools, said economic model is in danger. In this article, we investigate an Internet technology that targets users who are not, in general, against advertising, accept the trade-off that comes with the “free” content, but—for privacy concerns—they wish to exert fine-grained control over tracking. Our working assumption is that some categories of web pages (e.g., related to health or religion) are more privacy-sensitive to users than others (e.g., about education or science). Capitalizing on this, we propose a technology that allows users to specify the categories of web pages that are privacy-sensitive to them and block the trackers present on such web pages only. As tracking is prevented by blocking network connections of third-party domains, we avoid not only tracking but also third-party ads. Since users continue receiving ads on those web pages that belong to non-sensitive categories, our approach may provide a better point of operation within the trade-off between user privacy and the Web economy. To test the appropriateness and feasibility of our solution, we implemented it as a Web-browser plug-in, which is currently available for Google Chrome and Mozilla Firefox. Experimental results from the collected data of 746 users during one year show that only 16.25% of ads are blocked by our tool, which seems to indicate that the economic impact of the ad-blocking exerted by privacy-sensitive users could be significantly reduced.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W3004998422",
    "type": "article"
  },
  {
    "title": "Efficient Latency Control in Fog Deployments via Hardware-Accelerated Popularity Estimation",
    "doi": "https://doi.org/10.1145/3366020",
    "publication_date": "2020-08-12",
    "publication_year": 2020,
    "authors": "Marcel Enguehard; Yoann Desmouceaux; Giovanna Carofiglio",
    "corresponding_authors": "",
    "abstract": "Introduced as an extension of the Cloud at the network edge for computing and storage purposes, the Fog is increasingly considered a key enabler for Internet-of-Things applications whose latency requirements are not compatible with a Cloud-only approach. Unlike Cloud platforms, which can elastically accommodate large numbers of requests, Fog deployments are usually dimensioned for an average traffic load and, thus, unable to handle sudden bursts of requests without violating latency guarantees. In this article, we address the problem of efficiently controlling Fog admission to guarantee application response time. We propose request-aware admission control (AC) strategies maximizing the number of Fog-handled requests by means of dynamic popularity estimation. In particular, the LRU-AC , an AC strategy based on online learning of the request popularity distribution via a Least Recently Used (LRU) filter, is introduced. We contribute an analytical model for assessing LRU-AC performance and quantifying the incurred reduction of Cloud offload cost, w.r.t. both an ideal oracle-based and a request-oblivious AC strategy. Further, we propose a feasible implementation design of LRU-AC on FPGA hardware using Aging Bloom Filters (ABF) to mimic the function of the LRU-AC, while providing a compact memory representation. The use of ABFs for LRU-AC is theoretically validated and verified through simulation. The current implementation shows a throughput of 16.7 Mpps and a processing latency of less than 3μ s while multiplying the Fog acceptance-rate by 10 in the evaluated scenario.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W3048470949",
    "type": "article"
  },
  {
    "title": "Ursa",
    "doi": "https://doi.org/10.1145/3412341",
    "publication_date": "2020-11-05",
    "publication_year": 2020,
    "authors": "Na Ruan; Zhou Dong-li; Weijia Jia",
    "corresponding_authors": "",
    "abstract": "With the increasing number of users in blockchain-based cryptocurrencies, the public has raised the demand for transaction throughput, and many protocols are designed to improve the throughput following the Nakamoto consensus. Although astonishing progress has been made in the on-chain throughput improvement, high throughput makes the blockchains suffer from the increasing blockchain size, hard forks, and possible attacks. In this work, we propose a quantitative model to describe and analyze the Nakamoto consensus. We then design a robust scheme named Ursa to reduce storage requirements and to reduce the forks by automatically adjusting block size according to users’ needs.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W3097286648",
    "type": "article"
  },
  {
    "title": "A Reinforcement Learning Approach to Optimize Discount and Reputation Tradeoffs in E-commerce Systems",
    "doi": "https://doi.org/10.1145/3400024",
    "publication_date": "2020-10-27",
    "publication_year": 2020,
    "authors": "Hong Xie; Yongkun Li; John C. S. Lui",
    "corresponding_authors": "",
    "abstract": "Feedback-based reputation systems are widely deployed in E-commerce systems. Evidence shows that earning a reputable label (for sellers of such systems) may take a substantial amount of time, and this implies a reduction of profit. We propose to enhance sellers’ reputation via price discounts. However, the challenges are as follows: (1) The demands from buyers depend on both the discount and reputation, and (2) the demands are unknown to the seller. To address these challenges, we first formulate a profit maximization problem via a semi-Markov decision process to explore the optimal tradeoffs in selecting price discounts. We prove the monotonicity of the optimal profit and optimal discount. Based on the monotonicity, we design a Q-learning with forward projection (QLFP) algorithm, which infers the optimal discount from historical transaction data. We prove that the QLFP algorithm convergences to the optimal policy. We conduct trace-driven simulations using a dataset from eBay to evaluate the QLFP algorithm. Evaluation results show that QLFP improves the profit by as high as 50% over both Q-learning and Speedy Q-learning. The QLFP algorithm also improves both the reputation and profit by as high as two times over the scheme of not providing any price discount.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W3097781945",
    "type": "article"
  },
  {
    "title": "Personalizing Top-k Processing Online in a Peer-to-Peer Social Tagging Network",
    "doi": "https://doi.org/10.1145/2602572",
    "publication_date": "2014-07-01",
    "publication_year": 2014,
    "authors": "Xiao Bai; Rachid Guerraoui; Anne-Marie Kermarrec",
    "corresponding_authors": "",
    "abstract": "The rapidly increasing amount of user-generated content in social tagging systems provides a huge source of information. Yet, performing effective search in these systems is very challenging, especially when we seek the most appropriate items that match a potentially ambiguous query. Collaborative filtering-based personalization is appealing in this context, as it limits the search within a small network of participants with similar preferences. Offline personalization, which consists in maintaining, for every user, a network of similar participants based on their tagging behaviors, is effective for queries that are close to the querying user’s tagging profile but performs poorly when the queries, reflecting emerging interests, have little correlation with the querying user’s profile. We present P 2 TK 2 , the first protocol to personalize query processing in social tagging systems online. P 2 TK 2 is completely decentralized, and this design choice stems from the observation that the evolving social tagging systems naturally resemble P2P systems where users are both producers and consumers. This design exploits the power of the crowd and prevents any central authority from controlling personal information. P 2 TK 2 is gossip-based and probabilistic. It dynamically associates each user with social acquaintances sharing similar tagging behaviors. Appropriate users for answering a query are discovered at query time with the help of social acquaintances. This is achieved according to the hybrid interest of the querying user, taking into account both her tagging behavior and her query. Results are iteratively refined and returned to the querying user. We evaluate P 2 TK 2 on CiteULike and Delicious traces involving up to 50,000 users. We highlight the advantages of online personalization compared to offline personalization, as well as its efficiency, scalability, and inherent ability to cope with user departure and interest evolution in P2P systems.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W1967624602",
    "type": "article"
  },
  {
    "title": "Demand-Invariant Price Relationships and Market Outcomes in Competitive Private Commons",
    "doi": "https://doi.org/10.1145/2663495",
    "publication_date": "2014-10-28",
    "publication_year": 2014,
    "authors": "Emir Kavurmacioglu; Murat Alanyali; David Starobinski",
    "corresponding_authors": "",
    "abstract": "We introduce a private commons model that consists of network providers who serve a fixed primary demand and strategically price to improve their revenues from an additional secondary demand. For general forms of secondary demand, we establish the existence and uniqueness of two characteristic prices: the break-even price and the market sharing price. We show that the market sharing price is always greater than the break-even price, leading to a price interval in which a provider is both profitable and willing to share the demand. Making use of this result, we give insight into the nature of market outcomes.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2049128726",
    "type": "article"
  },
  {
    "title": "Mining and Quality Assessment of Mashup Model Patterns with the Crowd",
    "doi": "https://doi.org/10.1145/2903138",
    "publication_date": "2016-06-25",
    "publication_year": 2016,
    "authors": "Carlos Rodríguez; Florian Daniel; Fabio Casati",
    "corresponding_authors": "",
    "abstract": "Pattern mining, that is, the automated discovery of patterns from data, is a mathematically complex and computationally demanding problem that is generally not manageable by humans. In this article, we focus on small datasets and study whether it is possible to mine patterns with the help of the crowd by means of a set of controlled experiments on a common crowdsourcing platform. We specifically concentrate on mining model patterns from a dataset of real mashup models taken from Yahoo! Pipes and cover the entire pattern mining process, including pattern identification and quality assessment. The results of our experiments show that a sensible design of crowdsourcing tasks indeed may enable the crowd to identify patterns from small datasets (40 models). The results, however, also show that the design of tasks for the assessment of the quality of patterns to decide which patterns to retain for further processing and use is much harder (our experiments fail to elicit assessments from the crowd that are similar to those by an expert). The problem is relevant in general to model-driven development (e.g., UML, business processes, scientific workflows), in that reusable model patterns encode valuable modeling and domain knowledge, such as best practices, organizational conventions, or technical choices, that modelers can benefit from when designing their own models.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2469622947",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2630790",
    "publication_date": "2014-05-01",
    "publication_year": 2014,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "BitTorrent (BT) plays an important role in Internet content distribution. Because public BTs suffer from the free-rider problem, Darknets are becoming increasingly popular, which use Sharing Ratio Enforcement to increase their efficiency. We crawled and ...",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4236819414",
    "type": "paratext"
  },
  {
    "title": "Theory and network applications of balanced kautz tree structures",
    "doi": "https://doi.org/10.1145/2220352.2220355",
    "publication_date": "2012-06-01",
    "publication_year": 2012,
    "authors": "Deke Guo; Yunhao Liu; Hai Jin; Zhong Liu; Weiming Zhang; Hui Liu",
    "corresponding_authors": "",
    "abstract": "In order to improve scalability and to reduce the maintenance overhead for structured peer-to-peer (P2P) networks, researchers have proposed architectures based on several interconnection networks with a fixed-degree and a logarithmical diameter. Among existing fixed-degree interconnection networks, the Kautz digraph has many distinctive topological properties compared to others. It, however, requires that the number of peers have the some given values, determined by peer degree and network diameter. In practice, we cannot guarantee how many peers will join a P2P network at a given time, since a P2P network is typically dynamic with peers frequently entering and leaving. To address such an issue, we propose the balanced Kautz tree and Kautz ring structures. We further design a novel structured P2P system, called BAKE, based on the two structures that has the logarithmical diameter and constant degree, even the number of peers is an arbitrary value. By keeping a total ordering of peers and employing a robust locality-preserved resource placement strategy, resources that are similar in a single or multidimensional attributes space are stored on the same peer or neighboring peers. Through analysis and simulation, we show that BAKE achieves the optimal diameter and as good a connectivity as the Kautz digraph does (almost achieves the Moore bound), and supports the exact as well as the range queries efficiently. Indeed, the structures of balanced Kautz tree and Kautz ring we propose can also be applied to other interconnection networks after minimal modifications, for example, the de Bruijn digraph.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2024520444",
    "type": "article"
  },
  {
    "title": "Semantic integrity in large-scale online simulations",
    "doi": "https://doi.org/10.1145/1667067.1667069",
    "publication_date": "2010-02-01",
    "publication_year": 2010,
    "authors": "Somesh Jha; Stefan Katzenbeisser; Christian Schallhart; Helmut Veith; Stephen Chenney",
    "corresponding_authors": "",
    "abstract": "As large-scale online simulations such as Second Life and World of Warcraft are gaining economic significance, there is a growing incentive for attacks against such simulation software. We focus on attacks against the semantic integrity of the simulation. This class of attacks exploits the client-server architecture and is specific to online simulations which, for performance reasons, have to delegate the detailed rendering of the simulated world to the clients. Attacks against semantic integrity often compromise the physical laws of the simulated world—enabling the user's simulation persona to fly, walk through walls, or to run faster than anybody else. We introduce the Secure Semantic Integrity Protocol (SSIP), which enables the simulation provider to audit the client computations. Then we analyze the security and scalability of SSIP. First, we show that under standard cryptographic assumptions SSIP will detect semantic integrity attacks. Second, we analyze the network overhead, and determine the optimum tradeoff between cost of bandwidth and audit frequency for our protocol.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2069175038",
    "type": "article"
  },
  {
    "title": "Guest editorial",
    "doi": "https://doi.org/10.1145/1031114.1031115",
    "publication_date": "2004-11-01",
    "publication_year": 2004,
    "authors": "Gary William Flake; Paolo Frasconi; C. Lee Giles; Marco Maggini",
    "corresponding_authors": "",
    "abstract": "editorial Free Access Share on Guest editorial: Machine learning for the Internet Editors: Gary William Flake Yahoo! Research Labs Yahoo! Research LabsView Profile , Paolo Frasconi Università di Firenze Università di FirenzeView Profile , C. Lee Giles Pennsylvania State University Pennsylvania State UniversityView Profile , Marco Maggini Università di Siena Università di SienaView Profile Authors Info & Claims ACM Transactions on Internet TechnologyVolume 4Issue 4November 2004 pp 341–343https://doi.org/10.1145/1031114.1031115Published:01 November 2004Publication History 2citation900DownloadsMetricsTotal Citations2Total Downloads900Last 12 Months29Last 6 weeks3 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my Alerts New Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W1963825835",
    "type": "editorial"
  },
  {
    "title": "δ- <i> <b>Risk</b> </i> : Toward Context-aware Multi-objective Privacy Management in Connected Environments",
    "doi": "https://doi.org/10.1145/3418499",
    "publication_date": "2021-05-24",
    "publication_year": 2021,
    "authors": "Karam Bou‐Chaaya; Richard Chbeir; Mansour Naser Alraja; Philippe Arnould; Charith Perera; Mahmoud Barhamgi; Djamal Benslimane",
    "corresponding_authors": "",
    "abstract": "In today’s highly connected cyber-physical environments, users are becoming more and more concerned about their privacy and ask for more involvement in the control of their data. However, achieving effective involvement of users requires improving their privacy decision-making. This can be achieved by: (i) raising their awareness regarding the direct and indirect privacy risks they accept to take when sharing data with consumers; (ii) helping them in optimizing their privacy protection decisions to meet their privacy requirements while maximizing data utility. In this article, we address the second goal by proposing a user-centric multi-objective approach for context-aware privacy management in connected environments, denoted δ- Risk . Our approach features a new privacy risk quantification model to dynamically calculate and select the best protection strategies for the user based on her preferences and contexts. Computed strategies are optimal in that they seek to closely satisfy user requirements and preferences while maximizing data utility and minimizing the cost of protection. We implemented our proposed approach and evaluated its performance and effectiveness in various scenarios. The results show that δ- Risk delivers scalability and low-complexity in time and space. Besides, it handles privacy reasoning in real-time, making it able to support the user in various contexts, including ephemeral ones. It also provides the user with at least one best strategy per context.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W3093938569",
    "type": "article"
  },
  {
    "title": "Automated Discovery of Network Cameras in Heterogeneous Web Pages",
    "doi": "https://doi.org/10.1145/3450629",
    "publication_date": "2021-10-15",
    "publication_year": 2021,
    "authors": "Ryan Dailey; Aniesh Chawla; Andrew Liu; Sripath Mishra; Zhang Ling; Josh Majors; Yung-Hsiang Lu; George K. Thiruvathukal",
    "corresponding_authors": "",
    "abstract": "Reduction in the cost of Network Cameras along with a rise in connectivity enables entities all around the world to deploy vast arrays of camera networks. Network cameras offer real-time visual data that can be used for studying traffic patterns, emergency response, security, and other applications. Although many sources of Network Camera data are available, collecting the data remains difficult due to variations in programming interface and website structures. Previous solutions rely on manually parsing the target website, taking many hours to complete. We create a general and automated solution for aggregating Network Camera data spread across thousands of uniquely structured web pages. We analyze heterogeneous web page structures and identify common characteristics among 73 sample Network Camera websites (each website has multiple web pages). These characteristics are then used to build an automated camera discovery module that crawls and aggregates Network Camera data. Our system successfully extracts 57,364 Network Cameras from 237,257 unique web pages.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W3096595863",
    "type": "article"
  },
  {
    "title": "Special Section on AI-Empowered Internet of Things for Smart Cities",
    "doi": "https://doi.org/10.1145/3460868",
    "publication_date": "2021-06-09",
    "publication_year": 2021,
    "authors": "Wei Wei; Ammar Rayes; Wei Wang; Yiduo Mei",
    "corresponding_authors": "",
    "abstract": "editorial Free Access Share on Special Section on AI-Empowered Internet of Things for Smart Cities Editors: Wei Wei Xi'an University of Technology Xi'an University of TechnologyView Profile , Ammar Rayes Cisco Systems Cisco SystemsView Profile , Wei Wang University of Macau University of MacauView Profile , Yiduo Mei Beijing Jiaotong University Beijing Jiaotong UniversityView Profile Authors Info & Claims ACM Transactions on Internet TechnologyVolume 21Issue 3August 2021 Article No.: 64pp 1–3https://doi.org/10.1145/3460868Online:09 June 2021Publication History 1citation246DownloadsMetricsTotal Citations1Total Downloads246Last 12 Months246Last 6 weeks7 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteView all FormatsPDF",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W3166268651",
    "type": "article"
  },
  {
    "title": "Waiting for Tactile: Robotic and Virtual Experiences in the Fog",
    "doi": "https://doi.org/10.1145/3421507",
    "publication_date": "2021-06-16",
    "publication_year": 2021,
    "authors": "Lucia Cascone; Aniello Castiglione; Michele Nappi; Fabio Narducci; Ignazio Passero",
    "corresponding_authors": "",
    "abstract": "Social robots adopt an emotional touch to interact with users inducing and transmitting humanlike emotions. Natural interaction with humans needs to be in real time and well grounded on the full availability of information on the environment. These robots base their way of communicating on direct interaction (touch, listening, view), supported by a range of sensors on the surrounding environment that provide a radially central and partial knowledge on it. Over the past few years, social robots have been demonstrated to implement different features, going from biometric applications to the fusion of machine learning environmental information collected on the edge. This article aims at describing the experiences performed and still ongoing and characterizes a simulation environment developed for the social robot Pepper that aims to foresee the new scenarios and benefits that tactile connectivity will enable.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W3172158451",
    "type": "article"
  },
  {
    "title": "Detecting Malicious Switches for a Secure Software-defined Tactile Internet",
    "doi": "https://doi.org/10.1145/3415146",
    "publication_date": "2021-09-03",
    "publication_year": 2021,
    "authors": "Bin Yuan; Lin Chen; Deqing Zou; Laurence T. Yang; Hai Jin",
    "corresponding_authors": "",
    "abstract": "The rapid development of the Internet of Things has led to demand for high-speed data transformation. Serving this purpose is the Tactile Internet, which facilitates data transfer in extra-low latency. In particular, a Tactile Internet based on software-defined networking (SDN) has been broadly deployed because of the proven benefits of SDN in flexible and programmable network management. However, the vulnerabilities of SDN also threaten the security of the Tactile Internet. Specifically, an SDN controller relies on the network status (provided by the underlying switches) to make network decisions, e.g., calculating a routing path to deliver data in the Tactile Internet. Hence, the attackers can compromise the switches to jeopardize the SDN and further attack Tactile Internet systems. For example, an attacker can compromise switches to launch distributed denial-of-service attacks to overwhelm the SDN controller, which will disrupt all the applications in the Tactile Internet. In pursuit of a more secure Tactile Internet, the problem of abnormal SDN switches in the Tactile Internet is analyzed in this article, including the cause of abnormal switches and their influences on different network layers. Then we propose an approach that leverages the messages sent by all switches to identify abnormal switches, which adopts a linear structure to store historical messages at a relatively low cost. By mapping each flow message to the flow establishment model, our method can effectively identify malicious SDN switches in the Tactile Internet and thus enhance its security.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W3196876685",
    "type": "article"
  },
  {
    "title": "SANTM: Efficient Self-attention-driven Network for Text Matching",
    "doi": "https://doi.org/10.1145/3426971",
    "publication_date": "2021-11-29",
    "publication_year": 2021,
    "authors": "Prayag Tiwari; Amit Kumar Jaiswal; Sahil Garg; Ilsun You",
    "corresponding_authors": "",
    "abstract": "Self-attention mechanisms have recently been embraced for a broad range of text-matching applications. Self-attention model takes only one sentence as an input with no extra information, i.e., one can utilize the final hidden state or pooling. However, text-matching problems can be interpreted either in symmetrical or asymmetrical scopes. For instance, paraphrase detection is an asymmetrical task, while textual entailment classification and question-answer matching are considered asymmetrical tasks. In this article, we leverage attractive properties of self-attention mechanism and proposes an attention-based network that incorporates three key components for inter-sequence attention: global pointwise features, preceding attentive features, and contextual features while updating the rest of the components. Our model follows evaluation on two benchmark datasets cover tasks of textual entailment and question-answer matching. The proposed efficient Self-attention-driven Network for Text Matching outperforms the state of the art on the Stanford Natural Language Inference and WikiQA datasets with much fewer parameters.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4200584900",
    "type": "article"
  },
  {
    "title": "A Game Theoretic Model for the Formation of Navigable Small-World Networks—The Tradeoff between Distance and Reciprocity",
    "doi": "https://doi.org/10.1145/3183325",
    "publication_date": "2018-10-22",
    "publication_year": 2018,
    "authors": "Zhi Yang; Wei Chen",
    "corresponding_authors": "",
    "abstract": "Kleinberg proposed a family of small-world networks to explain the navigability of large-scale real-world social networks. However, the underlying mechanism that drives real networks to be navigable is not yet well understood. In this article, we present a game theoretic model for the formation of navigable small-world networks. We model the network formation as a game called the Distance-Reciprocity Balanced (DRB) game in which people seek for both high reciprocity and long-distance relationships. We show that the game has only two Nash equilibria: One is the navigable small-world network, and the other is the random network in which each node connects with each other node with equal probability, and any other network state can reach the navigable small world via a sequence of best-response moves of nodes. We further show that the navigable small-world equilibrium is very stable—(a) no collusion of any size would benefit from deviating from it; and (b) after an arbitrary deviations of a large random set of nodes, the network would return to the navigable small world as soon as every node takes one best-response step. In contrast, for the random network, a small group collusion or random perturbations is guaranteed to bring the network out of the random-network equilibrium and move to the navigable network as soon as every node takes one best-response step. Moreover, we show that navigable small-world equilibrium has much better social welfare than the random network, and we provide the price-of-anarchy and price-of-stability results of the game. Our empirical evaluation further demonstrates that the system always converges to the navigable network even when limited or no information about other players’ strategies is available, and the DRB game simulated on real-world networks leads to navigability characteristic that is very close to that of the real networks, even though the real-world networks have non-uniform population distributions different from Kleinberg’s small-world model. Our theoretical and empirical analyses provide important new insight on the connection between distance, reciprocity, and navigability in social networks.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2963671565",
    "type": "article"
  },
  {
    "title": "Universal Social Network Bus",
    "doi": "https://doi.org/10.1145/3323333",
    "publication_date": "2019-08-31",
    "publication_year": 2019,
    "authors": "Rafael Angarita; Bruno Lefèvre; Shohreh Ahvar; Ehsan Ahvar; Nikolaos Georgantas; Valérie Issarny",
    "corresponding_authors": "",
    "abstract": "Online Social Network Services (OSNSs) are changing the fabric of our society, impacting almost every aspect of it. Over the past few decades, an aggressive market rivalry has led to the emergence of multiple competing, “closed” OSNSs. As a result, users are trapped in the walled gardens of their OSNS, encountering restrictions about what they can do with their personal data, the people they can interact with, and the information they get access to. As an alternative to the platform lock-in, “open” OSNSs promote the adoption of open, standardized APIs. However, users still massively adopt closed OSNSs to benefit from the services’ advanced functionalities and/or follow their “friends,” although the users’ virtual social sphere is ultimately limited by the OSNSs they join. Our work aims at overcoming such a limitation by enabling users to meet and interact beyond the boundary of their OSNSs, including reaching out to “friends” of distinct closed OSNSs. We specifically introduce Universal Social Network Bus (USNB) , which revisits the “service bus” paradigm that enables interoperability across computing systems to address the requirements of “ social interoperability .” USNB features synthetic profiles and personae for interaction across the boundaries of closed and open and profile- and non-profile-based OSNSs through a reference social interaction service . We ran a 1-day workshop with a panel of users who experimented with the USNB prototype to assess the potential benefits of social interoperability for social network users. Results show the positive evaluation of users for USNB, especially as an enabler of applications for civic participation. This further opens up new perspectives for future work, among which includes enforcing security and privacy guarantees.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2969212313",
    "type": "article"
  },
  {
    "title": "Introduction to the Special Section on Advances in Internet-based Collaborative Technologies",
    "doi": "https://doi.org/10.1145/3361071",
    "publication_date": "2019-08-31",
    "publication_year": 2019,
    "authors": "Schahram Dustdar; ‪Surya Nepal‬; James Joshi",
    "corresponding_authors": "",
    "abstract": "Individuals, organizations, and government agencies are increasingly relying on Internet-enabled collaboration among distributed teams of humans, computer applications, and autonomous entities such as robots to develop products and deliver services. Technology trends in areas such as networking, data analytics, and distributed systems have significantly shifted the landscape of Internet-based collaborative tools and services. This particular special issue contains articles describing novel and innovative Internet-based collaborative technologies that leverage emerging technologies and enable seamless collaboration.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2990983898",
    "type": "article"
  },
  {
    "title": "Pay as Your Service Needs",
    "doi": "https://doi.org/10.1145/3361148",
    "publication_date": "2019-11-09",
    "publication_year": 2019,
    "authors": "Hong Xie; Weijie Wu; T. B. Richard; John C. S. Lui",
    "corresponding_authors": "",
    "abstract": "Various differentiated pricing schemes have been proposed for the Internet market. Aiming at replacing the traditional single-class pricing for better welfare, yet, researchers have shown that existing schemes can bring only marginal profit gain for the ISPs. In this article, we point out that a proper form of differentiated pricing for the Internet should not only consider congestion, but more importantly, it should provide application specific treatment to data delivery. Formally, we propose an “application-driven pricing” approach, where an ISP offers a number of service classes in terms of a guaranteed quality of service and announces a unit usage price for each class, and content providers are free to choose which class to use depending on the requirement of their applications. Unlike previous studies, we point out that the revenue gain of multi-class pricing under our scheme can be significant. This is because we capture important aspects of application heterogeneity and take the quality of service and price as control knobs. We identify key factors that impact the revenue gain and reveal fundamental understandings on when and why an application-driven multi-class pricing can significantly increase the revenue of ISPs.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2997589225",
    "type": "article"
  },
  {
    "title": "Internet Technology Outlook",
    "doi": "https://doi.org/10.1145/3378661",
    "publication_date": "2020-01-29",
    "publication_year": 2020,
    "authors": "Ling Liu",
    "corresponding_authors": "Ling Liu",
    "abstract": "editorial Free AccessInternet Technology Outlook: From Communication to Storage and Cognitive Computing Share on Author: Ling Liu Georgia Institute of Technology, Atlanta, GA 30332, USA Georgia Institute of Technology, Atlanta, GA 30332, USAView Profile Authors Info & Claims ACM Transactions on Internet TechnologyVolume 20Issue 1March 2020 Article No.: 1pp 1–4https://doi.org/10.1145/3378661Published:29 January 2020 0citation503DownloadsMetricsTotal Citations0Total Downloads503Last 12 Months215Last 6 weeks21 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteView all FormatsPDF",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W3003500411",
    "type": "article"
  },
  {
    "title": "Enabling Reference Verifiability for the World Wide Web with Webchain",
    "doi": "https://doi.org/10.1145/3392097",
    "publication_date": "2020-07-07",
    "publication_year": 2020,
    "authors": "Elias Rohrer; Steffen Heidel; Florian Tschorsch",
    "corresponding_authors": "",
    "abstract": "As online sources are becoming more prevalent in journalism and scientific literature, the ephemeral nature of the World Wide Web is becoming an increasingly serious issue for their verifiability, replicability, and reproducibility. The architecture of Webchain, a new system enabling source and reference verifiability on the Web, is combining distributed ledger technologies with secure timestamping to ensure the history of creation, ownership, and referential integrity of online resources. We present the architecture and system extensions, conduct a security analysis, and evaluate the Webchain system based on a comprehensive prototype implementation. The results confirm the feasibility and robustness of our approach.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W3082184326",
    "type": "article"
  },
  {
    "title": "A Security Cost Modelling Framework for Cyber-Physical Systems",
    "doi": "https://doi.org/10.1145/3450752",
    "publication_date": "2022-04-22",
    "publication_year": 2022,
    "authors": "Igor Ivkić; Patrizia Sailer; Antonios Gouglidis; Andreas Mauthe; Markus Tauber",
    "corresponding_authors": "",
    "abstract": "Cyber-Physical Systems (CPS) are formed through interconnected components capable of computation, communication, sensing and changing the physical world. The development of these systems poses a significant challenge, since they have to be designed in a way to ensure cyber-security without impacting their performance. This article presents the Security Cost Modelling Framework (SCMF) and shows supported by an experimental study how it can be used to measure, normalise, and aggregate the overall performance of a CPS. Unlike previous studies, our approach uses different metrics to measure the overall performance of a CPS and provides a methodology for normalising the measurement results of different units to a common Cost Unit . Moreover, we show how the Security Costs can be extracted from the overall performance measurements, which allows us to quantify the overhead imposed by performing security-related tasks. Furthermore, we describe the architecture of our experimental testbed and demonstrate the applicability of SCMF in an experimental study. Our results show that measuring the overall performance and extracting the security costs using SCMF can serve as basis to redesign interactions to achieve the same overall goal at less costs.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W3133931288",
    "type": "article"
  },
  {
    "title": "Modelling and Analysing Replica- and Fault-aware Management of Horizontally Scalable Applications",
    "doi": "https://doi.org/10.1145/3511302",
    "publication_date": "2022-02-03",
    "publication_year": 2022,
    "authors": "Jacopo Soldani; Marco Cameriero; Giulio Paparelli; Antonio Brogi",
    "corresponding_authors": "",
    "abstract": "Modern enterprise applications integrate multiple interdependent software components, whose management must be suitably coordinated. This must be done by taking into account all inter-component dependencies, the faults potentially affecting them, and the fact that each component can be horizontally scaled, i.e., that multiple instances of each component can be spawned or destroyed, depending on application needs. In this article, we introduce a novel solution for suitably modelling and analysing the replica- and fault-aware management of multi-component applications, based on topology graphs and management protocols. More precisely, we first introduce a compositional model of the management behaviour of the (possibly multiple) instances of the components forming an application, faults included. We then show how this model enables automating various useful analyses, from checking the validity of management plans to automatically determining management plans allowing the instance of an application to reach and maintain a desired target configuration.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4210588296",
    "type": "article"
  },
  {
    "title": "Guest Editorial Introduction for the Special Section on Deep Learning Algorithms and Systems for Enhancing Security in Cloud Services",
    "doi": "https://doi.org/10.1145/3516806",
    "publication_date": "2022-05-14",
    "publication_year": 2022,
    "authors": "Gunasekaran Manogaran; Hassan Qudrat‐Ullah; Qin Xin; Latifur Khan",
    "corresponding_authors": "",
    "abstract": "introduction Share on Guest Editorial Introduction for the Special Section on Deep Learning Algorithms and Systems for Enhancing Security in Cloud Services Editors: Gunasekaran Manogaran Howard University, Washington D.C., USA Howard University, Washington D.C., USAView Profile , Hassan Qudrat-Ullah York University, Toronto, Canada York University, Toronto, CanadaView Profile , Qin Xin University of the Faroe Islands, Faroe Islands University of the Faroe Islands, Faroe IslandsView Profile , Latifur Khan The University of Texas at Dallas, Texas, USA The University of Texas at Dallas, Texas, USAView Profile Authors Info & Claims ACM Transactions on Internet TechnologyVolume 22Issue 2May 2022 Article No.: 39epp 1–5https://doi.org/10.1145/3516806Online:14 May 2022Publication History 0citation49DownloadsMetricsTotal Citations0Total Downloads49Last 12 Months49Last 6 weeks6 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my Alerts New Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteGet Access",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4280598273",
    "type": "editorial"
  },
  {
    "title": "Breaking CaptchaStar Using the BASECASS Methodology",
    "doi": "https://doi.org/10.1145/3546867",
    "publication_date": "2022-09-02",
    "publication_year": 2022,
    "authors": "Carlos Javier Hernández‐Castro; David F. Barrero; María D. R‐Moreno",
    "corresponding_authors": "",
    "abstract": "In this article, we present fundamental design flaws of CaptchaStar. We also present a full analysis using the BASECASS methodology that employs machine learning techniques. By means of this methodology, we find an attack that bypasses CaptchaStar with almost 100% accuracy.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4294238439",
    "type": "article"
  },
  {
    "title": "Tuneman: Customizing Networks to Guarantee Application Bandwidth and Latency",
    "doi": "https://doi.org/10.1145/3575657",
    "publication_date": "2022-12-09",
    "publication_year": 2022,
    "authors": "Sidharth Sharma; Aniruddha Kushwaha; Mohammad Alizadeh; George Varghese; Ashwin Gumaste",
    "corresponding_authors": "",
    "abstract": "We examine how to provide applications with dedicated bandwidth and guaranteed latency in a programmable mission-critical network. Unlike other SDN approaches such as B4 or SWAN, our system Tuneman optimizes both routes and packet schedules at each node to provide flows with sub-second bandwidth changes. Tuneman uses node-level optimization to compute node schedules in a slotted switch and does dynamic routing using a search procedure with Quality of Service– (QoS) based weights. This allows Tuneman to provide an efficient solution for mission-critical networks that have stringent QoS requirements. We evaluate Tuneman on a telesurgery network using a switch prototype built using FPGAs and also via simulations on India’s Tata Network. For mission-critical networks with multiple QoS levels, Tuneman has comparable or better utilization than SWAN while providing delay bounds guarantees.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4311995774",
    "type": "article"
  },
  {
    "title": "P2P-Based, Multi-Attribute Resource Discovery under Real-World Resources and Queries",
    "doi": "https://doi.org/10.1145/2729139",
    "publication_date": "2015-03-12",
    "publication_year": 2015,
    "authors": "H. M. N. Dilum Bandara; Anura P. Jayasumana",
    "corresponding_authors": "",
    "abstract": "Collaborative peer-to-peer (P2P), grid, and cloud computing rely on resource discovery (RD) solutions to aggregate groups of multi-attribute, dynamic, and distributed resources. However, specific characteristics of real-world resources and queries, and their impact on P2P-based RD, are largely unknown. We analyze the characteristics of resources and queries using data from four real-world systems. These characteristics are then used to qualitatively and quantitatively evaluate the fundamental design choices for P2P-based multi-attribute RD. The datasets exhibit several noteworthy features that affect the performance. For example, compared to uniform queries, real-world queries are relatively easier to resolve using unstructured, superpeer, and single-attribute-dominated query-based structured P2P solutions, as queries mostly specify only a small subset of the available attributes and large ranges of attribute values. However, all the solutions are prone to significant load balancing issues, as the resources and queries are highly skewed and correlated. The implications of our findings for improving RD solutions are also discussed.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W1975899283",
    "type": "article"
  },
  {
    "title": "Equipping IDEs with XML-Path Reasoning Capabilities",
    "doi": "https://doi.org/10.1145/2602573",
    "publication_date": "2014-07-01",
    "publication_year": 2014,
    "authors": "Pierre Genevès; Nabil Layaïda",
    "corresponding_authors": "",
    "abstract": "One of the challenges in Web development is to achieve a good level of quality in terms of code size and runtime performance for popular domain-specific languages such as XQuery, XSLT, and XML Schema. We present the first IDE augmented with static detection of inconsistent XPath expressions that assists the programmer with simplifying development and debugging of any application involving XPath expressions. The tool is based on newly developed formal verification techniques based on expressive modal logics, which are now mature enough to be introduced in the process of software development. We further develop this idea in the context of XQuery for which we introduce an analysis for identifying and eliminating dead code automatically. This proof of concept aims at illustrating the benefits of equipping modern IDEs with reasoning capabilities.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W1998228155",
    "type": "article"
  },
  {
    "title": "Introduction to the Special Issue on Foundations of Social Computing",
    "doi": "https://doi.org/10.1145/2680536",
    "publication_date": "2014-12-17",
    "publication_year": 2014,
    "authors": "Amit K. Chopra; Raian Ali; Maja Vuković",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2084632630",
    "type": "article"
  },
  {
    "title": "Microcomputations as Micropayments in Web-based Services",
    "doi": "https://doi.org/10.1145/2611526",
    "publication_date": "2014-05-01",
    "publication_year": 2014,
    "authors": "Ghassan Karame; Aurélien Francillon; Victor Budilivschi; Srđjan Čapkun; Vedran Čapkun",
    "corresponding_authors": "",
    "abstract": "In this article, we propose a new micropayment model for nonspecialized commodity web-services based on microcomputations. In our model, a user that wishes to access online content (offered by a website) does not need to register or pay to access the website; instead, he will accept to run microcomputations on behalf of the service provider in exchange for access to the content. These microcomputations can, for example, support ongoing computing projects that have clear social benefits (e.g., projects relating to medical research) or can contribute towards commercial computing projects. We analyze the security and privacy of our proposal and we show that it preserves the privacy of users. We argue that this micropayment model is economically and technically viable and that it can be integrated in existing distributed computing frameworks (e.g., the BOINC platform). In this respect, we implement a prototype of a system based on our model and we deploy our prototype on Amazon Mechanical Turk to evaluate its performance and usability given a large number of users. Our results show that our proposed scheme does not affect the browsing experience of users and is likely to be used by a non-trivial proportion of users. Finally, we empirically show that our scheme incurs comparable bandwidth and CPU consumption to the resource usage incurred by online advertisements featured in popular websites.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2103923334",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2909066",
    "publication_date": "2016-04-20",
    "publication_year": 2016,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "An emerging issue in urban computing environments is the seamless selection, composition, and delivery of user-centric services that run over what is known as the Internet of Things (IoT). This challenge is about enabling services actuated by IoT ...",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4230272836",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2659232",
    "publication_date": "2014-07-01",
    "publication_year": 2014,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Event processing follows a decoupled model of interaction in space, time, and synchronization. However, another dimension of semantic coupling also exists and poses a challenge to the scalability of event processing systems in highly semantically ...",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4231285475",
    "type": "paratext"
  },
  {
    "title": "Finding the Source in Networks: An Approach Based on Structural Entropy",
    "doi": "https://doi.org/10.1145/3568309",
    "publication_date": "2023-02-06",
    "publication_year": 2023,
    "authors": "Chong Zhang; Qiang Guo; Luoyi Fu; Jiaxin Ding; Xinde Cao; Fei Long; Xinbing Wang; Chenghu Zhou",
    "corresponding_authors": "",
    "abstract": "The popularity of intelligent devices provides straightforward access to the Internet and online social networks. However, the quick and easy data updates from networks also benefit the risk spreading, such as rumor, malware, or computer viruses. To this end, this article studies the problem of source detection, which is to infer the source node out of an aftermath of a cascade, that is, the observed infected graph G N of the network at some time. Prior arts have adopted various statistical quantities such as degree, distance, or infection size to reflect the structural centrality of the source. In this article, we propose a new metric that we call the infected tree entropy (ITE), to utilize richer underlying structural features for source detection. Our idea of ITE is inspired by the conception of structural entropy [ 21 ], which demonstrated that the minimization of average bits to encode the network structures with different partitions is the principle for detecting the natural or true structures in real-world networks. Accordingly, our proposed ITE based estimator for the source tries to minimize the coding of network partitions brought by the infected tree rooted at all the potential sources, thus minimizing the structural deviation between the cascades from the potential sources and the actual infection process included in G N . On polynomially growing geometric trees, with increasing tree heterogeneity, the ITE estimator remarkably yields more reliable detection under only moderate infection sizes, and returns an asymptotically complete detection. In contrast, for regular expanding trees, we still observe guaranteed detection probability of ITE estimator even with an infinite infection size, thanks to the degree regularity property. We also algorithmically realize the ITE based detection that enjoys linear time complexity via a message-passing scheme, and further extend it to general graphs. Extensive experiments on synthetic and real datasets confirm the superiority of ITE to the baselines. For example, ITE returns an accuracy of 85%, ranking the source among the top 10%, far exceeding 55% of the classic algorithm on scale-free networks.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4319316884",
    "type": "article"
  },
  {
    "title": "Real-time Pricing-based Resource Allocation in Open Market Environments",
    "doi": "https://doi.org/10.1145/3465237",
    "publication_date": "2023-02-28",
    "publication_year": 2023,
    "authors": "Pankaj Mishra; Ahmed Moustafa; Takayuki Itō",
    "corresponding_authors": "",
    "abstract": "Open market environments consist of a set of participants (vendors and consumers) that dynamically leave or join the market. As a result, the arising dynamism leads to uncertainties in supply and demand of the resources in these open markets. In specific, in such uncertain markets, vendors attempt to maximise their revenue by dynamically changing their selling prices according to the market demand. In this regard, an optimal resource allocation approach becomes immensely needed to optimise the selling prices based on the supply and demand of the resources in the open market. Therefore, optimal selling prices should maximise the revenue of vendors while protecting the utility of buyers. In this context, we propose a real-time pricing approach for resource allocation in open market environments. The proposed approach introduces a priority-based fairness mechanism to allocate the available resources in a reverse-auction paradigm. Finally, we compare the proposed approach with two state-of-the-art resource allocation approaches. The experimental results show that the proposed approach outperforms the other two resource allocation approaches in its ability to maximise the vendors’ revenue.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4324157376",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1183463",
    "publication_date": "2006-11-01",
    "publication_year": 2006,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "This article presents the role of ontologies and Web mining techniques in the construction and maintenance of experts' profiles. This article also discusses the development of contemporary expertise-locator knowledge management systems and, specifically,...",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4249463090",
    "type": "paratext"
  },
  {
    "title": "Exploiting and Maintaining Materialized Views for XML Keyword Queries",
    "doi": "https://doi.org/10.1145/2390209.2390212",
    "publication_date": "2012-12-01",
    "publication_year": 2012,
    "authors": "Ziyang Liu; Yi Chen",
    "corresponding_authors": "",
    "abstract": "Keyword query is a user-friendly mechanism for retrieving useful information from XML data in Web and scientific applications. Inspired by the performance benefits of exploiting materialized views when processing structured queries, we investigate the feasibility and present a general framework for answering XML keyword queries using materialized views. Then we develop an XML keyword search engine that leverages materialized views for query evaluation and maintains materialized views incrementally upon XML data update. Experimental evaluation demonstrates the significance and efficiency of our approach.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W1975710928",
    "type": "article"
  },
  {
    "title": "Comparing ingress and egress detection to secure interdomain routing",
    "doi": "https://doi.org/10.1145/2049656.2049657",
    "publication_date": "2011-12-01",
    "publication_year": 2011,
    "authors": "Christoph Goebel; Dirk Neumann; Ramayya Krishnan",
    "corresponding_authors": "",
    "abstract": "The global economy and society increasingly depends on computer networks linked together by the Internet. The importance of computer networks reaches far beyond the telecommunications sector since they have become a critical factor for many other crucial infrastructures and markets. With threats mounting and security incidents becoming more frequent, concerns about network security grow. It is an acknowledged fact that some of the most fundamental network protocols that make the Internet work are exposed to serious threats. One of them is the Border Gateway Protocol (BGP) which determines how Internet traffic is routed through the topology of administratively independent networks that the Internet is comprised of. Despite the existence of a steadily growing number of BGP security proposals, to date none of them has been adopted. Using a precise definition of BGP robustness we experimentally show that the degree of robustness is distributed unequally across the administrative domains of the Internet, the so-called Autonomous Systems (ASes). The experiments confirm the intuition that the contribution ASes are able to make towards securing the correct working of the inter-domain routing infrastructure by deploying countermeasures against routing attacks differ depending on their position in the AS topology. We also show that the degree of this asymmetry can be controlled by the choice of the security strategy. We compare the strengths and weaknesses of two fundamentally different approaches in increasing BGP's robustness which we termed ingress and egress detection of false route advertisements and indicate their implications. Our quantitative results have important implications for Internet security policy, in particular with respect to the crucial question where to start the deployment of which type of security scheme in order to maximize the Internet's robustness to routing attacks.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2090943997",
    "type": "article"
  },
  {
    "title": "Distribution fairness in Internet-scale networks",
    "doi": "https://doi.org/10.1145/1592446.1592450",
    "publication_date": "2009-09-01",
    "publication_year": 2009,
    "authors": "Theoni Pitoura; Peter Triantafillou",
    "corresponding_authors": "",
    "abstract": "We address the issue of measuring distribution fairness in Internet-scale networks. This problem has several interesting instances encountered in different applications, ranging from assessing the distribution of load between network nodes for load balancing purposes, to measuring node utilization for optimal resource exploitation, and to guiding autonomous decisions of nodes in networks built with market-based economic principles. Although some metrics have been proposed, particularly for assessing load balancing algorithms, they fall short. We first study the appropriateness of various known and previously proposed statistical metrics for measuring distribution fairness. We put forward a number of required characteristics for appropriate metrics. We propose and comparatively study the appropriateness of the Gini coefficient ( G ) for this task. Our study reveals as most appropriate the metrics of G , the fairness index ( FI ), and the coefficient of variation ( C V ) in this order. Second, we develop six distributed sampling algorithms to estimate metrics online efficiently, accurately, and scalably. One of these algorithms ( 2-PRWS ) is based on two effective optimizations of a basic algorithm, and the other two (the sequential sampling algorithm, LBS-HL , and the clustered sampling one, EBSS ) are novel, developed especially to estimate G . Third, we show how these metrics, and especially G , can be readily utilized online by higher-level algorithms, which can now know when to best intervene to correct unfair distributions (in particular, load imbalances). We conclude with a comprehensive experimentation which comparatively evaluates both the various proposed estimation algorithms and the three most appropriate metrics ( G , C V , and FI ). Specifically, the evaluation quantifies the efficiency (in terms of number of the messages and a latency indicator), precision, and accuracy achieved by the proposed algorithms when estimating the competing fairness metrics. The central conclusion is that the proposed metric, G , can be estimated with a small number of messages and latency, regardless of the skew of the underlying distribution.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2024192644",
    "type": "article"
  },
  {
    "title": "Privacy-Enhanced Television Audience Measurements",
    "doi": "https://doi.org/10.1145/3009969",
    "publication_date": "2017-02-25",
    "publication_year": 2017,
    "authors": "George Drosatos; Αιμιλία Τασίδου; Pavlos S. Efraimidis",
    "corresponding_authors": "",
    "abstract": "Internet-enabled television systems (SmartTVs) are a development that introduces these devices into the interconnected environment of the Internet of Things. We propose a privacy-preserving application for computing Television Audience Measurement (TAM) ratings. SmartTVs communicate over the Internet to calculate aggregate measurements. Contemporary cryptographic building blocks are utilized to ensure the privacy of the participating individuals and the validity of the computed TAM ratings. Additionally, user compensation capabilities are introduced to bring some of the company profits back to the data owners. A prototype implementation is developed on an Android-based SmartTV platform and experimental results illustrate the feasibility of the approach.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2594687757",
    "type": "article"
  },
  {
    "title": "Guest Editorial",
    "doi": "https://doi.org/10.1145/3108938",
    "publication_date": "2017-08-18",
    "publication_year": 2017,
    "authors": "Adriane Chapman; James Cheney; Simon Miles",
    "corresponding_authors": "",
    "abstract": "editorial Free Access Share on Guest Editorial: The Provenance of Online Data Editors: Adriane Chapman University of Southampton, UK University of Southampton, UKView Profile , James Cheney University of Edinburgh, UK University of Edinburgh, UKView Profile , Simon Miles King's College London, UK King's College London, UKView Profile Authors Info & Claims ACM Transactions on Internet TechnologyVolume 17Issue 4November 2017 Article No.: 33pp 1–3https://doi.org/10.1145/3108938Published:18 August 2017Publication History 0citation256DownloadsMetricsTotal Citations0Total Downloads256Last 12 Months24Last 6 weeks1 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2745429434",
    "type": "editorial"
  },
  {
    "title": "Exploiting Contextual Information in Attacking Set-Generalized Transactions",
    "doi": "https://doi.org/10.1145/3106165",
    "publication_date": "2017-09-18",
    "publication_year": 2017,
    "authors": "Jianhua Shao; Hoang Ong",
    "corresponding_authors": "",
    "abstract": "Transactions are records that contain a set of items about individuals. For example, items browsed by a customer when shopping online form a transaction. Today, many activities are carried out on the Internet, resulting in a large amount of transaction data being collected. Such data are often shared and analyzed to improve business and services, but they also contain private information about individuals that must be protected. Techniques have been proposed to sanitize transaction data before their release, and set-based generalization is one such method. In this article, we study how well set-based generalization can protect transactions. We propose methods to attack set-generalized transactions by exploiting contextual information that is available within the released data. Our results show that set-based generalization may not provide adequate protection for transactions, and up to 70% of the items added into the transactions during generalization to obfuscate original data can be detected by our methods with a precision over 80%.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2747051396",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3068849",
    "publication_date": "2017-05-28",
    "publication_year": 2017,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Social media has become very popular and mainstream, leading to an abundance of content. This wealth of content contains many interactions and conversations that can be analyzed for a variety of information. One such type of information is analyzing the ...",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4234164355",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1754393",
    "publication_date": "2010-05-01",
    "publication_year": 2010,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "We propose a novel approach for detecting visual similarity between two Web pages. The proposed approach applies Gestalt theory and considers a Web page as a single indivisible entity. The concept of supersignals, as a realization of Gestalt principles, ...",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4244884241",
    "type": "paratext"
  },
  {
    "title": "PROLISEAN",
    "doi": "https://doi.org/10.1145/3432250",
    "publication_date": "2021-01-13",
    "publication_year": 2021,
    "authors": "Edy Hourany; Bachir Habib; Camille Fountaine; Abdallah Makhoul; Benoît Piranda; Julien Bourgeois",
    "corresponding_authors": "",
    "abstract": "The vision for programmable matter is to create a material that can be reprogrammed to have different shapes and to change its physical properties on demand. They are autonomous systems composed of a huge number of independent connected elements called particles. The connections to one another form the overall shape of the system. These particles are capable of interacting with each other and take decisions based on their environment. Beyond sensing, processing, and communication capabilities, programmable matter includes actuation and motion capabilities. It could be deployed in different domains and will constitute an intelligent component of the IoT. A lot of applications can derive from this technology, such as medical or industrial applications. However, just like any other technology, security is a huge concern. Given its distributed architecture and its processing limitations, programmable matter cannot handle the traditional security protocols and encryption algorithms. This article proposes a new security protocol optimized and dedicated for IoT programmable matter. This protocol is based on lightweight cryptography and uses the same encryption protocol as a hashing function while keeping the distributed architecture in mind. The analysis and simulation results show the efficiency of the proposed method and that a supercomputer will need about 5.93 × 10 25 years to decrypt the message.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W3119167309",
    "type": "article"
  },
  {
    "title": "Power Side-Channel Analysis of RNS GLV ECC Using Machine and Deep Learning Algorithms",
    "doi": "https://doi.org/10.1145/3423555",
    "publication_date": "2021-06-16",
    "publication_year": 2021,
    "authors": "Ali Mehrabi; Naila Mukhtar; Alireza Jolfaei",
    "corresponding_authors": "",
    "abstract": "Many Internet of Things applications in smart cities use elliptic-curve cryptosystems due to their efficiency compared to other well-known public-key cryptosystems such as RSA. One of the important components of an elliptic-curve-based cryptosystem is the elliptic-curve point multiplication which has been shown to be vulnerable to various types of side-channel attacks. Recently, substantial progress has been made in applying deep learning to side-channel attacks. Conceptually, the idea is to monitor a core while it is running encryption for information leakage of a certain kind, for example, power consumption. The knowledge of the underlying encryption algorithm can be used to train a model to recognise the key used for encryption. The model is then applied to traces gathered from the crypto core in order to recover the encryption key. In this article, we propose an RNS GLV elliptic curve cryptography core which is immune to machine learning and deep learning based side-channel attacks. The experimental analysis confirms the proposed crypto core does not leak any information about the private key and therefore it is suitable for hardware implementations.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W3166588404",
    "type": "article"
  },
  {
    "title": "Introduction to the Special Section on Data Science for Cyber-Physical Systems",
    "doi": "https://doi.org/10.1145/3464766",
    "publication_date": "2021-06-15",
    "publication_year": 2021,
    "authors": "Francesco Piccialli; Nik Bessis; Gwanggil Jeon; Calton Pu",
    "corresponding_authors": "",
    "abstract": "introduction Introduction to the Special Section on Data Science for Cyber-Physical Systems Share on Editors: Francesco Piccialli University of Naples FEDERICO II, Italy University of Naples FEDERICO II, ItalyView Profile , Nik Bessis Edge Hill University, UK Edge Hill University, UKView Profile , Gwanggil Jeon Incheon National University, Incheon, South Korea Incheon National University, Incheon, South KoreaView Profile , Calton Pu Georgia Institute of Technology, USA Georgia Institute of Technology, USAView Profile Authors Info & Claims ACM Transactions on Internet TechnologyVolume 21Issue 2June 2021 Article No.: 28epp 1–7https://doi.org/10.1145/3464766Online:15 June 2021Publication History 0citation51DownloadsMetricsTotal Citations0Total Downloads51Last 12 Months51Last 6 weeks3 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteGet Access",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W3171750153",
    "type": "article"
  },
  {
    "title": "A Secure Ticket-Based Authentication Mechanism for Proxy Mobile IPv6 Networks in Volunteer Computing",
    "doi": "https://doi.org/10.1145/3407189",
    "publication_date": "2021-07-22",
    "publication_year": 2021,
    "authors": "Mojtaba Alizadeh; Mohammad Hesam Tadayon; Kouichi Sakurai; Hiroaki Anada; Alireza Jolfaei",
    "corresponding_authors": "",
    "abstract": "Technology advances—such as improving processing power, battery life, and communication functionalities—contribute to making mobile devices an attractive research area. In 2008, in order to manage mobility, the Internet Engineering Task Force (IETF) developed Proxy Mobile IPv6, which is a network-based mobility management protocol to support seamless connectivity of mobile devices. This protocol can play a key role in volunteer computing paradigms as a user can seamlessly access computing resources. The procedure of user authentication is not defined in this standard; thus, many studies have been carried out to propose suitable authentication schemes. However, in the current authentication methods, with reduced latency and packet loss, some security and privacy considerations are neglected. In this study, we propose a secure and anonymous ticket-based authentication (SATA) method to protect mobile nodes against existing security and privacy issues. The proposed method reduces the overhead of handover authentication procedures using the ticket-based concept. We evaluated security and privacy strengths of the proposed method using security theorems and BAN logic.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W3184052296",
    "type": "article"
  },
  {
    "title": "Screw Slot Quality Inspection System Based on Tactile Network",
    "doi": "https://doi.org/10.1145/3423556",
    "publication_date": "2021-07-22",
    "publication_year": 2021,
    "authors": "Chen Yanchun; Ren‐Hung Hwang; Mu‐Yen Chen; Chih‐Chin Wen; Chih-Ping Hsu",
    "corresponding_authors": "",
    "abstract": "The popularity of 5G networks has made smart manufacturing not limited to high-tech industries such as semiconductors due to its high speed, ultra-high reliability, and low latency. With the advance of system on chip (SoC) design and manufacturing, 5G is also suitable for data transmission in harsh manufacturing environments such as high temperatures, dust, and extreme vibration. The defect of the screw head is caused by the wear and deformation of the die forming the head after mass production. Therefore, the screw quality inspection system based on the tactile network in this article monitors the production quality of the screw; the system will send a warning signal through the router to remind the technician to solve the production problem when the machine produces a defective product. Sensors are embedded into the traditional screw heading machine, and sensing data are transmitted through a gateway to the voluntary computing node for screw slot quality inspection. The anomaly detection data set collected by the screw heading machine has a ratio of anomaly to normal data of 0.006; thus, we propose a time-series deep AutoEncoder architecture for anomaly detection of screw slots. Our experimental results show that the proposed solution outperforms existing works in terms of efficiency and that the specificity and accuracy can reach 97% through the framework proposed in this article.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W3186738246",
    "type": "article"
  },
  {
    "title": "Neural Network Approximation of Graph Fourier Transform for Sparse Sampling of Networked Dynamics",
    "doi": "https://doi.org/10.1145/3461838",
    "publication_date": "2021-09-14",
    "publication_year": 2021,
    "authors": "Alessio Pagani; Zhuangkun Wei; Ricardo Silva; Weisi Guo",
    "corresponding_authors": "",
    "abstract": "Infrastructure monitoring is critical for safe operations and sustainability. Like many networked systems, water distribution networks (WDNs) exhibit both graph topological structure and complex embedded flow dynamics. The resulting networked cascade dynamics are difficult to predict without extensive sensor data. However, ubiquitous sensor monitoring in underground situations is expensive, and a key challenge is to infer the contaminant dynamics from partial sparse monitoring data. Existing approaches use multi-objective optimization to find the minimum set of essential monitoring points but lack performance guarantees and a theoretical framework. Here, we first develop a novel Graph Fourier Transform (GFT) operator to compress networked contamination dynamics to identify the essential principal data collection points with inference performance guarantees. As such, the GFT approach provides the theoretical sampling bound. We then achieve under-sampling performance by building auto-encoder (AE) neural networks (NN) to generalize the GFT sampling process and under-sample further from the initial sampling set, allowing a very small set of data points to largely reconstruct the contamination dynamics over real and artificial WDNs. Various sources of the contamination are tested, and we obtain high accuracy reconstruction using around 5%–10% of the network nodes for known contaminant sources, and 50%–75% for unknown source cases, which although larger than that of the schemes for contaminant detection and source identifications, is smaller than the current sampling schemes for contaminant data recovery. This general approach of compression and under-sampled recovery via NN can be applied to a wide range of networked infrastructures to enable efficient data sampling for digital twins.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W3201291973",
    "type": "article"
  },
  {
    "title": "Privacy-preserving Secure Media Streaming for Multi-user Smart Environments",
    "doi": "https://doi.org/10.1145/3423047",
    "publication_date": "2021-10-22",
    "publication_year": 2021,
    "authors": "Bruno Carpentieri; Arcangelo Castiglione; Alfredo De Santis; Francesco Palmieri; Raffaele Pizzolante",
    "corresponding_authors": "",
    "abstract": "Over the last years, our lifestyle has been positively upset by the sudden advent of technology. The Internet of Things (IoT), offering universal and ubiquitous connectivity to both people and objects, revealed to be the silver bullet for enabling a vast number of previously unexpected applications. In particular, media streaming providers are growing in business and scope, and we can forecast that soon, video streaming will substitute TV broadcasting activities. With the increasing success of multi-user smart environments, empowered by new-generation smart devices and IoT architectures, multimedia contents (i.e., images and videos) need to be effectively accessed anytime and anywhere. Recent advances in computer vision technologies have made the development of intelligent monitoring systems for video surveillance and ambient-assisted living. Such a scenario permits better integration among technologies, multimedia content, and end-users. However, there are several challenges, and some are still open. More precisely, due to the sensitivity of some multimedia content (e.g., video-surveillance streams), it is paramount to preserve users’ privacy. Again, it is necessary to guarantee the integrity of usage rights during any multimedia transmission process, starting from the video encoding phase. In this way, the private content is disclosed only when the stream is decoded on the other endpoint, by the legitimate user. In this article, we present a secure video transmission strategy that can address the challenges mentioned above. The proposed strategy takes advantage of both watermarking and video scrambling techniques to make it possible for the secure and privacy-preserving transmission of multimedia streaming. Through our proposal, multimedia streaming is of low quality and thus unusable. However, it can be fully recovered and enjoyed only by authorized users. Finally, due to its low complexity and energy-efficiency, our proposal is particularly suitable for onboard implementations.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W3208596673",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1294148",
    "publication_date": "2007-11-01",
    "publication_year": 2007,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Web service discovery is one of the main applications of semantic Web services, which extend standard Web services with semantic annotations. Current discovery solutions were developed in the context of automatic service composition. Thus, the “client” ...",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4232101507",
    "type": "paratext"
  },
  {
    "title": "TOIT Reviewers over 2017",
    "doi": "https://doi.org/10.1145/3232919",
    "publication_date": "2018-11-19",
    "publication_year": 2018,
    "authors": "Munindar P. Singh",
    "corresponding_authors": "Munindar P. Singh",
    "abstract": "editorial Free Access Share on TOIT Reviewers over 2017 Editor: Munindar P. Singh View Profile Authors Info & Claims ACM Transactions on Internet TechnologyVolume 18Issue 4November 2018 Article No.: 57pp 1–5https://doi.org/10.1145/3232919Published:19 November 2018Publication History 0citation182DownloadsMetricsTotal Citations0Total Downloads182Last 12 Months16Last 6 weeks0 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2907309269",
    "type": "article"
  },
  {
    "title": "Mitigating Tail Response Time of n-Tier Applications",
    "doi": "https://doi.org/10.1145/3340462",
    "publication_date": "2019-07-25",
    "publication_year": 2019,
    "authors": "Qingyang Wang; Shungeng Zhang; Yasuhiko Kanemasa; Calton Pu",
    "corresponding_authors": "",
    "abstract": "Consistent low response time is essential for e-commerce due to intense competitive pressure. However, practitioners of web applications have often encountered the long-tail response time problem in cloud data centers as the system utilization reaches moderate levels (e.g., 50%). Our fine-grained measurements of an open source n-tier benchmark application (RUBBoS) show such long response times are often caused by Cross-tier Queue Overflow (CTQO). Our experiments reveal the CTQO is primarily created by the synchronous nature of RPC-style call/response inter-tier communications, which create strong inter-tier dependencies due to the request processing chain of classic n-tier applications composed of synchronous RPC/thread-based servers. We remove gradually the dependencies in n-tier applications by replacing the classic synchronous servers (e.g., Apache, Tomcat, and MySQL) with their corresponding event-driven asynchronous version (e.g., Nginx, XTomcat, and XMySQL) one-by-one. Our measurements with two application scenarios (virtual machine co-location and background monitoring interference) show that replacing a subset of asynchronous servers will shift the CTQO, without significant improvements in long-tail response time. Only when all the servers become asynchronous the CTQO is resolved. In synchronous n-tier applications, long-tail response times resulting from CTQO arise at utilization as low as 43%. On the other hand, the completely asynchronous n-tier system can disrupt CTQO and remove the long tail latency at utilization as high as 83%.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2963883790",
    "type": "article"
  },
  {
    "title": "CloseUp—A Community-Driven Live Online Search Engine",
    "doi": "https://doi.org/10.1145/3301442",
    "publication_date": "2019-08-27",
    "publication_year": 2019,
    "authors": "Christian von der Weth; Ashraf Abdul; Abhinav Ramesh Kashyap; Mohan Kankanhalli",
    "corresponding_authors": "",
    "abstract": "Search engines are still the most common way of finding information on the Web. However, they are largely unable to provide satisfactory answers to time- and location-specific queries. Such queries can best and often only be answered by humans that are currently on-site. Although online platforms for community question answering are very popular, very few exceptions consider the notion of users’ current physical locations. In this article, we present CloseUp, our prototype for the seamless integration of community-driven live search into a Google-like search experience. Our efforts focus on overcoming the defining differences between traditional Web search and community question answering, namely the formulation of search requests (keyword-based queries vs. well-formed questions) and the expected response times (milliseconds vs. minutes/hours). To this end, the system features a deep learning pipeline to analyze submitted queries and translate relevant queries into questions. Searching users can submit suggested questions to a community of mobile users. CloseUp provides a stand-alone mobile application for submitting, browsing, and replying to questions. Replies from mobile users are presented as live results in the search interface. Using a field study, we evaluated the feasibility and practicability of our approach.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2970386355",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3182619",
    "publication_date": "2018-03-18",
    "publication_year": 2018,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Web browsing is always a key requirement of Internet users. Current mobile Web apps can contain computation-intensive JavaScript logics and thus affect browsing performance. Learning from our over-decade research and development experiences of the ...",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4229545557",
    "type": "paratext"
  },
  {
    "title": "A Novel Point Cloud Registration Method for Multimedia Communication in Automated Driving Metaverse",
    "doi": "https://doi.org/10.1145/3672561",
    "publication_date": "2024-07-12",
    "publication_year": 2024,
    "authors": "Binbin Yong; Lei Ming; Jun Shen; Peng Zhi; Rui Zhao; Qingguo Zhou",
    "corresponding_authors": "",
    "abstract": "The development of the Metaverse offers more possibilities for autonomous driving. This is mainly reflected in the fact that the scene reconstructed based on multiple sensors can help the autonomous vehicle establish a Metaverse world based on its own real situation. When multiple vehicles build such a Metaverse world in the same scene, they can exchange their information including the perception of the vehicle’s condition and the surrounding environment, which means the creation of a Metaverse world containing all vehicles. Thus, an indirect Human-Human Multimedia Communications based on the Metaverse is realized, in which the autonomous driving system acts as a multimedia to provide a medium for the exchange of information between vehicles. The establishment of the Metaverse is based on stable and high-quality scene reconstruction. Accurate scene information can bring high quality Human-Human Multimedia Communications. Achieving this requires accurate scene reconstruction and vehicle positioning, both of which depend on accurate point cloud registration. In this work, we propose a robust registration method that is based on semantic information and scaling constraints. Our method consists of three steps. Firstly, we filter out points that might mislead the point cloud registration process by leveraging semantic information. Secondly, we obtain a more accurate initial matrix using TEASER++, which is based on semantic information and feature descriptors. Finally, we use semantic information and scaling to constrain the nearest neighbor matching and filter out error matches to obtain a higher quality registration. By following these steps, our method overcomes the memory problem faced by TEASER++ when there are large-scale point clouds, and greatly reduces its running time. Meanwhile, our algorithm achieved superior point cloud registration results compared to two state-of-the-art robust registration techniques: Globally optimal Iterative Closest Point (Go-ICP) and Generalized Iterative Closest Point (GICP).",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4400587629",
    "type": "article"
  },
  {
    "title": "Local Load Migration in High-Capacity Fog Computing",
    "doi": "https://doi.org/10.1145/3690386",
    "publication_date": "2024-08-27",
    "publication_year": 2024,
    "authors": "Mohammed Jasim; Nazli Siasi",
    "corresponding_authors": "",
    "abstract": "Fog computing brings storage and computational capabilities closer to the data source, which reduces latency and enhances efficiency in processing data. However, these capabilities are resource-constrained at the fog nodes as compared to the cloud core. This limitation can result in high computational loads that yield in saturation and congestion at the fog nodes when processing large traffic volumes. Hence, this article introduces a novel load migration scheme for delay-sensitive and computation-intensive requests in fog computing without relaying to the cloud core, thus avoiding prolonged link delays. First, a grouped service function chain (SFC) provisioning framework is embedded on a heterogeneous architecture composed of super fog (SF) and ordinary fog (OF) nodes, where all the virtual network functions (VNFs) in the SFC are mapped on a single SF node to reduce resource use. Here, the SF nodes are always in active mode to receive incoming traffic, whereas the OF nodes are maintained in idle mode to save power and computing resources. When the SF node approaches a saturation threshold alarm, it diffuses its load (hosted VNFs) gradually to neighboring OF nodes in the vicinity, thus avoiding saturation at the SF node and providing service continuity. The framework is implemented on a resource-constrained network to achieve realistic operating conditions. Overall, the proposed work achieves high admission and resource utilization rates, reduced delays, and power consumption, as compared to key network architectures and provisioning schemes that separately map delay-sensitive and computation-intensive on hierarchical fog layers, which incur increased delays, network traffic, and power usage.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4401918515",
    "type": "article"
  },
  {
    "title": "Enhancing Alexa Skill Testing Through Improved Utterance Discovery",
    "doi": "https://doi.org/10.1145/3698200",
    "publication_date": "2024-09-28",
    "publication_year": 2024,
    "authors": "Hassan A. Shafei; Chiu C. Tan",
    "corresponding_authors": "",
    "abstract": "Extracting skill utterances is a crucial step in testing and evaluating smart speaker skills. Previous works have proposed various techniques for extracting utterances from the skill web page to test and evaluate smart speaker skills. In this paper, we evaluate the effectiveness and correctness of different utterance-extracting techniques proposed in previous works. Our evaluation reveals that some techniques can capture incorrect utterances that the skill will not accept as spoken utterances. We also find that all the proposed techniques would never capture the total utterances supported by skills, and combining these techniques yields the best results in terms of text parsing. To address these limitations, we propose a new technique that combines the strengths of previous techniques and leverages human to interact with a small set of skills to expand the coverage for testing other skills. We evaluate the effectiveness of our technique and demonstrate that it can capture a higher number of utterances supported by skills. We delved into the impact assessment of utterance extraction, aiming to enhance the thoroughness and effectiveness of skill testing. We conducted an impact study on 11 skills to assess the importance of utterance extraction in the context of skills testing. Our findings demonstrate that our technique captures a higher number of utterances compared to previous techniques. Through our evaluation, we provide insights into the significance of discovering more utterances in the testing context, and demonstrate the effectiveness of our proposed technique in capturing more utterances for skill testing and evaluation.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4402949318",
    "type": "article"
  },
  {
    "title": "Safeguarding User-Centric Privacy in Smart Homes",
    "doi": "https://doi.org/10.1145/3701726",
    "publication_date": "2024-10-25",
    "publication_year": 2024,
    "authors": "Keyang Yu; Qi Li; Dong Chen; Liting Hu",
    "corresponding_authors": "",
    "abstract": "The Internet of Things (IoT) devices have been increasingly deployed in smart homes to automatically monitor and control their environments. Unfortunately, extensive recent research has shown that on-path external adversaries can infer and further fingerprint people’s sensitive private information by analyzing IoT network traffic traces. In addition, most recent approaches that aim to defend against these malicious IoT traffic analytics cannot adequately protect user privacy with reasonable traffic overhead. In particular, these approaches often did not consider practical traffic reshaping limitations, user daily routine permitting, and user privacy protection preference in their design. To address these issues, we design a new low-cost, open-source user-centric defense system—PrivacyGuard that enables people to regain the privacy leakage control of their IoT devices, while still permitting sophisticated IoT data analytics that is necessary for smart home automation. In essence, our approach employs intelligent deep convolutional generative adversarial networks (DCGANs)-assisted IoT device traffic signature learning, long short-term memory (LSTM)-based artificial traffic signature injection, and partial traffic reshaping to obfuscate private information that can be observed in IoT device traffic traces. We evaluate PrivacyGuard using IoT network traffic traces of 31 IoT devices from 5 smart homes and buildings. We find that PrivacyGuard can effectively prevent a wide range of state-of-the-art adversarial machine learning and deep learning based user in-home activity inference and fingerprinting attacks and help users to achieve the balance between their IoT data utility and privacy preserving.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4403747793",
    "type": "article"
  },
  {
    "title": "Signature-based IaaS Performance Change Detection",
    "doi": "https://doi.org/10.1145/3702228",
    "publication_date": "2024-10-26",
    "publication_year": 2024,
    "authors": "Athman Bouguettaya; Sheik Mohammad Mostakim Fattah",
    "corresponding_authors": "",
    "abstract": "We propose a novel change detection framework to identify changes in the long-term performance behavior of an IaaS service. An IaaS service’s long-term performance behavior is represented by an IaaS performance signature. The proposed framework leverages time series similarity measures and a sliding window technique to detect changes in IaaS performance signatures. We introduce a new IaaS performance noise model that enables the proposed framework to distinguish between performance noise and actual changes in performance. The proposed framework utilizes a novel Signal-to-Noise Ratio (SNR) based approach to detect changes when prior knowledge about performance noise is available. A set of experiments is conducted using real-world datasets to demonstrate the effectiveness of the proposed change detection framework.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4403790288",
    "type": "article"
  },
  {
    "title": "Introduction to the Special Issue on Distributed Intelligence on the Internet",
    "doi": "https://doi.org/10.1145/3700769",
    "publication_date": "2024-11-15",
    "publication_year": 2024,
    "authors": "Simon Mayer; Arne Bröring; Kimberly García; Konstantinos Fysarakis; Beatriz Soret",
    "corresponding_authors": "",
    "abstract": "The special issue on Explainable Artificial Intelligence (XAI) provides a representative snapshot of the state of the art in the 2020-2021 time-frame and highlights future research directions. The scope of the special issue is ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4404415417",
    "type": "article"
  },
  {
    "title": "Optimizing Geo-Distributed Data Processing with Resource Heterogeneity over the Internet",
    "doi": "https://doi.org/10.1145/3708322",
    "publication_date": "2024-12-17",
    "publication_year": 2024,
    "authors": "Saeed Mirpour Marzuni; Adel N. Toosi; Abdorreza Savadi; Mahmoud Naghibzadeh; David Taniar",
    "corresponding_authors": "",
    "abstract": "The traditional MapReduce frameworks were originally designed for processing data within a single cluster and are not suitable for handling geo-distributed data. Consequently, alternative approaches such as Hierarchical and Geo-Hadoop have been proposed to address this limitation. However, these approaches still face challenges in efficiently managing inter-cluster data transfer, particularly considering the heterogeneity of clusters and varying bandwidth among them. Moreover, the need to transmit results to a central global reducer for geo-distributed MapReduce operations adds unnecessary complexity. To tackle these issues, we introduce Extended Cross-MapReduce (ECMR), a framework that integrates resource heterogeneity and network links in geo-distributed MapReduce workflows. ECMR optimizes data management and determines the necessary data volume for generating final results. To enhance performance, ECMR leverages the overlap between data transfer and execution time by utilizing multiple global reducers and grouping temporary results that require data transfer over the Internet. In ECMR, we propose a bipartite graph and extend the Gale-Shapley algorithm to determine the optimal number of clusters and select the most suitable locations for global reducers. Through extensive experimental evaluations conducted on a real testbed, we demonstrate the effectiveness of our proposed ECMR method. The results exhibit significant improvements over traditional Hierarchical and Geo-Hadoop approaches, achieving reductions of up to 81% and 85% in overall makespan, respectively.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4405513866",
    "type": "article"
  },
  {
    "title": "Relieving Overexposure in Information Diffusion Through a Budget Multi-stage Allocation",
    "doi": "https://doi.org/10.1145/3708537",
    "publication_date": "2024-12-17",
    "publication_year": 2024,
    "authors": "Peikun Ni; Barbara Guidi; Andrea Michienzi; Jianming Zhu",
    "corresponding_authors": "",
    "abstract": "When information dissemination campaigns on Online Social Networking platforms are too aggressive, this can easily cause information overexposure. Overexposure can break through the psychological and physiological limits that the audience can tolerate, making it difficult for the audience to obtain reasonable cognitive concepts. For example, the overexposure of information referring to an object in a promotional campaign can lead to inflated expectations in individuals. Building on this, we introduce two indicators for individuals’ expectations and actual utility of the object and design a multi-stage triggered mechanism for seed individuals to explore the relieving overexposure problem in information diffusion. We build a multi-stage information diffusion model and characterize the evolution of individual expectations. We verify the hardness result of the relieving overexposure problem by budget multi-stage allocation, and the non-submodularity and non-monotonicity of the objective function. Addressing the non-monotonic and non-submodular set function, we provide a direct influence-oriented algorithm with a greedy approach. Extensive experiments are performed on four real networks to explore how model parameters and network properties affect the effects of multi-stage triggered strategies for seed individuals. Using the experiments, we found that the seed individual multi-stage incremental triggered strategy of dissemination campaign of information referring to an object shows better performance, and the lower the actual utility of the specific object, the more accurate the promotion strategy needs to be developed.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4405513954",
    "type": "article"
  },
  {
    "title": "Online Worker Scheduling for Maximizing Long-Term Utility in Crowdsourcing with Unknown Quality",
    "doi": "https://doi.org/10.1145/3708893",
    "publication_date": "2024-12-18",
    "publication_year": 2024,
    "authors": "J.C. Wang; Pengfei Lin; Xingjian Ding; Jianxiong Guo; Zhiqing Tang; Deying Li; Weili Wu",
    "corresponding_authors": "",
    "abstract": "Spatiotemporal Mobile CrowdSourcing (MCS) is a new intelligent sensing paradigm for large-scale data acquisition where requesters can recruit a crowd of workers to perform data collection tasks. How to recruit suitable workers in a dynamic environment to maximize platform utility is a key issue and has become a research hotspot. Many past studies have made great efforts in this regard, but most of them either assume that the worker quality is known in advance or ignore the limitations of workers’ short-term ability to provide resources. In this paper, we consider a platform-centered online spatiotemporal MCS system where mobile workers have both long-term and short-term constraints for providing resources, and their quality is unknown to the platform, while the platform has a long-term budget constraint for recruiting workers. We aim to find an online worker scheduling scheme to maximize the platform’s long-term utility without violating the constraints of both workers and the platform. To address this problem, we first transform the long-term utility maximization problem into a real-time utility maximization problem by leveraging the Lyapunov optimization, then design algorithms based on the Upper Confidence Bound (UCB) and Markov approximation to solve each real-time utility maximization problem with unknown worker quality. We demonstrate that our UCB-based algorithm has a sublinear regret and prove that our proposed framework has a performance guarantee for the addressed problem. Finally, we evaluate our design through numerical simulation experiments, and the results demonstrate the effectiveness of our algorithm.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4405546972",
    "type": "article"
  },
  {
    "title": "IDN server proxy architecture for Internationalized Domain Name resolution and experiences with providing Web services",
    "doi": "https://doi.org/10.1145/1125274.1125275",
    "publication_date": "2006-02-01",
    "publication_year": 2006,
    "authors": "Jeng-Wei Lin; Jan-Ming Ho; Li‐Ming Tseng; Feipei Lai",
    "corresponding_authors": "",
    "abstract": "The composition of traditional domain names are restricted to ASCII letters, digits, and hyphens (abbreviated as LDH). This makes it difficult for many to use their native language to name and access their Internet hosts. The IETF IDN (Internationalized Domain Name) Working Group proposes a mechanism, IDNA (Internationalizing Domain Names in Applications), for internationalized access to multilingual domain names. The proposal uses a preparation process that converts a Unicode IDN into an ACE (ASCII Compatible Encoding) string that uses only LDH. Thus, applications can look up the ACE string by using the existing DNS infrastructure. However, some of the domain name strings embedded in multilingual content do not have any charset tag so they cannot appropriately be converted into ACE strings. We noticed that many Internet applications allow users to use non-ASCII domain names. We were motivated to design an architecture for IDN resolution as well as to minimize the cost of modifying legacy Internet applications. We specifically focus on designing an IDN server proxy, which is located on the domain name server side, to handle domain names in multiple encodings. In this article, we study several architecture design issues including detection of charset encoding, routing of non-ACE IDN lookup requests, and so on.With respect to these design issues, we present an IDN server proxy architecture which stores ACE IDNs in domain name servers. Note that traditional domain name servers can be used without modification. An IDN server proxy, called Octopus, is employed on the domain name server side. Octopus converts a non-ACE IDN string into ACE upon receiving an IDN lookup request from remote users or autonomous systems. The ACE string is then forwarded to backend domain name servers (where the traditional domain names and ACE IDNs are stored) for further processing. This allows Internet users to access IDNs without having to upgrade their software.Based on the design and implementation of Octopus, we deployed a CDN (Chinese domain name) trial in July 2002. In this article, we present the results of testing Octopus IDN lookup functions as well as our experiences in providing CDN Web services. Several types of errors can occur if applications are unable to handle IDNs adequately. For example, a Web browser may erroneously parse an IDN within a URL. Many legacy Web servers are unable to process the IDN of a virtual host. Web application servers may have trouble completing some actions such as redirecting Web pages to alternative Web pages. Our studies help service providers understand potential problems when non-ASCII domain names are used and the best common practice at this stage. As well, the experiences give some guidance for software developers to develop IDNA-compliant Internet applications.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2128614318",
    "type": "article"
  },
  {
    "title": "Exploiting Proxy Sensing for Efficient Monitoring of Large-Scale Sensor Networks",
    "doi": "https://doi.org/10.1145/3376919",
    "publication_date": "2020-05-03",
    "publication_year": 2020,
    "authors": "Amitangshu Pal; Krishna Kant",
    "corresponding_authors": "",
    "abstract": "Large networks of IoT devices, each consisting of one or more sensors, are being increasingly deployed for comprehensive real-time monitoring of cyber-physical systems. Such networks form an essential component of the emerging edge computing paradigm and are expected to increase in complexity and size. The physical phenomenon sensed by different sensors (within the same or different IoT devices in close proximity) often have relationships that makes them correlated. This is a form of proxy sensing that can be exploited for achieving better energy efficiency and higher robustness in monitoring. In this article, we explore how a set of sensors can optimize its data collection rates efficiently in a semi-distributed manner and yet provide the advantages of autonomy, relative isolation, and distributed control that is essential in a large-scale network.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W3021673380",
    "type": "article"
  },
  {
    "title": "Introduction to the Special Issue on Evolution of IoT Networking Architectures",
    "doi": "https://doi.org/10.1145/3406087",
    "publication_date": "2020-08-31",
    "publication_year": 2020,
    "authors": "Rute C. Sofia; Eve M. Schooler; Dirk Kutscher; Chris Winkler",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W3091225207",
    "type": "article"
  },
  {
    "title": "Decentralized Dynamic Scheduling of TCPS Flows and a Simulator for Time-sensitive Networking",
    "doi": "https://doi.org/10.1145/3498729",
    "publication_date": "2022-02-03",
    "publication_year": 2022,
    "authors": "Kurian Polachan; Chandramani Singh; T. V. Prabhakar",
    "corresponding_authors": "",
    "abstract": "Cybersickness and control-loop instabilities are two main concerns in Tactile Cyber-Physical Systems (TCPS). TCPS applications demand stringent bounds on end-to-end latencies to avoid their occurrences. Traditional best-effort networks cannot guarantee packet latencies in the presence of external traffic. However, emerging deterministic networks such as IEEE 802.1 Time-Sensitive Networking (TSN) can isolate time-critical flows from external traffic using IEEE 802.1Qbv Time-Aware Shaper (TAS) to guarantee bounded end-to-end packet latencies. In this work, we develop eDDSCH-TSN, a decentralized dynamic scheduling protocol to configure non-overlapping gate slots in TAS-enabled TSN switches to support TCPS flows. eDDSCH-TSN supports plug-and-play operation of compatible TCPS terminals with guaranteed minimal end-to-end packet latencies. Compared to the state-of-the-art, eDDSCH-TSN provides three orders lower end-to-end packet latencies for TCPS flows in mid-size networks with 10 hops between source and destination terminals. Further, we also present PYTSN, an open-source discrete-event TSN simulator that we use for evaluating eDDSCH-TSN. In particular, we use PYTSN to show the isolation of TCPS flows from external traffic and plug-and-play operation of TCPS terminals.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4210758114",
    "type": "article"
  },
  {
    "title": "Pedestrian Trajectory Prediction in Heterogeneous Traffic using Facial Keypoints-based Convolutional Encoder-decoder Network",
    "doi": "https://doi.org/10.1145/3410444",
    "publication_date": "2022-03-22",
    "publication_year": 2022,
    "authors": "Song Xiao; Kai Chen; Xiaoxiang Ren; Haitao Yuan",
    "corresponding_authors": "",
    "abstract": "Future pedestrian trajectory prediction offers great prospects for many practical applications such as unmanned vehicles, building evacuation design and robotic path planning. Most existing methods focus on social interaction among pedestrians but ignore the fact that heterogeneous traffic objects (cars, dogs, bicycles, motorcycles, etc.) have significant influence on the future trajectory of a subject pedestrian. Also, the walking direction intention of a pedestrian may be referred by his/her facial keypoints. Considering this, this work proposes to predict a pedestrian's future trajectory by jointly using neighboring heterogeneous traffic information and his/her facial keypoints. To fulfill this, an end-to-end facial keypoints-based convolutional encoder-decoder network (FK-CEN) is designed, in which the heterogeneous traffic and facial keypoints are input. After training, FK-CEN is evaluated on 5 crowded video sequences collected from the public datasets MOT-16 and MOT-17. Experimental results demonstrate that it outperforms state-of-the-art approaches, in terms of prediction errors.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4221041899",
    "type": "article"
  },
  {
    "title": "A Highly Compatible Verification Framework with Minimal Upgrades to Secure an Existing Edge Network",
    "doi": "https://doi.org/10.1145/3511901",
    "publication_date": "2022-03-25",
    "publication_year": 2022,
    "authors": "Zhenyu Li; Yong Ding; Honghao Gao; Bo Qu; Yujue Wang; Jun Li",
    "corresponding_authors": "",
    "abstract": "Edge networks are providing services for an increasing number of companies, and they can be used for communication between edge devices and edge gateways. However, the performance of edge devices varies greatly, and it is not easy to upgrade low-performance edge devices. Therefore, cyber attackers can use the vulnerability of edge devices to implement advanced persistent threat attacks. This article proposes a network verification framework for edge networks that can minimize the upgrades needed to strengthen edge network security. First, the communication parties use the data transmitted by the given edge network. Our method uses our proposed PacketVerifier to attach verification information to the packet after it is sent and to verify and restore the packet before it reaches the receiver. Second, due to the performance requirements of edge networks, we design a new data processing structure, namely, a sliding window double ring, to improve the performance of strict sequential protocols in parallel validation. Finally, experimental simulations show that our parallel processing algorithm has good performance in terms of network bandwidth compared with two existing packet processing algorithms. Furthermore, the proposed packet with verification information is compatible with the existing network topology, which helps PacketVerifier establish trustworthy transmission in a zero-trust environment.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4221060012",
    "type": "article"
  },
  {
    "title": "Enhancing Security-Problem-Based Deep Learning in Mobile Edge Computing",
    "doi": "https://doi.org/10.1145/3458931",
    "publication_date": "2022-05-14",
    "publication_year": 2022,
    "authors": "Xiao Zheng; Mingchu Li; Syed Bilal Hussain Shah; Dinh‐Thuan Do; Yuanfang Chen; Constandinos X. Mavromoustakis; George Mastorakis; Evangelos Pallis",
    "corresponding_authors": "",
    "abstract": "The implementation of a variety of complex and energy-intensive mobile applications by resource-limited mobile devices (MDs) is a huge challenge. Fortunately, mobile edge computing (MEC) as a new computing paragon can offer rich resources to perform all or part of the MD’s task, which greatly reduces the energy consumption of the MD and improves the quality of service (QoS) for applications. However, offloading tasks to the edge server is vulnerable to attacks such as tampering and snooping, resulting in a deep learning (DL) security feature developed by major cloud service providers. An effective security strategy method to minimize ongoing attacks in the MEC setting is proposed. The algorithm is based on the synthetic principle of a special set of strategies, and it can quickly construct suboptimal solutions even if the number of targets achieves hundreds of millions. In addition, for a given structure and a given number of patrollers, the upper bound of the protection level can be obtained, and the lower bound required for a given protection level can also be inferred. These bounds apply to universal strategies. By comparing with the previous three basic experiments, it can be proved that our algorithm is better than the previous ones in terms of security and running time.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4280631396",
    "type": "article"
  },
  {
    "title": "VoiceTalk: Multimedia-IoT Applications for Mixing Mandarin, Taiwanese, and English",
    "doi": "https://doi.org/10.1145/3543854",
    "publication_date": "2022-06-14",
    "publication_year": 2022,
    "authors": "Yi‐Bing Lin; Yuan‐Fu Liao; Sin‐Horng Chen; Shaw‐Hwa Hwang; Yih‐Ru Wang",
    "corresponding_authors": "",
    "abstract": "The voice-based Internet of Multimedia Things (IoMT) is the combination of IoT interfaces and protocols with associated voice-related information, which enables advanced applications based on human-to-device interactions. An example is Automatic Speech Recognition (ASR) for live captioning and voice translation. Three major issues of ASR for IoMT are IoT development cost, speech recognition accuracy, and execution time complexity. For the first issue, most non-voice IoT applications are upgraded with the ASR feature through hard coding, which are error prone. For the second issue, recognition accuracy must be improved for ASR. For the third issue, many multimedia IoT services are real-time applications and, therefore, the ASR delay must be short. This article elaborates on the above issues based on an IoT platform called VoiceTalk. We built the largest Taiwanese spoken corpus to train VoiceTalk ASR (VT-ASR) and show how the VT-ASR mechanism can be transparently integrated with existing IoT applications. We consider two performance measures for VoiceTalk: speech recognition accuracy and VT-ASR delay. For the acoustic tests of PAL-Labs, VT-ASR's accuracy is 96.47%, while Google's accuracy is 94.28%. We are the first to develop an analytic model to investigate the probability that the VT-ASR delay for the first speaker is complete before the second speaker starts talking. From the measurements and analytic modeling, we show that the VT-ASR delay is short enough to result in a very good user experience. Our solution has won several important government and commercial TV contracts in Taiwan. VT-ASR has demonstrated better Taiwanese Mandarin speech recognition accuracy than famous commercial products (including Google and Iflytek) in Formosa Speech Recognition Challenge 2018 (FSR-2018) and was the best among all participating ASR systems for Taiwanese recognition accuracy in FSR-2020.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4282837673",
    "type": "article"
  },
  {
    "title": "SAM: Multi-turn Response Selection Based on Semantic Awareness Matching",
    "doi": "https://doi.org/10.1145/3545570",
    "publication_date": "2022-06-30",
    "publication_year": 2022,
    "authors": "Rongjunchen Zhang; Tingmin Wu; Sheng Wen; ‪Surya Nepal‬; Cécile Paris; Yang Xiang",
    "corresponding_authors": "",
    "abstract": "Multi-turn response selection is a key issue in retrieval-based chatbots and has attracted considerable attention in the NLP (Natural Language processing) field. So far, researchers have developed many solutions that can select appropriate responses for multi-turn conversations. However, these works are still suffering from the semantic mismatch problem when responses and context share similar words with different meanings. In this article, we propose a novel chatbot model based on Semantic Awareness Matching, called SAM. SAM can capture both similarity and semantic features in the context by a two-layer matching network. Appropriate responses are selected according to the matching probability made through the aggregation of the two feature types. In the evaluation, we pick 4 widely used datasets and compare SAM’s performance to that of 12 other models. Experiment results show that SAM achieves substantial improvements, with up to 1.5% R 10 @1 on Ubuntu Dialogue Corpus V2, 0.5% R 10 @1 on Douban Conversation Corpus, and 1.3% R 10 @1 on E-commerce Corpus.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4283764330",
    "type": "article"
  },
  {
    "title": "The Tip of the Buyer: Extracting Product Tips from Reviews",
    "doi": "https://doi.org/10.1145/3547140",
    "publication_date": "2022-07-14",
    "publication_year": 2022,
    "authors": "Sharon Hirsch; Slava Novgorodov; Ido Guy; Alexander Nus",
    "corresponding_authors": "",
    "abstract": "Product reviews play a key role in e-commerce platforms. Studies show that many users read product reviews before a purchase and trust them to the same extent as personal recommendations. However, in many cases, the number of reviews per product is large and extracting useful information becomes a challenging task. Several websites have recently added an option to post tips —short, concise, practical, and self-contained pieces of advice about the products. These tips are complementary to the reviews and usually add a new non-trivial insight about the product, beyond its title, attributes, and description. Yet, most if not all major e-commerce platforms lack the notion of a tip as a first-class citizen and customers typically express their advice through other means, such as reviews. In this work, we propose an extractive method for tip generation from product reviews. We focus on five popular e-commerce domains whose reviews tend to contain useful non-trivial tips that are beneficial for potential customers. We formally define the task of tip extraction in e-commerce by providing the list of tip types, tip timing (before and/or after the purchase), and connection to the surrounding context sentences. To extract the tips, we propose a supervised approach and leverage a publicly available dataset, annotated by human editors, containing 14,000 product reviews. To demonstrate the potential of our approach, we compare different tip generation methods and evaluate them both manually and over the labeled set. Our approach demonstrates particularly high performance for popular products in the Baby, Home Improvement, and Sports &amp; Outdoors domains, with precision of over 95% for the top 3 tips per product. In addition, we evaluate the performance of our methods on previously unseen domains. Finally, we discuss the practical usage of our approach in real-world applications. Concretely, we explain how tips generated from user reviews can be integrated in various use cases within e-commerce platforms and benefit both buyers and sellers.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4285386982",
    "type": "article"
  },
  {
    "title": "Elastically Augmenting the Control-path Throughput in SDN to Deal with Internet DDoS Attacks",
    "doi": "https://doi.org/10.1145/3559759",
    "publication_date": "2022-09-02",
    "publication_year": 2022,
    "authors": "Yuanjun Dai; An Wang; Yang Guo; Songqing Chen",
    "corresponding_authors": "",
    "abstract": "Distributed denial of service (DDoS) attacks have been prevalent on the Internet for decades. Albeit various defenses, they keep growing in size, frequency, and duration. The new network paradigm, Software-defined networking (SDN), is also vulnerable to DDoS attacks. SDN uses logically centralized control, bringing the advantages in maintaining a global network view and simplifying programmability. When attacks happen, the control path between the switches and their associated controllers may become congested due to their limited capacity. However, the data plane visibility of SDN provides new opportunities to defend against DDoS attacks in the cloud computing environment. To this end, we conduct measurements to evaluate the throughput of the software control agents on some of the hardware switches when they are under attacks. Then, we design a new mechanism, called Scotch , to enable the network to scale up its capability and handle the DDoS attack traffic. In our design, the congestion works as an indicator to trigger the mitigation mechanism. Scotch elastically scales up the control plane capacity by using an Open vSwitch-based overlay. Scotch takes advantage of both the high control plane capacity of a large number of vSwitches and the high data plane capacity of commodity physical switches to increase the SDN network scalability and resiliency under abnormal (e.g., DDoS attacks) traffic surges. We have implemented a prototype and experimentally evaluated Scotch . Our experiments in the small-scale lab environment and large-scale GENI testbed demonstrate that Scotch can elastically scale up the control channel bandwidth upon attacks.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4294237804",
    "type": "article"
  },
  {
    "title": "Tripartite Transmitting Methodology for Intermittently Connected Mobile Network (ICMN)",
    "doi": "https://doi.org/10.1145/3433545",
    "publication_date": "2022-11-17",
    "publication_year": 2022,
    "authors": "Ramesh Sekaran; Fadi Al‐Turjman; Rizwan Patan; Velmani Ramasamy",
    "corresponding_authors": "",
    "abstract": "Mobile network is a collection of devices with dynamic behavior where devices keep moving, which may lead to the network track to be connected or disconnected. This type of network is called Intermittently Connected Mobile Network (ICMN) . The ICMN network is designed by splitting the region into `n' regions, ensuring it is a disconnected network. This network holds the same topological structure with mobile devices in it. This type of network routing is a challenging task. Though research keeps deriving techniques to achieve efficient routing in ICMN such as Epidemic, Flooding, Spray, copy case, Probabilistic, and Wait, these derived techniques for routing in ICMN are wise with higher packet delivery ratio, minimum latency, lesser overhead, and so on. A new routing schedule has been enacted comprising three optimization techniques such as Privacy-Preserving Ant Routing Protocol (PPARP), Privacy-Preserving Routing Protocol (PPRP), and Privacy-Preserving Bee Routing Protocol (PPBRP) . In this paper, the enacted technique gives an optimal result following various network characteristics. Algorithms embedded with productive routing provide maximum security. Results are pointed out by analysis taken from spreading false devices into the network and its effectiveness at worst case. This paper also aids with the comparative results of enacted algorithms for secure routing in ICMN.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4309619920",
    "type": "article"
  },
  {
    "title": "LSDN Empowers the Metaverse Communication to Achieve High-Resolution Visuals with Lower Bandwidth",
    "doi": "https://doi.org/10.1145/3672075",
    "publication_date": "2024-06-24",
    "publication_year": 2024,
    "authors": "Kehua Guo; Xuyang Tan; Liang Chen; Xiangyuan Zhu; Jian Zhang; Xiaokang Zhou",
    "corresponding_authors": "",
    "abstract": "Deploying super-resolution models on metaverse terminal devices can enhance visual effects without increasing network bandwidth. However, deploying most current super-resolution networks on metaverse terminal devices with limited hardware resources poses a challenge due to their large volumes and high computing power consumption. In this paper, we present a lightweight separation and distillation network (LSDN) aimed at reducing the model complexity by prioritizing network structure. Specifically, we initially present the blueprint separable convolution (BSConv) to decrease model complexity and utilize the BSConv and information distillation mechanism building the channel separation distillation block (CSDB). Subsequently, we develop the enhanced spatial attention block (ESA) and Fused-MBConv (FMBConv) to explore latent information. In addition, we employ three CSDBs, an ESA, and an FMBConv to construct the residual attention unit (RAU). Finally, we concatenate several RAUs and amalgamate their hierarchical results, and transmit them to the upsampler for reconstructing the high-resolution images. We carried out comprehensive experiments on a range of datasets and found conclusive evidence that the LSDN outperforms state-of-the-art approaches, exhibiting notable enhancements in quantitative and qualitative terms.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4399985031",
    "type": "article"
  },
  {
    "title": "A Network Calculus Model for SFC Realization and Traffic Bounds Estimation in Data Centers",
    "doi": "https://doi.org/10.1145/3700440",
    "publication_date": "2024-10-11",
    "publication_year": 2024,
    "authors": "Sidharth Sharma; Admela Jukan; Aashi Malik; Ashwin Gumaste",
    "corresponding_authors": "",
    "abstract": "Network Function Virtualization (NFV) is a promising technology that can transform how internet service providers deliver their services. However, recent studies have identified several challenges in adopting NFV. Two key challenges are central to the operation and capacity planning of NFV Data Centers (DCs): (i) Service Function Chain (SFC) realization —determining if a new request with a known profile can be accommodated—and (ii) Network Function Virtualization (NFV) traffic bounds estimation —estimating the total traffic that a data center can handle considering all service requests and their performance constraints. To address these challenges, we propose a model that leverages stochastic network calculus to effectively dimension an NFV DC while ensuring delay and availability bounds for all service requests. Our theoretical model provides a mathematical framework to assess the realization of a single SFC request without delving into the specifics of the realization process. We utilize established availability-aware Virtual Network Function (VNF) placement patterns to obtain traffic bounds essential to planning data center capacity. We analyze NFV data center traffic under various scenarios over a Fat-tree DC topology. The results demonstrate that data center capacity is significantly influenced by the VNF placement strategy. Additionally, for data centers hosting latency-sensitive services, Service Level Objective (SLO) constraints on availability and delay are crucial in determining the number of such requests that can be accommodated.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4403318577",
    "type": "article"
  },
  {
    "title": "Special Issue on Pricing and Incentives in Networks and Systems",
    "doi": "https://doi.org/10.1145/2665064",
    "publication_date": "2014-10-28",
    "publication_year": 2014,
    "authors": "Costas Courcoubetis; R. Guérin; Patrick Loiseau; David C. Parkes; Jean Walrand; Adam Wierman",
    "corresponding_authors": "",
    "abstract": "research-article Free Access Share on Special Issue on Pricing and Incentives in Networks and Systems: Guest Editors' Introduction Editors: Costas Courcoubetis SUTD, Singapore SUTD, SingaporeView Profile , Roch Guérin Washington University in St. Louis, USA Washington University in St. Louis, USAView Profile , Patrick Loiseau EURECOM, France EURECOM, FranceView Profile , David Parkes Harvard University, USA Harvard University, USAView Profile , Jean Walrand University of California, Berkeley, USA University of California, Berkeley, USAView Profile , Adam Wierman Caltech, USA Caltech, USAView Profile Authors Info & Claims ACM Transactions on Internet TechnologyVolume 14Issue 2-3Article No.: 8pp 1–3https://doi.org/10.1145/2665064Published:28 October 2014Publication History 0citation285DownloadsMetricsTotal Citations0Total Downloads285Last 12 Months17Last 6 weeks0 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2117061093",
    "type": "article"
  },
  {
    "title": "Introduction to Theme Section on Trust in Social Networks and Systems",
    "doi": "https://doi.org/10.1145/2835510",
    "publication_date": "2015-12-14",
    "publication_year": 2015,
    "authors": "Timothy J. Norman; K. Suzanne Barber; Rino Falcone; Jie Zhang",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2293735694",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2869768",
    "publication_date": "2016-02-24",
    "publication_year": 2016,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Witnessing the wide spread of malicious information in large networks, we develop an efficient method to detect anomalous diffusion sources and thus protect networks from security and privacy attacks. To date, most existing work on diffusion sources ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4233803622",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3023158",
    "publication_date": "2016-12-22",
    "publication_year": 2016,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "The Internet of Things (IoT) is the latest Internet evolution that incorporates a diverse range of things such as sensors, actuators, and services deployed by different organizations and individuals to support a variety of applications. The information ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4233927548",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2796692",
    "publication_date": "2015-06-24",
    "publication_year": 2015,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "A key challenge in online communities is that of keeping a community active and alive. All online communities work hard to keep their members through various initiatives, such as personalisation and recommendation technologies. In online communities ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4237943243",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2851090",
    "publication_date": "2015-12-14",
    "publication_year": 2015,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "In this article, we are interested in the fact that relevance and trustworthiness of information acquired by an agent X from a source F strictly depends and derives from X's trust in F with respect to the kind of information. In particular, we are ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4239702808",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2656491",
    "publication_date": "2014-07-01",
    "publication_year": 2014,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "The rapidly increasing amount of user-generated content in social tagging systems provides a huge source of information. Yet, performing effective search in these systems is very challenging, especially when we seek the most appropriate items that match ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4246516314",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2684804",
    "publication_date": "2014-10-28",
    "publication_year": 2014,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "In recent years there has been an explosive growth of digital content in the form of news feeds, videos, and original content on online platforms such as blogs and social networks. Indeed, such platforms have been used as a means of sharing and ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4250857571",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2745838",
    "publication_date": "2015-03-12",
    "publication_year": 2015,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "An unprecedented information wealth produced by online social networks, further augmented by location/collocation data, is currently fragmented across different proprietary services. Combined, it can accurately represent the social world and enable ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4252003694",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2809898",
    "publication_date": "2015-09-28",
    "publication_year": 2015,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "This article addresses a multi-query optimization problem for distributed medical image retrieval in mobile wireless networks by exploiting the dependencies in the derivation of a retrieval evaluation plan. To the best of our knowledge, this is the ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4252693433",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2699996",
    "publication_date": "2014-12-17",
    "publication_year": 2014,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Socio-Technical Systems demand an evolution of computing into social computing, with a transition from an individualistic to a societal view. As such, they seem particularly suitable to realize multiparty, cross-organizational systems. Multi-Agent ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4254179849",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2926746",
    "publication_date": "2016-08-22",
    "publication_year": 2016,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Benchmarking the performance of public cloud providers is a common research topic. Previous work has already extensively evaluated the performance of different cloud platforms for different use cases, and under different constraints and experiment ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4255324414",
    "type": "paratext"
  },
  {
    "title": "Layer-based Composite Reputation Bootstrapping",
    "doi": "https://doi.org/10.1145/3448610",
    "publication_date": "2021-09-14",
    "publication_year": 2021,
    "authors": "Sajib Mistry; Lie Qu; Athman Bouguettaya",
    "corresponding_authors": "",
    "abstract": "We propose a novel generic reputation bootstrapping framework for composite services. Multiple reputation-related indicators are considered in a layer-based framework to implicitly reflect the reputation of the component services. The importance of an indicator on the future performance of a component service is learned using a modified Random Forest algorithm. We propose a topology-aware Forest Deep Neural Network (fDNN) to find the correlations between the reputation of a composite service and reputation indicators of component services. The trained fDNN model predicts the reputation of a new composite service with the confidence value. Experimental results with real-world dataset prove the efficiency of the proposed approach.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W3129593549",
    "type": "article"
  },
  {
    "title": "Fast Search of Lightweight Block Cipher Primitives via Swarm-like Metaheuristics for Cyber Security",
    "doi": "https://doi.org/10.1145/3417296",
    "publication_date": "2021-07-16",
    "publication_year": 2021,
    "authors": "Xin Jin; Yuwei Duan; Ying Zhang; Yating Huang; Mengdong Li; Ming Mao; Amit Kumar Singh; Yujie Li",
    "corresponding_authors": "",
    "abstract": "With the construction and improvement of 5G infrastructure, more devices choose to access the Internet to achieve some functions. People are paying more attention to information security in the use of network devices. This makes lightweight block ciphers become a hotspot. A lightweight block cipher with superior performance can ensure the security of information while reducing the consumption of device resources. Traditional optimization tools, such as brute force or random search, are often used to solve the design of Symmetric-Key primitives. The metaheuristic algorithm was first used to solve the design of Symmetric-Key primitives of SKINNY. The genetic algorithm and the simulated annealing algorithm are used to increase the number of active S-boxes in SKINNY, thus improving the security of SKINNY. Based on this, to improve search efficiency and optimize search results, we design a novel metaheuristic algorithm, named particle swarm-like normal optimization algorithm (PSNO) to design the Symmetric-Key primitives of SKINNY. With our algorithm, one or better algorithm components can be obtained more quickly. The results in the experiments show that our search results are better than those of the genetic algorithm and the simulated annealing algorithm. The search efficiency is significantly improved. The algorithm we proposed can be generalized to the design of Symmetric-Key primitives of other lightweight block ciphers with clear evaluation indicators, where the corresponding indicators can be used as the objective functions.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W3186664374",
    "type": "article"
  },
  {
    "title": "A Novel Approach for Efficient Packet Transmission in Volunteered Computing MANET",
    "doi": "https://doi.org/10.1145/3418203",
    "publication_date": "2021-09-03",
    "publication_year": 2021,
    "authors": "Ramesh Sekaran; Rizwan Patan; Fadi Al‐Turjman",
    "corresponding_authors": "",
    "abstract": "A mobile ad hoc network (MANET) is summarized as a combination device that can move, synchronize and converse without any preceding management. Enhancing the lifetime energy is based on the status of the concerned channel. The node is accomplished of control the control messages. Due to unplanned methods of energy conservation, the node lifespan and quality of packet flow is defaced in the existing solution. It results in a network-to-node-energy trade-off, ensuing in a failure of the post-network. This failure results in reduced time-to-live and higher overhead. This paper discusses an effective buffer management mechanism, in addition to proposing a novel performance modeling in Volunteered Computing MANET and tactile internet Next, the best execution the nodes can accomplish under fractional data is completely portrayed for utilities for a general purpose. To associate the space between network efficiency and energy conservation based on the minimal overhead, this article proposes a switch state promoting mutual Optimized MAC protocol for conservation of a node's energy and the optimal use of available nodes before their energy drain. Simulation results are provided as proof of the proposed solution. The simulation results are compared with the existing system with performance measures of delay, throughput, energy consumption, and availability of the node.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W3196868941",
    "type": "article"
  },
  {
    "title": "Vision for TOIT",
    "doi": "https://doi.org/10.1145/2499926.2499929",
    "publication_date": "2013-07-01",
    "publication_year": 2013,
    "authors": "Munindar P. Singh",
    "corresponding_authors": "Munindar P. Singh",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W1983888946",
    "type": "article"
  },
  {
    "title": "User and ISP Rights of Device Attachment and Device Management",
    "doi": "https://doi.org/10.1145/2513227",
    "publication_date": "2013-12-01",
    "publication_year": 2013,
    "authors": "Scott Jordan; Gwen Shaffer",
    "corresponding_authors": "",
    "abstract": "Internet research often assumes users may connect devices without consent by their service providers. However, in many networks the service provider only allows use of devices obtained directly from the provider. We review how United States communications law addresses the rights of users to connect devices of their choice. We explicate a set of user and service provider rights. We propose legal requirements for attachment and management of devices. We illustrate how these proposed regulations would affect the services currently offered on telephone, cable, satellite, video networks, and cellular networks, as well as on the Internet.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2013497023",
    "type": "article"
  },
  {
    "title": "LAKE",
    "doi": "https://doi.org/10.1145/2542214.2542216",
    "publication_date": "2013-12-01",
    "publication_year": 2013,
    "authors": "Kemal Biçakcı; Bruno Crispo; Gabriele Oligeri",
    "corresponding_authors": "",
    "abstract": "Server-side authenticated key-establishment protocols are characterized by placing a heavy workload on the server. We propose LAKE: a new protocol that enables amortizing servers’ workload peaks by moving most of the computational burden to the clients. We provide a formal analysis of the LAKE protocol under the Canetti-Krawczyk model and prove it to be secure. To the best of our knowledge, this is the most computationally efficient authenticated key-establishment ever proposed in the literature.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2051047485",
    "type": "article"
  },
  {
    "title": "TOIT Administrative Updates",
    "doi": "https://doi.org/10.1145/2499926.2499930",
    "publication_date": "2013-07-01",
    "publication_year": 2013,
    "authors": "Munindar P. Singh",
    "corresponding_authors": "Munindar P. Singh",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2077847646",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2499926",
    "publication_date": "2013-07-01",
    "publication_year": 2013,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Product visualization is able to help users easily get knowledge about the visual appearance of a product. It is useful in many application and commercialization scenarios. However, the existing product image search on e-commerce Web sites or general ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4233094757",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2049656",
    "publication_date": "2011-12-01",
    "publication_year": 2011,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "The global economy and society increasingly depends on computer networks linked together by the Internet. The importance of computer networks reaches far beyond the telecommunications sector since they have become a critical factor for many other ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4246947651",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2555514",
    "publication_date": "2013-11-01",
    "publication_year": 2013,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "We present a comprehensive classification of data misinterpretation problems and develop an approach to automatic detection and reconciliation of data interpretation conflicts in Web services composition. The approach uses a lightweight ontology ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4248678454",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2461321",
    "publication_date": "2013-05-01",
    "publication_year": 2013,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4252731906",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1944339",
    "publication_date": "2011-03-01",
    "publication_year": 2011,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Recent years have witnessed the emergence and rapid development of collaborative Web-based applications exemplified by Web-based office productivity applications. One major challenge in building these applications is maintaining data consistency while ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4253181934",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1993083",
    "publication_date": "2011-07-01",
    "publication_year": 2011,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "It is often difficult to tune the performance of modern component-based Internet services because: (1) component middleware are complex software systems that expose several independently tuned server resource management mechanisms; (2) session-oriented ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4253312114",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2542214",
    "publication_date": "2013-12-01",
    "publication_year": 2013,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4253563175",
    "type": "paratext"
  },
  {
    "title": "Using Priced Options to Solve the Exposure Problem in Sequential Auctions",
    "doi": "https://doi.org/10.1145/2390209.2390211",
    "publication_date": "2012-12-01",
    "publication_year": 2012,
    "authors": "Valentin Robu; Lonneke Mous; Han La Poutré",
    "corresponding_authors": "",
    "abstract": "We propose a priced options model for solving the exposure problem of bidders with valuation synergies participating in a sequence of online auctions. We consider a setting in which complementary-valued items are offered sequentially by different sellers, who have the choice of either selling their item directly or through a priced option. In our model, the seller fixes the exercise price for this option, and then sells it through a first-price auction. We analyze this model from a decision-theoretic perspective and we show, for a setting where the competition is formed by local bidders (which desire a single item), that using options can increase the expected profit for both sides. Furthermore, we derive the equations that provide minimum and maximum bounds between which the bids of the synergy buyer are expected to fall, in order for both sides of the market to have an incentive to use the options mechanism. Next, we perform an experimental analysis of a market in which multiple synergy buyers are active simultaneously. We show that, despite the extra competition, some synergy buyers may benefit, because sellers are forced to set their exercise prices for options at levels which encourage participation of all buyers.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W1996503387",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2220352",
    "publication_date": "2012-06-01",
    "publication_year": 2012,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "HTTP cookies are the de facto mechanism for session authentication in Web applications. However, their inherent security weaknesses allow attacks against the integrity of Web sessions. HTTPS is often recommended to protect cookies, but deploying full ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4236197694",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1552291",
    "publication_date": "2009-07-01",
    "publication_year": 2009,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4236992642",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1667067",
    "publication_date": "2010-02-01",
    "publication_year": 2010,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4237595045",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1852096",
    "publication_date": "2010-10-01",
    "publication_year": 2010,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Reliable network demographics are quickly becoming a much sought-after digital commodity. However, as the need for more refined Internet demographics has grown, so too has the tension between privacy and utility. Unfortunately, current techniques lean ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4239285924",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1592446",
    "publication_date": "2009-09-01",
    "publication_year": 2009,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "XML-enabled publish-subscribe (pub-sub) systems have emerged as an increasingly important tool for e-commerce and Internet applications. In a typical pub-sub system, subscribed users specify their interests in a profile expressed in the XPath language. ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4240998810",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1516539",
    "publication_date": "2009-05-01",
    "publication_year": 2009,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Net neutrality represents the idea that Internet users are entitled to service that does not discriminate on the basis of source, destination, or ownership of Internet traffic. The United States Congress is considering legislation on net neutrality, and ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4242627460",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1462159",
    "publication_date": "2009-02-01",
    "publication_year": 2009,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "In this article, we present techniques for provisioning CPU and network resources in shared Internet hosting platforms running potentially antagonistic third-party applications. The primary contribution of our work is to demonstrate the feasibility and ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4244041531",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2078316",
    "publication_date": "2012-01-01",
    "publication_year": 2012,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Context-aware Web services are identified as an important technology to support new applications on the future Internet. Context information has several qualities that make the development of these services challenging, compared to conventional, Web ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4246780844",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2390209",
    "publication_date": "2012-12-01",
    "publication_year": 2012,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "This article proposes a new delivery-centric abstraction which extends the existing content-centric networking API. A delivery-centric abstraction allows applications to generate content requests agnostic to location or protocol, with the additional ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4247680827",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2109211",
    "publication_date": "2012-03-01",
    "publication_year": 2012,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Firewalls are the cornerstones of the security infrastructure for most enterprises. They have been widely deployed for protecting private networks. The quality of the protection provided by a firewall directly depends on the quality of its policy (i.e., ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4256492675",
    "type": "paratext"
  },
  {
    "title": "Guest editorial",
    "doi": "https://doi.org/10.1145/1275505.1275506",
    "publication_date": "2007-08-01",
    "publication_year": 2007,
    "authors": "Amar Gupta; Satwiksai Seshasai",
    "corresponding_authors": "",
    "abstract": "editorial Free Access Share on Guest editorial: The Internet and outsourcing Authors: Amar Gupta University of Arizona University of ArizonaView Profile , Satwiksai Seshasai IBM and MIT IBM and MITView Profile Authors Info & Claims ACM Transactions on Internet TechnologyVolume 7Issue 3August 2007 pp 13–eshttps://doi.org/10.1145/1275505.1275506Published:01 August 2007Publication History 0citation512DownloadsMetricsTotal Citations0Total Downloads512Last 12 Months13Last 6 weeks2 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my Alerts New Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2008692179",
    "type": "editorial"
  },
  {
    "title": "Guest editorial",
    "doi": "https://doi.org/10.1145/1361186.1361187",
    "publication_date": "2008-05-01",
    "publication_year": 2008,
    "authors": "Qusay H. Mahmoud; Peter Langendöerfer",
    "corresponding_authors": "",
    "abstract": "editorial Free Access Share on Guest editorial: Service-oriented computing Authors: Qusay H. Mahmoud University of Guelph, Canada University of Guelph, CanadaView Profile , Peter Langendoerfer IHP, Germany IHP, GermanyView Profile Authors Info & Claims ACM Transactions on Internet TechnologyVolume 8Issue 3May 2008 Article No.: 11pp 1–3https://doi.org/10.1145/1361186.1361187Published:28 May 2008Publication History 0citation526DownloadsMetricsTotal Citations0Total Downloads526Last 12 Months1Last 6 weeks1 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my Alerts New Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2043874930",
    "type": "editorial"
  },
  {
    "title": "Facilitating Adoption of Internet Technologies and Services with Externalities via Cost Subsidization",
    "doi": "https://doi.org/10.1145/3091109",
    "publication_date": "2017-08-18",
    "publication_year": 2017,
    "authors": "Steven Weber",
    "corresponding_authors": "Steven Weber",
    "abstract": "This article models the temporal adoption dynamics of an abstracted Internet technology or service, where the instantaneous net value of the service perceived by each (current or potential) user/customer incorporates three key features: (i) user service affinity heterogeneity, (ii) a network externality, and (iii) a subscription cost. Internet technologies and services with network externalities face a “chicken-and-egg” adoption problem in that the service requires an established customer base to attract new customers. In this article, we study cost subsidization as a means to “reach the knee,” at which point the externality drives rapid service adoption, and thereby change the equilibrium service fractional adoption level from an initial near-zero level to a final near-one level (full adoption). We present three simple subsidy models and evaluate them under two natural performance metrics: (i) the duration required for the subsidized service to reach a given target adoption level and (ii) the aggregate cost of the subsidy born by the service provide. First, we present a “two-target adoption subsidy” that subsidizes the cost to keep the fraction of users with positive net utility at a (constant) target level until the actual adoption target is reached. Second, we study a special case of the above where the target ensures all users have positive net utility, corresponding to a “quickest adoption” subsidy (QAS). Third, we introduce an approximation of QAS that only requires the service provider adjust the subsidy level a prescribed number of times. Fourth, we study equilibria and their stability under uniformly and normally distributed user service affinities, highlighting the unstable equilibrium in each case as the natural target adoption level for the provider. Finally, we provide a fictional case study to illustrate the application of the results in a (hopefully) realistic scenario, along with a brief discussion of the limitations of the model and analysis.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2610275243",
    "type": "article"
  },
  {
    "title": "Introduction to the Special Issue on Advances in Social Computing",
    "doi": "https://doi.org/10.1145/3080258",
    "publication_date": "2017-05-24",
    "publication_year": 2017,
    "authors": "Amit K. Chopra; Erez Shmueli; Vivek K. Singh",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2617679675",
    "type": "article"
  },
  {
    "title": "TOIT Reviewers over 2015 and 2016",
    "doi": "https://doi.org/10.1145/3140541",
    "publication_date": "2017-11-30",
    "publication_year": 2017,
    "authors": "Munindar P. Singh",
    "corresponding_authors": "Munindar P. Singh",
    "abstract": "editorial Free Access Share on TOIT Reviewers over 2015 and 2016 Editor: Munindar P. Singh View Profile Authors Info & Claims ACM Transactions on Internet TechnologyVolume 18Issue 1February 2018 Article No.: 12pp 1–7https://doi.org/10.1145/3140541Published:30 November 2017Publication History 0citation238DownloadsMetricsTotal Citations0Total Downloads238Last 12 Months20Last 6 weeks2 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2773650477",
    "type": "article"
  },
  {
    "title": "Seamless Virtual Network for International Business Continuity in Presence of Intentional Blocks",
    "doi": "https://doi.org/10.1145/3133325",
    "publication_date": "2017-12-15",
    "publication_year": 2017,
    "authors": "Hiroshi Fujikawa; Hirofumi Yamaki; Setsuo Tsuruta",
    "corresponding_authors": "",
    "abstract": "In developing countries, links are poor among domestic communities or internet service providers. Besides, international internet channels are suddenly blocked by such as Golden Shield (GS) in China. Offshore business communications are involved in these. To avoid such involvement, a seamless virtual network is proposed as an international business communication bridging solution. This uses Round Trip Time (RTT) based multiple thresholds for differential switch to Virtual Private Network (VPN) bypass. The characteristics are (1) using multiple threshold integrated differential calculus of RTT increase, a sign of the block is recognized as the steep staircase increase of RTT, (2) followed by the immediate automatic switch to VPN having RTT below 200ms. (3) Asymmetrically, only the absolute threshold value and continuation time are used to determine when to switch back. This method is analytically and statistically evaluated as being successful (below 3% errors), using around 200 cases of data on GS blocks. Furthermore, it has been validated by the real seamless usage in more than 20 offshore companies for three years. Besides response time in offshore applications, our method can also alleviate problems such as voice echoes and video jitters which irritate business users. These effects were validated analytically and by questionnaires to scores of business customers.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2778079900",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1391949",
    "publication_date": "2008-09-01",
    "publication_year": 2008,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "In spite of the use of standard Web security measures (SSL/TLS), users enter sensitive information such as passwords into fake Web sites. Such fake sites cause substantial damages to individuals and corporations. In this work, we identify several ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4232174241",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1239971",
    "publication_date": "2007-05-01",
    "publication_year": 2007,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4232288728",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1323651",
    "publication_date": "2008-02-01",
    "publication_year": 2008,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4232350460",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1278366",
    "publication_date": "2007-10-01",
    "publication_year": 2007,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "This article addresses search engine personalization. We present a new approach to mining a user's preferences on the search results from clickthrough data and using the discovered preferences to adapt the search engine's ranking function for improving ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4232829502",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3106680",
    "publication_date": "2017-07-14",
    "publication_year": 2017,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Debating technologies, a newly emerging strand of research into computational technologies to support human debating, offer a powerful way of providing naturalistic, dialogue-based interaction with complex information spaces. The full potential of ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4236566190",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3155100",
    "publication_date": "2017-12-15",
    "publication_year": 2017,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Connected Communities (CCs) are socio-technical systems that rely on an information and communication technology (ICT) infrastructure to integrate people and organizations (companies, schools, hospitals, universities, local and national government ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4239125429",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3133307",
    "publication_date": "2017-09-29",
    "publication_year": 2017,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Provenance is an increasingly important tool for understanding and even actively preventing system intrusion, but the excessive storage burden imposed by automatic provenance collection threatens to undermine its value in practice. This situation is ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4248159420",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1361186",
    "publication_date": "2008-05-01",
    "publication_year": 2008,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4250558284",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1275505",
    "publication_date": "2007-08-01",
    "publication_year": 2007,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4252251568",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1189740",
    "publication_date": "2007-02-01",
    "publication_year": 2007,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "The World Wide Web has enabled anybody with a low cost Internet connection to access vast information repositories. Some of these repositories contain information (e.g., hate speech and pornography) that is considered objectionable, especially for ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4255016536",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3036639",
    "publication_date": "2017-03-06",
    "publication_year": 2017,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Software-based agents are becoming increasingly ubiquitous and automated. However, current technology and algorithms are still fallible, which considerably affects users’ trust and interaction with such agents. In this article, we investigate two ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4255721293",
    "type": "paratext"
  },
  {
    "title": "Guest Editors’ Introduction for Special Issue on Applications of Computational Linguistics in Multimedia IoT Services",
    "doi": "https://doi.org/10.1145/3591355",
    "publication_date": "2023-05-23",
    "publication_year": 2023,
    "authors": "Quan Z. Sheng; Arun Kumar Sangaiah; Ankit Chaudhary",
    "corresponding_authors": "",
    "abstract": "introduction Share on Guest Editors’ Introduction for Special Issue on Applications of Computational Linguistics in Multimedia IoT Services Authors: Quan Z. Sheng School of Computing, Macquarie University, Sydney, Australia School of Computing, Macquarie University, Sydney, Australia 0000-0002-3326-4147View Profile , Arun Kumar Sangaiah National Yunlin University of Science and Technology, Taiwan National Yunlin University of Science and Technology, Taiwan 0000-0002-0229-2460View Profile , Ankit Chaudhary Department of Computer Science, University of Missouri at Saint Louis, USA Department of Computer Science, University of Missouri at Saint Louis, USA 0000-0001-7510-1963View Profile Authors Info & Claims ACM Transactions on Internet TechnologyVolume 23Issue 223 May 2023Article No.: 24pp 1–3https://doi.org/10.1145/3591355Published:23 May 2023Publication History 0citation28DownloadsMetricsTotal Citations0Total Downloads28Last 12 Months28Last 6 weeks28 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteGet Access",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4377821138",
    "type": "article"
  },
  {
    "title": "Special Section on “Advances in Cyber-Manufacturing: Architectures, Challenges, &amp; Future Research Directions”",
    "doi": "https://doi.org/10.1145/3627990",
    "publication_date": "2023-11-17",
    "publication_year": 2023,
    "authors": "Gautam Srivastava; Jerry Chun‐Wei Lin; Calton Pu; Yudong Zhang",
    "corresponding_authors": "",
    "abstract": "introduction Share on Special Section on “Advances in Cyber-Manufacturing: Architectures, Challenges, & Future Research Directions” Editors: Gautam Srivastava Brandon University, Canada Brandon University, CanadaSearch about this author , Jerry Chun-Wei Lin Silesian Uiversity of Technology, Poland Silesian Uiversity of Technology, PolandSearch about this author , Calton Pu Georgia Tech, USA Georgia Tech, USASearch about this author , Yudong Zhang University of Leicester, UK University of Leicester, UKSearch about this author Authors Info & Claims ACM Transactions on Internet TechnologyVolume 23Issue 4Article No.: 49pp 1–4https://doi.org/10.1145/3627990Published:17 November 2023Publication History 0citation0DownloadsMetricsTotal Citations0Total Downloads0Last 12 Months0Last 6 weeks0 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteGet Access",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4388763650",
    "type": "article"
  },
  {
    "title": "A wide-area Distribution Network for free software",
    "doi": "https://doi.org/10.1145/1151087.1151089",
    "publication_date": "2006-08-01",
    "publication_year": 2006,
    "authors": "Arno Bakker; Maarten van Steen; Andrew S. Tanenbaum",
    "corresponding_authors": "",
    "abstract": "The Globe Distribution Network (GDN) is an application for the efficient, worldwide distribution of freely redistributable software packages. Distribution is made efficient by encapsulating the software into special distributed objects which efficiently replicate themselves near to the downloading clients. The Globe Distribution Network takes a novel, optimistic approach to stop the illegal distribution of copyrighted and illicit material via the network. Instead of having moderators check the packages at upload time, illegal content is removed and its uploader's access to the network permanently revoked only when the violation is discovered. Other protective measures defend the GDN against internal and external attacks to its availability. By exploiting the replication of the software and using fault-tolerant server software, the Globe Distribution Network achieves high availability. A prototype implementation of the GDN is available from http://www.cs.vu.nl/globe/.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2111756215",
    "type": "article"
  },
  {
    "title": "Introduction to the Special Issue on Emerging Software Technologies for Internet-Based Systems",
    "doi": "https://doi.org/10.1145/3173572",
    "publication_date": "2018-03-13",
    "publication_year": 2018,
    "authors": "Tao Xie; André van Hoorn; Huaimin Wang; Ingo Weber",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2793774151",
    "type": "article"
  },
  {
    "title": "Special Issue",
    "doi": "https://doi.org/10.1145/3195835",
    "publication_date": "2018-04-24",
    "publication_year": 2018,
    "authors": "Cristina Baroglio; Olivier Boissier; Axel Polleres",
    "corresponding_authors": "",
    "abstract": "editorial Free AccessSpecial Issue: Computational Ethics and Accountability Share on Authors: Cristina Baroglio University of Torino, Italy, Torino (TO), Italy University of Torino, Italy, Torino (TO), ItalyView Profile , Olivier Boissier Univ. Lyon, IMT Mines, Saint-Etienne, CNRS, Laboratoire Hubert Curien UMR 5516, France Univ. Lyon, IMT Mines, Saint-Etienne, CNRS, Laboratoire Hubert Curien UMR 5516, FranceView Profile , Axel Polleres Vienna Univ. of Economics and Business 8 Complexity Science Hub Vienna, Austria Vienna Univ. of Economics and Business 8 Complexity Science Hub Vienna, AustriaView Profile Authors Info & Affiliations ACM Transactions on Internet TechnologyVolume 18Issue 4November 2018 Article No.: 40pp 1–4https://doi.org/10.1145/3195835Published:24 April 2018 0citation475DownloadsMetricsTotal Citations0Total Downloads475Last 12 Months110Last 6 weeks9 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2800245524",
    "type": "article"
  },
  {
    "title": "Guest Editors’ Introduction for Special Issue on Service Management for the Internet of Things",
    "doi": "https://doi.org/10.1145/3293539",
    "publication_date": "2018-12-22",
    "publication_year": 2018,
    "authors": "Samir Tata; Quan Z. Sheng; Eleni Stroulia",
    "corresponding_authors": "",
    "abstract": "editorial Free Access Share on Guest Editors’ Introduction for Special Issue on Service Management for the Internet of Things Authors: Samir Tata IBM Research, USA IBM Research, USAView Profile , Quan Z. Sheng Macquarie University, NSW, Australia Macquarie University, NSW, AustraliaView Profile , Eleni Stroulia University of Alberta, Alberta, Canada University of Alberta, Alberta, CanadaView Profile Authors Info & Claims ACM Transactions on Internet TechnologyVolume 19Issue 1February 2019 Article No.: 6pp 1–3https://doi.org/10.1145/3293539Published:22 December 2018Publication History 0citation285DownloadsMetricsTotal Citations0Total Downloads285Last 12 Months42Last 6 weeks9 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2906365555",
    "type": "article"
  },
  {
    "title": "Special Issue on the Economics of Security and Privacy",
    "doi": "https://doi.org/10.1145/3216902",
    "publication_date": "2018-11-19",
    "publication_year": 2018,
    "authors": "Rainer Böhme; Richard Clayton; Jens Großklags; Katrina Ligett; Patrick Loiseau; Galina Schwartz",
    "corresponding_authors": "",
    "abstract": "This editorial introduces the special issue on the economics of security and privacy.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2907642365",
    "type": "article"
  },
  {
    "title": "Guest Editors’ Introduction to the Special Issue on Knowledge-Driven Business Process Management",
    "doi": "https://doi.org/10.1145/3296981",
    "publication_date": "2019-02-21",
    "publication_year": 2019,
    "authors": "Aditya Ghose; Hamid R. Motahari Nezhad; Manfred Reichert",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2916992998",
    "type": "article"
  },
  {
    "title": "Guest Editors’ Introduction",
    "doi": "https://doi.org/10.1145/3177884",
    "publication_date": "2018-03-06",
    "publication_year": 2018,
    "authors": "Özgür Kafalı; Natalia Criado; Martin Řehák; José M. Such; Pınar Yolum",
    "corresponding_authors": "",
    "abstract": "editorial Free Access Share on Guest Editors’ Introduction Authors: Özgür Kafali University of Kent, Canterbury, Kent, UK University of Kent, Canterbury, Kent, UKView Profile , Natalia Criado King’s College London, London, UK King’s College London, London, UKView Profile , Martin Rehak Cisco Systems, Czech Republic Cisco Systems, Czech RepublicView Profile , Jose M. Such King’s College London, London, UK King’s College London, London, UKView Profile , Pinar Yolum Utrecht University, Utrecht, Netherlands Utrecht University, Utrecht, NetherlandsView Profile Authors Info & Claims ACM Transactions on Internet TechnologyVolume 18Issue 3August 2018 Article No.: 26pp 1–4https://doi.org/10.1145/3177884Published:06 March 2018Publication History 0citation462DownloadsMetricsTotal Citations0Total Downloads462Last 12 Months21Last 6 weeks4 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2923168227",
    "type": "article"
  },
  {
    "title": "A Dynamic Data-throttling Approach to Minimize Workflow Imbalance",
    "doi": "https://doi.org/10.1145/3278720",
    "publication_date": "2019-05-07",
    "publication_year": 2019,
    "authors": "Ricardo J. Rodríguez; Rafael Tolosana‐Calasanz; Omer Rana",
    "corresponding_authors": "",
    "abstract": "Scientific workflows enable scientists to undertake analysis on large datasets and perform complex scientific simulations. These workflows are often mapped onto distributed and parallel computational infrastructures to speed up their executions. Prior to its execution, a workflow structure may suffer transformations to accommodate the computing infrastructures, normally involving task clustering and partitioning. However, these transformations may cause workflow imbalance because of the difference between execution task times (runtime imbalance) or because of unconsidered data dependencies that lead to data locality issues (data imbalance). In this article, to mitigate these imbalances, we enhance the workflow lifecycle process in use by introducing a workflow imbalance phase that quantifies workflow imbalance after the transformations. Our technique is based on structural analysis of Petri nets, obtained by model transformation of a data-intensive workflow, and Linear Programming techniques. Our analysis can be used to assist workflow practitioners in finding more efficient ways of transforming and scheduling their workflows. Moreover, based on our analysis, we also propose a technique to mitigate workflow imbalance by data throttling. Our approach is based on autonomic computing principles that determine how data transmission must be throttled throughout workflow jobs. Our autonomic data-throttling approach mainly monitors the execution of the workflow and recompute data-throttling values when certain watchpoints are reached and time derivation is observed. We validate our approach by a formal proof and by simulations along with the Montage workflow. Our findings show that a dynamic data-throttling approach is feasible, does not introduce a significant overhead, and minimizes the usage of input buffers and network bandwidth.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2943998133",
    "type": "article"
  },
  {
    "title": "オンラインソーシャルネットワークにおける社会的責任としてのプライバシーの保存【JST・京大機械翻訳】",
    "doi": null,
    "publication_date": "2018-01-01",
    "publication_year": 2018,
    "authors": "Kekulluoglu Dilara; K ouml kciyan Nadin; Yolum Pinar",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3178769973",
    "type": "article"
  },
  {
    "title": "Webページ解析のための新しいブロックレイアウトの構築【JST・京大機械翻訳】",
    "doi": null,
    "publication_date": "2019-01-01",
    "publication_year": 2019,
    "authors": "Jiang Zexun; Hao Yin; Wu Yulei; Yongqiang Lyu; Geyong Min; Xu Zhang",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3190627711",
    "type": "article"
  },
  {
    "title": "クラウドにおけるデータ中心型サービスの文脈駆動および実時間提供【JST・京大機械翻訳】",
    "doi": null,
    "publication_date": "2018-01-01",
    "publication_year": 2018,
    "authors": "Taherkordi Amir; E. Frank; Mcdonald Michael; Horn Geir",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3209967598",
    "type": "article"
  },
  {
    "title": "Corrigenda",
    "doi": "https://doi.org/10.1145/1084772.1084777",
    "publication_date": "2005-08-01",
    "publication_year": 2005,
    "authors": "Vasilis Vassalos",
    "corresponding_authors": "Vasilis Vassalos",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4229725553",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3283809",
    "publication_date": "2019-03-05",
    "publication_year": 2019,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "User behaviors in online social networks convey not only literal information but also one’s emotional attitudes towards the information. To compute this attitude, we define the concept of emotion role as the concentrated reflection of a user’s online ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4229806972",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3322882",
    "publication_date": "2019-04-24",
    "publication_year": 2019,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Research in the Internet of Things (IoT) conceives a world where everyday objects are connected to the Internet and exchange, store, process, and collect data from the surrounding environment. IoT devices are becoming essential for supporting the ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4229933079",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3210373",
    "publication_date": "2018-11-19",
    "publication_year": 2018,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4230843820",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3362102",
    "publication_date": "2019-11-27",
    "publication_year": 2019,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "In this article, we propose the PTP-MF (Pairwise Trust Prediction through Matrix Factorisation) algorithm, an approach to predicting the intensity of trust and distrust relations in Online Social Networks (OSNs).",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4234238089",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3185332",
    "publication_date": "2018-05-30",
    "publication_year": 2018,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "To create solutions for providing the required access control in computer networks it is not sufficient to have only tools and protocols in the network that are needed for it. It is necessary to create corresponding configuration, or scheme, of such ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4236012431",
    "type": "paratext"
  },
  {
    "title": "Guest editorial",
    "doi": "https://doi.org/10.1145/990301.990302",
    "publication_date": "2004-05-01",
    "publication_year": 2004,
    "authors": "Gary William Flake; Paolo Frasconi; C. Lee Giles; Marco Maggini",
    "corresponding_authors": "",
    "abstract": "editorial Free Access Share on Guest editorial: Machine learning for the Internet Authors: Gary William Flake Yahoo! Research Labs Yahoo! Research LabsView Profile , Paolo Frasconi Università di Firenze Università di FirenzeView Profile , C. Lee Giles Pennsylvania State University Pennsylvania State UniversityView Profile , Marco Maggini Università di Siena Università di SienaView Profile Authors Info & Claims ACM Transactions on Internet TechnologyVolume 4Issue 2May 2004 pp 125–128https://doi.org/10.1145/990301.990302Online:01 May 2004Publication History 0citation765DownloadsMetricsTotal Citations0Total Downloads765Last 12 Months14Last 6 weeks0 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4237965956",
    "type": "editorial"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1149121",
    "publication_date": "2006-05-01",
    "publication_year": 2006,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Recently several authors have proposed stochastic evolutionary models for the growth of the Web graph and other networks that give rise to power-law distributions. These models are based on the notion of preferential attachment, leading to the “rich get ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4239394314",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1125274",
    "publication_date": "2006-02-01",
    "publication_year": 2006,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4240162882",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3329912",
    "publication_date": "2019-11-22",
    "publication_year": 2019,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "In recent years, we have witnessed a growing trend for online service companies to offer “bundling sales” to increase revenue. Bundling sale means that a company groups a set of products/services and charges this bundle at a fixed price, which is ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4248265144",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1151087",
    "publication_date": "2006-08-01",
    "publication_year": 2006,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4254297875",
    "type": "paratext"
  },
  {
    "title": "Introduction to the Special Section on Computational Modeling and Understanding of Emotions in Conflictual Social Interactions",
    "doi": "https://doi.org/10.1145/3392334",
    "publication_date": "2020-05-23",
    "publication_year": 2020,
    "authors": "Rossana Damiano; Viviana Patti; Chloé Clavel; Paolo Rosso",
    "corresponding_authors": "",
    "abstract": "introduction Free AccessIntroduction to the Special Section on Computational Modeling and Understanding of Emotions in Conflictual Social Interactions Share on Authors: Rossana Damiano Dipartimento di Informatica University of Turin, Turin, Italy Dipartimento di Informatica University of Turin, Turin, ItalyView Profile , Viviana Patti Dipartimento di Informatica University of Turin, Turin, Italy Dipartimento di Informatica University of Turin, Turin, ItalyView Profile , Chloé Clavel LTCI, Telecom Paris, Institut Polytechnique de Paris, Paris, France LTCI, Telecom Paris, Institut Polytechnique de Paris, Paris, FranceView Profile , Paolo Rosso Universitat Politècnica de València, València, Spain Universitat Politècnica de València, València, SpainView Profile Authors Info & Claims ACM Transactions on Internet TechnologyVolume 20Issue 2May 2020 Article No.: 8pp 1–5https://doi.org/10.1145/3392334Online:23 May 2020Publication History 0citation285DownloadsMetricsTotal Citations0Total Downloads285Last 12 Months138Last 6 weeks1 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteView all FormatsPDF",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3033792951",
    "type": "article"
  },
  {
    "title": "過剰曝露を意識した影響最大化【JST・京大機械翻訳】",
    "doi": null,
    "publication_date": "2020-01-01",
    "publication_year": 2020,
    "authors": "Loukides Grigorios; Gwadera Robert; Chang Shing-Wan",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3163509554",
    "type": "article"
  },
  {
    "title": "EコマースブロックチェーンのためのトランザクションとコンセンサスインセンティブによるRTチェーンA評判システム【JST・京大機械翻訳】",
    "doi": null,
    "publication_date": "2020-01-01",
    "publication_year": 2020,
    "authors": "Sun You; Xue Rui; Zhang Rui; Su Qianqian; Gao Sheng",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3197887652",
    "type": "article"
  },
  {
    "title": "<i>NLUBroker</i> : A QoE-driven Broker System for Natural Language Understanding Services",
    "doi": "https://doi.org/10.1145/3497807",
    "publication_date": "2022-02-01",
    "publication_year": 2022,
    "authors": "Lanyu Xu; Arun Iyengar; Weisong Shi",
    "corresponding_authors": "",
    "abstract": "Cloud-based Natural Language Understanding (NLU) services are becoming more popular with the development of artificial intelligence. More applications are integrated with cloud-based NLU services to enhance the way people communicate with machines. However, with NLU services provided by different companies powered by unrevealed AI technology, how to choose the best one is a problem for developers. Existing tools that can provide guidance to developers and make recommendations based on their needs are severely limited. This article comprehensively evaluates multiple state-of-the-art NLU services, and the results indicate that there is no absolute winner for different usage requirements. Motivated by this observation, we provide several insights and propose NLUBroker , a Quality of Experience-driven (QoE-driven) broker system, to select the proper service according to the environment. NLUBroker senses the client and service status and leverages a solution to the multi-armed bandit problem to conduct online learning, aiming to achieve maximum expected QoE. The performance of NLUBroker is evaluated in both simulation and real-world environments, and the evaluation results demonstrate that NLUBroker is an efficient solution for selecting NLU services. It is adaptive to changes in the environment, outperforms three baseline methods we evaluated and improves overall QoE up to 1.5× for the evaluated state-of-the-art NLU services.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4210521001",
    "type": "article"
  },
  {
    "title": "Special Section on Edge-AI for Connected Living",
    "doi": "https://doi.org/10.1145/3514196",
    "publication_date": "2022-03-14",
    "publication_year": 2022,
    "authors": "M. Shamim Hossain; Changsheng Xu; Josu Bilbao; Md. Abdur Rahman; Abdulmotaleb El Saddik; Mohamed Bin Zayed",
    "corresponding_authors": "",
    "abstract": "introduction Share on Special Section on Edge-AI for Connected Living Editors: M. Shamim Hossain King Saud University, Saudi Arabia King Saud University, Saudi ArabiaView Profile , Changsheng Xu Chinese Academy of Sciences, China Chinese Academy of Sciences, ChinaView Profile , Josu Bilbao IKERLAN, Spain IKERLAN, SpainView Profile , Md. Abdur Rahman University of Prince Mugrin, KSA University of Prince Mugrin, KSAView Profile , Abdulmotaleb El Saddik University of Ottawa, Canada University of Ottawa, CanadaView Profile , Mohamed Bin Zayed University of Artificial Intelligence, UAE & University of Ottawa, Canada University of Artificial Intelligence, UAE & University of Ottawa, CanadaView Profile Authors Info & Claims ACM Transactions on Internet TechnologyVolume 22Issue 3August 2022 Article No.: 55epp 1–3https://doi.org/10.1145/3514196Published:14 March 2022Publication History 0citation176DownloadsMetricsTotal Citations0Total Downloads176Last 12 Months176Last 6 weeks24 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my Alerts New Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteGet Access",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4221114533",
    "type": "article"
  },
  {
    "title": "Extracting Formats of Service Messages with Varying Payloads",
    "doi": "https://doi.org/10.1145/3503159",
    "publication_date": "2022-02-01",
    "publication_year": 2022,
    "authors": "Md. Arafat Hossain; Jun Han; Jean-Guy Schneider; Jiaojiao Jiang; Muhammad Ashad Kabir; Steve Versteeg",
    "corresponding_authors": "",
    "abstract": "Having precise specifications of service APIs is essential for many Software Engineering activities. Unfortunately, available documentation of services is often inadequate and/or imprecise and, hence, cannot be fully relied upon. Generating service documentation manually is a tedious and error-prone task, especially in light of changes to services. Therefore, there is a need for automated support in generating service documentation. In this work, we present a novel approach to infer the API of a service by analyzing recorded messages sent to and received from this service. Our approach includes a novel, two-level clustering technique to cluster messages, a step that many existing approaches to infer message formats fail to perform precisely in the presence of significant variation of payload information of the available messages. We have evaluated our approach on message traces from four different real-world services. The experimental result shows that our approach is more effective than existing techniques in extracting correct message formats from recorded messages.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4225469019",
    "type": "article"
  },
  {
    "title": "SDN-enabled Resource Provisioning Framework for Geo-Distributed Streaming Analytics",
    "doi": "https://doi.org/10.1145/3571158",
    "publication_date": "2022-11-10",
    "publication_year": 2022,
    "authors": "Habib Mostafaei; Shafi Afridi",
    "corresponding_authors": "",
    "abstract": "Geographically distributed (geo-distributed) datacenters for stream data processing typically comprise multiple edges and core datacenters connected through Wide-Area Network (WAN) with a master node responsible for allocating tasks to worker nodes. Since WAN links significantly impact the performance of distributed task execution, the existing task assignment approach is unsuitable for distributed stream data processing with low latency and high throughput demand. In this paper, we propose SAFA, a resource provisioning framework using the Software-Defined Networking (SDN) concept with an SDN controller responsible for monitoring the WAN, selecting an appropriate subset of worker nodes, and assigning tasks to the designated worker nodes. We implemented the data plane of the framework in P4 and the control plane components in Python. We tested the performance of the proposed system on Apache Spark, Apache Storm, and Apache Flink using the Yahoo! streaming benchmark on a set of custom topologies. The results of the experiments validate that the proposed approach is viable for distributed stream processing and confirm that it can improve at least 1.64× the processing time of incoming events of the current stream processing systems.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4308884320",
    "type": "article"
  },
  {
    "title": "Introduction to the Special Section on Edge Computing AI-IoT Integrated Energy Efficient Intelligent Transportation System for Smart Cities",
    "doi": "https://doi.org/10.1145/3584745",
    "publication_date": "2022-11-30",
    "publication_year": 2022,
    "authors": "Vicente García‐Díaz; Jerry Chun‐Wei Lin; Juan Antonio Morente-Molinera",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4323060301",
    "type": "article"
  },
  {
    "title": "Introduction to the Special Issue on Multiagent Systems and Services in the Internet of Things",
    "doi": "https://doi.org/10.1145/3584744",
    "publication_date": "2022-11-30",
    "publication_year": 2022,
    "authors": "Andrei Ciortea; Xiaomin Zhu; Calton Pu; Munindar P. Singh",
    "corresponding_authors": "",
    "abstract": "research-article Share on Introduction to the Special Issue on Multiagent Systems and Services in the Internet of Things Authors: Andrei Ciortea University of St. Gallen, Switzerland University of St. Gallen, Switzerland 0000-0003-0721-4135Search about this author , Xiaomin Zhu National University of Defense Technology, China National University of Defense Technology, China 0000-0003-1301-7840Search about this author , Calton Pu Georgia Institute of Technology, USA Georgia Institute of Technology, USA 0000-0002-6616-8987Search about this author , Munindar P. Singh North Carolina State University, USA North Carolina State University, USA 0000-0003-3599-3893Search about this author Authors Info & Claims ACM Transactions on Internet TechnologyVolume 22Issue 4November 2022 Article No.: 99pp 1–3https://doi.org/10.1145/3584744Published:03 March 2023Publication History 0citation0DownloadsMetricsTotal Citations0Total Downloads0Last 12 Months0Last 6 weeks0 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteGet Access",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4323060425",
    "type": "article"
  },
  {
    "title": "Introduction to the Special Section on Recent Advances in Networks and Distributed Systems",
    "doi": "https://doi.org/10.1145/3584743",
    "publication_date": "2022-11-30",
    "publication_year": 2022,
    "authors": "Mathias Fischer; Winfried Lamersdorf; Jörg Liebeherr; Max Mühlhäuser",
    "corresponding_authors": "",
    "abstract": "introduction Share on Introduction to the Special Section on Recent Advances in Networks and Distributed Systems Authors: Mathias Fischer Universität Hamburg, Hamburg, Germany Universität Hamburg, Hamburg, GermanySearch about this author , Winfried Lamersdorf Universität Hamburg, Hamburg, Germany Universität Hamburg, Hamburg, GermanySearch about this author , Jörg Liebeherr University of Toronto, Toronto, Ontario, Canada University of Toronto, Toronto, Ontario, CanadaSearch about this author , Max Mühlhäuser TU Darmstadt, Darmstadt, Germany TU Darmstadt, Darmstadt, GermanySearch about this author Authors Info & Claims ACM Transactions on Internet TechnologyVolume 22Issue 4November 2022 Article No.: 93pp 1–3https://doi.org/10.1145/3584743Published:15 March 2023Publication History 0citation0DownloadsMetricsTotal Citations0Total Downloads0Last 12 Months0Last 6 weeks0 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteGet Access",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4327520620",
    "type": "article"
  },
  {
    "title": "A Novel Image Inpainting Framework Using Regression",
    "doi": "https://doi.org/10.1145/3402177",
    "publication_date": "2021-06-16",
    "publication_year": 2021,
    "authors": "Somanka Maiti; Ashish Kumar; Smriti Jain; Gaurav Bhatnagar",
    "corresponding_authors": "",
    "abstract": "In this article, a blockwise regression-based image inpainting framework is proposed. The core idea is to fill the unknown region in two stages: Extrapolate the edges to the unknown region and then fill the unknown pixels values in each sub-region demarcated by the extended edges. Canny edge detection and linear edge extension are used to respectively identify and extend edges to the unknown region followed by regression within each sub-region to predict the unknown pixel values. Two different regression models based on K-nearest neighbours and support vectors machine are used to predict the unknown pixel values. The proposed framework has the advantage of inpainting without requiring prior training on any image dataset. The extensive experiments on different images with contrasting distortions demonstrate the robustness of the proposed framework and a detailed comparative analysis shows that the proposed technique outperforms existing state-of-the-art image inpainting methods. Finally, the proposed techniques are applied to MRI images suffering from susceptibility artifacts to illustrate the practical usage of the proposed work.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3167374240",
    "type": "article"
  },
  {
    "title": "An Efficient Interaction Protocol Inference Scheme for Incompatible Updates in IoT Environments",
    "doi": "https://doi.org/10.1145/3430501",
    "publication_date": "2021-10-22",
    "publication_year": 2021,
    "authors": "Heesuk Son; Dongman Lee",
    "corresponding_authors": "",
    "abstract": "Incompatible updates of IoT systems and protocols give rise to interoperability problems. Even though various protocol adaptation and unknown protocol inference schemes have been proposed, they either do not work where the updated protocol specifications are not given or suffer from inefficiency issues. In this work, we present an efficient protocol inference scheme for incompatible updates in IoT environments. The scheme refines an active automata learning algorithm, L*, by incorporating a knowledge base of the legacy protocol behavior into its membership query selection procedure for updated protocol behavior inference. It also infers protocol syntax based on our previous work that computes the most probable message field updates and adapts the legacy protocol message accordingly. We evaluate the proposed scheme with two case studies with the most popular IoT protocols and prove that it infers updated protocols efficiently while improving the L* algorithm’s performance for resolving the incompatibility.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3209755829",
    "type": "article"
  },
  {
    "title": "Edge Computing to Solve Security Issues for Infectious Disease Intelligence Prevention",
    "doi": "https://doi.org/10.1145/3475869",
    "publication_date": "2021-11-29",
    "publication_year": 2021,
    "authors": "Zhihan Lv; Ranran Lou; Haibin Lv",
    "corresponding_authors": "",
    "abstract": "Nowadays, with the rapid development of intelligent technology, it is urgent to effectively prevent infectious diseases and ensure people's privacy. The present work constructs the intelligent prevention system of infectious diseases based on edge computing by using the edge computing algorithm, and further deploys and optimizes the privacy information security defense strategy of users in the system, controls the cost, constructs the optimal conditions of the system security defense, and finally analyzes the performance of the model. The results show that the system delay decreases with the increase of power in the downlink. In the analysis of the security performance of personal privacy information, it is found that six different nodes can maintain the optimal strategy when the cost is minimized in the finite time domain and infinite time domain. In comparison with other classical algorithms in the communication field, when the intelligent prevention system of infectious diseases constructed adopts the best defense strategy, it can effectively reduce the consumption of computing resources of edge network equipment, and the prediction accuracy is obviously better than that of other algorithms, reaching 83%. Hence, the results demonstrate that the model constructed can ensure the safety performance and forecast accuracy, and achieve the best defense strategy at low cost, which provides experimental reference for the prevention and detection of infectious diseases in the later period.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3214800499",
    "type": "article"
  },
  {
    "title": "Extracting Formats of Service Messages with Varying Payloads",
    "doi": null,
    "publication_date": "2021-11-30",
    "publication_year": 2021,
    "authors": "Arafat Hossain; Jun Han; Jean-Guy Schneider; Jiaojiao Jiang; Muhammad Ashad Kabir; Steve Versteeg",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3215162959",
    "type": "article"
  },
  {
    "title": "Introduction To The Special Section On Edge/Fog Computing For Infectious Disease Intelligence",
    "doi": "https://doi.org/10.1145/3494119",
    "publication_date": "2021-12-06",
    "publication_year": 2021,
    "authors": "Kaijian Xia; Wenbing Zhao; Alireza Jolfaei; M. TAMER ÖZSU",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4200018309",
    "type": "article"
  },
  {
    "title": "Forecasting Trend of Coronavirus Disease 2019 using Multi-Task Weighted TSK Fuzzy System",
    "doi": "https://doi.org/10.1145/3475870",
    "publication_date": "2021-11-29",
    "publication_year": 2021,
    "authors": "Yizhang Jiang; Xiaoqing Gu; Lei Hua; Kang Li; Yuwen Tao; Bo Li",
    "corresponding_authors": "",
    "abstract": "Artificial intelligence– (AI) based fog/edge computing has become a promising paradigm for infectious disease. Various AI algorithms are embedded in cooperative fog/edge devices to construct medical Internet of Things environments, infectious disease forecast systems, smart health, and so on. However, these systems are usually done in isolation, which is called single-task learning. They do not consider the correlation and relationship between multiple/different tasks, so some common information in the model parameters or data characteristics is lost. In this study, each data center in fog/edge computing is considered as a task in the multi-task learning framework. In such a learning framework, a multi-task weighted Takagi-Sugeno-Kang (TSK) fuzzy system, called MW-TSKFS, is developed to forecast the trend of Coronavirus disease 2019 (COVID-19). MW-TSKFS provides a multi-task learning strategy for both antecedent and consequent parameters of fuzzy rules. First, a multi-task weighted fuzzy c-means clustering algorithm is developed for antecedent parameter learning, which extracts the public information among all tasks and the private information of each task. By sharing the public cluster centroid and public membership matrix, the differences of commonality and individuality can be further exploited. For consequent parameter learning of MW-TSKFS, a multi-task collaborative learning mechanism is developed based on ε-insensitive criterion and L2 norm penalty term, which can enhance the generalization and forecasting ability of the proposed fuzzy system. The experimental results on the real COVID-19 time series show that the forecasting tend model based on multi-task the weighted TSK fuzzy system has a high application value.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4200100109",
    "type": "article"
  }
]